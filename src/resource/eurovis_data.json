{"100": [{"image_id": 0, "file_name": "100_00.png", "page": 1, "dpi": 300, "bbox": [461, 829, 734, 972], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A sketch of the shear-warp mechanism.", "caption_bbox": [451, 979, 704, 992]}, {"image_id": 1, "file_name": "100_01.png", "page": 3, "dpi": 300, "bbox": [101, 708, 427, 835], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Pseudocode of the standard shear-warp algorithm.", "caption_bbox": [111, 841, 423, 854]}, {"image_id": 2, "file_name": "100_02.png", "page": 4, "dpi": 300, "bbox": [457, 619, 705, 771], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The scaling of the warped base plane image.", "caption_bbox": [445, 779, 725, 792]}, {"image_id": 3, "file_name": "100_03.png", "page": 4, "dpi": 300, "bbox": [138, 98, 395, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An edge rendered both with pre-interpolated shading (left) and post-interpolated shading (right). The order of classification, shading, and interpolation is inter- changed in these two variations. In post-interpolated shad- ing, the blur left by the interpolation filter can be removed in the classification stage, while in pre-interpolated shad- ing the interpolation is the final stage and the blur remains. ", "caption_bbox": [104, 310, 400, 415]}, {"image_id": 4, "file_name": "100_04.png", "page": 5, "dpi": 300, "bbox": [481, 682, 681, 962], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Intermediate slice in (a) unsheared space and (b) sheared space. ", "caption_bbox": [445, 970, 741, 999]}, {"image_id": 5, "file_name": "100_05.png", "page": 5, "dpi": 300, "bbox": [481, 105, 733, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Illustration of inter-slice undersampling and the interpolation of one intermediate slice per volume slice pair to resolve this. To show the actual sampling distance in volume space, we have left the volume slices unsheared. ", "caption_bbox": [445, 261, 741, 320]}, {"image_id": 6, "file_name": "100_06.png", "page": 6, "dpi": 300, "bbox": [457, 788, 725, 944], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A cubic cartesian grid cell vs. a body-centered grid (BCC) cell, drawn in relative proportions. The BCC grid cell has a sample point in the center of the cell. ", "caption_bbox": [451, 951, 747, 995]}, {"image_id": 7, "file_name": "100_07.png", "page": 10, "dpi": 300, "bbox": [103, 124, 746, 939], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Rendering results, 5122 image (S: Standard shear-warp, I: intermediate slice, P: post-interpolated classification, M: matched sampling) ", "caption_bbox": [111, 944, 738, 976]}, {"image_id": 8, "file_name": "100_08.png", "page": 11, "dpi": 300, "bbox": [102, 99, 740, 948], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Rendering results, 5122 image (S: Standard shear-warp, I: intermediate slice, P: post-interpolated classification, M: matched sampling) ", "caption_bbox": [111, 957, 732, 989]}], "101": [{"image_id": 0, "file_name": "101_00.png", "page": 5, "dpi": 300, "bbox": [162, 348, 669, 525], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The middle slice of the equivalent convolution kernel p using varying parameter settings: (a) S = 0, G = 1, (b) S = 1, G = 1, (c) S = 1, G = 0. ", "caption_bbox": [98, 536, 731, 565]}, {"image_id": 1, "file_name": "101_01.png", "page": 5, "dpi": 300, "bbox": [147, 117, 684, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) The original binary dithered image. (b) Gaussian filtering. (c) Feature-preserving filtering.", "caption_bbox": [153, 314, 676, 327]}, {"image_id": 2, "file_name": "101_02.png", "page": 7, "dpi": 300, "bbox": [108, 118, 724, 497], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A binary volume filtered with varying S and G parameters.", "caption_bbox": [242, 507, 587, 520]}, {"image_id": 3, "file_name": "101_03.png", "page": 7, "dpi": 300, "bbox": [120, 541, 711, 847], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Rendering of a 64 64 32 binary volume using the original (a) and the filtered (S = 3, G = 3) data (b).", "caption_bbox": [126, 856, 704, 869]}, {"image_id": 4, "file_name": "101_04.png", "page": 8, "dpi": 300, "bbox": [120, 541, 711, 847], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Rendering of the lobster using the original (a) and the filtered (S = 3, G = 12) data (b).", "caption_bbox": [170, 856, 658, 869]}, {"image_id": 5, "file_name": "101_05.png", "page": 8, "dpi": 300, "bbox": [108, 118, 724, 497], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A CT scan of a lobster filtered with varying S and G parameters.", "caption_bbox": [227, 507, 602, 520]}, {"image_id": 6, "file_name": "101_06.png", "page": 9, "dpi": 300, "bbox": [156, 117, 675, 387], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Direct volume rendering of a human body using the original (a) and the filtered (S = 1, G = 1) data (b).", "caption_bbox": [129, 396, 699, 409]}, {"image_id": 7, "file_name": "101_07.png", "page": 11, "dpi": 300, "bbox": [218, 117, 614, 940], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Direct volume rendering of a human body using the original (a) and the filtered (S = 1, G = 1) data (b).", "caption_bbox": [129, 949, 699, 962]}], "102": [{"image_id": 0, "file_name": "102_00.png", "page": 2, "dpi": 300, "bbox": [113, 111, 718, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Renderings of the head and upper torso from using the CIE L\u2217 gradient magnitude function. Left) kgc =0.25,", "caption_bbox": [104, 326, 726, 345]}, {"image_id": 1, "file_name": "102_01.png", "page": 5, "dpi": 300, "bbox": [113, 112, 718, 576], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Renderings of the upper torso from the side view using the gradient boundary enhancement function with kgc =0.0,", "caption_bbox": [104, 601, 726, 615]}, {"image_id": 2, "file_name": "102_02.png", "page": 6, "dpi": 300, "bbox": [113, 111, 718, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Renderings of the thigh and knee regions using the transfer functions implementing the second directional deriva-", "caption_bbox": [104, 312, 725, 325]}, {"image_id": 3, "file_name": "102_03.png", "page": 6, "dpi": 300, "bbox": [113, 326, 727, 663], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Renderings of the head, from the side view. Left) Using equation (1), kgc =0.0, kgs =0.75, kge =1.5 Center) Us-", "caption_bbox": [104, 689, 726, 703]}, {"image_id": 4, "file_name": "102_04.png", "page": 10, "dpi": 300, "bbox": [113, 111, 718, 845], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Renderings of the upper torso region using the L* component. From top to bottom: First Row) Equation (1):", "caption_bbox": [104, 871, 725, 884]}, {"image_id": 5, "file_name": "102_05.png", "page": 11, "dpi": 300, "bbox": [110, 687, 727, 879], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Renderings of the upper torso region using the L* component with kgc =0.0, kgs =0.75, and kge =1.5.From left to", "caption_bbox": [104, 905, 726, 919]}, {"image_id": 6, "file_name": "102_06.png", "page": 11, "dpi": 300, "bbox": [123, 462, 727, 646], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: From left to right: First) Renderings of the thighs and knees where ov is the L* component with kgc =0.0, kgs =0.75,", "caption_bbox": [104, 672, 726, 686]}, {"image_id": 7, "file_name": "102_07.png", "page": 11, "dpi": 300, "bbox": [123, 112, 708, 422], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Renderings of upper torso and head from side view. From left to right: First)Color distance gradient magnitude", "caption_bbox": [104, 448, 725, 461]}], "103": [{"image_id": 0, "file_name": "103_00.png", "page": 3, "dpi": 300, "bbox": [431, 325, 733, 628], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Embedded, adaptive volume tree in global earth environment. ", "caption_bbox": [430, 638, 731, 666]}, {"image_id": 1, "file_name": "103_01.png", "page": 4, "dpi": 300, "bbox": [430, 116, 730, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Screen projection of a hierarchy cell at different orientations. ", "caption_bbox": [430, 314, 731, 342]}, {"image_id": 2, "file_name": "103_02.png", "page": 5, "dpi": 300, "bbox": [114, 117, 717, 153], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Side cut-away view of a single Nexrad radar. The 9 gray sweep lines are surrounded by regions of higher confidence in the accuracy of the readings, At lower elevations, spacing between the sweeps is close enough to assume readings from a continuous medium. ", "caption_bbox": [98, 170, 731, 214]}, {"image_id": 3, "file_name": "103_03.png", "page": 5, "dpi": 300, "bbox": [184, 367, 327, 443], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Splatting in a 2D cell formed by nearest neighbors of central point. ", "caption_bbox": [98, 454, 399, 482]}, {"image_id": 4, "file_name": "103_04.png", "page": 6, "dpi": 300, "bbox": [98, 548, 401, 778], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Two overlapping radar volumes. The new radar has been added 150 miles southeast of the original radar. ", "caption_bbox": [98, 789, 399, 817]}, {"image_id": 5, "file_name": "103_05.png", "page": 7, "dpi": 300, "bbox": [114, 111, 717, 502], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Screen-space selected Level-of-Detail renderings of Doppler reflectivity as the viewpoint moves from 2667 km to an altitude of 229km above North Georgia. These images correspond to lines 1-5 in table 1. ", "caption_bbox": [98, 512, 731, 540]}, {"image_id": 6, "file_name": "103_06.png", "page": 8, "dpi": 300, "bbox": [141, 111, 690, 687], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Levels of detail. The four images from left to right are images drawn with 4, 8, 16 and 32 -pixel screen-space error metrics. The images are from the same dataset as Fig. 5, but cropped. ", "caption_bbox": [98, 697, 731, 725]}, {"image_id": 7, "file_name": "103_07.png", "page": 9, "dpi": 300, "bbox": [174, 503, 657, 867], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Close-up view of velocity of Doppler radar. Mesocyclones (red and orange circles) have been detected in the velocity profile. This view of the velocity volume shows how they are distributed near an outcrop of negative velocities (dark blue top center) in among the positive velocity zone (green/cyan). The empty area to the right has been made transparent to expose the mesocyclone glyphs. Mesocyclones to the left arise from velocity shears (blue-purple) that are at low-elevation scans and hard to see from this view. ", "caption_bbox": [98, 878, 731, 952]}, {"image_id": 8, "file_name": "103_08.png", "page": 9, "dpi": 300, "bbox": [113, 111, 718, 412], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (left) Image of Doppler radar reflectivities over North Georgia. Heavy rainfall is evident along a front from the southwest towards the center (yellow and red splats). Doppler velocities are shown in the right image for the same time step. We have drawn a more limited radius of radar. Because the winds are heading northeast, the northeast half show positive velocities (away from the radar) and the southwest half show negative velocities (toward the radar). ", "caption_bbox": [98, 423, 731, 482]}], "104": [{"image_id": 0, "file_name": "104_00.png", "page": 2, "dpi": 300, "bbox": [442, 114, 722, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Correspondence between 2D basis functions B2i j and knots (indicated by bullets and circles) in uv-parameter space. ", "caption_bbox": [430, 237, 730, 287]}, {"image_id": 1, "file_name": "104_01.png", "page": 3, "dpi": 300, "bbox": [440, 114, 723, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Types of basis functions: basis function associated with corner (left) and edge (right). ", "caption_bbox": [430, 252, 730, 285]}, {"image_id": 2, "file_name": "104_02.png", "page": 3, "dpi": 300, "bbox": [460, 306, 702, 531], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Basis functions associated with the platelet of ver- tex vi and the edge neighbors of edge e j . ", "caption_bbox": [430, 538, 731, 572]}, {"image_id": 3, "file_name": "104_03.png", "page": 5, "dpi": 300, "bbox": [108, 115, 390, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Bisection of simplices in bivariate and trivariate cases. Darker simplex is the one selected for bisection. ", "caption_bbox": [98, 254, 399, 286]}, {"image_id": 4, "file_name": "104_04.png", "page": 5, "dpi": 300, "bbox": [442, 116, 724, 398], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison between quadratic spline approxi- mation (left) and linear spline approximation (right). Un- der each approximation, we show the corresponding do- main decomposition. The quadratic approximation uses 9 knots and 2 simplices. The linear approximation uses 111 knots and 187 simplices. The function being approximated          9 is F x y                :<;=    >             x 2 y2 x y        1 1                               2 2 . ", "caption_bbox": [430, 406, 731, 518]}, {"image_id": 5, "file_name": "104_05.png", "page": 6, "dpi": 300, "bbox": [109, 115, 390, 400], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Comparison between quadratic approximation (left) and linear approximation (right). Original image is shown at the top. The quadratic approximation uses 6076 knots and 2989 simplices. The linear approximation uses 5816 knots and 11482 simplices. ", "caption_bbox": [98, 411, 399, 489]}, {"image_id": 6, "file_name": "104_06.png", "page": 6, "dpi": 300, "bbox": [451, 494, 714, 694], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparison between quadratic approximation (left) and linear approximation (right). The quadratic ap- proximation uses 7487 knots and 5348 simplices. The linear approximation uses 14667 knots and 78530 simplices. ", "caption_bbox": [430, 710, 731, 773]}, {"image_id": 7, "file_name": "104_07.png", "page": 6, "dpi": 300, "bbox": [439, 111, 723, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Hierarchical approximations of digital image data set. Original image is shown at the top. Four approximations are shown, 16, 48, 191, and 790 simplices, respectively. ", "caption_bbox": [430, 416, 731, 464]}, {"image_id": 8, "file_name": "104_08.png", "page": 6, "dpi": 300, "bbox": [110, 526, 391, 808], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Hierarchical approximations of digital image data set. Original image is shown at the top. Six approximations are shown, 8, 20, 38, 90, 225, and 633 simplices, respec- tively. ", "caption_bbox": [98, 819, 399, 882]}, {"image_id": 9, "file_name": "104_09.png", "page": 7, "dpi": 300, "bbox": [108, 114, 389, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Hierarchical approximations of skull data set. Four approximations are shown, 62, 125, 741, and 5348 sim- plices, respectively. ", "caption_bbox": [98, 402, 399, 450]}], "105": [{"image_id": 0, "file_name": "105_00.png", "page": 3, "dpi": 300, "bbox": [431, 815, 733, 932], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Oriented particle forces and torques.", "caption_bbox": [462, 942, 700, 955]}, {"image_id": 1, "file_name": "105_01.png", "page": 3, "dpi": 300, "bbox": [105, 112, 392, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Lennard-Jones potential, \u03c6   r   , and force, f   r   .", "caption_bbox": [105, 313, 392, 337]}, {"image_id": 2, "file_name": "105_02.png", "page": 3, "dpi": 300, "bbox": [98, 801, 400, 906], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Object as a labelled bitmap.", "caption_bbox": [151, 917, 345, 930]}, {"image_id": 3, "file_name": "105_03.png", "page": 4, "dpi": 300, "bbox": [467, 113, 695, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Particles in a bag within a bag.", "caption_bbox": [476, 339, 686, 352]}, {"image_id": 4, "file_name": "105_04.png", "page": 4, "dpi": 300, "bbox": [99, 458, 398, 568], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Gradient map force applied to volume particles.", "caption_bbox": [102, 581, 395, 594]}, {"image_id": 5, "file_name": "105_05.png", "page": 5, "dpi": 300, "bbox": [463, 260, 714, 486], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Creating multiple surfaces.", "caption_bbox": [486, 512, 675, 525]}, {"image_id": 6, "file_name": "105_06.png", "page": 6, "dpi": 300, "bbox": [468, 317, 699, 618], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Deforming a bag with a probe modeled as a single particle. ", "caption_bbox": [430, 629, 731, 657]}, {"image_id": 7, "file_name": "105_07.png", "page": 6, "dpi": 300, "bbox": [134, 365, 364, 725], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Example source data and bag of particles models.", "caption_bbox": [98, 745, 399, 758]}, {"image_id": 8, "file_name": "105_08.png", "page": 7, "dpi": 300, "bbox": [110, 125, 390, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Sequence showing a planar sheet being deformed (the single point probe particle is not shown). ", "caption_bbox": [98, 413, 399, 441]}, {"image_id": 9, "file_name": "105_09.png", "page": 8, "dpi": 300, "bbox": [445, 251, 709, 529], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Eight frames of a gated PET acquisition of a human heart left ventricle during one cardiac cycle, volume rendered using 3D texture. ", "caption_bbox": [430, 553, 731, 597]}, {"image_id": 10, "file_name": "105_10.png", "page": 9, "dpi": 300, "bbox": [431, 114, 732, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Shape of ventricle pressure vs. time through one cardiac cycle, for a bag-of-particles model and a typical left ventricle (scaled to give peak systolic pressure of 120 mm Hg). ", "caption_bbox": [430, 349, 731, 408]}, {"image_id": 11, "file_name": "105_11.png", "page": 9, "dpi": 300, "bbox": [104, 121, 383, 435], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Left ventricle bag-of-particles model through one cardiac cycle. ", "caption_bbox": [98, 453, 399, 481]}], "106": [{"image_id": 0, "file_name": "106_00.png", "page": 1, "dpi": 300, "bbox": [433, 636, 733, 831], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Object (a) and distance transform (DT) (b)", "caption_bbox": [447, 843, 715, 856]}, {"image_id": 1, "file_name": "106_01.png", "page": 2, "dpi": 300, "bbox": [103, 112, 401, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Evolved boundary under constant speed (a) and skeleton detector (b) ", "caption_bbox": [98, 320, 399, 348]}, {"image_id": 2, "file_name": "106_02.png", "page": 2, "dpi": 300, "bbox": [430, 112, 732, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: DT of skeleton (a) and inflated skeleton (b) for object in Fig. 1 ", "caption_bbox": [430, 321, 731, 349]}, {"image_id": 3, "file_name": "106_03.png", "page": 2, "dpi": 300, "bbox": [104, 692, 401, 878], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Skeleton (a) and detail of distance close to skele- ton (b) for object in Fig. 1 ", "caption_bbox": [98, 889, 399, 917]}, {"image_id": 4, "file_name": "106_04.png", "page": 3, "dpi": 300, "bbox": [105, 364, 390, 523], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Definition of zero and first order moments of graph of T   x   ", "caption_bbox": [98, 535, 399, 566]}, {"image_id": 5, "file_name": "106_05.png", "page": 4, "dpi": 300, "bbox": [111, 111, 717, 283], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Singularity detection in 1D (a), singularity detector computation in 2D and 3D (b,c)", "caption_bbox": [178, 295, 651, 308]}, {"image_id": 6, "file_name": "106_06.png", "page": 5, "dpi": 300, "bbox": [438, 112, 724, 373], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Difference between exact and computed distance to skeleton fields ", "caption_bbox": [430, 383, 730, 411]}, {"image_id": 7, "file_name": "106_07.png", "page": 6, "dpi": 300, "bbox": [105, 434, 393, 778], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Singularity detector (a), skeleton neighborhood (b), inflated skeleton and original boundary (c), reconstruc- tion detail (d) ", "caption_bbox": [98, 790, 398, 834]}, {"image_id": 8, "file_name": "106_08.png", "page": 6, "dpi": 300, "bbox": [114, 217, 716, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Morphing between object (leftmost image) and skeleton (rightmost image)", "caption_bbox": [200, 384, 629, 397]}, {"image_id": 9, "file_name": "106_09.png", "page": 6, "dpi": 300, "bbox": [113, 111, 718, 167], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Skeletonization algorithm pipeline", "caption_bbox": [302, 178, 527, 191]}, {"image_id": 10, "file_name": "106_10.png", "page": 8, "dpi": 300, "bbox": [98, 112, 732, 884], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: 2D and 3D skeletonization applications", "caption_bbox": [286, 895, 543, 908]}], "107": [{"image_id": 0, "file_name": "107_00.png", "page": 2, "dpi": 300, "bbox": [112, 134, 387, 717], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Operators transforming a citation network into weighted undirected graphs representing the essence of cer- tain analytic perspectives. ", "caption_bbox": [98, 737, 399, 781]}, {"image_id": 1, "file_name": "107_01.png", "page": 4, "dpi": 300, "bbox": [135, 134, 364, 879], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Co-citation in citation network of Sect. 5; note that the Laplacian layouts are not primarily determined by citations, but the similarity of citation patterns. ", "caption_bbox": [98, 899, 399, 943]}, {"image_id": 2, "file_name": "107_02.png", "page": 7, "dpi": 300, "bbox": [430, 525, 733, 837], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Restricted triangulation refining the layout in Fig. 2(c) ", "caption_bbox": [430, 848, 731, 876]}, {"image_id": 3, "file_name": "107_03.png", "page": 7, "dpi": 300, "bbox": [98, 527, 401, 839], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Graph-Drawing Contest Reports form a village hidden behind the mainstream ridge. ", "caption_bbox": [98, 850, 399, 878]}, {"image_id": 4, "file_name": "107_04.png", "page": 7, "dpi": 300, "bbox": [430, 111, 733, 424], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Similar citation patterns lead to close positions (citation edges shown, semi-transparent surface). Height and width of house depict the number of citations received and made. ", "caption_bbox": [430, 434, 731, 493]}, {"image_id": 5, "file_name": "107_05.png", "page": 7, "dpi": 300, "bbox": [98, 111, 401, 424], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Simultaneous visualization of prominence (au- thority) and clustering (co-citation similarity) for Graph Drawing Proceedings citation network. Peaks correspond to landmark papers. ", "caption_bbox": [98, 434, 399, 493]}], "108": [{"image_id": 0, "file_name": "108_00.png", "page": 3, "dpi": 300, "bbox": [440, 439, 708, 709], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Attribute scales and encoding schemes used in the experiment are shown (a). Relative increases within attribute values are uniform. Participants are shown the applicable scale before the start of each round. Each of the three attribute images (b) encodes the same dataset values {1, 5, 2}. In a given round, one of these images is presented as a secondary task. Only three values are shown here, but the experiment\u2019s images encode ten. ", "caption_bbox": [440, 717, 706, 819]}, {"image_id": 1, "file_name": "108_01.png", "page": 3, "dpi": 300, "bbox": [147, 191, 692, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Screen shots of experimental platform. A round begins with scale display; scale disappears and question is displayed; question disappears and game begins\u2014alone for eight seconds (not shown); eight seconds of game playing (left side of screen) and image display (right side of screen); eight final seconds of game playing only (not shown); answer input. ", "caption_bbox": [152, 360, 685, 413]}, {"image_id": 2, "file_name": "108_02.png", "page": 4, "dpi": 300, "bbox": [440, 514, 705, 669], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Resulting answer correctness percentages for images displayed as a focal task (displayed without any other objects on the screen) are compared to results from secondary task images (displayed while user continues playing a game). In this case, participants maintained 75 percent of game performance (acceptable degradation was 25 percent) during image display period for answer correctness to be evaluated. ", "caption_bbox": [439, 679, 701, 784]}, {"image_id": 3, "file_name": "108_03.png", "page": 5, "dpi": 300, "bbox": [159, 677, 670, 863], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Solid trendlines show that levels of significance for attribute ordering vary with degree of acceptable primary task degradation. ", "caption_bbox": [142, 872, 698, 900]}, {"image_id": 4, "file_name": "108_04.png", "page": 5, "dpi": 300, "bbox": [159, 417, 668, 608], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Answer correctness by attribute type for levels of acceptable degradation. Note that levels of acceptable degradation cumulate from the left side of the figure (i.e., subjects that meet five percent acceptable degradation include those at zero through four percent, and five. ", "caption_bbox": [143, 618, 699, 659]}, {"image_id": 5, "file_name": "108_05.png", "page": 6, "dpi": 300, "bbox": [142, 187, 716, 352], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Significant Attribute Ordering, by Cognitive Tasks (p < .05)", "caption_bbox": [269, 917, 579, 933]}], "109": [{"image_id": 0, "file_name": "109_00.png", "page": 3, "dpi": 300, "bbox": [412, 101, 702, 788], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Progressive selection of subspaces with different dimensionalities using the Interaction Graph (N=5). ", "caption_bbox": [415, 787, 704, 813]}, {"image_id": 1, "file_name": "109_01.png", "page": 4, "dpi": 300, "bbox": [412, 108, 717, 707], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Current implementation of workspaces through a tree control. Three workspaces have been created. ", "caption_bbox": [426, 708, 711, 734]}, {"image_id": 2, "file_name": "109_02.png", "page": 4, "dpi": 300, "bbox": [125, 602, 355, 755], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The concept of region of interest (the 3D dotted box) applied to a 3-dimensional space. ", "caption_bbox": [106, 763, 393, 789]}, {"image_id": 3, "file_name": "109_03.png", "page": 5, "dpi": 300, "bbox": [113, 438, 383, 598], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Choosing a new position through the 3D cursor.", "caption_bbox": [106, 601, 384, 614]}, {"image_id": 4, "file_name": "109_04.png", "page": 5, "dpi": 300, "bbox": [473, 140, 642, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Control triangle showing the rotation angles for a cell x1x2x3. ", "caption_bbox": [425, 275, 711, 302]}, {"image_id": 5, "file_name": "109_05.png", "page": 5, "dpi": 300, "bbox": [424, 304, 717, 713], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Correspondence between Brushing Graph and cell for N=3. ", "caption_bbox": [427, 715, 712, 741]}, {"image_id": 6, "file_name": "109_06.png", "page": 6, "dpi": 300, "bbox": [101, 134, 392, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": " Figure 7: Splitting the cell x1x2x3to accommodate the new added dimension x4 in a schematic visualization of a 5D function. The modified region is on the left hand side of the  cell. ", "caption_bbox": [99, 346, 387, 399]}, {"image_id": 7, "file_name": "109_07.png", "page": 8, "dpi": 300, "bbox": [412, 112, 701, 586], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a): HyperCell\u2019s main window showing the visu- alization of the 4D hypersphericalfield with a ball of radius 0.5 (top image). Three different cells have been created in the active workspace using a volume rendering technique. The cell located in the left comer has the ball depicted through an isosuface. Pictures (b) to (i) correspond to a cell built from x1, x2, and x3 dimensions. (b):Visualization of a cell without a ball. (c) to (i): The same cell with a ball inside (the red region). In each following image the focal point has been moved along the x4 axis from position (0,0,0,0) to (0,0,0,0.6), with steps of 0.1. In the last image (i) the ball is no longer visible. ", "caption_bbox": [415, 588, 701, 750]}], "110": [{"image_id": 0, "file_name": "110_00.png", "page": 3, "dpi": 300, "bbox": [503, 112, 657, 225], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Computation of the viewpoint entropy by project- ing the objects onto a bounding sphere of the viewing point. ", "caption_bbox": [430, 224, 731, 252]}, {"image_id": 1, "file_name": "110_01.png", "page": 3, "dpi": 300, "bbox": [503, 261, 656, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Only the objects inside the frustum volume are considered for the entropy computation. ", "caption_bbox": [430, 382, 731, 410]}, {"image_id": 2, "file_name": "110_02.png", "page": 4, "dpi": 300, "bbox": [126, 125, 373, 440], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Figures (a) and (c) show the points of maxi- mum orthogonal entropy of a molecular representation of Ru(III) trichloro-2,2\u2019:6\u2019,2\"-terpyridine and an arrangement of the same molecule. Figures (b) and (d) show the respec- tive points of minimum orthogonal viewpoint entropy. ", "caption_bbox": [98, 444, 399, 518]}, {"image_id": 3, "file_name": "110_03.png", "page": 4, "dpi": 300, "bbox": [442, 117, 733, 421], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Algorithm that computes the set of view with high entropy of a molecule and which covers all the elements. ", "caption_bbox": [430, 434, 731, 462]}, {"image_id": 4, "file_name": "110_04.png", "page": 5, "dpi": 300, "bbox": [126, 577, 373, 896], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Figures (a) and (b) show a molecular represen- tation of a tetrabromic salt of a hexaazamacrocyclic ligand seen from the points of maximum and minimum entropy re- spectively. Figures (c) and (d) show the views of maximum and minimum entropy for a set of these molecules.     c The Eurographics Association 2002. ", "caption_bbox": [98, 900, 399, 992]}, {"image_id": 5, "file_name": "110_05.png", "page": 5, "dpi": 300, "bbox": [458, 125, 705, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Figures (a) and (b) show the minimum entropy views of the molecular representations of two Carbon forms, graphite and diamond respectively. From these views molec- ular scientists can infer the resistance to physical pressure. While diamond is very strong due to the bonds in three direc- tions, graphite\u2019s layered structure makes the molecule easily exfoliable. ", "caption_bbox": [430, 284, 731, 389]}], "111": [{"image_id": 0, "file_name": "111_00.png", "page": 4, "dpi": 300, "bbox": [441, 109, 721, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) shows a map of the dataset extent. (b) shows the expert analysis using Edigraph. (c) and (d) show slices of temperature and humidity, respectively, passed through a spectral color map. ", "caption_bbox": [430, 409, 731, 468]}, {"image_id": 1, "file_name": "111_01.png", "page": 4, "dpi": 300, "bbox": [441, 604, 719, 774], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: This is an example of volume rendering using properties from each of the data channels. In (a), color varies only with temperature and opacity varies only with humidity. (b) shows the reverse of this, color with humidity, opacity with temperature. ", "caption_bbox": [430, 775, 731, 849]}, {"image_id": 2, "file_name": "111_02.png", "page": 5, "dpi": 300, "bbox": [104, 451, 392, 765], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: This figure demonstrates the full expressivity of a multi-dimensional transfer function. The transfer function was created using dual-domain interaction. The sliders on the top of the transfer function widget allow us to restrict the opacity applied to samples with low gradient magnitudes. Blue regions indicate cold airmasses, red regions indicate warm airmasses. ", "caption_bbox": [98, 775, 399, 880]}, {"image_id": 3, "file_name": "111_03.png", "page": 5, "dpi": 300, "bbox": [438, 112, 724, 429], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: This image shows a transfer function similar to the one in Figure 3 applied to a different timestep. ", "caption_bbox": [430, 439, 731, 467]}, {"image_id": 4, "file_name": "111_04.png", "page": 7, "dpi": 300, "bbox": [437, 111, 724, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: This figure demonstrates the full expressivity of a multi-dimensional transfer function. The transfer function was created using dual-domain interaction. The sliders on the top of the transfer function widget allow us to restrict the opacity applied to samples with low gradient magnitudes. Blue regions indicate cold airmasses, red regions indicate warm airmasses. ", "caption_bbox": [430, 436, 732, 541]}, {"image_id": 5, "file_name": "111_05.png", "page": 7, "dpi": 300, "bbox": [438, 566, 724, 882], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: This image shows a transfer function similar to the one in Figure 3 applied to a different timestep. ", "caption_bbox": [430, 893, 731, 921]}, {"image_id": 6, "file_name": "111_06.png", "page": 7, "dpi": 300, "bbox": [109, 109, 388, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) shows a map of the dataset extent. (b) shows the expert analysis using Edigraph. (c) and (d) show slices of temperature and humidity, respectively, passed through a spectral color map. ", "caption_bbox": [98, 409, 400, 468]}, {"image_id": 7, "file_name": "111_07.png", "page": 7, "dpi": 300, "bbox": [109, 494, 387, 663], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: This is an example of volume rendering using properties from each of the data channels. In (a), color varies only with temperature and opacity varies only with humidity. (b) shows the reverse of this, color with humidity, opacity with temperature. ", "caption_bbox": [98, 665, 400, 739]}], "112": [{"image_id": 0, "file_name": "112_00.png", "page": 2, "dpi": 300, "bbox": [482, 112, 681, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: System Processes", "caption_bbox": [500, 313, 660, 326]}, {"image_id": 1, "file_name": "112_01.png", "page": 2, "dpi": 300, "bbox": [140, 112, 359, 276], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Orbital View from VGIS", "caption_bbox": [147, 287, 349, 300]}, {"image_id": 2, "file_name": "112_02.png", "page": 2, "dpi": 300, "bbox": [140, 307, 359, 472], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Surface View from VGIS", "caption_bbox": [146, 482, 350, 495]}, {"image_id": 3, "file_name": "112_03.png", "page": 3, "dpi": 300, "bbox": [167, 112, 332, 236], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: A Sample of Recognized Speech Commands", "caption_bbox": [431, 404, 729, 417]}, {"image_id": 4, "file_name": "112_04.png", "page": 5, "dpi": 300, "bbox": [98, 112, 400, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Workbench and Mobile Interfaces", "caption_bbox": [122, 266, 373, 279]}], "113": [{"image_id": 0, "file_name": "113_00.png", "page": 2, "dpi": 300, "bbox": [424, 79, 786, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An Architectural Overview", "caption_bbox": [440, 319, 639, 332]}, {"image_id": 1, "file_name": "113_01.png", "page": 3, "dpi": 300, "bbox": [81, 646, 414, 759], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Cluster Highly Correlated Web Clients", "caption_bbox": [73, 766, 319, 779]}, {"image_id": 2, "file_name": "113_02.png", "page": 3, "dpi": 300, "bbox": [81, 370, 416, 486], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Encapsulate A Physics-Based Mass-Spring Engine", "caption_bbox": [73, 492, 378, 505]}, {"image_id": 3, "file_name": "113_03.png", "page": 5, "dpi": 300, "bbox": [73, 379, 427, 932], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: An Example of Web Transaction Observation", "caption_bbox": [83, 944, 418, 958]}], "114": [{"image_id": 0, "file_name": "114_00.png", "page": 2, "dpi": 300, "bbox": [468, 115, 695, 343], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Chess board application, with the chessmen threatening the knight on e3 in focus (from Kosara et al.6 ) ", "caption_bbox": [430, 355, 731, 384]}, {"image_id": 1, "file_name": "114_01.png", "page": 3, "dpi": 300, "bbox": [458, 114, 705, 842], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Test sequence and sample images. a) The sequence of screens for testing preattentive location of objects (Sec- tion 3) and interplay (Section 4); b) Sample image for target detection and location with 32 distractors of the highest blur level, and a target; c) Example image for interplay: Find the rotated, sharp object. ", "caption_bbox": [430, 856, 732, 945]}, {"image_id": 2, "file_name": "114_02.png", "page": 4, "dpi": 300, "bbox": [196, 116, 628, 483], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Results for preattentiveness: a) Ratio of correctly located targets depending on blur levels used (encoding of blur levels see below); b) Ratio of correct answers by number of objects; c) Correct answers by blur level and number of objects; d) Ratio of correct estimations by blur level and number of targets. Encoding of blur levels: for each of the three blur levels, a 1 indicates that it is present, and a 0 that it is not. So for \u201cb011\u201d, the lowest blur level was not present, the higher ones were. ", "caption_bbox": [98, 502, 731, 561]}, {"image_id": 3, "file_name": "114_03.png", "page": 5, "dpi": 300, "bbox": [468, 117, 693, 640], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Results for blur perception. a) Correct answers for identical (\u201cno\u201d) and different (\u201cyes\u201d) objects, by blur level; b) Distance needed to detect difference, by blur level; c) Numerical answer to perception of absolute blur value, by displayed blur value (error bars for 95% of values). ", "caption_bbox": [429, 659, 730, 733]}, {"image_id": 4, "file_name": "114_04.png", "page": 5, "dpi": 300, "bbox": [148, 114, 346, 463], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Results for interplay of features. a) time needed for search when target present (\u201csimple\u201d: only look for one fea- ture, with no other feature present; \u201cdis\u201d: disjunctive search for one feature with two distractor features; \u201ccon\u201d: conjunc- tive search for combination of features; b) search times for conjunctive search by search task and existence of target. ", "caption_bbox": [98, 480, 400, 569]}], "115": [{"image_id": 0, "file_name": "115_00.png", "page": 3, "dpi": 300, "bbox": [104, 112, 700, 413], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Sample information visualizations used in the experiment. Figure a shows a low density visualization while b shows a high density visualization, both representing the same distribution of data. ", "caption_bbox": [98, 432, 731, 460]}, {"image_id": 1, "file_name": "115_01.png", "page": 3, "dpi": 300, "bbox": [430, 497, 718, 714], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Game and visualization seen by participants in the experiment. The visualization was only present for either one or eight seconds. Before each round, participants were given a question that they used the visualization to answer. ", "caption_bbox": [430, 725, 731, 784]}, {"image_id": 2, "file_name": "115_02.png", "page": 4, "dpi": 300, "bbox": [445, 127, 718, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Average performance (ratio of blocks caught to total blocks) for the 1 second conditions, based on high vs low density and single vs cluster question type. ", "caption_bbox": [430, 300, 731, 344]}, {"image_id": 3, "file_name": "115_03.png", "page": 5, "dpi": 300, "bbox": [98, 112, 385, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Correctness based on density for the single-item question. There are significant differences in both the one and eight second conditions. ", "caption_bbox": [98, 303, 399, 347]}], "116": [{"image_id": 0, "file_name": "116_00.png", "page": 3, "dpi": 300, "bbox": [136, 616, 366, 757], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Sperner labeling and simplicial subdivision of the original fully labeled triangle ABC result in three fully la- beled subtriangles, colored dark blue ", "caption_bbox": [98, 776, 399, 820]}, {"image_id": 1, "file_name": "116_01.png", "page": 3, "dpi": 300, "bbox": [464, 384, 700, 548], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A 2D vector field that satisfies Sperner\u2019s lemma. Note the two swirling centers on each side of the triangular domain and the switching saddle region near the top ", "caption_bbox": [430, 564, 731, 608]}, {"image_id": 2, "file_name": "116_02.png", "page": 4, "dpi": 300, "bbox": [434, 656, 728, 800], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The duality between subdivision with Sperner la- beling and interpolation with direction labeling ", "caption_bbox": [430, 818, 731, 846]}, {"image_id": 3, "file_name": "116_03.png", "page": 4, "dpi": 300, "bbox": [135, 117, 362, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The three equally spaced direction ranges corre- spond to direction labeling of the triangular cell ", "caption_bbox": [98, 264, 399, 292]}, {"image_id": 4, "file_name": "116_04.png", "page": 4, "dpi": 300, "bbox": [101, 320, 398, 562], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Sperner labeling a triangulation, (b) direction labeling a vector field defined on an unstructured grid, and (c) superimposing the two to show their labeling duality ", "caption_bbox": [98, 577, 399, 621]}, {"image_id": 5, "file_name": "116_05.png", "page": 5, "dpi": 300, "bbox": [440, 652, 726, 879], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: 3D vortex core region detection. Grid point (i, j, k) is detected because its immediate neighbors satisfy the direction-spanning property on the swirl plane ", "caption_bbox": [430, 903, 731, 947]}, {"image_id": 6, "file_name": "116_06.png", "page": 5, "dpi": 300, "bbox": [164, 118, 334, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: 2D vortex core region detection. Grid point (i, j) is detected because its immediate neighbors satisfy the direction-spanning property ", "caption_bbox": [98, 299, 399, 343]}, {"image_id": 7, "file_name": "116_07.png", "page": 6, "dpi": 300, "bbox": [468, 382, 695, 616], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The four possible types of direction-spanning with three vectors and four direction ranges: (a) ABC, (b) ABD, (c) BCD, and (d) ACD ", "caption_bbox": [430, 636, 731, 680]}, {"image_id": 8, "file_name": "116_08.png", "page": 6, "dpi": 300, "bbox": [434, 117, 727, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The left grid was labeled with three direction ranges, and the right grid was labeled with four direction ranges. The four grid points that satisfied the direction- spanning property in the right grid more faithfully captured the swirling region than the single grid point that satisfied the direction-spanning property in the left grid ", "caption_bbox": [430, 261, 731, 350]}, {"image_id": 9, "file_name": "116_09.png", "page": 7, "dpi": 300, "bbox": [431, 308, 732, 460], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Wake simulation using Rankine vortices", "caption_bbox": [451, 470, 709, 483]}, {"image_id": 10, "file_name": "116_10.png", "page": 7, "dpi": 300, "bbox": [431, 111, 732, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: 2D Rankine vortices", "caption_bbox": [500, 273, 661, 286]}, {"image_id": 11, "file_name": "116_11.png", "page": 8, "dpi": 300, "bbox": [99, 111, 400, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: LIC dataset from NASA Ames 24", "caption_bbox": [139, 273, 357, 287]}, {"image_id": 12, "file_name": "116_12.png", "page": 10, "dpi": 300, "bbox": [98, 390, 733, 603], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Blunt fin vortices", "caption_bbox": [342, 629, 487, 642]}, {"image_id": 13, "file_name": "116_13.png", "page": 10, "dpi": 300, "bbox": [99, 669, 733, 872], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Delta wing vortices", "caption_bbox": [336, 908, 493, 921]}, {"image_id": 14, "file_name": "116_14.png", "page": 10, "dpi": 300, "bbox": [98, 111, 733, 325], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Bent-helical vortex", "caption_bbox": [337, 350, 492, 363]}], "117": [{"image_id": 0, "file_name": "117_00.png", "page": 2, "dpi": 300, "bbox": [465, 491, 701, 714], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A streamline approaching a limit cycle has to reenter cells. ", "caption_bbox": [430, 725, 731, 754]}, {"image_id": 1, "file_name": "117_01.png", "page": 2, "dpi": 300, "bbox": [504, 112, 662, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A limit cycle may attract streamlines in its neigh- borhood. ", "caption_bbox": [430, 228, 731, 256]}, {"image_id": 2, "file_name": "117_02.png", "page": 3, "dpi": 300, "bbox": [133, 112, 369, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: If a real exit can be reached, the streamline will leave the cell cycle. ", "caption_bbox": [98, 310, 399, 338]}, {"image_id": 3, "file_name": "117_03.png", "page": 3, "dpi": 300, "bbox": [431, 278, 735, 528], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Exits of a cell cycle.", "caption_bbox": [504, 538, 657, 551]}, {"image_id": 4, "file_name": "117_04.png", "page": 3, "dpi": 300, "bbox": [133, 644, 369, 830], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: If no real exit can be reached, the streamline will approach a limit cycle. ", "caption_bbox": [98, 841, 400, 869]}, {"image_id": 5, "file_name": "117_05.png", "page": 3, "dpi": 300, "bbox": [516, 708, 706, 907], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Backward integrated surface.", "caption_bbox": [481, 942, 681, 955]}, {"image_id": 6, "file_name": "117_06.png", "page": 4, "dpi": 300, "bbox": [134, 680, 367, 901], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Backward integration in one cell.", "caption_bbox": [139, 916, 359, 929]}, {"image_id": 7, "file_name": "117_07.png", "page": 4, "dpi": 300, "bbox": [194, 510, 308, 609], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Intermediate backward integrated streamline.", "caption_bbox": [108, 624, 389, 637]}, {"image_id": 8, "file_name": "117_08.png", "page": 5, "dpi": 300, "bbox": [225, 437, 610, 896], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Closed streamline in a 3D vector field.", "caption_bbox": [289, 907, 542, 920]}, {"image_id": 9, "file_name": "117_09.png", "page": 5, "dpi": 300, "bbox": [194, 111, 640, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Closed streamline including cell cycle and backward integrations.", "caption_bbox": [223, 402, 607, 415]}, {"image_id": 10, "file_name": "117_10.png", "page": 6, "dpi": 300, "bbox": [91, 407, 411, 919], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Close up of the spiraling effect around the closed streamline. ", "caption_bbox": [98, 929, 400, 958]}, {"image_id": 11, "file_name": "117_11.png", "page": 7, "dpi": 300, "bbox": [225, 437, 610, 896], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Closed streamline in a 3D vector field.", "caption_bbox": [289, 907, 542, 920]}, {"image_id": 12, "file_name": "117_12.png", "page": 7, "dpi": 300, "bbox": [194, 111, 640, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Closed streamline including cell cycle and backward integrations.", "caption_bbox": [223, 402, 607, 415]}], "118": [{"image_id": 0, "file_name": "118_00.png", "page": 5, "dpi": 300, "bbox": [96, 322, 400, 681], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Example application of tracking             in scale and time. ", "caption_bbox": [138, 691, 356, 722]}, {"image_id": 1, "file_name": "118_01.png", "page": 5, "dpi": 300, "bbox": [426, 430, 732, 679], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Lifting of cells and features.", "caption_bbox": [479, 689, 676, 705]}, {"image_id": 2, "file_name": "118_02.png", "page": 6, "dpi": 300, "bbox": [98, 293, 398, 514], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Three of the eight boundary cubes            of a hypercube cell. ", "caption_bbox": [133, 524, 361, 555]}, {"image_id": 3, "file_name": "118_03.png", "page": 7, "dpi": 300, "bbox": [98, 687, 399, 829], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Number of features at different scales", "caption_bbox": [125, 839, 370, 855]}, {"image_id": 4, "file_name": "118_04.png", "page": 9, "dpi": 300, "bbox": [96, 381, 727, 595], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "  Figure 8: In the modernized draft tube, vortices are less articulate and harder to extract. Vortex core extraction based on normalized helicity has been applied to unsmoothed velocity field (left) and to Gaussian-smoothed data with \u03c3=0.008 (middle)        and \u03c3=0.032 (right). Colors represent connected components of the surface swept by the core lines, see Fig. 9. ", "caption_bbox": [96, 594, 725, 639]}, {"image_id": 5, "file_name": "118_05.png", "page": 9, "dpi": 300, "bbox": [96, 102, 730, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Original draft tube dataset: geometry and instantaneous streamlines (left). Pressure isosurfaces and pressure valley    line indicate the so-called vortex rope. Pressure data have been Gaussian-smoothed with \u03c3=0.008 (middle). Vortex core                 extraction based on normalized helicity can be successfully applied to unsmoothed data (right). ", "caption_bbox": [96, 317, 725, 362]}, {"image_id": 6, "file_name": "118_06.png", "page": 9, "dpi": 300, "bbox": [96, 656, 730, 871], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Vortex cores of Fig. 8 tracked through scales \u03c3\u2208[0, 0.032] (left). Diagonal pump dataset with vortices extracted in runner and diffusor along with a few manually seeded streamlines (middle). Vortex cores tracked temporally for a 90\u00b0 rotation                                               of the four-bladed runner (right). ", "caption_bbox": [96, 870, 725, 917]}], "119": [{"image_id": 0, "file_name": "119_00.png", "page": 2, "dpi": 300, "bbox": [113, 112, 718, 412], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Reverse engineering pipeline (a). Toolkit architecture overview (b)", "caption_bbox": [222, 424, 607, 437]}, {"image_id": 1, "file_name": "119_01.png", "page": 4, "dpi": 300, "bbox": [186, 111, 644, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Software visualization overview (a) and detail (b)", "caption_bbox": [264, 342, 564, 355]}, {"image_id": 2, "file_name": "119_02.png", "page": 4, "dpi": 300, "bbox": [184, 377, 646, 586], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Custom layouts: stacked layout (a) and nested layout (b)", "caption_bbox": [247, 598, 582, 611]}, {"image_id": 3, "file_name": "119_03.png", "page": 5, "dpi": 300, "bbox": [152, 112, 683, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Software components of the mapping operation", "caption_bbox": [270, 244, 559, 257]}, {"image_id": 4, "file_name": "119_04.png", "page": 5, "dpi": 300, "bbox": [199, 278, 632, 519], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualization of program analysis tool (a) and clustered core detail using glyphs(b)", "caption_bbox": [181, 530, 648, 543]}, {"image_id": 5, "file_name": "119_05.png", "page": 6, "dpi": 300, "bbox": [192, 111, 640, 320], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Tcl/Tk interface of the integrated reverse engineering application", "caption_bbox": [225, 330, 604, 343]}, {"image_id": 6, "file_name": "119_06.png", "page": 7, "dpi": 300, "bbox": [113, 429, 386, 688], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Software graph splatting. Packages\u2019 requirements", "caption_bbox": [98, 698, 398, 711]}, {"image_id": 7, "file_name": "119_07.png", "page": 7, "dpi": 300, "bbox": [450, 362, 712, 576], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Software splatting visualized with elevation plots", "caption_bbox": [430, 587, 730, 600]}, {"image_id": 8, "file_name": "119_08.png", "page": 7, "dpi": 300, "bbox": [113, 111, 386, 370], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Software graph splatting. Packages using String class ", "caption_bbox": [98, 381, 399, 409]}, {"image_id": 9, "file_name": "119_09.png", "page": 7, "dpi": 300, "bbox": [450, 112, 712, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Software splatting visualized with elevation plots", "caption_bbox": [432, 328, 729, 341]}, {"image_id": 10, "file_name": "119_10.png", "page": 10, "dpi": 300, "bbox": [98, 112, 731, 905], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Software visualizations in reverse engineering applications", "caption_bbox": [237, 917, 591, 930]}], "120": [{"image_id": 0, "file_name": "120_00.png", "page": 2, "dpi": 300, "bbox": [103, 111, 402, 461], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Object (a), distance transform DT (b), boundary evolution (level sets) (c), skeleton (d), and DT elevation plot (e) ", "caption_bbox": [98, 472, 399, 516]}, {"image_id": 1, "file_name": "120_01.png", "page": 3, "dpi": 300, "bbox": [108, 113, 363, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: FMM initialization code", "caption_bbox": [161, 302, 336, 315]}, {"image_id": 2, "file_name": "120_02.png", "page": 3, "dpi": 300, "bbox": [434, 433, 748, 751], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Objects (a,c) and the order in which U is assigned to their boundaries (b,d) ", "caption_bbox": [430, 764, 730, 792]}, {"image_id": 3, "file_name": "120_03.png", "page": 4, "dpi": 300, "bbox": [107, 112, 518, 549], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: FMM iteration code", "caption_bbox": [337, 570, 491, 583]}, {"image_id": 4, "file_name": "120_04.png", "page": 4, "dpi": 300, "bbox": [439, 620, 738, 851], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Augmented FMM code (a) Boundary neighbor distances (b) ", "caption_bbox": [430, 863, 730, 891]}, {"image_id": 5, "file_name": "120_05.png", "page": 5, "dpi": 300, "bbox": [98, 430, 415, 680], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Rectangle and its skeleton (a). Detail of the aug- mented FMM result around the rectangle\u2019s lower left corner (b). Complete U field (c) ", "caption_bbox": [98, 695, 398, 739]}, {"image_id": 6, "file_name": "120_06.png", "page": 5, "dpi": 300, "bbox": [140, 112, 690, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Overview of the skeletionzation algorithm", "caption_bbox": [283, 380, 545, 393]}, {"image_id": 7, "file_name": "120_07.png", "page": 6, "dpi": 300, "bbox": [130, 112, 700, 232], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Feature-based skeleton pruning for different thresholds t", "caption_bbox": [247, 245, 581, 258]}, {"image_id": 8, "file_name": "120_08.png", "page": 6, "dpi": 300, "bbox": [98, 295, 415, 665], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Treatment of special boundary points: original ob- ject (a), initial U (b), computed U (c), and skeleton (d) ", "caption_bbox": [98, 677, 399, 705]}, {"image_id": 9, "file_name": "120_09.png", "page": 7, "dpi": 300, "bbox": [432, 404, 745, 791], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Examples of 3D centerlines", "caption_bbox": [482, 803, 679, 816]}, {"image_id": 10, "file_name": "120_10.png", "page": 7, "dpi": 300, "bbox": [192, 112, 639, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Centerline computation pipeline", "caption_bbox": [304, 349, 525, 362]}, {"image_id": 11, "file_name": "120_11.png", "page": 10, "dpi": 300, "bbox": [100, 113, 732, 889], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Skeletonization examples", "caption_bbox": [322, 901, 507, 914]}], "121": [{"image_id": 0, "file_name": "121_00.png", "page": 3, "dpi": 300, "bbox": [424, 52, 690, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Array-based tree organization", "caption_bbox": [443, 239, 647, 257]}, {"image_id": 1, "file_name": "121_01.png", "page": 3, "dpi": 300, "bbox": [99, 52, 398, 219], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Influence of location in branches for tree-based error evaluation between successive time steps: accurate for same parent (e01 \u2248 e1 ), not accurate for different branches (e02   e2 ) ", "caption_bbox": [63, 231, 364, 296]}, {"image_id": 2, "file_name": "121_02.png", "page": 4, "dpi": 300, "bbox": [99, 52, 398, 196], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Memory requirement for fully implicit (all nodes) and partially implicit structure (gray nodes) of a binary tree ", "caption_bbox": [63, 205, 364, 238]}, {"image_id": 3, "file_name": "121_03.png", "page": 5, "dpi": 300, "bbox": [99, 52, 396, 196], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Edge-based error calculation by following tree edges only ", "caption_bbox": [63, 205, 364, 238]}, {"image_id": 4, "file_name": "121_04.png", "page": 5, "dpi": 300, "bbox": [364, 279, 396, 438], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Inter-level error calculation by following tree edges, inter- and intra-level edges ", "caption_bbox": [395, 387, 696, 420]}, {"image_id": 5, "file_name": "121_05.png", "page": 6, "dpi": 300, "bbox": [363, 52, 742, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Number of entries for 274 time steps of a Richtmyer-Meshkov simulation. Shown are the numbers for all three modes and the percentage values of error terms when compared to the exact error table. ", "caption_bbox": [395, 498, 695, 561]}, {"image_id": 6, "file_name": "121_06.png", "page": 7, "dpi": 300, "bbox": [695, 684, 732, 744], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Surfaces showing exact two-dimensional error ta- ble (green), tree (wire frame, using original datasets for in- ternal nodes) as a height field e(ti ,t j ), and difference be- tween both tables (yellow): adaptive tree (top), binary tree (bottom). ", "caption_bbox": [395, 680, 696, 758]}, {"image_id": 7, "file_name": "121_07.png", "page": 7, "dpi": 300, "bbox": [100, 52, 731, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Surfaces showing exact two-dimensional error table (green), adaptive tree (wire frame, using original datasets for internal nodes) as a height field e(ti ,t j ), and difference between both tables (yellow): inter-level evaluation (left), intra-level evaluation (middle), edge-based evaluation (right). ", "caption_bbox": [63, 251, 695, 299]}, {"image_id": 8, "file_name": "121_08.png", "page": 8, "dpi": 300, "bbox": [385, 902, 727, 979], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Error terms shown for a 100-step unicolor dataset with shades from black to white, e(ti ,ti+1 ) = const (upper: trees using averages, lower: trees using repre- sentants); correct error e(t0 ,ti ) = i/100 only provided by squared table. ", "caption_bbox": [392, 825, 691, 903]}, {"image_id": 9, "file_name": "121_09.png", "page": 8, "dpi": 300, "bbox": [363, 380, 731, 823], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Approximation errors between t0 and ti for dif- ferent trees (adaptive: red, 2-ary: green, 3-ary: dark blue, 4-ary: pink, 5-ary: light blue, 10-ary: black) ", "caption_bbox": [394, 300, 694, 348]}, {"image_id": 10, "file_name": "121_10.png", "page": 8, "dpi": 300, "bbox": [95, 52, 395, 284], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Pattern on error height field caused by n-ary trees. Images show adaptive tree and trees with bifurcation- factor n = 2, 3, 4. ", "caption_bbox": [63, 291, 364, 339]}, {"image_id": 11, "file_name": "121_11.png", "page": 9, "dpi": 300, "bbox": [363, 52, 735, 232], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Comparison between average and representative based trees (n = 2, close-up of error surface shown). ", "caption_bbox": [395, 231, 695, 264]}, {"image_id": 12, "file_name": "121_12.png", "page": 11, "dpi": 300, "bbox": [79, 642, 750, 876], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Error terms shown for a 100-step unicolor dataset with shades from black to white, e(t i ,ti+1 ) = const (upper: trees using averages, lower: trees using representants); correct error e(t 0 ,ti ) = i/100 only provided by squared table. ", "caption_bbox": [62, 885, 692, 919]}, {"image_id": 13, "file_name": "121_13.png", "page": 11, "dpi": 300, "bbox": [257, 343, 566, 570], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Approximation errors between t0 and ti for different trees (adaptive: red, 2-ary: green, 3-ary: dark blue, 4-ary: pink, 5-ary: light blue, 10-ary: black) ", "caption_bbox": [63, 580, 695, 612]}, {"image_id": 14, "file_name": "121_14.png", "page": 11, "dpi": 300, "bbox": [100, 52, 731, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Surfaces showing exact two-dimensional error table (green), adaptive tree (wire frame, using original datasets for internal nodes) as a height field e(ti ,t j ), and difference between both tables (yellow): inter-level evaluation (left), intra-level evaluation (middle), edge-based evaluation (right). ", "caption_bbox": [63, 266, 695, 314]}], "122": [{"image_id": 0, "file_name": "122_00.png", "page": 2, "dpi": 300, "bbox": [98, 404, 398, 670], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A subset of a Census Income data set (42 dimen- sions, 200 data items) in Parallel Coordinates. Individual data items cannot be seen clearly. ", "caption_bbox": [63, 669, 364, 717]}, {"image_id": 1, "file_name": "122_01.png", "page": 2, "dpi": 300, "bbox": [108, 88, 398, 368], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Iris data set (4 dimensions, 150 data items) in Par- allel Coordinates. Individual data items can be seen clearly. ", "caption_bbox": [63, 367, 364, 400]}, {"image_id": 2, "file_name": "122_02.png", "page": 3, "dpi": 300, "bbox": [108, 88, 398, 629], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: System structure of VHDR.", "caption_bbox": [119, 628, 307, 646]}, {"image_id": 3, "file_name": "122_03.png", "page": 5, "dpi": 300, "bbox": [98, 115, 398, 419], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: InterRing. Display of a 42 dimension hierarchy.", "caption_bbox": [68, 418, 359, 436]}, {"image_id": 4, "file_name": "122_04.png", "page": 5, "dpi": 300, "bbox": [363, 700, 733, 731], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: 3 of the green terminal nodes on the left of the tree in Figure 4 has been moved to the root. ", "caption_bbox": [395, 663, 696, 696]}, {"image_id": 5, "file_name": "122_05.png", "page": 7, "dpi": 300, "bbox": [363, 447, 733, 857], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: LDOD display using the Three-Axes Method. The green axis represents the minimum within the dimension cluster and the blue axis corresponds to the maximum. ", "caption_bbox": [395, 856, 696, 904]}, {"image_id": 6, "file_name": "122_06.png", "page": 7, "dpi": 300, "bbox": [363, 88, 725, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An LD space of the Census Dataset constructed of 4 dimension clusters. These clusters are composed of 3, 4, 2, and 1 original dimensions respectively from left to right of the displays. The GDODs are shown using the Axis Width Method. ", "caption_bbox": [395, 368, 696, 446]}, {"image_id": 7, "file_name": "122_07.png", "page": 8, "dpi": 300, "bbox": [386, 898, 733, 1013], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The lower dimensional subspaces generated by VHDR. ", "caption_bbox": [395, 861, 696, 894]}, {"image_id": 8, "file_name": "122_08.png", "page": 8, "dpi": 300, "bbox": [98, 818, 401, 854], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: LDOD using the Diagonal Plot Method. The sec- ond and fourth dimensions represent clusters with the second dimension being better correlated. ", "caption_bbox": [63, 771, 364, 819]}, {"image_id": 9, "file_name": "122_09.png", "page": 11, "dpi": 300, "bbox": [98, 746, 362, 997], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: 3 of the green terminal nodes on the left of the tree in Figure 1 has been moved to the root. ", "caption_bbox": [51, 709, 352, 742]}, {"image_id": 10, "file_name": "122_10.png", "page": 11, "dpi": 300, "bbox": [115, 88, 384, 368], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: InterRing. Display of a 42 dimension hierarchy.", "caption_bbox": [56, 367, 347, 385]}, {"image_id": 11, "file_name": "122_11.png", "page": 11, "dpi": 300, "bbox": [430, 809, 733, 845], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: LDOD display using the Three-Axes Method. The green axis represents the minimum within the dimension cluster and the blue axis corresponds to the maximum. ", "caption_bbox": [383, 762, 684, 810]}], "123": [{"image_id": 0, "file_name": "123_00.png", "page": 2, "dpi": 300, "bbox": [98, 88, 398, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Multidimensional, time-varying, multivariate dis- tributions. ", "caption_bbox": [63, 241, 364, 273]}, {"image_id": 1, "file_name": "123_01.png", "page": 3, "dpi": 300, "bbox": [165, 88, 668, 283], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Bar chart glyphs representing distributions are drawn over each distribution. (a) shows the original 100 x 100 grid displayed as a 50 x 50 array of histograms, while (b) shows the same data as a 10 x 10 array of histograms. ", "caption_bbox": [63, 282, 696, 314]}, {"image_id": 2, "file_name": "123_02.png", "page": 4, "dpi": 300, "bbox": [363, 88, 679, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Pseudocolor rendering of the mean of the sg2 data. Mean is obtained using a ToScalar() operator defined in Equation 8. ", "caption_bbox": [395, 298, 696, 346]}, {"image_id": 3, "file_name": "123_03.png", "page": 5, "dpi": 300, "bbox": [363, 88, 684, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Discontinuous color map of output from a bump hunting algorithm on the sg2 data set. The number of bumps (or modality) of a distribution is mapped to different colors. The output of the bump hunting algorithm 11 presented here is a procedural ToScalar() operation. The arch observed in Figured 4 is also noticeable here. The reddish region in- dicates that the distributions at those locations are more bumpy (higher modality). ", "caption_bbox": [395, 284, 696, 408]}, {"image_id": 4, "file_name": "123_04.png", "page": 5, "dpi": 300, "bbox": [143, 88, 396, 347], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Pseudocolor rendering of the three parameters from sg2 obtained using a ToVector() operation that ex- tracted the mean, standard deviation, and skewness of the distribution. Mean is mapped to hue using the same color range as in Figure 3, standard deviation is inversely mapped to value, and the absolute value of skewness is inversely mapped to saturation. The locations of the ground truth points are also easily visible as brighter, fully saturated points. Places with higher standard deviations are showing up as darker regions, especially prominent across the arch and the lower, middle region. The color map on the left has the value held constant at one, while the color map on the right has the saturation also held constant at one. ", "caption_bbox": [63, 346, 364, 546]}, {"image_id": 5, "file_name": "123_05.png", "page": 5, "dpi": 300, "bbox": [363, 412, 733, 603], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Streamlines of the sref RSM models on Octo- ber the 24th of 2002. The background field is colored with the mean velocity magnitude using the same color map as in Figure 3. The white streamlines are traditional streamlines calculated independently over each vector field realization. One can see why they are referred to as spaghetti plots in meteorology. The black streamline uses Equation 8 to con- vert the distribution at each component of Pi  1 to a scalar. It also corresponds to what one might expect as the average streamlines of all the spaghetti plots. ", "caption_bbox": [395, 602, 696, 756]}, {"image_id": 6, "file_name": "123_06.png", "page": 6, "dpi": 300, "bbox": [98, 677, 398, 860], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Streamline visualization using the binwise addi- tion operation. It is rendered with transparent circles as in Figure 8, and has the same seed point as the previous three streamline images. ", "caption_bbox": [63, 859, 364, 922]}, {"image_id": 7, "file_name": "123_07.png", "page": 6, "dpi": 300, "bbox": [363, 281, 733, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The white swath represents streamline trajecto- ries, while the yellow swath represents pathline trajectories of the ensemble. Both swaths use binwise addition. ", "caption_bbox": [395, 234, 696, 282]}, {"image_id": 8, "file_name": "123_08.png", "page": 6, "dpi": 300, "bbox": [122, 88, 396, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Same as Figure 6 but showing the spaghetti plots with the streamlines generated using Equations 6 and 7. The two blue streamlines correspond to the envelope of the spaghetti plots. ", "caption_bbox": [63, 232, 364, 295]}, {"image_id": 9, "file_name": "123_09.png", "page": 6, "dpi": 300, "bbox": [98, 299, 398, 472], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Streamline visualization using the convolution ad- dition operation. The distribution of positions at the end of each time step is rendered as a transparent circle encom- passing those points. ", "caption_bbox": [63, 471, 364, 534]}, {"image_id": 10, "file_name": "123_10.png", "page": 8, "dpi": 300, "bbox": [106, 692, 758, 728], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: An isosurface using a reference distribution within the mixing region. The surface represents regions in the data where the distributions are very similar to the reference dis- tribution shown on the right. Not surprisingly, it corresponds quite well with Figure 13. Color can also be used to display other properties of the distributions by using an appropriate ToScalar() operator. Here we color the surface by the standard deviation of the distribution at each location. ", "caption_bbox": [403, 569, 720, 693]}, {"image_id": 11, "file_name": "123_11.png", "page": 8, "dpi": 300, "bbox": [387, 354, 758, 567], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Similar to Figure 11 except a different reference dis- tribution is used. The reference distribution is made up by ag- gregating all the samples of all the pixels in the data set. The dots correspond to locations of the ground truth points. Color corresponds to the output of the SKLZ similarity measure. ", "caption_bbox": [403, 277, 720, 355]}, {"image_id": 12, "file_name": "123_12.png", "page": 8, "dpi": 300, "bbox": [136, 88, 404, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Contours of distribution data sg2 using SKLZ op- erator. The distribution to the right is the reference distribution used to find the contour lines. That is, points along the contour lines have distributions very similar to the reference distribution according to the SKLZ similarity measure. Color corresponds to the output of the SKLZ similarity measure. ", "caption_bbox": [71, 269, 388, 362]}, {"image_id": 13, "file_name": "123_13.png", "page": 10, "dpi": 300, "bbox": [104, 351, 758, 411], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Comparison of Chi-square distributions with dif- ferent shape parameters (different amounts of skewness). The higher the curve, the more discriminating (more powerful) the distance measure. ", "caption_bbox": [403, 289, 720, 352]}, {"image_id": 14, "file_name": "123_14.png", "page": 10, "dpi": 300, "bbox": [154, 88, 751, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: The black distribution is obtained when the null hy- pothesis is true and the red distribution is obtained when the al-                                                                    Figur ternative hypothesis is true. The x-axis is the distance measure                                                                    ferent ", "caption_bbox": [71, 267, 434, 322]}], "124": [{"image_id": 0, "file_name": "124_00.png", "page": 2, "dpi": 300, "bbox": [424, 88, 711, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Building a Cubic Mesh", "caption_bbox": [461, 279, 630, 297]}, {"image_id": 1, "file_name": "124_01.png", "page": 3, "dpi": 300, "bbox": [107, 88, 398, 479], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Lattices in the Spatial and Frequency Domains", "caption_bbox": [69, 493, 357, 511]}, {"image_id": 2, "file_name": "124_02.png", "page": 4, "dpi": 300, "bbox": [117, 88, 713, 207], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Marching Octahedra Cases", "caption_bbox": [284, 224, 475, 242]}, {"image_id": 3, "file_name": "124_03.png", "page": 4, "dpi": 300, "bbox": [614, 312, 718, 414], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Ambiguous Faces", "caption_bbox": [474, 364, 615, 382]}, {"image_id": 4, "file_name": "124_04.png", "page": 4, "dpi": 300, "bbox": [113, 260, 398, 458], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Generating Meshes from Regular Samples", "caption_bbox": [81, 479, 345, 497]}, {"image_id": 5, "file_name": "124_05.png", "page": 5, "dpi": 300, "bbox": [110, 88, 398, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Modified Marching Octahedra Cases", "caption_bbox": [94, 275, 332, 293]}, {"image_id": 6, "file_name": "124_06.png", "page": 6, "dpi": 300, "bbox": [507, 88, 696, 495], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Cases for Modified Marching Hexahedra", "caption_bbox": [250, 445, 508, 463]}, {"image_id": 7, "file_name": "124_07.png", "page": 11, "dpi": 300, "bbox": [161, 641, 660, 844], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Grouping Tetrahedra", "caption_bbox": [300, 879, 459, 897]}, {"image_id": 8, "file_name": "124_08.png", "page": 11, "dpi": 300, "bbox": [161, 88, 670, 623], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Four Lobsters", "caption_bbox": [318, 622, 441, 640]}], "125": [{"image_id": 0, "file_name": "125_00.png", "page": 3, "dpi": 300, "bbox": [165, 88, 685, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A Small Example in Three dimensions", "caption_bbox": [258, 360, 501, 378]}, {"image_id": 1, "file_name": "125_01.png", "page": 4, "dpi": 300, "bbox": [153, 88, 398, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A Small Sample Triangulation", "caption_bbox": [111, 259, 315, 277]}, {"image_id": 2, "file_name": "125_02.png", "page": 4, "dpi": 300, "bbox": [330, 296, 368, 486], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Graph Matching to extract Seed Sets", "caption_bbox": [95, 435, 331, 453]}, {"image_id": 3, "file_name": "125_03.png", "page": 5, "dpi": 300, "bbox": [424, 88, 678, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Monotone Paths as Seeds", "caption_bbox": [455, 259, 635, 277]}, {"image_id": 4, "file_name": "125_04.png", "page": 5, "dpi": 300, "bbox": [363, 278, 672, 472], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Storing Monotone Paths as Path Seeds", "caption_bbox": [422, 471, 667, 489]}, {"image_id": 5, "file_name": "125_05.png", "page": 7, "dpi": 300, "bbox": [336, 88, 398, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A Contour Tree that is Hard to Display", "caption_bbox": [89, 205, 337, 223]}, {"image_id": 6, "file_name": "125_06.png", "page": 11, "dpi": 300, "bbox": [106, 465, 392, 654], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Isolating Local Maxima", "caption_bbox": [123, 653, 302, 671]}, {"image_id": 7, "file_name": "125_07.png", "page": 11, "dpi": 300, "bbox": [129, 258, 369, 447], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: After Adjusting The Isovalue, and Unselecting", "caption_bbox": [71, 446, 355, 464]}, {"image_id": 8, "file_name": "125_08.png", "page": 11, "dpi": 300, "bbox": [424, 88, 652, 890], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Flexible Isosurface Operations", "caption_bbox": [438, 889, 652, 907]}, {"image_id": 9, "file_name": "125_09.png", "page": 11, "dpi": 300, "bbox": [143, 88, 427, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A Level Set, with Colour-Coded Tags", "caption_bbox": [94, 239, 332, 257]}, {"image_id": 10, "file_name": "125_10.png", "page": 11, "dpi": 300, "bbox": [150, 672, 354, 861], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: A Molecule with a Complex Contour Tree", "caption_bbox": [79, 860, 346, 878]}], "126": [{"image_id": 0, "file_name": "126_00.png", "page": 2, "dpi": 300, "bbox": [352, 426, 741, 727], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1. Customized potentials for       different similarities. On the horizontal axis, the distance between two objects is depicted. The      different functions describe the energy for         different similarities. ", "caption_bbox": [401, 726, 673, 799]}, {"image_id": 1, "file_name": "126_01.png", "page": 4, "dpi": 300, "bbox": [129, 127, 396, 406], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A new accelerated potential function with prediction and correction. ", "caption_bbox": [81, 405, 353, 438]}, {"image_id": 2, "file_name": "126_02.png", "page": 4, "dpi": 300, "bbox": [352, 542, 737, 811], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: System architecture and components.", "caption_bbox": [401, 810, 638, 826]}, {"image_id": 3, "file_name": "126_03.png", "page": 7, "dpi": 300, "bbox": [141, 90, 735, 492], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Product-Country Relationship: The selected product is sold only in Mexico and Argentina.                There were 47,753 product sales transaction records in the year 2000. ", "caption_bbox": [116, 491, 679, 524]}], "127": [{"image_id": 0, "file_name": "127_00.png", "page": 3, "dpi": 300, "bbox": [364, 272, 732, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Planar unfolding of a sequence of faces. The closed geodesic path \u03b1 unfolds to the line segment [a1 a2 ], but is not a strict constriction since \u03b2 which unfolds to [b1 b2 ] has the same length. ", "caption_bbox": [395, 210, 696, 273]}, {"image_id": 1, "file_name": "127_01.png", "page": 4, "dpi": 300, "bbox": [98, 88, 738, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Seed curve (abc) on a surface. (b) After one more simplification step, the surface is not a manifold any- more. ", "caption_bbox": [395, 240, 696, 288]}, {"image_id": 2, "file_name": "127_02.png", "page": 6, "dpi": 300, "bbox": [162, 88, 394, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: This seed curve (abc) will lead to a degenerate constriction. ", "caption_bbox": [63, 225, 364, 258]}, {"image_id": 3, "file_name": "127_03.png", "page": 7, "dpi": 300, "bbox": [363, 88, 396, 689], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Left: Simplification steps on a simple butterfly model. Right: corresponding reconstructed curves. The seed curve \u03b22 is made of three edges, between the vertices p1 , p2 and p3 of T 2 . Since p3 = v, \u03b21 is initialized with only two pivot vertices, p1 and p2 , on T 1 . The computation of a geodesic path between p2 and p1 creates a new pivot vertex p3 . For the same reason, \u03b20 is initialized with only two pivot vertices, p1 and p3 , on T 0 . Geodesic paths between them cross two faces each. ", "caption_bbox": [395, 513, 696, 652]}, {"image_id": 4, "file_name": "127_04.png", "page": 8, "dpi": 300, "bbox": [98, 961, 366, 1001], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Left: Simplification steps on a simple twisted cylinder. Right: corresponding reconstructed curves. The seed curve \u03b24 is made of three edges, between the vertices p1 , p2 and p3 of T 4 . Since p3 = v, \u03b23 is initialized with only two pivot vertices, p1 and p2 , on T 3 . The computation of a geodesic path between p2 and p1 creates two new pivot vertices p3 and p4 . For the same reason, \u03b22 is initialized with three pivot vertices, p2 , p3 and p4 on T 2 . The compu- tation of a geodesic path between p4 and p2 creates a ne ", "caption_bbox": [63, 821, 364, 962]}, {"image_id": 5, "file_name": "127_05.png", "page": 8, "dpi": 300, "bbox": [386, 915, 732, 1018], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Left: some simplified surfaces and their first found seed curves. Right: constrictions constructed on the initial surfaces. ", "caption_bbox": [395, 868, 696, 916]}], "128": [{"image_id": 0, "file_name": "128_00.png", "page": 6, "dpi": 300, "bbox": [361, 412, 401, 928], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5 where we start with an enumerated volume of size 100 \u00d7 300 \u00d7 100 . For some applications, an approximation of the quality shown in the right image of this Figure 5a may be sufficient. This requires no information beyond the topology. The smooth quality is gained through the optimization process used to compute the shroud. While the shroud adds no additional cost in space, there is the cost required for computing the \u03b4 i ' s of the optimal surface. It depends upon the application and the efficiency of the implementation as to whether or not the archiving or bandwidth costs are sufficient to justify the smoothing costs. In most situations, this decision would require additional study. The model of the left image of Figure 5b is optimized after 1-bit of quantification and the right uses 2-bits. All four models have the same topology with approximately 100K triangles. The two models of Figure 5a can be represented with approximately 50K bits. The left model of Figure 5b requires approximately 150K bits and the right about 250K bits. ", "caption_bbox": [63, 621, 362, 903]}, {"image_id": 1, "file_name": "128_01.png", "page": 7, "dpi": 300, "bbox": [97, 366, 396, 746], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The left image is the midpoint surface defining segmented data of size 32 \u00d7 96 \u00d7 32 of a right tibia from a male Pan troglodytes (chimpanzee). The right image is the optimal shroud with its 4*-network. ", "caption_bbox": [63, 745, 362, 806]}, {"image_id": 2, "file_name": "128_02.png", "page": 9, "dpi": 300, "bbox": [97, 729, 396, 771], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Target containment region modeled as enumerated volume and displayed with optimal separating surface. ", "caption_bbox": [63, 685, 362, 730]}, {"image_id": 3, "file_name": "128_03.png", "page": 9, "dpi": 300, "bbox": [145, 83, 396, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The basic geometry of towed sonar data. From the data, a point on the target (right submarine) is known to be in the reflected annulus. Image is courtesy of K. Lima & R. Shell, Naval Undersea Warfare Center, Newport. ", "caption_bbox": [63, 264, 362, 337]}], "129": [{"image_id": 0, "file_name": "129_00.png", "page": 3, "dpi": 300, "bbox": [363, 88, 733, 176], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) Around a regular point x \u2208 R3 , the isosurface F \u22121 (F(x)) divides space into a single connected volume P with F > 0 (dark gray) and a single connected volume N with F < 0 (white). (b)/(c) Around a minimum/maximum, all points in U have a larger/smaller value than F(x). (d) In case of a saddle, there are multiple (more than one) regions with values larger or smaller than the value F(x). ", "caption_bbox": [395, 175, 696, 286]}, {"image_id": 1, "file_name": "129_01.png", "page": 4, "dpi": 300, "bbox": [363, 88, 663, 164], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: With respect to the L\u221e -norm, the intersection of the neighborhood with a cell is a collection of boxes. If the neighborhood is chosen sufficiently small, vertices of the boxes that do not coincide with cell vertices or faces have the same polarity as an edge-connected vertex, and their corre- sponding region is also connected to one of the cell\u2019s edges. ", "caption_bbox": [395, 163, 696, 256]}, {"image_id": 2, "file_name": "129_02.png", "page": 5, "dpi": 300, "bbox": [363, 88, 662, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Vertex (v0 \u2013v8 )and edge (e0 \u2013e11 ) numbering scheme employed in this paper. Vertex numbers are also used to determine the topology case number. ", "caption_bbox": [395, 187, 696, 235]}, {"image_id": 3, "file_name": "129_03.png", "page": 6, "dpi": 300, "bbox": [124, 88, 733, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Stages of the algorithm: (a) After the local pass all vertices that cannot be classified locally are marked with a flag (indicated by a rectangle around these vertices in the figure). Once the first flagged vertex is determined we perform a flood fill that marks all vertices belonging to the classification section (marked by solid black disks in the figure). The region is classified by constructing two graphs, one representing positive- and one representing negative-connected regions in the neighborhood around the classification region. For each edge originating in a vertex belonging to the classification region, a corresponding node in the graph exists (shown as dark and light gray solid rectangles). Two nodes in the graph are connected when the corresponding edges belong to the same connected region in a cell. A region can be classified by counting the connected components in the two graphs. ", "caption_bbox": [63, 245, 695, 369]}, {"image_id": 4, "file_name": "129_04.png", "page": 7, "dpi": 300, "bbox": [664, 257, 730, 367], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Sub-cases for topology base case C8.", "caption_bbox": [426, 334, 665, 352]}, {"image_id": 5, "file_name": "129_05.png", "page": 7, "dpi": 300, "bbox": [316, 245, 379, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Disambiguation for case C2.4.", "caption_bbox": [110, 314, 317, 332]}, {"image_id": 6, "file_name": "129_06.png", "page": 8, "dpi": 300, "bbox": [334, 88, 398, 283], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Sub-cases for topology base case C9.", "caption_bbox": [90, 154, 335, 172]}, {"image_id": 7, "file_name": "129_07.png", "page": 9, "dpi": 300, "bbox": [98, 315, 399, 347], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Region maximum in \u201cNucleon\u201d data set (cour- tesy of SFB 382 of the German Research Council (DFG)). (a) Isosurface for an isovalue slightly below the maximum. (b) Isosurface for an isovalue slightly above the maximum. ", "caption_bbox": [63, 253, 364, 316]}, {"image_id": 8, "file_name": "129_08.png", "page": 10, "dpi": 300, "bbox": [101, 88, 730, 747], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Topological analysis of the \u201cHydrogen\u201d data set: (a), (b) Volume rendered images with automatically generated transfer functions emphasizing topological changes (a) and zones of similar topological behavior (b); (c) \u2013 (l) topological structure; (c) around a region minim having a value of zero, two components appear simultaneously; (d), (e) at a saddle region having a value of 3.5, a hole in one surface component closes; (f), (g) the \u201cinner\u201d surface is separated into three disjoint components along two saddle regions having a value of 12; (h) a close-up of one of the two saddle regions having a value of 12; (i), (j) The \u201cring\u201d component disappears around a region maximum having a value of 36; (k),(l) Two components disappear at two region maxima having a value of 80; The remaining component disappears around a localized maximum having a value of 250; (Data set courtesy of SFB 382 of the German Research Council (DFG).) ", "caption_bbox": [63, 746, 695, 870]}, {"image_id": 9, "file_name": "129_09.png", "page": 11, "dpi": 300, "bbox": [101, 88, 730, 747], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Topological analysis of the \u201cHydrogen\u201d data set: (a), (b) Volume rendered images with automatically generated transfer functions emphasizing topological changes (a) and zones of similar topological behavior (b); (c) \u2013 (l) topological structure; (c) around a region minim having a value of zero, two components appear simultaneously; (d), (e) at a saddle region having a value of 3.5, a hole in one surface component closes; (f), (g) the \u201cinner\u201d surface is separated into three disjoint components along two saddle regions having a value of 12; (h) a close-up of one of the two saddle regions having a value of 12; (i), (j) The \u201cring\u201d component disappears around a region maximum having a value of 36; (k),(l) Two components disappear at two region maxima having a value of 80; The remaining component disappears around a localized maximum having a value of 250; (Data set courtesy of SFB 382 of the German Research Council (DFG).) ", "caption_bbox": [63, 746, 695, 870]}], "130": [{"image_id": 0, "file_name": "130_00.png", "page": 3, "dpi": 300, "bbox": [363, 88, 726, 282], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) HDAF1 (\u03c3 = 0.598413420), (b) HDAF4 (\u03c3 = 0.981772018), and (c) HDAF6 (\u03c3 = 1.169944988) interpo- lation filters and their Fourier transform (d-f). ", "caption_bbox": [394, 281, 695, 329]}, {"image_id": 1, "file_name": "130_01.png", "page": 5, "dpi": 300, "bbox": [103, 88, 415, 486], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Coefficients of the interpolation filters.", "caption_bbox": [90, 485, 336, 503]}, {"image_id": 2, "file_name": "130_02.png", "page": 5, "dpi": 300, "bbox": [412, 88, 728, 486], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Coefficients of the derivative filters.", "caption_bbox": [430, 485, 661, 503]}, {"image_id": 3, "file_name": "130_03.png", "page": 6, "dpi": 300, "bbox": [130, 88, 408, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 4: Overlap percentage of (a) the box filter area for the interpolation filters, and (b) the ramp filter area for the derivative filters. ", "caption_bbox": [63, 755, 364, 803]}, {"image_id": 4, "file_name": "130_04.png", "page": 7, "dpi": 300, "bbox": [363, 88, 728, 447], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Volume visualization of the MRI data set using (a) Catmull-Rom, (b) cardinal cubic B-spline, (c) cardinal cubic o-Moms, (d) HDAF1 (\u03c3 = 0.598413420), (e) HDAF4 (\u03c3 = 0.981772018), (f) HDAF6 (\u03c3 = 1.169944988), (g) HDAF1 (\u03c3 = 0.897620130), (h) HDAF4 (\u03c3 = 1.472658027), and (i) HDAF6 (\u03c3 = 1.754917482). ", "caption_bbox": [395, 446, 696, 541]}, {"image_id": 5, "file_name": "130_05.png", "page": 8, "dpi": 300, "bbox": [98, 308, 398, 498], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Isosurface rendering of the Marschner-Lobb func- tion. (a) Overview and (b) central part. ", "caption_bbox": [63, 497, 364, 530]}], "131": [{"image_id": 0, "file_name": "131_00.png", "page": 4, "dpi": 300, "bbox": [99, 88, 396, 224], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Illustration of the calculation of the reconstruction function bounding function in voxel space, transformation to world space and projection space and the subsequent \u201cflat- tening\u201d and transformation back to voxel space. ", "caption_bbox": [63, 223, 364, 286]}, {"image_id": 1, "file_name": "131_01.png", "page": 8, "dpi": 300, "bbox": [98, 642, 732, 884], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: ShellSplat rendering of the well-known engine block data set. The grey material has been made transparent. Data set supplied by volvis.org, originally made by General Electric. Fast rendering on left, high quality on the right. ", "caption_bbox": [63, 883, 695, 916]}, {"image_id": 2, "file_name": "131_02.png", "page": 8, "dpi": 300, "bbox": [97, 351, 732, 601], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: ShellSplat rendering of the Stanford CTHead data set. The fast rendering is on the left and the high quality is on the right. Note that this data set is anisotropically sampled. ", "caption_bbox": [63, 600, 695, 633]}, {"image_id": 3, "file_name": "131_03.png", "page": 8, "dpi": 300, "bbox": [213, 88, 618, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: ShellSplat rendering of rotational b-plane x-ray scan of the arteries of the right half of a human head, showing an aneurism. On the left is the fast rendering and on the right is the high quality version. Data from volvis.org courtesy of Philips Research, Hamburg, Germany. ", "caption_bbox": [63, 302, 695, 350]}, {"image_id": 4, "file_name": "131_04.png", "page": 9, "dpi": 300, "bbox": [98, 642, 732, 884], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: ShellSplat rendering of the well-known engine block data set. The grey material has been made transparent. Data set supplied by volvis.org, originally made by General Electric. Fast rendering on left, high quality on the right. ", "caption_bbox": [63, 883, 695, 916]}, {"image_id": 5, "file_name": "131_05.png", "page": 9, "dpi": 300, "bbox": [97, 351, 732, 601], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: ShellSplat rendering of the Stanford CTHead data set. The fast rendering is on the left and the high quality is on the right. Note that this data set is anisotropically sampled. ", "caption_bbox": [63, 600, 695, 633]}, {"image_id": 6, "file_name": "131_06.png", "page": 9, "dpi": 300, "bbox": [213, 88, 618, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: ShellSplat rendering of rotational b-plane x-ray scan of the arteries of the right half of a human head, showing an aneurism. On the left is the fast rendering and on the right is the high quality version. Data from volvis.org courtesy of Philips Research, Hamburg, Germany. ", "caption_bbox": [63, 302, 695, 350]}], "132": [{"image_id": 0, "file_name": "132_00.png", "page": 2, "dpi": 300, "bbox": [363, 724, 733, 761], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Loss of fuzzy boundary can adversely affect direct volume rendering results of an engine CT dataset. ", "caption_bbox": [395, 693, 695, 725]}, {"image_id": 1, "file_name": "132_01.png", "page": 2, "dpi": 300, "bbox": [98, 480, 400, 511], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Direct volume rendering approach to segmenta- tion and analysis of volumetric data. ", "caption_bbox": [63, 443, 363, 475]}, {"image_id": 2, "file_name": "132_02.png", "page": 4, "dpi": 300, "bbox": [98, 503, 398, 708], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The region of interest to be extracted (dotted) is itself made up of many regions (Ra , Rb , . . . ), and surrounded by other regions (R1 , R2 , . . . ). ", "caption_bbox": [63, 707, 364, 756]}, {"image_id": 3, "file_name": "132_03.png", "page": 4, "dpi": 300, "bbox": [390, 925, 732, 1013], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: At the end of step 1, the boundary voxels are marked. ", "caption_bbox": [394, 892, 694, 924]}, {"image_id": 4, "file_name": "132_04.png", "page": 5, "dpi": 300, "bbox": [424, 88, 737, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Intensity flipping for voxel p.", "caption_bbox": [446, 334, 644, 352]}, {"image_id": 5, "file_name": "132_05.png", "page": 5, "dpi": 300, "bbox": [435, 370, 737, 606], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Intensity flipping graph for voxel p.", "caption_bbox": [430, 605, 660, 623]}, {"image_id": 6, "file_name": "132_06.png", "page": 6, "dpi": 300, "bbox": [98, 494, 398, 702], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: At the end of step 4, all category 3 voxels are con- verted to air. ", "caption_bbox": [63, 701, 363, 733]}, {"image_id": 7, "file_name": "132_07.png", "page": 6, "dpi": 300, "bbox": [363, 88, 727, 477], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A cup is extracted using our algorithm.", "caption_bbox": [421, 481, 669, 499]}, {"image_id": 8, "file_name": "132_08.png", "page": 7, "dpi": 300, "bbox": [107, 88, 396, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Extraction of cup using simple thresholding.", "caption_bbox": [73, 293, 353, 311]}, {"image_id": 9, "file_name": "132_09.png", "page": 7, "dpi": 300, "bbox": [399, 926, 733, 1013], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Extraction of the valve from the CT engine dataset using our anti-aliased extraction. ", "caption_bbox": [395, 889, 696, 921]}, {"image_id": 10, "file_name": "132_10.png", "page": 7, "dpi": 300, "bbox": [98, 435, 396, 905], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Direct volume rendering of the extracted cup.", "caption_bbox": [70, 904, 356, 922]}, {"image_id": 11, "file_name": "132_11.png", "page": 8, "dpi": 300, "bbox": [107, 88, 398, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Direct volume rendering of the extracted valve.", "caption_bbox": [66, 293, 360, 311]}, {"image_id": 12, "file_name": "132_12.png", "page": 8, "dpi": 300, "bbox": [98, 466, 396, 877], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Direct volume rendering of an anti-aliased ex- tracted bone of the right foot of the Visible Human CT dataset. ", "caption_bbox": [63, 876, 364, 924]}, {"image_id": 13, "file_name": "132_13.png", "page": 8, "dpi": 300, "bbox": [391, 920, 733, 1013], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Zoomed in portion of the extracted bone shown in Figure 15 ", "caption_bbox": [395, 889, 696, 921]}, {"image_id": 14, "file_name": "132_14.png", "page": 9, "dpi": 300, "bbox": [98, 375, 398, 654], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 18: Bone marrow hidden behind muscle tissues. (Also see Color Plate Figure 2.) ", "caption_bbox": [63, 653, 364, 685]}, {"image_id": 15, "file_name": "132_15.png", "page": 9, "dpi": 300, "bbox": [98, 88, 398, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Experimental results with three datasets.", "caption_bbox": [420, 82, 670, 100]}, {"image_id": 16, "file_name": "132_16.png", "page": 11, "dpi": 300, "bbox": [178, 88, 653, 464], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Bone marrow clearly visible after extracting soft tissues using anti-aliased extraction.", "caption_bbox": [139, 463, 619, 481]}], "133": [{"image_id": 0, "file_name": "133_00.png", "page": 3, "dpi": 300, "bbox": [363, 88, 398, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Illustration of the geometric meaning of crest point in a 2D surface. ", "caption_bbox": [63, 227, 364, 260]}, {"image_id": 1, "file_name": "133_01.png", "page": 6, "dpi": 300, "bbox": [98, 606, 396, 822], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The results of line-like point extraction based on Hessian matrix of the real mouse egg data, (a) vector repre- sentation, and (b) boundary surface representation of the set of line-like points. ", "caption_bbox": [63, 821, 364, 884]}, {"image_id": 2, "file_name": "133_02.png", "page": 6, "dpi": 300, "bbox": [105, 88, 396, 236], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: These images show single tiff slices. (a) a slice of raw data, (b) a slice of data segmented using Weibull E-SD highlighting the spindle region ", "caption_bbox": [63, 235, 364, 283]}, {"image_id": 3, "file_name": "133_03.png", "page": 6, "dpi": 300, "bbox": [98, 284, 396, 543], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) The distribution of coefficients of S-G filter when the window of width is 27 (i.e. nl = nr = 13) with M = 2 and M = 4. (b) A numerical experiment using a 27 point smoothing filter. ", "caption_bbox": [63, 542, 364, 605]}, {"image_id": 4, "file_name": "133_04.png", "page": 6, "dpi": 300, "bbox": [391, 751, 733, 1018], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) and (b) are the different viewports of spin- dle scaffold with increased detail using our extraction algo- rithms. (c) and (d) are the different viewports of mulitchan- nel ray casting which includes spindle scaffold (green) and DNA (red). ", "caption_bbox": [395, 674, 696, 752]}, {"image_id": 5, "file_name": "133_05.png", "page": 7, "dpi": 300, "bbox": [98, 606, 396, 822], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The results of line-like point extraction based on Hessian matrix of the real mouse egg data, (a) vector repre- sentation, and (b) boundary surface representation of the set of line-like points. ", "caption_bbox": [63, 821, 364, 884]}, {"image_id": 6, "file_name": "133_06.png", "page": 7, "dpi": 300, "bbox": [105, 88, 396, 236], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: These images show single tiff slices. (a) a slice of raw data, (b) a slice of data segmented using Weibull E-SD highlighting the spindle region ", "caption_bbox": [63, 235, 364, 283]}, {"image_id": 7, "file_name": "133_07.png", "page": 7, "dpi": 300, "bbox": [98, 284, 396, 543], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) The distribution of coefficients of S-G filter when the window of width is 27 (i.e. nl = nr = 13) with M = 2 and M = 4. (b) A numerical experiment using a 27 point smoothing filter. ", "caption_bbox": [63, 542, 364, 605]}, {"image_id": 8, "file_name": "133_08.png", "page": 7, "dpi": 300, "bbox": [391, 751, 733, 1018], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) and (b) are the different viewports of spin- dle scaffold with increased detail using our extraction algo- rithms. (c) and (d) are the different viewports of mulitchan- nel ray casting which includes spindle scaffold (green) and DNA (red). ", "caption_bbox": [395, 674, 696, 752]}], "134": [{"image_id": 0, "file_name": "134_00.png", "page": 2, "dpi": 300, "bbox": [127, 52, 703, 364], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Feature tracking applied to confocal data. The left image shows tracks of the raw data (internal and external motion). The right image shows tracks of the filtered data (internal motion only). ", "caption_bbox": [63, 371, 695, 404]}, {"image_id": 1, "file_name": "134_01.png", "page": 3, "dpi": 300, "bbox": [101, 52, 729, 483], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The rotation angle in the XY-plane of the data in five time steps of the time series. The top row shows slices of raw data set and the found landmarks at each time step, The middle row shows slices using the landmark registration method. The yellow angle shows the rigid rotation with respect to the raw data. The bottom row shows the rotation angles found using the voxel based method. ", "caption_bbox": [63, 489, 695, 552]}, {"image_id": 2, "file_name": "134_02.png", "page": 4, "dpi": 300, "bbox": [363, 52, 721, 689], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Angles found by the registration algorithms. The top plot shows the found angles for the landmark method (green) and voxel method (red). The middle plot shows the distribution of angle values. The bottom plot shows the dif- ferences between the found angles. ", "caption_bbox": [394, 688, 694, 766]}, {"image_id": 3, "file_name": "134_03.png", "page": 5, "dpi": 300, "bbox": [108, 348, 388, 544], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Number of landmarks.", "caption_bbox": [130, 552, 295, 570]}, {"image_id": 4, "file_name": "134_04.png", "page": 5, "dpi": 300, "bbox": [108, 52, 397, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Cumulated angles (top) and angle difference (bot- tom). ", "caption_bbox": [63, 287, 363, 320]}, {"image_id": 5, "file_name": "134_05.png", "page": 7, "dpi": 300, "bbox": [127, 77, 703, 364], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Feature tracking applied to confocal data. The left image shows tracks of the raw data (internal and external motion). The right image shows tracks of the filtered data (internal motion only). ", "caption_bbox": [63, 371, 695, 404]}, {"image_id": 6, "file_name": "134_06.png", "page": 7, "dpi": 300, "bbox": [101, 429, 729, 834], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The rotation angle in the XY-plane of the data in five time steps of the time series. The top row shows slices of raw data set and the found landmarks at each time step, The middle row shows slices using the landmark registration method. The yellow angle shows the rigid rotation with respect to the raw data. The bottom row shows the rotation angles found using the voxel based method. ", "caption_bbox": [63, 841, 695, 904]}], "135": [{"image_id": 0, "file_name": "135_00.png", "page": 3, "dpi": 300, "bbox": [98, 52, 398, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Minimum and maximum rendering time in depen- dence on the block size. ", "caption_bbox": [63, 310, 364, 343]}, {"image_id": 1, "file_name": "135_01.png", "page": 4, "dpi": 300, "bbox": [98, 771, 398, 898], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Equidistant (a) and cell-border (b) sampling.", "caption_bbox": [74, 903, 352, 921]}, {"image_id": 2, "file_name": "135_02.png", "page": 6, "dpi": 300, "bbox": [98, 632, 733, 841], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Selected MIPs from the image sequence with a CT dataset.", "caption_bbox": [206, 848, 552, 866]}, {"image_id": 3, "file_name": "135_03.png", "page": 6, "dpi": 300, "bbox": [98, 369, 733, 578], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Selected MIPs from the image sequence with a thorax dataset.", "caption_bbox": [198, 585, 561, 603]}, {"image_id": 4, "file_name": "135_04.png", "page": 6, "dpi": 300, "bbox": [98, 52, 733, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Maximum intensity projection (MIP) of a contrast enhanced MR angiography dataset. Frontal view (left) and diagonal close-up views. Tri-linear interpolation with 4 \u00d7 oversampling (middle) and bi-linear interpolation at the voxels boundaries (right). ", "caption_bbox": [63, 292, 695, 340]}], "136": [{"image_id": 0, "file_name": "136_00.png", "page": 2, "dpi": 300, "bbox": [363, 494, 732, 739], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The stream lines of f may go \"forward\" and \"back- ward\" in time. ", "caption_bbox": [395, 738, 695, 771]}, {"image_id": 1, "file_name": "136_01.png", "page": 2, "dpi": 300, "bbox": [363, 88, 726, 331], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Feature tracking using feature flow fields. The dy- namic behavior of a feature of v at a certain time ti is tracked by tracing the stream lines of f from the feature. The features at a certain time ti+1 can be observed by intersecting these stream lines with the time plane t = ti+1 . ", "caption_bbox": [395, 330, 696, 410]}, {"image_id": 2, "file_name": "136_02.png", "page": 3, "dpi": 300, "bbox": [98, 247, 398, 534], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Two events in a flow. Shown are two times tb and ts in which events take place. At the time tb , a new feature is born, at the time ts it splits into two features. ", "caption_bbox": [62, 533, 363, 581]}, {"image_id": 3, "file_name": "136_03.png", "page": 4, "dpi": 300, "bbox": [364, 510, 395, 692], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Test data set at two different time steps t0 and t24 . Data set provided by Department of Mathematics, Univer- sity of Rostock. ", "caption_bbox": [394, 646, 695, 694]}, {"image_id": 4, "file_name": "136_04.png", "page": 5, "dpi": 300, "bbox": [98, 369, 401, 638], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Critical points and stream lines of f at the time steps t0 and t24 . ", "caption_bbox": [63, 637, 364, 671]}, {"image_id": 5, "file_name": "136_05.png", "page": 5, "dpi": 300, "bbox": [123, 88, 396, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Critical points and stream lines of v at the time steps t0 and t24 . ", "caption_bbox": [63, 328, 364, 362]}, {"image_id": 6, "file_name": "136_06.png", "page": 9, "dpi": 300, "bbox": [413, 88, 732, 385], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Zoom into the test data set.", "caption_bbox": [448, 384, 643, 402]}, {"image_id": 7, "file_name": "136_07.png", "page": 9, "dpi": 300, "bbox": [98, 430, 401, 778], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Critical points and stream lines of f at the time steps t0 and t24 . ", "caption_bbox": [63, 777, 364, 811]}, {"image_id": 8, "file_name": "136_08.png", "page": 9, "dpi": 300, "bbox": [125, 88, 415, 389], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Critical points and stream lines of f at the time steps t0 and t24 . ", "caption_bbox": [63, 388, 364, 422]}], "137": [{"image_id": 0, "file_name": "137_00.png", "page": 2, "dpi": 300, "bbox": [363, 524, 662, 630], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The movement of a sphere-like object can be de- scribed as a rigid rotation (left) or as a deformation (right) of the sphere. If only the movement of mass is known, then an additional constraint over the vector field is need to dis- tinguish between these movements. ", "caption_bbox": [395, 632, 696, 710]}, {"image_id": 1, "file_name": "137_01.png", "page": 3, "dpi": 300, "bbox": [106, 215, 393, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Computing M~V? (~x,t + \u2206t) : \u03a6 is applied to a mass distribution at time t (shown in yellow, left) to compute a new mass distribution at time t + \u2206 (right). Black solid lines indi- cate nodes in the velocity grid G. Blue dashed lines indicate voxels in M. Red dots indicate the sampling pattern in each voxel. ", "caption_bbox": [63, 366, 364, 460]}, {"image_id": 2, "file_name": "137_02.png", "page": 3, "dpi": 300, "bbox": [363, 608, 709, 775], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Improving the fit of a particular node using hill climbing. ", "caption_bbox": [395, 782, 696, 815]}, {"image_id": 3, "file_name": "137_03.png", "page": 6, "dpi": 300, "bbox": [113, 326, 718, 637], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The origin of dense chromatin regions: The data at the initial time step is shown using volume rendering. The 21 highest local maximum values in the final time of the data are chosen as seed points for the particle paths. Paths are traced backward in time. End points of the particle path are drawn as small green spheres. ", "caption_bbox": [63, 644, 695, 692]}, {"image_id": 4, "file_name": "137_04.png", "page": 6, "dpi": 300, "bbox": [99, 52, 732, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The process of decondensation visualized using volume rendering (top) and particle paths (bottom). The red/white segments in the particle paths show the dynamics of the data movement. Seed points are drawn as small green spheres. ", "caption_bbox": [63, 273, 695, 306]}, {"image_id": 5, "file_name": "137_05.png", "page": 7, "dpi": 300, "bbox": [113, 52, 717, 390], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The movement of two chromatin regions: stream tubes show movement in two different regions. The shape of checker- board cells in each stream tube show the dynamics of the data movement. The shape of stream tube can be compared to get insight to the dynamics of two different chromatin regions. ", "caption_bbox": [63, 397, 695, 445]}, {"image_id": 6, "file_name": "137_06.png", "page": 9, "dpi": 300, "bbox": [177, 632, 653, 880], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The movement of two chromatin regions: stream tubes show movement in two different regions. The shape of checker- board cells in each stream tube show the dynamics of the data movement. ", "caption_bbox": [63, 887, 695, 920]}, {"image_id": 7, "file_name": "137_07.png", "page": 9, "dpi": 300, "bbox": [177, 326, 654, 572], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The origin of dense chromatin. The data at the first time step is shown using volume rendering. Starting points of the particle path are drawn as small green spheres. ", "caption_bbox": [63, 579, 695, 612]}, {"image_id": 8, "file_name": "137_08.png", "page": 9, "dpi": 300, "bbox": [99, 75, 732, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The process of decondensation visualized using volume rendering (top) and particle paths (bottom). Seed points are drawn as small green spheres. ", "caption_bbox": [63, 273, 695, 306]}], "138": [{"image_id": 0, "file_name": "138_00.png", "page": 8, "dpi": 300, "bbox": [96, 318, 733, 517], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Path tracing algorithm on the hemisphere dataset. Rays are going towards the hemispherical cap (from right to left). Most traces converge at the rear end of the cylinder. It reveals the compressing directions in this dataset. Note how the tubes gets thicker when they approach the hemisphere cap and then get thinner as they reach the top of the cylinder. This shows that the compressing forces are larger in the vertical direction near the cap area. We also note that in the area where the tubes are converging near the rear end, the tubes are almost flat, which illustrates higher anisotropy. ", "caption_bbox": [63, 516, 696, 594]}, {"image_id": 1, "file_name": "138_01.png", "page": 8, "dpi": 300, "bbox": [107, 88, 711, 283], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Path tracing algorithm on the point load dataset. Rays are cast from different directions. On the left, rays are cast from the top; in the middle, rays are cast from the bottom; and in the right, rays are cast from the right. ", "caption_bbox": [63, 282, 696, 314]}, {"image_id": 2, "file_name": "138_02.png", "page": 8, "dpi": 300, "bbox": [98, 595, 733, 811], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Path tracing algorithm on hemisphere dataset using large ray flexibility. Different view points are used to present the deformed rays. The pattern of the rays is very close to Hesselink\u2019s result on the same viscous stress tensor data set. They both get across the hemispherical cap and converge at the other end in a similar way. ", "caption_bbox": [63, 810, 696, 858]}, {"image_id": 3, "file_name": "138_03.png", "page": 9, "dpi": 300, "bbox": [518, 570, 721, 861], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Lens simulation algorithm on point load data.", "caption_bbox": [236, 811, 519, 829]}, {"image_id": 4, "file_name": "138_04.png", "page": 9, "dpi": 300, "bbox": [108, 88, 728, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Photon mapping algorithm on point load data.", "caption_bbox": [234, 288, 520, 306]}, {"image_id": 5, "file_name": "138_05.png", "page": 9, "dpi": 300, "bbox": [98, 307, 718, 554], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Photon mapping algorithm on hemisphere data.", "caption_bbox": [231, 553, 523, 571]}, {"image_id": 6, "file_name": "138_06.png", "page": 10, "dpi": 300, "bbox": [521, 88, 733, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Lens simulation algorithm on hemisphere data.", "caption_bbox": [233, 282, 522, 300]}, {"image_id": 7, "file_name": "138_07.png", "page": 11, "dpi": 300, "bbox": [96, 88, 735, 259], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Path tracing algorithm on the hemisphere dataset.", "caption_bbox": [226, 258, 529, 276]}, {"image_id": 8, "file_name": "138_08.png", "page": 11, "dpi": 300, "bbox": [131, 277, 691, 521], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Path tracing algorithm on hemisphere dataset using large ray flexibility.", "caption_bbox": [172, 520, 584, 538]}, {"image_id": 9, "file_name": "138_09.png", "page": 11, "dpi": 300, "bbox": [522, 537, 718, 841], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Photon mapping algorithm on hemisphere data.", "caption_bbox": [231, 791, 523, 809]}], "139": [{"image_id": 0, "file_name": "139_00.png", "page": 2, "dpi": 300, "bbox": [130, 88, 691, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Advantage of using a higher-order element representation. Left image shows original piecewise linear data. Middle image shows linear approximation using one linear element. Right image shows quadratic approximation using one quadratic element. Gray area represents approximation error. ", "caption_bbox": [63, 222, 695, 270]}, {"image_id": 1, "file_name": "139_01.png", "page": 3, "dpi": 300, "bbox": [363, 90, 396, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Two contour surfaces inside a quadratic tetrahe- dron. Dark dots are the contour intersections with the edges. Dark curves are the contour intersections with the faces. There are two groups of three curves that bound two inde- pendent surfaces of the contour. ", "caption_bbox": [63, 247, 364, 325]}, {"image_id": 2, "file_name": "139_02.png", "page": 4, "dpi": 300, "bbox": [363, 88, 398, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Contour surface bounded by six face-intersection curves. Dark dots are the endpoints of the curves. ", "caption_bbox": [63, 239, 364, 272]}, {"image_id": 3, "file_name": "139_03.png", "page": 5, "dpi": 300, "bbox": [133, 88, 693, 185], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Constructing four triangular patches from six face-intersection curves. Circles are endpoints and squares are center control points of face-intersection curves. Dark lines are chosen diagonal for splits. Dark squares are control points used to determine the center control point for each diagonal. An original polygon is shown in image A. Image B shows the first diagonal selection. Image C shows the diagonal selection for the left half. Image D shows the diagonal selection for the right half. ", "caption_bbox": [63, 184, 695, 247]}, {"image_id": 4, "file_name": "139_04.png", "page": 6, "dpi": 300, "bbox": [695, 280, 732, 312], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Relationship between control net of Q(u) and control net of C(u). Left image shows rational-quadratic curve Q(u) in parameter space. Middle image shows control net of Q(u) transformed into physical space. Right image shows rational-quartic curve C(u) resulting from transforming Q(u) into physical space. It turns out that l 1 = d1 , r1 = d3 , T(p0 ) = d0 , and T(p2 ) = d4 . ", "caption_bbox": [63, 239, 696, 289]}, {"image_id": 5, "file_name": "139_05.png", "page": 7, "dpi": 300, "bbox": [389, 907, 731, 1018], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Enlargement of rational-quartic contour surface extracted from twisted mesh shown in Figure 8 (right); 320 curved-quadratic tetrahedra. ", "caption_bbox": [394, 860, 694, 908]}, {"image_id": 6, "file_name": "139_06.png", "page": 7, "dpi": 300, "bbox": [361, 592, 731, 860], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Enlargement of rational-quadratic contour sur- face extracted from un-twisted mesh shown in Figure 8 (left); 320 quadratic tetrahedra. ", "caption_bbox": [394, 545, 694, 593]}, {"image_id": 7, "file_name": "139_07.png", "page": 7, "dpi": 300, "bbox": [120, 285, 733, 545], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Left image shows \u201cun-twisted\u201d mesh containing only linear-edge quadratic tetrahedra. Right image shows twisted mesh containing curved-quadratic tetrahedra. The mesh is twisted by 90\u25e6 comparing top and bottom faces of entire mesh configuration. ", "caption_bbox": [394, 208, 694, 286]}, {"image_id": 8, "file_name": "139_08.png", "page": 8, "dpi": 300, "bbox": [96, 394, 398, 708], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Rational-quartic contour surface extracted from 15918 curved-quadratic tetrahedra. ", "caption_bbox": [63, 707, 364, 740]}, {"image_id": 9, "file_name": "139_09.png", "page": 8, "dpi": 300, "bbox": [124, 88, 398, 346], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Rational-quadratic contour surface extracted from un-twisted mesh consisting of 15918 quadratic tetra- hedra. ", "caption_bbox": [63, 345, 364, 393]}, {"image_id": 10, "file_name": "139_10.png", "page": 11, "dpi": 300, "bbox": [391, 892, 694, 1018], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Rational-quartic contour surface extracted from 15918 curved-quadratic tetrahedra. ", "caption_bbox": [396, 850, 656, 880]}, {"image_id": 11, "file_name": "139_11.png", "page": 11, "dpi": 300, "bbox": [139, 892, 397, 932], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Rational-quadratic contour surface extracted from un-twisted mesh consisting of 15918 quadratic tetra- hedra. ", "caption_bbox": [104, 850, 364, 893]}, {"image_id": 12, "file_name": "139_12.png", "page": 11, "dpi": 300, "bbox": [655, 347, 694, 648], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Enlargement of rational-quartic contour surface extracted from twisted mesh shown in Figure 8 (right); 320 curved-quadratic tetrahedra. ", "caption_bbox": [396, 578, 656, 621]}, {"image_id": 13, "file_name": "139_13.png", "page": 11, "dpi": 300, "bbox": [147, 349, 397, 579], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Enlargement of rational-quadratic contour sur- face extracted from un-twisted mesh shown in Figure 8 (left); 320 quadratic tetrahedra. ", "caption_bbox": [104, 578, 364, 621]}, {"image_id": 14, "file_name": "139_14.png", "page": 11, "dpi": 300, "bbox": [205, 88, 627, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Left image shows \u201cun-twisted\u201d mesh containing only linear-edge quadratic tetrahedra. Right image shows twisted mesh containing curved-quadratic tetrahedra. The mesh is twisted by 90 \u25e6 comparing top and bottom faces of entire mesh configuration. ", "caption_bbox": [112, 305, 650, 348]}], "140": [{"image_id": 0, "file_name": "140_00.png", "page": 1, "dpi": 300, "bbox": [363, 334, 733, 687], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Scattered data points pi with associated function values fi . ", "caption_bbox": [395, 694, 696, 728]}, {"image_id": 1, "file_name": "140_01.png", "page": 3, "dpi": 300, "bbox": [130, 52, 394, 259], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Adaptive clustering based on quadtree refine- ment. ", "caption_bbox": [63, 268, 364, 301]}, {"image_id": 2, "file_name": "140_02.png", "page": 4, "dpi": 300, "bbox": [111, 333, 388, 497], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Knot removal for piecewise linear representation. The left side corresponds to a zero function on an \u201cidle\u201d cluster, while the right side is treated like a domain bound- ary. ", "caption_bbox": [63, 249, 364, 312]}, {"image_id": 3, "file_name": "140_03.png", "page": 4, "dpi": 300, "bbox": [363, 52, 720, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Support and control points of \u2206F j . The lower left corner defines a domain boundary, requiring extra control points. The white clusters are \u201cidle\u201d and contain only zero control points. ", "caption_bbox": [395, 284, 696, 348]}, {"image_id": 4, "file_name": "140_04.png", "page": 4, "dpi": 300, "bbox": [363, 487, 397, 536], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Knot removal for piecewise quadratic representa- tion. The zero function on the left side is approximated such that the boundary is C 1 -continuous. ", "caption_bbox": [63, 505, 364, 553]}, {"image_id": 5, "file_name": "140_05.png", "page": 5, "dpi": 300, "bbox": [363, 52, 734, 469], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: a) Crater Lake data set, composed of 18,818 points (11.8 percent of its original size). b) Adaptive bilinear approximation. c) Adaptive biquadratic approximation. ", "caption_bbox": [395, 468, 696, 516]}, {"image_id": 6, "file_name": "140_06.png", "page": 6, "dpi": 300, "bbox": [118, 479, 713, 805], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Approximations at different levels of subdivision (biquadratic case). a-d) Levels 0-3.", "caption_bbox": [143, 815, 616, 833]}, {"image_id": 7, "file_name": "140_07.png", "page": 6, "dpi": 300, "bbox": [118, 52, 713, 402], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: a) Piecewise bilinear fit of the base level (32 \u00d7 24 clusters). b) C 0 -continuous approximation after knot removal. c) Piecewise biquadratic fit of the base level. d) C 1 -continuous approximation after knot removal. ", "caption_bbox": [63, 409, 696, 444]}, {"image_id": 8, "file_name": "140_08.png", "page": 7, "dpi": 300, "bbox": [96, 480, 390, 682], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Seattle data set, composed of 586,970 points.", "caption_bbox": [69, 689, 347, 707]}, {"image_id": 9, "file_name": "140_09.png", "page": 7, "dpi": 300, "bbox": [346, 755, 723, 935], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Adaptive bilinear approximation of Seattle data set. ", "caption_bbox": [389, 689, 686, 721]}], "141": [{"image_id": 0, "file_name": "141_00.png", "page": 2, "dpi": 300, "bbox": [143, 588, 355, 629], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: a) Skeleton; b) Centerline", "caption_bbox": [108, 574, 317, 588]}, {"image_id": 1, "file_name": "141_01.png", "page": 3, "dpi": 300, "bbox": [145, 87, 686, 216], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Centerline extraction pipeline", "caption_bbox": [264, 215, 493, 229]}, {"image_id": 2, "file_name": "141_02.png", "page": 5, "dpi": 300, "bbox": [98, 425, 733, 455], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Centerline extraction steps: detection (a,e), thinning (b,f ), reconnection (c,g), for two different detection thresholds. Ranking (d) and initial object (h) ", "caption_bbox": [63, 386, 695, 416]}, {"image_id": 3, "file_name": "141_03.png", "page": 5, "dpi": 300, "bbox": [98, 797, 398, 839], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Three-rings object (a). Centerlines: PK thining method (b), VKG thinning method (see also Sec. 4) (c), our method (d) ", "caption_bbox": [63, 753, 364, 798]}, {"image_id": 4, "file_name": "141_04.png", "page": 6, "dpi": 300, "bbox": [195, 87, 636, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Reconnection algorithm", "caption_bbox": [281, 393, 476, 407]}, {"image_id": 5, "file_name": "141_05.png", "page": 7, "dpi": 300, "bbox": [201, 87, 628, 443], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Ranking algorithm", "caption_bbox": [295, 442, 462, 456]}, {"image_id": 6, "file_name": "141_06.png", "page": 8, "dpi": 300, "bbox": [363, 215, 748, 529], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Straightened colon centerline: our method (a), VKG method (b) ", "caption_bbox": [395, 528, 696, 558]}, {"image_id": 7, "file_name": "141_07.png", "page": 8, "dpi": 300, "bbox": [98, 909, 398, 941], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: 3D skeletons (b,d,f ) and centerlines (a,c,e) of the same object, different views ", "caption_bbox": [63, 871, 364, 901]}, {"image_id": 8, "file_name": "141_08.png", "page": 9, "dpi": 300, "bbox": [103, 88, 415, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Colon centerline: VKG method (a), our method R0 = 0 (b) and R0 = 15 (c) ", "caption_bbox": [63, 299, 364, 329]}, {"image_id": 9, "file_name": "141_09.png", "page": 9, "dpi": 300, "bbox": [363, 476, 733, 866], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Additional centerline examples. Twisted object: our method (a), VKG method (b), 3D skeleton (c). Lobster, our method (d) ", "caption_bbox": [395, 432, 696, 477]}, {"image_id": 10, "file_name": "141_10.png", "page": 11, "dpi": 300, "bbox": [98, 878, 731, 910], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Centerline examples: Simple object centerline and skeleton (a,b). Straightened and original colon (c,d). Frog duodenum (e). Spiral (h). Cow centerline and skeleton (f,g,i-l). Lobster (m) ", "caption_bbox": [63, 840, 695, 870]}], "142": [{"image_id": 0, "file_name": "142_00.png", "page": 2, "dpi": 300, "bbox": [121, 52, 707, 364], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Vector field visualizations synthesized using MRF texture synthesis with a gradient example texture that is rotated and scaled according to the vector field. The two images use different sample textures, which are characterized by lines of different orientations. ", "caption_bbox": [63, 371, 695, 419]}, {"image_id": 1, "file_name": "142_01.png", "page": 3, "dpi": 300, "bbox": [363, 52, 699, 435], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Pyramid levels for the synthesis process of the im- age in Figure 1 ", "caption_bbox": [395, 437, 696, 470]}, {"image_id": 2, "file_name": "142_02.png", "page": 4, "dpi": 300, "bbox": [123, 52, 398, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Examples of sample patterns for imput images.", "caption_bbox": [69, 270, 356, 288]}, {"image_id": 3, "file_name": "142_03.png", "page": 4, "dpi": 300, "bbox": [363, 434, 401, 523], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Scaled and rotated sample input images.", "caption_bbox": [418, 417, 673, 435]}, {"image_id": 4, "file_name": "142_04.png", "page": 5, "dpi": 300, "bbox": [111, 413, 396, 588], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Different parts of the vector field visualized using the same output resolution. ", "caption_bbox": [395, 497, 696, 530]}, {"image_id": 5, "file_name": "142_05.png", "page": 5, "dpi": 300, "bbox": [109, 52, 427, 352], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Table of variables", "caption_bbox": [477, 293, 614, 311]}, {"image_id": 6, "file_name": "142_06.png", "page": 6, "dpi": 300, "bbox": [222, 52, 609, 460], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Examples of synthetized vector fields.", "caption_bbox": [259, 467, 499, 485]}, {"image_id": 7, "file_name": "142_07.png", "page": 6, "dpi": 300, "bbox": [156, 505, 675, 764], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Synthetized outputs: two vector fields are obtained both usind two sets of different input sample images chosen from Figure 3 ", "caption_bbox": [63, 771, 695, 804]}, {"image_id": 8, "file_name": "142_08.png", "page": 7, "dpi": 300, "bbox": [98, 52, 726, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Using a small scale example texture might lead to aliasing artifacts in the synthesized visualization. ", "caption_bbox": [395, 371, 696, 404]}], "143": [{"image_id": 0, "file_name": "143_00.png", "page": 2, "dpi": 300, "bbox": [108, 52, 394, 366], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Topological boundaries of the tornado data set. The boundary of the tornado data set is shown, where red signi- fies inflow portions of the boundary and green outflow. Illuminated streamlines22 are used to show the flow and structure of the tor- nado\u2019s core (from Mahrous et al.12 ). Data set courtesy of LLNL2 . ", "caption_bbox": [63, 372, 364, 444]}, {"image_id": 1, "file_name": "143_01.png", "page": 3, "dpi": 300, "bbox": [363, 52, 694, 451], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Sampling with streamlines and tabulating their values. Figure (a) shows a close-up view of a cell in a 2D data set. The Voronoi cell decomposition is shown to illustrate tabulation assign- ments (e.g. all portions of the streamlines that are in the red sec- tion of the cell contribute to the red vertex). The accumulated prop- erties are also shown, on a per-vertex basis. Thus the red vertex has 100% contribution from the green streamlines, the yellow ver- tex has 100% contribution from the blue streamlines and the orange vertex has 70% green contribution and 30% blue contribution. Fig- ure (b) shows the cell embedded in the data set. Notice the green streamlines accumulate their properties from the green section of the boundary, while the blue streamlines are accumulating their prop- erties from an internal \u201corbit.\u201d ", "caption_bbox": [395, 455, 696, 638]}, {"image_id": 2, "file_name": "143_02.png", "page": 5, "dpi": 300, "bbox": [180, 245, 317, 437], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Property space three-simplex. The \u201cproperty space\u201d three-simplex in the case m = 4 (four prop- erties). The figure illustrates a three-dimensional projection of the three-simplex with an embedded tetrahedron. ", "caption_bbox": [63, 445, 364, 503]}, {"image_id": 3, "file_name": "143_03.png", "page": 6, "dpi": 300, "bbox": [127, 52, 394, 336], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Locking cells that initially contain a property. This boundary cell\u2019s boundary face has a specific property P. The green vectors indicate outflow, and the red vectors indicate in- flow. Thus, the only outflow location is on the boundary face and a streamline entering this cell has only one possible exit location. The cell can therefore be \u201clocked\u201d with the property P. ", "caption_bbox": [63, 342, 364, 428]}, {"image_id": 4, "file_name": "143_04.png", "page": 9, "dpi": 300, "bbox": [154, 427, 680, 681], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Cell-locking in tornado data set. Figures (a) and (b) show the boundary of the locked outflow cells in green. All tetrahedral cells that lie between the green surface and the data set boundary are locked. ", "caption_bbox": [63, 685, 695, 730]}, {"image_id": 5, "file_name": "143_05.png", "page": 9, "dpi": 300, "bbox": [121, 52, 721, 279], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Tornado separatrices at different sampling intervals. Figure (a) shows the tornado data set uniformly sampled with several million uniform samples. Figure (b) shows the tornado data set with 32,000 uniform samples. Figure (c) shows the tornado data set with 1,800 adaptive samples. During creation of the separatrices a property is artificially assigned to a vertex when it remains un-sampled. Techniques such as interpolation with neighbor quantities can be employed. However, in some cases artifacts are still produced, such as those seen in (b). ", "caption_bbox": [63, 284, 695, 356]}, {"image_id": 6, "file_name": "143_06.png", "page": 10, "dpi": 300, "bbox": [119, 413, 733, 612], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Separatrices found using inflow/outflow enhancement in the critical point data set. Streamlines can have one of three different entrance properties, however, they all have the same exit property. Figures (a) and (b) show streamlines in addition to the separatrices. The critical point is located on the shared diagonal of the tetrahedra outlined in black. Figure (c) shows the separatrices that would not have been generated by the original algorithm. ", "caption_bbox": [63, 617, 695, 675]}, {"image_id": 7, "file_name": "143_07.png", "page": 10, "dpi": 300, "bbox": [133, 52, 698, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Separatrices found using inflow/outflow improvement in tornado data set. Figure (a) shows the topological separation of the boundary of the tornado data set. Figure (b) shows the topological separation generated by the original algorithm. Figure (c) shows the topological separatrices generated using the inflow/outflow improvement. This improvement separates regions of flow that have distinct entrance/exit conditions, which explains the existence of the \u201cpockets\u201d of separated flow in the corners of the data set. ", "caption_bbox": [63, 277, 695, 349]}, {"image_id": 8, "file_name": "143_08.png", "page": 11, "dpi": 300, "bbox": [695, 785, 733, 883], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Separatrices found using inflow/outflow enhance- ment in the critical point data set. ", "caption_bbox": [395, 781, 696, 812]}, {"image_id": 9, "file_name": "143_09.png", "page": 11, "dpi": 300, "bbox": [137, 52, 396, 781], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Separatrices found using inflow/outflow improvement in tornado data set. ", "caption_bbox": [63, 785, 364, 816]}], "144": [{"image_id": 0, "file_name": "144_00.png", "page": 3, "dpi": 300, "bbox": [366, 444, 725, 822], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Pseudo-code for Data Structures", "caption_bbox": [395, 821, 590, 836]}, {"image_id": 1, "file_name": "144_01.png", "page": 4, "dpi": 300, "bbox": [366, 146, 727, 609], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Polyline over a quad node with just a 9x9 block of vertices in RQT triangulation. ", "caption_bbox": [395, 608, 670, 637]}, {"image_id": 2, "file_name": "144_02.png", "page": 6, "dpi": 300, "bbox": [123, 850, 398, 887], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Example of Vertex Borrowing. Gray meshes are quadnodes with no loaded vertex data. Black meshes are quadnodes with loaded vertex data. The outlined sub-regions of AQ are the borrowed vertex data regions borrowed by ", "caption_bbox": [80, 797, 367, 851]}, {"image_id": 3, "file_name": "144_03.png", "page": 10, "dpi": 300, "bbox": [184, 87, 395, 512], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A-E illustrate the partial construction of a BLG- tree. The trees in B-E show all nodes added at successive tree levels. The polyline to the right of each tree illustrates the polyline geometry related to the newest tree node. Dashed lines are the spanning line segment being refined. Thick lines are the polyline refinement. ", "caption_bbox": [395, 76, 682, 156]}, {"image_id": 4, "file_name": "144_04.png", "page": 10, "dpi": 300, "bbox": [123, 547, 359, 870], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Triangle Clippings of a single segment quad clipping assuming a 9x9 vertex quad. ", "caption_bbox": [80, 511, 331, 540]}, {"image_id": 5, "file_name": "144_05.png", "page": 10, "dpi": 300, "bbox": [402, 839, 727, 1012], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Georgia County Borders (240K points) and North & South Korea borders (10K points). ", "caption_bbox": [395, 803, 679, 832]}], "145": [{"image_id": 0, "file_name": "145_00.png", "page": 2, "dpi": 300, "bbox": [362, 109, 399, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Two-phase splatting for magnification=2: (a) splatting of a voxel into a (low-resolution) grid at volume resolution, (b) post-convolution of the low-resolution grid samples to give the high resolution grid samples. ", "caption_bbox": [398, 270, 694, 332]}, {"image_id": 1, "file_name": "145_01.png", "page": 3, "dpi": 300, "bbox": [363, 109, 399, 658], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: PCVR in frequency space. Step 1: (a) reconstruc- tion of the volume with bandwidth fv and (b) sampling it into a slice at equal bandwidth fs=fv; Step 2: (c) reconstruction of the slice via convolution with a filter with bandwidth fs and (d) resampling it into the desired high-resolution grid. ", "caption_bbox": [398, 576, 700, 653]}, {"image_id": 2, "file_name": "145_02.png", "page": 4, "dpi": 300, "bbox": [362, 698, 752, 830], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) Cubic cartesian (CC) cell in frequency space, (b) Face centered cartesian (FCC) cell in frequency space. The dot labeled \u20181\u2019 marks the location of the main spec- trum. The dots labeled \u20182\u2019 mark the 1-neighbors (the neigh- bors with distance=1), the dots labeled \u20182\u2019 mark the 2 - neighbors, while the dots labeled \u20183\u2019 mark the 3 -neigh- bors. ", "caption_bbox": [398, 829, 694, 937]}, {"image_id": 3, "file_name": "145_03.png", "page": 5, "dpi": 300, "bbox": [362, 109, 746, 509], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Overview of the PCVR in our splatting pipeline: (a) splatting of a voxel into a (low-resolution) grid at vol- ume resolution, (b) post-convolution of the low-resolution grid samples to give the high resolution grid samples, using Gaussian kernel, (c) using a linear bilinear filter (shown for 1D) ", "caption_bbox": [404, 509, 701, 601]}, {"image_id": 4, "file_name": "145_04.png", "page": 6, "dpi": 300, "bbox": [98, 667, 752, 913], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Impact of PCVR on our splating pipeline for: (a) Full Volume rendering, (b) X-Ray Splatting. The graphs show time to render in seconds for scales of 1X to 8X. ", "caption_bbox": [58, 912, 696, 943]}], "146": [{"image_id": 0, "file_name": "146_00.png", "page": 2, "dpi": 300, "bbox": [363, 322, 733, 492], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Using slabs instead of slices for pre-integrated volume rendering as introduced by Engel et al.6 . The scalar values at the entry and the exit point of the viewing ray are denoted by S f and Sb , respectively. The thickness of the slab is denoted by l. The dark blue region remains after volumet- ric clipping. For this purpose, S f has to be replaced by S0f . ", "caption_bbox": [395, 491, 696, 588]}, {"image_id": 1, "file_name": "146_01.png", "page": 3, "dpi": 300, "bbox": [364, 270, 396, 463], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparison of volumetric clipping quality. Left: Naive approach. Right: Accurate method. ", "caption_bbox": [395, 406, 696, 439]}, {"image_id": 2, "file_name": "146_02.png", "page": 4, "dpi": 300, "bbox": [363, 88, 733, 391], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A leave of the Bonsai20 . The degradation of ren- dering quality is displayed from top left to bottom right: with pre-integration and 4-times over-sampling, with pre- integration and 2-times over-sampling, with pre-integration and without over-sampling, and neither with pre-integration nor over-sampling. In the bottom right corner of each image the zoom of a critical region is depicted which should show a smooth color transition. Due to slicing artifacts in the bot- tom right image artificial bands are visible. These remain even with 2-times oversampling but almost disappear with 4-times oversampling. ", "caption_bbox": [395, 390, 696, 560]}, {"image_id": 3, "file_name": "146_03.png", "page": 5, "dpi": 300, "bbox": [362, 568, 732, 603], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Quality comparison between slicing with pre- integration and 4-times over-sampling (left) and ray cast- ing with full floating point accuracy and adaptive pre- integration (right). On the left highly transparent areas are neglected due to 8 bit frame buffer quantization. ", "caption_bbox": [394, 491, 694, 569]}, {"image_id": 4, "file_name": "146_04.png", "page": 5, "dpi": 300, "bbox": [98, 169, 396, 363], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Ray casting scheme: All viewing rays are pro- cessed simultaneously. For each integration step the pre- integration technique is used. After each step the colors are blended and the ray parameter corresponding to the next sampling position is written back into alternating render tar- gets (ping-pong rendering). ", "caption_bbox": [63, 362, 364, 455]}, {"image_id": 5, "file_name": "146_05.png", "page": 5, "dpi": 300, "bbox": [363, 396, 401, 475], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Number of sampling steps for different transfer functions: On the left the original image is depicted and at the center the corresponding number of sampling steps is shown (White corresponds to 512 samples). On the right a more opaque transfer function was chosen to illustrate the impact of early ray termination. ", "caption_bbox": [395, 208, 695, 301]}], "147": [{"image_id": 0, "file_name": "147_00.png", "page": 2, "dpi": 300, "bbox": [102, 88, 731, 421], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Flexible Feature Specification: simulation data of a catalytic converter is shown, two features have been specified", "caption_bbox": [63, 420, 695, 438]}, {"image_id": 1, "file_name": "147_01.png", "page": 3, "dpi": 300, "bbox": [98, 526, 394, 644], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Feature definition language: sketch of its structure.", "caption_bbox": [63, 643, 364, 661]}, {"image_id": 2, "file_name": "147_02.png", "page": 5, "dpi": 300, "bbox": [117, 88, 714, 477], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Interactive feature specification and refinement: (a)-(c): first step: defining backflow region in a catalytic converter (see also Fig. 1) in a scatterplot view (a) by selecting negative x-flow values, direct linking to a second scatterplot view (b) and the 3D view (c). (d)-(f): second step: AND-refinement with a new selection in the second scatterplot view (e), back linking of the interaction via feedback visualization (color of points according to newly calculated DOI values) to the first scatterplot view (d). Now only the backflow region is selected, that exhibits general velocity above a specified threshold (f). ", "caption_bbox": [63, 476, 696, 554]}, {"image_id": 3, "file_name": "147_03.png", "page": 7, "dpi": 300, "bbox": [98, 88, 734, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Air-Flow around a moving car: After loading the data set, an empty feature set is created, and the spatial layout of", "caption_bbox": [63, 376, 696, 394]}, {"image_id": 4, "file_name": "147_04.png", "page": 8, "dpi": 300, "bbox": [363, 546, 733, 801], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Step 2 of analysis: AND-refinement, restricting feat. spec. to high viscosity values in the second scatterplot view. Only features behind the car are part of focus now. ", "caption_bbox": [395, 800, 696, 848]}, {"image_id": 5, "file_name": "147_05.png", "page": 8, "dpi": 300, "bbox": [98, 88, 734, 480], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: First step of analysis (non-horizontal slow flow): a tree viewer showing the current feature specification in the upper", "caption_bbox": [63, 479, 695, 497]}, {"image_id": 6, "file_name": "147_06.png", "page": 9, "dpi": 300, "bbox": [98, 88, 734, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Step 3 of analysis: another AND refinement, further restricting to high values of turb. kinetic energy, performed in", "caption_bbox": [63, 360, 696, 378]}, {"image_id": 7, "file_name": "147_07.png", "page": 10, "dpi": 300, "bbox": [98, 276, 401, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Step 5 of analysis: interactive probing of V- velocity reveals different behavior of vortical structures, only downfacing parts are shown here. ", "caption_bbox": [63, 229, 364, 277]}, {"image_id": 8, "file_name": "147_08.png", "page": 11, "dpi": 300, "bbox": [98, 88, 734, 887], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Two examples for feature-based flow visualization using our framework for interactive feature specification and four", "caption_bbox": [63, 886, 695, 904]}], "148": [{"image_id": 0, "file_name": "148_00.png", "page": 1, "dpi": 300, "bbox": [424, 308, 733, 725], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Boundary of brain in 2D image slice.", "caption_bbox": [426, 724, 664, 742]}, {"image_id": 1, "file_name": "148_01.png", "page": 3, "dpi": 300, "bbox": [114, 94, 716, 390], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Processing pipeline from a volume data set to a segmented and topologically analyzed isosurface.", "caption_bbox": [109, 389, 649, 407]}, {"image_id": 2, "file_name": "148_02.png", "page": 4, "dpi": 300, "bbox": [364, 767, 401, 956], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Removal of isolated components due to noise.", "caption_bbox": [405, 910, 686, 928]}, {"image_id": 3, "file_name": "148_03.png", "page": 4, "dpi": 300, "bbox": [364, 372, 396, 670], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Matching of structures as seen in original 2D MRI slices and extracted isosurfaces. ", "caption_bbox": [395, 613, 696, 646]}, {"image_id": 4, "file_name": "148_04.png", "page": 4, "dpi": 300, "bbox": [363, 94, 726, 225], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Isosurface without and with smoothing original data. ", "caption_bbox": [395, 224, 696, 257]}, {"image_id": 5, "file_name": "148_05.png", "page": 5, "dpi": 300, "bbox": [363, 273, 733, 441], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Modification of mesh in neighborhood of col- lapsed edge. ", "caption_bbox": [395, 440, 696, 473]}, {"image_id": 6, "file_name": "148_06.png", "page": 5, "dpi": 300, "bbox": [302, 621, 401, 731], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Multiresolution mapping.", "caption_bbox": [123, 682, 303, 700]}, {"image_id": 7, "file_name": "148_07.png", "page": 5, "dpi": 300, "bbox": [363, 819, 705, 866], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Multiresolution surface representation.", "caption_bbox": [421, 802, 669, 820]}, {"image_id": 8, "file_name": "148_08.png", "page": 6, "dpi": 300, "bbox": [363, 94, 711, 196], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Parameters used by mean curvature operator.", "caption_bbox": [402, 195, 689, 213]}, {"image_id": 9, "file_name": "148_09.png", "page": 6, "dpi": 300, "bbox": [430, 629, 732, 660], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Exploiting the mean curvature operator to dis- tinguish between convex and concave regions. ", "caption_bbox": [395, 592, 696, 625]}, {"image_id": 10, "file_name": "148_10.png", "page": 7, "dpi": 300, "bbox": [363, 486, 733, 667], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Topology graphs for different levels of detail.", "caption_bbox": [403, 666, 687, 684]}, {"image_id": 11, "file_name": "148_11.png", "page": 8, "dpi": 300, "bbox": [364, 460, 404, 663], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Surface segmentation at different resolutions.", "caption_bbox": [403, 609, 688, 627]}, {"image_id": 12, "file_name": "148_12.png", "page": 8, "dpi": 300, "bbox": [103, 94, 724, 424], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Classifying regions based on discrete curvature estimations.", "caption_bbox": [200, 423, 559, 441]}, {"image_id": 13, "file_name": "148_13.png", "page": 9, "dpi": 300, "bbox": [132, 94, 699, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Surface segmentations and associated topology graphs for four different human brain data sets.", "caption_bbox": [111, 379, 647, 397]}], "149": [{"image_id": 0, "file_name": "149_00.png", "page": 3, "dpi": 300, "bbox": [431, 376, 735, 480], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Skip List", "caption_bbox": [497, 487, 594, 505]}, {"image_id": 1, "file_name": "149_01.png", "page": 4, "dpi": 300, "bbox": [424, 52, 734, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Cell Merging", "caption_bbox": [485, 276, 605, 294]}, {"image_id": 2, "file_name": "149_02.png", "page": 5, "dpi": 300, "bbox": [364, 671, 396, 733], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Retriangulating the original triangle XYZ to get the new triangles ", "caption_bbox": [395, 684, 695, 717]}, {"image_id": 3, "file_name": "149_03.png", "page": 9, "dpi": 300, "bbox": [106, 654, 780, 828], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Change in the number of triangles as the error threshold changes (a) No error: 740,249 triangles (b) 0.3% error: 645,153 triangles (c) 0.8% error: 536,856 triangles (d) 1.5% error: 80,197 triangles ", "caption_bbox": [43, 834, 675, 882]}, {"image_id": 4, "file_name": "149_04.png", "page": 9, "dpi": 300, "bbox": [106, 358, 714, 588], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Red marks the places where the isosurface changes in topology after a small change to the isovalue for (a) A RADMRI isosurface and (b) Boston Teapot isosurface ", "caption_bbox": [43, 595, 675, 628]}, {"image_id": 5, "file_name": "149_05.png", "page": 9, "dpi": 300, "bbox": [106, 52, 714, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) A RADMRI isosurface (b) A Bluntfin isosurface", "caption_bbox": [206, 312, 514, 330]}], "150": [{"image_id": 0, "file_name": "150_00.png", "page": 4, "dpi": 300, "bbox": [122, 304, 375, 543], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The spherical coordinate system.", "caption_bbox": [104, 542, 321, 560]}, {"image_id": 1, "file_name": "150_01.png", "page": 4, "dpi": 300, "bbox": [113, 88, 395, 269], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A 2D example of two partition methods.", "caption_bbox": [87, 268, 339, 286]}, {"image_id": 2, "file_name": "150_02.png", "page": 4, "dpi": 300, "bbox": [338, 279, 731, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An example of 2D spherical partition and its bi- nary tree. ", "caption_bbox": [394, 246, 694, 278]}, {"image_id": 3, "file_name": "150_03.png", "page": 5, "dpi": 300, "bbox": [429, 285, 732, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A 2D example of front and back layer traversal: the increasing order of the numbers represents the traversal order. ", "caption_bbox": [394, 238, 694, 286]}, {"image_id": 4, "file_name": "150_04.png", "page": 5, "dpi": 300, "bbox": [144, 88, 395, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A 2D example of the layer traversal: the increas- ing order of the numbers represents the traversal order. ", "caption_bbox": [63, 313, 364, 346]}, {"image_id": 5, "file_name": "150_05.png", "page": 6, "dpi": 300, "bbox": [98, 475, 398, 508], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A 2D example of front-to-back traversal of the blocks in the front sector: the increasing order of the num- bers represents the traversal order. ", "caption_bbox": [63, 428, 363, 476]}, {"image_id": 6, "file_name": "150_06.png", "page": 6, "dpi": 300, "bbox": [119, 88, 398, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A 2D example of sector traversal in a front layer: the increasing order of the numbers represents the traversal order. ", "caption_bbox": [63, 251, 363, 299]}, {"image_id": 7, "file_name": "150_07.png", "page": 10, "dpi": 300, "bbox": [98, 290, 731, 787], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The images generated for the Leg dataset after 20 percent, 35 percent and 50 percent of total isosurface blocks are queried during the occluder selection stage. (a)-(c) show the corresponding images generated by the spherical partition algorithm; (d)-(f) show the corresponding images generated by the octree partition algorithm. (g) shows the final image of the isosurface. ", "caption_bbox": [63, 786, 695, 849]}, {"image_id": 8, "file_name": "150_08.png", "page": 10, "dpi": 300, "bbox": [195, 88, 638, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The occluder constructed by different algorithms after 50 percent of the isosurface blocks were queried. (a) The octree partition algorithm; 2441 visible blocks are found. (b) The spherical partition algorithm; 6403 visible blocks are found. (c) The final image of the isosurface. 6620 visible blocks. ", "caption_bbox": [63, 238, 695, 286]}], "151": [{"image_id": 0, "file_name": "151_00.png", "page": 2, "dpi": 300, "bbox": [109, 113, 725, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A CT scan of engine rendered by various methods: (a) conventional volume rendering, (b) iso-surface with NPR illustration, (c) another iso-surface with NPR illustration, (d) mixture of iso-surfaces in (b) and (c) with volume rendering (a), (e) similar image as (d) with iso-surface illustration enhanced by PIP to emulate felt-tip pen drawing style. ", "caption_bbox": [98, 288, 731, 332]}, {"image_id": 1, "file_name": "151_01.png", "page": 4, "dpi": 300, "bbox": [112, 112, 387, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of rendering pipeline.", "caption_bbox": [142, 544, 355, 557]}, {"image_id": 2, "file_name": "151_02.png", "page": 5, "dpi": 300, "bbox": [181, 116, 645, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Surface illustration: (a) profiles only (filter-detected features), (b) with surface hatching, (b) with surface hatching and lighting effects. ", "caption_bbox": [98, 274, 731, 302]}, {"image_id": 3, "file_name": "151_03.png", "page": 5, "dpi": 300, "bbox": [459, 327, 760, 482], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Three isosurfaces (encoded by red, green, and blue colors in electronic version); (b) mixture of surfaces and volume. ", "caption_bbox": [430, 491, 731, 535]}, {"image_id": 4, "file_name": "151_04.png", "page": 5, "dpi": 300, "bbox": [454, 548, 742, 707], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Setting different global alpha \u03c1 for volume to ad- just the visibility of embedded surfaces: (a) \u03c1 = 0.25, (b) \u03c1 = 0.50. ", "caption_bbox": [430, 711, 731, 759]}, {"image_id": 5, "file_name": "151_05.png", "page": 6, "dpi": 300, "bbox": [115, 118, 385, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Silhouette width variation controlled by different constant perturbation functions: (a) P(x, y) = 1.0pixel, (b) P(x, y) = 2.0pixels. ", "caption_bbox": [98, 247, 399, 291]}, {"image_id": 6, "file_name": "151_06.png", "page": 7, "dpi": 300, "bbox": [121, 338, 378, 423], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Averaged rendering time for different volume data (Neghip(643 ), C60 (1283 ), Engine(2562 128)), Chest(2563 ). T0 is the total rendering time for each frame. T1 is the surface rendering time, T2 is the volume rendering time. N p repre- sents the number of isosurface points used. ", "caption_bbox": [98, 434, 399, 508]}, {"image_id": 7, "file_name": "151_07.png", "page": 7, "dpi": 300, "bbox": [106, 113, 730, 284], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A variety of stylization achieved by applying different perturbation patterns (top-left small texture images): (a) small \u2018dot\u2019 pattern, (b) Perlin\u2019s noise, (c) large \u2018dot\u2019 pattern, (d) irregular \u2019dot\u2019 pattern. ", "caption_bbox": [98, 293, 731, 321]}, {"image_id": 8, "file_name": "151_08.png", "page": 9, "dpi": 300, "bbox": [136, 316, 710, 644], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Surface-volume illustration of medical data: (a) NPR surface illustration of a CT scanned hand, (b) mixture of the surfaces in (a) and the corresponding volume, (c) mixture of surfaces and the foot volume, (d) NPR surface illustration of cranium, (e) mixture of the surfaces in (d) and the corresponding volume, (f) mixture of surfaces and the chest volume. ", "caption_bbox": [98, 643, 731, 687]}, {"image_id": 9, "file_name": "151_09.png", "page": 9, "dpi": 300, "bbox": [134, 104, 693, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Surface-volume illustration of simulation data: (a) Silicium grid (128 \u00d7 64 \u00d7 64), (b) Neghip, (c)Bucky ball(C60 ). Surface hatching is performed on all the illustrated surfaces except the outer layer surface in (b). Higher stroke density and shorter stroke lenghth are used in (a) compared with (b) and (c). Lighting effect is also enabled in (c). ", "caption_bbox": [98, 264, 731, 310]}], "152": [{"image_id": 0, "file_name": "152_00.png", "page": 2, "dpi": 300, "bbox": [430, 112, 732, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The cluster-space visualization process. A ran- domly chosen subset of the data is used as training data to obtain classes of different materials and the cluster centers. The cluster centers are then used to classify the whole vol- ume into classes, and the user can select classes with the interface for rendering. Further refinement of classification can also be performed by operating on the cluster space in- terface. ", "caption_bbox": [430, 352, 731, 476]}, {"image_id": 1, "file_name": "152_01.png", "page": 3, "dpi": 300, "bbox": [101, 112, 404, 493], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The cluster-space user interface. The images listed in the right column of the user interface are the classes obtained by the preprocessing step. The user is able to cre- ate visualization easily according to the classes by using per object material property widgets in the lower left. ", "caption_bbox": [98, 501, 399, 579]}, {"image_id": 2, "file_name": "152_02.png", "page": 4, "dpi": 300, "bbox": [101, 606, 407, 847], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Merging two classes. The left image shows the rendering of two similar classes and the right image is the result of rendering the merged class. ", "caption_bbox": [98, 855, 399, 903]}, {"image_id": 3, "file_name": "152_03.png", "page": 4, "dpi": 300, "bbox": [458, 112, 705, 382], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Modify the size of a class. The user is allowed to change the size of the classes. The left image is the rendered result of a class. The surface is rough and incomplete since part of the material is clustered into other classes. The right image shows the result after enlarging the class. More voxels are included and the classification is more accurate. ", "caption_bbox": [430, 389, 731, 482]}, {"image_id": 4, "file_name": "152_04.png", "page": 4, "dpi": 300, "bbox": [101, 112, 403, 476], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Splitting a class. The upper row shows the his- togram of classes and the rendered image of the class cir- cled in white, which contains two materials. The lower row shows the result after applying a split operation to the class. The class is separated in two and the rendered result of one material class is shown in the lower left. ", "caption_bbox": [98, 483, 399, 576]}, {"image_id": 5, "file_name": "152_05.png", "page": 6, "dpi": 300, "bbox": [101, 112, 404, 529], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Volume rendering results for classes of different materials in the tooth data set classified by the ISODATA technique. The histogram in the middle is shown with dif- ferent colors representing different classes. It illustrates that the classes are well classified according to the data points in the histogram space. ", "caption_bbox": [98, 536, 399, 629]}, {"image_id": 6, "file_name": "152_06.png", "page": 7, "dpi": 300, "bbox": [118, 420, 713, 554], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Four classes of the color brain data set generated by the cluster-space interface are displayed. The four classes are the brain, dark regions such as the blood and gaps of the data set, black materials caused by the table, and the white ice. ", "caption_bbox": [98, 561, 731, 594]}, {"image_id": 7, "file_name": "152_07.png", "page": 7, "dpi": 300, "bbox": [156, 112, 675, 375], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Volume rendering of multiple materials for the tooth data set.", "caption_bbox": [235, 382, 594, 400]}, {"image_id": 8, "file_name": "152_08.png", "page": 8, "dpi": 300, "bbox": [128, 112, 700, 461], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A classification process of the cryosection color brain data set with part of the brain cut away to show the inner structure. (A) and (B) are two of the classified classes obtained by the initial classification. The first class which consists of white ice and the cerebral is then divided into two by the cluster-space interface and shown in (C) and (D). Finally, the lobe class and the cerebral class are rendered together to create a visualization with the whole brain which is presented in (E). ", "caption_bbox": [98, 468, 731, 531]}], "153": [{"image_id": 0, "file_name": "153_00.png", "page": 2, "dpi": 300, "bbox": [98, 181, 402, 451], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: For transfer functions with spikes, such as this example of two isosurfaces, regular sampling can miss most of a feature, resulting in significant artifacts. Pre-integrated rendering solves the transfer function integration problem. ", "caption_bbox": [98, 458, 399, 521]}, {"image_id": 1, "file_name": "153_01.png", "page": 3, "dpi": 300, "bbox": [115, 112, 384, 343], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Special-case isosurface handling can still produce lighting artifacts if multiple transparent isosurfaces inter- sect the same sampling interval. If one of the surfaces moves to another sampling interval in an adjacent view ray, light- ing calculated from the normals (gray arrows) may change abruptly. ", "caption_bbox": [98, 351, 399, 444]}, {"image_id": 2, "file_name": "153_02.png", "page": 4, "dpi": 300, "bbox": [114, 127, 731, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: To calculate the lookup tables for two samples i and j, the transfer function red, green, and blue channels are scaled by two ramp functions, one for each lookup table. The volume rendering integral is then computed over these modified transfer functions for each i   j   pair. ", "caption_bbox": [98, 322, 731, 370]}, {"image_id": 3, "file_name": "153_03.png", "page": 5, "dpi": 300, "bbox": [119, 545, 382, 644], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The update rule for subranges. A left-hand sub- range can be expanded one step in the transfer function to the right, and a right-hand subrange can be expanded one step to the left. This process will eventually give all pairs of subranges between i and j. ", "caption_bbox": [98, 657, 399, 735]}, {"image_id": 4, "file_name": "153_04.png", "page": 6, "dpi": 300, "bbox": [106, 132, 722, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The pre-integrated lookup table showing the direction of computation along the table diagonals. Each diagonal (corresponding to integrals of length nr ) requires one subrange-integral table. Each subrange-integral table contains all length nr integrals over the transfer function in one direction. One such integral is shown as a dotted box in the lower-right table. ", "caption_bbox": [98, 444, 731, 492]}, {"image_id": 5, "file_name": "153_05.png", "page": 6, "dpi": 300, "bbox": [120, 520, 716, 705], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The standard, unweighted pre-integrated lookup table is shown in (a) for a transfer function of nt elements. The two modified weighting functions are shown in (b), which are used to generate two intermediate tables. The desired function shown in (c) uses weighting functions that depend on the range of integration for each element. ", "caption_bbox": [98, 716, 731, 764]}, {"image_id": 6, "file_name": "153_06.png", "page": 8, "dpi": 300, "bbox": [100, 115, 399, 419], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Comparing frames-per-second for the skull (256 256 256) and vortex flow (128 128 128) data sets rendered to a 512 512 window using interpolated pre- integrated lighting and the traditional method which uses a single sample for computing the lighting. Results are shown with and without computation masking, which eliminates calls to the fragment program for empty voxels. ", "caption_bbox": [430, 496, 731, 605]}, {"image_id": 7, "file_name": "153_07.png", "page": 9, "dpi": 300, "bbox": [106, 112, 727, 669], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparing rendering methods. Our general-purpose lighting method produces much better results than standard lighting. Compared to special-case isosurface rendering, it can introduce minor artifacts where the normal is poorly-defined which can be visible at high magnification. ", "caption_bbox": [98, 673, 730, 721]}], "154": [{"image_id": 0, "file_name": "154_00.png", "page": 1, "dpi": 300, "bbox": [123, 343, 708, 553], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: RBF reconstruction of unstructured CFD data. (a) Volume rendering of 1,943,383 tetrahedral shock data set using 2,932 RBF functions. (b) Volume rendering of a 156,642 tetrahedral oil reservoir data set using 222 RBF functions organized in a hierarchy of 49 cells. ", "caption_bbox": [98, 565, 730, 613]}, {"image_id": 1, "file_name": "154_01.png", "page": 4, "dpi": 300, "bbox": [430, 235, 733, 399], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Our interactive reconstruction is based on a vol- ume slicing approach with a fragment program evaluating, for each rendered fragment, the RBF encoding stored in two- dimensional textures on the fly. ", "caption_bbox": [430, 406, 731, 469]}, {"image_id": 2, "file_name": "154_02.png", "page": 5, "dpi": 300, "bbox": [98, 112, 401, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Traversal algorithm for slice-based RBF- Rendering. ", "caption_bbox": [98, 366, 399, 399]}, {"image_id": 3, "file_name": "154_03.png", "page": 6, "dpi": 300, "bbox": [99, 114, 401, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The RBF data for all cells is tightly packed into a single set of texture maps. In this example, two different frag- ment programs for 4 and 8 RBF evaluations are available. ", "caption_bbox": [98, 275, 399, 323]}, {"image_id": 4, "file_name": "154_04.png", "page": 6, "dpi": 300, "bbox": [430, 112, 733, 493], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The fragment program for reconstructing Gaus- sian radial basis functions. ", "caption_bbox": [430, 494, 731, 527]}, {"image_id": 5, "file_name": "154_05.png", "page": 7, "dpi": 300, "bbox": [437, 749, 726, 920], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Volume isosurface rendering of the X38 density data reconstructed with 1,611 RBFs. ", "caption_bbox": [430, 927, 731, 960]}, {"image_id": 6, "file_name": "154_06.png", "page": 7, "dpi": 300, "bbox": [431, 553, 732, 671], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: RBF reconstruction of the X 38 shock data set. (a) 855 RBFs are used for reconstruction. (b) 1,147 RBFs are used for reconstruction. ", "caption_bbox": [430, 678, 731, 726]}, {"image_id": 7, "file_name": "154_07.png", "page": 7, "dpi": 300, "bbox": [437, 112, 726, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: RBF reconstruction of the X 38 shock data set.", "caption_bbox": [436, 344, 721, 362]}, {"image_id": 8, "file_name": "154_08.png", "page": 7, "dpi": 300, "bbox": [105, 112, 394, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Volume rendering of the RBF encoded X38 shock data set. ", "caption_bbox": [98, 285, 399, 318]}, {"image_id": 9, "file_name": "154_09.png", "page": 8, "dpi": 300, "bbox": [127, 750, 371, 912], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Volume rendering of water pressure for an in- jection well. The 156,642 tetradra data set is encoded using 458 RBFs. ", "caption_bbox": [98, 919, 399, 967]}, {"image_id": 10, "file_name": "154_10.png", "page": 8, "dpi": 300, "bbox": [431, 273, 732, 424], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Semi-transparent volume rendering of the neghip data set using 812 basis functions. The rendering is per- formed on a spatial decomposition comprised of four sub- division levels. ", "caption_bbox": [430, 431, 731, 494]}, {"image_id": 11, "file_name": "154_11.png", "page": 8, "dpi": 300, "bbox": [98, 363, 401, 516], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Volume and isosurface rendering of temperature generated from a natural convection simulation. ", "caption_bbox": [98, 523, 399, 556]}, {"image_id": 12, "file_name": "154_12.png", "page": 9, "dpi": 300, "bbox": [98, 112, 401, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Volume rendering of the bluntfin data set with its subdivision hierarchy. ", "caption_bbox": [98, 292, 399, 325]}], "155": [{"image_id": 0, "file_name": "155_00.png", "page": 2, "dpi": 300, "bbox": [98, 369, 396, 435], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A time slab. The sliders define a time slab from time step 58 to 74 (both are included in the slab). ", "caption_bbox": [98, 452, 399, 480]}, {"image_id": 1, "file_name": "155_01.png", "page": 2, "dpi": 300, "bbox": [101, 117, 698, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: 2D and 3D visualizations of 1D and 2D histograms.", "caption_bbox": [258, 319, 571, 332]}, {"image_id": 2, "file_name": "155_02.png", "page": 8, "dpi": 300, "bbox": [98, 112, 734, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Getting rid of large occluders near the borders. The occluder at the far end of the left image would block the view from the other side. Pushing a few rows of the histogram into the context allows the user to see the data from another perspective, and even to get an idea of the context data. ", "caption_bbox": [98, 295, 731, 339]}, {"image_id": 3, "file_name": "155_03.png", "page": 9, "dpi": 300, "bbox": [98, 112, 734, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Using the TimeHistogram to plot two dimensions against each other \u2013 both plots show the same dimensions. In contrast to the scatterplot, the histogram shows the extreme clustering of a lot of values around very distinct structures. ", "caption_bbox": [98, 352, 731, 380]}, {"image_id": 4, "file_name": "155_04.png", "page": 10, "dpi": 300, "bbox": [98, 112, 734, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Working around occlusion using interaction: Seeing the small interesting detail marked in the left image requires quite some interaction to be clearly visible in the 3D view on the right. In such a case, the 2D view reveals details at one glance that could have easily been missed in 3D. ", "caption_bbox": [98, 320, 731, 364]}], "156": [{"image_id": 0, "file_name": "156_00.png", "page": 2, "dpi": 300, "bbox": [444, 117, 719, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview of the technique presented in this paper.", "caption_bbox": [430, 261, 731, 274]}, {"image_id": 1, "file_name": "156_01.png", "page": 3, "dpi": 300, "bbox": [442, 110, 733, 612], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The basic algorithm of our visualization tech- nique. ", "caption_bbox": [430, 625, 731, 653]}, {"image_id": 2, "file_name": "156_02.png", "page": 5, "dpi": 300, "bbox": [110, 110, 397, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The algorithm to determine the number of pixel for every bin. ", "caption_bbox": [98, 443, 399, 471]}, {"image_id": 3, "file_name": "156_03.png", "page": 6, "dpi": 300, "bbox": [438, 111, 722, 437], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: An example taken from the NHIS data set. X cor- responds to age and Y corresponds to weight. The embed- ded histogram shows the distribution of doctor visits. The visualization shows that increasing age as well as increas- ing weight results in a higher number of doctor visits per year. The colormap used is shown at the bottom, where aqua (red) colors correspond to a low (high) number of doctor visits. ", "caption_bbox": [430, 447, 731, 567]}, {"image_id": 4, "file_name": "156_04.png", "page": 6, "dpi": 300, "bbox": [111, 126, 365, 382], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The histogram shows the discretization of the Doc- tor Visits in Past 12 Month attribute into 5 bins. A nonlinear mapping is applied. The histogram is used in the experiments of Figure 5 and Figure 7. The original range is mapped to [0, 4], and the mapping is given at the x-axis. ", "caption_bbox": [98, 402, 399, 476]}, {"image_id": 5, "file_name": "156_05.png", "page": 7, "dpi": 300, "bbox": [112, 149, 371, 381], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The scatterplot corresponding to the data shown in Figure 5 and 7. The overplotting is 85%. With respect to Shape-Embedded-Histograms there is no information about a third variable or the density. Note that a weight of zero means children. ", "caption_bbox": [98, 402, 399, 476]}, {"image_id": 6, "file_name": "156_06.png", "page": 7, "dpi": 300, "bbox": [441, 111, 722, 460], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: This visualization corresponds to Figure 5 which does not show any information about the support of a spe- cific cell. In this figure this is achieved by using different values for lightness. Three levels of support are shown. The colormap is explained in Figure 8. ", "caption_bbox": [430, 471, 731, 545]}, {"image_id": 7, "file_name": "156_07.png", "page": 7, "dpi": 300, "bbox": [477, 563, 710, 668], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: This is the colormap used for Figure 7. Different levels of lightness correspond to different levels of support. Hue represents the index of the bin (that is, the number of doctor visits). ", "caption_bbox": [430, 673, 731, 732]}, {"image_id": 8, "file_name": "156_08.png", "page": 8, "dpi": 300, "bbox": [458, 468, 705, 505], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Writings of the digits. The upper row represents the European style, the lower row represents the US style. ", "caption_bbox": [430, 529, 731, 557]}, {"image_id": 9, "file_name": "156_09.png", "page": 8, "dpi": 300, "bbox": [438, 113, 729, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Some digits reconstructed from the pendigits data set. The solid circle identifies the point where a per- son starts to write a digit, and the square identifies the point where a person stops writing the digit. Those points can be easily and reliable reconstructed from the pendigits data. In- termediate points are identified by circles and the direction of writing is shown by arrows. Note that points where writing is interrupted (e.g., when writing \u201c5\u201d) can not be identified. ", "caption_bbox": [430, 314, 731, 434]}, {"image_id": 10, "file_name": "156_10.png", "page": 8, "dpi": 300, "bbox": [106, 113, 403, 398], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: An example taken from the CPSM data set. The horizontal axis corresponds to age. The height of different bins (upper part) reflects the amount of data in each bin. In- side each bin the distribution of AGI is shown. The colormap shown on the left side maps low (high) AGI to yellow (black) colors, whereas AGI below zero is mapped to red. The lower part does not map the support to the height of the bin. This allows easier comparison of different bins. ", "caption_bbox": [98, 408, 399, 528]}, {"image_id": 11, "file_name": "156_11.png", "page": 9, "dpi": 300, "bbox": [441, 111, 722, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: This visualization corresponds to Figure 12, but instead of the first point the last point (the point where the pen is lifted) is in focus. The visualization takes care of the support as explained in the text. The colormap is shown at the left side. ", "caption_bbox": [430, 402, 731, 476]}, {"image_id": 12, "file_name": "156_12.png", "page": 9, "dpi": 300, "bbox": [109, 111, 390, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: This visualization shows the locations where people tend to start to write different digits, i.e., the location where the pen hits the paper is shown. The coordinates in the visualization correspond to coordinates of the tablet. The amount of digits which start at a given location (grid cell) is represented by the embedded histogram. The colormap is shown at the left side. ", "caption_bbox": [98, 402, 399, 507]}, {"image_id": 13, "file_name": "156_13.png", "page": 9, "dpi": 300, "bbox": [443, 518, 720, 794], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: This scatterplot corresponds to Figure 12. The overplotting is 40%. The same colormap as in Figure 12 and 13 is used. ", "caption_bbox": [430, 806, 731, 850]}], "157": [{"image_id": 0, "file_name": "157_00.png", "page": 2, "dpi": 300, "bbox": [478, 629, 686, 929], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Gram-Schmidt orthonormalization", "caption_bbox": [467, 935, 694, 948]}, {"image_id": 1, "file_name": "157_01.png", "page": 3, "dpi": 300, "bbox": [142, 451, 357, 730], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Constructing an m-dimensional HDE", "caption_bbox": [139, 736, 358, 749]}, {"image_id": 2, "file_name": "157_02.png", "page": 4, "dpi": 300, "bbox": [139, 450, 360, 759], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The subspace iteration algorithm", "caption_bbox": [139, 764, 358, 777]}, {"image_id": 3, "file_name": "157_03.png", "page": 7, "dpi": 300, "bbox": [466, 715, 701, 945], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Stress minimization within a 50-D subspace of the graph Finan512 [Wal]. |V|=74,752, |E|=261,120, 225 sec ", "caption_bbox": [430, 951, 731, 980]}, {"image_id": 4, "file_name": "157_04.png", "page": 9, "dpi": 300, "bbox": [73, 116, 743, 807], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparison of three drawing algorithms: left: eigen-projection, middle: PHDE (PCA of high-dimensional em- bedding), and right: eigen-projection optimized in high-dimensional embedding subspace. The results are given for the three graphs: top: the Bfw782a graph [MM] (|V|=782, |E|=3,394), center: the 4elt graph [Wal] (|V|=15,606, |E|=45,878), and bottom: the Finan512 graph [Wal] (|V|=74,752, |E|=261,120). ", "caption_bbox": [98, 823, 731, 882]}, {"image_id": 5, "file_name": "157_05.png", "page": 10, "dpi": 300, "bbox": [169, 661, 661, 885], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The horse model: (a) Original polygonal mesh; (b) Drawing the connectivity of the mesh using stress minimization within a 50-D subspace. |V|=19,851, |E|=59,547, 29sec ", "caption_bbox": [98, 894, 731, 923]}, {"image_id": 6, "file_name": "157_06.png", "page": 10, "dpi": 300, "bbox": [51, 112, 781, 561], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Stress minimization within a 50-D subspace of the graphs (a) Crack [Pet]: |V|=10,240, |E|=30,380, running time is 9 sec; (b) Shuttle [Wal]: |V|=3200, |E|=7840, 2 sec; (c) Rdb3200l [MM]: |V|=3200, |E|=7840, 1 sec; (d) Bfw782a [MM]: |V|=782, |E|=3394, 0.3 sec; (e) Ocean [Wal]:|V|=143,437, |E|=409,593, 4 minutes; (f) Qh882 [MM]: |V|=882, |E|=1533, 0.5sec ", "caption_bbox": [98, 576, 731, 636]}], "158": [{"image_id": 0, "file_name": "158_00.png", "page": 1, "dpi": 300, "bbox": [412, 357, 733, 855], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Dendrogram representation of a (simple) phylo- genetic tree in which leaves represent species and internal nodes (or branching points) represent hypothetical ances- tors. Branch lengths give an indication of evolutionary time. (Data from [DKP95]) ", "caption_bbox": [430, 863, 731, 941]}, {"image_id": 1, "file_name": "158_01.png", "page": 2, "dpi": 300, "bbox": [431, 113, 732, 698], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visualization of a metabolic pathway produced with BioPath [FPR\u2217 02]. White (containing structural for- mulas) and blue nodes represent chemical substances, or- ange nodes represent enzymes ", "caption_bbox": [430, 706, 731, 769]}, {"image_id": 2, "file_name": "158_02.png", "page": 3, "dpi": 300, "bbox": [430, 112, 733, 284], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Use-case diagram for triangulating a complex phylogenetic tree by four coordinated visualizations ", "caption_bbox": [430, 291, 731, 324]}, {"image_id": 3, "file_name": "158_03.png", "page": 4, "dpi": 300, "bbox": [107, 114, 392, 609], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Thiamine pathway of Haemophilus influenzae. The layout is determined by the layout in Fig. 5 ", "caption_bbox": [98, 616, 399, 649]}, {"image_id": 4, "file_name": "158_04.png", "page": 5, "dpi": 300, "bbox": [224, 112, 607, 702], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Hypothetical thiamine pathway determined by all subtree leaves and the reference pathway; the brighter an element, the less likely its presence. The embedded operational pathway of Haemophilus influenzae is shown in red ", "caption_bbox": [98, 710, 730, 743]}, {"image_id": 5, "file_name": "158_05.png", "page": 6, "dpi": 300, "bbox": [437, 703, 726, 901], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: An operational pathway can be selected either di- rectly, using the radio buttons shown, or from the 2 21 D view ", "caption_bbox": [430, 908, 731, 944]}, {"image_id": 6, "file_name": "158_06.png", "page": 6, "dpi": 300, "bbox": [105, 679, 394, 856], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Phylogenetic tree view and Hypothetical pathway view showing the phylogenetic tree built from the thiamine pathway of twelve species. Since no internal node of the tree has been selected by the user the hypothetical pathway cor- responds to the root of the tree. The ultimate drawing of the sketched hypothetical pathway on the right is shown in Fig. 5 ", "caption_bbox": [98, 863, 399, 956]}, {"image_id": 7, "file_name": "158_07.png", "page": 6, "dpi": 300, "bbox": [124, 113, 707, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Hamming-distance matrix of thiamine pathways", "caption_bbox": [268, 298, 561, 316]}, {"image_id": 8, "file_name": "158_08.png", "page": 7, "dpi": 300, "bbox": [161, 112, 670, 569], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Related pathways view showing pathways from Fig. 7 stacked in leaf order with the thiamine reference pathway located at the bottom of the stacking ", "caption_bbox": [98, 576, 731, 609]}, {"image_id": 9, "file_name": "158_09.png", "page": 8, "dpi": 300, "bbox": [113, 113, 715, 578], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: A screen shot showing all the coordinated views. Again the phylogenetic tree window from Fig. 7 is shown. However, here an internal node has been selected by the user highlighting a subtree. Only elements which exist in leaves of this subtree and the reference pathway are shown in the hypothetical pathway on the right side of this window. The selection also applies to the leaf pathways shown in the 2 12 D stack (background window) and the individual pathways available for browsing in the ", "caption_bbox": [98, 588, 731, 655]}], "159": [{"image_id": 0, "file_name": "159_00.png", "page": 1, "dpi": 300, "bbox": [424, 348, 733, 750], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The swirling motion of flow in the combustion chamber of a diesel engine (side view). The intake ports at the top provide the tangential component of the flow neces- sary for swirl. ", "caption_bbox": [430, 761, 731, 820]}, {"image_id": 1, "file_name": "159_01.png", "page": 2, "dpi": 300, "bbox": [529, 76, 632, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The swirling motion of flow in the combustion chamber of a diesel engine (side view) as illustrated by an isosurface. This is a velocity isosurface with an isovalue of 5.0 m/s. Any CFD attribute can be mapped to hue. ", "caption_bbox": [430, 324, 731, 383]}, {"image_id": 2, "file_name": "159_02.png", "page": 5, "dpi": 300, "bbox": [119, 76, 712, 355], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (left) a velocity isosurface of value 5.0 m/s with a CFD simulation attribute mapped to hue and texture-based flow visualization (right) texture-based flow visualization on the isosurface combined with a normal mask. A close-up is shown in Figure 6. ", "caption_bbox": [98, 366, 730, 410]}, {"image_id": 3, "file_name": "159_03.png", "page": 7, "dpi": 300, "bbox": [446, 511, 723, 793], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (color plate) (top) the intersection of three blood vessels. An abnormal pocket has formed at the junction. (bottom) a velocity isosurface of value 0.04 m/s with texture- based flow visualization applied. The recirculation zone where blood flows in the opposing direction becomes clear. ", "caption_bbox": [430, 839, 731, 913]}, {"image_id": 4, "file_name": "159_04.png", "page": 7, "dpi": 300, "bbox": [117, 77, 411, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (color plate) A close-up, wire-frame view of the isosurface from Figure 2. The algorithm we describe must be applicable to adaptive resolution isosurface meshes. ", "caption_bbox": [98, 405, 399, 449]}, {"image_id": 5, "file_name": "159_05.png", "page": 7, "dpi": 300, "bbox": [452, 77, 740, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (color plate) A close-up of a velocity isosurface from Figure 3: with texture-based flow visualization and a normal mask applied. With the texture advection on the iso- surface, it is clear that the ideal swirl flow pattern is not exhibited in this region. ", "caption_bbox": [430, 404, 731, 478]}, {"image_id": 6, "file_name": "159_06.png", "page": 7, "dpi": 300, "bbox": [117, 482, 413, 800], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (color plate) A close up view of the same isosur- face shown in Figure 3 using a clipping plane tangent to the view-point in order to reveal occluded isosurface structures. ", "caption_bbox": [98, 810, 399, 854]}], "160": [{"image_id": 0, "file_name": "160_00.png", "page": 2, "dpi": 300, "bbox": [134, 113, 365, 194], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A diesel exhaust system consisting of a diesel oxi- dation catalyst (DOC) and a diesel particulate filter (DPF). ", "caption_bbox": [98, 205, 399, 233]}, {"image_id": 1, "file_name": "160_01.png", "page": 2, "dpi": 300, "bbox": [475, 111, 689, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Emission reductions in the DOC [9]", "caption_bbox": [464, 198, 698, 211]}, {"image_id": 2, "file_name": "160_02.png", "page": 3, "dpi": 300, "bbox": [101, 111, 730, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visualization of soot mass in the DPF after 30 sec. (middle) and after 50 sec. (right). Histograms (left) and 3D views for both cases are shown. ", "caption_bbox": [98, 399, 732, 427]}, {"image_id": 3, "file_name": "160_03.png", "page": 5, "dpi": 300, "bbox": [431, 112, 732, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: High solid catalyst temperature after 30 sec.", "caption_bbox": [443, 344, 719, 357]}, {"image_id": 4, "file_name": "160_04.png", "page": 5, "dpi": 300, "bbox": [105, 112, 394, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Velocity values in cells with high soot mass values and low mass fraction of O2 after 40 sec. ", "caption_bbox": [98, 298, 399, 326]}], "161": [{"image_id": 0, "file_name": "161_00.png", "page": 3, "dpi": 300, "bbox": [436, 731, 726, 916], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Specification of a Bio-Vector", "caption_bbox": [430, 933, 625, 946]}, {"image_id": 1, "file_name": "161_01.png", "page": 4, "dpi": 300, "bbox": [466, 592, 708, 749], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Volume of Segments", "caption_bbox": [430, 775, 581, 788]}, {"image_id": 2, "file_name": "161_02.png", "page": 4, "dpi": 300, "bbox": [131, 748, 364, 928], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Bio-Coordinates", "caption_bbox": [98, 942, 233, 955]}, {"image_id": 3, "file_name": "161_03.png", "page": 5, "dpi": 300, "bbox": [430, 529, 733, 708], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: An animal visualised by e-Voluzzer.", "caption_bbox": [430, 719, 658, 732]}, {"image_id": 4, "file_name": "161_04.png", "page": 5, "dpi": 300, "bbox": [431, 112, 733, 480], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Interface Junctions (as wireframe and shaded)", "caption_bbox": [430, 492, 714, 505]}, {"image_id": 5, "file_name": "161_05.png", "page": 6, "dpi": 300, "bbox": [98, 112, 401, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A biologically correct evolutionary morphing", "caption_bbox": [98, 300, 376, 313]}], "162": [{"image_id": 0, "file_name": "162_00.png", "page": 2, "dpi": 300, "bbox": [467, 211, 698, 452], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Architecture of the participant package. All com- ponents are installed on the participant\u2019s machine. Details of parameter perturbations are downloaded from climatepre- diction.net servers and the simulation results are uploaded to these servers at the end of the run. SM1 and SM2 are two shared memory arenas which are used for communica- tion between the client, model and visualization components (SM1) and for transfer of data from the model to the visual- ization (SM2). ", "caption_bbox": [430, 473, 731, 608]}, {"image_id": 1, "file_name": "162_01.png", "page": 4, "dpi": 300, "bbox": [124, 111, 374, 505], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Continuous cloud cover of entire globe (top) and a close-up (bottom) using cell-based display. ", "caption_bbox": [98, 516, 399, 544]}, {"image_id": 2, "file_name": "162_02.png", "page": 5, "dpi": 300, "bbox": [124, 111, 374, 495], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Two options for visualizing field data\u2014here, temperature\u2014using (top) cell-based display and (bottom) solid contours. ", "caption_bbox": [98, 506, 399, 550]}], "163": [{"image_id": 0, "file_name": "163_00.png", "page": 2, "dpi": 300, "bbox": [116, 112, 715, 463], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A screen shot of DNAVis with notes added to identify user interface elements. DNAVis has a configurable number of views. Here four views are shown. Each bar view shows information on a region of DNA sequence and matrix views on a combination of two regions. ", "caption_bbox": [98, 470, 730, 518]}, {"image_id": 1, "file_name": "163_01.png", "page": 3, "dpi": 300, "bbox": [157, 112, 673, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A bar view showing a region of Arabidopsis thaliana, chromosome 1, with two annotations: At1g60820 representing a \u2018tRNA\u2019 annotation and At1g60830 representing a \u2018Gene\u2019 annotation with multiple exons and introns. See color section. ", "caption_bbox": [98, 274, 730, 307]}, {"image_id": 2, "file_name": "163_02.png", "page": 4, "dpi": 300, "bbox": [177, 113, 653, 493], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Three views that show the same location (around the 10 millionth nucleotide) on chromosome 4 of Arabidopsis but each on a different level of detail. All views have multiple bars with different layouts for the annotations. The top view shows approximately 1 million nucleotides of the data set. The center view shows a region of 17659 nucleotides and the bottom view shows the actual nucleotides and their complements on a sequence region of 52 nucleotides. ", "caption_bbox": [98, 500, 730, 563]}, {"image_id": 3, "file_name": "163_03.png", "page": 5, "dpi": 300, "bbox": [216, 113, 614, 410], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A matrix view comparing two different regions of the Arabidopsis genome. The large dark rectangles in the compari- son matrix indicate a precalculated large scale similarity between the two regions. On a smaller scale the results of a nucleotide comparison, which is calculated on-the-fly, is shown. ", "caption_bbox": [98, 417, 730, 465]}, {"image_id": 4, "file_name": "163_04.png", "page": 6, "dpi": 300, "bbox": [216, 112, 614, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A miRNA candidate shown to be directly downstream of a gene.", "caption_bbox": [229, 258, 599, 276]}], "164": [{"image_id": 0, "file_name": "164_00.png", "page": 2, "dpi": 300, "bbox": [534, 113, 629, 209], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example of the ray casting method", "caption_bbox": [467, 220, 694, 233]}, {"image_id": 1, "file_name": "164_01.png", "page": 3, "dpi": 300, "bbox": [466, 759, 698, 883], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Ellipse Approximation. (a) Estimation of line where the ellipse center should pass. (b) Estimation of the ellipse center. ", "caption_bbox": [430, 893, 731, 937]}, {"image_id": 2, "file_name": "164_02.png", "page": 4, "dpi": 300, "bbox": [127, 357, 371, 442], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Comparison of the evaluated methods.", "caption_bbox": [471, 536, 689, 549]}, {"image_id": 3, "file_name": "164_03.png", "page": 5, "dpi": 300, "bbox": [120, 128, 710, 427], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Distance error graphs of the center estimated by (a) RCT, (b) RCMG, (c) CoG, (d) BM, (e) EF, and (f) RHT method", "caption_bbox": [100, 443, 729, 456]}, {"image_id": 4, "file_name": "164_04.png", "page": 5, "dpi": 300, "bbox": [222, 494, 608, 793], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Diameter estimated by (a) RCT, (b) RCMG, (c) EF, and (d) RHT method", "caption_bbox": [207, 808, 621, 821]}, {"image_id": 5, "file_name": "164_05.png", "page": 7, "dpi": 300, "bbox": [117, 121, 714, 786], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: From left to right rotating CPR with 45, 135, 225 and 315 degree. From top to bottom centered with RCT, RCMG, CoG, EF, BM and RHT. This data corresponds to a femoral with a diameter between 2mm and 4mm, and present a calcification part and one bifurcation. Brighter objects correspond to bone structures. Observing, from left to right, from top to button, the third image exhibits the best approximation center in different rotations of the CPR. This is without consider bifurcations, and corresponds with the CoG method. In this data the best result is exhibited by the RCMG method. ", "caption_bbox": [98, 804, 731, 878]}], "165": [{"image_id": 0, "file_name": "165_00.png", "page": 3, "dpi": 300, "bbox": [430, 421, 733, 668], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Color coding the type of leaf nodes in addition to a structure visualization. ", "caption_bbox": [430, 679, 731, 707]}, {"image_id": 1, "file_name": "165_01.png", "page": 3, "dpi": 300, "bbox": [430, 112, 733, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Using treemaps to visualize the structure of the document without showing any additional information. ", "caption_bbox": [430, 370, 731, 398]}, {"image_id": 2, "file_name": "165_02.png", "page": 4, "dpi": 300, "bbox": [430, 112, 733, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Encoding the number of occurrences of a single query term in the color of the rectangles. ", "caption_bbox": [430, 370, 731, 398]}, {"image_id": 3, "file_name": "165_03.png", "page": 4, "dpi": 300, "bbox": [430, 422, 733, 669], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Combining size and color coding in one view re- sults in an overview of the term distribution related to the document\u2019s structure. ", "caption_bbox": [430, 680, 731, 724]}, {"image_id": 4, "file_name": "165_04.png", "page": 5, "dpi": 300, "bbox": [430, 419, 733, 667], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Omitting the structure and adjusting the size", "caption_bbox": [443, 677, 718, 690]}, {"image_id": 5, "file_name": "165_05.png", "page": 5, "dpi": 300, "bbox": [430, 112, 733, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Omitting the structure but keeping the size as that of the whole subtree ", "caption_bbox": [430, 369, 731, 397]}, {"image_id": 6, "file_name": "165_06.png", "page": 6, "dpi": 300, "bbox": [429, 518, 733, 998], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Integrating context information as tooltips. The images show just a part of the treemap ", "caption_bbox": [430, 441, 731, 469]}, {"image_id": 7, "file_name": "165_07.png", "page": 6, "dpi": 300, "bbox": [433, 114, 733, 432], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Using cushion treemaps in areas where query terms have been found and leaving all other areas flat. ", "caption_bbox": [98, 369, 399, 397]}, {"image_id": 8, "file_name": "165_08.png", "page": 7, "dpi": 300, "bbox": [98, 111, 733, 506], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The complete search interface. In the right window, the query terms are selected from the list and the treemap is built. The term distribution in the currently pointed at node is shown in the histogram in the bottom left corner of that window. Finally, the user selected this specific paragraph and the document browser (left window) shows the respective position. ", "caption_bbox": [98, 518, 731, 562]}], "166": [{"image_id": 0, "file_name": "166_00.png", "page": 2, "dpi": 300, "bbox": [97, 84, 415, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A scatterplot matrix", "caption_bbox": [169, 393, 322, 406]}, {"image_id": 1, "file_name": "166_01.png", "page": 4, "dpi": 300, "bbox": [97, 84, 715, 729], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Principal and visual component analysis of data in a scatterplot matrix. The left column shows the principal direction corresponding to the principal component of the data and the projection along this direction onto the orthogonal subspace. In the right column, the user has corrected the direction based on the trend apparent in the middle block of the panel matrix. In the projection (lower right), the main variation of the data in the middle part is removed. ", "caption_bbox": [96, 740, 729, 799]}, {"image_id": 2, "file_name": "166_02.png", "page": 6, "dpi": 300, "bbox": [97, 84, 715, 540], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Data that benefits from a piecewise linear representation. The left column shows the usual representation with a single line segment. The other two columns show different representations with three line segments. The lower row shows the data after projecting (each cluster) along the principal directions. ", "caption_bbox": [96, 550, 729, 594]}], "167": [{"image_id": 0, "file_name": "167_00.png", "page": 3, "dpi": 300, "bbox": [219, 117, 613, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: In screen-space techniques, pixel regions are enlarged or reduced to provide selective detail. In this scatterplot matrix display, a center of focus has been selected and magni\u00a3ed using a confocal lens technique. ", "caption_bbox": [98, 478, 731, 506]}, {"image_id": 1, "file_name": "167_01.png", "page": 4, "dpi": 300, "bbox": [147, 473, 684, 674], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: In screen-space zooming (left), pixels are replicated to provide selective size, while in data space zooming (right), the data itself can be resampled at the appropriate resolution. ", "caption_bbox": [98, 685, 731, 713]}, {"image_id": 2, "file_name": "167_02.png", "page": 4, "dpi": 300, "bbox": [162, 112, 673, 379], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: In data value-space distortion, transformations are performed according to the dimensionality of the data. In this example, generated using XmdvTool [FWR99], an N-dimensional hyperbox is selected via painting over a section of an axis and scaled in all dimensions (by different amounts) to \u00a3ll a unit hypercube, which is then displayed. Animation is used to preserve context. Clusters and anomalies within the selected region are much easier to see in the zoomed version. ", "caption_bbox": [98, 393, 731, 452]}, {"image_id": 3, "file_name": "167_03.png", "page": 5, "dpi": 300, "bbox": [155, 127, 358, 321], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Selection of nodes in a hierarchy via InterRing [YWR02]. Nodes with a red stripe in them have been selected via a user-speci\u00a3ed query rather than one node at a time. ", "caption_bbox": [98, 346, 399, 390]}, {"image_id": 4, "file_name": "167_04.png", "page": 5, "dpi": 300, "bbox": [445, 443, 720, 664], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Object-based techniques distort an object upon which data has been projected. In this example, inspired by the Perspective Wall [MRC91], a parallel coordinates display is projected onto walls, and perspective is used to make a selected wall more readable while maintaining con- text with the rest of the data. ", "caption_bbox": [430, 714, 731, 803]}, {"image_id": 5, "file_name": "167_05.png", "page": 6, "dpi": 300, "bbox": [105, 111, 727, 509], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Attribute-based distortion modi\u00a3es one or more attributes of the graphical objects used to depict the data, as shown with this colormap modi\u00a3cation, generated using the colormap editor in OpenDX. The color map is distorted to allot a greater portion to values in the middle of the data range. ", "caption_bbox": [98, 520, 731, 564]}, {"image_id": 6, "file_name": "167_06.png", "page": 7, "dpi": 300, "bbox": [441, 649, 718, 798], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The Distortion Pipeline. The user interactively controls each stage of the pipeline. Each distortion opera- tion is optional. ", "caption_bbox": [430, 886, 731, 930]}, {"image_id": 7, "file_name": "167_07.png", "page": 7, "dpi": 300, "bbox": [217, 113, 613, 436], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Structure-based distortion modi\u00a3es the underlying structural elements of the visualization. This example, inspired by Table Lens [RC94], shows a scatterplot matrix with two grid cells (and their corresponding rows and columns) magni\u00a3ed, with a corresponding shrinkage in other cells. ", "caption_bbox": [98, 449, 731, 493]}], "168": [{"image_id": 0, "file_name": "168_00.png", "page": 2, "dpi": 300, "bbox": [442, 230, 718, 472], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Tensor shapes, with cuboids.", "caption_bbox": [482, 471, 679, 484]}, {"image_id": 1, "file_name": "168_01.png", "page": 2, "dpi": 300, "bbox": [440, 707, 714, 950], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Tensor shapes, with cylinders.", "caption_bbox": [479, 949, 682, 962]}, {"image_id": 2, "file_name": "168_02.png", "page": 3, "dpi": 300, "bbox": [102, 119, 715, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: From some viewpoints, ellipsoids poorly convey tensor shape.", "caption_bbox": [234, 258, 594, 271]}, {"image_id": 3, "file_name": "168_03.png", "page": 3, "dpi": 300, "bbox": [107, 296, 382, 539], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Tensor shapes, with ellipsoids.", "caption_bbox": [146, 538, 352, 551]}, {"image_id": 4, "file_name": "168_04.png", "page": 4, "dpi": 300, "bbox": [438, 109, 720, 800], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Tensor shapes, with superquadric glyphs, and three different values of edge sharpness parameter \u03b3. ", "caption_bbox": [430, 815, 731, 844]}, {"image_id": 5, "file_name": "168_05.png", "page": 4, "dpi": 300, "bbox": [101, 119, 399, 412], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Superquadrics defined by Equation 3. The gray triangle indicates the subset of the shape space employed by superquadric tensor glyphs. Edges indicate the tessellation resulting from uniform steps in \u03c6 and \u03b8. ", "caption_bbox": [98, 425, 399, 485]}, {"image_id": 6, "file_name": "168_06.png", "page": 5, "dpi": 300, "bbox": [101, 311, 398, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Parameterization change across the linear/planar seam, from cl > c p to cl < c p (\u03b3 = 3). ", "caption_bbox": [98, 407, 399, 436]}, {"image_id": 7, "file_name": "168_07.png", "page": 5, "dpi": 300, "bbox": [99, 113, 716, 255], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Superquadrics convey shape differences more reliably than ellipsoids (\u03b3 = 3).", "caption_bbox": [195, 260, 633, 274]}, {"image_id": 8, "file_name": "168_08.png", "page": 6, "dpi": 300, "bbox": [433, 112, 736, 749], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: 3-D region of DT-MRI dataset of brain visualized with ellipsoids (top) and superquadrics (bottom). ", "caption_bbox": [430, 768, 731, 796]}, {"image_id": 9, "file_name": "168_09.png", "page": 6, "dpi": 300, "bbox": [101, 116, 404, 757], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Slice of DT-MRI dataset of brain visualized with ellipsoids (top) and superquadrics (bottom). ", "caption_bbox": [98, 777, 399, 805]}], "169": [{"image_id": 0, "file_name": "169_00.png", "page": 3, "dpi": 300, "bbox": [520, 112, 643, 192], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: angular criterion", "caption_bbox": [511, 199, 651, 217]}, {"image_id": 1, "file_name": "169_01.png", "page": 3, "dpi": 300, "bbox": [111, 112, 396, 194], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: improved triangulation resulting from higher or- der integration combined with arc length parametrization ", "caption_bbox": [98, 199, 399, 232]}, {"image_id": 2, "file_name": "169_02.png", "page": 4, "dpi": 300, "bbox": [107, 112, 392, 205], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Tangential velocity (left) and Rankine vortex model (right) ", "caption_bbox": [98, 212, 399, 245]}, {"image_id": 3, "file_name": "169_03.png", "page": 4, "dpi": 300, "bbox": [459, 788, 704, 932], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Boundary curve computation", "caption_bbox": [481, 939, 680, 957]}, {"image_id": 4, "file_name": "169_04.png", "page": 5, "dpi": 300, "bbox": [482, 820, 687, 885], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Left: streamline starting curve P0 at assumed vor- tex core line position p, perpendicular to the flow v(p) at p. Right: stream surface colored to perceive rotation around vortex core line ", "caption_bbox": [430, 895, 731, 958]}, {"image_id": 5, "file_name": "169_05.png", "page": 9, "dpi": 300, "bbox": [159, 131, 672, 432], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Upper row: Vortex cores boundaries above the delta wing. Note the clean distinction between the vortices and the non- trivial shapes. Lower row: Vortex core boundaries in the ICE dataset. Although detected incompletely by the Sujudi-Haimes algorithm, vortex cores could be extracted by our method. The streamlines give a rough impression of how the vortices are created (right). The streamsurface across the nose of the train \u201cwraps\u201d the head vortex (right). ", "caption_bbox": [98, 440, 730, 503]}, {"image_id": 6, "file_name": "169_06.png", "page": 9, "dpi": 300, "bbox": [188, 537, 656, 815], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Upper image: Results of stream surface based vortex core line extraction on the ICE train: Sujudi-Haimes output with false positives indicated by arrows (blue), vortex core lines computed as gravity lines (magenta), visual verification of the upper vortex using a wrapping stream surface, with color mapping to show the rotation around the vortex axis (yellow/green). Note: not all vortex cores lines have been extracted. Lower left image: Results of vortex core line and vortex core boundary extraction on the delta wing: Sujudi-Haimes output (dark blue, false positives indicated by arrows), vortex core lines from gravity lines (magenta), triangle meshes of vortex core boundaries (primary: blue, secondary: green, tertiary: red). Lower right image: Cutting plane with closed stream surfaces started using plane singularities. Stream surface coloring indicates rotation and confirms the existence of vortices. ", "caption_bbox": [98, 822, 730, 946]}, {"image_id": 7, "file_name": "169_07.png", "page": 10, "dpi": 300, "bbox": [145, 504, 686, 797], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Upper left: Stream surfaces in the F6 dataset. Vortex generation at the wing. Upper right: Stream surface showing vortex breakdown, helicity magnitude color mapping. A strong correlation between helicity magnitude and the onset of vortex breakdown is evident. Lower row: Apex surface in the delta wing dataset, colored according to Gaussian curvature (left) and streamline stretching (right), revealing geometric properties of the stream surface. ", "caption_bbox": [98, 820, 730, 883]}, {"image_id": 8, "file_name": "169_08.png", "page": 10, "dpi": 300, "bbox": [173, 112, 658, 402], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Upper left: Overview of the delta wing dataset with vortex creation at apex and the two primary vortices, breaking down differently. Upper right: Stream surface around ICE train showing vortices on the lee side. Lower left: Vortex breakdown cut open, revealing recirculation. Lower right: Formation of primary, secondary and tertiary vortices at wing apex. Note how the shape of the tertiary vortex is strongly elliptic. ", "caption_bbox": [98, 409, 730, 472]}], "170": [{"image_id": 0, "file_name": "170_00.png", "page": 3, "dpi": 300, "bbox": [98, 439, 400, 551], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Two histograms taken from different regions of figure 1. The left image depicts the intensity distribution of a low-contrast region. The rightmost image depicts a high- contrast region. ", "caption_bbox": [98, 558, 399, 621]}, {"image_id": 1, "file_name": "170_01.png", "page": 3, "dpi": 300, "bbox": [98, 41, 402, 346], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Manipulation of contrast is used in this image to represent a scalar distribution. Local differences between black and white values are used to portray the calculated quantity of uniform momentum. ", "caption_bbox": [98, 353, 399, 416]}, {"image_id": 2, "file_name": "170_02.png", "page": 3, "dpi": 300, "bbox": [430, 41, 735, 346], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Manipulation of mean luminance is used in this image to represent a scalar distribution. Luminance values in an original LIC image are shifted according to the values in an auxiliary scalar distribution \u2013 in this case representing uniform momentum. ", "caption_bbox": [430, 353, 731, 431]}, {"image_id": 3, "file_name": "170_03.png", "page": 3, "dpi": 300, "bbox": [430, 452, 732, 565], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Two histograms taken from different regions of fig- ure 3 showing that the shapes of the histograms remain sim- ilar, and only the average luminance value is changed. ", "caption_bbox": [430, 572, 731, 620]}, {"image_id": 4, "file_name": "170_04.png", "page": 4, "dpi": 300, "bbox": [430, 299, 733, 453], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Restricting the initial value of the streamline can lead to artifacts at boundary of the image domain, as seen in the lower left and bottom of the leftmost image. This problem can be alleviated by allowing the initial pixel values to span the entire range from 0 to 255. ", "caption_bbox": [430, 460, 731, 538]}, {"image_id": 5, "file_name": "170_05.png", "page": 5, "dpi": 300, "bbox": [430, 392, 733, 695], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A sparse texture in which streamlines are not ter- minated when their proximity becomes too great. This en- hances bifurcation lines in the data. ", "caption_bbox": [430, 703, 731, 751]}, {"image_id": 6, "file_name": "170_06.png", "page": 5, "dpi": 300, "bbox": [430, 42, 733, 346], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A sparse texture of evenly distributed streamlets.", "caption_bbox": [433, 353, 728, 371]}, {"image_id": 7, "file_name": "170_07.png", "page": 5, "dpi": 300, "bbox": [98, 42, 401, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: In the topmost image, velocity magnitude is nor- malized with respect to the values along the local streamline only. This results in short streamlines at places where the velocity is greatest along each individual streamline. In the lower image, velocity magnitude is normalized with respect to the global velocity magnitude. The luminance ramp along streamlines is also defined using an inverse relationship be- tween the step size and the vector magnitude, resulting in long streamlines where the velocity is at the largest magni- tude globally over the domain ", "caption_bbox": [98, 257, 399, 411]}, {"image_id": 8, "file_name": "170_08.png", "page": 6, "dpi": 300, "bbox": [430, 427, 733, 731], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Overlying a sparse streamline texture on an em- bossed representation of the out-of-plane vector component. ", "caption_bbox": [430, 738, 731, 771]}, {"image_id": 9, "file_name": "170_09.png", "page": 6, "dpi": 300, "bbox": [430, 42, 733, 346], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: An embossed and depth-shaded image represent- ing the gain-adjusted magnitude of the out-of-plane compo- nent of a vector field. ", "caption_bbox": [430, 353, 731, 401]}, {"image_id": 10, "file_name": "170_10.png", "page": 7, "dpi": 300, "bbox": [430, 392, 733, 695], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Embossed streamlines on an embossed represen- tation of the out-of-plane vector component. ", "caption_bbox": [430, 703, 731, 736]}, {"image_id": 11, "file_name": "170_11.png", "page": 7, "dpi": 300, "bbox": [430, 42, 733, 346], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Embossed streamlines", "caption_bbox": [495, 353, 665, 371]}, {"image_id": 12, "file_name": "170_12.png", "page": 7, "dpi": 300, "bbox": [98, 41, 404, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Different levels of embossing applied to stream- lines to represent the magnitude of an auxiliary scalar dis- tribution. ", "caption_bbox": [98, 253, 399, 301]}, {"image_id": 13, "file_name": "170_13.png", "page": 9, "dpi": 300, "bbox": [224, 42, 607, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Using luminance to depict flow direction and color to represent multiple distributions.", "caption_bbox": [173, 433, 655, 451]}], "171": [{"image_id": 0, "file_name": "171_00.png", "page": 1, "dpi": 300, "bbox": [412, 395, 734, 834], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The components of the diffusion tensor of a transversal brain slice from a healthy person. ", "caption_bbox": [430, 845, 731, 873]}, {"image_id": 1, "file_name": "171_01.png", "page": 3, "dpi": 300, "bbox": [122, 113, 377, 316], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Barycentric space defined by the anisotropy in- dices Cl , C p and Cs and the corresponding shapes. ", "caption_bbox": [98, 331, 400, 361]}, {"image_id": 2, "file_name": "171_02.png", "page": 4, "dpi": 300, "bbox": [98, 276, 401, 374], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Examples of regions where fibers are present but the diffusion tensor is planar: (left) kissing fibers, (middle) two fiber bundles crossing and (right) diver- gence/convergence of fibers. Regions that are marked grey will have a tensor with planar diffusion. ", "caption_bbox": [98, 385, 400, 459]}, {"image_id": 3, "file_name": "171_03.png", "page": 5, "dpi": 300, "bbox": [98, 115, 734, 456], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Table T and its corresponding meshes at different iterations, inserting point 1,2,7, and 19.", "caption_bbox": [162, 467, 666, 480]}, {"image_id": 4, "file_name": "171_04.png", "page": 6, "dpi": 300, "bbox": [100, 118, 729, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Streamlines and streamsurfaces traced in a healthy adult brain data set with TCl = 0.2 and TCp = 0.4: a) streamsur- face with a hole generated at the end of a streamline given one seed point. b) One streamline traced given a seed point c) the same seed point as b but tracing streamsurfaces and showing the possible prolongation of the fiber bundle d) streamlines using three seed points e) the same seed points as d with tracing streamsurfaces and showing the possible prolongation of the fiber bundle. ", "caption_bbox": [98, 369, 733, 446]}, {"image_id": 5, "file_name": "171_05.png", "page": 8, "dpi": 300, "bbox": [107, 113, 711, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Evenly-spaced volume seeding in a pig optic nerve (64x64x128) DTI data set. The pig optic nerve has been extracted and twisted before acquisition. a) dc is not used, b) a dc = 12 dl , c) is as b but adding distance-dependent tube thickness. ", "caption_bbox": [98, 334, 733, 366]}, {"image_id": 6, "file_name": "171_06.png", "page": 9, "dpi": 300, "bbox": [106, 113, 410, 457], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: a) Streamlines traced in a data set of a mouse leg 64x64x128. b) Histogram of fibers of generated in a. ", "caption_bbox": [98, 467, 400, 496]}, {"image_id": 7, "file_name": "171_07.png", "page": 10, "dpi": 300, "bbox": [159, 112, 672, 382], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Streamlines in the corpus callosum of a neonate that suffered hypoxic ischemic injury b) same seed points as a) but streamsurfaces are traced. ", "caption_bbox": [98, 392, 733, 420]}, {"image_id": 8, "file_name": "171_08.png", "page": 11, "dpi": 300, "bbox": [192, 112, 638, 562], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Studies of fibers in the brain with different data sets. a) healthy adult with streamsurfaces, b) premature neonate missing corpus callosum (see arrow), c) and d) Show behavior of fibers in two data sets with tumors (see arrows) ", "caption_bbox": [98, 572, 732, 601]}], "172": [{"image_id": 0, "file_name": "172_00.png", "page": 2, "dpi": 300, "bbox": [98, 112, 401, 670], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Topological representations of the Benzene data set. (top) The topological skeleton looks visually cluttered due to the shown separation surfaces. (bottom) Visualization of the topological skeleton using connectors. ", "caption_bbox": [98, 680, 399, 739]}, {"image_id": 1, "file_name": "172_01.png", "page": 3, "dpi": 300, "bbox": [430, 112, 733, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Sources and sinks; (a) repelling node and (b) its icon; (c) repelling focus and (d) its icon; (e) attracting node and (f) its icon; (g) attracting focus and (h) its icon. ", "caption_bbox": [430, 271, 731, 315]}, {"image_id": 2, "file_name": "172_02.png", "page": 3, "dpi": 300, "bbox": [430, 335, 733, 458], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Repelling and attracting saddles; (a) repelling node saddle and (b) its icon; (c) repelling focus saddle and (d) its icon; (e) attracting node saddle and (f) its icon; (g) attracting focus saddle and (h) its icon. ", "caption_bbox": [430, 468, 731, 527]}, {"image_id": 3, "file_name": "172_03.png", "page": 3, "dpi": 300, "bbox": [430, 548, 733, 884], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Topological skeleton of the benzene data set showing saddle connectors and critical points. Left: Out- flow/inflow planes of the saddle points depicted with flat el- lipses. Right: Our enhanced design using elliptic cylinders. ", "caption_bbox": [430, 895, 731, 954]}, {"image_id": 4, "file_name": "172_04.png", "page": 4, "dpi": 300, "bbox": [437, 113, 725, 206], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Boundary plane z = zmin consisting of an in- flow area (blue), an outflow area (red), and their separat- ing boundary switch curve; shown are 4 vectors of v on the boundary switch curve, and one each in the inflow and out- flow area. ", "caption_bbox": [430, 217, 731, 292]}, {"image_id": 5, "file_name": "172_05.png", "page": 5, "dpi": 300, "bbox": [437, 402, 725, 493], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Description of a hyperbolic segment as a piece- wise rational quadratic B\u00e9zier curve. ", "caption_bbox": [430, 504, 731, 532]}, {"image_id": 6, "file_name": "172_06.png", "page": 5, "dpi": 300, "bbox": [437, 113, 725, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: a) boundary switch curve consisting of one in- bound segment (dark red) and one outbound segment (dark blue); they are separated by an inout point (green); b) sep- aration surface starting from an inbound segment in both forward and backward integration. ", "caption_bbox": [430, 306, 731, 380]}, {"image_id": 7, "file_name": "172_07.png", "page": 5, "dpi": 300, "bbox": [105, 113, 393, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: a) inbound point p0 on a boundary switch curve: v(p0 ) points into the inflow area, v\u0307(p0 ) points inside D; shown is a part of the stream line starting in p0 both in for- ward and backward integration; b) outbound point p0 on a boundary switch curve; v(p0 ) points into the outflow area, v\u0307(p0 ) points outside D; shown is a stream line close to p0 starting in the inflow area and leaving D in the outflow area. ", "caption_bbox": [98, 315, 399, 420]}, {"image_id": 8, "file_name": "172_08.png", "page": 6, "dpi": 300, "bbox": [105, 294, 394, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: a) inflow/outflow behavior on two faces of D creates two boundary switch curves on the shared edge; these boundary switch curves are always outbound seg- ments; b) inbound boundary switch point divides D into 3 areas A1 , A2 , A3 . ", "caption_bbox": [98, 395, 399, 469]}, {"image_id": 9, "file_name": "172_09.png", "page": 6, "dpi": 300, "bbox": [106, 112, 393, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: a) boundary switch point on a vertex of the rect- angular domain of a 2D vector field; b) inbound segments on the edges of D do not exist. ", "caption_bbox": [98, 228, 399, 272]}, {"image_id": 10, "file_name": "172_10.png", "page": 7, "dpi": 300, "bbox": [105, 112, 393, 482], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Cases of intersection curves of separation sur- faces: a) saddle connectors; b)-e) boundary switch connec- tors. ", "caption_bbox": [98, 494, 399, 538]}, {"image_id": 11, "file_name": "172_11.png", "page": 7, "dpi": 300, "bbox": [438, 112, 725, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Finding the intersection of two separation sur- faces \u2013 one comes from a saddle, while the other one comes from a boundary switch curve; shown is the situation short before an intersection is found; in the next integration step an intersection point p1 is found which defines the boundary switch connector. ", "caption_bbox": [430, 262, 731, 351]}, {"image_id": 12, "file_name": "172_12.png", "page": 8, "dpi": 300, "bbox": [105, 112, 393, 174], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Number of features detected by our algorithms.", "caption_bbox": [439, 291, 723, 304]}], "173": [{"image_id": 0, "file_name": "173_00.png", "page": 2, "dpi": 300, "bbox": [463, 707, 701, 881], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: UT VisLab Environment", "caption_bbox": [494, 892, 667, 905]}, {"image_id": 1, "file_name": "173_01.png", "page": 3, "dpi": 300, "bbox": [444, 401, 718, 502], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Three types of sound sources", "caption_bbox": [482, 510, 680, 523]}, {"image_id": 2, "file_name": "173_02.png", "page": 6, "dpi": 300, "bbox": [501, 329, 662, 451], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Listener and Volume Source", "caption_bbox": [484, 462, 677, 475]}, {"image_id": 3, "file_name": "173_03.png", "page": 6, "dpi": 300, "bbox": [122, 542, 377, 680], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Computing \u2206V", "caption_bbox": [184, 683, 311, 701]}, {"image_id": 4, "file_name": "173_04.png", "page": 7, "dpi": 300, "bbox": [131, 837, 369, 918], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Capturing User Movement", "caption_bbox": [155, 930, 342, 943]}], "174": [{"image_id": 0, "file_name": "174_00.png", "page": 1, "dpi": 300, "bbox": [586, 1078, 809, 1151], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example of a curved quadratic tetrahedron having ten control points; one for each corner and one at the mid- point of each edge. (Interior parameter lines, on the faces, are shown to indicate curvature.) ", "caption_bbox": [430, 897, 731, 956]}, {"image_id": 1, "file_name": "174_01.png", "page": 2, "dpi": 300, "bbox": [165, 114, 336, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Ray casting of an MRI (magnetic resonance imag- ing) data set of human head. ", "caption_bbox": [98, 308, 399, 336]}, {"image_id": 2, "file_name": "174_02.png", "page": 4, "dpi": 300, "bbox": [161, 116, 338, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Intersection of line l(s) with linear-edge quadratic triangle T (u, v) at points a and b. ", "caption_bbox": [98, 302, 399, 332]}, {"image_id": 3, "file_name": "174_03.png", "page": 4, "dpi": 300, "bbox": [435, 354, 729, 494], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Transformation of line l(s) in xy-space to l \u22121 (t) in uv-space by the inverse transformation of the curved- quadratic triangle T (u, v). ", "caption_bbox": [430, 502, 731, 553]}, {"image_id": 4, "file_name": "174_04.png", "page": 5, "dpi": 300, "bbox": [432, 116, 732, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Inverse transformation of vector v\u2014located at point p = T (u)\u2014through curved-quadratic mapping T (u, v). Vector v is transformed from physical space to vector w in parameter space by considering the linear combination v = \u03b1X + \u03b2Y, where w = (\u03b1, \u03b2)T . ", "caption_bbox": [430, 264, 731, 342]}, {"image_id": 5, "file_name": "174_05.png", "page": 5, "dpi": 300, "bbox": [431, 380, 732, 498], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Quadratic curve C(t) approximates the inverse of line l(s) based on the curved-quadratic mapping T (u, v). ", "caption_bbox": [430, 514, 731, 544]}, {"image_id": 6, "file_name": "174_06.png", "page": 6, "dpi": 300, "bbox": [449, 112, 720, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Ray casting of curved-quadratic tetrahedron T (u, v, w) having non-uniform density\u2014where corner coef- ficients are zero and edge coefficients are one. Left image shows a rendering of the curved \u201cfaces\u201d of T (u, v, w). Right image shows ray casting of T (u, v, w). Isosurfaces are for a small range of values near {0.2, 0.575, 0.725}. The \u201cegg\u201d corresponds to the isosurface at 0.725 and the corners cor- respond to 0.2. ", "caption_bbox": [430, 300, 731, 420]}, {"image_id": 7, "file_name": "174_07.png", "page": 7, "dpi": 300, "bbox": [157, 113, 342, 401], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Ray casting of 320  curved-quadratic                                                tetrahedra                                2   2   2 approximating f (x, y, z) = 4 x + y + z ,\u2212 2 \u2264 x, y, z \u2264                             3                1 ", "caption_bbox": [98, 411, 399, 444]}, {"image_id": 8, "file_name": "174_08.png", "page": 8, "dpi": 300, "bbox": [433, 739, 728, 819], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Discrete sampling of cutting plane. Rays are cast through data and then sampled discretely to construct a uni- form rectilinear grid that represents the cutting plane. Left image shows rays\u2014lying on the cutting plane\u2014used to inter- sect elements. Middle image shows discretely sampled rays. Right image shows resulting uniform rectilinear grid used for visualization. ", "caption_bbox": [430, 833, 731, 938]}, {"image_id": 9, "file_name": "174_09.png", "page": 8, "dpi": 300, "bbox": [493, 113, 672, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Intersection of plane and curved-quadratic tetra- hedron. Difficulties arise since the plane can intersect the tetrahedron without intersecting its edges. (In this paper, quadratic tetrahedra are often rendered with parametric lines on the faces of the element. These lines help show the curvature of the element. Plane R intersects the parametric lines shown on the faces of tetrahedron T , however, these lines are not as useful as the edges of the tetrahedron.) ", "caption_bbox": [430, 320, 731, 440]}, {"image_id": 10, "file_name": "174_10.png", "page": 8, "dpi": 300, "bbox": [183, 114, 316, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Indexing used for curved-quadratic tetrahedron.", "caption_bbox": [101, 331, 395, 344]}, {"image_id": 11, "file_name": "174_11.png", "page": 9, "dpi": 300, "bbox": [126, 368, 354, 648], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Two cutting planes intersecting curved-quadratic tetrahedron. ", "caption_bbox": [98, 666, 399, 694]}, {"image_id": 12, "file_name": "174_12.png", "page": 10, "dpi": 300, "bbox": [470, 133, 696, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Ray casting of 320 curved-quadratic tetrahedra approx-                                        imating f (x, y, z) = 34 x2 + y2 + z2 ,\u2212 12 \u2264 x, y, z \u2264 12 . The curved tetrahedra are produced by twisting the mesh a quarter turn from the top to the bottom. Isosurfaces are for a small range of values near {0.2, 0.43, 0.5}. The \u201csphere\u201d corresponds to the isosurface at 0.2. ", "caption_bbox": [437, 362, 729, 445]}, {"image_id": 13, "file_name": "174_13.png", "page": 10, "dpi": 300, "bbox": [147, 125, 373, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Ray casting of curved-quadratic tetrahedron T (u, v, w) having non-uniform density\u2014where corner coefficients are zero and edge coefficients are one. Top image shows a rendering of the curved \u201cfaces\u201d of T (u, v, w). Bottom image shows ray cast- ing of T (u, v, w). Isosurfaces are for a small range of values near {0.2, 0.575, 0.725}. The \u201cegg\u201d corresponds to the isosurface at 0.725 and the corners correspond to 0.2. ", "caption_bbox": [115, 359, 407, 457]}], "175": [{"image_id": 0, "file_name": "175_00.png", "page": 4, "dpi": 300, "bbox": [446, 761, 717, 870], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Combination of error measures.", "caption_bbox": [474, 881, 687, 894]}, {"image_id": 1, "file_name": "175_01.png", "page": 6, "dpi": 300, "bbox": [113, 471, 386, 666], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Frame rates for the golf video sequence using the golf video sequence using the different tessellation algo- rithms. ", "caption_bbox": [98, 871, 399, 915]}, {"image_id": 2, "file_name": "175_02.png", "page": 6, "dpi": 300, "bbox": [445, 111, 718, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 4: Prefiltering times for different environment resolu- tions and exponents. ", "caption_bbox": [430, 644, 731, 672]}, {"image_id": 3, "file_name": "175_03.png", "page": 7, "dpi": 300, "bbox": [474, 720, 689, 917], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Wheel rim model rendered with isophotes (32 units). ", "caption_bbox": [430, 927, 731, 955]}, {"image_id": 4, "file_name": "175_04.png", "page": 7, "dpi": 300, "bbox": [458, 110, 732, 530], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Normal deviation error for a frame of the rendered animation using geometric approximation without (top) and with normal maps (middle) and appearance preserving tes- sellation (bottom). ", "caption_bbox": [430, 540, 731, 599]}, {"image_id": 5, "file_name": "175_05.png", "page": 7, "dpi": 300, "bbox": [113, 243, 386, 438], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 6: Normal approximation error for the golf video se- quence using the different visualization algorithms. ", "caption_bbox": [98, 846, 399, 874]}, {"image_id": 6, "file_name": "175_06.png", "page": 8, "dpi": 300, "bbox": [142, 675, 357, 820], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The discontinuity becomes even more apparent with a reflection lines environment. ", "caption_bbox": [98, 830, 399, 858]}, {"image_id": 7, "file_name": "175_07.png", "page": 8, "dpi": 300, "bbox": [474, 190, 689, 632], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Three frames from an animation sequence show- ing a deformable NURBS surface. The elevation in the mid- dle frame is about 0.1% of the edge length. Note that stan- dard tessellation would only generate two triangles in this case. ", "caption_bbox": [430, 643, 731, 717]}, {"image_id": 8, "file_name": "175_08.png", "page": 8, "dpi": 300, "bbox": [142, 187, 357, 481], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Close up of the wheel rim model with standard tessellation (top) and appearance preserving tessellation (bottom) using isophotes visualization. The discontinuity is clearly visible only when using appearance preserving tes- sellation. ", "caption_bbox": [98, 491, 399, 565]}, {"image_id": 9, "file_name": "175_09.png", "page": 10, "dpi": 300, "bbox": [98, 738, 728, 909], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: A frame from the golf video sequence showing the results of standard tessellation (left), normal maps (middle) and appearance preserving tessellation (right). Note that although the reflections seem to be correct for the normal map method, they are all shifted due to the discretization of the normals leading to false conclusions or even fake discontinuities. ", "caption_bbox": [99, 920, 729, 964]}], "176": [{"image_id": 0, "file_name": "176_00.png", "page": 5, "dpi": 300, "bbox": [113, 636, 386, 931], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Tiling in the hierarchical acceleration scheme", "caption_bbox": [107, 942, 389, 955]}, {"image_id": 1, "file_name": "176_01.png", "page": 5, "dpi": 300, "bbox": [106, 121, 722, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Diffusion error (a,c). Correct skeletons (b,d)", "caption_bbox": [277, 324, 552, 337]}, {"image_id": 2, "file_name": "176_02.png", "page": 6, "dpi": 300, "bbox": [142, 595, 352, 772], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Hierarchical acceleration algorithm", "caption_bbox": [131, 798, 366, 811]}, {"image_id": 3, "file_name": "176_03.png", "page": 6, "dpi": 300, "bbox": [98, 112, 415, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Software FDT Timings", "caption_bbox": [500, 588, 661, 601]}, {"image_id": 4, "file_name": "176_04.png", "page": 7, "dpi": 300, "bbox": [98, 652, 415, 929], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Generalized Voronoi diagrams and skeletons", "caption_bbox": [109, 942, 386, 955]}, {"image_id": 5, "file_name": "176_05.png", "page": 8, "dpi": 300, "bbox": [126, 429, 705, 607], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Feature preserving evolution", "caption_bbox": [316, 620, 513, 633]}, {"image_id": 6, "file_name": "176_06.png", "page": 8, "dpi": 300, "bbox": [192, 112, 638, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Euclidean versus Manhattan distances in Voronoi diagrams", "caption_bbox": [239, 394, 590, 407]}, {"image_id": 7, "file_name": "176_07.png", "page": 9, "dpi": 300, "bbox": [128, 112, 371, 375], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Subpixel resolution scheme", "caption_bbox": [154, 386, 343, 399]}, {"image_id": 8, "file_name": "176_08.png", "page": 9, "dpi": 300, "bbox": [98, 423, 401, 584], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Subpixel versus pixel resolution skeletons", "caption_bbox": [118, 595, 378, 608]}, {"image_id": 9, "file_name": "176_09.png", "page": 10, "dpi": 300, "bbox": [130, 117, 701, 674], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Hardware-based skeletonization applications. Neuron images (a,b). Rice plant roots (c,d)", "caption_bbox": [162, 686, 667, 699]}], "177": [{"image_id": 0, "file_name": "177_00.png", "page": 4, "dpi": 300, "bbox": [461, 168, 702, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Beech Cross Section (used by permission [Sic])", "caption_bbox": [435, 331, 725, 349]}, {"image_id": 1, "file_name": "177_01.png", "page": 5, "dpi": 300, "bbox": [115, 42, 716, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Age, Gender and Probability of High Salary for (a) Branch Cross-Section of Pink Highlighted Node and (b) Child Clusters Showing Middle and (c) Outermost Child ", "caption_bbox": [98, 196, 730, 229]}, {"image_id": 2, "file_name": "177_02.png", "page": 7, "dpi": 300, "bbox": [120, 42, 711, 478], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Census Data Example (a) Without Leaves (b) With Leaves Mapped to Probability of High Salary (c) Cluster View Showing Clustering of Age (d) Hours Worked and (e) Hours Worked for Entire Dataset ", "caption_bbox": [98, 485, 730, 518]}], "178": [{"image_id": 0, "file_name": "178_00.png", "page": 2, "dpi": 300, "bbox": [138, 113, 360, 372], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Moduls of the DBL-Browser framework.", "caption_bbox": [121, 384, 375, 397]}, {"image_id": 1, "file_name": "178_01.png", "page": 3, "dpi": 300, "bbox": [105, 112, 394, 390], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Example view of the browser application", "caption_bbox": [120, 400, 377, 413]}, {"image_id": 2, "file_name": "178_02.png", "page": 3, "dpi": 300, "bbox": [431, 380, 732, 713], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: BibTeX entry with abstract and citations", "caption_bbox": [453, 724, 708, 737]}, {"image_id": 3, "file_name": "178_03.png", "page": 4, "dpi": 300, "bbox": [472, 117, 739, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Time Line of coauthors", "caption_bbox": [496, 340, 665, 353]}, {"image_id": 4, "file_name": "178_04.png", "page": 4, "dpi": 300, "bbox": [440, 711, 723, 882], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Publications per journal.", "caption_bbox": [491, 896, 670, 909]}, {"image_id": 5, "file_name": "178_05.png", "page": 5, "dpi": 300, "bbox": [154, 533, 344, 674], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Relations between the author and the coauthors.", "caption_bbox": [101, 686, 396, 699]}, {"image_id": 6, "file_name": "178_06.png", "page": 5, "dpi": 300, "bbox": [438, 360, 724, 485], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Conference/Journal relationships", "caption_bbox": [470, 498, 690, 511]}], "179": [{"image_id": 0, "file_name": "179_00.png", "page": 2, "dpi": 300, "bbox": [98, 556, 401, 724], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A simple pixel shader computing a post- interpolative texture lookup. ", "caption_bbox": [98, 726, 399, 759]}, {"image_id": 1, "file_name": "179_01.png", "page": 3, "dpi": 300, "bbox": [98, 112, 401, 543], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A more complex pixel shader computing gradients and local diffuse illumination. ", "caption_bbox": [98, 545, 399, 578]}, {"image_id": 2, "file_name": "179_02.png", "page": 4, "dpi": 300, "bbox": [98, 367, 401, 520], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The manipulation of 2D Transfer functions is done via an editor show here. In the background a 2D histogram of a CT dataset is shown. It contains typical parabola- shapes which arise from boundaries with partial volume ef- fects between different tissues. ", "caption_bbox": [98, 527, 399, 605]}, {"image_id": 3, "file_name": "179_03.png", "page": 4, "dpi": 300, "bbox": [139, 128, 358, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: 2D transfer functions are constructed by combin- ing different predefined shapes. Some examples are shown here, e.g. a parabola, a radial gradient, three tensor product based shapes and a triangular shape. ", "caption_bbox": [98, 283, 399, 346]}, {"image_id": 4, "file_name": "179_04.png", "page": 5, "dpi": 300, "bbox": [103, 123, 728, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Performance of the implemented rendering meth- ods. All measurements were done with a volume of 2563 cu- bic voxels with 8 bit precision per voxel using a 5122 view- port. The data have been sampled with a slice distance of one voxel and shading was done on the fly with a forward dif- ference scheme for gradient estimation. The graphics board was an NVIDIA GeForce FX 5900 ultra. ", "caption_bbox": [98, 694, 399, 803]}], "180": [{"image_id": 0, "file_name": "180_00.png", "page": 2, "dpi": 300, "bbox": [460, 359, 703, 649], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Immersive volume rendering workspace. The top illustration shows the workspace configuration. The bottom image shows standing interaction using the immersive 3D display. ", "caption_bbox": [430, 656, 731, 719]}, {"image_id": 1, "file_name": "180_01.png", "page": 3, "dpi": 300, "bbox": [490, 752, 673, 894], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Software framework for immersive volume render- ing. ", "caption_bbox": [430, 901, 731, 934]}, {"image_id": 2, "file_name": "180_02.png", "page": 5, "dpi": 300, "bbox": [98, 534, 401, 709], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Example joint-histogram of T2 and Proton Den- sity (PD) MRI scans. A shows the log-scale joint histogram with the corresponding scalar histograms for each scan seen at the left and top. B shows a joint histogram created by ex- cluding values with high multi-gradient magnitudes. The la- beled materials are: a cerebro-spinal fluid, b gray matter, c white matter, d fat, e background, f bone marrow. ", "caption_bbox": [98, 716, 399, 825]}], "181": [{"image_id": 0, "file_name": "181_00.png", "page": 2, "dpi": 300, "bbox": [460, 404, 703, 526], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization pipeline showing the data flow as arrows, and user adjustments, like filtering, as dashed ar- rows ", "caption_bbox": [430, 535, 731, 574]}, {"image_id": 1, "file_name": "181_01.png", "page": 3, "dpi": 300, "bbox": [430, 159, 733, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Fragment program diagram. The attribute IDs are combined ( \u02c6 ), prioritizing the image space mask, to select (&) one of the four volume components for each slab end. The ID also serves as Z coordinate for the transfer function lookup. ", "caption_bbox": [430, 350, 731, 415]}, {"image_id": 2, "file_name": "181_02.png", "page": 3, "dpi": 300, "bbox": [98, 338, 401, 510], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Comparison of linear interpolation (left) and nearest neighbor (right) when displaying categorical values. On the left one can clearly see the artifacts of a different color introduced in areas of otherwise uniform color. ", "caption_bbox": [98, 518, 399, 570]}, {"image_id": 3, "file_name": "181_03.png", "page": 3, "dpi": 300, "bbox": [459, 803, 704, 925], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Effect of 5 different transfer functions. The carp is segmented into two halves using a segmentation primitive, 4 lenses apply 4 different transfer functions in image space. ", "caption_bbox": [430, 933, 731, 972]}, {"image_id": 4, "file_name": "181_04.png", "page": 4, "dpi": 300, "bbox": [430, 762, 733, 892], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Before (left) and after (right) filtering the trees having an elevation lower than 85% of the elevation range. ", "caption_bbox": [430, 900, 731, 926]}, {"image_id": 5, "file_name": "181_05.png", "page": 4, "dpi": 300, "bbox": [437, 111, 726, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Picking linked between windows: The selection can be made in the detail view or in the corresponding table, the highlight is spanned across the windows. ", "caption_bbox": [430, 330, 731, 369]}, {"image_id": 6, "file_name": "181_06.png", "page": 5, "dpi": 300, "bbox": [142, 649, 357, 863], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Trees colored by type with a transfer function divided in 7 parts (see color plate). ", "caption_bbox": [98, 871, 399, 897]}, {"image_id": 7, "file_name": "181_07.png", "page": 5, "dpi": 300, "bbox": [459, 386, 704, 631], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: A detail view of the actual trees in regions of high elevation, coloring taken over from the transfer function in figure 9. ", "caption_bbox": [430, 639, 731, 678]}, {"image_id": 8, "file_name": "181_08.png", "page": 5, "dpi": 300, "bbox": [467, 111, 696, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Trees colored by type, filtered by a second transfer function making all trees beneath 85% elevation transparent ", "caption_bbox": [430, 349, 731, 375]}, {"image_id": 9, "file_name": "181_09.png", "page": 5, "dpi": 300, "bbox": [98, 111, 401, 279], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Collage of 4 wilderness clusters, FastMap with euclidean distances to the left (higher fragmentation), frac- tional distances ( f = 0.3) to the right (better defined clus- ters) ", "caption_bbox": [98, 287, 399, 339]}, {"image_id": 10, "file_name": "181_10.png", "page": 6, "dpi": 300, "bbox": [142, 111, 357, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Showing the trees of wilderness Rawah. Hue is produced by one transfer function on the tree type at- tribute and modulated by the transfer function filtering out the wilderness. ", "caption_bbox": [98, 334, 399, 386]}, {"image_id": 11, "file_name": "181_11.png", "page": 7, "dpi": 300, "bbox": [453, 111, 719, 378], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Trees colored by type with a transfer function divided in 7 parts. ", "caption_bbox": [439, 382, 731, 407]}, {"image_id": 12, "file_name": "181_12.png", "page": 7, "dpi": 300, "bbox": [119, 120, 371, 378], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Comparison of linear interpolation (left) and nearest neighbor (right) when displaying categorical val- ues. On the left one can clearly see the artifacts of a differ- ent color introduced in areas of otherwise uniform color. ", "caption_bbox": [98, 382, 390, 432]}], "183": [{"image_id": 0, "file_name": "183_00.png", "page": 1, "dpi": 300, "bbox": [586, 1078, 809, 1151], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A typical oil exploration data set containing subsurface structures, wells, and seismic slices. The subsurface model consists of two main structures: horizons and faults. Horizons separate two earth layers, and faults are breaks in the rocks, where one side is moved relative to the other. Horizons are typically horizontal while faults are inclined. Three orthogonal slicing planes are used to visualise the seismic volume. The inline-slice is typically perpendicular to the main fault direction. The time-slice is horizontal and the crossline-slice is perpendicular to both. ", "caption_bbox": [427, 896, 728, 1037]}, {"image_id": 1, "file_name": "183_01.png", "page": 2, "dpi": 300, "bbox": [96, 746, 400, 988], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Horizons are divided into tiles. The light blue tile in the middle of the image is the high resolution ver- sion. The other tiles around it are low resolution versions. ", "caption_bbox": [100, 987, 394, 1031]}, {"image_id": 2, "file_name": "183_02.png", "page": 6, "dpi": 300, "bbox": [96, 601, 401, 931], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The effect of the pixel threshold (0 pixels on top and 50 pixels on bottom) on the final image. For a threshold of 0 pixels 940k triangles are rendered, and for 50 pixels 476k. Some of the errors are marked. In these areas there are typically complete horizon tiles missing in the lower image. The colors are just arbitrarily chosen such that the horizon surface can be visually differentiated. ", "caption_bbox": [97, 935, 398, 1037]}, {"image_id": 3, "file_name": "183_03.png", "page": 6, "dpi": 300, "bbox": [426, 601, 732, 932], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The effect of different simplification factors (25 on top and 400 on bottom) on the final image. For a simplification factor of 25 there are 1388k triangles rendered for the final image, and for a factor of 400 there are 1280k triangles rendered. The pictures are enlarged versions of the critical areas and some errors are marked, where horizon tiles are missing. ", "caption_bbox": [427, 935, 728, 1037]}, {"image_id": 4, "file_name": "183_04.png", "page": 6, "dpi": 300, "bbox": [143, 129, 714, 556], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Two representative views onto the data. Both graphics cards behave pretty similar overall.", "caption_bbox": [146, 562, 651, 578]}], "184": [{"image_id": 0, "file_name": "184_00.png", "page": 2, "dpi": 300, "bbox": [102, 111, 397, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An example of a multiblock data representa- tion used in the simulation of flow around a space shut- tle launch vehicle. (The data set is available online at http://www.nas.nasa.gov/Research/. Visualization courtesy of Edward A. Mayda of the Department of Mechanical and Aeronautical Engineering at UC Davis.) ", "caption_bbox": [98, 281, 399, 370]}, {"image_id": 1, "file_name": "184_01.png", "page": 3, "dpi": 300, "bbox": [107, 112, 387, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Grid layouts in multiblock data sets. Many tech- niques exist to generate isocontours from (a) conforming grids and (b) semi-conforming grids, where some sample points are shared among grids at the interface. Relatively few techniques exist to generate isocontours from (c) non- conforming grids or from (d) overlapping grids. In these en- vironments, common methods for interpolation are not well defined, and it is unclear how to extract a continuous isosur- face representation. ", "caption_bbox": [98, 298, 399, 433]}, {"image_id": 2, "file_name": "184_02.png", "page": 4, "dpi": 300, "bbox": [164, 111, 668, 218], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Local RBF Construction. (a) The input is multiblock data. (b) The grid connectivity is disregarded. (c) Data points (shown as black dots) are binned into RBF grid cells. (d) Local RBFs are computed with centers placed at the center of the cells. An RBF center is shown here as a square point, and its radius of influence is shown as a shaded circle. To avoid visual clutter, only the three middle RBFs are shown. ", "caption_bbox": [98, 226, 731, 285]}, {"image_id": 3, "file_name": "184_03.png", "page": 5, "dpi": 300, "bbox": [131, 112, 367, 877], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Illustration of our isosurface generation method. (a) Marching Cubes triangles are generated inside each cell. (b) The point samples are generated in each triangle and then (c) projected onto the isosurface. (d) The point set is rendered using a surface splatting algorithm. ", "caption_bbox": [98, 887, 399, 961]}, {"image_id": 4, "file_name": "184_04.png", "page": 8, "dpi": 300, "bbox": [434, 113, 735, 877], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Isosurface visualization of a semi-conformal multiblock representation of the bucky ball data set. Top: View showing two grid resolutions. Middle: Marching Cubes results in cracks at the coarse-fine boundary. Bottom: Our method applied to the same data set produces a continuous closed isosurface representation. ", "caption_bbox": [430, 891, 731, 980]}, {"image_id": 5, "file_name": "184_05.png", "page": 9, "dpi": 300, "bbox": [117, 697, 730, 900], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A fuel injection data set represented by five overlapping grids. Left: A visualization of the five grids. Middle: A naive application of Marching Cubes produces several cracks and self-intersections in regions of overlap. Right: Our method generates a single continuous surface. Overlapping points are not a problem, as they project to a globally defined isosurface. ", "caption_bbox": [98, 911, 731, 955]}, {"image_id": 6, "file_name": "184_06.png", "page": 9, "dpi": 300, "bbox": [109, 113, 757, 617], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Isosurface visualization of a multiblock representation of the neghip data set. Top-left: Axis-aligned view showing two overlapping grids representing the data. Top-right: Marching Cubes triangles color-coded by grid. Notice the self-intersections and cracks in the isosurface. Bottom: Side-by-side comparison of Marching Cubes versus our approach. ", "caption_bbox": [98, 631, 731, 675]}], "185": [{"image_id": 0, "file_name": "185_00.png", "page": 2, "dpi": 300, "bbox": [468, 128, 695, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The evolutionary events that a feature may expe- rience. ", "caption_bbox": [430, 306, 731, 339]}, {"image_id": 1, "file_name": "185_01.png", "page": 4, "dpi": 300, "bbox": [125, 142, 748, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Four snapshots to illustrate how the correspondence relationship between isosurfaces from two consecutive time steps changes when the isovalue increases from v0 to v3 (v0 <v1 <v2 <v3 ). ", "caption_bbox": [98, 344, 730, 378]}, {"image_id": 2, "file_name": "185_02.png", "page": 4, "dpi": 300, "bbox": [469, 419, 695, 599], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Two previously corresponding components do not correspond to each other any more and the number of com- ponents in R3 remains the same when the isovalue changes. ", "caption_bbox": [430, 605, 731, 653]}, {"image_id": 3, "file_name": "185_03.png", "page": 5, "dpi": 300, "bbox": [138, 119, 358, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A plausible case where two pairs of components switch their correspondence without the change of number of isosurface components in R3 and R4 when the isovalue changes. ", "caption_bbox": [98, 299, 399, 362]}, {"image_id": 4, "file_name": "185_04.png", "page": 5, "dpi": 300, "bbox": [136, 390, 362, 565], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Another seemingly reasonable case: one compo- nent at each time step changes its correspondence when the isovalue changes but without the change of number of iso- surface components in R3 and R4 . ", "caption_bbox": [98, 572, 399, 635]}, {"image_id": 5, "file_name": "185_05.png", "page": 7, "dpi": 300, "bbox": [116, 111, 696, 419], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: The time to track the whole isosurface illustrated in figure 6 (in seconds). Timing from 5 time steps are shown due to space limitation. ", "caption_bbox": [430, 810, 731, 858]}, {"image_id": 6, "file_name": "185_06.png", "page": 8, "dpi": 300, "bbox": [116, 289, 711, 407], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: The time to track two isosurface components illus- trated in figure 8 (in seconds). Timing from time step 1, 2, 6, 7 and 14 are shown due to space limitation. ", "caption_bbox": [430, 796, 731, 844]}, {"image_id": 7, "file_name": "185_07.png", "page": 8, "dpi": 300, "bbox": [116, 111, 711, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: The time to track two isosurface components illus- trated in figure 7 (in seconds). Timing from time step 4, 9, 15 and 21 are shown due to space limitation. ", "caption_bbox": [98, 795, 399, 843]}], "186": [{"image_id": 0, "file_name": "186_00.png", "page": 2, "dpi": 300, "bbox": [104, 111, 736, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Four isosurfaces computed entirely by the GPU. The main application sends the vertices of the tetrahedra to the graphics card while a vertex program executed by the GPU computes the edge interpolation and the surface normals. (a) Aneurysm (rectilinear grid). (b) Skull (rectilinear grid). (c) Engine piece (unstructured mesh). (d) Blunt Fin (curvilinear grid). ", "caption_bbox": [98, 294, 731, 338]}, {"image_id": 1, "file_name": "186_01.png", "page": 3, "dpi": 300, "bbox": [144, 113, 357, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A tetrahedron with function values associated with each vertex. The gray polygons show three possible isosur- faces of the scalar field obtained by linear interpolation of the function values at the vertices. ", "caption_bbox": [98, 270, 399, 329]}, {"image_id": 2, "file_name": "186_02.png", "page": 5, "dpi": 300, "bbox": [108, 116, 394, 228], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Four steps of longest-edge-bisection for a rectilin- ear  grid.  Figure  3: (top              Fourrow)                     stepsConcurrent     refinement offortetrahedra                            of longest-edge-bisection                  and                                                           a rectilinear  grid. (top octree       row)          cells.    Concurrent                 Three    tiers ofrefinement                                   tetrahedralof refinement                                                 tetrahedra andareoctree                                                                    equiv-  cells. Three  tiers of tetrahedral  refinement are  equivalent alent to one level of octree refinement. (bottom row) A single  to  one ", "caption_bbox": [98, 236, 399, 295]}, {"image_id": 3, "file_name": "186_03.png", "page": 5, "dpi": 300, "bbox": [98, 732, 288, 997], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "ofthe  e     same longest    tetrahedra       edge               that share  Figure 4 shows the typ ", "caption_bbox": [287, 738, 398, 759]}, {"image_id": 4, "file_name": "186_04.png", "page": 7, "dpi": 300, "bbox": [96, 110, 400, 381], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Three levels of refinement of our 3D space-filling curve. The curve traverses once all the tetrahedra in the mesh, forming a tetrahedral strip. The base mesh is a pyra- mid with square basis (one sixth of a cube). (top row) Side view. (middle row) Bottom view. (bottom row) Test isosur- faces of a simple scalar field (distance from a point). ", "caption_bbox": [98, 384, 399, 473]}], "187": [{"image_id": 0, "file_name": "187_00.png", "page": 2, "dpi": 300, "bbox": [113, 111, 717, 216], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The rendering pipeline. Step 1: Object segmentation; Step 2: Iso-surface generation; Step 3: Iso-surface smoothing; Step 4: Rendering ", "caption_bbox": [98, 227, 731, 256]}, {"image_id": 1, "file_name": "187_01.png", "page": 3, "dpi": 300, "bbox": [153, 112, 678, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Surface smoothing: v1   0, v2   100, tiso   50. Left: Iso-surface initialized; Center: Iso-surface smoothed (high- lighted voxels are part of the reference mask - those which remained after the erosion were set to the value 100, the others acquired their values through equation 1); Right: Erroneously added voxels (highlighted) are removed from the object ", "caption_bbox": [98, 252, 731, 301]}, {"image_id": 2, "file_name": "187_02.png", "page": 3, "dpi": 300, "bbox": [106, 337, 394, 486], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Left: Object imported from binary mask without smoothing; Right: Smoothed object ", "caption_bbox": [98, 497, 399, 525]}, {"image_id": 3, "file_name": "187_03.png", "page": 5, "dpi": 300, "bbox": [130, 112, 702, 284], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The new optimizations and which parts of the original algorithm they require to be changed", "caption_bbox": [159, 296, 669, 309]}, {"image_id": 4, "file_name": "187_04.png", "page": 5, "dpi": 300, "bbox": [158, 344, 341, 467], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Silhouette lines (solid), frontier lines (dotted), vis- ibility coefficients and an example scan line ", "caption_bbox": [98, 479, 399, 507]}, {"image_id": 5, "file_name": "187_05.png", "page": 6, "dpi": 300, "bbox": [452, 112, 711, 391], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Increased ray-tracking distance caused by ray segment concatenation ", "caption_bbox": [430, 401, 731, 429]}, {"image_id": 6, "file_name": "187_06.png", "page": 6, "dpi": 300, "bbox": [105, 112, 394, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Ray segment concatenation and concat values", "caption_bbox": [107, 329, 390, 342]}, {"image_id": 7, "file_name": "187_07.png", "page": 7, "dpi": 300, "bbox": [482, 112, 681, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Tracking ray segments backwards: During pro- cessing of macro-cell M2, rays 1 and 3 encounter no inter- section, therefore ray 2 is erroneously skipped. Macro-cell M1 is processed after M2. The entry point of ray 2 into M1 is inside the object - the ray must be traced backwards. ", "caption_bbox": [430, 300, 731, 374]}, {"image_id": 8, "file_name": "187_08.png", "page": 8, "dpi": 300, "bbox": [106, 113, 391, 471], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Pseudo code of the rasterization process", "caption_bbox": [121, 483, 376, 496]}, {"image_id": 9, "file_name": "187_09.png", "page": 11, "dpi": 300, "bbox": [107, 684, 723, 891], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Other applications: Left: A segmented heart; Center: A segmented head; Right: Assessment of stent placement", "caption_bbox": [109, 901, 719, 914]}, {"image_id": 10, "file_name": "187_10.png", "page": 11, "dpi": 300, "bbox": [145, 385, 686, 632], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Virtual bronchoscopy: Background objects are a tumor, the pulmonary artery and the aorta", "caption_bbox": [157, 643, 672, 656]}, {"image_id": 11, "file_name": "187_11.png", "page": 11, "dpi": 300, "bbox": [113, 112, 717, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Left: Moving through the nose, the tumor still far away; Center: Inside the sinus sphenoidalis; Right: The sella floor has been opened ", "caption_bbox": [98, 329, 731, 358]}], "188": [{"image_id": 0, "file_name": "188_00.png", "page": 4, "dpi": 300, "bbox": [456, 321, 704, 375], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Blending strength, left: skeleton, middle: high blending strength, right: reduced blending strength ", "caption_bbox": [430, 396, 731, 424]}, {"image_id": 1, "file_name": "188_01.png", "page": 4, "dpi": 300, "bbox": [176, 111, 323, 255], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Filter functions for convolution surfaces, (a): Gaussian [Blo95], (b) 1/d(p, H)3 and (c) r2 /d(p, H)2 , r = 1 as used in [HAC03] ", "caption_bbox": [98, 276, 355, 320]}, {"image_id": 2, "file_name": "188_02.png", "page": 5, "dpi": 300, "bbox": [445, 682, 719, 753], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Transition at branching, left: skeleton, middle: convolved with original filter, right: convolved with modified filter ", "caption_bbox": [430, 764, 731, 808]}, {"image_id": 3, "file_name": "188_03.png", "page": 5, "dpi": 300, "bbox": [508, 211, 655, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Original Gaussian function (d) from Bloomenthal compared to the modified version of our method (e). ", "caption_bbox": [430, 368, 731, 396]}, {"image_id": 4, "file_name": "188_04.png", "page": 5, "dpi": 300, "bbox": [130, 316, 384, 368], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Bulging problem, left: skeleton, middle: convolu- tion surface, right: Bulge at the branching in horizontal view ", "caption_bbox": [98, 389, 399, 417]}, {"image_id": 5, "file_name": "188_05.png", "page": 6, "dpi": 300, "bbox": [127, 266, 371, 449], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Unwanted blending, Distance between the branches of the S-shapes is 3 mm. The radius of all branches is 1.07 mm in the upper row and 1.37 in the lower row. Un- wanted blending (left) is considerably reduced with the nar- rower filter (right). ", "caption_bbox": [98, 459, 399, 533]}, {"image_id": 6, "file_name": "188_06.png", "page": 6, "dpi": 300, "bbox": [127, 113, 371, 206], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Side view to skeleton used in Fig. 5. The bulging problem (left) is avoided with the modified filter (right). ", "caption_bbox": [98, 217, 399, 245]}, {"image_id": 7, "file_name": "188_07.png", "page": 6, "dpi": 300, "bbox": [459, 334, 704, 429], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Axes-aligned bounding boxes (left) and cylindri- cal bounding volumes (right) for an artificial tree (right) ", "caption_bbox": [430, 439, 731, 467]}, {"image_id": 8, "file_name": "188_08.png", "page": 6, "dpi": 300, "bbox": [459, 499, 704, 640], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Voxel selection for a single line segment. Green spheres mark midpoints of voxels which are within the AABB of this segment. Dark green spheres mark midpoints of vox- els which passed the cylindrical bounding volume test. ", "caption_bbox": [430, 651, 731, 710]}, {"image_id": 9, "file_name": "188_09.png", "page": 7, "dpi": 300, "bbox": [474, 172, 689, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Lasso selection and defocused visualization of the selected vessel segments. Inside the semitransparent ves- sels the centerline is presented. ", "caption_bbox": [430, 344, 731, 388]}, {"image_id": 10, "file_name": "188_10.png", "page": 8, "dpi": 300, "bbox": [112, 111, 386, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The visualization method described by Hahn et al. [HPSP01] (concatenated truncated cones) and our method are combined. The convolution surfaces are ren- dered as wire-frame while the results of the other method are shaded. ", "caption_bbox": [98, 285, 399, 359]}, {"image_id": 11, "file_name": "188_11.png", "page": 8, "dpi": 300, "bbox": [459, 200, 732, 397], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: The convolution surface is completely enclosed by the visualization of the vessel segmentation result. ", "caption_bbox": [430, 412, 731, 440]}, {"image_id": 12, "file_name": "188_12.png", "page": 8, "dpi": 300, "bbox": [445, 745, 719, 851], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Close-up of a visualization with truncated cones with artifacts along the seams. Smooth visualization with im- plicit functions of the same dataset. ", "caption_bbox": [430, 861, 731, 905]}, {"image_id": 13, "file_name": "188_13.png", "page": 8, "dpi": 300, "bbox": [127, 377, 371, 562], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: A close-up of the visualization from Fig:11", "caption_bbox": [112, 572, 385, 585]}, {"image_id": 14, "file_name": "188_14.png", "page": 9, "dpi": 300, "bbox": [120, 725, 379, 916], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 17: Visualization of a bronchial tree derived from a clinical CT dataset with 1504 edges. ", "caption_bbox": [98, 927, 399, 955]}, {"image_id": 15, "file_name": "188_15.png", "page": 9, "dpi": 300, "bbox": [120, 342, 379, 518], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Visualization of cerebral blood vessels derived from a clinical MR angiography with 149 edges. ", "caption_bbox": [98, 529, 399, 557]}, {"image_id": 16, "file_name": "188_16.png", "page": 9, "dpi": 300, "bbox": [452, 111, 711, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 18: Visualization of vascular structures with other intrahepatic structures for liver surgery planning. ", "caption_bbox": [430, 292, 731, 320]}, {"image_id": 17, "file_name": "188_17.png", "page": 9, "dpi": 300, "bbox": [112, 111, 386, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Performance measurements for anatomic tree structures ", "caption_bbox": [430, 489, 731, 517]}], "189": [{"image_id": 0, "file_name": "189_00.png", "page": 2, "dpi": 300, "bbox": [375, 66, 692, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Scan conversion (warp) of the original data dur- ing reconstruction. ", "caption_bbox": [391, 338, 692, 366]}, {"image_id": 1, "file_name": "189_01.png", "page": 2, "dpi": 300, "bbox": [58, 64, 375, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Interpolation between two nearest scans using a circular arc to locate corresponding points on B-scan slices. ", "caption_bbox": [59, 312, 360, 340]}, {"image_id": 2, "file_name": "189_02.png", "page": 3, "dpi": 300, "bbox": [375, 64, 694, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Geometry of the fan acquired dataset and close- up of the positions (10 out of 1182 samples) ", "caption_bbox": [391, 353, 692, 381]}, {"image_id": 3, "file_name": "189_03.png", "page": 4, "dpi": 300, "bbox": [375, 66, 694, 179], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Normalization of different ECG-traces. The effect of the procedure at the t-wave (left) before (right) after the normalization process. ", "caption_bbox": [391, 189, 692, 233]}, {"image_id": 4, "file_name": "189_04.png", "page": 5, "dpi": 300, "bbox": [375, 64, 695, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Filling spaces between slices by interpolation along spherical arcs. (l) small, (m) medium, and (c) large angles between sucessive slices. ", "caption_bbox": [391, 300, 692, 344]}, {"image_id": 5, "file_name": "189_05.png", "page": 5, "dpi": 300, "bbox": [59, 66, 378, 486], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Parametric situation for the interpolation of a single data point. ", "caption_bbox": [59, 496, 360, 524]}, {"image_id": 6, "file_name": "189_06.png", "page": 6, "dpi": 300, "bbox": [375, 66, 694, 405], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Excerpt of a MIP stack. Top: original frame, mid- dle: frame at level 4, bottom: frame at level 7 ", "caption_bbox": [391, 415, 692, 443]}, {"image_id": 7, "file_name": "189_07.png", "page": 8, "dpi": 300, "bbox": [58, 64, 692, 514], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Octree statistics. Percentage of leafs per level. In both cases less than 20% of all nodes are used in total. ", "caption_bbox": [59, 812, 360, 840]}, {"image_id": 8, "file_name": "189_08.png", "page": 9, "dpi": 300, "bbox": [375, 64, 694, 499], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Volume rendering of a reconstructed ultrasound data set at a very coarse level. The image clearly exhibits the octree structure for a reconstruction based on two slices. (Artefacts at the sides due to gradient opacity mapping dur- ing visualization) ", "caption_bbox": [391, 509, 692, 583]}, {"image_id": 9, "file_name": "189_09.png", "page": 9, "dpi": 300, "bbox": [59, 66, 378, 499], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Volume rendering of a reconstructed ultrasound data set. The image shows the left ventricle in the long axis view. (Artefacts at the front and bottom due to gradient opac- ity mapping during visualization) ", "caption_bbox": [59, 509, 360, 568]}, {"image_id": 10, "file_name": "189_10.png", "page": 10, "dpi": 300, "bbox": [58, 64, 693, 232], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Slice sequence of reconstructed volume with a temporal offset of 20% heart cycle.", "caption_bbox": [139, 243, 609, 256]}], "190": [{"image_id": 0, "file_name": "190_00.png", "page": 3, "dpi": 300, "bbox": [145, 113, 686, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Mapping between logical 3D memory and physical 2D memory by means of a lookup table.", "caption_bbox": [160, 323, 669, 341]}, {"image_id": 1, "file_name": "190_01.png", "page": 4, "dpi": 300, "bbox": [138, 310, 361, 378], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Basic structure of the injection mechanism of IBFV. ", "caption_bbox": [98, 390, 399, 423]}, {"image_id": 2, "file_name": "190_02.png", "page": 4, "dpi": 300, "bbox": [438, 112, 722, 336], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Reordering of stack direction.", "caption_bbox": [480, 344, 682, 362]}, {"image_id": 3, "file_name": "190_03.png", "page": 5, "dpi": 300, "bbox": [98, 112, 733, 568], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: 3D advection for a tornado data set with volume rendering based on the emission-absorption model (a), Phong illumination (b), cool/warm shading (c), depth cueing (d), halos (e), and velocity masking (f). ", "caption_bbox": [98, 573, 730, 606]}, {"image_id": 4, "file_name": "190_04.png", "page": 6, "dpi": 300, "bbox": [430, 112, 733, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Benard flow with \u03bb2 vortex visualization.", "caption_bbox": [450, 315, 708, 334]}], "191": [{"image_id": 0, "file_name": "191_00.png", "page": 3, "dpi": 300, "bbox": [158, 740, 341, 891], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Processing pipeline for streamline rendering. Life- cycle of streamlines is divided into phases seeding (S), ad- vection (A), and expiration (E). ", "caption_bbox": [98, 898, 399, 946]}, {"image_id": 1, "file_name": "191_01.png", "page": 8, "dpi": 300, "bbox": [450, 112, 708, 883], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Animation with dense geometric flow visualiza- tion applied to unsteady flow of jets data set. Pathlines are rendered at time steps 1120, 1400, and 1800. ", "caption_bbox": [430, 888, 731, 936]}, {"image_id": 2, "file_name": "191_02.png", "page": 9, "dpi": 300, "bbox": [163, 112, 664, 589], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Dense geometric flow visualization applied to steady flow. Tornado data set: Streamlines are rendered using (a) haloing and flow orientation or (b) depth sorting and illumination in conjuction with depth-based attenuation. MDTFs are used for feature extraction, e. g., regions of high curl magnitude (c). Time step 1500 of jets data set: MDTFs extract regions of high curl magnitude and high velocity magnitude (d). ", "caption_bbox": [98, 594, 730, 657]}], "192": [{"image_id": 0, "file_name": "192_00.png", "page": 2, "dpi": 300, "bbox": [98, 118, 401, 422], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Variational Segmentation: Error-driven clustering is performed on various flow fields using the L2 metric for vector comparisons. Each color represents an area in which both direction and magnitude of the field is very similar, pro- viding an otherwise hidden insight into the system. ", "caption_bbox": [98, 425, 399, 503]}, {"image_id": 1, "file_name": "192_01.png", "page": 2, "dpi": 300, "bbox": [430, 216, 734, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Popular techniques of vector field visualization ap- plied to a non-trivial 2D dataset. ", "caption_bbox": [430, 312, 731, 344]}, {"image_id": 2, "file_name": "192_02.png", "page": 4, "dpi": 300, "bbox": [98, 118, 401, 456], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Application of various distortion metrics, 100 proxies. ", "caption_bbox": [98, 460, 399, 492]}, {"image_id": 3, "file_name": "192_03.png", "page": 4, "dpi": 300, "bbox": [168, 677, 330, 775], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "                                 fi = 0 Figure 4: Basis functions: Value of \u03c6i over a tetrahedron is shown via the color gradient. The vector \u2207\u03c6i has length 1/h where h is the height of the tetrahedron from base face F\u0303. ", "caption_bbox": [98, 774, 399, 828]}, {"image_id": 4, "file_name": "192_04.png", "page": 5, "dpi": 300, "bbox": [98, 111, 733, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Pipeline for visualizing a cylinder dataset during impact under non-slip conditions, 100k tetrahedra. Left: Variational segmentation into 200 regions. Middle-Left: Exploded view of the cluster volumes. Middle-Right: Streamlines initiated from the centroid of each cluster, terminated at the region boundary. Right: Thinning tubes drawn through the entire domain while adhering to a distance threshold. We use orthogonal shadows projected on the base planes for added 3D cues. ", "caption_bbox": [98, 340, 730, 403]}, {"image_id": 5, "file_name": "192_05.png", "page": 5, "dpi": 300, "bbox": [98, 411, 401, 503], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Lloyd\u2019s algorithm is applied to quickly drive down the distortion error. Through iterative partitioning and proxy fitting, the clustering converges in just a few steps. bitrary fields. Second, the metric can be easily altered: one especially useful metric for visualization is a weighted com- bination between the gradient tensor metric and a spatial po- sition metric. But more physically-driven metric choices can also be made. ", "caption_bbox": [98, 507, 399, 635]}, {"image_id": 6, "file_name": "192_06.png", "page": 6, "dpi": 300, "bbox": [98, 111, 733, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The effects of an increasing streamline distance threshold.", "caption_bbox": [244, 257, 584, 274]}, {"image_id": 7, "file_name": "192_07.png", "page": 7, "dpi": 300, "bbox": [98, 365, 733, 520], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Perspectives from the resulting visualization of the vehicle flow field in Figure 8, taken 30\u25e6 apart.", "caption_bbox": [147, 526, 682, 543]}, {"image_id": 8, "file_name": "192_08.png", "page": 7, "dpi": 300, "bbox": [98, 111, 733, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visualizing a flow field left in the wake of a moving automobile, 1.25 million tetrahedra. We cluster the dataset into 200 regions (Left; exploded view Middle-Left), initiate streamlines from the cluster centroids (Middle-Right) and ultimately apply thinning tubes and distance threshold for the final result (Right). Notice how a cross section of the station wagon (Left, red cluster) is preserved in the gradient tensor partition, and how turbulent flow is densely clustered leaving the area of sparse activity relatively untouched. ", "caption_bbox": [98, 279, 731, 357]}], "193": [{"image_id": 0, "file_name": "193_00.png", "page": 3, "dpi": 300, "bbox": [112, 112, 386, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: TreeJuxtaposer Quadtree Structure. The bottom level of the quadtree defines a grid with vertical lines be- tween each level of the topological tree and horizontal lines between each leaf. As the size of the tree grows, the cells be- come much wider than they are tall. For roughly balanced trees, increasing the size of the tree by one level halves the height of a cell while the width is made only slightly smaller. ", "caption_bbox": [98, 288, 399, 397]}, {"image_id": 1, "file_name": "193_01.png", "page": 4, "dpi": 300, "bbox": [99, 112, 401, 284], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Subtree Culling. Left: For any given subtree, we check the top-most and bottom-most leaves (marked in red) to determine if they map to the same pixel. Right: If so, then the entire subtree maps to the same row of pixels, with y- coordinate y2. We can then draw only the edges between the root of the subtree and the top-most leaf, marked in red. This flattened path maps to a single straight line on the screen. ", "caption_bbox": [98, 292, 399, 401]}, {"image_id": 2, "file_name": "193_02.png", "page": 4, "dpi": 300, "bbox": [174, 428, 327, 615], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Guaranteeing the visibility of marked edges in a small subtree. For the subtree starting at node 1, we must continue descending into the tree until we find a subtree that is either homogeneous, or either the top or bottom flattened path of all edges from the root to the top-most leaf is com- pletely marked. For the subtree starting at node 9, we see that all edges along the line from the root to the top-most leaf are marked, and we only need to draw the flattened path of edges for nodes 9, 10, and 11. ", "caption_bbox": [98, 624, 399, 763]}, {"image_id": 3, "file_name": "193_03.png", "page": 5, "dpi": 300, "bbox": [444, 112, 719, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Grid Structure. We replace the quadtree with a lightweight hierarchical grid that still allows stretchable navigation, but with decoupled horizontal and vertical lines. Each line is represented by a split value with respect to a set of two parent lines, shown by maroon annotation lines. Each node has a row index for a horizontal reference line plus a vertical offset from it (magenta), plus a column index for a vertical reference line plus a horizontal offset (green). ", "caption_bbox": [430, 347, 731, 471]}, {"image_id": 4, "file_name": "193_04.png", "page": 6, "dpi": 300, "bbox": [433, 112, 764, 366], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Data Structure Sizes. We compare the theoretical memory requirements of the quadtree-based TreeJuxtaposer (TJ), the optimized quadtree of TJC-Q, and the lightweight grid of TJC. These theoretical numbers were generated by inspecting class fields rather than instrumenting a running executable, so as not to include overhead due to language differences. As expected, the required memory for each data structure grows linearly, but the constant factor is smaller with TJC-Q and much smaller with TJC. Note that these numbers do not include edge attachment information for reasons described in Section 8. ", "caption_bbox": [430, 375, 731, 545]}, {"image_id": 5, "file_name": "193_05.png", "page": 7, "dpi": 300, "bbox": [105, 112, 402, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Drawing Performance. We show two performance measures for our drawing and culling algorithm: the time to draw the scene with vs. without culling, and the number of nodes drawn (with culling). Our new method achieves a near-constant drawing time for any size tree. Note that for the largest tree, we are not able to enqueue all nodes in the tree as the size of the vector grows too large for the applica- tion to fit in main memory. ", "caption_bbox": [98, 625, 399, 749]}, {"image_id": 6, "file_name": "193_06.png", "page": 8, "dpi": 300, "bbox": [101, 111, 374, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Screenshot ofTJC during interaction, running on a tree of 14.6 million nodes with a window size of 1024x768. ", "caption_bbox": [98, 349, 399, 382]}], "194": [{"image_id": 0, "file_name": "194_00.png", "page": 2, "dpi": 300, "bbox": [113, 42, 718, 418], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The i-Disc displaying several activated topics. A dark red typing topic in the middle ring activates and extends its children, among them a leaf topic in the outer ring displaying details: base name, associations, and dependencies. The exterior blue ring serves as a handle to rotate the model. ", "caption_bbox": [98, 425, 730, 473]}, {"image_id": 1, "file_name": "194_01.png", "page": 4, "dpi": 300, "bbox": [437, 430, 726, 622], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The two typing topics \"Products\" and \"Vendors\" on the inner ring in an activated state. The degree of pro- trusion of an activated topic is determined by the number of associations it shares. ", "caption_bbox": [430, 630, 731, 693]}, {"image_id": 2, "file_name": "194_02.png", "page": 5, "dpi": 300, "bbox": [105, 335, 394, 577], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An activated topic and one role of its associations. The radial length of the activated topic is determined by the number of associations it is part of. Top: The association label is minimized, and its connection to the topics hidden. Bottom: The label \"Subcategory\" and connections to several topics playing that role in the association. ", "caption_bbox": [98, 585, 399, 678]}, {"image_id": 3, "file_name": "194_03.png", "page": 5, "dpi": 300, "bbox": [437, 42, 726, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Three types of occurrences belonging to the topic \"expat\": a simple description, a Home Page, and several re- sources. A click on each of the rectangles opens the accord- ing resource. ", "caption_bbox": [430, 237, 731, 300]}], "195": [{"image_id": 0, "file_name": "195_00.png", "page": 2, "dpi": 300, "bbox": [101, 116, 730, 245], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An A RC T REES visualization of a scientific book. Arcs indicate references between images and paragraphs in the book. The circular glyphs indicate currently not visible relations. ", "caption_bbox": [98, 259, 731, 287]}, {"image_id": 1, "file_name": "195_01.png", "page": 3, "dpi": 300, "bbox": [430, 113, 732, 169], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A RC T REES layout (top) and metaphor (bottom).", "caption_bbox": [432, 180, 728, 193]}, {"image_id": 2, "file_name": "195_02.png", "page": 4, "dpi": 300, "bbox": [99, 323, 733, 424], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Color coding according to the hierarchy levels (top) and based on semantic information (bottom). Here, an XML file is visualized using different colors for different tag types in the leaf nodes. Inner nodes all represent the same kind of grouping tag so that level information can be given by alternating dark and bright rectangles. ", "caption_bbox": [98, 435, 731, 478]}, {"image_id": 3, "file_name": "195_03.png", "page": 4, "dpi": 300, "bbox": [430, 518, 732, 689], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Drawing circular arcs (top) or Chaikin curves (bottom) to visualize relations. ", "caption_bbox": [430, 700, 731, 728]}, {"image_id": 4, "file_name": "195_04.png", "page": 4, "dpi": 300, "bbox": [98, 111, 733, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Different tree layouts depending on the node metric. All leaf nodes having the same width (top), node width depending on the number of direct children (middle), node width depending on the size of the subtree (bottom) ", "caption_bbox": [98, 273, 731, 301]}, {"image_id": 5, "file_name": "195_05.png", "page": 4, "dpi": 300, "bbox": [430, 755, 733, 846], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Encoding techniques used for relations.", "caption_bbox": [455, 857, 706, 870]}, {"image_id": 6, "file_name": "195_06.png", "page": 5, "dpi": 300, "bbox": [98, 321, 401, 379], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A tree containing three subtrees (top). All three nodes are collapsed. After interaction, the middle subtree is expanded one level (bottom). ", "caption_bbox": [98, 389, 399, 432]}, {"image_id": 7, "file_name": "195_07.png", "page": 6, "dpi": 300, "bbox": [98, 232, 401, 368], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Direct interaction with relations.", "caption_bbox": [140, 379, 357, 392]}, {"image_id": 8, "file_name": "195_08.png", "page": 6, "dpi": 300, "bbox": [98, 111, 733, 156], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: DOI based node metric. The focus is on the first node on the left. Note that no Focus+Context techniques have been applied here, this is just a visualization of the node metric. ", "caption_bbox": [98, 167, 731, 195]}, {"image_id": 9, "file_name": "195_09.png", "page": 7, "dpi": 300, "bbox": [105, 333, 725, 720], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Using A RC T REES to explore a scientific book. (a) shows the general structure of the book being divided into 21 chapters and an appendix. (b) shows that the topic that is treated in Chapter 16 builds on information from Chapters 3, 12, and 15. Selecting the wide arc finally results in (c), which allows a detailed exploration of the connections between both chapters. ", "caption_bbox": [98, 729, 731, 772]}, {"image_id": 10, "file_name": "195_10.png", "page": 7, "dpi": 300, "bbox": [99, 113, 732, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The complete interactive visualization with all additional tools present. This example shows the exploration of a person\u2019s calendar. Relations represent recurring events. ", "caption_bbox": [98, 283, 731, 311]}, {"image_id": 11, "file_name": "195_11.png", "page": 9, "dpi": 300, "bbox": [430, 388, 733, 516], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Direct interaction with relations.", "caption_bbox": [472, 522, 689, 535]}, {"image_id": 12, "file_name": "195_12.png", "page": 9, "dpi": 300, "bbox": [101, 116, 730, 245], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A complete A RC T REES visualization.", "caption_bbox": [294, 246, 536, 259]}, {"image_id": 13, "file_name": "195_13.png", "page": 9, "dpi": 300, "bbox": [99, 263, 733, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Ordinal (top) and semantic (bottom) color coding.", "caption_bbox": [262, 363, 566, 376]}, {"image_id": 14, "file_name": "195_14.png", "page": 9, "dpi": 300, "bbox": [98, 425, 401, 515], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Encoding techniques used for relations.", "caption_bbox": [123, 522, 374, 535]}], "196": [{"image_id": 0, "file_name": "196_00.png", "page": 2, "dpi": 300, "bbox": [431, 256, 731, 458], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Conventional EEG representation. Measured volt- ages for a five second time interval are shown, for five elec- trodes (indicated by the labels T3, C3, Cz, C4, and T4). ", "caption_bbox": [430, 470, 731, 514]}, {"image_id": 1, "file_name": "196_01.png", "page": 3, "dpi": 300, "bbox": [103, 115, 397, 351], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Butterfly plot, showing 0.1 s of data, for 128 elec- trodes. ", "caption_bbox": [98, 365, 399, 393]}, {"image_id": 2, "file_name": "196_02.png", "page": 3, "dpi": 300, "bbox": [445, 114, 705, 397], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Topographic array, for thirty electrodes.", "caption_bbox": [453, 410, 707, 423]}, {"image_id": 3, "file_name": "196_03.png", "page": 3, "dpi": 300, "bbox": [98, 560, 400, 616], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Topographic maps, for four consecutive time steps, including isolines. ", "caption_bbox": [98, 627, 399, 655]}, {"image_id": 4, "file_name": "196_04.png", "page": 4, "dpi": 300, "bbox": [432, 319, 719, 395], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Parallel coordinate representation for a hundred time steps and the same number of electrodes as in figure 6. ", "caption_bbox": [430, 409, 731, 437]}, {"image_id": 5, "file_name": "196_05.png", "page": 4, "dpi": 300, "bbox": [432, 116, 719, 192], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Parallel coordinate representation for two five- dimensional vectors, each of which represents one time step. For each vector, one connected line is drawn. The data have been recorded from five EEG electrodes simultaneously (la- beled T3, C3, Cz, C4, and T4). The voltage (\u00b5V ) is set out vertically. ", "caption_bbox": [430, 205, 731, 294]}, {"image_id": 6, "file_name": "196_06.png", "page": 4, "dpi": 300, "bbox": [101, 112, 401, 375], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: ERP images for the electrode labeled Cz. Top: ERP image without smoothing. Sixteen responses are color- coded separately. Bottom: Smoothened image. The average of three consecutive responses is color-coded. Below both ERP images, the (average) ERP is shown. ", "caption_bbox": [98, 386, 399, 460]}, {"image_id": 7, "file_name": "196_07.png", "page": 5, "dpi": 300, "bbox": [100, 519, 399, 599], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Density map, combined with minmax plot, for the data in figure 7, reflecting the distribution of the vector ele- ments along the vertical axes (dark grey for high, light grey for low densities). ", "caption_bbox": [98, 613, 399, 672]}, {"image_id": 8, "file_name": "196_08.png", "page": 5, "dpi": 300, "bbox": [432, 116, 731, 197], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Combination of parallel coordinates, the minmax plot, and the density map. ", "caption_bbox": [430, 210, 731, 238]}, {"image_id": 9, "file_name": "196_09.png", "page": 5, "dpi": 300, "bbox": [100, 116, 399, 196], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Minmax plot containing five tiles, showing the ex- treme values for five electrodes. For the 100 data vectors shown in figure 7, the intervals containing no vector ele- ments are excluded. The amplitude scale is indicated with a dashed line on the left, while the zero-level is indicated with a dotted line. ", "caption_bbox": [98, 210, 399, 299]}, {"image_id": 10, "file_name": "196_10.png", "page": 6, "dpi": 300, "bbox": [432, 117, 731, 560], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: TPC map for left-hand stimulation showing 116 channels. The same data set has been used again and the same time-steps are shown with connected lines as in figure 11. Locations where no electrodes were attached have been marked as \u2018xx\u2019. For each time-step, these have been assigned the averaged value over their neighbors. ", "caption_bbox": [430, 572, 731, 661]}, {"image_id": 11, "file_name": "196_11.png", "page": 6, "dpi": 300, "bbox": [99, 113, 398, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Two TPC maps, both offering a top view of 58 electrodes (nose on top) and showing EEG data for a left- hand and a right-hand SEP, respectively. Each tile corre- sponds to one electrode. The red and blue lines correspond to two time steps. In the plot below, linked brushing of points indicates the corresponding instants on the time axis. ", "caption_bbox": [98, 366, 399, 455]}], "197": [{"image_id": 0, "file_name": "197_00.png", "page": 1, "dpi": 300, "bbox": [98, 602, 733, 831], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Contrast-enhanced CT angiography data set. (a) Gradient-magnitude opacity-modulation. (b) Direct volume render- ing. (c) Direct volume rendering with cutting plane. (d) Context-preserving volume rendering. ", "caption_bbox": [98, 544, 731, 572]}, {"image_id": 1, "file_name": "197_01.png", "page": 2, "dpi": 300, "bbox": [116, 111, 383, 283], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Technical illustration using ghosting to display in- terior structures. ", "caption_bbox": [98, 299, 399, 327]}, {"image_id": 2, "file_name": "197_02.png", "page": 4, "dpi": 300, "bbox": [117, 112, 712, 692], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Context-preserving volume rendering of a contrast-enhanced CT angiography data set using different values for \u03bat and \u03bas . Columns have the same \u03bat value and rows have the same \u03bas value. ", "caption_bbox": [98, 695, 730, 728]}, {"image_id": 3, "file_name": "197_03.png", "page": 5, "dpi": 300, "bbox": [108, 113, 392, 276], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: CT scan of a tooth rendered with three different techniques. (a) Gradient-magnitude opacity-modulation. (b) Direct volume rendering with clipping plane. (c) Context- preserving volume rendering. ", "caption_bbox": [98, 285, 399, 344]}, {"image_id": 4, "file_name": "197_04.png", "page": 5, "dpi": 300, "bbox": [479, 112, 700, 720], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparing context-preserving volume rendering to illustration. (a) Context-preserving volume rendering of a hand data set. (b) Medical illustration using ghosting. ", "caption_bbox": [430, 729, 731, 773]}, {"image_id": 5, "file_name": "197_05.png", "page": 6, "dpi": 300, "bbox": [494, 111, 669, 363], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Contrast-enhanced CT scan of a torso rendered using context-preserving volume rendering. ", "caption_bbox": [430, 373, 731, 401]}, {"image_id": 6, "file_name": "197_06.png", "page": 6, "dpi": 300, "bbox": [196, 111, 303, 363], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Contrast-enhanced CT scan of a leg rendered us- ing context-preserving volume rendering. ", "caption_bbox": [98, 373, 399, 401]}, {"image_id": 7, "file_name": "197_07.png", "page": 7, "dpi": 300, "bbox": [106, 111, 396, 402], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Context-preserving volume rendering of the vis- ible human male CT data set. (a) Only global parameter settings are used. (b) Bone is made impenetrable by using data-dependent parameters. ", "caption_bbox": [98, 410, 399, 469]}], "198": [{"image_id": 0, "file_name": "198_00.png", "page": 2, "dpi": 300, "bbox": [439, 833, 743, 940], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Space-filling arrangements shown in 2D for a 4x4 block (a). Linear (in this case bilinear) interpolation requires 1-space-filling (b), whereas shading based on gradients requires 3-space-filling (c). ", "caption_bbox": [439, 945, 742, 1003]}, {"image_id": 1, "file_name": "198_01.png", "page": 2, "dpi": 300, "bbox": [445, 96, 741, 201], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview of block-based volumetric compression method for graphics hardware. Lossless compression (texture packing) stores only non-empty blocks and uses an index texture for mapping from the original volume domain to the packed volume. Lossy compression is similar to packing but uses a small representative set of blocks called the codebook instead of the packed texture. ", "caption_bbox": [439, 214, 743, 315]}, {"image_id": 2, "file_name": "198_02.png", "page": 3, "dpi": 300, "bbox": [113, 764, 401, 889], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The filter support for linear interpolation (a) and gradient calculation (b) shown in 2D. Any sample within this support will require decompression of V. If V must be decompressed separately for each sample then we will perform 4 decompressions of V in (a) and 12 decompressions of V in (b). Analogously, in 3D we will perform 8 decompressions for linear interpolation and 32 for gradient calculation. ", "caption_bbox": [113, 888, 400, 1003]}, {"image_id": 3, "file_name": "198_03.png", "page": 4, "dpi": 300, "bbox": [99, 94, 415, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The basic algorithm for deferred filtering. In the first pass (Step A) two consecutive slices are decompressed according to the axis with which the view is most closely aligned. In the second pass (Step B) the axis-aligned slab is rendered using sampling slices which lie in between the two decompressed volume slices. ", "caption_bbox": [97, 461, 416, 548]}, {"image_id": 4, "file_name": "198_04.png", "page": 4, "dpi": 300, "bbox": [106, 808, 408, 903], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Overview of integrated volume rendering and decompression. Whereas Lazy Decompression (LD) maps backward from volume space to compression space, Deferred Filtering (DF) maps forward from compression space to volume space. In mapping forward DF achieves greater efficiency by decompressing each voxel only once, regardless of how many times it is needed in filtering. ", "caption_bbox": [105, 903, 409, 1004]}, {"image_id": 5, "file_name": "198_05.png", "page": 5, "dpi": 300, "bbox": [109, 101, 742, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Implementation of deferred filtering. In the first pass we use proxy geometry to generate a fragment per voxel; possible configurations are simple quad (left), multiple slice-filling quads for static resolution of volume partitions (center), and multiple quads for region-selective decompression (right). Four consecutive slices stored in the four back pbuffer channels allow efficient linear interpolation and gradient calculation for a single slab. Finally, in the second pass sampling slices within the slab are composited in the front pbuffer surface. ", "caption_bbox": [107, 220, 740, 293]}, {"image_id": 6, "file_name": "198_06.png", "page": 6, "dpi": 300, "bbox": [123, 97, 398, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Calculation of the gradient using central differences for a given sample ( ) in a sampling slice requires six gradient samples ( ). In order to obtain the gradient samples we need to access the decompressed slices at the corresponding locations ( ). As the slices are stacked in the RGBA texture channels we need only five texture reads (horizontal lines). Calculation of the gradient samples then requires six lerps, using Zlerp as the interpolation weight. ", "caption_bbox": [109, 289, 405, 418]}, {"image_id": 7, "file_name": "198_07.png", "page": 9, "dpi": 300, "bbox": [432, 127, 752, 761], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparison of high quality volume rendering from compressed textures using lazy decompression (LD) vs. deferred filtering (DF). Images generated are almost identical, but DF is about 20 times faster than LD. ", "caption_bbox": [425, 760, 758, 818]}, {"image_id": 8, "file_name": "198_08.png", "page": 9, "dpi": 300, "bbox": [113, 151, 394, 621], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison of high quality volume rendering from packed textures using lazy decompression (LD) vs. deferred filtering (DF). Although DF is about 15% slower it allows significantly better compression. ", "caption_bbox": [113, 620, 400, 678]}], "199": [{"image_id": 0, "file_name": "199_00.png", "page": 3, "dpi": 300, "bbox": [111, 637, 402, 796], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The shear transform of the shear-warp factoriza- tion for two different viewing directions. ", "caption_bbox": [98, 806, 399, 839]}, {"image_id": 1, "file_name": "199_01.png", "page": 3, "dpi": 300, "bbox": [99, 114, 728, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Rendering pipeline of the shear-warp factorization in the frequency domain.", "caption_bbox": [196, 305, 629, 323]}, {"image_id": 2, "file_name": "199_02.png", "page": 3, "dpi": 300, "bbox": [447, 562, 719, 726], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Calculation of the sampling distance s for a given viewing vector ~vso and slice distance dk . ", "caption_bbox": [430, 735, 731, 769]}, {"image_id": 3, "file_name": "199_03.png", "page": 4, "dpi": 300, "bbox": [448, 113, 706, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The shift of the signal by axk is split into a spatial domain (axkSD ) and a frequency domain (axkFD ) fragment. ", "caption_bbox": [430, 223, 731, 257]}, {"image_id": 4, "file_name": "199_04.png", "page": 5, "dpi": 300, "bbox": [101, 114, 399, 249], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Error when zooming a slice of \u03c1ml with several spatial domain filters and by zero padding in the frequency domain. ", "caption_bbox": [98, 258, 399, 306]}, {"image_id": 5, "file_name": "199_05.png", "page": 5, "dpi": 300, "bbox": [100, 328, 399, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Error when shifting a slice of \u03c1ml for sub-pixels with several spatial domain filters and phase shifts in the frequency domain. ", "caption_bbox": [98, 470, 399, 518]}, {"image_id": 6, "file_name": "199_06.png", "page": 6, "dpi": 300, "bbox": [98, 111, 733, 470], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Quality comparison of the analytic dataset \u03c1ml with different reconstruction schemes. The first column shows refer- ence images rendered by analytically evaluating the \u03c1ml function. The images of the subsequent columns were rendered (from left to right) based on DN C2 2EF (B-spline) and D0 C0 1EF (Catmull-Rom spline) interpolation, and the new frequency domain based method applied to the \u03c1ml and the \u03c1mlext dataset. The first row displays an iso-surface extraction. The second row shows divergence images of the estimated gradient direction to the analytic reference gradient. The third row presents resampled center slices (x = 0) of the \u03c1ml and \u03c1mlext datasets. ", "caption_bbox": [98, 476, 731, 572]}, {"image_id": 7, "file_name": "199_07.png", "page": 7, "dpi": 300, "bbox": [98, 111, 733, 427], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The Stanford Bunny rendered (from left to right) with D0 C0 1EF (linear), DN C2 2EF (B-spline), D0 C1 3EF (Catmull-Rom spline) interpolation, and the new frequency domain based method. The zoom factor in i and j direction for the images of the first row was 10.0 and for the second row 20.0. ", "caption_bbox": [98, 434, 730, 482]}, {"image_id": 8, "file_name": "199_08.png", "page": 9, "dpi": 300, "bbox": [129, 112, 702, 582], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: These images show results of rendering CT datasets. They have been created with the new frequency domain based method. These pictures demonstrate the practical results that can be achieved with real-world datasets. The result images except the Stanford Bunny image are created with the application of standard density based transfer functions. An arbitrary volumetric procedural texture was used to color the iso-surface rendered from the Stanford Bunny dataset. ", "caption_bbox": [98, 589, 730, 652]}], "200": [{"image_id": 0, "file_name": "200_00.png", "page": 2, "dpi": 300, "bbox": [103, 280, 396, 407], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Volume rendering of a whole Drosophila blasto- derm embryo, stained for nuclei (green) and two genes (red and blue). Note the lower resolution along the optical axis and the attenuation with depth; artifacts inherent to the con- focal microscopy approach. (Color versions of this figure and other figures are included on the color plate at the end of the proceedings.) ", "caption_bbox": [98, 416, 399, 522]}, {"image_id": 1, "file_name": "200_01.png", "page": 3, "dpi": 300, "bbox": [435, 284, 728, 401], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Rendering of all nuclei of a Drosophila embryo with segmentation mask. ", "caption_bbox": [430, 409, 731, 439]}, {"image_id": 2, "file_name": "200_02.png", "page": 6, "dpi": 300, "bbox": [103, 188, 396, 321], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Cross-section through a 3D segmented data set.", "caption_bbox": [103, 332, 395, 345]}, {"image_id": 3, "file_name": "200_03.png", "page": 6, "dpi": 300, "bbox": [433, 170, 730, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Side-by-side comparison of 2D (left side) and 3D (right side) visualization of segmentation results, showing one nucleus marked as two separate regions ", "caption_bbox": [430, 280, 731, 324]}, {"image_id": 4, "file_name": "200_04.png", "page": 6, "dpi": 300, "bbox": [434, 347, 729, 447], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Side-by-side comparison of 2D (left side) and 3D (right side) visualization of segmentation results, showing a couple of nuclei fused by the low z-resolution of the micro- scope. ", "caption_bbox": [430, 457, 731, 516]}, {"image_id": 5, "file_name": "200_05.png", "page": 6, "dpi": 300, "bbox": [432, 539, 731, 625], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Side-by-side comparison of 2D (left side) and 3D (right side) visualization of segmentation results, showing the use of the cutting plane to find an incorrect region. ", "caption_bbox": [430, 636, 731, 680]}, {"image_id": 6, "file_name": "200_06.png", "page": 7, "dpi": 300, "bbox": [103, 572, 396, 689], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Segmentation of Drosophila nuclei highlighting large regions. ", "caption_bbox": [98, 697, 399, 727]}, {"image_id": 7, "file_name": "200_07.png", "page": 7, "dpi": 300, "bbox": [437, 261, 726, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Highlighting modes for a selected region.", "caption_bbox": [447, 399, 713, 412]}, {"image_id": 8, "file_name": "200_08.png", "page": 7, "dpi": 300, "bbox": [442, 112, 721, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Splitting an incorrectly segmented nucleus.", "caption_bbox": [443, 233, 717, 246]}, {"image_id": 9, "file_name": "200_09.png", "page": 7, "dpi": 300, "bbox": [98, 277, 397, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Removing a feature in the input image.", "caption_bbox": [125, 390, 372, 403]}, {"image_id": 10, "file_name": "200_10.png", "page": 7, "dpi": 300, "bbox": [98, 112, 400, 225], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Growing regions in segmentation mask to improve evaluation. ", "caption_bbox": [98, 235, 399, 263]}], "201": [{"image_id": 0, "file_name": "201_00.png", "page": 2, "dpi": 300, "bbox": [271, 42, 400, 154], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1:", "caption_bbox": [222, 161, 272, 179]}, {"image_id": 1, "file_name": "201_01.png", "page": 6, "dpi": 300, "bbox": [99, 486, 399, 797], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Example results of in vivo camera tracking for the patient studied in this paper. The left column shows samples of real bronchoscopic images and the right column presents the matched virtual bronchoscopic images after pq-space based 2D/3D registration. ", "caption_bbox": [98, 804, 399, 882]}, {"image_id": 2, "file_name": "201_02.png", "page": 6, "dpi": 300, "bbox": [99, 43, 399, 364], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Quantitative assessment of pq-space 2D/3D regis- tration ", "caption_bbox": [430, 121, 731, 154]}, {"image_id": 3, "file_name": "201_03.png", "page": 7, "dpi": 300, "bbox": [98, 42, 733, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a)A typical frame captured from the video stream output of the bronchoscopy video processor is shown here. (b-d) New views of the bronchial lumen were generated using texture maps merged from the training video frames. (e-h) Results when applied to different patients. In g-h drops of mucous on the camera lens are treated as part of the surface texture. ", "caption_bbox": [98, 366, 730, 414]}], "202": [{"image_id": 0, "file_name": "202_00.png", "page": 5, "dpi": 300, "bbox": [153, 121, 688, 669], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Credit Card Usage Analysis", "caption_bbox": [312, 668, 505, 684]}], "203": [{"image_id": 0, "file_name": "203_00.png", "page": 2, "dpi": 300, "bbox": [101, 44, 728, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) A plot of the summation of all spectra in the data-cube from the cerebral ganglia of the pond snail. The right part of the plot is scaled by a factor of 447. (b) The spatial distribution of spectral profiles. ", "caption_bbox": [98, 294, 730, 327]}, {"image_id": 1, "file_name": "203_01.png", "page": 3, "dpi": 300, "bbox": [437, 431, 726, 573], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) A single spectrum and (b) a single image in the spectral data-cube. ", "caption_bbox": [430, 580, 731, 613]}, {"image_id": 2, "file_name": "203_02.png", "page": 5, "dpi": 300, "bbox": [98, 530, 412, 759], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a-c) The first two score vectors with (b-d) the accompanying eigenimages as a result from the PCA. ", "caption_bbox": [98, 764, 399, 797]}, {"image_id": 3, "file_name": "203_03.png", "page": 6, "dpi": 300, "bbox": [104, 209, 728, 348], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a-b) Two resulting component mappings applied on the original data compared with (c) the VolView representation of the same dataset. ", "caption_bbox": [98, 353, 730, 386]}, {"image_id": 4, "file_name": "203_04.png", "page": 6, "dpi": 300, "bbox": [105, 42, 726, 154], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The (a) second, (b) third and (c) fourth component mappings with the negative contributions in blue and positive contributions in red. ", "caption_bbox": [98, 159, 730, 192]}], "204": [{"image_id": 0, "file_name": "204_00.png", "page": 3, "dpi": 300, "bbox": [479, 113, 683, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A min-max span space of a dataset, where each cell is represented as a black dot. The grey area corresponds to an iso-value query, and the cells falling into this area in- tersect with the desired iso-surface.Those dots who have no upper-left neighbors are marked with circles. ", "caption_bbox": [430, 295, 731, 373]}, {"image_id": 1, "file_name": "204_01.png", "page": 3, "dpi": 300, "bbox": [107, 156, 392, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A 2D volume thinning process. On the left: the original dataset, where the extremum points are marked in dark gray. On the right: The resulting skeleton after the thin- ning process. ", "caption_bbox": [98, 243, 399, 306]}, {"image_id": 2, "file_name": "204_02.png", "page": 4, "dpi": 300, "bbox": [192, 424, 306, 486], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A 2D counterexample. The numbers are the cor- responding scalar values defined on the grid points. ", "caption_bbox": [98, 493, 399, 526]}, {"image_id": 3, "file_name": "204_03.png", "page": 4, "dpi": 300, "bbox": [524, 480, 638, 597], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A 2D example where several cells with exactly the same range are connected together. ", "caption_bbox": [430, 604, 731, 637]}, {"image_id": 4, "file_name": "204_04.png", "page": 5, "dpi": 300, "bbox": [192, 112, 306, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A 2D example of iso-surface(s). Here the given iso-value is 25. ", "caption_bbox": [98, 241, 399, 274]}, {"image_id": 5, "file_name": "204_05.png", "page": 5, "dpi": 300, "bbox": [520, 371, 642, 473], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An example showing the cyclicity of the relation- ships between a cell and its neighbors. ", "caption_bbox": [430, 480, 731, 513]}], "205": [{"image_id": 0, "file_name": "205_00.png", "page": 2, "dpi": 300, "bbox": [434, 367, 727, 538], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A parallelization model for LOD.", "caption_bbox": [471, 573, 691, 591]}, {"image_id": 1, "file_name": "205_01.png", "page": 3, "dpi": 300, "bbox": [141, 309, 365, 433], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Lacking complete neighborhood information leads to cracks between adjacent blocks of different parti- tions. ", "caption_bbox": [98, 449, 399, 497]}, {"image_id": 2, "file_name": "205_02.png", "page": 4, "dpi": 300, "bbox": [98, 113, 400, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Binary tree of neighboring d2 values at the border of the tile right edge. ", "caption_bbox": [98, 227, 399, 260]}, {"image_id": 3, "file_name": "205_03.png", "page": 5, "dpi": 300, "bbox": [98, 791, 401, 883], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: New vertices at each level of refinement. Only these vertices have to be geomorphed, while corner ones stay at the same 3D position. ", "caption_bbox": [98, 890, 399, 938]}, {"image_id": 4, "file_name": "205_04.png", "page": 6, "dpi": 300, "bbox": [453, 136, 733, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Data scalability test.", "caption_bbox": [502, 339, 659, 357]}, {"image_id": 5, "file_name": "205_05.png", "page": 6, "dpi": 300, "bbox": [452, 567, 733, 765], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Implementing geomorphing introduces important computation overhead. Observe the distance between the 2 top curves. These curves represent the global computation time when geomorphing is ON (curve on the bottom) and OFF (curve on the top). ", "caption_bbox": [430, 767, 731, 845]}, {"image_id": 6, "file_name": "205_06.png", "page": 7, "dpi": 300, "bbox": [98, 111, 401, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Our parallel framework running on USGS Wash- ington State dataset. ", "caption_bbox": [98, 347, 399, 380]}], "206": [{"image_id": 0, "file_name": "206_00.png", "page": 2, "dpi": 300, "bbox": [99, 135, 726, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Illustration of the different components of the flow around the delta wing. Left: Original flow field from the CFD simulation, Middle: Laplacian field computed by the original field\u2019s flow normal to the boundary. Note that the flow is simple but not constant. Right: Localized or region-specific flow obtained by subtracting the Laplacian field from the original field. ", "caption_bbox": [98, 262, 730, 310]}, {"image_id": 1, "file_name": "206_01.png", "page": 4, "dpi": 300, "bbox": [447, 635, 696, 782], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Comparison of different fields obtained from cylin- der dataset with Karman vortex street. a) Streamlines in the original flow. Only sinuous line structures give hints on the vortices. b) Three vortices revealed by removing average flow. c) Potential flow induced by the flow on the boundary of the considered region. Note how the flow attaches to the cylinder and does not seem to cross it as it would be the case for constant flow. d) Subtracting the Laplacian field reveals all five vortices present in the considered region by use of topology. ", "caption_bbox": [430, 791, 731, 945]}, {"image_id": 2, "file_name": "206_02.png", "page": 8, "dpi": 300, "bbox": [115, 625, 724, 845], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Left:Vortex core lines and volume rendering of the \u03bb2 -criterion, both computed for the localized flow around the delta wing. The vortex core lines were extracted using the algorithm of Sujudi and Haimes. Right: Streamlines and topology in the localized field of the delta wing dataset. Two 3D-saddle points are shown as small spheres. 1D separatrices are integrated from the saddles. ", "caption_bbox": [98, 854, 731, 918]}, {"image_id": 3, "file_name": "206_03.png", "page": 8, "dpi": 300, "bbox": [203, 113, 627, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: HART II dataset consisting of PIV measurements. Left image shows the original measured flow with no visible features. On the right, the topology of the region-specific flow reveals the vortices present in the correct frame of reference ", "caption_bbox": [98, 314, 730, 347]}, {"image_id": 4, "file_name": "206_04.png", "page": 8, "dpi": 300, "bbox": [106, 374, 750, 550], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Original, potential and region-specific flow around two obstacles for vortex generation. The local contributions to the flow and the locations where the vortices begin are easily identified in the right image. ", "caption_bbox": [98, 555, 730, 588]}], "207": [{"image_id": 0, "file_name": "207_00.png", "page": 2, "dpi": 300, "bbox": [111, 891, 401, 966], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Flow behind a circular cylinder. Vortex regions visualized as transparent isosurfaces of \u03bb2 . Vortex core lines displayed as cylindrical lines. ", "caption_bbox": [98, 790, 399, 833]}, {"image_id": 1, "file_name": "207_01.png", "page": 4, "dpi": 300, "bbox": [430, 118, 733, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Vortex region quantities pressure p, vorticity \u03c9, ro- tation strength \u2206 from [SP03], Q-criterion and \u03bb2 criterion with the value range in which they indicate vortices. Vortex cores according to definition 2 are either ridges or valleys as shown in column 3. ", "caption_bbox": [430, 445, 731, 519]}, {"image_id": 2, "file_name": "207_02.png", "page": 6, "dpi": 300, "bbox": [430, 111, 733, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Flow behind a circular cylinder. Iconic repre- sentation of Galilean invariant vortex core lines. \u03bb2 was used for extraction and is encoded into color and scale of the cylindrical meshes. Red / blue color is used to indicate strong / weak vortex activity. \u03d5 is encoded into color and spiral direction of the orbits. ", "caption_bbox": [430, 310, 731, 399]}, {"image_id": 3, "file_name": "207_03.png", "page": 6, "dpi": 300, "bbox": [102, 122, 400, 752], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Different approaches to encoding a scalar value into the representation of a line. ", "caption_bbox": [98, 764, 399, 792]}, {"image_id": 4, "file_name": "207_04.png", "page": 7, "dpi": 300, "bbox": [98, 427, 733, 712], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Bubble chamber. Vortex core lines extracted, colored and scaled according to \u03bb2 . Same colormap as in figure 4.", "caption_bbox": [110, 725, 719, 740]}, {"image_id": 5, "file_name": "207_05.png", "page": 9, "dpi": 300, "bbox": [98, 297, 733, 890], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Flow around a backward-facing step. Vortex core lines extracted, colored and scaled according to Q.", "caption_bbox": [136, 902, 693, 915]}], "208": [{"image_id": 0, "file_name": "208_00.png", "page": 1, "dpi": 300, "bbox": [412, 357, 733, 810], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: PIV measurement positions in the wake of a he- licopter rotor. The red blade is at the rear position, and the wind comes from right. Figure courtesy of DLR Braun- schweig. ", "caption_bbox": [430, 818, 731, 881]}, {"image_id": 1, "file_name": "208_01.png", "page": 2, "dpi": 300, "bbox": [445, 112, 717, 520], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: HART II measurement configuration. Figure cour- tesy of DLR Braunschweig. ", "caption_bbox": [430, 527, 731, 560]}, {"image_id": 2, "file_name": "208_02.png", "page": 3, "dpi": 300, "bbox": [432, 112, 730, 208], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Part of a 3-C PIV image around a vortex. The global average has already been removed. Left: Velocity in the direction of the vortex. The image is shown from front. Middle and Right: The local average has been removed, too. Now the vectors are only orthogonal to the vortex direction. As the vortex direction is not orthogonal to the image plane, the vectors come out of the plane. The image is shown from front (middle) and back (right). ", "caption_bbox": [430, 215, 731, 339]}, {"image_id": 3, "file_name": "208_03.png", "page": 3, "dpi": 300, "bbox": [98, 739, 401, 856], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Hedgehog and colormap of the velocities of the same part of one dataset. Original data (left) and the data after removing the average vector of the field (right). The color map is scaled from zero to the maximal velocity of the data, that is 36.3 for the original data and 11.4 for the data with the average removed. ", "caption_bbox": [98, 863, 399, 956]}, {"image_id": 4, "file_name": "208_04.png", "page": 4, "dpi": 300, "bbox": [98, 112, 401, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Vortex core positions at two measurement posi- tions, 20 images each. The measurement position of the left image is shortly after vortex creation and the measurement position of the right image is at a place where the vortex is quite old. ", "caption_bbox": [98, 248, 399, 326]}, {"image_id": 5, "file_name": "208_05.png", "page": 5, "dpi": 300, "bbox": [98, 791, 399, 915], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A normalized rotational mask (left) and a Rankine vortex mask (right). ", "caption_bbox": [98, 924, 399, 957]}, {"image_id": 6, "file_name": "208_06.png", "page": 5, "dpi": 300, "bbox": [430, 112, 733, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Top: Vorticity (top left) and a similarity image (top right). The similarity to a 52 rotational mask is shown where blue denotes high similarity to a lefthanded rotation and red a high similarity to a righthanded rotation. Therefore the color is inverted in comparison to the vorticity image. Note that the scaling differs, between \u00b14500 in the case of vor- ticity and \u00b14 for the similarity image. Bottom: Line integral convolution (LIC) of the field where the average has been subtracted (bottom left) and LIC overlaid with the similarity image (bottom right). ", "caption_bbox": [430, 376, 731, 530]}, {"image_id": 7, "file_name": "208_07.png", "page": 6, "dpi": 300, "bbox": [519, 796, 644, 901], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: When the direction of the vortex is not orthogonal to the image plane, the vortex shape in the image plane will be elliptical. ", "caption_bbox": [430, 908, 731, 956]}, {"image_id": 8, "file_name": "208_08.png", "page": 6, "dpi": 300, "bbox": [111, 641, 401, 825], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Similarity with a pure rotational mask (y-axis) vs. mask size (x-axis) for three positions. Shown are the position with maximal similarity to the 52 rotational mask (red), the mask with maximal similarity within the scale computation (green), and the position with maximal mask size within the region defined by a percentage threshold (blue). The maxi- mal similarity of the green line determines the position and size of the vortex. ", "caption_bbox": [98, 832, 399, 956]}, {"image_id": 9, "file_name": "208_09.png", "page": 6, "dpi": 300, "bbox": [116, 118, 381, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The size of a vortex can be determined by convo- lution with successively larger masks. ", "caption_bbox": [98, 305, 399, 338]}, {"image_id": 10, "file_name": "208_10.png", "page": 7, "dpi": 300, "bbox": [431, 712, 732, 809], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Similarity (red) and scale (green) of the vortices of 20 images each of two measurement positions. The first position shows a young and well defined vortex (left). At the second position, the vortex is quite old and often, the vortex can not be found at all (right). The x-axis gives the number of the image and the y-axis gives the similarity values in red and the diameter of the vortices in green. The results are computed without orientation correction or subpixel accu- racy. ", "caption_bbox": [430, 817, 731, 956]}, {"image_id": 11, "file_name": "208_11.png", "page": 7, "dpi": 300, "bbox": [98, 112, 401, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Looking at similarity images gained by convolv- ing a data set with a rotational mask or a Rankine vortex, the shape of the resulting image tells whether the vortex di- rection is orthogonal to the cutting or image plane (left) or not (right). Out of the shape of the ellipse in the right im- age, the direction of the vortex can be computed except for the sign of the second rotation angle. The color map of the similarity image, where red denotes high similarity and blue low similarity, is overlaid with isolines. ", "caption_bbox": [98, 233, 399, 372]}], "209": [{"image_id": 0, "file_name": "209_00.png", "page": 2, "dpi": 300, "bbox": [105, 92, 744, 536], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Direct renderings of mean diameter and standard deviation versus pointillist rendering on the heated-object scale.", "caption_bbox": [111, 542, 737, 561]}, {"image_id": 1, "file_name": "209_01.png", "page": 3, "dpi": 300, "bbox": [438, 93, 744, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Spot glyph rendering of mean diameter and standard deviation on the heated-object scale. ", "caption_bbox": [439, 424, 742, 458]}, {"image_id": 2, "file_name": "209_02.png", "page": 4, "dpi": 300, "bbox": [105, 311, 411, 612], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Enlargement of spot glyphs shows size and packing detail ", "caption_bbox": [106, 611, 409, 645]}, {"image_id": 3, "file_name": "209_03.png", "page": 5, "dpi": 300, "bbox": [106, 228, 405, 379], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Perceptually equiluminant colorscales for use with all renderings of multiple sizes and counts of nanoparticles. ", "caption_bbox": [106, 378, 409, 412]}, {"image_id": 4, "file_name": "209_04.png", "page": 6, "dpi": 300, "bbox": [105, 435, 744, 737], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Blending versus pointillism for showing multiple datasets. At left, blended rendering for all sizes of nanoparticles. At right, pointillized rendering for all sizes preserves relevant details. ", "caption_bbox": [106, 736, 742, 770]}, {"image_id": 5, "file_name": "209_05.png", "page": 6, "dpi": 300, "bbox": [199, 94, 651, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Direct renderings of nanoparticle counts at each point for six sizes of nanoparticles. Clockwise from the upperleft: counts for 1, 2, 4, 8, 16, and 32 nm. sizes. Colorscales follow from \ufb01gure 4. ", "caption_bbox": [106, 393, 742, 427]}, {"image_id": 6, "file_name": "209_06.png", "page": 7, "dpi": 300, "bbox": [438, 435, 745, 736], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Detail view of target glyph rendering for all nanoparticles in formation. ", "caption_bbox": [439, 735, 742, 769]}, {"image_id": 7, "file_name": "209_07.png", "page": 7, "dpi": 300, "bbox": [106, 435, 412, 735], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Detail view of stochastic pointillist rendering maintains the integrity of the visualization. ", "caption_bbox": [106, 734, 409, 768]}, {"image_id": 8, "file_name": "209_08.png", "page": 7, "dpi": 300, "bbox": [438, 94, 745, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Target glyph rendering for all nanoparticles in formation. ", "caption_bbox": [439, 392, 742, 426]}, {"image_id": 9, "file_name": "209_09.png", "page": 7, "dpi": 300, "bbox": [106, 94, 412, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Detail view of regularly-spaced pointillist rendering. ", "caption_bbox": [106, 392, 409, 426]}], "210": [{"image_id": 0, "file_name": "210_00.png", "page": 2, "dpi": 300, "bbox": [467, 489, 696, 666], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Conventional visualization of molecular dynam- ics simulation with polygonal primitives and simple glyphs lacking polarity ", "caption_bbox": [430, 676, 731, 719]}, {"image_id": 1, "file_name": "210_01.png", "page": 3, "dpi": 300, "bbox": [139, 426, 354, 599], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Dipole glyph and the adjustable visualization pa- rameters ", "caption_bbox": [98, 613, 399, 641]}, {"image_id": 2, "file_name": "210_02.png", "page": 4, "dpi": 300, "bbox": [452, 175, 711, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A mixture with three different dipoles, colored by dipole type ", "caption_bbox": [430, 405, 731, 433]}, {"image_id": 3, "file_name": "210_03.png", "page": 4, "dpi": 300, "bbox": [140, 260, 360, 511], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The different cases when raycasting the cylinder alongside indications where the distinguishing conditions are true ", "caption_bbox": [98, 524, 399, 567]}, {"image_id": 4, "file_name": "210_04.png", "page": 5, "dpi": 300, "bbox": [135, 493, 364, 704], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Supersaturated gas; detected germs(clusters) are cyan ", "caption_bbox": [98, 714, 399, 742]}, {"image_id": 5, "file_name": "210_05.png", "page": 6, "dpi": 300, "bbox": [112, 308, 386, 556], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Synthetic data set consisting of 200,000 dipoles, visualized with depth cues turned on ", "caption_bbox": [98, 566, 399, 594]}], "211": [{"image_id": 0, "file_name": "211_00.png", "page": 3, "dpi": 300, "bbox": [98, 111, 733, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Screenshot of a computer-generated video (left) next to a field-recorded video (right). Both videos show the trunk-view for the mature stand. Click here to view sample videos. ", "caption_bbox": [98, 364, 731, 392]}, {"image_id": 1, "file_name": "211_01.png", "page": 4, "dpi": 300, "bbox": [452, 111, 715, 407], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An illustration of the two-segment trunk.", "caption_bbox": [451, 422, 709, 435]}, {"image_id": 2, "file_name": "211_02.png", "page": 4, "dpi": 300, "bbox": [457, 457, 718, 743], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An illustration of branch whorls.", "caption_bbox": [471, 753, 691, 766]}, {"image_id": 3, "file_name": "211_03.png", "page": 5, "dpi": 300, "bbox": [128, 341, 371, 553], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Screenshots of the hardwood trunk (left) and crown textures (right). The hardwood tree textures were ap- plied separately so they could be scaled independently. ", "caption_bbox": [98, 564, 399, 607]}, {"image_id": 4, "file_name": "211_04.png", "page": 5, "dpi": 300, "bbox": [445, 705, 719, 890], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: An example screenshot of a computer-generated video for the immature stand. Distance cues (red flags) and other virtual forest elements are visible. ", "caption_bbox": [430, 900, 731, 943]}], "212": [{"image_id": 0, "file_name": "212_00.png", "page": 3, "dpi": 300, "bbox": [447, 98, 736, 489], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2. Zoom in operation from root (all genomes) to a specific genome (Human herpesvirus 7). ", "caption_bbox": [441, 488, 743, 518]}, {"image_id": 1, "file_name": "212_01.png", "page": 4, "dpi": 300, "bbox": [111, 97, 416, 232], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Translation from tree structure to Venn diagram group genomes with similar characteristics in size and functional structures on nearby branches. The phylogeny classification structure embodies how biologists tend to think about organisms. Nevertheless, it is also true that no structure, even if comprehensive, can encompass all the relationships that genomic scientists discover and investigate. Indeed, it is increasingly true that scientist compare quite disparate species (e.g., viruses and bacteria) to discover common mechanisms. Finally, it is important to note that the data layout and organization mechanism does not depend on the details of the structure used. If a universal structure other than a phylogeny tree were deemed more useful, the data could be efficiently organized for this structure. ", "caption_bbox": [106, 235, 409, 457]}, {"image_id": 2, "file_name": "212_02.png", "page": 5, "dpi": 300, "bbox": [102, 80, 409, 387], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. Upper Left: Node link tree of genome database containing 500Mbytes of data and 1500 genomes. Lower Left: Corresponding and overview image of zoomable phylogeny tree. Upper Right: Node link tree with a virus highlighted in green Lower Right: Corresponding zoomed-in view of bacteriophages. The pink rectangle is the view being displayed in the main window. ", "caption_bbox": [100, 405, 415, 507]}, {"image_id": 3, "file_name": "212_03.png", "page": 6, "dpi": 300, "bbox": [426, 667, 745, 964], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8. Selection from genome and resulting BLAST output window. ", "caption_bbox": [427, 963, 744, 993]}, {"image_id": 4, "file_name": "212_04.png", "page": 6, "dpi": 300, "bbox": [438, 170, 735, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7. Building a binary tree from bottom to top for a DNA sequence. As we go up the tree, gene buttons that are close merge into one box. ", "caption_bbox": [434, 396, 738, 441]}, {"image_id": 5, "file_name": "212_05.png", "page": 6, "dpi": 300, "bbox": [93, 438, 411, 710], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6. Representing a small segment of the E. Coli genome.", "caption_bbox": [93, 709, 408, 725]}, {"image_id": 6, "file_name": "212_06.png", "page": 7, "dpi": 300, "bbox": [450, 97, 743, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9. Selection interface. The black barbell at the bottom is the selection and the colored barbells indicate ORFs. ", "caption_bbox": [440, 329, 752, 360]}], "213": [{"image_id": 0, "file_name": "213_00.png", "page": 1, "dpi": 300, "bbox": [101, 714, 398, 847], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Magnetic resonance image (left) and segmented image (right). ", "caption_bbox": [98, 854, 399, 887]}, {"image_id": 1, "file_name": "213_01.png", "page": 2, "dpi": 300, "bbox": [106, 46, 725, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Heart model extracted from time-varying segmented volume, illustrating the in- and deflation of the left ventricle.", "caption_bbox": [104, 263, 720, 281]}, {"image_id": 2, "file_name": "213_02.png", "page": 3, "dpi": 300, "bbox": [98, 43, 733, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Interpolation between two slices (left and right upper image) based on linear combinations of signed distance func- tions (bottom row). ", "caption_bbox": [98, 210, 730, 243]}, {"image_id": 3, "file_name": "213_03.png", "page": 4, "dpi": 300, "bbox": [178, 280, 321, 389], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: For every edge connecting voxels with two differ- ent materials, here denoted by A and B, a quadrilateral is generated. ", "caption_bbox": [98, 396, 399, 444]}, {"image_id": 4, "file_name": "213_04.png", "page": 4, "dpi": 300, "bbox": [434, 43, 731, 155], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Solving topological ambiguities by virtually mov- ing the boundary towards the material of lower priority and by splitting the involved vertices. ", "caption_bbox": [430, 179, 731, 227]}, {"image_id": 5, "file_name": "213_05.png", "page": 4, "dpi": 300, "bbox": [114, 47, 386, 215], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The effect of volume smoothing on the cavity com- plex of the left ventricle. ", "caption_bbox": [98, 227, 399, 260]}, {"image_id": 6, "file_name": "213_06.png", "page": 4, "dpi": 300, "bbox": [511, 248, 652, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Two-pass smoothing strategy.", "caption_bbox": [479, 336, 679, 354]}, {"image_id": 7, "file_name": "213_07.png", "page": 5, "dpi": 300, "bbox": [184, 46, 641, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Meshes during the fairing process (rendered with flat shading). a) heart before fairing; b) after one constrained fairing step; c) after five fairing passes. ", "caption_bbox": [98, 267, 730, 300]}, {"image_id": 8, "file_name": "213_08.png", "page": 6, "dpi": 300, "bbox": [103, 710, 368, 849], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: a) Left ventricle with atrium (right) and aorta; b) left ventricle with mitral and aortic valves. ", "caption_bbox": [98, 854, 399, 887]}, {"image_id": 9, "file_name": "213_09.png", "page": 6, "dpi": 300, "bbox": [98, 185, 401, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Heart ontology defining left and right ventricular complexes embedded in the heart domain. ", "caption_bbox": [98, 394, 399, 427]}, {"image_id": 10, "file_name": "213_10.png", "page": 6, "dpi": 300, "bbox": [130, 43, 369, 114], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Regularization of mesh structure by collapsing quadrilaterals with two opposing valence-three vertices. ", "caption_bbox": [98, 122, 399, 155]}, {"image_id": 11, "file_name": "213_11.png", "page": 7, "dpi": 300, "bbox": [157, 47, 670, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Mesh sizes and computation times for contouring and mesh fairing of the first time step.", "caption_bbox": [171, 383, 654, 401]}], "214": [{"image_id": 0, "file_name": "214_00.png", "page": 2, "dpi": 300, "bbox": [114, 113, 386, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Illustration of the correspondence between span space and our data structure. (a) The problem of active cell determination becomes a range finding problem in span space. An isovalue q defines a 2D active region. (b) Our method efficiently implements this range search using a straightforward 2D array representation of the span space. Cells are rendered as black points and active regions are shaded with diagonal hatches. Alternating colors are used to show the correspondence between columns (buckets) of our 2D array structure and span space. The region in span space corresponding to the last active bucket ca is split by the ver- tical line induced by query q resulting in non-contiguous ac- tive cell locations in that bucket. ", "caption_bbox": [98, 297, 399, 497]}, {"image_id": 1, "file_name": "214_01.png", "page": 3, "dpi": 300, "bbox": [193, 113, 638, 325], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of the construction of our data structure. (a) Input cells are classified by their min- and max-values in the span space. (b) The cells are sorted globally by their minimum intensity value and then placed into buckets that contain up to B cells. (B = 3 in this example.) Each bucket is shown in a different color. Note that the last bucket may contain less than B cells. (c) Min-dictionary cells, shown here as hollow circles, are identified. (d) The cells of each bucket are sorted according to maximum intensity value. (e) The resulting data structure is a logical 2D array. ", "caption_bbox": [98, 333, 730, 411]}, {"image_id": 2, "file_name": "214_02.png", "page": 4, "dpi": 300, "bbox": [108, 115, 376, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Incremental extraction for increasing isovalue. Red regions contain cells to be deactivated, and green re- gions contain cells that must be activated. Three categories of buckets exist: (1) buckets that remain active where mark- ers must be pushed upward, deactivating cells passed along the way, (2) the former last active bucket ca where active and inactive cells are interleaved, and (3) additional buckets that can be traversed using a procedure similar to full extraction. ", "caption_bbox": [98, 331, 399, 455]}, {"image_id": 3, "file_name": "214_03.png", "page": 4, "dpi": 300, "bbox": [440, 115, 708, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Incremental extraction for decreasing isovalue. Red regions contain cells to be deactivated, and green re- gions contain cells that must be activated. Three categories of buckets exist: (1) buckets that remain active where mark- ers must be pushed downward, adding cells passed along the way, (2) the new last active bucket ca0 where active and in- active cells are interleaved, and (3) inactive buckets that can be deactivated using a procedure similar to full extraction. ", "caption_bbox": [430, 331, 731, 455]}, {"image_id": 4, "file_name": "214_04.png", "page": 5, "dpi": 300, "bbox": [435, 380, 728, 832], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Timing comparison between an interval tree im- plementation and our approach shown as a plot of average search time versus the number of active cells. The plots show that the running time of our method is competitive with an in- terval tree, an optimal technique. The regression lines show that our method achieves O(K) performance on average. ", "caption_bbox": [430, 845, 731, 938]}, {"image_id": 5, "file_name": "214_05.png", "page": 6, "dpi": 300, "bbox": [438, 118, 727, 344], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Log-linear plot of average search time versus bucket size. These results indicate that a reasonable bucket size B is around 4096, regardless of the input data size. ", "caption_bbox": [430, 354, 731, 402]}, {"image_id": 6, "file_name": "214_06.png", "page": 8, "dpi": 300, "bbox": [98, 115, 401, 586], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Isosurfaces extracted using our method. Above: Single surface extracted from the Engine data set. Below: Multiple isosurfaces from the Kyle unstructured flow simu- lation data set. ", "caption_bbox": [98, 593, 399, 656]}], "215": [{"image_id": 0, "file_name": "215_00.png", "page": 4, "dpi": 300, "bbox": [443, 112, 730, 643], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Frequency responses of (a) B-Spline, (b) B- Spline 3 and smooth B-Spline 3, (c) derivative B-Spline. ", "caption_bbox": [445, 644, 742, 675]}, {"image_id": 1, "file_name": "215_01.png", "page": 5, "dpi": 300, "bbox": [288, 519, 396, 626], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Poor result obtained with the cubic gradient filter, which is the derivative of the Cat- mull-Rom            filter [BLM96]. ", "caption_bbox": [274, 627, 403, 719]}, {"image_id": 2, "file_name": "215_02.png", "page": 7, "dpi": 300, "bbox": [131, 115, 721, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Gradients computed along one circle on the smooth sphere, with average error angle(up to 360). (a. perfect, b. central difference, c. trilinear-analytical, d. Catmull-Rom Spline, e. B-Spline 2, f. B-Spline3-smooth \u03bb =1, g. B-Spline 3, h. B-Spline 4, i. B-Spline 5, j. B-Spline 6, k-o. B-Spline without prefiltering, order 2 to 6) ", "caption_bbox": [102, 261, 748, 307]}, {"image_id": 3, "file_name": "215_03.png", "page": 7, "dpi": 300, "bbox": [131, 315, 718, 417], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Gradients computed along one circle on the M-L. dataset, with average error angle. (a. perfect, b. central difference, c. trilinear-analytical, d. Catmull-Rom Spline, e. B-Spline 2, f. B-Spline 3, g. B-Spline 4, h. B-Spline 5, i. B-Spline 6) ", "caption_bbox": [105, 423, 733, 454]}, {"image_id": 4, "file_name": "215_04.png", "page": 9, "dpi": 300, "bbox": [110, 422, 425, 685], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7. Refracted results of the Sphere.", "caption_bbox": [126, 388, 333, 404]}], "216": [{"image_id": 0, "file_name": "216_00.png", "page": 3, "dpi": 300, "bbox": [439, 248, 723, 721], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: File-based (a) and line-based (b) layouts", "caption_bbox": [458, 726, 702, 741]}, {"image_id": 1, "file_name": "216_01.png", "page": 3, "dpi": 300, "bbox": [140, 628, 399, 768], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Global line position computation", "caption_bbox": [165, 776, 372, 791]}, {"image_id": 2, "file_name": "216_02.png", "page": 4, "dpi": 300, "bbox": [444, 121, 714, 221], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Profile function for empty space", "caption_bbox": [478, 225, 680, 240]}, {"image_id": 3, "file_name": "216_03.png", "page": 4, "dpi": 300, "bbox": [443, 342, 705, 528], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Balanced interpolated layout with asymptotical decrease of empty space size ", "caption_bbox": [438, 531, 722, 560]}, {"image_id": 4, "file_name": "216_04.png", "page": 4, "dpi": 300, "bbox": [156, 426, 393, 744], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Line layout: file-based (top) line-based (middle) and interpolated (bottom) ", "caption_bbox": [126, 743, 410, 772]}, {"image_id": 5, "file_name": "216_05.png", "page": 4, "dpi": 300, "bbox": [484, 715, 683, 920], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Compensated interpolated layout with sharp empty space decrease ", "caption_bbox": [438, 922, 722, 951]}, {"image_id": 6, "file_name": "216_06.png", "page": 5, "dpi": 300, "bbox": [151, 727, 390, 906], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Interpolated layout without (a) and with", "caption_bbox": [126, 905, 410, 920]}, {"image_id": 7, "file_name": "216_07.png", "page": 5, "dpi": 300, "bbox": [438, 447, 720, 641], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Interpolated layout a) without antialiasing b) with position-based antialiasing. ", "caption_bbox": [438, 641, 722, 670]}, {"image_id": 8, "file_name": "216_08.png", "page": 5, "dpi": 300, "bbox": [128, 292, 427, 516], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Interpolated layout, empty space reduction", "caption_bbox": [142, 528, 395, 543]}, {"image_id": 9, "file_name": "216_09.png", "page": 6, "dpi": 300, "bbox": [445, 447, 711, 646], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Interpolated layout with constrained mouse motion ", "caption_bbox": [438, 645, 722, 674]}, {"image_id": 10, "file_name": "216_10.png", "page": 6, "dpi": 300, "bbox": [127, 324, 418, 456], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Detection of stable code fragments", "caption_bbox": [126, 465, 410, 480]}, {"image_id": 11, "file_name": "216_11.png", "page": 7, "dpi": 300, "bbox": [127, 320, 721, 765], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Version-centric visualization using the interpolated layout and the stable blocks detection", "caption_bbox": [184, 785, 663, 800]}, {"image_id": 12, "file_name": "216_12.png", "page": 9, "dpi": 300, "bbox": [127, 131, 721, 576], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Version-centric visualization using the interpolated layout and the stable blocks detection", "caption_bbox": [184, 596, 663, 611]}], "217": [{"image_id": 0, "file_name": "217_00.png", "page": 2, "dpi": 300, "bbox": [109, 123, 723, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Euler diagram representation (middle) of a traditional hierarchy (left) and an Euler diagram for a multi-hierarchy (right). In a traditional hierarchy, there is one path to any leaf element (e.g., A\u2192B\u2192D); in a multi-hierarchy, there are mul- tiple equivalent paths (e.g., Main Dish\u2192Pasta\u2192Italian vs. Italian\u2192Main Dish\u2192Pasta). Any top level set is a possible root. Equivalent paths are different paths that produce the same results. ", "caption_bbox": [98, 302, 731, 361]}, {"image_id": 1, "file_name": "217_01.png", "page": 4, "dpi": 300, "bbox": [148, 349, 352, 793], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Radial focus+context hierarchy layout. (a) In the first step, maximum node radii rni are calculated such that rni = 12 rni\u22121 . The level radii (the center of the nodes) are then calculated (rli = rli\u22121 + rni\u22121 + rni ). (b) In the second step, polar coordinates for each node is calculated. For each node at level i, its radial position is rli ; its angular position is calculated by uniformly dividing the circle for all siblings. A void (the dashed circle) is left for the node that is currently selected at that level. Node size is determined by the number of descendants. ", "caption_bbox": [98, 801, 399, 951]}, {"image_id": 2, "file_name": "217_02.png", "page": 4, "dpi": 300, "bbox": [108, 124, 722, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Defining a path in a MoireTree. Starting from the initial display of four sub-sets (left), the user selects the left most sub-set to become the new focus (middle). Finally, the top sub-set in the new focus class is selected, initiating a final transition (right). In the figure, lines connect the same hierarchy level in each display. ", "caption_bbox": [98, 264, 731, 307]}, {"image_id": 3, "file_name": "217_03.png", "page": 6, "dpi": 300, "bbox": [157, 382, 730, 593], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Different views of multi-hierarchical data using MoireTree. To find an internet chicken soup recipe, the user first selects \"From Internet\" from the category list. Two paths exist. The user can either select \"Chicken\" and then \"Soups\" (left), or \"Soups\" and then \"Chicken\". Notice that both paths bring the user to the same results. ", "caption_bbox": [98, 603, 731, 646]}, {"image_id": 4, "file_name": "217_04.png", "page": 6, "dpi": 300, "bbox": [149, 113, 725, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Browsing a recipe collection with a MoireTree. Starting from the initial display of six sub-sets (left), the user selects the \"Chicken\" sub-set to become the new focus (middle). Next, the \"Curry\" sub-set is selected and becomes the focus (right). All the node and label transitions are animated. ", "caption_bbox": [98, 320, 731, 363]}, {"image_id": 5, "file_name": "217_05.png", "page": 7, "dpi": 300, "bbox": [142, 111, 357, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Browsing a paper database with a MoireTree. In the database, papers are limited to three keywords. There- fore, after three subsequent queries, the results are all leaf nodes. The leaf nodes are labeled with the first few words of the title. Clicking on a leaf node prints details of the corre- sponding data element (e.g., paper title, abstract). ", "caption_bbox": [98, 297, 399, 386]}], "218": [{"image_id": 0, "file_name": "218_00.png", "page": 3, "dpi": 300, "bbox": [187, 366, 312, 497], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Parallel plane layout.", "caption_bbox": [166, 507, 331, 520]}, {"image_id": 1, "file_name": "218_01.png", "page": 3, "dpi": 300, "bbox": [187, 546, 312, 671], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Concentric sphere layout", "caption_bbox": [157, 682, 339, 695]}, {"image_id": 2, "file_name": "218_02.png", "page": 4, "dpi": 300, "bbox": [486, 747, 670, 904], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Concentric sphere layout of collaboration net- work. ", "caption_bbox": [430, 916, 731, 944]}, {"image_id": 3, "file_name": "218_03.png", "page": 4, "dpi": 300, "bbox": [98, 87, 415, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Parallel plane layout of PPI network.", "caption_bbox": [127, 261, 370, 274]}, {"image_id": 4, "file_name": "218_04.png", "page": 4, "dpi": 300, "bbox": [158, 300, 324, 454], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Concentric sphere layout of PPI network.", "caption_bbox": [117, 472, 381, 485]}, {"image_id": 5, "file_name": "218_05.png", "page": 4, "dpi": 300, "bbox": [414, 87, 674, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Zoomed view showing the most highly cited pa- pers ", "caption_bbox": [430, 223, 731, 251]}, {"image_id": 6, "file_name": "218_06.png", "page": 4, "dpi": 300, "bbox": [142, 830, 357, 921], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Parallel plane layout of citation network", "caption_bbox": [119, 931, 378, 944]}, {"image_id": 7, "file_name": "218_07.png", "page": 5, "dpi": 300, "bbox": [482, 111, 669, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visualisation of InfoVis research area evolution", "caption_bbox": [434, 284, 727, 297]}, {"image_id": 8, "file_name": "218_08.png", "page": 6, "dpi": 300, "bbox": [142, 709, 357, 873], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Reference to future publication.", "caption_bbox": [138, 884, 358, 897]}, {"image_id": 9, "file_name": "218_09.png", "page": 6, "dpi": 300, "bbox": [98, 87, 415, 208], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The first layer of research area evolution network.", "caption_bbox": [98, 218, 399, 231]}, {"image_id": 10, "file_name": "218_10.png", "page": 6, "dpi": 300, "bbox": [142, 434, 357, 542], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Addition of the second layer to evolution net- work. ", "caption_bbox": [98, 552, 399, 580]}, {"image_id": 11, "file_name": "218_11.png", "page": 7, "dpi": 300, "bbox": [476, 112, 687, 276], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: A global view of integration with collaboration network. ", "caption_bbox": [430, 288, 731, 316]}, {"image_id": 12, "file_name": "218_12.png", "page": 7, "dpi": 300, "bbox": [142, 356, 357, 518], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Integration with collaboration network.", "caption_bbox": [118, 529, 378, 542]}, {"image_id": 13, "file_name": "218_13.png", "page": 7, "dpi": 300, "bbox": [133, 116, 368, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Research area of G. Robertson.", "caption_bbox": [139, 321, 359, 334]}], "219": [{"image_id": 0, "file_name": "219_00.png", "page": 2, "dpi": 300, "bbox": [103, 118, 399, 320], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: This chart shows the e-mail statistics of three of our IMAP users. From July 2003 to May 2004 we received more spam than solicited messages. Infrastructural changes in September 2004 decreased the spam volume considerably. ", "caption_bbox": [98, 338, 399, 397]}, {"image_id": 1, "file_name": "219_01.png", "page": 2, "dpi": 300, "bbox": [430, 558, 733, 745], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Three layer architecture of the Mail Explorer \u2013 Retrieving, exploring and browsing large collections of e- mail ", "caption_bbox": [430, 758, 731, 802]}, {"image_id": 2, "file_name": "219_02.png", "page": 3, "dpi": 300, "bbox": [99, 111, 730, 733], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Overview first \u2013 The Mail Explorer Interface has a number of configurable visual analytics. The user has four overview visualizations to analyze temporal and geo-spatial properties of the e-mail communication. He can identify interesting patterns: here, for example, most sender locations are in the US and Europe. This can be explained by the fact that most research partners of one of the authors are located in US and Europe. Some e-mails with exotic sender locations such as China are probably spam. ", "caption_bbox": [98, 744, 731, 818]}, {"image_id": 3, "file_name": "219_03.png", "page": 5, "dpi": 300, "bbox": [98, 277, 401, 467], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Scheme of the recursive pattern used. Four years are placed next to each other. They are vertically subdivided into four quarters with three months each. A month consists of a matrix of the size 5x6. ", "caption_bbox": [98, 478, 399, 537]}, {"image_id": 4, "file_name": "219_04.png", "page": 6, "dpi": 300, "bbox": [98, 111, 733, 449], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Details on Demand \u2013 shows three plots of different mail traffic of the year 2004 in a Recursive Pattern. Each square represents the mail volume of one day. Dark colors indicate high e-mail traffic. ", "caption_bbox": [98, 454, 731, 482]}, {"image_id": 5, "file_name": "219_05.png", "page": 7, "dpi": 300, "bbox": [103, 111, 728, 403], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Zoom and Filter \u2013 Gain insight into spam. The HistoMap visualization shows a typical spam folder in our depart- ment. Colors are used in order to distinguish between the countries; brightness and size indicate the number of e-mails from the corresponding spatial location . ", "caption_bbox": [98, 413, 731, 457]}], "220": [{"image_id": 0, "file_name": "220_00.png", "page": 3, "dpi": 300, "bbox": [432, 270, 732, 607], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Decision tree for the sketchiness parameter. The leaf nodes indicate sketchiness values; internal nodes corre- spond to the low-level parameters. ", "caption_bbox": [430, 613, 731, 657]}, {"image_id": 1, "file_name": "220_01.png", "page": 4, "dpi": 300, "bbox": [450, 112, 714, 373], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: P is the direction vector; L is the step size that is required to change the sketchiness value from one to zero. ", "caption_bbox": [430, 379, 731, 407]}, {"image_id": 2, "file_name": "220_02.png", "page": 5, "dpi": 300, "bbox": [442, 112, 723, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Graph showing the Euclidean distance between the images generated (at each step) and the target image in the high-level space. Steps 1 to 10 correspond to the images in Figures 5 (a) to (l). ", "caption_bbox": [430, 314, 731, 373]}, {"image_id": 3, "file_name": "220_03.png", "page": 5, "dpi": 300, "bbox": [118, 364, 382, 625], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An example where the new coordinate position can belong to a wrong bin. ", "caption_bbox": [98, 631, 399, 659]}, {"image_id": 4, "file_name": "220_04.png", "page": 6, "dpi": 300, "bbox": [107, 609, 389, 799], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Graph showing change in the contrast value at each step. Step number 1 to 10 correspond to the images Figure 5 (a) to (l). ", "caption_bbox": [98, 810, 399, 854]}, {"image_id": 5, "file_name": "220_05.png", "page": 6, "dpi": 300, "bbox": [115, 112, 716, 531], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Images generated by modifying the smoothness value of the tomato. The value of smoothness decreases from (a) to (f). ", "caption_bbox": [98, 540, 730, 568]}, {"image_id": 6, "file_name": "220_06.png", "page": 7, "dpi": 300, "bbox": [123, 112, 709, 930], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Using our system to generate the target image starting from the source image (a).", "caption_bbox": [185, 942, 644, 955]}, {"image_id": 7, "file_name": "220_07.png", "page": 9, "dpi": 300, "bbox": [122, 112, 710, 521], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Images generated by changing different high-level values of the foot dataset.", "caption_bbox": [196, 530, 633, 543]}], "221": [{"image_id": 0, "file_name": "221_00.png", "page": 2, "dpi": 300, "bbox": [434, 121, 725, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Histogram of MR renal arteries data set, full and magnified scale. The main peak completely dominates the minor peak from the arteries (orange), which is the interest- ing tissue. In full scale, the artery peak is hardly visible. ", "caption_bbox": [430, 236, 731, 295]}, {"image_id": 1, "file_name": "221_01.png", "page": 4, "dpi": 300, "bbox": [434, 121, 723, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Classification probability. The probability p1 is a function of the range weight wr (\u03a61 ). The transformation is defined by the confidence levels wA1 and wB1 . ", "caption_bbox": [430, 236, 731, 281]}, {"image_id": 2, "file_name": "221_02.png", "page": 4, "dpi": 300, "bbox": [102, 121, 397, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Adaptive Trapezoid. Top: The peak detection re- sults in a PRH (gray), to which a Gaussian is fitted (blue), which defines the Adaptive Trapezoid (red). Bottom: The re- sulting rendering. A low-opacity gray ramp is added to the TF for clarity. ", "caption_bbox": [98, 436, 399, 510]}, {"image_id": 3, "file_name": "221_03.png", "page": 5, "dpi": 300, "bbox": [130, 112, 370, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: 2D TF. The traditional 1D TF is extended with a material classification dimension. Trapezoids for overlap- ping materials are placed at extreme classification values and the 2D TF is interpolated in between them. ", "caption_bbox": [98, 261, 399, 320]}, {"image_id": 4, "file_name": "221_04.png", "page": 5, "dpi": 300, "bbox": [434, 117, 712, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A block histogram from a medical CT volume and its piece-wise constant approximation using 12 segments. ", "caption_bbox": [430, 248, 731, 276]}, {"image_id": 5, "file_name": "221_05.png", "page": 6, "dpi": 300, "bbox": [102, 122, 395, 387], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Automatic peak detection. Top: MR biliary duct data set, \u03b5 = 0.5. The position of the segmented peaks cor- respond well to the automatic detection. Bottom: MR renal arteries data set, \u03b5 = 0.95. One of the detected peaks coin- cides well with the true peak from the segmentation. ", "caption_bbox": [98, 399, 399, 473]}, {"image_id": 6, "file_name": "221_06.png", "page": 7, "dpi": 300, "bbox": [98, 453, 732, 712], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Highlighting a coronary artery. Left: With a 1D TF, the brightness of the large vessels disturb the study of the coronary artery. Middle: With a classifying 2D TF, voxel-centric nbh, the coronary artery stands out (wA1 =0.3,wB1 =0.1,wA2 =0.2,wB2 =0.4). Right: A classifying 2D TF for double block nbh also highlights the coronary artery, while introducing speckle artifacts at the large vessel boundaries (wA1 =0.5,wB1 =0.2,wA2 =0.2,wB2 =0.4). Ranges: \u03a61 =[1300,1500],\u03a62 =[900,1150]. ", "caption_bbox": [98, 722, 731, 781]}, {"image_id": 7, "file_name": "221_07.png", "page": 7, "dpi": 300, "bbox": [98, 111, 732, 363], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Separation of spongy bone and vessels. Left: With a 1D TF, spongy bone turns red. Middle: With a classifying 2D TF, voxel-centric nbh, the vessels stand out from the background (wA1 =0.0,wB1 =0.1,wA2 =0.2,wB2 =\u22120.1). Right: A classifying 2D TF for double block nbh achieves the separation with minor artifacts (wA1 =0.0,wB1 =0.05,wA2 =0.2,wB2 =\u22120.2). Ranges: \u03a61 =[1300,2000],\u03a62 = [900,1150]. ", "caption_bbox": [98, 374, 731, 433]}, {"image_id": 8, "file_name": "221_08.png", "page": 8, "dpi": 300, "bbox": [98, 111, 395, 485], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Highlighting of liver tumor. Top: 1D TF render- ing, the tumor area is slightly darker than the liver. Middle: An attempt to highlight the tumor with a 1D TF. Bottom: A classifying 2D TF, voxel-centric nbh, clearly highlights the tumor and the spleen (wA1 =0.1,wB1 =0.6,wA2 =0.2,wB2 =0.1,\u03a61 = [150,200],\u03a62 =[0,140]). ", "caption_bbox": [98, 495, 399, 584]}], "222": [{"image_id": 0, "file_name": "222_00.png", "page": 3, "dpi": 300, "bbox": [431, 112, 732, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: 2D Histograms based on scalar values on the x- axis and gradients on the y-axis (left) and corresponding spatialized transfer functions for r = 0.1 (right). In the bot- tom row noise has been smoothed out by using two-times super-sampling and a k-neighborhood with k = 2. ", "caption_bbox": [430, 322, 731, 400]}, {"image_id": 1, "file_name": "222_01.png", "page": 4, "dpi": 300, "bbox": [431, 512, 732, 813], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: STF based visualization of the Bonsai #1 dataset [Roe04] using pseudo-shading. The leaves (green) and the trunk (brown) have been selected by high-lighting the corresponding classes in the STF. ", "caption_bbox": [430, 820, 731, 883]}, {"image_id": 2, "file_name": "222_02.png", "page": 5, "dpi": 300, "bbox": [431, 173, 732, 325], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Benefit of pre-integrating along the scalar axis of 2D transfer functions. A pre-integrated visualization of the Neghip dataset [Roe04] is shown on the left. Highest gradi- ents are depicted in yellow. On the right slicing artifacts are clearly visible which are due to disabled pre-integration. ", "caption_bbox": [430, 332, 731, 410]}, {"image_id": 3, "file_name": "222_03.png", "page": 6, "dpi": 300, "bbox": [99, 112, 400, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: STF guided segmentation of the Carp. In the left image the bones were selected in the STF (the skin is ad- ditionally shown in white). Then the Carp was segmented by performing region growing on the selected parts. Each segment is given a random hue value. After that the orange spine segment was picked and emphasized. As a result, the spine protrusion is clearly visible. Otherwise it would be ob- scured by the head bones. ", "caption_bbox": [98, 270, 399, 394]}, {"image_id": 4, "file_name": "222_04.png", "page": 7, "dpi": 300, "bbox": [99, 112, 400, 411], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: STF example visualizations from top left to bot- tom right: visualization of an aneurysm (CTA), separation of brain and skull (MRI/T1+PD), identification of nerve pathways (DTI/MRI+FA), visualization of tumor and skull (CT+MRI). ", "caption_bbox": [98, 418, 399, 496]}], "223": [{"image_id": 0, "file_name": "223_00.png", "page": 3, "dpi": 300, "bbox": [450, 119, 722, 810], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: 3D scatterplots as rendered by our program. (a) A standard xyz-plot of time step 60 of a 276 time step linear accelerator simulation is shown. (b) The same data set is shown rendered using our novel oriented-disk approach. To a certain extent, the influence of the (c) electromagnetic field on the particles can be observed in this style of rendering by visually piecing together the facets of neighboring disks. ", "caption_bbox": [430, 815, 731, 924]}, {"image_id": 1, "file_name": "223_01.png", "page": 4, "dpi": 300, "bbox": [436, 112, 727, 398], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Demonstration of manual particle selection through the use of a painting tool. (a) Particles belonging to the \u201cspiral arm\u201d of an early time step (left) are painted on. (b) These particles are marked red and can be seen in a later time step (right) of the simulation. The red circle rep- resents the paint brush used for selection. ", "caption_bbox": [430, 403, 731, 496]}, {"image_id": 2, "file_name": "223_02.png", "page": 5, "dpi": 300, "bbox": [98, 112, 401, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Example showing a xyz-plot of time step 214 of a 276 time step linear accelerator simulation run. Points are colorized according to the magnitude of their momen- tum vector. ", "caption_bbox": [98, 357, 399, 420]}, {"image_id": 3, "file_name": "223_03.png", "page": 6, "dpi": 300, "bbox": [117, 122, 736, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Correlating points across different views of the same data. An integrated beam experiment (IBX) data set represents a beam after it has undergone significant phase space distortion. (a) An Rv R v\u0398 -plot of a polar coordinate version of the data is plotted in Cartesian coordinates. R denotes the radial coordinate, v R the velocity of R, and v\u0398 the velocity of the angular coordinate \u0398. A typical \u201choe\u201d-shaped distribution is observed. (b) The corresponding xp x py -plot of a Cartesian coordinate version of the data is plotted. (c) Attention is brought to the interesting shape representing the effects of strong anharmonic forces in the xpx py -plot by making selections other than the red selection invisible. ", "caption_bbox": [98, 337, 731, 431]}, {"image_id": 4, "file_name": "223_04.png", "page": 7, "dpi": 300, "bbox": [149, 125, 344, 812], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Tracking particle motion over time in a 500 time step beam injector simulation. (a) The px py pz -plot of the full distribution in time step 500, at the end of the simulation, where four jets of particles are clearly visible and have been selected in four distinct groups, each with its own color. Fig- ures (b), (c), and (d) show xyz-plots of time steps 90, 370, and 500, respectively, of the four selected groups, the core of the beam being rendered invisible. Note that each group re- mains in a tight formation even though heavy particle mixing is occurring, but is spread over multiple beamlets. ", "caption_bbox": [98, 817, 399, 971]}], "224": [{"image_id": 0, "file_name": "224_00.png", "page": 2, "dpi": 300, "bbox": [388, 90, 693, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The interconnection between the BioBrowser modules. The five display modules can be used indepen- dently, even in the same frame, to blend visualization styles. ", "caption_bbox": [388, 320, 690, 364]}, {"image_id": 1, "file_name": "224_01.png", "page": 2, "dpi": 300, "bbox": [56, 356, 358, 495], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Structure of a protein chain: a peptide bond links amino acids in a linear way ", "caption_bbox": [56, 505, 358, 534]}, {"image_id": 2, "file_name": "224_02.png", "page": 3, "dpi": 300, "bbox": [71, 520, 344, 794], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Ball-and-Stick visualization of protein 1axq", "caption_bbox": [71, 804, 342, 817]}, {"image_id": 3, "file_name": "224_03.png", "page": 3, "dpi": 300, "bbox": [412, 567, 667, 759], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: How to correct the saved z-depth of the billboard when projecting it onto the viewplane. ", "caption_bbox": [388, 768, 689, 796]}, {"image_id": 4, "file_name": "224_04.png", "page": 3, "dpi": 300, "bbox": [403, 91, 676, 363], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Space-fill visualization of protein 1axq", "caption_bbox": [416, 374, 663, 387]}, {"image_id": 5, "file_name": "224_05.png", "page": 3, "dpi": 300, "bbox": [56, 129, 353, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Billboard for an atom (a) and a bond (b), Gener- ating the alpha channel of the 2D texture (c) ", "caption_bbox": [56, 273, 358, 301]}, {"image_id": 6, "file_name": "224_06.png", "page": 4, "dpi": 300, "bbox": [391, 656, 689, 719], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Computation of the base mesh. The stars show the positions of the C\u03b1 atoms. While the generated base mesh does not need to include the C\u03b1 positions, the spline curve that is generated at run time always does. ", "caption_bbox": [388, 741, 689, 800]}, {"image_id": 7, "file_name": "224_07.png", "page": 4, "dpi": 300, "bbox": [75, 619, 344, 879], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Stick visualization of protein 1axq", "caption_bbox": [95, 890, 318, 903]}, {"image_id": 8, "file_name": "224_08.png", "page": 5, "dpi": 300, "bbox": [63, 296, 353, 585], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Ribbon computation for a helix structure. a) The generated base mesh. b) Very low detail wireframe display of the ribbon mesh. c) Medium detail wireframe display. d) High detail wireframe display. e) Very low detail display of the ribbon mesh. f) High detail display of the ribbon mesh. While moving the structure, the detail is automatically ad- justed to reach a frame rate of 20\u201324 fps. For still images, the highest detail setting is used. ", "caption_bbox": [56, 608, 358, 728]}, {"image_id": 9, "file_name": "224_09.png", "page": 5, "dpi": 300, "bbox": [403, 572, 704, 836], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The solvent accessible surface (SAS) is traced by the center of the probe. The solvent excluded surface (SES) is the topological boundary of the union of all possible probes which do not overlap with the molecule. ", "caption_bbox": [388, 847, 690, 906]}, {"image_id": 10, "file_name": "224_10.png", "page": 5, "dpi": 300, "bbox": [399, 88, 680, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Result images for molecules, rendered with high detail. a) Oxidized Dsba Crystal Form II (21 ribbons). Note the arrows generated in the sheets. b) Cholesterol Oxidase (69 ribbons) ", "caption_bbox": [388, 270, 690, 329]}, {"image_id": 11, "file_name": "224_11.png", "page": 6, "dpi": 300, "bbox": [61, 707, 355, 821], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Reduced surface for the protein 1a3i. On the right the SAS edges are shown, too. ", "caption_bbox": [56, 832, 358, 860]}, {"image_id": 12, "file_name": "224_12.png", "page": 7, "dpi": 300, "bbox": [403, 606, 677, 822], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: First impression of a semantic lens", "caption_bbox": [422, 832, 656, 845]}, {"image_id": 13, "file_name": "224_13.png", "page": 7, "dpi": 300, "bbox": [64, 556, 356, 666], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: (a) Calculating a B\u00e9zier Curve (b) Generating a triangular B\u00e9zier patch (c) Generating a quadrangular B\u00e9zier patch ", "caption_bbox": [56, 683, 358, 727]}, {"image_id": 14, "file_name": "224_14.png", "page": 7, "dpi": 300, "bbox": [392, 89, 688, 201], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Generated solvent excluded surface for protein 1a3i. On the left with adaptive tessellation and on the right with full resolution. ", "caption_bbox": [388, 211, 690, 255]}], "225": [{"image_id": 0, "file_name": "225_00.png", "page": 3, "dpi": 300, "bbox": [430, 244, 733, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: With object-based transparency assignment, the location of lymph nodes cannot be depicted effectively. ", "caption_bbox": [430, 475, 731, 503]}, {"image_id": 1, "file_name": "225_01.png", "page": 3, "dpi": 300, "bbox": [139, 112, 360, 376], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Color table for the standardized visualization of neck structures ", "caption_bbox": [98, 929, 399, 957]}, {"image_id": 2, "file_name": "225_02.png", "page": 4, "dpi": 300, "bbox": [126, 112, 373, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Emphasized lymph node partially behind the M. sternocleidomastoideus. Note the use of a cutaway view as well as the thin silhouette line to enhance depth perception. ", "caption_bbox": [98, 392, 399, 435]}, {"image_id": 3, "file_name": "225_03.png", "page": 5, "dpi": 300, "bbox": [458, 561, 705, 797], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Possible infiltration of the M. sternocleidomas- toideus. Silhouette lines form an intersection line between muscle and lymph nodes. ", "caption_bbox": [430, 806, 731, 849]}, {"image_id": 4, "file_name": "225_04.png", "page": 5, "dpi": 300, "bbox": [458, 112, 705, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Color-coded distance of a lymph node to the M. sternocleidomastoideus. The 2 mm distance is coded in red, 5 mm in yellow. ", "caption_bbox": [430, 370, 731, 413]}, {"image_id": 5, "file_name": "225_05.png", "page": 6, "dpi": 300, "bbox": [430, 588, 733, 722], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Representation of a lymph node with a central necrosis marked in 3d and in a 2d view. ", "caption_bbox": [430, 735, 731, 763]}, {"image_id": 6, "file_name": "225_06.png", "page": 6, "dpi": 300, "bbox": [461, 112, 702, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Color-coded lymph node size. Two levels are used: yellow below 1cm and turquoise above. The exact values are readable via tooltip. ", "caption_bbox": [430, 349, 731, 392]}, {"image_id": 7, "file_name": "225_07.png", "page": 7, "dpi": 300, "bbox": [477, 614, 686, 784], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: N. hypoglossus (yellow) and A. jugularis (red). Notice the slice artifacts in the course of the nerve near the tumor (dark yellow). ", "caption_bbox": [430, 793, 731, 836]}, {"image_id": 8, "file_name": "225_08.png", "page": 7, "dpi": 300, "bbox": [430, 255, 733, 416], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: A large tumor (green) is infiltrating the Pharynx. The upper tail also infiltrates the cranial base. ", "caption_bbox": [430, 429, 731, 457]}], "226": [{"image_id": 0, "file_name": "226_00.png", "page": 3, "dpi": 300, "bbox": [430, 673, 733, 788], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The original volume has been segmented in ad- vance. Thus, it may be restricted to bones, gallbladder, aorta, kidneys, milt and lung. The gallbladder is not visible because of the chosen transfer function. ", "caption_bbox": [430, 801, 734, 860]}, {"image_id": 1, "file_name": "226_01.png", "page": 4, "dpi": 300, "bbox": [430, 390, 733, 833], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Sequence for combining all rendering styles.", "caption_bbox": [443, 845, 719, 858]}, {"image_id": 2, "file_name": "226_02.png", "page": 4, "dpi": 300, "bbox": [98, 776, 401, 930], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Scene graph for silhouette rendering.", "caption_bbox": [129, 942, 368, 955]}, {"image_id": 3, "file_name": "226_03.png", "page": 5, "dpi": 300, "bbox": [98, 111, 400, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Scene graph for combining all rendering styles.", "caption_bbox": [103, 279, 394, 292]}, {"image_id": 4, "file_name": "226_04.png", "page": 5, "dpi": 300, "bbox": [430, 118, 733, 410], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Removing self-occluding lines. In (a) the render- ing of hidden lines is prevented due to a collective z-buffer. Individual HLR (c) solves this problem. Additional dashing and thinner hidden lines (d) produce an even stronger effect. ", "caption_bbox": [430, 422, 734, 481]}, {"image_id": 5, "file_name": "226_05.png", "page": 6, "dpi": 300, "bbox": [432, 119, 731, 406], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Selected variants without lines. Other visualiza- tions shown are transparent versions of Figure (a) and (b). ", "caption_bbox": [430, 418, 734, 446]}, {"image_id": 6, "file_name": "226_06.png", "page": 6, "dpi": 300, "bbox": [98, 721, 401, 803], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Different coronal visualizations of the affected vascular territories. Left to right: affected vascular territo- ries displayed via silhouettes, all segments transparent, and healthy territories via silhouettes. ", "caption_bbox": [98, 815, 402, 874]}, {"image_id": 7, "file_name": "226_07.png", "page": 7, "dpi": 300, "bbox": [113, 112, 386, 190], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Extraction of the decision tree for the medical doctors after critical examination. V1 refers to Figure 7(a), V2 to Figure 9(b), V3 to Figure 4(e), and V4 to Figure 9(a). From these Figure 7(a) was voted to be best. ", "caption_bbox": [98, 201, 401, 260]}, {"image_id": 8, "file_name": "226_08.png", "page": 9, "dpi": 300, "bbox": [416, 373, 729, 457], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Selected variants without lines.", "caption_bbox": [468, 462, 677, 475]}, {"image_id": 9, "file_name": "226_09.png", "page": 9, "dpi": 300, "bbox": [97, 373, 414, 459], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Different coronal visualizations of the liver.", "caption_bbox": [122, 462, 392, 475]}, {"image_id": 10, "file_name": "226_10.png", "page": 9, "dpi": 300, "bbox": [100, 218, 730, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A number of possibilities to visualize COs, NFOs, and FOs differently.", "caption_bbox": [212, 353, 616, 366]}, {"image_id": 11, "file_name": "226_11.png", "page": 9, "dpi": 300, "bbox": [98, 111, 733, 201], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Sequence for combining all rendering styles.", "caption_bbox": [277, 204, 553, 217]}], "227": [{"image_id": 0, "file_name": "227_00.png", "page": 3, "dpi": 300, "bbox": [104, 80, 405, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Modified image-aligned sheet-buffered splat- ting, as seen from the top. Kernels and planes extend to 3D. A viewing angle of 0\u00b0 is shown, but any viewing angle is possible since the kernels are radially symmetric. ", "caption_bbox": [110, 270, 400, 325]}, {"image_id": 1, "file_name": "227_01.png", "page": 3, "dpi": 300, "bbox": [444, 566, 725, 763], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of the kernel warping process in 2D. In the original image-aligned splatting algorithm, the kernel slice tables would store the pre-integration of the rays across the slab, traversing it orthogonal to the slab\u2019s two bounding planes. However, the warping undoes this orthog- onality. The integrals due to the red rays would be looked up and not those due to the warped black rays. This could lead to slight errors, which are different for each slab posi- tion. Therefore we do not store the slab integrals, but only use a cross-sectional texture of the radially symmetric RBF (we use Gaussians), which is then scaled by the orthogonal kernel value. ", "caption_bbox": [445, 769, 741, 935]}, {"image_id": 2, "file_name": "227_02.png", "page": 4, "dpi": 300, "bbox": [111, 88, 407, 224], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Ellipsoidal kernel sliced (a) in screen space, (b) in unit texture space (unit sphere space). The u,v,n vectors are shown in red, blue, and black respectively. These 3 vectors, along with the size of the direction vector n pro- vide enough information to create all the intersecting slices of the ellipsoid in screen space (progressing along the viewing direction) and evaluate the corresponding Gaussian kernel by texture-mapping the 2D slices from the unit sphere space. ", "caption_bbox": [110, 234, 400, 358]}, {"image_id": 3, "file_name": "227_03.png", "page": 9, "dpi": 300, "bbox": [110, 89, 738, 444], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": " (e)                          (f)                                                                   (h) Figure 4: Example renderings of irregular datasets using our(g)                                                              image aligned splattr: (a,b) two views of Blunt Fin, (c,d) two different views of the Combustion dataset, (e) deformed chess piece, (f) deformed green monster, (g) Deformed toy car, (h) deformed toy train. ", "caption_bbox": [109, 443, 731, 492]}], "228": [{"image_id": 0, "file_name": "228_00.png", "page": 5, "dpi": 300, "bbox": [162, 445, 335, 614], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Calculating the intersection of the ray with the local approximation stored in each sample point. ", "caption_bbox": [98, 629, 399, 662]}, {"image_id": 1, "file_name": "228_01.png", "page": 6, "dpi": 300, "bbox": [103, 429, 395, 557], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The Bucky Ball dataset. (a) The final result of ap- plying the predictor-corrector method. (b) The points pro- jected by the predictor at a distance greater than a pre- defined error are shown in red (see colorplate). (c) The out- put points from the predictor projected by the corrector at a distance greater than the error are shown in green. ", "caption_bbox": [98, 574, 399, 667]}, {"image_id": 2, "file_name": "228_02.png", "page": 6, "dpi": 300, "bbox": [449, 419, 726, 739], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: PSS extracted for the Engine and the Cadaver Head datasets using the gradient magnitude (top) and iso- values (bottom). ", "caption_bbox": [430, 747, 731, 795]}, {"image_id": 3, "file_name": "228_03.png", "page": 7, "dpi": 300, "bbox": [143, 348, 355, 561], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: GPU-based ray-tracing of PSS for the Horse point cloud. ", "caption_bbox": [98, 568, 399, 601]}, {"image_id": 4, "file_name": "228_04.png", "page": 7, "dpi": 300, "bbox": [494, 112, 672, 276], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: PSS for the vertices of an iso-surface mesh ex- tracted from the Knee dataset with marching cubes. ", "caption_bbox": [430, 284, 731, 317]}], "229": [{"image_id": 0, "file_name": "229_00.png", "page": 3, "dpi": 300, "bbox": [412, 88, 732, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Illustration of the algorithm.", "caption_bbox": [483, 348, 679, 361]}, {"image_id": 1, "file_name": "229_01.png", "page": 4, "dpi": 300, "bbox": [98, 88, 413, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Texture layout for particle attributes and intensi- ties (shown as \u2206T \u00d7 h = 4 ). ", "caption_bbox": [98, 283, 399, 312]}, {"image_id": 2, "file_name": "229_02.png", "page": 5, "dpi": 300, "bbox": [98, 461, 401, 764], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: JP8 dataset.", "caption_bbox": [191, 775, 306, 788]}, {"image_id": 3, "file_name": "229_03.png", "page": 5, "dpi": 300, "bbox": [98, 88, 415, 415], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: PSI dataset.", "caption_bbox": [192, 426, 306, 439]}], "230": [{"image_id": 0, "file_name": "230_00.png", "page": 2, "dpi": 300, "bbox": [459, 520, 704, 747], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Hyperstreamline visualization of a whole-brain tracking. The viewpoint is positioned left, posterior above the brain. Green segments indicate tracking in reliable re- gions with high anisotropy. Yellow tube sections suggest fiber crossings. The absence of red segments in the cen- tral parts of the hyperstreamlines documents the correctness of the fiber tracking algorithm. Dataset as used for perfor- mance measurements in Table 1. ", "caption_bbox": [430, 757, 731, 877]}, {"image_id": 1, "file_name": "230_01.png", "page": 3, "dpi": 300, "bbox": [467, 158, 695, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Ellipse in polar coordinates.", "caption_bbox": [481, 303, 680, 316]}, {"image_id": 2, "file_name": "230_02.png", "page": 3, "dpi": 300, "bbox": [426, 706, 717, 810], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Definition of a tubelet along x.", "caption_bbox": [476, 822, 685, 835]}, {"image_id": 3, "file_name": "230_03.png", "page": 4, "dpi": 300, "bbox": [446, 390, 717, 541], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Correction of distance and interpolation range. El is the left cutting plane, ~Nl the corresponding normal vec- tor. ", "caption_bbox": [430, 552, 731, 595]}, {"image_id": 4, "file_name": "230_04.png", "page": 4, "dpi": 300, "bbox": [123, 420, 375, 632], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Distance measurement from the current position ~p to the rotated ellipse ~x(x, \u03d5) within a plane of constant x. ", "caption_bbox": [98, 645, 399, 674]}, {"image_id": 5, "file_name": "230_05.png", "page": 5, "dpi": 300, "bbox": [477, 536, 731, 726], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Local tubelet coordinates (green) in relation to world coordinates (black). ", "caption_bbox": [430, 738, 731, 766]}, {"image_id": 6, "file_name": "230_06.png", "page": 6, "dpi": 300, "bbox": [437, 678, 726, 761], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The left figure shows a bundle of hyperstreamlines traversing a region of planar diffusion which leads to yel- low coloring and a flattening of the tube. On the right side, some segments showing extreme torsion are depicted. The displayed extreme torsions are added manually as a proof of concept by switching off angle correction, thus allowing ro- tations larger than 90 degrees between consecutive ellipses. ", "caption_bbox": [430, 772, 731, 876]}, {"image_id": 7, "file_name": "230_07.png", "page": 6, "dpi": 300, "bbox": [105, 567, 394, 825], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: These two figures show the same pyramidal tract rendered with standard streamline (left) and with our method (right) in combination with direct volume rendering of a T1- weighted MRI dataset. For coloring the principal eigenvec- tors are mapped into RGB-color space. ", "caption_bbox": [98, 836, 399, 910]}, {"image_id": 8, "file_name": "230_08.png", "page": 7, "dpi": 300, "bbox": [115, 757, 384, 832], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Interpolated vertex positions (left) with erro- neous self-intersection vs. interpolated ellipse orientation (right). ", "caption_bbox": [98, 843, 399, 886]}], "231": [{"image_id": 0, "file_name": "231_00.png", "page": 2, "dpi": 300, "bbox": [438, 117, 742, 576], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2 Left: These are examples of unnatural images. The first is purely random noise. The second is a radial gradient repeated ten times. The third is just a scribbling. Right: These plots correspond to the power spectra of the images on the left. The x-axis is the frequency on a log scale, and the y-axis is the amplitude which is also on a log scale. ", "caption_bbox": [438, 589, 735, 689]}, {"image_id": 1, "file_name": "231_01.png", "page": 2, "dpi": 300, "bbox": [109, 117, 414, 576], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1 Left: These are examples of natural images. Right: These plots correspond to the power spectra of the images on the left. The x-axis is the frequency on a log scale, and the y-axis is the amplitude which is also on a log scale. ", "caption_bbox": [109, 588, 406, 659]}, {"image_id": 2, "file_name": "231_02.png", "page": 3, "dpi": 300, "bbox": [107, 117, 412, 424], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3 These images were generated by randomly placing squares with random Gaussian-fit grayscale values. The size distributions are power (a), exponential (b), linear (c), and constant (d). ", "caption_bbox": [108, 425, 411, 482]}, {"image_id": 3, "file_name": "231_03.png", "page": 3, "dpi": 300, "bbox": [441, 118, 733, 412], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4 The power spectra of images generated by occluding squares. Notice that the power function stays slightly above the others. ", "caption_bbox": [438, 426, 735, 468]}, {"image_id": 4, "file_name": "231_04.png", "page": 3, "dpi": 300, "bbox": [452, 481, 718, 739], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5 The slopes of the linear trends fit to the power spectra in Figure 4. ", "caption_bbox": [438, 759, 735, 787]}, {"image_id": 5, "file_name": "231_05.png", "page": 4, "dpi": 300, "bbox": [446, 465, 718, 731], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8 The slope of the linear trends fit to the power spectra of the non-overlapping squares. ", "caption_bbox": [438, 748, 735, 776]}, {"image_id": 6, "file_name": "231_06.png", "page": 4, "dpi": 300, "bbox": [447, 118, 737, 409], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7 The power spectra of images generated by rows of non-overlapping squares ", "caption_bbox": [447, 422, 735, 450]}, {"image_id": 7, "file_name": "231_07.png", "page": 4, "dpi": 300, "bbox": [107, 117, 401, 427], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6 These Treemap [JS91] resembling images were generated by creating rows of non-overlapping squares with random greyscale values. The size distributions are power (a), exponential (b), linear(c), and constant (d). ", "caption_bbox": [108, 427, 405, 484]}, {"image_id": 8, "file_name": "231_08.png", "page": 5, "dpi": 300, "bbox": [438, 822, 727, 927], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10 Here are select thumbnails from the InfoVis 2004 contest. The left two visualizations received 1st place prizes. The right visualization received a 2nd place prize. ", "caption_bbox": [438, 940, 740, 982]}, {"image_id": 9, "file_name": "231_09.png", "page": 5, "dpi": 300, "bbox": [443, 119, 736, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9 The average deviation from the linear-fit trends of the power spectra from two natural images as well as the images from Figure 6. ", "caption_bbox": [438, 362, 735, 404]}, {"image_id": 10, "file_name": "231_10.png", "page": 6, "dpi": 300, "bbox": [448, 713, 727, 936], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13 The absolute value of the correlation between the user response time for each interface and the respective naturalness of a screenshot of that image ", "caption_bbox": [438, 946, 735, 988]}, {"image_id": 11, "file_name": "231_11.png", "page": 6, "dpi": 300, "bbox": [107, 487, 413, 748], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12 In the results from the 2005 Infovis contest, a pattern between the first place, second place, and honorable mention averages is clearly prevalent. The error bars show the total range for each rank. All of the entrants\u2019     images     can  be     found    at    http: //ivpr.cs.uml.edu/infovis05 ", "caption_bbox": [108, 761, 405, 846]}, {"image_id": 12, "file_name": "231_12.png", "page": 6, "dpi": 300, "bbox": [107, 122, 413, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11 This graph shows our analysis results from the 2004 Infovis contest. We measured the distance of the linear-fit trend from -2. We then took the average of those who came in first place and those who came in second place. The error bars show the total range for each rank. ", "caption_bbox": [108, 397, 405, 468]}, {"image_id": 13, "file_name": "231_13.png", "page": 7, "dpi": 300, "bbox": [107, 118, 735, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14 These are treemaps generated using power (top), linear (middle), and constant (bottom) size distributions. Their corresponding power spectra are next to them. Notice the low average deviation for the power function. ", "caption_bbox": [108, 285, 735, 313]}], "232": [{"image_id": 0, "file_name": "232_00.png", "page": 3, "dpi": 300, "bbox": [391, 210, 698, 612], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Cushion shading and coloring design", "caption_bbox": [419, 614, 663, 627]}, {"image_id": 1, "file_name": "232_01.png", "page": 3, "dpi": 300, "bbox": [59, 182, 366, 585], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Multiple sorting in the table view", "caption_bbox": [98, 588, 320, 601]}, {"image_id": 2, "file_name": "232_02.png", "page": 4, "dpi": 300, "bbox": [59, 64, 660, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Interaction between cushions, sorting, and equal-value row ranges", "caption_bbox": [180, 335, 569, 348]}, {"image_id": 3, "file_name": "232_03.png", "page": 4, "dpi": 300, "bbox": [392, 384, 693, 623], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visualization simplification via clustering", "caption_bbox": [409, 633, 673, 646]}, {"image_id": 4, "file_name": "232_04.png", "page": 5, "dpi": 300, "bbox": [59, 516, 360, 693], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Subsampling artifacts (large cushions, left) are removed by clustering (right) ", "caption_bbox": [59, 703, 360, 731]}, {"image_id": 5, "file_name": "232_05.png", "page": 5, "dpi": 300, "bbox": [375, 64, 693, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Blending text and graphics", "caption_bbox": [446, 312, 637, 325]}, {"image_id": 6, "file_name": "232_06.png", "page": 6, "dpi": 300, "bbox": [59, 64, 704, 279], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Table view zooming from text level (a) to whole-table-in-window (d)", "caption_bbox": [177, 281, 572, 294]}, {"image_id": 7, "file_name": "232_07.png", "page": 6, "dpi": 300, "bbox": [61, 331, 359, 814], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Treemap view: stock data visualization scenarios", "caption_bbox": [59, 825, 360, 838]}, {"image_id": 8, "file_name": "232_08.png", "page": 7, "dpi": 300, "bbox": [62, 246, 357, 817], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Treemap view: intraday change (top); open price versus time (bottom) ", "caption_bbox": [59, 827, 360, 855]}], "233": [{"image_id": 0, "file_name": "233_00.png", "page": 1, "dpi": 300, "bbox": [430, 678, 733, 780], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Phyllotactic patterns in plants. Images are copy- right of Tillman Steinbrecher (left) and Tobias Isenberg (mid- dle, right), used with permission. ", "caption_bbox": [430, 790, 734, 833]}, {"image_id": 1, "file_name": "233_01.png", "page": 2, "dpi": 300, "bbox": [436, 674, 733, 842], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Development of the phyllotactic pattern (a) and a phyllotactic pattern with 300 nodes using \u03b1 = 137.5\u25e6 (b). ", "caption_bbox": [430, 855, 731, 884]}, {"image_id": 2, "file_name": "233_02.png", "page": 3, "dpi": 300, "bbox": [98, 207, 401, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Different patterns created by changing the angular constant \u03b1. ", "caption_bbox": [98, 314, 399, 343]}, {"image_id": 3, "file_name": "233_03.png", "page": 4, "dpi": 300, "bbox": [98, 157, 733, 928], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Different possible mappings of the 2D pyllotactic patterns to 3D. The second column shows the respective layouts applied to a 5.000 node tree as seen from the same distance in 3D. The third column shows a close-up side view of each layout. ", "caption_bbox": [98, 940, 731, 968]}, {"image_id": 4, "file_name": "233_04.png", "page": 5, "dpi": 300, "bbox": [430, 382, 733, 497], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Using the primary children\u2019s spacing constant to provide more space for secondary children. ", "caption_bbox": [430, 510, 731, 538]}, {"image_id": 5, "file_name": "233_05.png", "page": 5, "dpi": 300, "bbox": [98, 157, 403, 538], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Spherical mapping for PhylloTree Layout IV. The first image (a) shows the spherical coordinates used for the mapping shown in (b). A less effective mapping is shown in (c). How to avoid the apparent node overlap in (b) will be discussed in the following. ", "caption_bbox": [98, 550, 399, 624]}, {"image_id": 6, "file_name": "233_06.png", "page": 5, "dpi": 300, "bbox": [430, 118, 733, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Single level tree with \u03b1 = 137.5\u25e6 ; varying the spacing constant adjusts the space between nodes. ", "caption_bbox": [430, 205, 731, 237]}, {"image_id": 7, "file_name": "233_07.png", "page": 7, "dpi": 300, "bbox": [98, 297, 403, 464], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Constant vs. adaptively chosen spacing constants.", "caption_bbox": [98, 477, 401, 490]}, {"image_id": 8, "file_name": "233_08.png", "page": 8, "dpi": 300, "bbox": [98, 408, 733, 772], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Several real world examples for large unbalanced trees.", "caption_bbox": [245, 784, 584, 797]}, {"image_id": 9, "file_name": "233_09.png", "page": 9, "dpi": 300, "bbox": [98, 299, 733, 531], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Real world examples for large unbalanced trees: files on the University of Maryland\u2019s webserver.", "caption_bbox": [142, 532, 686, 545]}, {"image_id": 10, "file_name": "233_10.png", "page": 9, "dpi": 300, "bbox": [98, 106, 733, 279], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Several large balanced and unbalanced trees using different angular constants.", "caption_bbox": [190, 280, 639, 293]}], "234": [{"image_id": 0, "file_name": "234_00.png", "page": 3, "dpi": 300, "bbox": [430, 113, 733, 416], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: RINGS users found the directory \"pic\" very homo-", "caption_bbox": [430, 436, 731, 457]}, {"image_id": 1, "file_name": "234_01.png", "page": 3, "dpi": 300, "bbox": [98, 111, 401, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Windows Explorer users found the directory \"pic\"", "caption_bbox": [98, 341, 399, 362]}, {"image_id": 2, "file_name": "234_02.png", "page": 4, "dpi": 300, "bbox": [98, 113, 401, 409], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Treemap users found the directory \"pic\" very ho-", "caption_bbox": [98, 429, 399, 450]}, {"image_id": 3, "file_name": "234_03.png", "page": 6, "dpi": 300, "bbox": [98, 119, 732, 321], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The properties of the file directory each subject used to derive the answers to the questions. Users of Windows", "caption_bbox": [98, 347, 730, 368]}, {"image_id": 4, "file_name": "234_04.png", "page": 6, "dpi": 300, "bbox": [438, 440, 725, 728], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The average time taken by users to complete each", "caption_bbox": [430, 738, 731, 759]}, {"image_id": 5, "file_name": "234_05.png", "page": 7, "dpi": 300, "bbox": [430, 112, 734, 404], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: An example of two similar directories (\"viewpoly-", "caption_bbox": [430, 409, 731, 430]}, {"image_id": 6, "file_name": "234_06.png", "page": 7, "dpi": 300, "bbox": [102, 115, 398, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The difficulty in answering the questions by the", "caption_bbox": [98, 298, 399, 319]}], "235": [{"image_id": 0, "file_name": "235_00.png", "page": 1, "dpi": 300, "bbox": [98, 354, 731, 490], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Homogeneous industrial work piece segmentation based on 3D watershed and constrained elastic-surface nets", "caption_bbox": [110, 500, 719, 513]}, {"image_id": 1, "file_name": "235_01.png", "page": 2, "dpi": 300, "bbox": [475, 112, 686, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: CT dataset of an industrial filter housing, large penetration lengths and complex geometry result in heavy artefacts. (a) thinning and holes, (b) additional volume through thickening ", "caption_bbox": [430, 344, 731, 403]}, {"image_id": 2, "file_name": "235_02.png", "page": 3, "dpi": 300, "bbox": [459, 112, 703, 548], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Workpiece segmentation and surface extraction of homogeneous industrial components; Input: volume dataset with distorted density values, Output: Surface mesh ", "caption_bbox": [430, 562, 731, 605]}, {"image_id": 3, "file_name": "235_03.png", "page": 4, "dpi": 300, "bbox": [102, 181, 397, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Anisotropic-Diffusion Filter, axial cross section through a filter housing, (a) scattered radiation artefacts throughout the material, (b) after anisotropic diffusion filter- ing small artefacts are removed; some artefacts are marked by ellipses ", "caption_bbox": [98, 283, 399, 357]}, {"image_id": 4, "file_name": "235_04.png", "page": 5, "dpi": 300, "bbox": [142, 317, 357, 476], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: CT-scan of workpiece one. This reference ob- ject creates severe scattered radiation and beam hardening artefacts in the area of the drill holes and the rectangular milling. In the areas affected by artefacts the geometry is modified (see smaller drill hole) ", "caption_bbox": [98, 486, 399, 560]}, {"image_id": 5, "file_name": "235_05.png", "page": 5, "dpi": 300, "bbox": [474, 111, 689, 528], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: CT scan of workpiece two, Oblique view (a) shows the reference object which is used for geometric and dimensional measurement tasks. Along the horizontal axis the outer ring diameters and wall thicknesses increase, while the inner ring diameters remain constant. Small variations of the data values result in a fine texturing in the result im- ages. The sagital cross-section (b) shows increasing arte- facts in the centre drill hole when wall thicknesses are in- creasing ", "caption_bbox": [430, 541, 731, 676]}, {"image_id": 6, "file_name": "235_06.png", "page": 6, "dpi": 300, "bbox": [459, 111, 704, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Axial cross section of workpiece one. Severe scat- tered radiation and beam hardening are present. Greyvalues of the drill holes and the rectangular milling are elevated ", "caption_bbox": [430, 281, 731, 324]}, {"image_id": 7, "file_name": "235_07.png", "page": 6, "dpi": 300, "bbox": [474, 349, 689, 687], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Surface model of workpiece one: (a) best isosur- face, (b) presented method: geometric modifications, thin- ning and thickening artefacts are successfully removed ", "caption_bbox": [430, 700, 731, 743]}, {"image_id": 8, "file_name": "235_08.png", "page": 7, "dpi": 300, "bbox": [142, 118, 357, 617], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: 2D variance comparison of the three resulting surface models. Axial cross section in the middle of (a) first and (b) last ring. The CAD model was taken as reference (black). The best global isovalue of workpiece two is de- picted in red and the output of the presented pipeline in green. Variations of the inner and outer contours are de- picted 15 times scaled. Mind the different scales: inner cir- cles of both figures have the same size ", "caption_bbox": [98, 630, 399, 750]}, {"image_id": 9, "file_name": "235_09.png", "page": 8, "dpi": 300, "bbox": [135, 111, 364, 671], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Variance comparison for workpiece three (rep- resentative sub grid) between best isovalue vs. pipeline. Colour-coded visualization (a), glyph-based visualization using arrows (b), and cylinders (c) ", "caption_bbox": [98, 684, 399, 743]}], "236": [{"image_id": 0, "file_name": "236_00.png", "page": 2, "dpi": 300, "bbox": [432, 112, 732, 141], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Algorithmic flow diagram of the proposed method.", "caption_bbox": [430, 149, 731, 167]}, {"image_id": 1, "file_name": "236_01.png", "page": 4, "dpi": 300, "bbox": [430, 111, 732, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Reconstruction of large models, see Table 1.", "caption_bbox": [444, 307, 718, 325]}, {"image_id": 2, "file_name": "236_02.png", "page": 5, "dpi": 300, "bbox": [412, 141, 724, 461], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Gaussian noise with zero mean and standard de- viation \u03c3 (expressed as a percentage of diagonal size of the bounding box); first row: source points, second row: recon- structed surfaces. ", "caption_bbox": [430, 467, 731, 530]}, {"image_id": 3, "file_name": "236_03.png", "page": 5, "dpi": 300, "bbox": [154, 566, 345, 771], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Shot noise. The number of corrupted voxels is ex- pressed as a percentage of the number of source points. ", "caption_bbox": [98, 777, 399, 810]}, {"image_id": 4, "file_name": "236_04.png", "page": 6, "dpi": 300, "bbox": [452, 111, 722, 386], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Mesh smoothing comparison. Left-to-right, top- to-bottom: original mesh, method of Jones et al. [JDD03], curvature flow [MDSB03, DMSB99], our method. ", "caption_bbox": [430, 394, 731, 442]}, {"image_id": 5, "file_name": "236_05.png", "page": 6, "dpi": 300, "bbox": [138, 113, 361, 422], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Random sampling. First row: sampled points as a percentage of the number of source points; second row: reconstructed surfaces. ", "caption_bbox": [98, 429, 399, 477]}, {"image_id": 6, "file_name": "236_06.png", "page": 7, "dpi": 300, "bbox": [104, 405, 381, 557], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Left: noisy data set with 2, 008, 414 input points and 4000 outliers; right: reconstructed surface. Computa- tion time was 234 seconds. ", "caption_bbox": [98, 565, 399, 613]}, {"image_id": 7, "file_name": "236_07.png", "page": 7, "dpi": 300, "bbox": [118, 111, 380, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Grid resolution vs. reconstruction error with/without mesh smoothing; results using the Buddha model. ", "caption_bbox": [430, 117, 731, 165]}], "237": [{"image_id": 0, "file_name": "237_00.png", "page": 2, "dpi": 300, "bbox": [431, 113, 733, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The clipmap contains a fixed-size segment of each mipmap level around an arbitrary focus point. ", "caption_bbox": [430, 347, 731, 375]}, {"image_id": 1, "file_name": "237_01.png", "page": 2, "dpi": 300, "bbox": [430, 598, 734, 822], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: We use circular instead of rectangular rings to cover the hemisphere. ", "caption_bbox": [430, 833, 731, 861]}, {"image_id": 2, "file_name": "237_02.png", "page": 3, "dpi": 300, "bbox": [430, 398, 734, 621], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: For \u03c6v = 0, the hemisphere is rotated only around the y-axis. ", "caption_bbox": [430, 628, 731, 661]}, {"image_id": 3, "file_name": "237_03.png", "page": 3, "dpi": 300, "bbox": [98, 238, 402, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The sphere can be parametrized by (\u03c6, \u03b8) which map directly to a planar rectangle. ", "caption_bbox": [98, 469, 399, 501]}, {"image_id": 4, "file_name": "237_04.png", "page": 3, "dpi": 300, "bbox": [430, 113, 734, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Points on the view hemisphere are transformed into world space to sample the rectangular height map. ", "caption_bbox": [430, 347, 731, 375]}, {"image_id": 5, "file_name": "237_05.png", "page": 4, "dpi": 300, "bbox": [430, 434, 734, 659], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The world space size of the clipmap regions have to be chosen according to \u03b8v to handle the anisotropy. ", "caption_bbox": [430, 670, 731, 699]}, {"image_id": 6, "file_name": "237_06.png", "page": 4, "dpi": 300, "bbox": [98, 554, 401, 779], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Triangles twice as far away are rendered twice as small, so our expontially growing triangles have about the same size in screen space. ", "caption_bbox": [98, 790, 399, 834]}, {"image_id": 7, "file_name": "237_07.png", "page": 5, "dpi": 300, "bbox": [431, 418, 733, 641], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Visibility of the lower levels of detail depends pri- marily on earth curvature and the distance to the surface. ", "caption_bbox": [430, 652, 731, 680]}, {"image_id": 8, "file_name": "237_08.png", "page": 5, "dpi": 300, "bbox": [98, 742, 402, 857], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Texture coordinate interpolation results in arte- facts beyond the poles, so one line of vertices has to be du- plicated. ", "caption_bbox": [98, 867, 399, 911]}, {"image_id": 9, "file_name": "237_09.png", "page": 6, "dpi": 300, "bbox": [99, 112, 401, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Visibility of the higher levels of detail depends on the screen resolution and the distance to the surface. ", "caption_bbox": [98, 347, 399, 375]}, {"image_id": 10, "file_name": "237_10.png", "page": 6, "dpi": 300, "bbox": [430, 112, 734, 598], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: \u03c6\u0303- and \u03b8\u0303-iso-lines in world space (\u03c6, \u03b8): Whereas the overall distortion of the mapped hemisphere is quite large, the area around the viewer is only stretched in \u03c6- direction. ", "caption_bbox": [430, 644, 731, 707]}, {"image_id": 11, "file_name": "237_11.png", "page": 7, "dpi": 300, "bbox": [98, 112, 402, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: The relative approximation error stays below 0.001 for \u03c0 48              1                < \u03b8v < \u03c0 48                         47 ", "caption_bbox": [98, 387, 399, 416]}, {"image_id": 12, "file_name": "237_12.png", "page": 7, "dpi": 300, "bbox": [430, 255, 733, 480], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Missing blending between exact calculation and approximation can lead to gaps. ", "caption_bbox": [430, 491, 731, 519]}, {"image_id": 13, "file_name": "237_13.png", "page": 7, "dpi": 300, "bbox": [98, 510, 401, 735], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: The inaccuracy of the tan\u22121 -implementation causes distortion in the texture coordinate calculation: The central \u03c6 line should be straight, not jagged. ", "caption_bbox": [98, 743, 399, 790]}, {"image_id": 14, "file_name": "237_14.png", "page": 8, "dpi": 300, "bbox": [98, 635, 401, 860], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Lake Garda, aircraft view", "caption_bbox": [154, 871, 343, 884]}, {"image_id": 15, "file_name": "237_15.png", "page": 8, "dpi": 300, "bbox": [430, 112, 733, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 17: Lake Garda, space view", "caption_bbox": [491, 347, 670, 360]}, {"image_id": 16, "file_name": "237_16.png", "page": 8, "dpi": 300, "bbox": [98, 277, 401, 502], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Lake Garda, ground view", "caption_bbox": [155, 513, 342, 526]}], "238": [{"image_id": 0, "file_name": "238_00.png", "page": 3, "dpi": 300, "bbox": [428, 90, 656, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Isopoint computation for scattered data via De- launay triangulation and linear interpolation along Delau- nay edges. For sample position xi the incident edges to sam- ple locations x j , xk , and xl intersect the contour. ", "caption_bbox": [391, 306, 692, 371]}, {"image_id": 1, "file_name": "238_01.png", "page": 4, "dpi": 300, "bbox": [104, 690, 316, 832], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Indexing scheme for two-dimensional kd-tree.", "caption_bbox": [68, 841, 349, 859]}, {"image_id": 2, "file_name": "238_02.png", "page": 4, "dpi": 300, "bbox": [445, 153, 639, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Neighborhood of x.", "caption_bbox": [466, 299, 617, 317]}, {"image_id": 3, "file_name": "238_03.png", "page": 4, "dpi": 300, "bbox": [431, 583, 690, 696], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Direct neighbors search for cell c with index bd .", "caption_bbox": [394, 705, 687, 724]}, {"image_id": 4, "file_name": "238_04.png", "page": 5, "dpi": 300, "bbox": [117, 378, 303, 619], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Indirect neighbors of x.", "caption_bbox": [124, 627, 295, 645]}, {"image_id": 5, "file_name": "238_05.png", "page": 5, "dpi": 300, "bbox": [59, 930, 361, 976], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Bit swap search for dimensions x0 (top), x1 (mid- dle), and x2 (bottom). ", "caption_bbox": [58, 873, 359, 908]}, {"image_id": 6, "file_name": "238_06.png", "page": 6, "dpi": 300, "bbox": [109, 717, 311, 880], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Choice of minimal angle \u03b1 between edges to the neighbors of x. ", "caption_bbox": [58, 888, 359, 922]}, {"image_id": 7, "file_name": "238_07.png", "page": 6, "dpi": 300, "bbox": [154, 449, 266, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Isopoint computation times for sphere data set.", "caption_bbox": [400, 687, 682, 705]}, {"image_id": 8, "file_name": "238_08.png", "page": 6, "dpi": 300, "bbox": [148, 91, 271, 215], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Dashed Neighbor of x violates angle criterion (\u03b2 < \u03b1). ", "caption_bbox": [58, 541, 359, 574]}, {"image_id": 9, "file_name": "238_09.png", "page": 7, "dpi": 300, "bbox": [390, 315, 693, 524], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Isopoints of Boston Teapot with lobster, ex- tracted out of 16M sample points. (Data set courtesy of Ter- arecon Inc, MERL and Brigham and Women\u2019s Hospital.) ", "caption_bbox": [391, 534, 692, 582]}, {"image_id": 10, "file_name": "238_10.png", "page": 7, "dpi": 300, "bbox": [390, 89, 694, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Point-based ray tracing of two isosurfaces, gen- erated from the sphere data set with 8M sample points. (Im- age courtesy of Karsten M\u00fcller.) ", "caption_bbox": [391, 242, 692, 290]}, {"image_id": 11, "file_name": "238_11.png", "page": 7, "dpi": 300, "bbox": [89, 90, 330, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Deviations for sphere data set.", "caption_bbox": [109, 627, 309, 645]}, {"image_id": 12, "file_name": "238_12.png", "page": 8, "dpi": 300, "bbox": [58, 92, 359, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Engine with point-based rendering out of 16M sample points. (Data set courtesy of General Electric.) ", "caption_bbox": [58, 358, 359, 391]}], "239": [{"image_id": 0, "file_name": "239_00.png", "page": 3, "dpi": 300, "bbox": [432, 112, 731, 370], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The David dataset (Stanford) contains 28,184,526 points, for which an octree with 10 levels takes about 64 GB space. The visualization with shadows gives extra visual cues about the spatial relationship between the object and its surrounding, and between different parts of the object. ", "caption_bbox": [430, 374, 731, 452]}, {"image_id": 1, "file_name": "239_01.png", "page": 3, "dpi": 300, "bbox": [105, 112, 403, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Five iso-surfaces of a hyperbolic field are visual- ized using point sets that are randomly placed on the sur- faces with different resolutions. Each iso-surface is approxi- mated by (a) 1K, (b) 10K and (c) 1M points respectively. ", "caption_bbox": [98, 263, 399, 326]}, {"image_id": 2, "file_name": "239_02.png", "page": 3, "dpi": 300, "bbox": [111, 349, 382, 745], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Two Visible Human point sets, representing bones (1,218,973 points) and skin (267,303 points) respectively, are combined together using a volume scene graph. The point sets were part of the polygonal model provided by William E. Lorensen [Lor95] and made available by Geor- gia Institute of Technology. ", "caption_bbox": [98, 744, 399, 837]}, {"image_id": 3, "file_name": "239_03.png", "page": 4, "dpi": 300, "bbox": [130, 113, 368, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The software architecture of the testing environ- ment for our out-of-core algorithms. ", "caption_bbox": [98, 268, 399, 301]}, {"image_id": 4, "file_name": "239_04.png", "page": 7, "dpi": 300, "bbox": [101, 115, 392, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 4: Summary of cache hit rates for real data.", "caption_bbox": [454, 261, 706, 279]}, {"image_id": 5, "file_name": "239_05.png", "page": 7, "dpi": 300, "bbox": [101, 385, 394, 601], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Cache hit rates for random data sets comprising points in a spherical volume. ", "caption_bbox": [98, 604, 399, 637]}, {"image_id": 6, "file_name": "239_06.png", "page": 8, "dpi": 300, "bbox": [101, 367, 394, 587], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Cache hit rates for real data.", "caption_bbox": [149, 586, 347, 604]}, {"image_id": 7, "file_name": "239_07.png", "page": 8, "dpi": 300, "bbox": [101, 115, 392, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Normalized disk reads for real data.", "caption_bbox": [131, 334, 365, 352]}], "240": [{"image_id": 0, "file_name": "240_00.png", "page": 4, "dpi": 300, "bbox": [103, 111, 728, 176], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A sequence of eye movement during the volume rotation and isovalue changing. The red point indicates the position of the eye gaze. ", "caption_bbox": [98, 186, 731, 214]}, {"image_id": 1, "file_name": "240_01.png", "page": 8, "dpi": 300, "bbox": [107, 112, 724, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (Left) The left six images show the reconstructed visiting volumes, the cluster results, and the composition results for the segmented hand dataset and a foot dataset. For the hand, since the bones are viewed as more important than the skin, they are less transparent, with less silhouette enhancement and a warmer color. The viewpoint is also selected for better bone observance. For the foot, although the user is more interested in the bones on the first and second toes, all the bones are highlighted because of their value similarities. (Right) The right four images show two pairs of visiting volumes and composition results for a segmented feet dataset. The top pair focuses on the bones and the bottom pair focuses on the skin. Different user interests result in different composite visualizations, which are adjusted specifically to observe the objects of interest using our automatic approach. ", "caption_bbox": [98, 380, 731, 500]}], "241": [{"image_id": 0, "file_name": "241_00.png", "page": 2, "dpi": 300, "bbox": [98, 111, 401, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Illustrative cross sectional images convey differ- ent strategies for the needle placement in the spine. From: [GP98] ", "caption_bbox": [98, 261, 399, 304]}, {"image_id": 1, "file_name": "241_01.png", "page": 3, "dpi": 300, "bbox": [135, 111, 364, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Concept of the L IFT C HART widget. The colored bars represent z-dimensions of anatomical structures in a volume dataset (right portion). ", "caption_bbox": [98, 343, 399, 386]}, {"image_id": 2, "file_name": "241_02.png", "page": 4, "dpi": 300, "bbox": [101, 119, 401, 356], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Different possibilities of arranging structures in the L IFT C HART. (a) shows the most simple form. Each anatomic structure is represented by one bar. In (b), the L IFT C HART is divided in three parts: one part for struc- tures on the left and on the right side each and one part for structures in the middle. In (c), structures of one category are aggregated in one column. Additional landmarks for orien- tation are displayed. ", "caption_bbox": [98, 369, 399, 489]}, {"image_id": 3, "file_name": "241_03.png", "page": 4, "dpi": 300, "bbox": [460, 112, 703, 202], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The size of the halos depends on their distance from the target point (gray slice). The line style indicates if the current slice is above or below the target. ", "caption_bbox": [430, 212, 731, 255]}, {"image_id": 4, "file_name": "241_04.png", "page": 5, "dpi": 300, "bbox": [430, 112, 733, 366], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The probably pathologic structures (tumor and lymph nodes) are shown in the L IFT C HART. The lymph nodes of one side are combined into one column. Enlarged lymph nodes are colored red. For the lymph nodes safety margins of 2mm (red) and 5mm (yellow) are shown. ", "caption_bbox": [430, 376, 731, 450]}, {"image_id": 5, "file_name": "241_05.png", "page": 5, "dpi": 300, "bbox": [143, 112, 356, 325], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The traditional crosshairs are enhanced to spec- ify two points. The center is used to track a surgical tool, whereas the marks on the axes define a second target point. ", "caption_bbox": [98, 336, 399, 379]}, {"image_id": 6, "file_name": "241_06.png", "page": 6, "dpi": 300, "bbox": [157, 111, 342, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Corresponding 3D visualization of Figure 7. Mar- gins for lymph nodes outside the current slice are also visi- ble. ", "caption_bbox": [98, 311, 399, 354]}, {"image_id": 7, "file_name": "241_07.png", "page": 9, "dpi": 300, "bbox": [329, 319, 728, 501], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Intraoperative navigation in an orthogonal view.", "caption_bbox": [379, 512, 675, 525]}, {"image_id": 8, "file_name": "241_08.png", "page": 9, "dpi": 300, "bbox": [98, 111, 256, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Corresponding 3D visualization of Figure 7. ", "caption_bbox": [98, 284, 245, 312]}, {"image_id": 9, "file_name": "241_09.png", "page": 9, "dpi": 300, "bbox": [486, 112, 730, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Possibilities of arranging the L IFT C HART. ", "caption_bbox": [486, 284, 728, 313]}], "242": [{"image_id": 0, "file_name": "242_00.png", "page": 2, "dpi": 300, "bbox": [157, 731, 342, 878], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Bull\u2019s-Eye Plot and AHA-conform nomenclature. The plot is generated by projecting the myocardial segments onto a plane (see Fig. 1, (upper left)). The segments are col- ored according to the supplying coronary branch. ", "caption_bbox": [98, 889, 399, 948]}, {"image_id": 1, "file_name": "242_01.png", "page": 2, "dpi": 300, "bbox": [112, 173, 389, 473], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: AHA-conform acquisition and segmentation of myocardial perfusion data in short-axis views. Upper left: Schematic representation of the left ventricle. Typically, 3 to 4 slices are planned dissecting the left ventricle basally, centrically, apically and at the apex itself. Upper right and lower row: Nomenclature of radially distributed segments in each slice. Segment 17 is the apex itself. The right ventricle is indicated as filled semi-circle. ", "caption_bbox": [98, 484, 399, 604]}, {"image_id": 2, "file_name": "242_02.png", "page": 3, "dpi": 300, "bbox": [106, 676, 394, 853], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Schematic representation of a typical time- intensity curve and labeling of characteristic dynamic pa- rameters. The first pass of the CA causes the highest intensity changes and is therefore utilized for parameter derivation. Subsequent passes (Peak 2) are not considered normally. ", "caption_bbox": [98, 864, 399, 938]}, {"image_id": 3, "file_name": "242_03.png", "page": 5, "dpi": 300, "bbox": [105, 111, 394, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Integrated visualization of the parameter PE for the rest and stress state in a refined Bull\u2019s-Eye Plot. An is- chemic area is revealed in each slice (ring) from anterior to inferoseptal along the septum. Dark regions mark a dimin- ished perfusion. Apically the perfusion defect may remain unnoticed if perfusion is only examined at rest. Segment 17 is missing since no slice has been acquired at the apex itself. ", "caption_bbox": [98, 359, 399, 463]}, {"image_id": 4, "file_name": "242_04.png", "page": 5, "dpi": 300, "bbox": [437, 330, 726, 558], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Parameter up-slope is displayed for the my- ocardium in the context of an original slice. Parameter inte- gral is projected through a user-defined lens. Dark inferior and septal regions indicate a perfusion defect. ", "caption_bbox": [430, 568, 731, 627]}, {"image_id": 5, "file_name": "242_05.png", "page": 5, "dpi": 300, "bbox": [105, 628, 394, 861], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Colored heightfield based on parameters PE (height) and up-slope (color). Small elevations (diminished perfusion) and dark colors (delayed perfusion) represent is- chemic territories. The corresponding original slice at an adjustable time-point serves as context information. ", "caption_bbox": [98, 872, 399, 946]}, {"image_id": 6, "file_name": "242_06.png", "page": 6, "dpi": 300, "bbox": [127, 111, 372, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Color icons illustrating the parameters PE and up-slope. The icon\u2019s structure is represented as an inlet. Sep- tal, a large dark area is characterized by diminished and delayed perfusion indicating a serious perfusion defect. In- ferolateral, slight perfusion disturbances are observed. ", "caption_bbox": [98, 369, 399, 443]}, {"image_id": 7, "file_name": "242_07.png", "page": 7, "dpi": 300, "bbox": [437, 111, 726, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Selection and focus of a coronary branch (LAD). The course of the animation is illustrated by a superim- position of a previous point in time. The other branches are rendered semi-transparent with the vessel skeleton over- laid to enhance spatial comprehensibility. The segments of the Bull\u2019s-Eye Plot which correspond to myocardial regions supplied by the selected branch are highlighted. The respec- tive time-intensity curves are visualized. ", "caption_bbox": [430, 301, 731, 421]}, {"image_id": 8, "file_name": "242_08.png", "page": 7, "dpi": 300, "bbox": [105, 111, 394, 399], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Anatomy and myocardial perfusion of a patient suffering from atherosclerosis of the RCA and the LAD. Up- per left: Apical slice of the original perfusion data set and the AHA-consistent segmentation of the myocardium over- laid. Upper right: Apical slice of the parameter volume com- puted for up-slope. Middle left: Selection of 2 segments in the Bull\u2019s-Eye Plot which color-codes the parameter up-slope. Segment 17 is missing since no slice has been acquired at the apex itself. Lower left: Time-intensity curves correspond- ing to the selected segments. Lower Right: Coronary branch (RCA) supplying the selected segments. The animated fo- cussing is illustrated by a semitransparent overlay of a pre- vious point in time. ", "caption_bbox": [98, 409, 399, 605]}], "243": [{"image_id": 0, "file_name": "243_00.png", "page": 2, "dpi": 300, "bbox": [391, 90, 693, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Two equivalent approaches of a stream line integration in a periodic field p: (a) In the unbounded time-domain; (b) Periodically continued in the time-domain [tmin ,tmax ]. ", "caption_bbox": [391, 293, 692, 357]}, {"image_id": 1, "file_name": "243_01.png", "page": 3, "dpi": 300, "bbox": [59, 90, 361, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) The definition of m\u03c4 (x) and m\u0304\u03c4 (x); (b) A con- tinuous forward integration of p corresponds to a discrete integration of m\u03c4 (x). ", "caption_bbox": [58, 261, 359, 310]}, {"image_id": 2, "file_name": "243_02.png", "page": 3, "dpi": 300, "bbox": [390, 91, 693, 257], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) A critical path line corresponds to fix points in m\u03c4 , m\u0304\u03c4 . (b) Critical path line over two time periods. ", "caption_bbox": [390, 265, 690, 298]}, {"image_id": 3, "file_name": "243_03.png", "page": 4, "dpi": 300, "bbox": [118, 90, 302, 201], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Pseudo discontinuities in m\u03c4 : if x1 and x2 are close but at different sides of a separatrix of v(x) = v(x,t), m\u03c4 has too large changes that it is impossible for discrete numerical method to deal with it though it is still continuous. ", "caption_bbox": [58, 209, 359, 272]}, {"image_id": 4, "file_name": "243_04.png", "page": 4, "dpi": 300, "bbox": [392, 90, 692, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Classification of sources/sinks of m\u03c4 : (a) repelling/alternating; (b) attracting/alternating; (c) attracting/non-alternating (d) repelling/non-alternating; (e) attracting/rotating; (f) repelling/rotating. ", "caption_bbox": [390, 286, 691, 349]}, {"image_id": 5, "file_name": "243_05.png", "page": 5, "dpi": 300, "bbox": [390, 89, 694, 429], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The random data set.", "caption_bbox": [461, 438, 620, 456]}, {"image_id": 6, "file_name": "243_06.png", "page": 6, "dpi": 300, "bbox": [58, 625, 694, 872], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The cavity data.", "caption_bbox": [305, 882, 445, 900]}, {"image_id": 7, "file_name": "243_07.png", "page": 6, "dpi": 300, "bbox": [58, 326, 694, 572], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The ABC flow.", "caption_bbox": [312, 582, 437, 600]}, {"image_id": 8, "file_name": "243_08.png", "page": 6, "dpi": 300, "bbox": [58, 89, 694, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The random data set.", "caption_bbox": [295, 282, 454, 300]}, {"image_id": 9, "file_name": "243_09.png", "page": 7, "dpi": 300, "bbox": [58, 303, 362, 477], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The cavity flow.", "caption_bbox": [140, 486, 277, 504]}, {"image_id": 10, "file_name": "243_10.png", "page": 7, "dpi": 300, "bbox": [58, 90, 362, 257], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The ABC flow.", "caption_bbox": [146, 266, 271, 284]}], "244": [{"image_id": 0, "file_name": "244_00.png", "page": 3, "dpi": 300, "bbox": [431, 821, 732, 885], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A 2d template set. From left to right: rotation, convergence, saddle, shear flow, convergence line. Note that counterclockwise and divergence pattern can be found with these templates as well. ", "caption_bbox": [430, 896, 731, 955]}, {"image_id": 1, "file_name": "244_01.png", "page": 4, "dpi": 300, "bbox": [430, 112, 733, 411], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Vortices generated by an ICE train (top left). Segmentation of a section plane through the flow (thresh- old=0.5), overlaid with LIC. The data set was normal- ized. Red: rotation, orange: shear flow, light blue: conver- gent/divergent line, green: saddle point. Top right: only 3x3 templates were used to determine the line features shear flow and convergent/divergent lines. Bottom: templates from size 3x3 till no significant similarities were gained were used to detect the features. Bottom right: Topology added. Note that the elliptical vortices are classified as shear flow when using larger templates. ", "caption_bbox": [430, 416, 731, 581]}, {"image_id": 2, "file_name": "244_02.png", "page": 5, "dpi": 300, "bbox": [98, 820, 396, 915], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Superposition of a rotation and a divergence re- sults in a spiral pattern. ", "caption_bbox": [98, 927, 399, 955]}, {"image_id": 3, "file_name": "244_03.png", "page": 5, "dpi": 300, "bbox": [430, 604, 733, 840], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A swirling jet data set. Segmentation and LIC. Red: rotation, orange: shear flow, light blue: conver- gent/divergent line, dark blue: sink/source, green:saddle. Left: threshold of 0.5, right: threshold of 0.7. Top: segmenta- tion using the similarity values, bottom: when the difference between shear and rotation was below 0.05, the flow was classified as shear rather than rotation. ", "caption_bbox": [430, 851, 731, 956]}, {"image_id": 4, "file_name": "244_04.png", "page": 6, "dpi": 300, "bbox": [430, 112, 733, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Segmentations of three successive time steps of a swirling jet data set data set (from left to right, thresh- old=0.5). The data has been normalized before match- ing. Color coding: clockwise rotations in red and counter- clockwise rotations in blue. From light to dark colors: in- crease in similarity values. ", "caption_bbox": [430, 217, 731, 306]}, {"image_id": 5, "file_name": "244_05.png", "page": 7, "dpi": 300, "bbox": [430, 112, 733, 428], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Segmentation of the normalized gas furnace cham- ber (Threshold: 0.5). Isosurfaces of the results (Value 0.5): Red: rotations, yellow: shear flow, green: saddles. The cores of the regions are displayed, too, and in the same colors. Templates of divergence/convergence resulted in similarities below the threshold. Top: The velocity of the original data set is displayed at an isovalue of 15. Bottom: The results of the segmentation can also be used for streamline seeding. ", "caption_bbox": [430, 438, 731, 558]}, {"image_id": 6, "file_name": "244_06.png", "page": 7, "dpi": 300, "bbox": [98, 112, 401, 471], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Segmentation of a simulation of a swirling jet en- tering a fluid at rest (threshold=0.5). Red: rotation, orange: shear flow, light blue: convergent/divergent line, dark blue: sink/source, green: saddle. Top: whole data set. Middle and bottom left: zoomed in. Streamlines respectively. topology added. Bottom right: some details. Hedgehogs and stream- lines added. ", "caption_bbox": [98, 481, 399, 586]}], "245": [{"image_id": 0, "file_name": "245_00.png", "page": 3, "dpi": 300, "bbox": [129, 118, 325, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (left) The swirling motion of flow in the combus- tion chamber of a diesel engine. Swirl is used to describe cir- culation about the axis aligned with the valve cylinder. The intake ports at the top provide the tangential component of the flow necessary for swirl. The data set consists of 776,000 unstructured, adaptive resolution grid cells. (right) Some in- cylinder flows require a tumble motion flow pattern in order to mix fluid with oxygen. Tumble flow circulates around an axis perpendicular to the cylinder axis, orthogonal to the case of swirl motion. ", "caption_bbox": [98, 302, 399, 456]}, {"image_id": 1, "file_name": "245_01.png", "page": 4, "dpi": 300, "bbox": [145, 112, 684, 436], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The depiction of swirl motion with surfaces and texture advection: (left) a velocity isosurface of 5.0 m/s with an addition CFD simulation attribute mapped to hue, (middle-left) a hybrid visualization of texture advection on the same iso- surface, (middle-right) a stream surface seeded in an intake port with velocity magnitude mapped to hue, and (right) a hybrid visualization of texture advection on the same stream surface. ", "caption_bbox": [98, 443, 730, 506]}, {"image_id": 2, "file_name": "245_02.png", "page": 4, "dpi": 300, "bbox": [111, 542, 389, 763], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A stream surface in the gray-scale context of a combustion chamber in a gas engine simulation. A candi- date tumble axis is indicated. For the stream surface, color is mapped to velocity magnitude. ", "caption_bbox": [98, 770, 399, 833]}, {"image_id": 3, "file_name": "245_03.png", "page": 5, "dpi": 300, "bbox": [109, 112, 388, 669], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A hybrid stream surface\u2013texture advection visu- alization the tumble pattern of motion from the simulation results of a gas engine: (top) velocity magnitude mapped to hue and texture advection applied to the flow field and (bot- tom) vorticity magnitude mapped to hue and texture advec- tion applied to the vorticity field. ", "caption_bbox": [98, 676, 399, 769]}, {"image_id": 4, "file_name": "245_04.png", "page": 5, "dpi": 300, "bbox": [450, 112, 721, 671], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The same stream surface as shown in Figure 4 viewed from the side and with alternative color mappings: (top) velocity magnitude mapped to a simple yellow-blue color scale and texture advection applied to the flow field, and (bottom) vorticity magnitude mapped to a more opti- mal color scale and texture advection applied to the vorticity field. ", "caption_bbox": [430, 678, 731, 787]}, {"image_id": 5, "file_name": "245_05.png", "page": 6, "dpi": 300, "bbox": [430, 112, 729, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Streamsurfaces in the cooling jacket: (top) red and blue streamsurfaces are seeded close to the inlet and tra- verse the jacket mainly in longitudinal direction. Parts of a stream surface are drawn into the interconnections and cre- ate vortices upon entering the jacket head (highlighted in inset). ", "caption_bbox": [430, 261, 731, 354]}, {"image_id": 6, "file_name": "245_06.png", "page": 6, "dpi": 300, "bbox": [119, 118, 390, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The major components of the flow through a cooling jacket include a longitudinal component, length- wise along the geometry and a transversal component in the upward-and-over direction. The inlet and outlet of the cool- ing jacket are also indicated. ", "caption_bbox": [98, 317, 399, 395]}, {"image_id": 7, "file_name": "245_07.png", "page": 7, "dpi": 300, "bbox": [104, 135, 399, 431], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A hybrid texture advection-stream surface visu- alization. A color (red and green) is assigned to each side of the stream surface in order to aid perception of the sur- face properties: (top) The same stream surface shown in Fig- ure 7 is complimented with texture advection: (bottom-left) a close-up of recirculation zone is highlighted and (bottom- right) a close-up view of a region with high vorticity. ", "caption_bbox": [98, 439, 399, 548]}, {"image_id": 8, "file_name": "245_08.png", "page": 9, "dpi": 300, "bbox": [104, 112, 726, 424], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: (color plate) (left) A hybrid stream surface\u2013texture advection visualization the tumble pattern of motion from the simulation results of a gas engine. In this case, texture properties are advected according to vorticity and color is mapped to helicity. (right) A hybrid stream surface-texture advection visualization with pressure gradient magnitude mapped to hue and texture advection applied to the pressure gradient field. The same stream surface is shown from a different view point. ", "caption_bbox": [98, 431, 730, 494]}], "246": [{"image_id": 0, "file_name": "246_00.png", "page": 3, "dpi": 300, "bbox": [106, 111, 729, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Density change in neighborhood of isolated singularities of first order: (a) Source with forward propagation; (b)", "caption_bbox": [98, 246, 730, 267]}, {"image_id": 1, "file_name": "246_01.png", "page": 4, "dpi": 300, "bbox": [111, 308, 388, 683], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Density change in neighborhood of simple combi-", "caption_bbox": [98, 684, 399, 705]}, {"image_id": 2, "file_name": "246_02.png", "page": 4, "dpi": 300, "bbox": [438, 641, 727, 768], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) Density field influenced by domain shape; (b)", "caption_bbox": [430, 770, 731, 791]}, {"image_id": 3, "file_name": "246_03.png", "page": 6, "dpi": 300, "bbox": [459, 643, 704, 888], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Structure visualization of 2D slice of New Orleans", "caption_bbox": [430, 892, 731, 913]}, {"image_id": 4, "file_name": "246_04.png", "page": 7, "dpi": 300, "bbox": [121, 111, 710, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: 2D slice of New Orleans airflow dataset showing the same density function rendered with two different transfer", "caption_bbox": [98, 298, 730, 319]}, {"image_id": 5, "file_name": "246_05.png", "page": 7, "dpi": 300, "bbox": [131, 368, 699, 567], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: 2D simulation of a swirling jet, using two different transfer functions, (a) Overall flow behavior; (b) transfer function", "caption_bbox": [98, 569, 730, 590]}, {"image_id": 6, "file_name": "246_06.png", "page": 9, "dpi": 300, "bbox": [105, 443, 726, 638], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) Visualizing core of 3D tornado dataset; (b),(c) full 3D New Orleans airflow dataset, using two different transfer", "caption_bbox": [98, 641, 730, 662]}, {"image_id": 7, "file_name": "246_07.png", "page": 9, "dpi": 300, "bbox": [112, 112, 718, 323], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: 2D simulation of a swirling jet, using two different transfer functions, (a) Overall flow behavior; (b) transfer function", "caption_bbox": [98, 325, 730, 346]}], "247": [{"image_id": 0, "file_name": "247_00.png", "page": 2, "dpi": 300, "bbox": [399, 817, 684, 922], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A 2D time histogram can be displayed as a 3D", "caption_bbox": [391, 921, 692, 942]}, {"image_id": 1, "file_name": "247_01.png", "page": 2, "dpi": 300, "bbox": [60, 64, 378, 167], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Histograms are useful in classification and are", "caption_bbox": [58, 166, 359, 187]}, {"image_id": 2, "file_name": "247_02.png", "page": 3, "dpi": 300, "bbox": [68, 65, 378, 352], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Display of the time histogram from a combustion", "caption_bbox": [58, 351, 359, 372]}, {"image_id": 3, "file_name": "247_03.png", "page": 3, "dpi": 300, "bbox": [375, 64, 693, 464], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Display of some typical time histograms. The time", "caption_bbox": [391, 480, 692, 501]}, {"image_id": 4, "file_name": "247_04.png", "page": 4, "dpi": 300, "bbox": [60, 64, 378, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Time histogram computed from the temporal gra-", "caption_bbox": [58, 332, 359, 353]}, {"image_id": 5, "file_name": "247_05.png", "page": 4, "dpi": 300, "bbox": [375, 65, 678, 206], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The constrained freeform interval is a component", "caption_bbox": [391, 216, 692, 237]}, {"image_id": 6, "file_name": "247_06.png", "page": 5, "dpi": 300, "bbox": [375, 64, 693, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: By adjusting the histogram display mapping and", "caption_bbox": [391, 348, 692, 369]}, {"image_id": 7, "file_name": "247_07.png", "page": 5, "dpi": 300, "bbox": [65, 65, 378, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A quantization of the time histogram creates some", "caption_bbox": [58, 361, 359, 382]}, {"image_id": 8, "file_name": "247_08.png", "page": 6, "dpi": 300, "bbox": [375, 65, 693, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Since the turbulent jet data set is statistically", "caption_bbox": [391, 266, 692, 287]}, {"image_id": 9, "file_name": "247_09.png", "page": 6, "dpi": 300, "bbox": [59, 64, 378, 257], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Time intervals resulting from the histogram merg-", "caption_bbox": [58, 267, 359, 288]}, {"image_id": 10, "file_name": "247_10.png", "page": 7, "dpi": 300, "bbox": [375, 64, 694, 549], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Classification of the vorticity magnitude field in", "caption_bbox": [391, 550, 692, 571]}, {"image_id": 11, "file_name": "247_11.png", "page": 7, "dpi": 300, "bbox": [58, 65, 378, 469], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Classification of the argon bubble data set. The", "caption_bbox": [58, 469, 359, 490]}], "248": [{"image_id": 0, "file_name": "248_00.png", "page": 2, "dpi": 300, "bbox": [119, 183, 302, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The tripartite graph with partition sides A (set of actors), E (set of events) and D (set of descriptors) as well as time stamps te for every item e \u2208 E. ", "caption_bbox": [59, 361, 360, 405]}, {"image_id": 1, "file_name": "248_01.png", "page": 3, "dpi": 300, "bbox": [426, 550, 648, 708], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The radius function with k \u2208 {1, 2, 5}.", "caption_bbox": [420, 731, 663, 745]}, {"image_id": 2, "file_name": "248_02.png", "page": 4, "dpi": 300, "bbox": [60, 64, 378, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Time ripple with various radii.", "caption_bbox": [106, 261, 312, 274]}, {"image_id": 3, "file_name": "248_03.png", "page": 4, "dpi": 300, "bbox": [119, 600, 302, 780], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The average angle \u03b3 of \u03b31 , \u03b32 , \u03b33 .", "caption_bbox": [102, 791, 317, 806]}, {"image_id": 4, "file_name": "248_04.png", "page": 8, "dpi": 300, "bbox": [60, 64, 631, 879], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Actor biography of Arnold Schwarzenegger. The snapshots are taken in intervals of five years, starting in 1982. In the lower region of the image \u201cTerminator\u201d movies are clustered. ", "caption_bbox": [59, 890, 692, 918]}], "249": [{"image_id": 0, "file_name": "249_00.png", "page": 3, "dpi": 300, "bbox": [427, 726, 726, 863], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Sorted files layout based on a similarity measure", "caption_bbox": [427, 862, 726, 878]}, {"image_id": 1, "file_name": "249_01.png", "page": 3, "dpi": 300, "bbox": [96, 394, 394, 482], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: File evolution representation. Color encodes user identity (top) and activity (bottom) ", "caption_bbox": [96, 483, 398, 513]}, {"image_id": 2, "file_name": "249_02.png", "page": 4, "dpi": 300, "bbox": [95, 756, 393, 903], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Cluster segregation: color blending only (top), plateau cushions (bottom) ", "caption_bbox": [96, 903, 398, 933]}, {"image_id": 3, "file_name": "249_03.png", "page": 4, "dpi": 300, "bbox": [98, 510, 397, 611], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Cluster segregation: plateau cushions without (left) and with alternating hues (right) ", "caption_bbox": [96, 610, 398, 640]}, {"image_id": 4, "file_name": "249_04.png", "page": 4, "dpi": 300, "bbox": [431, 338, 727, 502], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Interactively built layout using sort and clustering operations ", "caption_bbox": [427, 507, 729, 537]}, {"image_id": 5, "file_name": "249_05.png", "page": 5, "dpi": 300, "bbox": [98, 726, 398, 912], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Metric views. Vertical: file activity. Horizontal: project- wide activity ", "caption_bbox": [96, 911, 398, 941]}, {"image_id": 6, "file_name": "249_06.png", "page": 6, "dpi": 300, "bbox": [96, 163, 730, 537], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Interactively built layouts of the VTK project using sort operations: (a) files sorted alphabetically, vertical metric shows cluster IDs, (b) files sorted by creation time, vertical metric shows activity, (c) files sorted by activity, vertical metric shows activity, (d) files sorted by similarity with respect to a reference file- vtkIntArray.cxx , vertical metric shows similarity. ", "caption_bbox": [96, 536, 730, 581]}, {"image_id": 7, "file_name": "249_07.png", "page": 7, "dpi": 300, "bbox": [96, 632, 728, 1001], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visualization layouts: clustering and alphabetical sort (top row); clustering and sort on creation time (bottom row) \u00a9 The Eurographics Association 2006. ", "caption_bbox": [96, 1005, 728, 1038]}], "250": [{"image_id": 0, "file_name": "250_00.png", "page": 3, "dpi": 300, "bbox": [114, 133, 721, 248], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Decomposition of a time series into all possible subintervals. (a) Original line chart equivalent with subinterval chart of length 3. (b) All possible subinterval time frames. (c,d) Partial line charts of all possible subintervals of length 1 and 2, normalized with corresponding start values. By displaying normalized subinterval line charts, growth rates are perceivable. Note that for realistic (lager) financial time series, such charts quickly become crowded. ", "caption_bbox": [98, 258, 730, 320]}, {"image_id": 1, "file_name": "250_01.png", "page": 4, "dpi": 300, "bbox": [434, 116, 725, 225], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The Growth Matrix coordinate system. i and j de- note the start and endpoints of subintervals in the time span given by an original time series. Vertical, horizontal, and lines parallel to the reference frame diagonal can be mean- ingfully interpreted in terms of hypothetical investment deci- sions. ", "caption_bbox": [430, 228, 731, 320]}, {"image_id": 2, "file_name": "250_02.png", "page": 5, "dpi": 300, "bbox": [100, 114, 399, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: From Line Charts to Growth Matrix: Simultane- ously displaying growth rates for all possible subintervals in one global time series allows to show details on the global and local return rates of assets. ", "caption_bbox": [98, 332, 399, 394]}, {"image_id": 3, "file_name": "250_03.png", "page": 5, "dpi": 300, "bbox": [430, 631, 732, 782], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Growth Matrices (using gi) of a fund composed of bonds (left) and of technology stocks (right). Identifiable are prototypical growth patterns in both kinds of funds. The bond fund achieves moderate, but steady growth throughout all investment subintervals (up to 110 percent gain within the complete time frame of 14 years). Conversely, the stock fund experiences sub periods of significant gains (multiplying in price), but also loosing such intermediate gains in the long run due to the \u201cnew-economy\u201d breakdown. ", "caption_bbox": [430, 790, 731, 928]}, {"image_id": 4, "file_name": "250_04.png", "page": 6, "dpi": 300, "bbox": [430, 285, 732, 436], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The bond (left) and stock (right) funds from Fig- ure 5 benchmarked against the market. The large Growth Matrices show the rank index ri for all investment sub peri- ods of these funds, as compared to our full asset database. The small Growth Matrices show the respective asset-local growth patterns (gi) for reference. ", "caption_bbox": [430, 444, 731, 536]}, {"image_id": 5, "file_name": "250_05.png", "page": 7, "dpi": 300, "bbox": [98, 113, 405, 219], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Three stock-based funds from the Asian-Pacific re- gion. The funds generally under perform the database me- dian, and negative growth patterns are characteristic. Com- pared to the other funds, the rightmost one performs best. ", "caption_bbox": [98, 227, 399, 289]}, {"image_id": 6, "file_name": "250_06.png", "page": 8, "dpi": 300, "bbox": [102, 117, 737, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Three funds composed of technology stocks. By simultaneous visualization of a set of similar assets, these can be readily compared. Strong and weak candidates can be identified. ", "caption_bbox": [98, 340, 730, 371]}], "251": [{"image_id": 0, "file_name": "251_00.png", "page": 2, "dpi": 300, "bbox": [140, 116, 362, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Using parallel coordinates to visualize imaginary expression levels of four genes. ", "caption_bbox": [98, 263, 399, 291]}, {"image_id": 1, "file_name": "251_01.png", "page": 3, "dpi": 300, "bbox": [99, 111, 400, 325], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Gene Expression Data and Visualization Pipeline showing that PointCloudXplore is used to visualize data from single embryo PointClouds and Virtual PointClouds. ", "caption_bbox": [98, 336, 399, 379]}, {"image_id": 2, "file_name": "251_02.png", "page": 3, "dpi": 300, "bbox": [431, 111, 732, 347], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Orthographic Views showing expression patterns of four genes: eve (red), ftz (green), Giant (gt) (blue) and fork head (fkh) (yellow). The projections in the lower panels show the ventral (V), dorsal (D), anterior (A), posterior (P), left (L) and right (R) views. ", "caption_bbox": [430, 358, 731, 432]}, {"image_id": 3, "file_name": "251_03.png", "page": 4, "dpi": 300, "bbox": [99, 111, 400, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) shows a representation of a 3D embryo sur- rounded by a cylindrical projection. (b) shows an Unrolled View derived from the cylindrical projection. The genes whose expression patterns are displayed are the same as those in Figure 3. ", "caption_bbox": [98, 243, 399, 317]}, {"image_id": 4, "file_name": "251_04.png", "page": 4, "dpi": 300, "bbox": [431, 112, 732, 323], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Gene expression surfaces for eve (red) and ftz (green) colored according to these two genes\u2019 expression values. ", "caption_bbox": [430, 334, 731, 377]}, {"image_id": 5, "file_name": "251_05.png", "page": 5, "dpi": 300, "bbox": [98, 111, 733, 859], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: 2D Parallel Coordinate View showing expression data for nine genes. (a) A view in which data lines have maximum opacity. (b) A view in which data line transparancy has been increased. (c) A view in which color from an Embryo View showing hkb expression (green) is shown. (d) A view in which colors from an Embryo view showing both hkb (green) and hb (orange) expression are shown. (e) A view showing two brushes drawn on an Embryo View to highlight distinguish between the three hb stripes of expression (light blue, yellow and pink). (f) A view showing line traces that highlight data associated with several cells. ", "caption_bbox": [98, 872, 731, 961]}, {"image_id": 6, "file_name": "251_06.png", "page": 7, "dpi": 300, "bbox": [99, 290, 400, 853], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: 2D (a) and 3D (b) Parallel Coordinate Views com- paring expression of five genes. The coloring of the expres- sion levels of the ftz gene in an embryo view has been used to highlight ftz expressing cells in the parallel coordinates. In the 3D view, the anterior/posterior axis runs from top down, with anterior being at the bottom ", "caption_bbox": [98, 866, 399, 955]}, {"image_id": 7, "file_name": "251_07.png", "page": 8, "dpi": 300, "bbox": [98, 111, 733, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Defining brushes in Parallel Coordinate View. In (a) a brush is defined to exclude all cells expressing eve at more than 20%. In (b) this brush is further refined to also exclude all cells expressing ftz at greater than 20%. (c) shows a 3D Parallel Coordinate View of the brush defined in (b) in which location along the A/P axis of the embryo is shown in the 3D dimension. (d) Shows a broad color band display of the brush selected in (b), indicating the minimum, maximum, mean, and standard deviations for expression values for each gene. ", "caption_bbox": [98, 314, 731, 388]}], "252": [{"image_id": 0, "file_name": "252_00.png", "page": 1, "dpi": 300, "bbox": [98, 555, 733, 799], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: CT scan with insufficient resolution of a stag beetle as specimen. Figure (a) to (d) show DVR using different re- construction schemes: (a) using nearest neighbor reconstruction, (b) using trilinear-, (c) using Catmull-Rom-, and (d) using polynomial interpolation of degree five. (e) shows D2 VR of projection-based volumetric data. Figure (a) - (d) were rendered from grids with a resolution of 643 . Figure (e) was rendered from 64 projections each with a resolution of 642 . ", "caption_bbox": [98, 473, 731, 532]}, {"image_id": 1, "file_name": "252_01.png", "page": 2, "dpi": 300, "bbox": [98, 111, 733, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Data processing work flow of projection- and grid-based volume rendering. The dashed line corresponds to the traditional volume rendering pipeline. It requires two resampling steps in order to visualize the data. First an intermediate grid is resampled and then this grid is resampled again during ray traversal. The solid line corresponds to the projection-based volume rendering pipeline; one lossy resampling step is avoided. ", "caption_bbox": [98, 335, 731, 394]}, {"image_id": 2, "file_name": "252_02.png", "page": 3, "dpi": 300, "bbox": [430, 460, 733, 659], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Difference of grid-based and projection-based re- sampling. (a) illustrates resampling along a ray on rectilin- ear volumetric data and (b) shows resampling along a ray directly from the filtered projections. ", "caption_bbox": [430, 674, 731, 733]}, {"image_id": 3, "file_name": "252_03.png", "page": 4, "dpi": 300, "bbox": [430, 194, 732, 502], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Parallel projection for a specific angle \u03b8.", "caption_bbox": [454, 515, 706, 533]}, {"image_id": 4, "file_name": "252_04.png", "page": 5, "dpi": 300, "bbox": [430, 112, 733, 442], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison of an iso-surface of the Marschner & Lobb function: (a) Analytically computed. (b) DVR render- ing of a 643 grid. (c) DVR rendering of an eight times big- ger grid (1283 ). (d) D2 VR from projection-based volumet- ric data (64 projections, each projection with a resolution of 642 ). Grids are reconstructed from 64 filtered projections, each projection with a resolution of 642 . ", "caption_bbox": [430, 457, 731, 562]}, {"image_id": 5, "file_name": "252_05.png", "page": 6, "dpi": 300, "bbox": [98, 112, 732, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Average (AVG) and maximum (MAX) absolute difference of projection-based and grid-based reconstruc- tion in percent of the data range, using different reconstruc- tion schemes. Grid-based reconstruction schemes from left to right: nearest neighbor- (NN), trilinear- (TRI), Catmull- Rom- (CAT), and polynomial interpolation with polynomi- als of degree 3 (P3), 4 (P4) and 5 (P5). ", "caption_bbox": [98, 857, 399, 962]}, {"image_id": 6, "file_name": "252_06.png", "page": 7, "dpi": 300, "bbox": [98, 596, 401, 828], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) Axial slice of the Carp dataset, (b) close-up using grid-based reconstruction with Catmull-Rom interpo- lation on a 256x256x512 resolution grid, (c) close-up using projection-based reconstruction from 128 projections each with a resolution of 128x256, (d) Absolute difference of data values of (b) and (c), dark green regions depicting zero difference, light red regions depicting a difference of up to 7.5% of the range of data values. ", "caption_bbox": [98, 842, 399, 962]}, {"image_id": 7, "file_name": "252_07.png", "page": 9, "dpi": 300, "bbox": [427, 112, 715, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Color encoded differences in degrees between analytically computed gradients and (a) the estimated gradients using central difference gradient estimation on the grid, (b) the estimated gradients using our new projection-based gradient estimation method. ", "caption_bbox": [427, 354, 713, 428]}, {"image_id": 8, "file_name": "252_08.png", "page": 9, "dpi": 300, "bbox": [115, 113, 403, 321], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Color encoded differences between analytical value and (a) the reconstructed value using trilinear in- terpolation on the grid (643 ), (b) the reconstructed value using Filtered Back-Projection. ", "caption_bbox": [116, 353, 402, 412]}], "253": [{"image_id": 0, "file_name": "253_00.png", "page": 2, "dpi": 300, "bbox": [96, 118, 735, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization of an MRI of a mouse torso. The original volume (left) is tone shaded. (right) Volume deformed using a Hierarchical B-Spline. Red circles denote source points, and blue circles denote target points. ", "caption_bbox": [98, 293, 731, 321]}, {"image_id": 1, "file_name": "253_01.png", "page": 3, "dpi": 300, "bbox": [98, 114, 732, 336], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of deformation rendering. Sampling planes are spaced uniformly in view space. Polygons are drawn in each sampling plane. Their texture coordinates provide positions in object space to be sampled. To render deformed volumes, the deformation function is used to map between object space coordinates and volume texture coordinates. ", "caption_bbox": [98, 348, 731, 392]}, {"image_id": 2, "file_name": "253_02.png", "page": 4, "dpi": 300, "bbox": [427, 111, 736, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Images of a solid brick inside of a 2563 volume un- der a sine deformation. The deformation is performed with control texures of: a) 163 , b) 323 , c) 643 . d) performs the deformation in the fragment shader. ", "caption_bbox": [430, 381, 731, 443]}, {"image_id": 3, "file_name": "253_03.png", "page": 5, "dpi": 300, "bbox": [95, 111, 404, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A sphere with diffuse illumination illustrates is- sues in gradient computation. (a) forward differences poorly estimate gradients yielding a blocky appearance, this is solved by pre-filtering the volume before gradient compu- tation (b). ", "caption_bbox": [98, 293, 399, 367]}, {"image_id": 4, "file_name": "253_04.png", "page": 5, "dpi": 300, "bbox": [474, 111, 689, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A rendering of a human head captured via CT imaging (512x512x106). This rendering displays a clipping plane with a sampling plane rendered both on the clipping plane and in a detached viewport on the image plane. ", "caption_bbox": [430, 330, 731, 389]}, {"image_id": 5, "file_name": "253_05.png", "page": 6, "dpi": 300, "bbox": [142, 111, 357, 231], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A crude registration of a mouse torso captured via MRI (256x256x192), shown in blue/grey, to a second mouse captured via CT (256x256x385), shown in black/red. Both datasets and their associated warp textures are passed to the fragment shaders, where they are shaded and mixed. ", "caption_bbox": [98, 242, 399, 316]}, {"image_id": 6, "file_name": "253_06.png", "page": 7, "dpi": 300, "bbox": [138, 111, 362, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Frame rates in fps of control texture size vs. sam- ple planes per voxel, using the mouse torso of Figure 1, a 256x256x192 volume. ", "caption_bbox": [430, 324, 731, 368]}], "254": [{"image_id": 0, "file_name": "254_00.png", "page": 2, "dpi": 300, "bbox": [104, 118, 391, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Difficult TF construction. For this MR angiogra- phy there is no clue to the value range of the vessels in the full histogram. Thus, there is no guidance for selecting an appropriate TF, which in this case would be number 3. ", "caption_bbox": [98, 248, 399, 306]}, {"image_id": 1, "file_name": "254_01.png", "page": 3, "dpi": 300, "bbox": [461, 113, 700, 189], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Complex peak shapes. If this histogram is to be represented as two peaks, which would they be? ", "caption_bbox": [430, 201, 731, 229]}, {"image_id": 2, "file_name": "254_02.png", "page": 3, "dpi": 300, "bbox": [481, 251, 682, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Definition of peak area. The base line is the solid straight line, invalid base lines are dashed. The peak area is shaded. ", "caption_bbox": [430, 368, 731, 411]}, {"image_id": 3, "file_name": "254_03.png", "page": 4, "dpi": 300, "bbox": [436, 111, 718, 400], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Synthetic data set imitating a vessel, designed not to coincide with a Cartesian block structure. The back- ground and the spiral have Gamma and Gaussian distribu- tions, respectively. The spiral peak at value 100 is not visible, even using a logarithmic scale as proposed in [PM04]. ", "caption_bbox": [430, 414, 731, 488]}, {"image_id": 4, "file_name": "254_04.png", "page": 5, "dpi": 300, "bbox": [437, 768, 665, 875], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Varying block size for spiral data sets, \u03b1 = 10. Blocks smaller than 63 yield less effect from spatial coher- ence. Otherwise a block size similar to the size of the feature in question is appropriate. ", "caption_bbox": [430, 888, 731, 947]}, {"image_id": 5, "file_name": "254_05.png", "page": 5, "dpi": 300, "bbox": [436, 437, 686, 654], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Varying \u03b1, yin-yang data set. Top: For higher \u03b1 the peak amplification and the noise both increase. (\u00b5y2 = 150) Bottom: Peak detection for the high-intensity \u2018organ\u2019. Detection confidence generally increases with \u03b1 but quickly reaches a plateau for simpler detections. ", "caption_bbox": [430, 661, 731, 735]}, {"image_id": 6, "file_name": "254_06.png", "page": 5, "dpi": 300, "bbox": [436, 118, 674, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Varying \u03b1, spiral data set. Top: For higher \u03b1 the peak amplification and the noise both increase. (\u03c1 = 6) Bot- tom: \u2018Vessel\u2019 peak detection. Detection improves for higher \u03b1 but noise reduces the confidence at very high \u03b1. ", "caption_bbox": [430, 346, 731, 405]}, {"image_id": 7, "file_name": "254_07.png", "page": 5, "dpi": 300, "bbox": [104, 111, 359, 400], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Synthetic data set imitating two organs. The \u2018yin- yang\u2019 shape is chosen so as not to coincide with a Cartesian block structure. The background is zero, the \u2018organs\u2019 have separate Gaussian distributions. ", "caption_bbox": [98, 414, 399, 472]}, {"image_id": 8, "file_name": "254_08.png", "page": 6, "dpi": 300, "bbox": [105, 122, 382, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Peak detection results for 20 MR AAA angiogra- phies. The block size is 83 for both \u03b1-histograms and PRHs. ", "caption_bbox": [430, 120, 731, 149]}, {"image_id": 9, "file_name": "254_09.png", "page": 7, "dpi": 300, "bbox": [436, 111, 733, 791], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Adapting TFs for MR angiographies. The width of the aorta (the large central vessel) is to be measured at high precision, the error should be less than 2 mm (\u2248 2 pix- els). Left column: A TF based on the average vessel intensity value of the 20 data sets is unacceptable. In the top image the aorta width is exaggerated, in the bottom image the aorta is hardly visible. Right column: An adapted TF based on the detected peak in the \u03b1-histogram (\u03b1 = 10) correctly renders the width of the aorta in both cases. In the graphs, a cross denotes the peak and a circle denotes the TF reference point. ", "caption_bbox": [430, 804, 731, 954]}, {"image_id": 10, "file_name": "254_10.png", "page": 7, "dpi": 300, "bbox": [104, 122, 402, 386], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Resulting \u03b1-histograms for two challenging MR angiography cases. Smoothing applied, \u03b1 = 10. Top: Using the \u03b1-histogram the peak is found with high accuracy and confidence (e p = 0.03, c p = 0.20). Bottom: Even though the detected peak apex is not quite accurate, the peak range is readily found (e p = 0.30, c p = 0.01). ", "caption_bbox": [98, 400, 399, 490]}, {"image_id": 11, "file_name": "254_11.png", "page": 8, "dpi": 300, "bbox": [104, 118, 374, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Peak detection for MR biliary duct examination. In contrast to the PRH method, the \u03b1-histogram fails to dis- tinguish the kidney peak, since it is highly overlapping. ", "caption_bbox": [98, 278, 399, 321]}], "255": [{"image_id": 0, "file_name": "255_00.png", "page": 3, "dpi": 300, "bbox": [376, 64, 693, 198], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Two different configurations with the same result: (a) the ray passes all line segments of the triangle clockwise, hence all signs are positive, and (b) the ray passes all line segments counter-clockwise, and therefore all signs are neg- ative. ", "caption_bbox": [391, 209, 692, 283]}, {"image_id": 1, "file_name": "255_01.png", "page": 3, "dpi": 300, "bbox": [83, 66, 377, 196], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Three possible cases for the Pl\u00fccker test: (a) ray r passes clockwise line s, (b) ray r passes counter-clockwise line s, and (c) ray r intersects line s. ", "caption_bbox": [58, 206, 359, 250]}, {"image_id": 2, "file_name": "255_02.png", "page": 3, "dpi": 300, "bbox": [401, 503, 681, 595], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) Na\u00efve approach: All three exiting faces of the triangle are tested independently although each line is shared by two faces, and (b) Optimized approach: The solid lines tests are given from the previous tetrahedron and the dotted line needs only to be computed if the test with the dashed lines failed. The direction of each line can be swapped by turning the sign of the Pl\u00fccker test. ", "caption_bbox": [391, 606, 692, 711]}, {"image_id": 3, "file_name": "255_03.png", "page": 4, "dpi": 300, "bbox": [76, 651, 344, 852], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The tetrahedral Blunt-fin data set rendered as an iso-surface (upper-left), maximum-intensity-projection (upper-right), direct volume rendering (lower-left) with transfer functions (lower-right). ", "caption_bbox": [58, 863, 359, 922]}, {"image_id": 4, "file_name": "255_04.png", "page": 5, "dpi": 300, "bbox": [69, 599, 349, 744], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) To determine the exiting face, the hexahedron is subdivided into three areas. (b) The next step is then to check which face is intersected by applying two additional Pl\u00fccker tests (A0 : dotted edges, A1 : solid edges, and A2 : dashed edges). ", "caption_bbox": [58, 756, 359, 830]}, {"image_id": 5, "file_name": "255_05.png", "page": 5, "dpi": 300, "bbox": [418, 171, 666, 296], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Blunt-fin: Decomposing produces artifacts (left), while the bilinear patch delivers smooth results (right). ", "caption_bbox": [391, 306, 692, 334]}, {"image_id": 6, "file_name": "255_06.png", "page": 6, "dpi": 300, "bbox": [86, 392, 334, 579], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Combustion chamber data set rendered as iso- surface (upper-left), maximum-intensity-projection (upper- right), direct volume rendering (lower-left) with transfer functions (lower-right). ", "caption_bbox": [58, 589, 359, 648]}, {"image_id": 7, "file_name": "255_07.png", "page": 7, "dpi": 300, "bbox": [72, 288, 347, 509], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Seamless integration with surface ray tracing. The volume data set, in this case the Bucky-ball, is augmented and surrounded by reflective surfaces and light sources. ", "caption_bbox": [58, 519, 359, 563]}, {"image_id": 8, "file_name": "255_08.png", "page": 7, "dpi": 300, "bbox": [376, 64, 693, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Unstructured (Bucky-ball) and curvilinear (Com- bustion Chamber) data sets can not only be rendered into one scene. Even more important is that all primitives inter- act with each other. ", "caption_bbox": [391, 321, 692, 380]}], "256": [{"image_id": 0, "file_name": "256_00.png", "page": 2, "dpi": 300, "bbox": [469, 535, 694, 667], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example of hierarchical clustering of five initial clusters visualized using a dendrogram. ", "caption_bbox": [430, 679, 731, 707]}, {"image_id": 1, "file_name": "256_01.png", "page": 3, "dpi": 300, "bbox": [106, 273, 394, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A 1D illustration of the initial labelling of the 2D peaks in the LH histogram. Every peak becomes one initial cluster. ", "caption_bbox": [98, 395, 399, 439]}, {"image_id": 2, "file_name": "256_02.png", "page": 3, "dpi": 300, "bbox": [470, 324, 694, 434], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Two probability distributions. The dashed line is the decision boundary made by a Bayesian classifier. The red area represents the probability of a wrong decision. We use an estimate of the overlap of two 2D distributions as our similarity measure. ", "caption_bbox": [430, 444, 731, 518]}, {"image_id": 3, "file_name": "256_03.png", "page": 5, "dpi": 300, "bbox": [143, 111, 688, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Phantom data set. (a) shows a slice and the correspondence of four most important boundaries in the LH histogram. (d) shows the initial clustering. In (e) and (f) the hierarchy based on the LH similarity was used (see dendrogram (b)). The level chosen in (e) yields each of the four boundaries in own cluster. In (f) boundaries 1 and 4 are grouped since they are close in the LH space. A hierarchy that combines both similarity measures (c) results in desired clustering (g). The dendrograms (b, c) show the order of grouping. The right child inherits the color from the left child. ", "caption_bbox": [98, 391, 731, 465]}, {"image_id": 4, "file_name": "256_04.png", "page": 5, "dpi": 300, "bbox": [438, 639, 726, 810], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The hierarchy interaction framework. First, the hierarchy is generated for the initial clusters using a default similarity s. Then the user can interact with the hierarchy by changing the level k and (de)selecting clusters. The user can also change the similarity measure or apply constrains to selected clusters. ", "caption_bbox": [430, 822, 731, 911]}, {"image_id": 5, "file_name": "256_05.png", "page": 6, "dpi": 300, "bbox": [438, 474, 725, 756], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Renderings of the carp (256x256x512) and engine (256x256x110) data sets. The green and blue boundaries of the engine were visualized at a certain hierarchy level. Af- ter fixing them at that level a further change of the level grouped the brown boundary. For the carp we first fixed the bone boundaries at the level where all of them were grouped and then continued joining the remaining air boundaries. ", "caption_bbox": [430, 767, 731, 872]}, {"image_id": 6, "file_name": "256_06.png", "page": 6, "dpi": 300, "bbox": [106, 157, 393, 279], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A hierarchy cut at level k = 3 yields clusters that are further grouped using another similarity measure. The hierarchy can be, therefore, a combination of several simi- larity measures. The cluster consisting of elements e1 and e2 was fixed on level 2 and taken out of the hierarchy. ", "caption_bbox": [98, 286, 399, 363]}, {"image_id": 7, "file_name": "256_07.png", "page": 8, "dpi": 300, "bbox": [131, 399, 698, 712], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: CTA data set of a head (512x512x286). One level in the hierarchy and corresponding rendering is shown in (a). In (b) only two of the clusters were chosen: the skin and the skull. In (c) the skull and the vessels were selected, fixed and the color of the vessels was changed. Then by changing the level all other clusters inside the head (green) were grouped and removed from the visualization. ", "caption_bbox": [98, 711, 731, 770]}, {"image_id": 8, "file_name": "256_08.png", "page": 8, "dpi": 300, "bbox": [130, 114, 698, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Tooth data set (256x256x161). In (a) the major boundaries were selected by an easy choice of the hierarchy level (see the red line in the dendrogram). The LH histogram shows corresponding selection. Then the surrounding (pink) boundary was removed (b) and after fixing the dentin-air (yellow) boundary the rest of the enamel-air (orange) boundary was selected. In (c) the inside boundaries are shown after making the outside boundaries to (semi)transparent. In (d) we illustrate the possibility of grouping the outer boundaries (yellow). We achieved that by choosing the spatial-based similarity measure. ", "caption_bbox": [98, 318, 731, 392]}], "257": [{"image_id": 0, "file_name": "257_00.png", "page": 3, "dpi": 300, "bbox": [464, 116, 695, 192], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Bottom: a transfer function with the opacities as the vertical axis (V ). Top: the computed Gaussian ba- sis transfer function; The horizontal and vertical axes are respectively mean (\u00b5 ) and standard deviation (\u03c3 ) and each point has been drawn with the color and opacity computed for the related \u00b5 and \u03c3 . ", "caption_bbox": [430, 199, 731, 293]}, {"image_id": 1, "file_name": "257_01.png", "page": 7, "dpi": 300, "bbox": [131, 112, 700, 395], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Renderings of the Visible Human Male Head (2563 ) at different levels of details. Top row: using mean value for approximation. Bottom row: using Gaussian function for approximation. From left to right, each image represents an additional level of coarsening by a factor of two in each dimension. ", "caption_bbox": [98, 401, 731, 450]}, {"image_id": 2, "file_name": "257_02.png", "page": 7, "dpi": 300, "bbox": [129, 473, 675, 917], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Effects of downsampling distributions with different filters on the Richtmyer-Meshkov Instability dataset.", "caption_bbox": [126, 924, 699, 942]}, {"image_id": 3, "file_name": "257_03.png", "page": 8, "dpi": 300, "bbox": [107, 703, 716, 853], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) Errors of the mean and Gaussian approximations of the histogram for the three test datasets. At a certain level of detail, for each method, the reported error is the root mean squared error of the voxels\u2019 approximated histogram in comparison with their actual histogram, for all voxels in that level of coarsening. Rendering errors of the mean and Gaussian approximations ( f ) of the histogram on (b) the Richtmyer-Meshkov Instability dataset using different filters and (c) the spherical distance dataset using a high-frequency and low-frequency transfer function (V ). ", "caption_bbox": [98, 862, 730, 940]}, {"image_id": 4, "file_name": "257_04.png", "page": 8, "dpi": 300, "bbox": [129, 115, 675, 651], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Rendering with different transfer functions on the spherical distance dataset.", "caption_bbox": [196, 656, 632, 674]}], "258": [{"image_id": 0, "file_name": "258_00.png", "page": 3, "dpi": 300, "bbox": [117, 117, 381, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A 2D illustration of a four-block neighborhood. Red points show the location of block samples, the red dashed lines are the sample boundaries. The sample bound- ary distance, \u03b4b , is indicated for each block, b. ", "caption_bbox": [98, 342, 399, 401]}, {"image_id": 1, "file_name": "258_01.png", "page": 3, "dpi": 300, "bbox": [467, 119, 681, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Center of eight-block neighborhood configuration with block and edge labeling. The gray solid lines indicate the block intersections. The edge labeling is used to define the edge weights, ei, j (\u03c1), where \u03c1 is the position along the edge in the local coordinate system, r, s,t, with origin at the block intersection center. ", "caption_bbox": [430, 321, 731, 410]}, {"image_id": 2, "file_name": "258_02.png", "page": 4, "dpi": 300, "bbox": [98, 473, 400, 553], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: One-dimensional illustrations of the three in- terblock interpolation variants (b\u2013d) and nearest neighbor sampling (a). Each graph contain two blocks, the leftmost with resolution level 0 and the rightmost with level 2. ", "caption_bbox": [98, 367, 399, 426]}, {"image_id": 3, "file_name": "258_03.png", "page": 5, "dpi": 300, "bbox": [103, 357, 396, 527], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: 2D illustration of block packing within a single texture object. Texture patches are allocated per level in chunks of the largest block size, S. Each block is represented by a square, smaller squares are lower resolution blocks. Multiple lower resolution blocks are packed tightly within the unit size S \u00d7 S, the largest squares. ", "caption_bbox": [98, 536, 399, 625]}, {"image_id": 4, "file_name": "258_04.png", "page": 6, "dpi": 300, "bbox": [97, 112, 734, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: The data sets that have been used for the evalua- tion of interblock interpolation. All are converted to 8-bits precision. The heart data set is statically compressed with- out gradients and stored on disk. ", "caption_bbox": [430, 392, 731, 451]}, {"image_id": 5, "file_name": "258_05.png", "page": 7, "dpi": 300, "bbox": [97, 386, 733, 719], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparison of interblock interpolation for an opaque lit surface. Original data set size 512\u00d7512\u00d7990 rendered at a ratio of 143:1. Block level distribution: 0, 2551, 5128, 23041, 32768 (highest to lowest resolution). ", "caption_bbox": [98, 725, 731, 753]}, {"image_id": 6, "file_name": "258_06.png", "page": 7, "dpi": 300, "bbox": [97, 111, 733, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison of the the presented block interpolations for a 32:1 data reduction of heart data set, original resolution 512\u00d7448\u00d7416. This rendering does not use any lighting and gradients are not present in the data set. ", "caption_bbox": [98, 345, 731, 373]}, {"image_id": 7, "file_name": "258_07.png", "page": 8, "dpi": 300, "bbox": [97, 111, 401, 495], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Comparison of interblock interpolation for a thin iso-surface, skin, and bones on the cadaver. The block boundary artefacts without interpolation are clearly re- moved by our scheme. There are, however, sampling arte- facts present in both images. Data reduction through LOD selection at 35:1. Original data set size 512\u00d7512\u00d72166 fit- ted into a 256\u00d7256\u00d7256 texture. ", "caption_bbox": [98, 501, 399, 605]}], "259": [{"image_id": 0, "file_name": "259_00.png", "page": 3, "dpi": 300, "bbox": [84, 268, 345, 547], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The Cartesian lattice and the structure of the sub- lattices. The FCC has half the sampling density and BCC has a quarter sampling density. The sampling density for each sampling lattice is the inverse of the volume of the Voronoi cell of that sampling lattice. ", "caption_bbox": [58, 554, 359, 632]}, {"image_id": 1, "file_name": "259_01.png", "page": 3, "dpi": 300, "bbox": [425, 296, 669, 421], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The Voronoi cells", "caption_bbox": [471, 426, 611, 444]}, {"image_id": 2, "file_name": "259_02.png", "page": 4, "dpi": 300, "bbox": [77, 106, 358, 201], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Nyquist regions for various subsampling steps. The gray cube indicates the support of the spectrum of the original Cartesian-sampled 3D function. ", "caption_bbox": [58, 206, 359, 254]}, {"image_id": 3, "file_name": "259_03.png", "page": 4, "dpi": 300, "bbox": [425, 245, 669, 368], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The first neighbor cells", "caption_bbox": [457, 374, 626, 392]}, {"image_id": 4, "file_name": "259_04.png", "page": 5, "dpi": 300, "bbox": [412, 722, 672, 847], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: ML Data at a CC resolution of 403 (left) and its error image (right). The max angular error depicted is 2 ra- dians. ", "caption_bbox": [391, 854, 692, 904]}, {"image_id": 5, "file_name": "259_05.png", "page": 5, "dpi": 300, "bbox": [148, 91, 269, 196], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: BCC indexing scheme. The sequence of images shows a simple 2x2x4 BCC dataset being mapped from canonical-lattice-space to compacted-Cartesian-space. Green (dotted) lines illustrate even z-slices of the BCC dataset. Red (solid) lines illustrate odd z-slices. Left column: canonical-lattice-space for BCC. Right column: compacted-Cartesian-space for CC; note that the size of each compacted Cartesian slice has been decreased by a scaling factor of two (and thus the concept of \u2019compaction\u2019). Top row: front view. Bottom row: side view. ", "caption_bbox": [58, 203, 359, 357]}, {"image_id": 6, "file_name": "259_06.png", "page": 5, "dpi": 300, "bbox": [80, 522, 338, 646], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: FCC index compaction into Cartesian scheme (given in xyz-coordinate tuples) used for memory storage. ", "caption_bbox": [58, 654, 359, 687]}, {"image_id": 7, "file_name": "259_07.png", "page": 6, "dpi": 300, "bbox": [412, 446, 672, 694], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Top row: BCC at one quarter resolution (left) and its error image (right); Bottom row: CC at one quarter resolution (left) and its error image (right). The max angular error depicted is 2 radians. We used linear down-sampling and linear reconstruction filters. ", "caption_bbox": [391, 701, 692, 779]}, {"image_id": 8, "file_name": "259_08.png", "page": 6, "dpi": 300, "bbox": [412, 90, 672, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Top row: FCC at half resolution (left) and its error image (right); Bottom row: CC at half resolution (left) and its error image (right). The max angular error depicted is 2 radians. We used linear down-sampling and cubic recon- struction filters. ", "caption_bbox": [391, 345, 692, 423]}, {"image_id": 9, "file_name": "259_09.png", "page": 6, "dpi": 300, "bbox": [80, 228, 340, 477], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Top row: FCC at half resolution (left) and its er- ror image (right); Bottom row: CC at half resolution (left) and its error image (right). The max angular error depicted is 2 radians. We used linear down-sampling and linear re- construction filters. ", "caption_bbox": [58, 483, 359, 561]}, {"image_id": 10, "file_name": "259_10.png", "page": 7, "dpi": 300, "bbox": [416, 90, 677, 586], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: The skull data set at the original resolution of 1283 at the top. First row, at half the resolution, left image on FCC, right on re-sampled Cartesian lattice. Second row at quarter resolution, left image on BCC and right image on re-sampled Cartesian. The bottom row, the dataset at one eighth resolution. These volumes are down-sampled using linear type filter and reconstructed using cubic type recon- structions. ", "caption_bbox": [391, 593, 692, 717]}, {"image_id": 11, "file_name": "259_11.png", "page": 7, "dpi": 300, "bbox": [80, 442, 340, 567], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: CC at one eight of the original resolution (left) and its error image (right). The max angular error depicted is 2 radians. We used linear down-sampling and linear re- construction filters. ", "caption_bbox": [58, 573, 359, 636]}, {"image_id": 12, "file_name": "259_12.png", "page": 7, "dpi": 300, "bbox": [80, 90, 340, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Top row: BCC at one quarter resolution (left) and its error image (right); Bottom row: CC at one quarter resolution (left) and its error image (right). The max angular error depicted is 2 radians. We used linear down-sampling and cubic reconstruction filters. ", "caption_bbox": [58, 345, 359, 423]}], "260": [], "261": [{"image_id": 0, "file_name": "261_00.png", "page": 2, "dpi": 300, "bbox": [430, 406, 732, 442], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: System overview.", "caption_bbox": [511, 449, 649, 470]}, {"image_id": 1, "file_name": "261_01.png", "page": 2, "dpi": 300, "bbox": [98, 111, 729, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The approach used by the system, using a skeleton to quantify the morphology of the scanned coral.", "caption_bbox": [140, 260, 689, 281]}, {"image_id": 2, "file_name": "261_02.png", "page": 3, "dpi": 300, "bbox": [99, 122, 390, 458], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Examples of the measurement method of five dif-", "caption_bbox": [98, 465, 399, 486]}, {"image_id": 3, "file_name": "261_03.png", "page": 3, "dpi": 300, "bbox": [435, 589, 731, 696], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Close-up volume rendering after various amounts", "caption_bbox": [430, 703, 731, 724]}, {"image_id": 4, "file_name": "261_04.png", "page": 4, "dpi": 300, "bbox": [157, 111, 342, 283], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Cross-section showing a clear fracture.", "caption_bbox": [124, 287, 374, 308]}, {"image_id": 5, "file_name": "261_05.png", "page": 4, "dpi": 300, "bbox": [489, 111, 674, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Part of a slice from a scanned coral, clearly show-", "caption_bbox": [430, 306, 731, 327]}, {"image_id": 6, "file_name": "261_06.png", "page": 5, "dpi": 300, "bbox": [489, 577, 674, 741], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Simplification of the skeleton.", "caption_bbox": [480, 746, 681, 767]}, {"image_id": 7, "file_name": "261_07.png", "page": 5, "dpi": 300, "bbox": [157, 448, 342, 612], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Skeleton with loops highlighted.", "caption_bbox": [142, 617, 355, 638]}, {"image_id": 8, "file_name": "261_08.png", "page": 5, "dpi": 300, "bbox": [489, 186, 674, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Removing short end branches from the skeleton.", "caption_bbox": [434, 355, 727, 376]}, {"image_id": 9, "file_name": "261_09.png", "page": 7, "dpi": 300, "bbox": [101, 111, 725, 473], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: From top to bottom: object 393, object 389, and object 394. From left to right: Volume rendering of the CT scan,", "caption_bbox": [98, 473, 730, 494]}], "262": [{"image_id": 0, "file_name": "262_00.png", "page": 3, "dpi": 300, "bbox": [148, 112, 683, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization of particular phonons. First (a) and fourth (d) reflection color coded using the overall frequency spec- trum. First (b, c) and fourth (e, f) reflection color coded using the frequency band at 160 Hz and at 10240 Hz, respectively. ", "caption_bbox": [98, 430, 730, 463]}, {"image_id": 1, "file_name": "262_01.png", "page": 4, "dpi": 300, "bbox": [148, 112, 683, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Clustered wave front. (a) first reflection color coded using the overall frequency spectrum. (b) Traversed distance represented by use of cones. (c) first reflection color coded using the frequency band at 10240 Hz. ", "caption_bbox": [98, 275, 730, 308]}, {"image_id": 2, "file_name": "262_02.png", "page": 4, "dpi": 300, "bbox": [148, 328, 683, 486], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Clustered wave fronts. First (a) and second (b) reflections at the bottom. (c) Second reflections at the bottom reflected before at the wall and powerwall, respectively. ", "caption_bbox": [98, 491, 730, 524]}, {"image_id": 3, "file_name": "262_03.png", "page": 4, "dpi": 300, "bbox": [443, 669, 720, 796], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Wave front traversed from the sound source (a), separated after reflections (b). ", "caption_bbox": [430, 801, 731, 834]}, {"image_id": 4, "file_name": "262_04.png", "page": 6, "dpi": 300, "bbox": [102, 484, 397, 621], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Energy on the floor after the 5th (a) and 10th (c) reflection for the 2560Hz band. ", "caption_bbox": [98, 626, 399, 659]}, {"image_id": 5, "file_name": "262_05.png", "page": 6, "dpi": 300, "bbox": [147, 112, 684, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Energy on the floor at timesteps 20-23 msec for the 160Hz band.", "caption_bbox": [227, 243, 601, 261]}, {"image_id": 6, "file_name": "262_06.png", "page": 6, "dpi": 300, "bbox": [434, 296, 729, 434], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Average energy between 0-49 (a) and 50-100 (b) msec for the 20480Hz band. ", "caption_bbox": [430, 439, 731, 472]}, {"image_id": 7, "file_name": "262_07.png", "page": 7, "dpi": 300, "bbox": [148, 332, 683, 490], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Deformed spheres representation at 80 Hz collected before (a) and after (b) 50 msec at one listener position. Deformed spheres representation at 5120 Hz at three position in a room with a separating wall with total absorption (c). ", "caption_bbox": [98, 495, 730, 528]}, {"image_id": 8, "file_name": "262_08.png", "page": 7, "dpi": 300, "bbox": [148, 112, 683, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Deformed spheres representation at four listener positions. (a) color coded using the overall frequency spectrum (b) by 80 Hz and (c) by 1280 Hz. ", "caption_bbox": [98, 279, 730, 312]}], "263": [{"image_id": 0, "file_name": "263_00.png", "page": 2, "dpi": 300, "bbox": [390, 89, 693, 554], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Illustration of the steps in the MPM algorithm for particles occupying a single cell of the background grid. 1. A representation of four material points (filled circles), over- laid with the computational grid (solid lines). Arrows repre- sent displacement vectors. 2. The material point state vector (mass, volume, velocity, etc.) is projected to the nodes of the computational grid. 3. The discrete form of the equations of motion is solved on the computational grid, resulting in up- dated nodal velocities and positions. 4. The updated nodal kinematics are interpolated back to the material points and their state updated. 5a. In the standard MPM algorithm, the computational grid is reset to its original configuration and the process repeated. 5b. In a modification to the algorithm, the grid is not reset, but is allowed to move with the parti- cles, thereby retaining the optimal distribution of particles with respect to the grid. ", "caption_bbox": [391, 561, 692, 807]}, {"image_id": 1, "file_name": "263_01.png", "page": 3, "dpi": 300, "bbox": [58, 212, 362, 445], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Tensor values can be used to deform and rotate spheres representing particles into ellipsoids. (Color version Figure 12.) ", "caption_bbox": [58, 463, 359, 511]}, {"image_id": 2, "file_name": "263_02.png", "page": 4, "dpi": 300, "bbox": [58, 184, 362, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Ambient occlusion shading texture values mapped on an aluminum cylinder impacted by a steel sphere (not shown). This configuration has been tested experimentally and provides a source of data for material model valida- tion. One thing to note is the ability to see the two spheres standing out in front of the hole. Subimages are referred to as A (left) and B (right). It took 25 minutes to precompute the textures. Frame rates to render image A (500x500) us- ing direct lighting only, direct lighting with ambient occlu- sion, and ambient occlusion only were 15.22 f/s, 14.04 f/s, and 15.14 f/s respectively. Frame rates to render image B (500x500) were 8.19 f/s, 7.84 f/s, and 8.35 f/s. ", "caption_bbox": [58, 345, 359, 530]}, {"image_id": 3, "file_name": "263_03.png", "page": 4, "dpi": 300, "bbox": [390, 90, 694, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Ambient occlusion shading texture values mapped on a steel projectile impacting an iron target. Extensive data has been collected on this configuration, making it a valu- able tool for validating material and contact models. Subim- ages are referred to as A, B, and C, left to right. Figure A is provides a view of the whole data set, while B and C show some close ups. The relative positions of the bullet with the material as well as inside the holes in the objects are eas- ily perceived. It took 33 minutes to precompute the textures. Frame rates to render image A (250x500) using direct light- ing only, direct lighting with ambient occlusion, and ambient occlusion only were 32.89 f/s, 28.75 f/s, and 30.50 f/s re- spectively. Frame rates to render image C (250x500) were 24.62 f/s, 22.66 f/s, and 26.32 f/s. ", "caption_bbox": [391, 297, 692, 512]}, {"image_id": 4, "file_name": "263_04.png", "page": 5, "dpi": 300, "bbox": [390, 90, 694, 194], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Ambient occlusion shading texture values mapped on a later time step of the same simulation as seen in Fig- ure 6. The views are identical. Subimages are referred to as A, B, and C, left to right. It took 261 minutes to precompute the textures. Frame rates to render image A (500x500) us- ing direct lighting only, direct lighting with ambient occlu- sion, and ambient occlusion only were 12.00 f/s, 10.68 f/s, and 10.86 f/s respectively. Frame rates to render image C (500x500) were 9.09 f/s, 8.49 f/s, and 9.45 f/s. ", "caption_bbox": [391, 201, 692, 340]}, {"image_id": 5, "file_name": "263_05.png", "page": 5, "dpi": 300, "bbox": [58, 426, 362, 531], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Ambient occlusion shading texture values mapped on a steel cylinder, filled with detonating high explosive. Container breakup has begun. The views are identical to the ones in Figure 7. Subimages are referred to as A, B, and C, left to right. It took 66 minutes to precompute the textures. Frame rates to render image A (500x500) using direct light- ing only, direct lighting with ambient occlusion, and ambient occlusion only were 18.96 f/s, 17.23 f/s, and 19.10 f/s re- spectively. Frame rates to render image C (500x500) were 13.89 f/s, 12.70 f/s, and 14.40 f/s. ", "caption_bbox": [58, 538, 359, 692]}, {"image_id": 6, "file_name": "263_06.png", "page": 5, "dpi": 300, "bbox": [391, 364, 694, 518], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Ambient occlusion texture maps are applied to the color-mapped particles. The image on the right adds direct lighting with shadows. The data set is the same as in Fig- ure 3. (Color version Figure 14.) ", "caption_bbox": [391, 525, 692, 588]}, {"image_id": 7, "file_name": "263_07.png", "page": 5, "dpi": 300, "bbox": [58, 90, 362, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Compaction of foam by a rigid plate. The foam sample is about 1 mm3 . The initial geometry was collected using micro-CT, which was then converted to a particle dis- tribution, thus bypassing the extreme difficulties associated with constructing a suitable body-fitted mesh [BBMS06]. The left image includes ambient occlusion shading texture values. The image on the right contains direct lighting only. It took 12 hours to precompute the textures. Frame rates to render the left and right images (500x500) were 7.35 f/s and 8.67 f/s respectively. (Color version Figure 13.) ", "caption_bbox": [58, 251, 359, 405]}, {"image_id": 8, "file_name": "263_08.png", "page": 6, "dpi": 300, "bbox": [390, 544, 694, 847], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: A container with explosives is heated by a pool fire. The explosive starts to burn and eventually causes a rup- ture at the top. (Color version Figure 15.) ", "caption_bbox": [391, 854, 692, 902]}, {"image_id": 9, "file_name": "263_09.png", "page": 6, "dpi": 300, "bbox": [58, 90, 362, 412], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: By varying the threshold of the Laplacian to be counted as an edge we can change how many edges are dis- played. The data visualized is a 9 mm bullet just prior to striking a model of the human torso. Several components of the torso have been removed to provide a view of the blood contained in the heart. The images are referred to as A (top left), B (top right), C (bottom left), and D (bottom right). Image A shows no silhouettes. Image B and C show pro- gressively more and more edges. Image D shows all the de- tectable edges. Frame rates to render image A, B, and C at 500x500 are 2.25 f/s, 2.22 f/s, and 2.22 f/s respectively. ", "caption_bbox": [58, 419, 359, 589]}, {"image_id": 10, "file_name": "263_10.png", "page": 7, "dpi": 300, "bbox": [58, 526, 362, 680], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: A foam structure being crushed (same data as in Figure 5). The images are color mapped and shaded with direct lighting. Images on the right contain silhouette edges, the ones on the left do not. Frame rates to render the left and right images (500x500) were 8.96 f/s and 8.80 f/s respec- tively. (Color version Figure 16.) ", "caption_bbox": [58, 687, 359, 780]}], "264": [{"image_id": 0, "file_name": "264_00.png", "page": 2, "dpi": 300, "bbox": [424, 609, 651, 681], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Different color scales (Grey-scale, Extended", "caption_bbox": [401, 705, 672, 717]}, {"image_id": 1, "file_name": "264_01.png", "page": 2, "dpi": 300, "bbox": [426, 164, 648, 321], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Existing thermographic visualization.", "caption_bbox": [423, 336, 649, 348]}, {"image_id": 2, "file_name": "264_02.png", "page": 4, "dpi": 300, "bbox": [400, 344, 662, 506], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: CIE L*a*b* approx luminance curves.", "caption_bbox": [420, 521, 652, 533]}, {"image_id": 3, "file_name": "264_03.png", "page": 5, "dpi": 300, "bbox": [430, 481, 630, 755], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Examples of the three different visual map-", "caption_bbox": [410, 778, 662, 790]}, {"image_id": 4, "file_name": "264_04.png", "page": 6, "dpi": 300, "bbox": [77, 479, 364, 701], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Example of a visual mapping, where \u03b8 is", "caption_bbox": [102, 704, 344, 722]}], "265": [{"image_id": 0, "file_name": "265_00.png", "page": 1, "dpi": 300, "bbox": [101, 272, 730, 436], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The three main application areas of our system. Left: Virtual colonoscopy. The semi-transparent isosurface is blended with a direct volume ray-casting of the area behind. Center: Planning of pituitary surgery for tumor removal. Using direct volume rendering in combination with semi-transparent isosurfaces allows for visualization of otherwise occluded objects. Right: Virtual angioscopy of the aorta and a stent that supports it. Two different isovalues have to be used in this case. ", "caption_bbox": [98, 446, 731, 505]}, {"image_id": 1, "file_name": "265_01.png", "page": 2, "dpi": 300, "bbox": [137, 119, 369, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of a 512x512x478 colonoscopy data set rendered with our system. Figure 1 (left) and Figure 3 show inside views using the same data set and transfer function. ", "caption_bbox": [98, 441, 399, 484]}, {"image_id": 2, "file_name": "265_02.png", "page": 3, "dpi": 300, "bbox": [99, 111, 732, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Changing the isosurface opacity allows to focus more on the foreground rendered with isosurfacing (e.g., the colon) or the background rendered with direct volume rendering. Correctly integrating polygonal geometry such as the grid shown here facilitates spatial orientation. Isosurface opacity also influences rendering performance, as illustrated in Tables 1 and 2. ", "caption_bbox": [98, 277, 731, 320]}, {"image_id": 3, "file_name": "265_03.png", "page": 4, "dpi": 300, "bbox": [98, 746, 401, 901], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: In endonasal pituitary surgery the endoscope en- ters through the nose and is advanced to the sphenoid sinus and the pituitary gland behind it (see Figure 1 (center)). ", "caption_bbox": [98, 912, 399, 955]}, {"image_id": 4, "file_name": "265_04.png", "page": 5, "dpi": 300, "bbox": [430, 718, 733, 886], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Determining ray start positions and ray lengths using rasterization of brick boundary faces. Left: The basic case described in Section 3.2.1. Right: Extended cases for endoscopy rendering, which are described in Section 3.2.2. ", "caption_bbox": [430, 896, 731, 955]}, {"image_id": 5, "file_name": "265_05.png", "page": 6, "dpi": 300, "bbox": [141, 809, 358, 912], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Holes resulting from near clipping plane intersec- tion (left) must be filled with valid starting positions (right). ", "caption_bbox": [98, 927, 399, 955]}, {"image_id": 6, "file_name": "265_06.png", "page": 7, "dpi": 300, "bbox": [175, 750, 324, 901], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Performance comparison of different isosurface opacities for the colonoscopy dataset with a simple ramp as transfer function. Measured for a 512x512 viewport on a GeForce 7800. ", "caption_bbox": [430, 904, 731, 963]}, {"image_id": 7, "file_name": "265_07.png", "page": 9, "dpi": 300, "bbox": [149, 128, 698, 505], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) A view from a planning session for virtual pituitary surgery. (b) and (c) illustrate virtual colonoscopy with an overview and an inside view, respectively. Both images use the same transfer function, and in (c) also the surface of the colon is shaded and rendered semi-transparently. (d) During virtual pituitary surgery an endoscope is inserted through the nose. ", "caption_bbox": [98, 527, 731, 570]}], "266": [{"image_id": 0, "file_name": "266_00.png", "page": 2, "dpi": 300, "bbox": [142, 111, 357, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Processing pipeline: From scanned raw data to a point-based visualization. ", "caption_bbox": [98, 335, 399, 368]}, {"image_id": 1, "file_name": "266_01.png", "page": 3, "dpi": 300, "bbox": [106, 112, 731, 283], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Filtering and data correction of the Mannequin dataset: (a) Data points which do not belong to the scanned subject (green) are selected and removed. (b) The positions of the remaining data points are smoothed. (c) Color values of the data points are corrected based on a median filter. A close-up can be seen in Figure 4. ", "caption_bbox": [98, 287, 730, 335]}, {"image_id": 2, "file_name": "266_02.png", "page": 3, "dpi": 300, "bbox": [438, 370, 728, 570], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Filtering and data correction of the head of the Mannequin dataset: (a) The positions of the data points are smoothed. (b) Color values of the data points are corrected based on a median filter. ", "caption_bbox": [430, 574, 731, 637]}, {"image_id": 3, "file_name": "266_03.png", "page": 3, "dpi": 300, "bbox": [106, 575, 396, 732], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Octree leaf block resolutions in left cheek area: (a) Blocks with 5mm resolution, (b) blocks with 20mm reso- lution. ", "caption_bbox": [98, 736, 399, 784]}, {"image_id": 4, "file_name": "266_04.png", "page": 5, "dpi": 300, "bbox": [106, 111, 724, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Color matching of the Accident Victim dataset: (a) Image with reference colors. (b) Image with yellow color cast that needs to be corrected. (c) Image with new matched colors. ", "caption_bbox": [98, 293, 730, 326]}, {"image_id": 5, "file_name": "266_05.png", "page": 5, "dpi": 300, "bbox": [106, 345, 731, 558], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Nose region of Mannequin with different QSplat sizes: (a) Small QSplats, (b) medium QSplats, and (c) large QSplats.", "caption_bbox": [98, 563, 730, 581]}, {"image_id": 6, "file_name": "266_06.png", "page": 6, "dpi": 300, "bbox": [106, 112, 404, 599], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Lighting correction with an image of the Accident Victim dataset: (a) Uncorrected image, (b) corrected image. ", "caption_bbox": [98, 603, 399, 636]}, {"image_id": 7, "file_name": "266_07.png", "page": 7, "dpi": 300, "bbox": [101, 112, 731, 442], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Registration of partial scans: In this example, four partial scans are registered into a combined model.", "caption_bbox": [132, 449, 696, 467]}, {"image_id": 8, "file_name": "266_08.png", "page": 9, "dpi": 300, "bbox": [106, 375, 724, 552], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Color matching of the Accident Victim dataset: (a) Image with reference colors. (b) Image with yellow color cast that needs to be corrected. (c) Image with new matched colors. ", "caption_bbox": [98, 557, 730, 590]}, {"image_id": 9, "file_name": "266_09.png", "page": 9, "dpi": 300, "bbox": [106, 112, 728, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: (a) Octree leaf block resolutions in left cheek area with 5mm resolution, and (b) 20mm resolution. (c) Filtering and data correction of the head of the Mannequin dataset: The positions of the data points are smoothed. (d) Color values of the data points are corrected based on a median filter. ", "caption_bbox": [98, 321, 730, 369]}], "267": [{"image_id": 0, "file_name": "267_00.png", "page": 3, "dpi": 300, "bbox": [113, 111, 387, 386], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Flowchart of the complete process using the geometric (I) or the diffusion approach (II). ", "caption_bbox": [98, 391, 398, 422]}, {"image_id": 1, "file_name": "267_01.png", "page": 5, "dpi": 300, "bbox": [128, 112, 371, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Cross section of a 3D distance volume (geometric ap- proach) with some equidistant isodistance surfaces. The bold white line marks the isodistance surface S(d \u2217 ). ", "caption_bbox": [98, 265, 399, 310]}, {"image_id": 2, "file_name": "267_02.png", "page": 6, "dpi": 300, "bbox": [98, 119, 729, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Cross sections of a 150\u00d7252\u00d7120 8 bit medical ultrasound data set of a breast lesion (Fig.3(a)) and its soft segmentation. The lesion is sharply defined mostly in the lower central region. Its border is indistinct in the right and very left region. Soft segmentation appropriately handles the fuzziness of the data, see Fig.3(b) and 3(c). ", "caption_bbox": [98, 271, 731, 316]}, {"image_id": 3, "file_name": "267_03.png", "page": 7, "dpi": 300, "bbox": [98, 365, 733, 587], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Renderings of soft segmentation results (bottom row) on different ultrasound data sets and comparison with simpler visualization techniques (top row). ", "caption_bbox": [98, 596, 730, 627]}], "268": [{"image_id": 0, "file_name": "268_00.png", "page": 2, "dpi": 300, "bbox": [98, 111, 401, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Color-coded T2 map of the articular cartilage with three locations of T2 profiles (white lines). ", "caption_bbox": [98, 299, 399, 329]}, {"image_id": 1, "file_name": "268_01.png", "page": 3, "dpi": 300, "bbox": [102, 115, 398, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Four types of time-signal profiles for DCE-MRI mammography (courtesy of Coto et al. [CGB\u2217 05]). ", "caption_bbox": [98, 391, 399, 419]}, {"image_id": 2, "file_name": "268_02.png", "page": 3, "dpi": 300, "bbox": [450, 333, 732, 650], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Profile Flag: a tool for probing of pro- files [MEV\u2217 05]. ", "caption_bbox": [430, 662, 731, 690]}, {"image_id": 3, "file_name": "268_03.png", "page": 4, "dpi": 300, "bbox": [106, 111, 725, 417], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Different approaches to visualize the thickness of the underlying tissue: (a) thin cartilage = low range selector, (b) thick cartilage = high range selector and (c) spherical marker on the flagpole. ", "caption_bbox": [98, 425, 731, 453]}, {"image_id": 4, "file_name": "268_04.png", "page": 5, "dpi": 300, "bbox": [98, 111, 401, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The cutting plane can be moved along its normal within the range of selected locations. ", "caption_bbox": [98, 339, 399, 367]}, {"image_id": 5, "file_name": "268_05.png", "page": 5, "dpi": 300, "bbox": [438, 111, 725, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Profile Flag showing selection of profiles accord- ing to a certain criteria: (a) spatial-difference, (b) curve- difference. ", "caption_bbox": [430, 336, 731, 380]}, {"image_id": 6, "file_name": "268_06.png", "page": 7, "dpi": 300, "bbox": [104, 113, 396, 468], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Extension of the Profile Flags for measurement of time-signal profiles. ", "caption_bbox": [98, 487, 399, 515]}, {"image_id": 7, "file_name": "268_07.png", "page": 7, "dpi": 300, "bbox": [430, 111, 733, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Cartilage lesion annotated by a Profile Flag.", "caption_bbox": [442, 350, 719, 363]}, {"image_id": 8, "file_name": "268_08.png", "page": 8, "dpi": 300, "bbox": [98, 111, 401, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Two time-signal profiles annotated by Profile Flags: a healthy profile (left) and a malignant profile (right). ", "caption_bbox": [98, 394, 399, 422]}], "269": [{"image_id": 0, "file_name": "269_00.png", "page": 1, "dpi": 300, "bbox": [447, 738, 717, 873], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Traditional medical illustrations using contex- tual close-up view technique depicting internal features with full context still visible. Illustrations printed with permis- sion: Copyright Fairman Studios, LLC 2005. http://www. fairmanstudios.com ", "caption_bbox": [430, 883, 731, 956]}, {"image_id": 1, "file_name": "269_01.png", "page": 2, "dpi": 300, "bbox": [98, 113, 400, 368], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Seven stages of our volume rendering pipeline.", "caption_bbox": [105, 381, 392, 394]}, {"image_id": 2, "file_name": "269_02.png", "page": 4, "dpi": 300, "bbox": [430, 156, 735, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A close-up view of a baby skull. (Left) low resolu- tion volume used during user interaction. (Middle) the orig- inal resolution volume used upon cessation of user interac- tion. (Right) the super-resolution volume used in the ROI. ", "caption_bbox": [430, 272, 731, 331]}, {"image_id": 3, "file_name": "269_03.png", "page": 5, "dpi": 300, "bbox": [98, 111, 402, 215], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Different levels of smoothness at the super- resolution ROI. (Left) no subdivision, (middle) order 3 and (right) order 4 subdivisions. ", "caption_bbox": [98, 226, 399, 270]}, {"image_id": 4, "file_name": "269_04.png", "page": 5, "dpi": 300, "bbox": [430, 111, 744, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) The gradient and index lookup tables con- structed after algorithm QuantizeGradient(). (b) The gradi- ent lookup table format, where a quantized gradient can be accessed via an index or an arbitrary vector (V~1 and V                                                       ~2 in the figure). ", "caption_bbox": [430, 341, 731, 415]}, {"image_id": 5, "file_name": "269_05.png", "page": 6, "dpi": 300, "bbox": [117, 295, 382, 411], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: For each voxel in the 3D texture, the silhouette or shading intensity is indexed via a texture indirection. Only the small 2D intensity texture is updated with each view change. The gradient magnitude |\u2206| is used for other trans- fer functions. ", "caption_bbox": [98, 422, 399, 496]}, {"image_id": 6, "file_name": "269_06.png", "page": 7, "dpi": 300, "bbox": [113, 299, 718, 497], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Contextual close-up with circular and rectangular ROIs: MRI of brain with maximum intensity projection; CT of foot joints. ", "caption_bbox": [98, 508, 731, 536]}, {"image_id": 7, "file_name": "269_07.png", "page": 9, "dpi": 300, "bbox": [98, 111, 733, 470], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (Color Plate) Contextual close-up with circular and rectangular ROIs: cerebral blood flow CT angiogram with contrast agent; MRI of liver with maximum intensity projection; CT scan of an anterior tibial osteotomy knee dataset; CT chest dataset with inside of rib cage; CT angiogram of the neck showing contrast-enhanced blood vessels of the right carotid artery and jugular vein. ", "caption_bbox": [98, 481, 731, 540]}], "270": [{"image_id": 0, "file_name": "270_00.png", "page": 2, "dpi": 300, "bbox": [433, 320, 722, 607], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Dynamic memory allocation visualization", "caption_bbox": [447, 606, 709, 627]}, {"image_id": 1, "file_name": "270_01.png", "page": 3, "dpi": 300, "bbox": [116, 349, 382, 838], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Importance-based antialiasing for memory log", "caption_bbox": [103, 838, 389, 859]}, {"image_id": 2, "file_name": "270_02.png", "page": 4, "dpi": 300, "bbox": [109, 859, 379, 970], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "     tsB  teA Figure 4: D ", "caption_bbox": [147, 969, 209, 996]}, {"image_id": 3, "file_name": "270_03.png", "page": 4, "dpi": 300, "bbox": [95, 131, 731, 551], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Importance-based antialiasing for the software evolution log", "caption_bbox": [234, 552, 590, 573]}, {"image_id": 4, "file_name": "270_04.png", "page": 5, "dpi": 300, "bbox": [448, 336, 707, 596], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Interleaved cushions", "caption_bbox": [500, 597, 657, 618]}, {"image_id": 5, "file_name": "270_05.png", "page": 6, "dpi": 300, "bbox": [95, 134, 731, 728], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Hierarchical visualization. Memory log, compact metric (a-c) and occupancy evolution (d). Repository log, compact", "caption_bbox": [96, 732, 728, 753]}, {"image_id": 6, "file_name": "270_06.png", "page": 7, "dpi": 300, "bbox": [96, 137, 731, 653], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Bins and heap occupancy visualization for the dynamic memory allocator log", "caption_bbox": [192, 654, 632, 675]}], "271": [{"image_id": 0, "file_name": "271_00.png", "page": 2, "dpi": 300, "bbox": [433, 307, 723, 542], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Price chart illustrating a technology fund during the \u2019dot-com\u2019 crisis. The common statistical measures for 5- year, 3-year and 1-year performance (see table) fail to rec- ognize the peak in the year 2000 because the peak is com- pletely situated between the corresponding time intervals. If the reference point for the time of sale is shifted for only a short period of time (see red colored time intervals), the performance measures return completely different values al- though most of the chart is identical. ", "caption_bbox": [428, 553, 729, 688]}, {"image_id": 1, "file_name": "271_01.png", "page": 3, "dpi": 300, "bbox": [412, 104, 730, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: For generating visual insight into the performance values of all time intervals, we use a rectangular pixel-based model and compute the statistical performance for all possi- ble combinations of holding periods [h_max \u2212 h_min, 60 by default] and times of sale [s_max \u2212 s_min, 100 by default]. ", "caption_bbox": [428, 344, 729, 418]}, {"image_id": 2, "file_name": "271_02.png", "page": 4, "dpi": 300, "bbox": [96, 104, 724, 431], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Two examples of our visualization technique. (a) shows a technology fund during the \u2019dot-com\u2019 crisis in 2000, (b) shows an asian market asset. As can be seen from left example, each pixel in our Performance Matrix can be mapped onto a time of sale and holding period in the chart above. Furthermore, each asset generates a unique fingerprint that reveals its special characteristics. When grouped to market sectors, assets in the same market show similar characteristics. ", "caption_bbox": [96, 444, 729, 503]}, {"image_id": 3, "file_name": "271_03.png", "page": 5, "dpi": 300, "bbox": [101, 219, 397, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The Weight Matrix WM shows the weights of all 6000 parameters, using a constant function for the relevance of the time of sale, and a Gauss function for the relevance of the holding period. The region of interest is set to a hold- ing period of 3 years. The variance of the Gauss function controls the weight for holding periods longer and shorter than 3 years, which in the example still have a considerable weight. ", "caption_bbox": [96, 373, 397, 493]}, {"image_id": 4, "file_name": "271_04.png", "page": 5, "dpi": 300, "bbox": [412, 104, 730, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: In contrast to the previous Weight Matrix, the Gauss function for the holding time in this Weight Matrix is characterized by a smaller variance, narrowing down the re- gion of interest for a holding time close to 3 years. The con- stant relevance function for the time of sale from the previ- ous image is now replaced by a wide Gauss function that in- creases with the recentness of time of sale, therefore putting emphasis on times of sale short ago. ", "caption_bbox": [428, 350, 729, 470]}, {"image_id": 5, "file_name": "271_05.png", "page": 6, "dpi": 300, "bbox": [96, 104, 415, 344], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: This Weight Matrix uses a more complex set of relevance functions with two regions of interest for the hold- ing time, and exemplarily demonstrates the computation of the element W Mn (2002, 2.5Years). The values from both rel- evance functions (2.2 \u00b7 21.8 = 47.48) are multiplied, and as a result the corresponding color from the gray scale color bar is taken. The maximum weight corresponds to the mul- tiplication of the peak of RSale,n with the peak of RHolding,n where n denotes the normalization of the relevance functions to min(R) = 1. Therefore the minimum value of a Weight Ma- trix element min(W Mn (s, h)) is 1. ", "caption_bbox": [96, 368, 397, 534]}, {"image_id": 6, "file_name": "271_06.png", "page": 6, "dpi": 300, "bbox": [412, 105, 722, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Weighted Performance Matrix of the \u2019Baring Hong Kong China USD\u2019 fund from Figure 4(b) after ap- plying the Weight Matrix from Figure 6. Unimportant areas outside the region of interest are faded out, whereas the sat- uration of important areas is increased to create a spotlight effect. According to the Weight Matrix, short time volatility next to the x-axis for holding periods shorter than a year are faded out nearly completely, as the investors are interested in the performance of this asset for a holding time of 3 years. ", "caption_bbox": [428, 341, 729, 476]}, {"image_id": 7, "file_name": "271_07.png", "page": 7, "dpi": 300, "bbox": [412, 104, 730, 390], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The Dominance Plot visualizes the distribution of performance and risk values for a sample set of 392 assets from our database, for the user-specified Weight Matrix dis- played in the upper middle of the image. The color of an as- set denotes to the number of bonds by which it is dominated. The selected asset in the middle, in this case the \"Naspa- Fonds\", divides the image into four sectors corresponding to the possible relationship of an asset. 183 assets with higher performance and lower risk (upper left sector) dominate the \"Naspa-Fonds\". ", "caption_bbox": [428, 404, 729, 554]}, {"image_id": 8, "file_name": "271_08.png", "page": 8, "dpi": 300, "bbox": [96, 104, 725, 389], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Assets that are not dominated by any other asset have in common that no second asset exists that offers a higher performance with a lower or identical risk. These assets form the Pareto efficiency frontier. It can be observed that the most efficient assets have low risk and low performance values, and look visually similar. By emphasizing the regions of interest in the icons, the investor has an instant overview of the development of an asset over time. For the given relevance matrix, we have a total of 12 assets that are not dominated by any other asset. Note that the Performance Matrices also provide a detailed view of the risk distribution for each asset (increasingly red regions from left to right). ", "caption_bbox": [96, 403, 729, 492]}], "272": [{"image_id": 0, "file_name": "272_00.png", "page": 2, "dpi": 300, "bbox": [452, 374, 689, 482], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A single-peaked DOI profile applied on a spreadsheet (taken from RC95). ", "caption_bbox": [437, 493, 713, 518]}, {"image_id": 1, "file_name": "272_01.png", "page": 4, "dpi": 300, "bbox": [91, 673, 390, 777], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparison of multiple time series along three resolution levels. The chart shows the continuous CPU utilization history (3 days = 864 values) of 8 different computing hosts. The color map assigns shades of green (low) to red (high) CPU utilization. Overall, there is little correlation between the servers\u2019 utilization profiles, leading us to conclude that these operate independently of each other (they are not pooled in a load-balancing configuration). The overall utilization level is rather low (green), except for one high utilization period of medium duration for server pepsedeapp24 (2nd from below) and one high utilization period of long duration for server pepdpepdc03 (1 st from above). ", "caption_bbox": [102, 787, 385, 946]}, {"image_id": 2, "file_name": "272_02.png", "page": 5, "dpi": 300, "bbox": [104, 736, 366, 887], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: DOI extraction from raw time series by determining the interestingness score over the time series for a number of bins N, followed by (optional) merging of bins with similar interestingness scores. ", "caption_bbox": [89, 897, 388, 946]}, {"image_id": 3, "file_name": "272_03.png", "page": 5, "dpi": 300, "bbox": [446, 736, 684, 851], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Mapping the generated DOI profile to a corresponding multiresolution layout using the color-coded matrix display visualization. The DOI profile determines the data partitioning, while the transfer function maps the data intervals to screen partitions. Implicitly, this also reflects the level of resolution of the partitions via the matrix dimensionality (cell sizes). ", "caption_bbox": [423, 869, 722, 955]}, {"image_id": 4, "file_name": "272_04.png", "page": 6, "dpi": 300, "bbox": [83, 280, 741, 508], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Showing four variable time-series results for exchange rate returns out of 12 International currencies measured against US-$ using MAXIMUM aggregation function and independent DOI analysis for each time series. ", "caption_bbox": [99, 512, 735, 543]}, {"image_id": 5, "file_name": "272_05.png", "page": 6, "dpi": 300, "bbox": [87, 104, 742, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Two series of CPU utilization measures in a fixed time-slice multi-resolution layout (FTS). The time slice was set to 2 hours. The DOI profile was generated using the AVERAGE aggregation function analyzing both time series. ", "caption_bbox": [93, 250, 720, 275]}, {"image_id": 6, "file_name": "272_06.png", "page": 7, "dpi": 300, "bbox": [66, 767, 731, 940], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Visualization of 28 days worth of CPU utilization probes from one server resulting in 7776 observation values. From top- left to bottom-right is given (1) the raw data showing overplotting artefacts, (2) sampled data, (3) averaged data (both loosing detail), and (4) the color-coded matrix display representing the whole information. Users can zoom to a detailed line chart. ", "caption_bbox": [77, 940, 726, 981]}], "273": [{"image_id": 0, "file_name": "273_00.png", "page": 2, "dpi": 300, "bbox": [412, 105, 718, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Displaying the changes within two sequences of data values, (a) and (d), using polygons ((c) and (f)) rather than displaying the values at each time step using lines ((b) and (e)). Opacity is used to convey the number of overlap- ping changes occurring over time, from highly transparent (few overlaps) to fully opaque (many overlaps). ", "caption_bbox": [428, 389, 729, 478]}, {"image_id": 1, "file_name": "273_01.png", "page": 3, "dpi": 300, "bbox": [139, 104, 730, 279], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visualizing changes between consecutive time steps. As the value of x changes over time, new polygons are rendered to produce a density map. ", "caption_bbox": [96, 291, 729, 319]}, {"image_id": 2, "file_name": "273_02.png", "page": 3, "dpi": 300, "bbox": [507, 356, 634, 520], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A \u2018twisted polygon\u2019 is used to convey a simultane- ous negative and positive change in two adjacent axes. ", "caption_bbox": [428, 531, 729, 559]}, {"image_id": 3, "file_name": "273_03.png", "page": 4, "dpi": 300, "bbox": [96, 104, 415, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: TDPC is used to explore the density over time. (a) a TF (\u03b3 = 1) is used to map density values to opacity. (b) a different TF (\u03b3 = 0.4) is used to emphasize low density regions. ", "caption_bbox": [96, 288, 397, 347]}, {"image_id": 4, "file_name": "273_04.png", "page": 4, "dpi": 300, "bbox": [412, 105, 702, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Results of using DCPC. A single hue is used and saturation and value are decreased for older changes. In (a) the data is viewed from the end of the time period. In (b) it is viewed from the beginning. ", "caption_bbox": [428, 288, 729, 347]}, {"image_id": 5, "file_name": "273_05.png", "page": 6, "dpi": 300, "bbox": [101, 649, 725, 764], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: TDPC and DCPC ((c)\u2013(g)) are used to interactively visualize a large, time-varying multivariate data set containing six variables and 100 data items at each of 500 time steps. The amount of change as well as where in time they occur are revealed. ", "caption_bbox": [96, 776, 729, 819]}, {"image_id": 6, "file_name": "273_06.png", "page": 7, "dpi": 300, "bbox": [124, 104, 730, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The effect of rendering lines (top row) versus polygons (bottom row) when the size of changes between time steps increase. For small changes the visual difference between rendering lines and polygons is small (figure 7(a)). For extremely large temporal changes a polygon-based rendering is advantageous since it better preserves structures (figure 7(d)). ", "caption_bbox": [96, 329, 729, 372]}], "274": [{"image_id": 0, "file_name": "274_00.png", "page": 2, "dpi": 300, "bbox": [471, 232, 688, 403], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Mapping of key locations.", "caption_bbox": [487, 411, 670, 424]}, {"image_id": 1, "file_name": "274_01.png", "page": 3, "dpi": 300, "bbox": [412, 104, 731, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A painted message showing the combination of all message pattern representations. ", "caption_bbox": [428, 328, 729, 356]}, {"image_id": 2, "file_name": "274_02.png", "page": 4, "dpi": 300, "bbox": [96, 332, 399, 451], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Two different colour themes that can be selected.", "caption_bbox": [98, 457, 395, 470]}, {"image_id": 3, "file_name": "274_03.png", "page": 5, "dpi": 300, "bbox": [428, 447, 731, 627], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Answer frequencies to Questions 3 and 4.", "caption_bbox": [448, 632, 708, 645]}], "275": [{"image_id": 0, "file_name": "275_00.png", "page": 2, "dpi": 300, "bbox": [96, 104, 676, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A speech recognition lattice for which the statistically-identified best path is not the best transcription. The best path according to the model is shown in green. Node uncertainty is represented by position, fill hue, and edge transparency gradient. Edges attached to the node under the mouse pointer are coloured gold. ", "caption_bbox": [96, 372, 729, 416]}, {"image_id": 1, "file_name": "275_01.png", "page": 4, "dpi": 300, "bbox": [412, 105, 727, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Layout construction: (A) rigid grid-based lattice, (B) force-directed layout, (C) hybrid layout. The hybrid lay- out provides the regularity benefit of the grid-based layout and the overlap avoidance of the force-directed layout. ", "caption_bbox": [428, 451, 729, 510]}, {"image_id": 2, "file_name": "275_02.png", "page": 5, "dpi": 300, "bbox": [143, 138, 682, 225], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Two alternative encodings of uncertainty. The top, \u201cbubble border\u201d, uses border thickness, hue, and transparency to convey uncertainty: tight, solid blue borders have a higher certainty. The bottom, \u201cgradient border\u201d, uses blurring of the edges through a gradient and variable transparency: more solid borders have higher certainty. Both variations also use hue variation from bright blue (high certainty) to gray-blue (low certainty). ", "caption_bbox": [96, 246, 729, 305]}, {"image_id": 3, "file_name": "275_03.png", "page": 5, "dpi": 300, "bbox": [96, 325, 398, 454], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Lattice from Figure 1 with best path corrected.", "caption_bbox": [105, 471, 388, 484]}, {"image_id": 4, "file_name": "275_04.png", "page": 6, "dpi": 300, "bbox": [96, 104, 668, 440], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Translation uncertainty visualization in a chat interface: upper panel records chat history in the language of the local conversant, lower panel displays the visualization of the most recently received message. Translations of low confidence are also augmented with representative pictures collected from the Internet. ", "caption_bbox": [96, 453, 729, 497]}, {"image_id": 5, "file_name": "275_05.png", "page": 7, "dpi": 300, "bbox": [141, 141, 684, 320], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Translation lattice for the German sentence, \u201cHallo, ich bin gerade auf einer Konferenz im Nationalpark in Banff.\u201d The statistically-identified best path (along the bottom) was incorrect and has been repaired. Photo nodes provide an alternative representation for words not in the translation vocabulary. Mouse over expands the node and reveals four photos, while other nodes move away to avoid occlusion. ", "caption_bbox": [96, 341, 729, 400]}, {"image_id": 6, "file_name": "275_06.png", "page": 8, "dpi": 300, "bbox": [96, 104, 415, 526], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Speech recognition lattices often have localized ar- eas of high uncertainty. ", "caption_bbox": [96, 540, 397, 568]}], "276": [{"image_id": 0, "file_name": "276_00.png", "page": 2, "dpi": 300, "bbox": [95, 103, 415, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: DAG visualization of a clustering.", "caption_bbox": [135, 260, 358, 273]}, {"image_id": 1, "file_name": "276_01.png", "page": 4, "dpi": 300, "bbox": [96, 103, 415, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: quad-tree test to approximate boundary", "caption_bbox": [121, 314, 372, 327]}, {"image_id": 2, "file_name": "276_02.png", "page": 5, "dpi": 300, "bbox": [119, 104, 415, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Addition of an entity to a blob.", "caption_bbox": [143, 316, 349, 329]}, {"image_id": 3, "file_name": "276_03.png", "page": 5, "dpi": 300, "bbox": [412, 103, 730, 546], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Grouping of multiple entities.", "caption_bbox": [478, 559, 678, 572]}, {"image_id": 4, "file_name": "276_04.png", "page": 5, "dpi": 300, "bbox": [170, 351, 314, 612], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Removal of an entity from a blob.", "caption_bbox": [136, 625, 356, 638]}, {"image_id": 5, "file_name": "276_05.png", "page": 6, "dpi": 300, "bbox": [96, 103, 619, 597], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (1) BubbleClusers\u2019 grouping technique was used to create this initial clustering to some randomly created gene names. (2) An entity has been pushed inside a cluster. (3) An entity has been pulled outside a cluster. ", "caption_bbox": [96, 610, 729, 638]}, {"image_id": 6, "file_name": "276_06.png", "page": 7, "dpi": 300, "bbox": [229, 103, 730, 460], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The complexity \u201cBubbleClusters\u201d can handle. The shown dataset is a randomly selected part of a real world dataset of a correlation analysis of genes. It consists of 78 entities and 24 clusters. On average each entity is part of 4 clusters. ", "caption_bbox": [96, 470, 729, 498]}], "277": [{"image_id": 0, "file_name": "277_00.png", "page": 3, "dpi": 300, "bbox": [142, 103, 731, 567], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The Grouse interface has two linked views, showing the selected node in both in red. On the left, all metanodes and leaves in the graph hierarchy in the tree view. On the right, the graph view shows closed metanodes on the cut with hexagons, and the open metanodes above them in the hierarchy as circles. The hierarchy structure is shown in the graph view by containment within nested circles, while graph structure is shown with connecting edges and metaedges. Metanodes are colored by the feature they contain, with leaves shown as grey boxes. ", "caption_bbox": [96, 577, 729, 651]}, {"image_id": 1, "file_name": "277_01.png", "page": 5, "dpi": 300, "bbox": [110, 103, 730, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Example of the computations made when changing the cut by opening a metanode. Open nodes are white, cut nodes are grey, and hidden nodes are black. (a) The initial cut shown in the context of the whole hierarchy. It has open metanodes A, C, and F. Metanodes B and G are in the cut, as are the leaves below F. The metanodes D and E are hidden, as are their leaves. (b) The initial cut as shown in the graph view. (c) After the selection, metanode B changes from cut to open and the two formerly hidden metanodes D and E become cut metanodes. The subgraph containing D and E is laid out and the size of B is updated. (d) The subgraph inside A is laid out, and the size of A is updated. (e) The metaedge to B is deleted and two edges to D and E are added. (f) The final cut, as a tree. The animated transition seen by the user is a linear interpolation between views (b) and (e). The intermediate stages of computation are not visible to the user. ", "caption_bbox": [96, 269, 729, 389]}, {"image_id": 2, "file_name": "277_02.png", "page": 7, "dpi": 300, "bbox": [126, 104, 415, 667], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: We compare the number of levels of the hierarchy that can be seen at once. With scaling (a), it is difficult to see deep into the hierarchy. Using relayout (b), more levels are distinguishable. The dataset is a subset of IMDB of 1,181 nodes and 31,527 edges centered around Jake Gyllenhaal. ", "caption_bbox": [96, 680, 397, 754]}, {"image_id": 3, "file_name": "277_03.png", "page": 8, "dpi": 300, "bbox": [216, 670, 609, 895], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A comparison of information density using force-directed layout with feature-based layout. (a) In the force-directed case, the leaf nodes in the cyan clique are so spread apart that they are tiny. (b) With feature-based layout, the clique leaves are far larger, as are the blue cut metanodes representing trees in the open metanode at the center. ", "caption_bbox": [96, 908, 729, 952]}, {"image_id": 4, "file_name": "277_04.png", "page": 8, "dpi": 300, "bbox": [96, 103, 703, 543], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Exploring an IMDB dataset of Sharon Stone movies from 1999, where the full input graph is 7,640 nodes and 277,029 edges. The left column shows snapshots of the graph view as the user explores by opening metanodes. On the right, the final cut includes one small and one large tree. The cyan clique of actors in the movie Anywhere but Here is shown in the inset. Labels have been turned on in the inset view, showing actor names. ", "caption_bbox": [96, 581, 729, 640]}], "278": [{"image_id": 0, "file_name": "278_00.png", "page": 2, "dpi": 300, "bbox": [104, 131, 747, 355], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Snapshots from the threads1 graph sequence, visualizing discussion threads at http://www.dailytech.com, left to right.", "caption_bbox": [96, 357, 728, 378]}, {"image_id": 1, "file_name": "278_01.png", "page": 4, "dpi": 300, "bbox": [430, 180, 728, 434], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Parallel force directed layout algorithm", "caption_bbox": [452, 434, 703, 455]}, {"image_id": 2, "file_name": "278_02.png", "page": 5, "dpi": 300, "bbox": [105, 131, 376, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Partition size effect on layout, graph 4elt, |V | = 15606, |E| = 45878 ", "caption_bbox": [96, 283, 397, 318]}, {"image_id": 3, "file_name": "278_03.png", "page": 6, "dpi": 300, "bbox": [452, 266, 707, 630], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Graph sequence information and running time", "caption_bbox": [428, 782, 729, 803]}, {"image_id": 4, "file_name": "278_04.png", "page": 7, "dpi": 300, "bbox": [110, 131, 716, 516], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Snapshots from the threads2 graph sequence, visualizing discussion threads at http://www.dailytech.com, left to right,", "caption_bbox": [96, 523, 728, 544]}], "279": [{"image_id": 0, "file_name": "279_00.png", "page": 2, "dpi": 300, "bbox": [435, 138, 727, 446], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Patterns of Adjacency Matrices", "caption_bbox": [473, 453, 683, 474]}, {"image_id": 1, "file_name": "279_01.png", "page": 3, "dpi": 300, "bbox": [140, 357, 354, 466], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Comparison of a Path in an Adjacency Matrix and", "caption_bbox": [96, 471, 397, 492]}, {"image_id": 2, "file_name": "279_02.png", "page": 4, "dpi": 300, "bbox": [432, 138, 730, 524], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Path Crossing Problem. In (a), ambiguities exist at", "caption_bbox": [428, 531, 729, 552]}, {"image_id": 3, "file_name": "279_03.png", "page": 4, "dpi": 300, "bbox": [146, 131, 351, 969], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Path Layout in Adjacency Matrices", "caption_bbox": [132, 976, 361, 997]}, {"image_id": 4, "file_name": "279_04.png", "page": 5, "dpi": 300, "bbox": [443, 454, 714, 658], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A Part of the Metro Map of Koln, Germany.", "caption_bbox": [443, 663, 713, 684]}, {"image_id": 5, "file_name": "279_05.png", "page": 5, "dpi": 300, "bbox": [103, 138, 395, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Rendering Options for Path Visualization. (a)", "caption_bbox": [96, 326, 397, 347]}, {"image_id": 6, "file_name": "279_06.png", "page": 5, "dpi": 300, "bbox": [472, 131, 686, 375], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualization of Multiple Paths Using the Ap-", "caption_bbox": [428, 379, 729, 400]}, {"image_id": 7, "file_name": "279_07.png", "page": 6, "dpi": 300, "bbox": [127, 138, 703, 424], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Multiple Path Visualization", "caption_bbox": [318, 431, 507, 452]}, {"image_id": 8, "file_name": "279_08.png", "page": 7, "dpi": 300, "bbox": [96, 504, 683, 818], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Comparison of the Energy Flow in Food Webs of Chesapeake Bay and Lake Michigan.", "caption_bbox": [165, 824, 655, 845]}, {"image_id": 9, "file_name": "279_09.png", "page": 7, "dpi": 300, "bbox": [148, 137, 682, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Friendship Network of a Hi-Tech Firm.", "caption_bbox": [288, 469, 536, 490]}, {"image_id": 10, "file_name": "279_10.png", "page": 8, "dpi": 300, "bbox": [125, 131, 367, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Food Web of Chesapeake Bay. The highlighted", "caption_bbox": [96, 392, 397, 413]}], "280": [{"image_id": 0, "file_name": "280_00.png", "page": 3, "dpi": 300, "bbox": [412, 104, 730, 402], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The visualization story model. This figure shows the elements of our story model and how they relate to each other to form a short sample story. Story nodes are connected through story transitions. Story transitions consist of one or multiple sequential story action groups. Story action atoms store the atomic visualization changes. ", "caption_bbox": [428, 413, 729, 502]}, {"image_id": 1, "file_name": "280_01.png", "page": 4, "dpi": 300, "bbox": [96, 104, 415, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Annotation possibilities. This figure shows anno- tation styles available in our prototype. General text annota- tion (bottom). Feature-specific annotation (top). ", "caption_bbox": [96, 321, 397, 365]}, {"image_id": 2, "file_name": "280_02.png", "page": 5, "dpi": 300, "bbox": [412, 104, 730, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Storytelling and interaction This figure shows in- stances of the possible interaction schemes. Non-interactive story consumption (yellow). Story playback with interactive approval during a halt at a story node affecting representa- tion parameters (red). Interactive visualization during story playback affecting viewing only (green). Total uncoupling from story guidance (blue). ", "caption_bbox": [428, 360, 729, 465]}, {"image_id": 3, "file_name": "280_03.png", "page": 6, "dpi": 300, "bbox": [96, 104, 415, 320], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Interactive story authoring. This figure shows, how interactive story authoring works. The user navigates to a position in the story (1). The visualization is changed ac- cordingly (2). The user changes the viewing angle (3). User interaction is recorded and incorporated into the story as a new story action group (4). ", "caption_bbox": [96, 331, 397, 420]}, {"image_id": 4, "file_name": "280_04.png", "page": 7, "dpi": 300, "bbox": [412, 104, 730, 808], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visualization story example. A sample visualiza- tion story from our application prototype, based on a human pelvis CT-dataset. ", "caption_bbox": [428, 821, 729, 865]}, {"image_id": 5, "file_name": "280_05.png", "page": 7, "dpi": 300, "bbox": [97, 105, 415, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The storytelling prototype application The scene tree view is used to import data, derive data subsets and cre- ate visual data representations (1). Below are the parameter controls for the active data representation (2). The naviga- tional controls influence story playback as well as story cou- pling (3). The story tree view shows the atomic visualization changes at the current story position (4). The story outline view gives an overview of the story plot (5). ", "caption_bbox": [96, 323, 397, 443]}], "281": [{"image_id": 0, "file_name": "281_00.png", "page": 2, "dpi": 300, "bbox": [110, 441, 384, 776], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The proposed visual data mining system.", "caption_bbox": [118, 787, 374, 800]}, {"image_id": 1, "file_name": "281_01.png", "page": 4, "dpi": 300, "bbox": [487, 750, 671, 933], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of the auto-stereoscopic monitor dis- playing our 3D visualization environment. ", "caption_bbox": [428, 944, 729, 972]}, {"image_id": 2, "file_name": "281_02.png", "page": 5, "dpi": 300, "bbox": [110, 331, 384, 683], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: 2D Tablet PC interface.", "caption_bbox": [160, 693, 332, 706]}, {"image_id": 3, "file_name": "281_03.png", "page": 5, "dpi": 300, "bbox": [443, 363, 716, 582], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: 3D document corpus overview and working desk.", "caption_bbox": [429, 593, 728, 606]}, {"image_id": 4, "file_name": "281_04.png", "page": 6, "dpi": 300, "bbox": [110, 328, 384, 548], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Browsing a stack of the virtual workdesk.", "caption_bbox": [116, 559, 375, 572]}], "282": [{"image_id": 0, "file_name": "282_00.png", "page": 1, "dpi": 300, "bbox": [412, 371, 731, 812], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: TrustNeighborhood visualization for a net- work of 2000 hosts. ", "caption_bbox": [428, 823, 729, 851]}, {"image_id": 1, "file_name": "282_01.png", "page": 3, "dpi": 300, "bbox": [427, 127, 731, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Prototype implementation with 2000 files.", "caption_bbox": [430, 375, 727, 388]}, {"image_id": 2, "file_name": "282_02.png", "page": 5, "dpi": 300, "bbox": [100, 128, 396, 167], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Trust scale with four societies at 0.5 inter- vals. ", "caption_bbox": [96, 178, 397, 206]}, {"image_id": 3, "file_name": "282_03.png", "page": 6, "dpi": 300, "bbox": [96, 127, 399, 222], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Subjective rankings.", "caption_bbox": [494, 332, 662, 345]}, {"image_id": 4, "file_name": "282_04.png", "page": 7, "dpi": 300, "bbox": [95, 127, 399, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Mockup of a TrustNeighborhood view run- ning in the background of a UNIX graphical file ex- plorer. (Note that this is a composite screenshot.) ", "caption_bbox": [96, 352, 397, 395]}], "283": [{"image_id": 0, "file_name": "283_00.png", "page": 4, "dpi": 300, "bbox": [430, 134, 729, 231], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Typical line patterns that could be shown in par-", "caption_bbox": [428, 240, 729, 261]}, {"image_id": 1, "file_name": "283_01.png", "page": 4, "dpi": 300, "bbox": [477, 358, 681, 485], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The magenta and cyan TF widgets are defined to", "caption_bbox": [428, 494, 729, 515]}, {"image_id": 2, "file_name": "283_02.png", "page": 6, "dpi": 300, "bbox": [96, 137, 730, 453], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visualization of the combustion dataset to find negative spatial correlation between variables \u03c7 and OH near the", "caption_bbox": [96, 455, 728, 476]}, {"image_id": 3, "file_name": "283_03.png", "page": 8, "dpi": 300, "bbox": [86, 182, 738, 553], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Exploration of the hurricane dataset to find correlation between cloud, wind speed, vapor and pressure. Three", "caption_bbox": [96, 555, 728, 576]}], "284": [{"image_id": 0, "file_name": "284_00.png", "page": 3, "dpi": 300, "bbox": [494, 357, 661, 522], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A projection plane that maps (x, y) to x \u2212 y, which can be used to study the difference between two feature val- ues directly. ", "caption_bbox": [428, 527, 729, 571]}, {"image_id": 1, "file_name": "284_01.png", "page": 4, "dpi": 300, "bbox": [412, 103, 699, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Two clusters of points separated by a single fea- ture. The separation can be easily found by moving the axis (red) corresponding to the separating feature. After moving the axis (right), the separating clusters can be distinguished ", "caption_bbox": [428, 293, 729, 352]}, {"image_id": 2, "file_name": "284_02.png", "page": 4, "dpi": 300, "bbox": [96, 101, 415, 389], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The four view components: histogram, scatterplot, slice-viewer and pseudo-color slice-viewer. ", "caption_bbox": [96, 398, 397, 426]}, {"image_id": 3, "file_name": "284_03.png", "page": 5, "dpi": 300, "bbox": [156, 723, 336, 846], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A histogram linked to a scatterplot. The histogram uses the Y coordinates of the projected points in the scatter- plot as a source. ", "caption_bbox": [96, 849, 397, 893]}, {"image_id": 4, "file_name": "284_04.png", "page": 6, "dpi": 300, "bbox": [125, 422, 369, 715], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Top: The interface during a user session. Bottom: The component grid, where red arrows indicate the coupling between components. ", "caption_bbox": [96, 718, 397, 762]}, {"image_id": 5, "file_name": "284_05.png", "page": 7, "dpi": 300, "bbox": [99, 426, 392, 566], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A shows the initial selection created through brushing in the slice-viewer. Red represents contrast liquid, green represents gas and blue marks tissue. B shows a de- tail of the expanded selection through application of the kNN classification process, note that the boundary is not correctly classified. ", "caption_bbox": [96, 571, 397, 660]}, {"image_id": 6, "file_name": "284_06.png", "page": 7, "dpi": 300, "bbox": [435, 337, 720, 454], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Expanded selection through application of the kNN classification process on the feature space that was ex- panded with the derived LH feature. ", "caption_bbox": [428, 457, 729, 501]}, {"image_id": 7, "file_name": "284_07.png", "page": 7, "dpi": 300, "bbox": [95, 103, 415, 363], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The gridded 2 \u00d7 2 layout of the user interface with the CT dataset loaded. From top left to bottom right: his- togram, slice view, scatter plot, color slice view ", "caption_bbox": [96, 381, 397, 425]}, {"image_id": 8, "file_name": "284_08.png", "page": 7, "dpi": 300, "bbox": [412, 101, 731, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Scatterplot showing the distribution of points in LH-space. Horizontal axis is L, vertical is H. ", "caption_bbox": [428, 307, 729, 335]}], "285": [{"image_id": 0, "file_name": "285_00.png", "page": 4, "dpi": 300, "bbox": [412, 105, 718, 419], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Maps of three-dimensional voxel signatures \u2014 a Kohonen map (a) and a spherical map (b). Scalar value is mapped to red, gradient magnitude to green and directional second derivative to blue. Transfer functions displayed on a Kohonen map (c) and on a spherical map (d). ", "caption_bbox": [428, 427, 729, 501]}, {"image_id": 1, "file_name": "285_01.png", "page": 5, "dpi": 300, "bbox": [104, 105, 415, 347], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visualizations of the tooth data set: a semi- transparent slice blended with the tooth image rendered us- ing a transfer function specified in a 2D space built from a Kohonen map (a); and a fully opaque slice of the tooth col- ored according to voxel coordinates in a spherical map (b). The noisy regions can be clearly seen. The red arrow is the plane normal. ", "caption_bbox": [96, 355, 397, 459]}, {"image_id": 2, "file_name": "285_02.png", "page": 7, "dpi": 300, "bbox": [104, 104, 730, 484], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Size, number of non-background voxels and time (seconds) spent in the dimensional reduction step, using Ko- honen maps and three voxel attributes, for the data sets pre- sented in this paper. ", "caption_bbox": [96, 743, 397, 802]}], "286": [{"image_id": 0, "file_name": "286_00.png", "page": 2, "dpi": 300, "bbox": [412, 104, 639, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Irregular topological configuration that can be easily accommodated by subdivision volumes but not oc- trees. ", "caption_bbox": [426, 262, 727, 306]}, {"image_id": 1, "file_name": "286_01.png", "page": 3, "dpi": 300, "bbox": [412, 104, 728, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Center slice of the 7 \u00d7 7 \u00d7 7 mesh of control ver- tices used to approximate the subdivision kernel. All 73 ver- tices except the center one are assigned a density of 0.0, while the center vertex, drawn in red, is assigned a weight of 1.0. This mesh, after several subdivisions, provides a dis- crete representation of the subdivision basis function. ", "caption_bbox": [426, 248, 727, 341]}, {"image_id": 2, "file_name": "286_02.png", "page": 4, "dpi": 300, "bbox": [94, 104, 415, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Isosurface rendering showing the central region of the MCQ subdivision algorithm\u2019s basis function. ", "caption_bbox": [94, 283, 395, 311]}, {"image_id": 3, "file_name": "286_03.png", "page": 5, "dpi": 300, "bbox": [149, 104, 728, 363], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Function parameters and fitting errors for different spline approximations of the basis function for the MCQ inter- polatory subdivision solid algorithm. MSE = \u201cMean Squared Error,\u201d RMSE = \u201cRoot Mean Squared Error,\u201d MAE = \u201cMean Absolute Error.\u201d ", "caption_bbox": [94, 650, 727, 694]}, {"image_id": 4, "file_name": "286_04.png", "page": 6, "dpi": 300, "bbox": [412, 104, 684, 378], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Resampling scheme used to compute RMSE of models. \u201cSubdivided point\u201d refers to a vertex generated by subdivision. Note that each control point has one RBF asso- ciated with it. ", "caption_bbox": [426, 388, 727, 447]}, {"image_id": 5, "file_name": "286_05.png", "page": 6, "dpi": 300, "bbox": [94, 104, 415, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Example of material density reconstruction in 2D. An analogous process is employed in 3D. Standard and de- formed cell geometries are shown in (a) and (b), respec- tively. In (c), a resampled cell is shown, with new sample points drawn in varying shades of gray. The RBF reconstruc- tion kernel of radius r for a particular sample is rendered as an overlaid circle. A weighted sum of the four data points pi is used to assign material attributes to the sample. ", "caption_bbox": [94, 307, 395, 427]}, {"image_id": 6, "file_name": "286_06.png", "page": 8, "dpi": 300, "bbox": [94, 104, 716, 448], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Rendering results: (a) Deformed Pawn, (b) Alien, (c) Train #1, (d) Deformed Toy Car, (e) CSG Fan, (f) Original Chess Pawn, (g) Deformed Nozzle, (h) Train #2 ", "caption_bbox": [94, 456, 727, 484]}], "287": [{"image_id": 0, "file_name": "287_00.png", "page": 8, "dpi": 300, "bbox": [429, 697, 729, 918], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A screenshot of the nepTune application, depicting a view on a Heavy Metal island. ", "caption_bbox": [428, 928, 729, 956]}, {"image_id": 1, "file_name": "287_01.png", "page": 8, "dpi": 300, "bbox": [97, 695, 397, 916], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A Circled Fans user interface of a matrix describ- ing similarities between music artists. ", "caption_bbox": [96, 927, 397, 955]}, {"image_id": 2, "file_name": "287_02.png", "page": 8, "dpi": 300, "bbox": [96, 104, 415, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A Smoothed Data Histogram (SDH) visualization of a Self-Organizing Map (SOM) trained on music features. ", "caption_bbox": [96, 361, 397, 389]}, {"image_id": 3, "file_name": "287_03.png", "page": 8, "dpi": 300, "bbox": [429, 413, 729, 634], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A user interface for finding (web) documents, which is based on the Sunburst visualization technique. ", "caption_bbox": [428, 645, 729, 673]}, {"image_id": 4, "file_name": "287_04.png", "page": 8, "dpi": 300, "bbox": [97, 413, 397, 634], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A Circled Bars visualization of a vector describing similarities between music artists. ", "caption_bbox": [96, 645, 397, 673]}, {"image_id": 5, "file_name": "287_05.png", "page": 8, "dpi": 300, "bbox": [412, 105, 729, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A Continuous Similarity Ring (CSR) for visualiz- ing prototypical entities. ", "caption_bbox": [428, 361, 729, 389]}], "288": [{"image_id": 0, "file_name": "288_00.png", "page": 1, "dpi": 300, "bbox": [426, 711, 738, 944], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Volume rendering of 3D sonar data.", "caption_bbox": [432, 959, 665, 972]}, {"image_id": 1, "file_name": "288_01.png", "page": 3, "dpi": 300, "bbox": [69, 212, 366, 433], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The overall processing pipeline with the Sonar Explorer pipeline in detail. ", "caption_bbox": [66, 447, 367, 475]}, {"image_id": 2, "file_name": "288_02.png", "page": 4, "dpi": 300, "bbox": [402, 606, 696, 700], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Two possible texture folding configurations. The R, G, B, and A values denote the color and alpha compo- nents used for storing. ", "caption_bbox": [398, 715, 699, 759]}, {"image_id": 3, "file_name": "288_03.png", "page": 4, "dpi": 300, "bbox": [65, 292, 368, 511], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Examples of typical noise in 3D sonar data: trans- ducer noise, water surface noise, high intensity beam, and high intensity noise-wall. ", "caption_bbox": [66, 524, 367, 568]}, {"image_id": 4, "file_name": "288_04.png", "page": 5, "dpi": 300, "bbox": [70, 104, 700, 504], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Screenshot of the Sonar Explorer application: Blue: The main control panel of the Sonar Explorer application. Yellow: 2D (top and side) and 3D visualizations of a single ping. Green: Observation map. Aerial overview of observation path (several pings). Red: Propagation view. Orthographic projection of segmentation masks (several pings). ", "caption_bbox": [66, 518, 699, 562]}, {"image_id": 5, "file_name": "288_05.png", "page": 8, "dpi": 300, "bbox": [67, 104, 641, 438], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Survey map showing detected herring schools. Rough depth contours are indicated in the background, with the sonar search volume shown in grey. ", "caption_bbox": [66, 448, 699, 476]}], "289": [{"image_id": 0, "file_name": "289_00.png", "page": 2, "dpi": 300, "bbox": [429, 704, 730, 789], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Mapping example.", "caption_bbox": [504, 800, 653, 813]}, {"image_id": 1, "file_name": "289_01.png", "page": 3, "dpi": 300, "bbox": [97, 493, 398, 695], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Infovis\u201905 contest linear mapping.", "caption_bbox": [132, 705, 360, 718]}, {"image_id": 2, "file_name": "289_02.png", "page": 3, "dpi": 300, "bbox": [97, 747, 398, 872], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Infovis\u201905 contest density frequency distribution.", "caption_bbox": [96, 882, 396, 895]}, {"image_id": 3, "file_name": "289_03.png", "page": 4, "dpi": 300, "bbox": [96, 104, 415, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Infovis\u201905 contest density function.", "caption_bbox": [131, 264, 362, 277]}, {"image_id": 4, "file_name": "289_04.png", "page": 4, "dpi": 300, "bbox": [412, 105, 730, 331], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Infovis\u201905 contest density function mapping.", "caption_bbox": [439, 341, 716, 354]}, {"image_id": 5, "file_name": "289_05.png", "page": 4, "dpi": 300, "bbox": [429, 379, 730, 581], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Infovis\u201905 contest histogram equalization map- ping. ", "caption_bbox": [428, 592, 729, 620]}, {"image_id": 6, "file_name": "289_06.png", "page": 5, "dpi": 300, "bbox": [97, 721, 398, 923], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Infovis\u201905 contest one to one mapping.", "caption_bbox": [121, 933, 371, 946]}, {"image_id": 7, "file_name": "289_07.png", "page": 6, "dpi": 300, "bbox": [96, 104, 415, 331], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Infovis\u201905 contest uniform color scale mapping.", "caption_bbox": [98, 341, 394, 354]}, {"image_id": 8, "file_name": "289_08.png", "page": 6, "dpi": 300, "bbox": [429, 335, 730, 459], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Parcels density frequency distribution.", "caption_bbox": [454, 470, 702, 483]}, {"image_id": 9, "file_name": "289_09.png", "page": 8, "dpi": 300, "bbox": [96, 104, 706, 916], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Mapping algorithms applied to the parcels data set: (a)linear mapping; (b)density function mapping; (c)one to one mapping; (d)uniform color scale mapping with a set of color tones reduced to 30 perceptible steps. ", "caption_bbox": [96, 916, 729, 944]}], "290": [{"image_id": 0, "file_name": "290_00.png", "page": 3, "dpi": 300, "bbox": [99, 131, 729, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The combination of smooth feature detectors and interactive visual analysis: (a) The histogram shows that only few data items trigger strong response of the \u03bb2 feature detector, (b) a scatterplot of temperature against velocity shows differences between the detected vortices, (c) a scatterplot of turbulent energy against relative pressure shows differences between the vortices near the outlet and the inlet (d) a derived distance to surface measure removes occluding elements located at the boundary. (e) This weak vortex in an early time step of the simulation would have broken into several parts using iso-value based visualization; (f) in the 3D overview of the situation we can see how the vortices differ in rotation speed and direction. ", "caption_bbox": [96, 381, 729, 470]}, {"image_id": 1, "file_name": "290_01.png", "page": 5, "dpi": 300, "bbox": [428, 133, 731, 320], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The major components of the flow through the cooling jacket include a longitudinal component from inlet to outlet and a transversal component in the upward-and- over direction through the gaskets [HLD07]. ", "caption_bbox": [428, 330, 729, 389]}, {"image_id": 2, "file_name": "290_02.png", "page": 6, "dpi": 300, "bbox": [95, 104, 731, 347], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A feature-based, focus+context visualization showing regions of near stagnant, hot flow with medium to high levels of the \u03bb2 vortex detector. On the left we see the regions in focus. The zoomed view shows details, especially the extent of critical (red) volume. A refined magnification reveals a vortex structure at this point. ", "caption_bbox": [96, 358, 729, 402]}, {"image_id": 3, "file_name": "290_03.png", "page": 7, "dpi": 300, "bbox": [95, 128, 731, 347], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) We have highlighted the turbulent region of interest. (b) From the top we can see that a large patch of the surface contains high temperature values. (c) We additionally include the two regions of turbulence below the surface. The lower one has smaller extent and not enough cooling fluid is transported to this point. (d) A magnified view of the lower turbulent structure. (e) The turbulent structure caused by a gasket, viewed from the side. ", "caption_bbox": [96, 357, 729, 416]}], "291": [{"image_id": 0, "file_name": "291_00.png", "page": 2, "dpi": 300, "bbox": [96, 104, 699, 412], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A small 3-D data set shown as a sequence a-f of isosurfaces on the left and as a contour tree on the right. Note the 1-1 correspondance between individual contours on the left and points in the tree on the right. ", "caption_bbox": [96, 433, 729, 461]}, {"image_id": 1, "file_name": "291_01.png", "page": 4, "dpi": 300, "bbox": [96, 104, 714, 398], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustrates the global behavior of the Chan-Vese method and the implications of using a narrow-band scheme ini- tialized from the contour shown in (1). The upper row (a) and the lower row (b) differ only in the intensity of the background (black (a) vs. very dark grey (b)). Although semantically this should not affect the final result, the outside image variance term is affected by it, leading to two different results (2a) and (2b) depending on the background intensity. Narrow-band methods improve the result as shown in (3a) and (3b), but the intensity difference still causes different results. Our methods, which use topology to localize the Chan-Vese computation, are more robust to these differences, extracting essentially the same contour in each case (4a) and (4b). ", "caption_bbox": [96, 408, 729, 512]}, {"image_id": 2, "file_name": "291_02.png", "page": 5, "dpi": 300, "bbox": [174, 104, 730, 362], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Screen shot of the flexible isosurface and segmentation interface. From left to right; the isosurface visualization, the contour tree with the selected contours and the amount of simplification (collapsing). ", "caption_bbox": [96, 373, 729, 401]}, {"image_id": 3, "file_name": "291_03.png", "page": 6, "dpi": 300, "bbox": [96, 104, 637, 664], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Interactive Brain Segmentation. In (a), an isosurface has been chosen, but the skull surface occludes the brain. In (b), local contours are used to display the largest topologically distinct surfaces. In (c), one of these contours has been selected visually as the initialization surface for level set segmentation. This contour fails to segment the brain properly since at lower isovalues a spurious connection is formed with the skull fragments. In (d), the final level set segmentation is shown. Using a level set segmentation instead of the single-isovalue contour of (c) allows us to produce a markedly superior result. ", "caption_bbox": [96, 683, 729, 757]}, {"image_id": 4, "file_name": "291_04.png", "page": 7, "dpi": 300, "bbox": [124, 450, 694, 654], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: This figure illustrates that our segmentation method is capable of segmenting thin structures, such as blood vessels, given a rough initial surface. Due to the relatively large dataset (112 \u00d7 512 \u00d7 416) the initial contour was extracted at quarter scale resolution to achieve rapid feedback when exploring the data. ", "caption_bbox": [96, 673, 729, 716]}, {"image_id": 5, "file_name": "291_05.png", "page": 7, "dpi": 300, "bbox": [115, 104, 730, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Synovial Capsule Segmentation. In this data set, the clinical goal is to segment the synovial capsule for further processing. (a) shows a coarse-resolution isosurface with a reference slice of the data set. (b) shows a single contour selected from the isosurface using the flexible isosurface interface. (c) shows the final segmented boundary initialized from the contour in (b). ", "caption_bbox": [96, 348, 729, 407]}], "292": [{"image_id": 0, "file_name": "292_00.png", "page": 4, "dpi": 300, "bbox": [155, 128, 339, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: In our terminology, the area between any two adjacent regions (shades of gray) is called their bound- ary (white). Boundary lines are shown dashed, the mid- boundary line is strong black. A single boundary triangle has been hatched. ", "caption_bbox": [96, 269, 397, 347]}, {"image_id": 1, "file_name": "292_01.png", "page": 4, "dpi": 300, "bbox": [487, 128, 671, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: In a junction, all three vertices belong to different regions (central triangle). Thus, there are two possible con- tinuations of each mid-boundary line, shown here dotted for the one coming from below. ", "caption_bbox": [428, 269, 729, 332]}, {"image_id": 2, "file_name": "292_02.png", "page": 6, "dpi": 300, "bbox": [109, 529, 717, 864], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Segmentation results can be used to reveal parts of the surface which are otherwise occluded. While (a) shows the largest connected component of an FA isosurface, parts of it have been clipped in (b) to give a better view on the corpus callosum. ", "caption_bbox": [96, 866, 728, 914]}, {"image_id": 3, "file_name": "292_03.png", "page": 6, "dpi": 300, "bbox": [109, 129, 717, 464], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A part of an FA=0.5 isosurface, viewed from the midsagittal plane. (a) shows the standard XYZ-RGB color scheme, (b) presents an annotated segmentation result in random pseudocolors. ", "caption_bbox": [96, 466, 728, 499]}, {"image_id": 4, "file_name": "292_04.png", "page": 7, "dpi": 300, "bbox": [109, 129, 717, 464], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: An isosurface at cl = 0.26, seen from the front/top/right. (a) shows the standard XYZ-RGB color scheme, while (b) presents the abstraction provided by a segmentation with region representative coloring. The annotations illustrate that our method has identified anatomically relevant regions. ", "caption_bbox": [96, 466, 728, 514]}], "293": [{"image_id": 0, "file_name": "293_00.png", "page": 2, "dpi": 300, "bbox": [96, 101, 729, 346], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Graphical overview of the two function field datasets used in this paper. In (a), we show the data layout of hy- perspectral images. Hyperspectral images are spatially two-dimensional with pixels that are sampled functions of radiance (or reflectance) versus wavelength. In (b), we show the data layout for the California Regional Particulate Air Quality Study (CRPAQS) dataset. Each cell in this time-varying, three-dimensional function field contains a sampled function of particle concentration versus diameter. ", "caption_bbox": [96, 358, 729, 432]}, {"image_id": 1, "file_name": "293_01.png", "page": 4, "dpi": 300, "bbox": [96, 101, 729, 382], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Distance field renderings for feature identification within two- and three-dimensional function fields. In (a), we show a distance field for a hyperspectral image. The probe is positioned over water. As expected, other water pixels have low distance values (blue) due to functional similarity. Features with functions mapping to high distances (red) include certain types of buildings and golf courses. In (b), we show a distance field of the CRPAQS dataset. The dark blue and red regions are located over the central San Joaquin Valley, California, U.S.A. ", "caption_bbox": [96, 395, 729, 469]}, {"image_id": 2, "file_name": "293_02.png", "page": 4, "dpi": 300, "bbox": [430, 505, 732, 849], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: In (a), we show the function-space constraints (green) used to extract golf courses from hyperspectral im- ages (Figure 4). In (b), we show the constraints (red) used to extract regions from the CRPAQS dataset in which medium- sized SO4 particles have high concentration (Figure 5). In both, the black curves are functions that satisfy the feature queries. ", "caption_bbox": [428, 862, 729, 967]}, {"image_id": 3, "file_name": "293_03.png", "page": 5, "dpi": 300, "bbox": [100, 101, 731, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Hyperspectral images annotated with overlays produced by three queries: golf courses as shown in Figure 3(a) (green), water (blue), and evaporation ponds containing brine shrimp (red). The feature queries were constructed by a user exploring the hyperspectral image of Moffett Field and the San Francisco Bay in (a). The image in (b) shows an area approx- imately 18 kilometers to the east of Moffett Field; golf courses and water were extracted using the pre-constructed queries without modification. ", "caption_bbox": [96, 396, 729, 470]}, {"image_id": 4, "file_name": "293_04.png", "page": 6, "dpi": 300, "bbox": [428, 400, 730, 702], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Part of our software system. The upper plot shows the probe function in black, and the constraint curves in red defining the query that extracts evaporation ponds contain- ing brine shrimp from hyperspectral images. The lower plot shows the sample weights curve. The minimum-maximum constraint curves and sample weights curve are modifiable by the user; control points can be added, removed, and ma- nipulated. The right side of the interface provides more con- trols for feature queries. ", "caption_bbox": [428, 712, 729, 847]}, {"image_id": 5, "file_name": "293_05.png", "page": 6, "dpi": 300, "bbox": [96, 101, 698, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Distance field renderings generated from the CRPAQS dataset, and the results of using the feature query shown in Figure 3(b) to extract regions in which medium-sized SO4 particles have high concentration. For clarity we only show ground layer images from the three-dimensional results. ", "caption_bbox": [96, 321, 729, 365]}], "294": [{"image_id": 0, "file_name": "294_00.png", "page": 2, "dpi": 300, "bbox": [96, 101, 701, 370], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) the sum of all binned spectral profiles with left part zoomed 200 times and (b) the matching sum of image planes", "caption_bbox": [97, 379, 728, 392]}, {"image_id": 1, "file_name": "294_01.png", "page": 3, "dpi": 300, "bbox": [124, 101, 730, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) the spectral profile of a second principal component and (b) the matching second image component", "caption_bbox": [129, 378, 696, 391]}, {"image_id": 2, "file_name": "294_02.png", "page": 4, "dpi": 300, "bbox": [412, 103, 725, 347], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: selection of spectral peaks outside the greyed area with \u03b1 = 0.3 from the spectral profile of the second principal component from Figure 2a ", "caption_bbox": [428, 357, 729, 401]}, {"image_id": 3, "file_name": "294_03.png", "page": 6, "dpi": 300, "bbox": [124, 447, 702, 725], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: the iso-surfaces of two anti-correlated features within the second principal component with (a) the red shape on \u03b3 = 0.4, a green shape on \u03b3 = 0.2 and (b) the red shape on \u03b3 = 0.6, a green shape on \u03b3 = 0.4 ", "caption_bbox": [96, 734, 729, 763]}, {"image_id": 4, "file_name": "294_04.png", "page": 6, "dpi": 300, "bbox": [96, 101, 702, 404], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: the iso-surfaces of two anti-correlated features within the second principal component with (a) \u03b2 = 16 and (b) \u03b2 = 32", "caption_bbox": [96, 412, 729, 426]}, {"image_id": 5, "file_name": "294_05.png", "page": 7, "dpi": 300, "bbox": [100, 103, 415, 420], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: the extracted correlated shapes in the second principal component component with \u03b1 = 0.3, \u03b2 = 16 and \u03b3 = 0.35 for the blue and red shape, \u03b3 = 0.15 for the green shape ", "caption_bbox": [96, 433, 397, 492]}], "295": [{"image_id": 0, "file_name": "295_00.png", "page": 2, "dpi": 300, "bbox": [450, 322, 716, 481], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Unstable manifold (blue) and stable manifold (red) of spiral saddles C0 and C1 , respectively, intersecting in saddle connectors \u03c3 and \u03c30 . In a Poincar\u00e9 plane through C0 and C1 , the seed curve for integration is chosen between two successive intersection points s0 and s1 of \u03c3. ", "caption_bbox": [427, 508, 729, 582]}, {"image_id": 1, "file_name": "295_01.png", "page": 3, "dpi": 300, "bbox": [412, 104, 730, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Planar section of 2D manifolds of a synthetic vor- tex breakdown bubble. ", "caption_bbox": [428, 322, 729, 350]}, {"image_id": 2, "file_name": "295_02.png", "page": 3, "dpi": 300, "bbox": [163, 296, 332, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Photograph of vortex breakdown bubble in exper- iment. Image copied with permission from [SMH98]. ", "caption_bbox": [96, 441, 397, 469]}, {"image_id": 3, "file_name": "295_03.png", "page": 3, "dpi": 300, "bbox": [429, 394, 730, 546], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Manifolds of Figure 3 at longer integration time.", "caption_bbox": [430, 568, 726, 581]}, {"image_id": 4, "file_name": "295_04.png", "page": 4, "dpi": 300, "bbox": [125, 324, 369, 523], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Poincar\u00e9 section of unstable (blue) and stable (red) manifolds. The manifolds are joined at P, resulting in a turnstile between A and B. ", "caption_bbox": [96, 533, 397, 576]}, {"image_id": 5, "file_name": "295_05.png", "page": 4, "dpi": 300, "bbox": [429, 475, 730, 508], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Close-up of Figure 6.", "caption_bbox": [498, 518, 658, 531]}, {"image_id": 6, "file_name": "295_06.png", "page": 4, "dpi": 300, "bbox": [469, 296, 684, 407], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Section of the manifolds of the vortex ring in the Francis draft tube. ", "caption_bbox": [428, 417, 729, 445]}, {"image_id": 7, "file_name": "295_07.png", "page": 4, "dpi": 300, "bbox": [429, 560, 730, 593], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Manifolds after trimming at selected intersection point, minimizing the maximal size of the lobes. ", "caption_bbox": [428, 604, 729, 632]}, {"image_id": 8, "file_name": "295_08.png", "page": 5, "dpi": 300, "bbox": [140, 328, 354, 543], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Close-up of Figure 9", "caption_bbox": [165, 553, 328, 566]}, {"image_id": 9, "file_name": "295_09.png", "page": 5, "dpi": 300, "bbox": [140, 105, 415, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Unstable manifold (blue) and stable manifold (red) rendered as stream surfaces. Streamlines entering (white) and leaving (black) the recirculation region. ", "caption_bbox": [96, 262, 397, 305]}, {"image_id": 10, "file_name": "295_10.png", "page": 6, "dpi": 300, "bbox": [429, 383, 730, 552], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Unstable manifold computed in divergence- conservingly interpolated field. Comparison of original data (white) and divergence-cleaned data (colored). ", "caption_bbox": [428, 562, 729, 605]}, {"image_id": 11, "file_name": "295_11.png", "page": 6, "dpi": 300, "bbox": [111, 606, 384, 874], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Vortex ring in Francis draft tube with section plane (blue), streamlines (yellow) and vortex core lines (red). ", "caption_bbox": [96, 885, 397, 928]}, {"image_id": 12, "file_name": "295_12.png", "page": 6, "dpi": 300, "bbox": [412, 105, 730, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Unstable manifold computed in trilinearly in- terpolated field. Comparison of original data (white) and divergence-cleaned data (colored). ", "caption_bbox": [428, 308, 729, 351]}, {"image_id": 13, "file_name": "295_13.png", "page": 7, "dpi": 300, "bbox": [412, 104, 730, 403], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Overview of the flow in the river power plant. Poincar\u00e9 section shown as blue rectangle. ", "caption_bbox": [428, 413, 729, 441]}, {"image_id": 14, "file_name": "295_14.png", "page": 8, "dpi": 300, "bbox": [96, 104, 415, 543], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Both manifolds of vortex in river power plant.", "caption_bbox": [102, 554, 391, 567]}], "296": [{"image_id": 0, "file_name": "296_00.png", "page": 3, "dpi": 300, "bbox": [196, 103, 415, 205], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Illustration of two perpendicular families of lines: one for a circular vector field v (dashed lines) and one for a radial vector field u (solid lines). ", "caption_bbox": [96, 216, 397, 260]}, {"image_id": 1, "file_name": "296_01.png", "page": 4, "dpi": 300, "bbox": [435, 845, 723, 942], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Processing stages and data flow for the 2D algo- rithm. ", "caption_bbox": [428, 952, 729, 980]}, {"image_id": 2, "file_name": "296_02.png", "page": 4, "dpi": 300, "bbox": [96, 101, 415, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of two transport and visualization ap- proaches, applied to a shear flow. The two resulting images (middle and bottom images in the right column) differ be- cause LIC and advection are not commutative. Seeds and streamlines are colored to allow for an easier recognition of correspondence between images. ", "caption_bbox": [96, 349, 397, 438]}, {"image_id": 3, "file_name": "296_03.png", "page": 6, "dpi": 300, "bbox": [95, 101, 723, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Performance results for varying parameters and squared viewports. All vertical axes show ms/frame.", "caption_bbox": [131, 232, 690, 245]}, {"image_id": 4, "file_name": "296_04.png", "page": 7, "dpi": 300, "bbox": [412, 101, 730, 489], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Flow visualization on curved surfaces: (top) stan- dard LIC, (bottom) orthogonal vector field visualization. ", "caption_bbox": [428, 500, 729, 528]}, {"image_id": 5, "file_name": "296_05.png", "page": 7, "dpi": 300, "bbox": [140, 103, 415, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualization of shear flow with different alpha blending weights: (a) \u03b1 = 0.1, (b) \u03b1 = 0.3. ", "caption_bbox": [96, 301, 397, 330]}], "297": [{"image_id": 0, "file_name": "297_00.png", "page": 2, "dpi": 300, "bbox": [440, 646, 731, 901], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Discrete streamline density definition. Our defini- tion of density is based on the ratio of counted streamline pixels or voxels to the total number of pixels or voxels on the whole domain P or on a local domain W . ", "caption_bbox": [428, 916, 729, 975]}, {"image_id": 1, "file_name": "297_01.png", "page": 3, "dpi": 300, "bbox": [159, 104, 731, 521], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Flow diagram of priority streamline algorithm.", "caption_bbox": [268, 531, 557, 544]}, {"image_id": 2, "file_name": "297_02.png", "page": 5, "dpi": 300, "bbox": [129, 105, 415, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Constructed Gauss-like filter for 2D-data. The center region is set to a large negative value. ", "caption_bbox": [96, 327, 397, 355]}, {"image_id": 3, "file_name": "297_03.png", "page": 5, "dpi": 300, "bbox": [412, 104, 730, 323], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Filtering process illustrated for 1D-case. The den- sity function (blue) is at its global maximum (below the green dotted line) subtracted by the filter (red). The result- ing function (black) acts as density function for the next it- eration. The hatched area shows the minimal distance zone of a streamline, where further placement is forbidden. The process is repeated until the global maximum of the current density function (below the green-dotted line) also lies below a certain threshold (here, the yellow dotted line). ", "caption_bbox": [428, 335, 729, 470]}, {"image_id": 4, "file_name": "297_04.png", "page": 6, "dpi": 300, "bbox": [96, 104, 739, 362], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Two test datasets: (a) and (b) two saddles, one source and one sink, (c) four saddles and one center point. (a) Streamlines drawn by the priority streamline algorithm using (a) a constant density map, (b) a heterogeneous density map: values of density map increase from the upper left to the lower right corner. (c) a density map highlighting saddle points. The density map is shown as background color. ", "caption_bbox": [96, 370, 729, 429]}, {"image_id": 5, "file_name": "297_05.png", "page": 6, "dpi": 300, "bbox": [104, 450, 738, 681], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) Swirling jet entering fluid at rest. Visualized with standard streamlines. (b)Swirling jet data visualized with priority streamlines using velocity magnitude as density map. (c) Comparative visualization of velocity (streamline density) and vorticity of swirling jet data. ", "caption_bbox": [96, 689, 729, 732]}, {"image_id": 6, "file_name": "297_06.png", "page": 7, "dpi": 300, "bbox": [95, 574, 399, 903], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Convection in Earth mantle. Red: streamlines in- dicate high vorticity, yellow: high velocity, green: high (posi- tive) values for Okubo-Weiss (OW), blue highly negative val- ues for OW, orange: hight temperature. ", "caption_bbox": [96, 914, 397, 973]}, {"image_id": 7, "file_name": "297_07.png", "page": 8, "dpi": 300, "bbox": [96, 104, 700, 478], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Snapshot of the velocity field of a 3D mixing layer. Three views onto the dataset. Red: streamlines indicate high vorticity, yellow: high velocity, green: high (positive) values for OW, blue highly negative values for OW. ", "caption_bbox": [96, 489, 729, 517]}], "298": [{"image_id": 0, "file_name": "298_00.png", "page": 4, "dpi": 300, "bbox": [96, 104, 703, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The pipeline of our texture-based stippling algorithm explained by using a kidney surface. (a) To parameterize the object for texture mapping, the object space is divided into axis-parallel unit cubes (multi-cube). Cube mapping is performed for every cube. To assign a texture position to each surface point, (b) the normalized surface normal (here mapped to a color in RGB-space) and (c) the light intensity at each surface point is calculated. The light\u2019s intensity is used to select a texture with the appropriate number of stippling points (d) to represent the shape with stippling. ", "caption_bbox": [96, 321, 729, 395]}, {"image_id": 1, "file_name": "298_01.png", "page": 4, "dpi": 300, "bbox": [446, 734, 716, 870], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: 2D sketch of the multi-cube method: (a) each cube can be treated equally for the texture position calculation. Only the relative position of each surface point according to a cube is important. (b) The major direction of the surface normal will select the cube side, even if another cube side is hit first (see p2 and ~n2 ). This minimizes texture distortions. ", "caption_bbox": [428, 883, 729, 972]}, {"image_id": 2, "file_name": "298_02.png", "page": 6, "dpi": 300, "bbox": [412, 105, 731, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Texture layers (1 brightest tone - 3 darkest tone) and resulting texture that encodes different tone layers with unique gray values. (b) One texture tile is replaced by a patch of (2 \u00d7 2) tiles of the same texture and vice versa. The (2 \u00d7 2) patch of a texture contains the scaled version of itself (gray dots). ", "caption_bbox": [428, 281, 729, 370]}, {"image_id": 3, "file_name": "298_03.png", "page": 6, "dpi": 300, "bbox": [96, 104, 415, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Stippling points appear while magnifying and dis- appear while minifying the object. Large structure repre- sentations contain more stippling points than smaller object representations. The point size remains constant over differ- ent scales. ", "caption_bbox": [96, 282, 397, 356]}, {"image_id": 4, "file_name": "298_04.png", "page": 7, "dpi": 300, "bbox": [101, 104, 731, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Performance of our stippling technique.", "caption_bbox": [123, 705, 369, 718]}], "299": [{"image_id": 0, "file_name": "299_00.png", "page": 5, "dpi": 300, "bbox": [426, 408, 728, 532], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Optimized streaming MIP. The process of selec- tion, projection and rendering of detail coefficients for one level of the pyramid. The black parts of the histogram cor- respond to the subset of detail coefficients that are selected according to the error criterion. ", "caption_bbox": [428, 542, 729, 616]}, {"image_id": 1, "file_name": "299_01.png", "page": 7, "dpi": 300, "bbox": [97, 579, 397, 730], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Streaming MIP rendering of the XMasTree data set with 5% of the detail coefficients (left image) and at full reconstruction (right image). ", "caption_bbox": [96, 740, 397, 784]}, {"image_id": 2, "file_name": "299_02.png", "page": 7, "dpi": 300, "bbox": [429, 174, 733, 484], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Streaming MIP rendering of the complete Visible Woman dataset in a 800 by 2000 window at various qual- ity settings (percentages of the total number of detail coeffi- cients). Second row: zoom-in for each quality setting; third row: the corresponding differences with the original (the bar indicates the error in grey levels). ", "caption_bbox": [428, 500, 729, 589]}], "300": [{"image_id": 0, "file_name": "300_00.png", "page": 1, "dpi": 300, "bbox": [412, 346, 731, 805], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization of the time-resolved Terashake 2.1 simu- lation data. On a dual core processor equipped with a single GPU particle-based visualization using 256K primitives in combination with volume rendering runs at over 40 fps. ", "caption_bbox": [428, 807, 729, 865]}, {"image_id": 1, "file_name": "300_01.png", "page": 3, "dpi": 300, "bbox": [95, 324, 399, 497], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visualization of a large eddy simulation of the flow around a cylinder. Dense particle sets are visualized using oriented rendering primitives to achieve a \u201cLIC-like\u201d look. ", "caption_bbox": [96, 499, 397, 544]}, {"image_id": 2, "file_name": "300_02.png", "page": 4, "dpi": 300, "bbox": [96, 129, 398, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Performance measurements of the stream manager under various configurations. ", "caption_bbox": [96, 739, 397, 770]}, {"image_id": 3, "file_name": "300_03.png", "page": 4, "dpi": 300, "bbox": [431, 810, 729, 904], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A fragment stream is generated by rendering a quad that covers as many pixels as there should be items in the stream. ", "caption_bbox": [428, 903, 729, 934]}, {"image_id": 4, "file_name": "300_04.png", "page": 6, "dpi": 300, "bbox": [95, 739, 399, 951], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Dye injection in the cylinder flow. Semi-transparent par- ticles are injected into the field using the probing metaphor. ", "caption_bbox": [96, 953, 397, 984]}, {"image_id": 5, "file_name": "300_05.png", "page": 6, "dpi": 300, "bbox": [95, 122, 731, 284], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Performance measurements (in fps) for stream / path / streak lines of varying length L. ", "caption_bbox": [428, 602, 729, 633]}, {"image_id": 6, "file_name": "300_06.png", "page": 7, "dpi": 300, "bbox": [427, 129, 731, 710], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Snapshot of the TeraShake 2.1 data set. Near-surface displacements are color-coded and visualized together with parti- cles. Top: Observe the characteristic patterns formed by the parti- cles. Bottom: Red particles indicate a large longitudinal displace- ment, while green indicates a large transversal component. ", "caption_bbox": [428, 712, 729, 784]}, {"image_id": 7, "file_name": "300_07.png", "page": 7, "dpi": 300, "bbox": [99, 562, 395, 657], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Wave types are revealed by specific particle patterns that are formed in the unsteady flow visualization. From left to right: P-waves, S-waves, and L-waves are shown. These three types can be recognized most effectively in motion. Orange marks the wave propagation direction, and white marks local particle motion. ", "caption_bbox": [96, 658, 397, 730]}, {"image_id": 8, "file_name": "300_08.png", "page": 7, "dpi": 300, "bbox": [95, 129, 399, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Particles-in-plane visualization.", "caption_bbox": [148, 363, 343, 381]}], "301": [{"image_id": 0, "file_name": "301_00.png", "page": 4, "dpi": 300, "bbox": [96, 101, 730, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Left: Initial graph (EEG frequency band 1-3 Hz, dataset 1). Vertices represent electrodes, edges represent signif- icant coherences between electrode signals. Edges are visualized as gray lines, vertices as black dots on top of the edges. This corresponds to a common existing data-driven visualization, showing cluttered edges. Middle: Histogram of the corre- sponding coherence. Vertical lines (dash, solid, dot) indicate significance thresholds associated with three probability levels (p = 0.10, 0.05, 0.01, respectively). Right: Voronoi diagram with electrode labels in the corresponding cells, having the convex hull of all electrodes as a boundary. To improve the readability, the Voronoi diagram is stretched horizontally. Because the coherence computation is independent of distance, distances between electrodes do not need to be preserved. However, spatial relationships between electrodes are maintained. ", "caption_bbox": [96, 339, 729, 459]}, {"image_id": 1, "file_name": "301_01.png", "page": 5, "dpi": 300, "bbox": [97, 101, 730, 320], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Functional Unit map (EEG frequency band 1-3 Hz, dataset 1). Left: A circle with a cross inside indicates the geographic center of all Voronoi centers belonging to one FU and has a corresponding gray value. The geographic center can be located in a cell not belonging to the corresponding FU. Middle: The same FU map, but with seven FUs larger than 5 cells. White Voronoi cells are part of smaller FUs. Right: Lines connect FU centers, if the inter-FU coherence exceeds the significance threshold (Eqn. 1). The color of the line depends on the inter-FU coherence (see color bar, with minimum corresponding to the coherence threshold \u2248 0.15). ", "caption_bbox": [96, 333, 729, 423]}, {"image_id": 2, "file_name": "301_02.png", "page": 6, "dpi": 300, "bbox": [96, 101, 741, 561], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: FU maps with FUs larger than 5 cells, for the 1-3 Hz EEG frequency band (top row) and for 13-20 Hz (bottom row), for three datasets. Displayed above each FU map are: the number of FUs, the number of connecting lines between FUs, and the relative number of connecting lines (between parentheses). A circle with a cross inside indicates the geographic center of all Voronoi centers belonging to an FU and has a corresponding gray value. ", "caption_bbox": [96, 566, 729, 625]}], "302": [{"image_id": 0, "file_name": "302_00.png", "page": 3, "dpi": 300, "bbox": [95, 436, 396, 595], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) z-buffer of one segmented structure (bones), (b) selection of the z-values of all buffers at one pixel position. ", "caption_bbox": [96, 609, 397, 637]}, {"image_id": 1, "file_name": "302_01.png", "page": 4, "dpi": 300, "bbox": [430, 142, 728, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Different viewpoints for the meniscus (yellow). (a): Viewpoint with respect to the largest visible surface of the meniscus. (b): Viewpoint from the top with respect of low importance of bones. The bones are almost completly faded out. ", "caption_bbox": [428, 405, 729, 479]}, {"image_id": 2, "file_name": "302_02.png", "page": 4, "dpi": 300, "bbox": [95, 129, 399, 609], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: This scheme illustrates the viewpoint estimation process. Several parameter maps are weighted and accumu- lated to a final result map. The maximum of this map is the best viewpoint for an object of interest. A Mercator projec- tion is used to map the values from the sphere\u2019s surface to a rectangular region. ", "caption_bbox": [96, 619, 397, 708]}, {"image_id": 3, "file_name": "302_03.png", "page": 5, "dpi": 300, "bbox": [442, 129, 716, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: View of the automatically determined minimal dis- tance between a liver tumor and a vascular tree. The small image shows an overview of the scene. ", "caption_bbox": [428, 338, 729, 381]}, {"image_id": 4, "file_name": "302_04.png", "page": 7, "dpi": 300, "bbox": [98, 104, 730, 498], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Evaluation of viewpoint quality. We received com- pleted questionnaires from 44 persons. 18 of them have good medical knowledge. Viewpoint quality 1.0 is best, 5.0 is worst. ", "caption_bbox": [428, 629, 729, 688]}], "303": [{"image_id": 0, "file_name": "303_00.png", "page": 3, "dpi": 300, "bbox": [98, 133, 396, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview of the pipeline for feature emphasis and contextual cutaway visualization. ", "caption_bbox": [96, 303, 397, 331]}, {"image_id": 1, "file_name": "303_01.png", "page": 4, "dpi": 300, "bbox": [412, 105, 725, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: With full emphasis, importance-driven Phong shading (a) and Gooch cool-to-warm shading [GGSC98] with silhouette enhancement (b) help provide visual distinc- tion between vessels and bone. ", "caption_bbox": [428, 312, 729, 371]}, {"image_id": 2, "file_name": "303_02.png", "page": 4, "dpi": 300, "bbox": [96, 104, 415, 599], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: No shading (a) results in low contrast and spatial distinction. With no emphasis (b), vessels in the skull are ob- scured by shading details in the bone. With full emphasis (c), shaded and unshaded samples are selectively combined to accentuate important materials (vessels) and suppress shad- ing detail of non-important materials (skin, bone). ", "caption_bbox": [96, 611, 397, 700]}, {"image_id": 3, "file_name": "303_03.png", "page": 5, "dpi": 300, "bbox": [101, 139, 393, 316], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Given an object of interest (shaded) and a view- ing direction, we can construct a cutaway with distinct base, transition, overlay, and clear regions, as shown in this cross section diagram. An occlusion function \u2126 can then affect visibility of materials in different areas of the cutaway struc- ture. In the traditional simple cutaway, \u03b81 = \u03b82 and d = 0. ", "caption_bbox": [96, 343, 397, 433]}, {"image_id": 4, "file_name": "303_04.png", "page": 6, "dpi": 300, "bbox": [96, 104, 719, 588], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The effects of various parameters in the cutaway structure are shown in the above images. Note that (a) and (b) are traditional cutaway views but (c) and (d) expose more contextual information by cutting away less important materials at wider angles. A smaller overlay thickness in (d) causes the embedded object to be less obscured. ", "caption_bbox": [96, 601, 729, 644]}, {"image_id": 5, "file_name": "303_05.png", "page": 7, "dpi": 300, "bbox": [103, 129, 392, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A transversal ultrasound image of a patient\u2019s liver is shown aligned in the context of a (non-contrasted) CT scan. Bone is allowed to obscure the ultrasound plane and as such helps facilitate spatial perception of the plane. ", "caption_bbox": [96, 405, 397, 464]}, {"image_id": 6, "file_name": "303_06.png", "page": 8, "dpi": 300, "bbox": [96, 104, 719, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Liver ultrasound images are shown within a CTA scan. Vessels (pink) with an importance value of 1 are allowed to obscure the ultrasound plane. The effect of shading emphasis can be seen in (a) as shading of skin and flesh is subdued. ", "caption_bbox": [96, 421, 729, 449]}, {"image_id": 7, "file_name": "303_07.png", "page": 8, "dpi": 300, "bbox": [108, 477, 718, 757], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A longitudinal ultrasound image of the liver is visualized within an MRI scan of the same volunteer. A simple cutaway scenario with no transition or overlay regions is shown in (a). The addition of transition and overlay regions in (b) allows one to see the vasculature emerge from regions with corresponding structure in the ultrasound plane. ", "caption_bbox": [96, 770, 729, 813]}], "304": [{"image_id": 0, "file_name": "304_00.png", "page": 2, "dpi": 300, "bbox": [412, 104, 678, 224], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Reconstruction of a thin structure (a) with CESN: result without any smoothing (b), with one iteration (c) and with 5 iterations (d). ", "caption_bbox": [428, 234, 729, 278]}, {"image_id": 1, "file_name": "304_01.png", "page": 3, "dpi": 300, "bbox": [427, 423, 732, 507], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Reconstruction of a liver tree with MPUIs: spher- ical artefacts occur at thin structures that are represented by too few points (left). Our method adapts point density to prevent those artefacts (right). ", "caption_bbox": [428, 517, 729, 576]}, {"image_id": 2, "file_name": "304_02.png", "page": 3, "dpi": 300, "bbox": [431, 788, 728, 867], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Surface generation for vascular structures with MPU implicits. ", "caption_bbox": [428, 877, 729, 905]}, {"image_id": 3, "file_name": "304_03.png", "page": 4, "dpi": 300, "bbox": [140, 787, 354, 939], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Placing of points (red) for different constellations of object voxels (blue) in the neighbourhood of an outer boundary voxel (red). ", "caption_bbox": [96, 948, 397, 992]}, {"image_id": 4, "file_name": "304_04.png", "page": 4, "dpi": 300, "bbox": [439, 519, 719, 611], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Due to subsampling, the constellation of points adheres very strictly to the original voxel grid (b). Addi- tional subvoxels are labeled as object-subvoxels to prevent staircase artefacts (c). ", "caption_bbox": [428, 621, 729, 680]}, {"image_id": 5, "file_name": "304_05.png", "page": 5, "dpi": 300, "bbox": [95, 718, 399, 900], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Effect of different values for nmin , \u03b1 and \u03bb: The left image shows a reconstruction using the values proposed in [OBA\u2217 03]. A smoother reconstruction of the vessel surface is possible using higher values (right). ", "caption_bbox": [96, 910, 397, 972]}, {"image_id": 6, "file_name": "304_06.png", "page": 5, "dpi": 300, "bbox": [121, 345, 373, 447], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Reduction of stair case artefacts by the addition of object-subvoxels demonstrated for a single thin branch (a): Staircase artefacts occur due to subsampling of the voxel grid (b). The addition of object-subvoxels yields a smoother reconstruction (c). ", "caption_bbox": [96, 457, 397, 531]}, {"image_id": 7, "file_name": "304_07.png", "page": 5, "dpi": 300, "bbox": [186, 217, 309, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Examples for the labeling of additional subvoxels (red) as object-subvoxels. ", "caption_bbox": [96, 299, 397, 327]}, {"image_id": 8, "file_name": "304_08.png", "page": 6, "dpi": 300, "bbox": [478, 277, 680, 555], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Reconstruction of an aneurysm with MC (top) and MPUs (bottom). ", "caption_bbox": [428, 566, 729, 594]}, {"image_id": 9, "file_name": "304_09.png", "page": 6, "dpi": 300, "bbox": [131, 277, 363, 557], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Accuracy of CESN, CS and MPUI. The table lists the median (med) and the maximum (max) of the deviations to the corresponding MC results. All values are given in re- lation to the length of one voxel diagonal of the respective volume data set. ", "caption_bbox": [428, 900, 721, 974]}, {"image_id": 10, "file_name": "304_10.png", "page": 7, "dpi": 300, "bbox": [427, 864, 732, 953], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Histograms of curvature values for the MC re- construction (left) and the MPUI reconstruction (right). ", "caption_bbox": [428, 964, 729, 993]}, {"image_id": 11, "file_name": "304_11.png", "page": 7, "dpi": 300, "bbox": [115, 128, 711, 362], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Efficiency of MPUI compared to MC, CESN and CS. The table lists the number of generated triangles (p) and the reconstruction time (t) in seconds. ", "caption_bbox": [96, 929, 389, 973]}], "305": [{"image_id": 0, "file_name": "305_00.png", "page": 2, "dpi": 300, "bbox": [375, 74, 695, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization of the DTI fibers of a normal hu- man brain with (a) unclustered DTI fibers, (b) clustered DTI fibers, (c) geometric hulls, and (d) geometric hulls with prin- cipal fibers inside. (d) was annotated by a neuropsycholo- gist. A: Anterior; P: Posterior; S: Superior; I: Inferior. ", "caption_bbox": [391, 435, 692, 509]}, {"image_id": 1, "file_name": "305_01.png", "page": 3, "dpi": 300, "bbox": [392, 318, 695, 574], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The hierarchical clustering results on the first data set with the distance thresholds at (a) 0.5 mm, (b) 2.0 mm, (c) 4.0 mm, and (d) 5.0 mm. The left and right cingulum bundles are shown with yellow arrows in (c). ", "caption_bbox": [391, 582, 692, 641]}, {"image_id": 2, "file_name": "305_02.png", "page": 4, "dpi": 300, "bbox": [67, 235, 352, 529], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) A fiber cluster; (b) The geometric hull of the fiber bundle; (c) The refined hull with Poisson reconstruction technique; (d) The composition of the refined hull and the fiber bundle. (b) and (c) are rendered with polygonal models. ", "caption_bbox": [58, 542, 359, 601]}, {"image_id": 3, "file_name": "305_03.png", "page": 5, "dpi": 300, "bbox": [67, 350, 352, 638], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Fibers with similar orientation (the principal fiber is shown in red); (b) Fibers with distinguishable ori- entations (the principal fibers are shown in red); (c) Several fiber bundles; (d) Principal fibers on the fiber bundles in (c). ", "caption_bbox": [58, 651, 359, 710]}, {"image_id": 4, "file_name": "305_04.png", "page": 6, "dpi": 300, "bbox": [399, 98, 684, 395], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) Rendering the fiber bundles (2, 406 fibers) of the multi-valued volume using the Banks model (Equa- tion 3); (b-d) The results with the modified model (Equa- tion 4). All tracts are displayed (i.e., lu is set to be zero). The hierarchies for (b-d) are 6, 8, and 9 respectively. ", "caption_bbox": [391, 406, 692, 480]}, {"image_id": 5, "file_name": "305_05.png", "page": 6, "dpi": 300, "bbox": [67, 98, 352, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) Order-false result; (b) Order-correct result.", "caption_bbox": [63, 255, 351, 268]}, {"image_id": 6, "file_name": "305_06.png", "page": 7, "dpi": 300, "bbox": [399, 98, 684, 381], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The comprehensive visualization of the fiber tracts with geometric hulls, principal fibers, and the fractional anisotropy volume. The second data set was used. ", "caption_bbox": [391, 392, 692, 436]}, {"image_id": 7, "file_name": "305_07.png", "page": 7, "dpi": 300, "bbox": [60, 477, 363, 642], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The abstractive visualization of the fiber tracts us- ing (a) geometric hulls only, and (b) geometric hulls with principal fibers inside. The second data set was used. ", "caption_bbox": [58, 651, 359, 695]}], "306": [{"image_id": 0, "file_name": "306_00.png", "page": 2, "dpi": 300, "bbox": [94, 97, 658, 497], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Compared to slice images (a) and direct volume rendering (b), our method for fused visualization of streamlines and T1 data (c) both relates fiber tracts more clearly to the anatomy and gives a more plastic impression of the cut T1 volume ", "caption_bbox": [58, 502, 691, 532]}, {"image_id": 1, "file_name": "306_01.png", "page": 3, "dpi": 300, "bbox": [390, 97, 694, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Pushing a surface through structures like skull and blood vessels can lead to shading artifacts (a) which are avoided by limiting the total resistance (b) ", "caption_bbox": [391, 385, 692, 429]}, {"image_id": 2, "file_name": "306_02.png", "page": 4, "dpi": 300, "bbox": [58, 97, 362, 236], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Unlike a simple 2D embossment filter (a), our method reveals structures behind the original plane (b) ", "caption_bbox": [58, 242, 359, 270]}, {"image_id": 3, "file_name": "306_03.png", "page": 5, "dpi": 300, "bbox": [390, 97, 694, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Our robust estimator (b) is less likely to propose unusable views than a simple least squares approach (a) ", "caption_bbox": [391, 236, 692, 264]}, {"image_id": 4, "file_name": "306_04.png", "page": 6, "dpi": 300, "bbox": [423, 97, 661, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Despite the non-planar shape of the corpus callo- sum, fitting a cutting plane produces a sensible result ", "caption_bbox": [391, 311, 692, 339]}, {"image_id": 5, "file_name": "306_05.png", "page": 6, "dpi": 300, "bbox": [58, 97, 362, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: In some cases, the T1 surface may occlude part of a fiber tract even after deformation (a). Such problems are easily resolved by a local, interactive deformation (b) ", "caption_bbox": [58, 226, 359, 270]}, {"image_id": 6, "file_name": "306_06.png", "page": 7, "dpi": 300, "bbox": [67, 97, 684, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Rotating the created geometry interactively (from (a) to (b)) supports the spatial impression. Due to its flat appear- ance, rotating a clipped volume rendering is less helpful (c) ", "caption_bbox": [58, 277, 691, 305]}, {"image_id": 7, "file_name": "306_07.png", "page": 8, "dpi": 300, "bbox": [67, 97, 684, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Deforming the cutting plane based on streamline density (a) or T1 value (b) alone is less effective in conveying their relation than a combined approach (c) ", "caption_bbox": [58, 280, 691, 308]}], "307": [{"image_id": 0, "file_name": "307_00.png", "page": 3, "dpi": 300, "bbox": [391, 600, 691, 735], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: In (a) the tumor is colored red, as the fMRI data (without color blending d f MRI = max), in (b) the tumor is colored purple whereas the saturation of the fMRI data is reduced (d f MRI = 15). ", "caption_bbox": [391, 748, 692, 807]}, {"image_id": 1, "file_name": "307_01.png", "page": 4, "dpi": 300, "bbox": [65, 358, 357, 515], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Brain with reconstructed fiber tracts, displayed entirely (dDT I = max); (b) reduced to silhouettes in depen- dence (dDT I = 31) of the distance to the ROI (b). ", "caption_bbox": [58, 528, 359, 571]}, {"image_id": 2, "file_name": "307_02.png", "page": 4, "dpi": 300, "bbox": [397, 436, 691, 570], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) If one of the axes is not visible, the perception of the spatial depth is difficult. (b) The ring is more than half closed (dring = 0.64), so the ROI is near the center of the brain at the back side in view direction ", "caption_bbox": [391, 583, 692, 642]}, {"image_id": 3, "file_name": "307_03.png", "page": 5, "dpi": 300, "bbox": [59, 75, 378, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Computation of the distance ring. Two rays are traced through the volume from the ROI to the backside and frontside along the view direction. The steps are counted to compute the distance of the ROI. ", "caption_bbox": [59, 299, 360, 358]}, {"image_id": 4, "file_name": "307_04.png", "page": 6, "dpi": 300, "bbox": [58, 598, 362, 751], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The cylindrical cut geometry without (a) and with consistent lighting (b). The visibility of anatomical details is superior with consistent shading. ", "caption_bbox": [59, 764, 360, 807]}, {"image_id": 5, "file_name": "307_05.png", "page": 6, "dpi": 300, "bbox": [59, 74, 378, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Computation of the cylindric path from entry point to region of interest. ", "caption_bbox": [59, 251, 360, 279]}, {"image_id": 6, "file_name": "307_06.png", "page": 8, "dpi": 300, "bbox": [375, 75, 692, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Average frame rates of the internal view (left) and external view (right), with additional rendering features from left to right, respectively. The computation of the access path reduces performance by a factor of two. All other meth- ods have negligible influence on the rendering performance. ", "caption_bbox": [391, 241, 692, 315]}, {"image_id": 7, "file_name": "307_07.png", "page": 8, "dpi": 300, "bbox": [58, 375, 694, 885], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The three implemented views. In (a) the internal view shows the functional data and the presented techniques for en- hancing the perception of the spatial depth. Figure (b) displays the corresponding external view with synchronized perspective. Each MPR view (c-e) shows a slice of the volume data, the virtual access path and functional as well as anatomical data. ", "caption_bbox": [59, 898, 692, 941]}], "308": [{"image_id": 0, "file_name": "308_00.png", "page": 3, "dpi": 300, "bbox": [414, 98, 669, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Energy Terms: (a) Curvature energy term; (b) Gravitation energy term; (c) Computing the force for the gravitation energy term; (d) The range of neighboring lines for gravitation interaction. m is set to be 3 for Eq. 2 and 3. ", "caption_bbox": [391, 397, 692, 456]}, {"image_id": 1, "file_name": "308_01.png", "page": 4, "dpi": 300, "bbox": [84, 98, 336, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The effect of energy term weighting on visual clus- tering: (a) No visual clustering; (b) \u03b1c = 0, q\u03b1 = qd = 15; (c) \u03b1c = 0, q\u03b1 = qd = 30; (d) \u03b1c = 0.15, q\u03b1 = qd = 30. ", "caption_bbox": [58, 259, 359, 305]}, {"image_id": 2, "file_name": "308_02.png", "page": 5, "dpi": 300, "bbox": [71, 98, 681, 228], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Applying color and opacity based on line density: (a) Density bins for each control point column; (b) Accumulation of line density for each bin; (c) Computation of the local density for each line by averaging the density values of all control points; (d) Applying color and opacity based on user specified transfer function; (e) Parallel coordinates before applying color and opacity; (f) Parallel coordinates plot after applying color and opacity. ", "caption_bbox": [58, 240, 691, 299]}, {"image_id": 3, "file_name": "308_03.png", "page": 5, "dpi": 300, "bbox": [398, 336, 686, 572], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visual clustering on synthesized datasets.", "caption_bbox": [411, 581, 671, 594]}, {"image_id": 4, "file_name": "308_04.png", "page": 6, "dpi": 300, "bbox": [435, 98, 649, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Experiments on a dataset with 5 variables and 3848 data items: (a) Original plot; (b) After visual clustering optimization and color and opacity enhancement. Data is from http://rosuda.org/Mondrian/. ", "caption_bbox": [391, 337, 692, 396]}, {"image_id": 5, "file_name": "308_05.png", "page": 6, "dpi": 300, "bbox": [59, 98, 363, 869], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Experiments on a dataset with 7 variables and 392 data items: (a) Original plot; (b) After visual cluster- ing optimization; (c) With color encoding the 8th variable, the origin of cars; (d) With one transfer function. Data from http://lib.stat.cmu.edu/datasets/cars.data. ", "caption_bbox": [58, 878, 359, 952]}, {"image_id": 6, "file_name": "308_06.png", "page": 7, "dpi": 300, "bbox": [59, 98, 366, 370], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Experiments on a dataset with 5 variables and 7736 data items: (a) Original plot; (b) Hierarchical parallel coordinates result [FWR99]; (c) Applying a transfer func- tion before visual clustering; (d) Applying a transfer func- tion after visual clustering. ", "caption_bbox": [58, 379, 359, 453]}], "309": [{"image_id": 0, "file_name": "309_00.png", "page": 3, "dpi": 300, "bbox": [70, 75, 378, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The screen space quality method consists of the following steps: (1) the original data set is abstracted, (2) the graphical representations of the original and abstracted data sets are rendered as images, (3) the images are trans- formed using distance transforms, and (4) a comparison function gives the quality value. ", "caption_bbox": [59, 242, 360, 331]}, {"image_id": 1, "file_name": "309_01.png", "page": 4, "dpi": 300, "bbox": [59, 74, 378, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Two cases where pixel by pixel comparison of original (blue) and abstracted (brown) versions is not pos- sible since the primitives do not overlap. The left and right images show a scatter plot and parallel coordinates. ", "caption_bbox": [59, 253, 360, 312]}, {"image_id": 2, "file_name": "309_02.png", "page": 4, "dpi": 300, "bbox": [375, 75, 683, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Quality-driven abstraction. A visual quality is pre- defined and controls the abstraction process. Generating the image and computing the distance map for the original data set is only done once (steps in white) while the correspond- ing steps for the abstracted data set together with the com- parison are made for each new abstraction (steps in blue). ", "caption_bbox": [391, 242, 692, 331]}, {"image_id": 3, "file_name": "309_03.png", "page": 4, "dpi": 300, "bbox": [62, 334, 359, 512], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An illustration of the distance transform used for parallel coordinates. The left figure shows a graphical rep- resentation consisting of two lines, each resulting in several objects (in blue). The right figure shows the corresponding distance map where each pixel describes the vertical dis- tance to the closest object, colour coded from black (a dis- tance of 0) to light grey (a distance of 3). ", "caption_bbox": [59, 523, 360, 627]}], "310": [{"image_id": 0, "file_name": "310_00.png", "page": 1, "dpi": 300, "bbox": [375, 325, 694, 741], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Traditional parallel coordinates visualiza- tion (color-coded by cluster) of the 392-point, seven- dimensional \u201ccars\u201d dataset. Point distributions along axes are given by histogram bars. All datasets visualized in this paper are courtesy of the XmdvTool home page (davis.wpi.edu/\u223cxmdv). ", "caption_bbox": [391, 753, 692, 840]}, {"image_id": 1, "file_name": "310_01.png", "page": 2, "dpi": 300, "bbox": [59, 73, 646, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An example of illustrative parallel coordinates (IPC) showing some of the major features of our new visualization approach. Shading and opacity are used extensively in IPC to convey information. ", "caption_bbox": [58, 309, 691, 337]}, {"image_id": 2, "file_name": "310_02.png", "page": 3, "dpi": 300, "bbox": [435, 98, 649, 276], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Each polyline of a traditional PC plot can be transformed into a polycurve to create edge bundles. ", "caption_bbox": [391, 286, 692, 314]}, {"image_id": 3, "file_name": "310_03.png", "page": 3, "dpi": 300, "bbox": [405, 336, 677, 505], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Edge bundles group polylines into tight groups of polycurves in the \u201ccars\u201d dataset. Curves of the same color are in the same cluster. ", "caption_bbox": [391, 515, 692, 558]}, {"image_id": 4, "file_name": "310_04.png", "page": 4, "dpi": 300, "bbox": [394, 289, 690, 417], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visualizations of a portion of the \u201cout5d\u201d dataset with opacity scaling (\u03b1s ) values of 0.5, 0.75 and 1.0, re- spectively. Of the four clusters shown, the red one has the greatest size; thus, it has full opacity when \u03b1s = 1.0. ", "caption_bbox": [391, 427, 692, 486]}, {"image_id": 5, "file_name": "310_05.png", "page": 4, "dpi": 300, "bbox": [62, 97, 358, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Scaling the clusters permits one to generate a wide range of visualizations. Shown is part of the \u201cscanbio\u201d dataset for cluster scaling factors (h) of 0.5, 3.0 and 12.0, respectively, and with an opacity scaling factor (\u03b1s ) of 0.5. ", "caption_bbox": [58, 205, 359, 264]}, {"image_id": 6, "file_name": "310_06.png", "page": 4, "dpi": 300, "bbox": [390, 97, 694, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A portion of the \u201cvenus\u201d dataset with spline ten- sion (\u03b2) values of 0.15, 0.50 and 0.85, respectively. ", "caption_bbox": [391, 239, 692, 269]}, {"image_id": 7, "file_name": "310_07.png", "page": 5, "dpi": 300, "bbox": [67, 97, 683, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Branching of the clusters provides insight into the distribution of the data. Shown is the \u201cnetperf\u201d dataset with minimum branching widths (w%) of 4.6%, 6.1% and 10.0%, respectively. As w% increases, small branches merge together. ", "caption_bbox": [58, 250, 691, 280]}, {"image_id": 8, "file_name": "310_08.png", "page": 6, "dpi": 300, "bbox": [392, 329, 693, 525], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: A portion of the \u201ciris\u201d dataset with histograms rendered in the traditional way and with our new approach. For the sake of this example we grouped the data into a sin- gle cluster. ", "caption_bbox": [391, 535, 692, 592]}, {"image_id": 9, "file_name": "310_09.png", "page": 6, "dpi": 300, "bbox": [59, 73, 684, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Shadows help the eye to determine the relative z order of clusters and provide a visually interesting rendering effect. Shown here is the \u201cnetperf\u201d dataset without shadows, with shadows, and with magenta halos, respectively. Note that we have drawn the shadow a little darker and wider than usual so that it reproduces well in print. ", "caption_bbox": [58, 250, 691, 293]}, {"image_id": 10, "file_name": "310_10.png", "page": 8, "dpi": 300, "bbox": [66, 97, 691, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Several visualizations of the \u201ccars\u201d dataset as part of the case study discussed in Section 3.", "caption_bbox": [117, 247, 634, 260]}], "311": [{"image_id": 0, "file_name": "311_00.png", "page": 3, "dpi": 300, "bbox": [455, 97, 628, 279], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Program flow for the computation of vortex core lines. ", "caption_bbox": [391, 289, 692, 317]}, {"image_id": 1, "file_name": "311_01.png", "page": 5, "dpi": 300, "bbox": [58, 303, 361, 494], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Isosurface (left) and core of a hairpin vortex in a transitional flow (right); both arms are growing tempo- rally and are connected with the existing vortex structure. The vortex core line is colored in red and the isoskeleton in blue. ", "caption_bbox": [58, 505, 359, 579]}, {"image_id": 2, "file_name": "311_02.png", "page": 5, "dpi": 300, "bbox": [73, 96, 345, 204], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Parameterization issues: the red curve of the vor- tex core line grows faster than the blue curve of the isoskele- ton (left). Therefore, the tangent vector for generating the search plane becomes corrupted. This problem is addressed by reparametrization of the vortex core line (right). ", "caption_bbox": [58, 218, 359, 292]}, {"image_id": 3, "file_name": "311_03.png", "page": 6, "dpi": 300, "bbox": [103, 96, 316, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Connection types in an isoskeleton: connection of two red bifurcation points \u2013 by splitting the connecting segment and starting the search for local \u03bb2 minima at the blue point it is assured that the search propagates toward the bifurcations (a); connection of cyan endpoints and red bifurcation points (b). ", "caption_bbox": [58, 238, 359, 327]}, {"image_id": 4, "file_name": "311_04.png", "page": 7, "dpi": 300, "bbox": [64, 276, 360, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Semi-automatic isovalue determination: original vortical region (left); decomposition with color coding by isovalue (middle); the respective vortex core lines (right). ", "caption_bbox": [58, 397, 359, 441]}, {"image_id": 5, "file_name": "311_05.png", "page": 7, "dpi": 300, "bbox": [61, 105, 690, 197], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Our approach faithfully extracts a vortex core line that consists of several connected components (left). The approach by Stegmaier et al. extracts components of the vortex core line that are equivalent to our results but remain unconnected (middle). The \u03bb2 -based parallel-vectors approach extracts unconnected points on the vortex core line; several outliers are present as well as sections where no core line points were detected (right). ", "caption_bbox": [58, 211, 691, 270]}], "312": [{"image_id": 0, "file_name": "312_00.png", "page": 3, "dpi": 300, "bbox": [67, 99, 688, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Algorithm overview focusing upon a single mixed cell with both pure and mixed neighbors (a). During optimization of the labeled discretization (b) a volume conservative swap of two subcell labels (c) is performed probabilistically, based upon its effect on the Potts-model energy. The converged material interface reconstruction produced by our method is shown in (d). ", "caption_bbox": [58, 275, 691, 316]}, {"image_id": 1, "file_name": "312_01.png", "page": 5, "dpi": 300, "bbox": [59, 97, 693, 198], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Evolution in time of the two-dimensional fluid flows considered in this paper; interfaces were reconstructed by our method. On the top, a bubble of low density fluid rises through a denser fluid. On the bottom, five fluids pass two cylinders (six total materials). ", "caption_bbox": [58, 207, 691, 234]}, {"image_id": 2, "file_name": "312_02.png", "page": 5, "dpi": 300, "bbox": [393, 250, 691, 516], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Close-ups of regions reconstructed by PLIC (left) and our method (right). Images in the top row are from the two- dimensional bubble dataset; the bottom row shows a \u201cT-junction\u201d between three materials in the two cylinders dataset. ", "caption_bbox": [391, 525, 692, 579]}, {"image_id": 3, "file_name": "312_03.png", "page": 6, "dpi": 300, "bbox": [58, 97, 694, 418], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Simulated annealing was performed on different parts of the discretization labeling for different lengths of time: the top third was left in the initial state without optimization, the middle third was optimized for 1 second, and the bottom third was optimized for 10 seconds. ", "caption_bbox": [58, 427, 691, 454]}, {"image_id": 4, "file_name": "312_04.png", "page": 7, "dpi": 300, "bbox": [410, 823, 679, 895], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Thin interfaces (left, 10x10 grid) are difficult to recon- struct for both PLIC (middle) and our method (right). ", "caption_bbox": [391, 914, 692, 941]}, {"image_id": 5, "file_name": "312_05.png", "page": 7, "dpi": 300, "bbox": [58, 97, 694, 492], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Interface reconstructions of the three-dimensional bubble dataset as the bubble bursts. On the left, we show the interface extracted from our discretization labeling; on the right is the discontinuous 3D PLIC reconstruction which has only one polygon per cell. ", "caption_bbox": [58, 501, 691, 528]}, {"image_id": 6, "file_name": "312_06.png", "page": 7, "dpi": 300, "bbox": [403, 551, 673, 746], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Percentage of mixed cells over time. Low percentages yield large memory savings, since subdivision is only performed upon mixed cells. ", "caption_bbox": [391, 753, 692, 794]}], "313": [{"image_id": 0, "file_name": "313_00.png", "page": 4, "dpi": 300, "bbox": [59, 74, 673, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Flow patterns close to the surface are reflected in integral curve convergence or divergence and hence in surface FTLE measures. ", "caption_bbox": [59, 263, 692, 291]}, {"image_id": 1, "file_name": "313_01.png", "page": 5, "dpi": 300, "bbox": [71, 599, 362, 885], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Volumetric FTLE fields around the high-speed train nose show a strong agreement with the results of Fig- ure 2(a). ", "caption_bbox": [59, 899, 360, 943]}, {"image_id": 2, "file_name": "313_02.png", "page": 5, "dpi": 300, "bbox": [112, 74, 693, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Direct surface FTLE visualization and stochastic streamline seeding in a high-speed train dataset.", "caption_bbox": [103, 546, 647, 559]}, {"image_id": 3, "file_name": "313_03.png", "page": 6, "dpi": 300, "bbox": [59, 74, 646, 344], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparison steady vs. unsteady surface FTLE fields and resulting flow structures illustrated by stochastical stream- line/pathline seeding. ", "caption_bbox": [59, 354, 692, 382]}, {"image_id": 4, "file_name": "313_04.png", "page": 8, "dpi": 300, "bbox": [59, 74, 657, 446], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Manual streamline seeding on the surface of the BMW dataset.", "caption_bbox": [191, 458, 558, 471]}], "314": [{"image_id": 0, "file_name": "314_00.png", "page": 2, "dpi": 300, "bbox": [467, 310, 612, 436], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The image conveys change over time using opacity-based techniques. The upward motion of the fea- ture is conveyed using opacity-based techniques. The older timesteps, shown by the faded representations of the feature over time, provide temporal context. ", "caption_bbox": [391, 453, 692, 527]}, {"image_id": 1, "file_name": "314_01.png", "page": 2, "dpi": 300, "bbox": [59, 75, 685, 214], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: These are a set of snapshots from evenly spaced time steps of the turbulent vortex dataset [FS98]. As is evident from looking at the snapshots, it is very hard to correlate and track a particular feature over different time steps. These images were generated using Volview [Kit06]. ", "caption_bbox": [58, 225, 691, 269]}, {"image_id": 2, "file_name": "314_02.png", "page": 2, "dpi": 300, "bbox": [133, 304, 287, 469], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The image depicts change over time in a feature for CFD data. The rightward motion of the flow feature is conveyed using speedlines. ", "caption_bbox": [58, 479, 359, 523]}, {"image_id": 3, "file_name": "314_03.png", "page": 3, "dpi": 300, "bbox": [118, 75, 693, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A screenshot of a sample screen that is shown to the subjects. The subjects were shown snapshots and were asked to indicate the direction of motion of a particular feature moving over time. They were also requested to specify a confidence level in their answer. ", "caption_bbox": [58, 391, 691, 435]}, {"image_id": 4, "file_name": "314_04.png", "page": 4, "dpi": 300, "bbox": [375, 75, 686, 129], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: These images show a subset of the kinds of motion that we asked the subjects to choose. This enabled us to test more complex motions than just simple leftwards, rightwards kinds of motion. ", "caption_bbox": [391, 139, 692, 198]}, {"image_id": 5, "file_name": "314_05.png", "page": 4, "dpi": 300, "bbox": [59, 75, 378, 569], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: This is a screenshot showing an augmented snap- shot based visualization to the subjects. The users were asked to indicate the direction of motion as well as their con- fidence in their answers. ", "caption_bbox": [58, 580, 359, 639]}, {"image_id": 6, "file_name": "314_06.png", "page": 5, "dpi": 300, "bbox": [414, 247, 668, 412], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: This table shows the result of performing the analy- sis of variance (ANOVA) on the accuracy per user. The prob- ability of these results, assuming the null hypothesis, is less than 0.0001. ", "caption_bbox": [391, 878, 692, 937]}, {"image_id": 7, "file_name": "314_07.png", "page": 6, "dpi": 300, "bbox": [84, 635, 336, 832], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: This graph shows the amount of time required by the subjects to complete the task using the four techniques. Users took more time to complete a task using snapshots as compared to all the other techniques. Users also took more time to answer questions using animations as compared to animations augmented with illustration-inspired techniques. ", "caption_bbox": [58, 846, 359, 935]}, {"image_id": 8, "file_name": "314_08.png", "page": 7, "dpi": 300, "bbox": [84, 641, 337, 834], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The users were asked to specify their confidence in their answers. This graph shows a representation of the overall confidence that the users had in their answers. As can be seen, users were more confident about their answers for the augmented snapshots and animated animations as compared to plain snapshots or animations. ", "caption_bbox": [58, 846, 359, 935]}, {"image_id": 9, "file_name": "314_09.png", "page": 8, "dpi": 300, "bbox": [59, 75, 378, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: In this graph, the accuracy of the users for syn- thetic data versus real world data is compared. As can be seen, the accuracy for synthetic data is high for both with and without illustration-inspired techniques. The accuracy for real world data without illustration-inspired techniques is very low whereas the use of illustration-inspired tech- niques when applied to real world data has boosted the ac- curacy of the users. ", "caption_bbox": [58, 272, 359, 392]}], "315": [{"image_id": 0, "file_name": "315_00.png", "page": 1, "dpi": 300, "bbox": [375, 357, 693, 789], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Hurricane Lili\u2019s track in Google Earth. Track data is from the National Hurricane Center [Law03]. Image credit: Mahnas Jean Mohammadi-Aragh. ", "caption_bbox": [391, 799, 692, 843]}, {"image_id": 1, "file_name": "315_01.png", "page": 2, "dpi": 300, "bbox": [435, 133, 642, 334], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Point selection circle that the observer would see. The selected point is at the center of the red/white circle. ", "caption_bbox": [391, 344, 692, 372]}, {"image_id": 2, "file_name": "315_02.png", "page": 2, "dpi": 300, "bbox": [435, 408, 649, 613], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Area selection box that the observer would see. The selected area is the area included in the black/white box. ", "caption_bbox": [391, 623, 692, 651]}, {"image_id": 3, "file_name": "315_03.png", "page": 4, "dpi": 300, "bbox": [153, 96, 599, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The user study GUI in training mode. Note the correct answer on the right side of the screen. This was removed once the test began. ", "caption_bbox": [58, 361, 691, 389]}, {"image_id": 4, "file_name": "315_04.png", "page": 5, "dpi": 300, "bbox": [66, 96, 679, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Each of the four basic types of images. Combinations of these four formed the eight image types used in the study. From left, (1) glyphs only (2) glyphs + state lines (3) glyphs + pressure contours (4) glyphs + color map. ", "caption_bbox": [58, 257, 691, 285]}, {"image_id": 5, "file_name": "315_05.png", "page": 6, "dpi": 300, "bbox": [436, 759, 648, 902], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Magnitude Response Time vs. Selection Area Size. ", "caption_bbox": [391, 913, 692, 941]}, {"image_id": 6, "file_name": "315_06.png", "page": 6, "dpi": 300, "bbox": [436, 288, 649, 431], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Magnitude Response Time vs. Question Type, Lay- ers. ", "caption_bbox": [391, 442, 692, 470]}, {"image_id": 7, "file_name": "315_07.png", "page": 6, "dpi": 300, "bbox": [436, 97, 648, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Magnitude Error vs. Selection Area Size.", "caption_bbox": [411, 251, 668, 264]}, {"image_id": 8, "file_name": "315_08.png", "page": 6, "dpi": 300, "bbox": [104, 290, 316, 434], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Magnitude Error vs. Question Type, Layers.", "caption_bbox": [71, 445, 344, 458]}, {"image_id": 9, "file_name": "315_09.png", "page": 6, "dpi": 300, "bbox": [104, 98, 316, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Magnitude Error vs. Observers.", "caption_bbox": [101, 252, 313, 265]}, {"image_id": 10, "file_name": "315_10.png", "page": 7, "dpi": 300, "bbox": [506, 289, 577, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: The glyph that is produced by RIP is shown on the left. In order to prove that the counter-clockwise bias is caused by the shape of the glyph, we implemented a small study (2 observers) where the glyph shape is flipped, as shown on the right. ", "caption_bbox": [391, 373, 692, 447]}, {"image_id": 11, "file_name": "315_11.png", "page": 7, "dpi": 300, "bbox": [104, 288, 316, 431], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Directional Error vs. Observers (880 trials). Ob- servers 10 and 11 saw reversed glyphs (Figure 14). ", "caption_bbox": [58, 442, 359, 470]}, {"image_id": 12, "file_name": "315_12.png", "page": 7, "dpi": 300, "bbox": [436, 97, 648, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Directional Error vs. Selection Area Size.", "caption_bbox": [406, 252, 672, 265]}, {"image_id": 13, "file_name": "315_13.png", "page": 7, "dpi": 300, "bbox": [59, 97, 361, 225], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Magnitude Response Time vs. Contour Lines, Color Map, State Lines for the area questions (360 trials). ", "caption_bbox": [58, 236, 359, 264]}, {"image_id": 14, "file_name": "315_14.png", "page": 8, "dpi": 300, "bbox": [103, 97, 316, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Directional Error vs. Glyph Orientation (880 tri- als). ", "caption_bbox": [58, 252, 359, 280]}], "316": [{"image_id": 0, "file_name": "316_00.png", "page": 3, "dpi": 300, "bbox": [57, 221, 361, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The four hand postures that can be recognized.", "caption_bbox": [64, 342, 352, 355]}, {"image_id": 1, "file_name": "316_01.png", "page": 3, "dpi": 300, "bbox": [96, 75, 378, 174], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Examples for hand-sketched directional glyphs.", "caption_bbox": [63, 185, 354, 198]}, {"image_id": 2, "file_name": "316_02.png", "page": 3, "dpi": 300, "bbox": [377, 75, 693, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The area for sketching glyphs is displayed after a pen has been picked up from the tray. The stroke\u2019s width is controlled through postures as well as drawing speed, while erasing is possible using a flat hand. ", "caption_bbox": [390, 299, 691, 358]}, {"image_id": 3, "file_name": "316_03.png", "page": 4, "dpi": 300, "bbox": [57, 75, 378, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Probing the dataset with a single glyph and the one-finger posture. The glyph is off-set to ensure its visibility. ", "caption_bbox": [58, 319, 361, 347]}, {"image_id": 4, "file_name": "316_04.png", "page": 4, "dpi": 300, "bbox": [377, 75, 693, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Exploring larger areas of the dataset using a fist.", "caption_bbox": [391, 319, 689, 332]}, {"image_id": 5, "file_name": "316_05.png", "page": 4, "dpi": 300, "bbox": [389, 354, 693, 564], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Glyph de-emphasis & erasing using the flat hand.", "caption_bbox": [390, 575, 691, 588]}, {"image_id": 6, "file_name": "316_06.png", "page": 5, "dpi": 300, "bbox": [57, 323, 361, 421], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Using colored glyph sources to identify trends.", "caption_bbox": [65, 432, 351, 445]}, {"image_id": 7, "file_name": "316_07.png", "page": 5, "dpi": 300, "bbox": [57, 75, 378, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Using glyph sources to illustrate flow properties. Sources are placed with the two-finger posture. ", "caption_bbox": [58, 274, 361, 302]}, {"image_id": 8, "file_name": "316_08.png", "page": 5, "dpi": 300, "bbox": [377, 75, 693, 201], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Annotation of a LIC image of a vortex simulation. Three hand-sketched glyphs are used to point out aspects that are otherwise not visible such as the field\u2019s strength. ", "caption_bbox": [389, 211, 692, 254]}, {"image_id": 9, "file_name": "316_09.png", "page": 6, "dpi": 300, "bbox": [389, 306, 693, 557], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Probing the dataset with few glyphs vs. revealing the flow\u2019s strength and direction using many glyphs. ", "caption_bbox": [390, 567, 691, 595]}, {"image_id": 10, "file_name": "316_10.png", "page": 6, "dpi": 300, "bbox": [87, 342, 361, 543], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Illustrating the identified trends using the one- finger posture and a larger glyph. ", "caption_bbox": [58, 553, 362, 581]}, {"image_id": 11, "file_name": "316_11.png", "page": 6, "dpi": 300, "bbox": [58, 75, 378, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Exploring trends using the fist posture.", "caption_bbox": [82, 311, 334, 324]}, {"image_id": 12, "file_name": "316_12.png", "page": 6, "dpi": 300, "bbox": [377, 75, 693, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Using sources to show the flow at different times.", "caption_bbox": [390, 274, 693, 287]}, {"image_id": 13, "file_name": "316_13.png", "page": 7, "dpi": 300, "bbox": [57, 407, 361, 525], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Visualization of storm Emma hitting Europe.", "caption_bbox": [67, 536, 349, 549]}, {"image_id": 14, "file_name": "316_14.png", "page": 7, "dpi": 300, "bbox": [57, 75, 378, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Illustrating the rotation direction using bent ar- rows and using a vorticity visualization for confirmation. ", "caption_bbox": [58, 360, 362, 388]}], "317": [{"image_id": 0, "file_name": "317_00.png", "page": 2, "dpi": 300, "bbox": [66, 98, 378, 532], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Layouts of a sparse graph (|V| = 500, |E| = 1032), with data taken from [Lov07]. Colors represent different classes of nodes, sizes represent node centralities. In the top view there is some rough clustering information visible but connectivity information is obscured by the large number of links in the center. The bottom view shows the graph after our method has been applied, making it easier to identify clusters and the connections between them. ", "caption_bbox": [59, 549, 360, 671]}, {"image_id": 1, "file_name": "317_01.png", "page": 3, "dpi": 300, "bbox": [64, 98, 683, 356], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Different layouts of the same graph, representing 500 artists and their mutual influences. Coloring is done by artistic movement. (a) Shows a the result after a standard force directed layout (b) Shows the result after a force directed layout using a Lin-Log model [Noa05] (c) Shows the result after computing a minimum edge centrality spanning tree and performing a force directed layout. ", "caption_bbox": [58, 362, 691, 423]}, {"image_id": 2, "file_name": "317_02.png", "page": 4, "dpi": 300, "bbox": [65, 98, 680, 454], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Two representations of a graph representing influences between great thinkers, taken from [Lov07]. Colors represent the general class of person, with philosophers in red, writers in green, artists in beige, scientists in blue and mathematicians in purple. (a) Minimum betweenness spanning tree, showing rough clustering structure in the graph (b) minimum betweenness planar graph, showing 81% of the edges in the original graph. Compare with the standard force directed view in the top of Figure 1. ", "caption_bbox": [58, 461, 691, 537]}, {"image_id": 3, "file_name": "317_03.png", "page": 6, "dpi": 300, "bbox": [66, 98, 376, 501], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Stability of the betweenness metric under noise.The top graph shows the correspondence between the minimum betweenness spanning tree of a graph and the min- imum betweenness spanning tree of the same graph with an increasing amount of edges rewired. Bottom shows the quality of the computed spanning tree as a function of noise added. ", "caption_bbox": [59, 509, 360, 615]}, {"image_id": 4, "file_name": "317_04.png", "page": 7, "dpi": 300, "bbox": [64, 98, 685, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Four different pseudo random graphs with 50 nodes, 200 edges and 4 clusters. Varying the ratio between cluster edges and non cluster edges lead to different degrees of clustering. The top row shows layouts of the graphs with spanning tree edges highlighted. The bottom row shows the corresponding spanning trees. ", "caption_bbox": [59, 367, 692, 413]}], "318": [{"image_id": 0, "file_name": "318_00.png", "page": 2, "dpi": 300, "bbox": [58, 75, 378, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Wafer stepper.", "caption_bbox": [145, 240, 272, 253]}, {"image_id": 1, "file_name": "318_01.png", "page": 4, "dpi": 300, "bbox": [58, 75, 378, 436], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Approach.", "caption_bbox": [155, 449, 263, 462]}, {"image_id": 2, "file_name": "318_02.png", "page": 5, "dpi": 300, "bbox": [58, 734, 361, 916], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Question 1.", "caption_bbox": [152, 926, 266, 939]}, {"image_id": 3, "file_name": "318_03.png", "page": 5, "dpi": 300, "bbox": [58, 75, 693, 590], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Multivariate graph visualization.", "caption_bbox": [264, 600, 485, 613]}, {"image_id": 4, "file_name": "318_04.png", "page": 6, "dpi": 300, "bbox": [375, 75, 693, 279], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Question 3.", "caption_bbox": [484, 289, 598, 302]}, {"image_id": 5, "file_name": "318_05.png", "page": 6, "dpi": 300, "bbox": [58, 75, 378, 499], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Question 2.", "caption_bbox": [152, 512, 266, 525]}], "319": [{"image_id": 0, "file_name": "319_00.png", "page": 2, "dpi": 300, "bbox": [58, 69, 378, 524], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: SemViz pipeline showing: Domain Ontology (DO); Semantic Bridging Ontology (SBO); and Visual Rep- resentation Ontology (VRO). ", "caption_bbox": [58, 536, 359, 580]}, {"image_id": 1, "file_name": "319_01.png", "page": 3, "dpi": 300, "bbox": [59, 72, 378, 410], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The SemViz technology pipeline, from Source web page to Target visualizations ", "caption_bbox": [58, 421, 359, 449]}, {"image_id": 2, "file_name": "319_02.png", "page": 4, "dpi": 300, "bbox": [375, 72, 692, 427], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The Domain Ontology instance for music charts subject area (as mapped to the BBC top 40 charts web page). ", "caption_bbox": [391, 438, 692, 467]}, {"image_id": 3, "file_name": "319_03.png", "page": 5, "dpi": 300, "bbox": [377, 69, 693, 419], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The Semantic Bridging Ontology containing the domain and visualization knowledge for mappings between the music DO and the 2D Graph VRO. ", "caption_bbox": [391, 431, 692, 475]}, {"image_id": 4, "file_name": "319_04.png", "page": 5, "dpi": 300, "bbox": [59, 72, 378, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The Visual Representation Ontology instance for a 2D Graph (as mapped to the DO instance in Figure 3). ", "caption_bbox": [58, 376, 359, 405]}, {"image_id": 5, "file_name": "319_05.png", "page": 6, "dpi": 300, "bbox": [375, 72, 691, 468], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Top: Schema-based semantics deduced from the Music Chart DO. Bottom: Instance-based semantics derived from the source data by the Data Analysis module. ", "caption_bbox": [391, 479, 692, 523]}, {"image_id": 6, "file_name": "319_06.png", "page": 6, "dpi": 300, "bbox": [58, 69, 378, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The DO and VRO of a base example.", "caption_bbox": [90, 306, 327, 319]}, {"image_id": 7, "file_name": "319_07.png", "page": 7, "dpi": 300, "bbox": [377, 69, 693, 605], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Top: The highest scoring visualization. Thumb- nails: Images showing all (usable) permutations of the BBC Top 40 web page to 2D Graph using ILOG Discovery. ", "caption_bbox": [391, 616, 692, 660]}], "320": [{"image_id": 0, "file_name": "320_00.png", "page": 2, "dpi": 300, "bbox": [58, 74, 378, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Section of the Roche Metabolic Network. The graph is hand-routed. The poster comes with a booklet which contains an index that provides the mapping from entity to a sector on the poster. ", "caption_bbox": [59, 326, 360, 385]}, {"image_id": 1, "file_name": "320_01.png", "page": 2, "dpi": 300, "bbox": [64, 410, 362, 605], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: KEGG pathway map modeling Long Term Depres- sion. Remarkable are the structures in the background pic- ture of the graph which provide important meta-information. ", "caption_bbox": [59, 611, 360, 654]}, {"image_id": 2, "file_name": "320_02.png", "page": 4, "dpi": 300, "bbox": [58, 74, 694, 460], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The jukebox view combines a textual list menu for browsing related pathways by name (1) with an interconnected pathway stack (2), an area designated for a detailed examination of a graph (3) and a memo pad (4). ", "caption_bbox": [59, 471, 692, 499]}, {"image_id": 3, "file_name": "320_03.png", "page": 5, "dpi": 300, "bbox": [390, 592, 694, 873], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The expression of gene-expression experiments, a snapshot of the regulation of genes at a certain time, are mapped onto the pathways. In this case a three part time- series experiment is color coded directly onto the nodes. ", "caption_bbox": [391, 883, 692, 942]}, {"image_id": 4, "file_name": "320_04.png", "page": 5, "dpi": 300, "bbox": [375, 74, 694, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The view shows the propagation of a signal in several pathways. ", "caption_bbox": [391, 330, 692, 358]}, {"image_id": 5, "file_name": "320_05.png", "page": 8, "dpi": 300, "bbox": [376, 75, 694, 829], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The series of screenshots depicts an exemplary part of the visual exploration process in Caleydo. In (a) the system presents the pathways for the PTK2 search query. By investigation of the adjacencies in the graph stack the user can identify other genes connected to PTK2 which are not present in the local pathway context (b). In (c) the user switches to the topmost graph in the stack. (d) shows multi- ple genes mapped on a neighboring enzyme. ", "caption_bbox": [391, 840, 692, 960]}], "321": [{"image_id": 0, "file_name": "321_00.png", "page": 4, "dpi": 300, "bbox": [118, 339, 301, 419], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Huygens\u2019 principle: A reflected sound wave cor- responds to an infinite set of point sources. When adding the individual pressure fields, shape and direction of the wave front are preserved. ", "caption_bbox": [58, 441, 359, 500]}, {"image_id": 1, "file_name": "321_01.png", "page": 4, "dpi": 300, "bbox": [58, 71, 378, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The pressure at the point L can be calculated by the pressure on the surface of an infinitesimal sphere S around L with diameter d = 2\u03c1 (a). In analogy, the pressure at the surface point E can be calculated by the pressure on an infinit small hemisphere H around E with diameter d (b). ", "caption_bbox": [58, 239, 359, 313]}, {"image_id": 2, "file_name": "321_02.png", "page": 5, "dpi": 300, "bbox": [86, 75, 693, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The same setup traced with recursion depth rd=1, rd=3 and rd=20 @640Hz. The floor has 1% and the other surfaces 90% scattering. The impact of the recursion dept is obvious. ", "caption_bbox": [58, 249, 691, 277]}, {"image_id": 3, "file_name": "321_03.png", "page": 5, "dpi": 300, "bbox": [394, 286, 689, 387], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Phonon map of simple wall with point source in front of it. The left half is interpolated with Shepard, the right half with gauss interpolation. (b) Legend for minampl = 10\u22124 ", "caption_bbox": [390, 397, 691, 457]}, {"image_id": 4, "file_name": "321_04.png", "page": 5, "dpi": 300, "bbox": [391, 736, 688, 872], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Configuration of the simulation scenario in two different lecture rooms. Orange spheres mark the sources and blue sphere marks the listener position. ", "caption_bbox": [390, 882, 691, 926]}, {"image_id": 5, "file_name": "321_05.png", "page": 6, "dpi": 300, "bbox": [58, 75, 598, 414], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The visualization of the phonon map using the described approach (a,b) and the phonon visualization described in [DMB+ 06] (c,d) for the second reflection showing the global (a,b) and local (c,d) influence of scattering. Pictures (a,c) are traced with a scattering coefficient of 1% and (b,d) with a scattering coefficient of 50% ", "caption_bbox": [58, 423, 691, 467]}, {"image_id": 6, "file_name": "321_06.png", "page": 7, "dpi": 300, "bbox": [73, 531, 346, 737], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Room HS46-110 at the university @452Hz", "caption_bbox": [76, 748, 343, 761]}, {"image_id": 7, "file_name": "321_07.png", "page": 7, "dpi": 300, "bbox": [68, 75, 694, 434], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Phase visualization of sound received at one listener position for the frequencies 452Hz (a,d), 640Hz (b,e), and 1280Hz (c,f) for the first reflection and after six reflections (d-f) for the scenarion shown in Figure 5 (a). ", "caption_bbox": [58, 444, 691, 472]}], "322": [{"image_id": 0, "file_name": "322_00.png", "page": 2, "dpi": 300, "bbox": [450, 292, 632, 470], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A protein-solvent system represented without any filtering of the solvent molecules. ", "caption_bbox": [391, 480, 692, 508]}, {"image_id": 1, "file_name": "322_01.png", "page": 3, "dpi": 300, "bbox": [450, 255, 634, 445], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The protein in spacefill representation. The grey sphere marks the region of interest enclosing the cavity. Sol- vent molecules outside are neglected in further processing. ", "caption_bbox": [391, 455, 692, 498]}, {"image_id": 2, "file_name": "322_02.png", "page": 4, "dpi": 300, "bbox": [102, 99, 318, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Schematic example for filtering solvent molecules of the bulk from those inside the cavity. Solvent molecules wi further away from the sphere\u2019s centre S than their nearest protein molecule pi are skipped as they are on the outer side of the protein and thus probably part of the bulk. ", "caption_bbox": [59, 263, 360, 337]}, {"image_id": 3, "file_name": "322_03.png", "page": 4, "dpi": 300, "bbox": [411, 665, 679, 827], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Properties mapped to the pathlines: The time within the trajectory is represented by a colour gradient from red (start of the trajectory) over yellow and cyan, to blue (end of the trajectory). An additional luminance ramp en- codes the molecule\u2019s direction of motion as can be seen in the cut-out. The velocity is encoded in the saturation. Fast pathlines (on the right side) are shown in gray. ", "caption_bbox": [391, 837, 692, 941]}, {"image_id": 4, "file_name": "322_04.png", "page": 5, "dpi": 300, "bbox": [58, 260, 347, 376], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The original pathlines are smoothed (right) to em- phasise the principal directions of motion normally obscured by the molecule\u2019s chaotic small-scale fluctuations (left). ", "caption_bbox": [59, 387, 360, 430]}, {"image_id": 5, "file_name": "322_05.png", "page": 5, "dpi": 300, "bbox": [390, 98, 682, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Clustering of the pathlines: vertices wi (blue) along a pathline pi with low enough velocity values form a spherical cluster ci,n (marked in light blue). Those clusters overlapping define a new major cluster c0k (green) connect- ing these pathlines. Finally, all paths (red) connecting the same major clusters are merged to a single directed edge between these two clusters. ", "caption_bbox": [391, 263, 692, 367]}, {"image_id": 6, "file_name": "322_06.png", "page": 6, "dpi": 300, "bbox": [90, 201, 331, 607], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Abstraction of the pathlines. The upper figure shows all pathlines. The middle figure shows the vertices of all pathlines, coloured based on the detected clusters of slower motion. Positions of conserved water correspond to the larger clusters. The lower figure shows the extracted principal paths. ", "caption_bbox": [59, 618, 360, 707]}, {"image_id": 7, "file_name": "322_07.png", "page": 6, "dpi": 300, "bbox": [428, 443, 656, 812], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: 5ns trajectory (5000 frames) compared to 50ns trajectory (50000 frames). The shorter trajectory in the up- per image could be evaluated manually using existing tools. However, results gained on such short datasets must be judged with care, since interesting values depend on the fre- quency of the water exchange. The 50ns trajectory, shown in the lower image, on the other hand is far too cluttered and too complex to be efficiently evaluated with existing tools. ", "caption_bbox": [391, 822, 692, 942]}, {"image_id": 8, "file_name": "322_08.png", "page": 7, "dpi": 300, "bbox": [96, 546, 325, 846], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Structure extraction of solvent paths. The upper image shows all water molecule pathlines. The lower image shows the extracted main solvent paths. The time frame is mapped to a colour gradient from yellow (start of the trajec- tory) to blue (end of the trajectory). ", "caption_bbox": [59, 868, 360, 942]}], "323": [{"image_id": 0, "file_name": "323_00.png", "page": 1, "dpi": 300, "bbox": [392, 666, 692, 888], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: With current highlighting techniques, short streets near origin or destination are not visible and require multi- ple zooming and panning steps as well as multiple printouts. ", "caption_bbox": [391, 898, 692, 941]}, {"image_id": 1, "file_name": "323_01.png", "page": 2, "dpi": 300, "bbox": [69, 326, 354, 572], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The same route from Figure 1 using LineDrive which depicts a route by a sequence of streets with street names, lengths and turning directions. This works well in the USA where routes are mainly described by numbers, while Europeans often navigate by town names on traffic signs. ", "caption_bbox": [59, 590, 360, 664]}, {"image_id": 2, "file_name": "323_02.png", "page": 2, "dpi": 300, "bbox": [441, 581, 643, 863], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A hand-drawn sketch of a street network accord- ing to our design principles. It allows navigation from node to node by using town names on traffic signs, but also shows cities left and right of the path to support orientation. ", "caption_bbox": [391, 873, 692, 932]}, {"image_id": 3, "file_name": "323_03.png", "page": 3, "dpi": 300, "bbox": [83, 75, 378, 416], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An overview of the system stages. After the context engine extracted the important information, heuristics rate their importance and build a hierarchy that is used by the scaling and rendering engine for generating our maps. ", "caption_bbox": [59, 427, 360, 486]}, {"image_id": 4, "file_name": "323_04.png", "page": 4, "dpi": 300, "bbox": [413, 518, 672, 601], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: One example of an importance rating heuristic: If a village is passed, and the combined length of streets inside the village is less than 2 miles, the number of streets inside the village is 3 or less, and the maximum turning angle from street to street is less than 20 degrees, then the small village is passed almost straight through. The node (a) is tagged \u2019unimportant\u2019 and replaced by a simplified view (b). ", "caption_bbox": [391, 612, 692, 716]}, {"image_id": 5, "file_name": "323_05.png", "page": 4, "dpi": 300, "bbox": [60, 446, 360, 609], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Showing the major cities in the vicinity of the route facilitates orientation and navigation on the highway net- work, as the traffic signs give a permanent feedback to the driver. In our system, the user can use a slider to specify the radius in which the cities along the route are displayed. ", "caption_bbox": [59, 624, 360, 698]}, {"image_id": 6, "file_name": "323_06.png", "page": 4, "dpi": 300, "bbox": [375, 75, 671, 202], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A set of heuristics determines whether a landmark is important or not. So far, only gasoline stations have been added as landmarks, but other types can easily be added. ", "caption_bbox": [391, 212, 692, 255]}, {"image_id": 7, "file_name": "323_07.png", "page": 4, "dpi": 300, "bbox": [58, 74, 378, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: In order to display the nodes, we use convex hulls instead of the exact geographic shape of the town boundaries as they symbolize the nodes in a space efficient and easy to understand way. The driver can navigate large parts of the map by following the traffic signs from town to town, without the necessity to rely only on street names. The curved shape of the roads also gives additional feedback to the driver. ", "caption_bbox": [59, 321, 360, 425]}, {"image_id": 8, "file_name": "323_08.png", "page": 5, "dpi": 300, "bbox": [375, 74, 693, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The length of the streets to be rendered depends on the amount of context information that has to be dis- played. Cross streets that leave left and right within a thresh- old are considered intersections and only need one space unit (D). A space-saving algorithm computes the minimum space that is required for each combination. ", "caption_bbox": [391, 271, 692, 360]}, {"image_id": 9, "file_name": "323_09.png", "page": 5, "dpi": 300, "bbox": [61, 144, 358, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: After evaluating the importance of nodes and edges, an algorithm determines which street segments are suitable for rendering the maps. The decision depends on the importance of a node or edge, length of the street and street type (from 1 to 5, see section 3.4). The bottom line represents the streets that are finally used by the rendering engine. ", "caption_bbox": [59, 309, 360, 398]}, {"image_id": 10, "file_name": "323_10.png", "page": 6, "dpi": 300, "bbox": [395, 335, 692, 616], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: The computation speed if false intersections oc- curred by the distortion algorithm can be significantly im- proved by using minimum bounding rectangles for each street. If two bounding rectangles do not overlap, there can also be no intersection of the streets that are enclosed. ", "caption_bbox": [391, 626, 692, 700]}, {"image_id": 11, "file_name": "323_11.png", "page": 6, "dpi": 300, "bbox": [58, 74, 378, 372], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: This image shows the final result of a route map created by our system. In contrast to existing mapping styles, the network graph metaphor allows navigation by \u2018hopping\u2018 from town to town. The individual scale factor for each street allows to see all streets clearly visible on a single page, so only one printout is required. ", "caption_bbox": [59, 383, 360, 472]}, {"image_id": 12, "file_name": "323_12.png", "page": 7, "dpi": 300, "bbox": [392, 386, 692, 554], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: One effect of linear scaling is that regardless of any vertical and horizontal distortion ratio a street will never be able to leave its quadrant. A street heading north- east remains between north and east, with extreme angles being unlikely so the general direction is maintained. ", "caption_bbox": [391, 564, 692, 638]}, {"image_id": 13, "file_name": "323_13.png", "page": 7, "dpi": 300, "bbox": [65, 74, 693, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: The scaling engine allows a seamless interactive scaling from the original route map to our route map design. The system performs a seamless transition into a context-based network-oriented layout where all streets are clearly visible, and outlines the boundaries of towns in order to allow a navigation from node to node by following the road signs with town names. ", "caption_bbox": [59, 305, 692, 348]}, {"image_id": 14, "file_name": "323_14.png", "page": 7, "dpi": 300, "bbox": [60, 447, 358, 522], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Preserving intersections at the correct positions during the distortion process can be difficult. We solve this by redefining the affinity of street segments. As a result, each of the bounding rectangles can be distorted independently with the intersection remaining at the correct position. ", "caption_bbox": [59, 533, 360, 607]}, {"image_id": 15, "file_name": "323_15.png", "page": 8, "dpi": 300, "bbox": [58, 74, 378, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: The shape of a street can give the driver a valu- able feedback if he is still driving on the correct road if the map reflects a characteristic curved path of a road. Our ap- plication allows to adjust the simplification rate individually. ", "caption_bbox": [59, 264, 360, 323]}], "324": [{"image_id": 0, "file_name": "324_00.png", "page": 2, "dpi": 300, "bbox": [58, 98, 694, 577], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: This is the overview of the entire system, including the map view (top right), temporal view (bottom right), entity view (top left) and activities panel (middle left). ", "caption_bbox": [59, 603, 692, 631]}, {"image_id": 1, "file_name": "324_01.png", "page": 4, "dpi": 300, "bbox": [390, 147, 694, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Global distribution of incidents are shown colored by attack type. The locations of the incidents show that at- tacks in North Africa occur largely along the coast and the Nile River. ", "caption_bbox": [391, 335, 692, 394]}, {"image_id": 2, "file_name": "324_02.png", "page": 4, "dpi": 300, "bbox": [400, 430, 684, 562], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Shape Gallery (left) shows activity patterns for in- dividual group. Activities of a terrorist group (right)are con- nected by lines to indicate the temporal sequence of events. The yellow circles represent the number of casualties per in- cident. The overall shape indicates that this group is mainly domestic but has one significant geographical outlier. ", "caption_bbox": [391, 573, 692, 662]}, {"image_id": 3, "file_name": "324_03.png", "page": 5, "dpi": 300, "bbox": [58, 98, 694, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Regional ThemeRiver: this view contains both dimensional information and temporal information, indicating global terrorism trends from 1971 to 1992. Here it shows regional distributions, as labeled. ", "caption_bbox": [59, 238, 692, 266]}, {"image_id": 4, "file_name": "324_04.png", "page": 5, "dpi": 300, "bbox": [390, 302, 694, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Activities Panel: This is an interactive filtering panel, which uses dimensions in the GTD to filter and color events in the other views. ", "caption_bbox": [391, 397, 692, 441]}, {"image_id": 5, "file_name": "324_05.png", "page": 5, "dpi": 300, "bbox": [393, 595, 692, 659], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Entity view: The Terrorist Name tab (left) lists 2404 terrorist groups extracted from the GTD, while the In- termediate Results tab shows suggestions for possible terror- ist groups. The Shoebox (right) is a container for collections of user-selected terrorist groups, providing the user an easy way to compare different terrorist groups. ", "caption_bbox": [391, 670, 692, 759]}, {"image_id": 6, "file_name": "324_06.png", "page": 6, "dpi": 300, "bbox": [58, 379, 362, 600], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: In this example, edges indicate that Organization A is an active international terrorist group, with a wide at- tack range. The highlighted city illustrates a significant out- lier in Argentina in 1994. ", "caption_bbox": [59, 626, 360, 685]}, {"image_id": 7, "file_name": "324_07.png", "page": 6, "dpi": 300, "bbox": [390, 200, 694, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: This image depicts changes in Organization A\u2019s attack methods over the last 17 years, which shifted from kidnappings to a mix of bombings and facility attacks, to almost entirely facility attacks. Note that the GTD does not contain data for the year 1993 [LD07]. ", "caption_bbox": [391, 272, 692, 346]}, {"image_id": 8, "file_name": "324_08.png", "page": 7, "dpi": 300, "bbox": [58, 98, 362, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: (Top) This image indicates that the Organization B was an active domestic terrorist group that was responsible for more than a thousand incidents within the Philippines. (Bottom) This result shows changes in Organization B\u2019s at- tack frequency during the time period of the dataset. Though it was very active in the late \u201980s, it suddenly disappeared in 1992. ", "caption_bbox": [59, 350, 360, 455]}], "325": [{"image_id": 0, "file_name": "325_00.png", "page": 2, "dpi": 300, "bbox": [58, 104, 688, 284], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: We extend the information visualization pipeline by a process (red) that iteratively refines the instance of a classifier model as a reaction to user input. An iteration starts with the selection of a training classification, proceeds with the update of the classifier and ends with the combination of the aggregate data and the classifier mapped into the same visualization space. The motivation of this approach is to allow an easy match between the visual/mental model and the formal model for the classification. The classifier can be used to compare the relevance of attributes in the search for hidden dependencies in a multi-dimensional dataset. ", "caption_bbox": [58, 296, 691, 385]}, {"image_id": 1, "file_name": "325_01.png", "page": 4, "dpi": 300, "bbox": [90, 98, 660, 257], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: This image sketches the visual mapping of the data-(hyper-)cube in the modified Karnaugh-Veitch Layout. Following the data aggregation process (left), the cube is sliced along one dimension and its partitioning. The slices are laid out along the horizontal and vertical axes (right). As the cube looses one dimension by this process, it can be repeated until all dimensions are mapped onto two-dimensional space. The information about the spatial coherency in the higher dimensions is not completely lost: The visualization exploits the ability of the human eyes to track different spatial frequencies, each of which represents one of the original dimensions. In this example, the new attribute (from third dimension) is mapped to a horizontal frequency of four, denoting that rectangles having that distance are closely related (in terms of the third attribute). ", "caption_bbox": [58, 270, 691, 375]}, {"image_id": 2, "file_name": "325_02.png", "page": 4, "dpi": 300, "bbox": [390, 410, 694, 565], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: This image shows the three types of aggregate data currently supported in the KVMap. Every rectangle refers to a partition: a subset of data items sharing a specific pro- file defined with independent attributes. Figure (a) shows the relative distribution of all items (ES ), red indicating common profiles, light grey indicating rare profiles and white indicat- ing empty partitions. Figure (b) shows the relative distribu- tion of items belonging to the target set defined by a depen- dent attribute (ET ). The statistical correlation coefficient (c) combines the former two values, with red and yellow indi- cating positive and blue and green negative correlations. ", "caption_bbox": [391, 575, 692, 740]}, {"image_id": 3, "file_name": "325_03.png", "page": 5, "dpi": 300, "bbox": [79, 104, 344, 378], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The entropy measures the discriminating value of an attribute partitioning. The histograms denote the distri- bution of S (blue) and its subset Tk (yellow) along the value- range of an attribute. Individual partitions are shown in the child nodes. Figure a) shows a good discrimination (low en- tropy) of the subset Tk in the individual partitions, while b) shows a bad discrimination. An optimal decision tree mini- mizes the entropy in its leaf nodes with as little inner nodes (decisions) as possible. ", "caption_bbox": [58, 395, 359, 530]}, {"image_id": 4, "file_name": "325_04.png", "page": 5, "dpi": 300, "bbox": [390, 98, 694, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: This image shows a sample using the three vi- sual attributes brightness (b), blur (c) and convexity (d). To compare the three visualizations the same pattern (a) is used with the same partitions selected. The attributes have different advantages and disadvantages: Brightness has its strengths when many dimensions and partitions are shown and the rectangles are small, but it obscures the selected pattern more than the other attributes. Blur has a small vi- sual range; only two or three different degrees of blur can be distinguished at a glance. The three attributes can easily be switched, but convexity appears to be the attribute of choice. ", "caption_bbox": [391, 309, 692, 474]}, {"image_id": 5, "file_name": "325_05.png", "page": 7, "dpi": 300, "bbox": [390, 446, 694, 592], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: After the refinement and definition of the formal model, it can easily be exposed for further processing or communication. We use this different perspective for pattern understanding. Colours in the tree indicate the fraction of elements in that set belonging to Tk (from green, via yellow to red). A user can manually modify and prune the tree and indicate his finalized decision scheme for T by selecting the corresponding leafnodes (blue crosses). ", "caption_bbox": [391, 603, 692, 723]}, {"image_id": 6, "file_name": "325_06.png", "page": 7, "dpi": 300, "bbox": [58, 98, 694, 355], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: This image shows the results after 4 (a), 9 (b) and 20 (c) refinement cycles. Each cycle corresponds to one partition selected by the user, which is colored black. The information about the partitions that are (more or less) likely to complement the visual pattern is blended with the original color using the convexity attribute. ", "caption_bbox": [58, 366, 691, 410]}], "326": [{"image_id": 0, "file_name": "326_00.png", "page": 4, "dpi": 300, "bbox": [390, 98, 694, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Changes to the university campus between 2002 and 2003. Green models show new construction while red models show demolition/tree clearing. 2004 building foot- prints are in black. The selected building (orange) was under construction, only filling half the future 2004 footprint. ", "caption_bbox": [391, 319, 692, 393]}, {"image_id": 1, "file_name": "326_01.png", "page": 4, "dpi": 300, "bbox": [390, 418, 694, 600], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Examining a new residential development under construction. The selected (orange) volume shown is an area where the earth has been regraded to allow the level con- struction of a new road. We can also see build up of earthen walls (green, lower-right) on either side of the large inter- state highway (red), as sonic barriers against traffic noise. ", "caption_bbox": [391, 611, 692, 700]}, {"image_id": 2, "file_name": "326_02.png", "page": 5, "dpi": 300, "bbox": [58, 311, 362, 503], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A view of the downtown area in hybrid mode. Change models of new construction are rendered in green and change models of buildings that have been demolished are rendered in red. ", "caption_bbox": [58, 529, 359, 588]}, {"image_id": 3, "file_name": "326_03.png", "page": 5, "dpi": 300, "bbox": [58, 99, 694, 173], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Shown here is a new residential development at increasingly further camera distances. As the camera moves further away, individual models gradually begin to glow to emphasize their presence, and are ultimately replaced by semi-transparent \u2019splats\u2019 which maintain near-constant screen-size regardless of distance. Notice that at the closest view (left) the building models are individually presented, and once the camera has moved significantly further away, the entire development is represented as a single entity (right); a seamless transition (middle two images) is presented at distances in between to avoid popping. ", "caption_bbox": [58, 199, 691, 273]}, {"image_id": 4, "file_name": "326_04.png", "page": 6, "dpi": 300, "bbox": [58, 99, 362, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Shown here are the regions selected in the heat map generated by various semantic filters. The \"trees\" filter produces the green region, \"residential\" - orange, \"commer- cial\" - yellow, \"grading\" - brown, and and a user defined region in black. Notice that the majority of detected changes fall within the \"trees\" filter, and that man made changes tend to be on the outskirts of the distribution; a logarithmic in- tensity function is used by default to allow these areas to be better discerned within the heat map. ", "caption_bbox": [58, 403, 359, 538]}, {"image_id": 5, "file_name": "326_05.png", "page": 7, "dpi": 300, "bbox": [58, 99, 692, 269], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A is the distribution of changes for a region on the edge of the city, under transition from rural to suburban. B is the distribution of changes for a region in the center of the city, which is an established urban and suburban area. C is the difference of the two, showing the wider distribution of changes, especially in the height dimension, in the center city region. ", "caption_bbox": [58, 294, 691, 338]}, {"image_id": 6, "file_name": "326_06.png", "page": 7, "dpi": 300, "bbox": [58, 360, 694, 595], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Shown here are the urban legibility regions at increasingly distant camera locations.", "caption_bbox": [136, 621, 611, 634]}, {"image_id": 7, "file_name": "326_07.png", "page": 8, "dpi": 300, "bbox": [58, 99, 694, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: By opting to view only destruction changes, and creating a custom filter on the heat map to show only changes above a certain area and height range, we can easily see in the 3D view, the red change models showing both the deforestation (left and center) due to clear cutting for construction, and the volumes of rock removed at a granite quarry (upper right). ", "caption_bbox": [58, 328, 691, 372]}], "327": [{"image_id": 0, "file_name": "327_00.png", "page": 5, "dpi": 300, "bbox": [90, 75, 378, 362], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Number of changed pixels over time. The plot shows the significant difference between the two algorithms. ", "caption_bbox": [57, 364, 356, 391]}, {"image_id": 1, "file_name": "327_01.png", "page": 5, "dpi": 300, "bbox": [75, 442, 630, 874], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Two Variable Resolution Density Displays (16 CPUs x 8 Servers)", "caption_bbox": [206, 881, 506, 892]}, {"image_id": 2, "file_name": "327_02.png", "page": 6, "dpi": 300, "bbox": [402, 640, 662, 805], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Number of changed pixels. It can be clearly seen that the Complete Shift algorithm with a pixel size of 2x2 results in a very high number of changed pixels. Note that the blue curve linearly increases with the very steep increase, starting around time step 1000 and is two orders of magnitude larger than our Variable Resolution Display. ", "caption_bbox": [387, 808, 686, 891]}, {"image_id": 3, "file_name": "327_03.png", "page": 6, "dpi": 300, "bbox": [390, 220, 636, 407], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Number of pixels that are used to display information. Our Variable Resolution Display technique is able to quickly fill the display and then oscillates at high levels. ", "caption_bbox": [387, 414, 686, 469]}], "328": [{"image_id": 0, "file_name": "328_00.png", "page": 3, "dpi": 300, "bbox": [405, 96, 679, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The network window shows the transcription net- work and gene expression time series. The data shown cor- respond to a part of the gene regulatory network of the bac- terium B. subtilis, and an expression ratio time series of four time points. Neighbor highlighting (of the gene ccpA) assists the user in understanding network structure. The interaction type is mapped to a color: red for inhibition, green for acti- vation, and grey for other cases. ", "caption_bbox": [391, 310, 692, 430]}, {"image_id": 1, "file_name": "328_01.png", "page": 4, "dpi": 300, "bbox": [58, 96, 362, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visualization of an expression ratio time series of four time points in the context of a part of the purine metabolism pathway in B. subtilis. ", "caption_bbox": [58, 243, 359, 287]}, {"image_id": 2, "file_name": "328_02.png", "page": 4, "dpi": 300, "bbox": [390, 96, 694, 367], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Part of the active network in B. subtilis at the last time point of a four-point time series. Active nodes and edges are drawn opaque and highlighted. ", "caption_bbox": [391, 377, 692, 421]}, {"image_id": 3, "file_name": "328_03.png", "page": 5, "dpi": 300, "bbox": [390, 96, 694, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Main application window after loading B. subtilis genome, its transcription network, a two time series con- taining gene expression ratios and gene expression levels, respectively. See text for more details of the user interface. ", "caption_bbox": [391, 369, 692, 428]}, {"image_id": 4, "file_name": "328_04.png", "page": 6, "dpi": 300, "bbox": [58, 96, 694, 527], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Active E. coli subnetwork at time point 6; the expression ratios determine the gene box fill colors. The LacI regulon is shown enlarged in the top right corner. There, a standard fill color is used, and the whole time series is shown with the expression glyphs colored by ratio. The genes lacI, lacA, lacY, and lacZ are all upregulated, as is indicated by red-colored expression glyphs, which reveals that the organism adjusts to growing on lactose. ", "caption_bbox": [58, 537, 691, 596]}, {"image_id": 5, "file_name": "328_05.png", "page": 7, "dpi": 300, "bbox": [391, 468, 693, 622], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: There is strong downregulation of the genes in involved in the chemotaxis pathway at time point 16. ", "caption_bbox": [391, 632, 692, 660]}, {"image_id": 6, "file_name": "328_06.png", "page": 7, "dpi": 300, "bbox": [64, 96, 687, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Many genes active at time point 6 are part of the ribosome pathway. The expression ratio at that time point was used to determine the fill color of a gene box. A green color indicates strong downregulation. ", "caption_bbox": [58, 403, 691, 431]}], "329": [{"image_id": 0, "file_name": "329_00.png", "page": 2, "dpi": 300, "bbox": [80, 98, 638, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Fig. (a) is a volume rendering of the original microscopy data. Fig. (b) shows a volume rendering after de-convolution, de-noising, segmentation and floating spine head connection. The arrows in Fig. (b) point to some of the spines on the middle dendrite. The blue arrows indicate clearly identifiable spines. The red arrow points to a more ambiguous case. Fig. (c) shows a surface reconstruction of the dendrites. ", "caption_bbox": [59, 289, 692, 350]}, {"image_id": 1, "file_name": "329_01.png", "page": 4, "dpi": 300, "bbox": [58, 98, 362, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustrative example (in 2-D) of the floating spine head problem and its solution. Fig. (a) shows the neuron im- age after segmentation with floating spine heads and spuri- ous tissue fragments in 3-D. Fig. (b) shows the speed func- tion that controls the level-set evolution. Fig. (c) shows the floating spine head connected to the backbone. ", "caption_bbox": [59, 384, 360, 475]}, {"image_id": 2, "file_name": "329_02.png", "page": 4, "dpi": 300, "bbox": [419, 148, 666, 363], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Fig. (a) shows surface rendering of a dendrite with its 1-D curve-skeleton overlaid in blue. The dendrogram is shown in Fig. (b) with branch chains in red and backbone chains in blue. The original curve-skeleton is in green. ", "caption_bbox": [391, 366, 692, 427]}, {"image_id": 3, "file_name": "329_03.png", "page": 5, "dpi": 300, "bbox": [97, 166, 325, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Morphological criteria for determining the shape class of the dendritic spines. Figure reproduced from [HJT92]. ", "caption_bbox": [59, 343, 360, 389]}, {"image_id": 4, "file_name": "329_04.png", "page": 5, "dpi": 300, "bbox": [61, 459, 362, 814], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The plot of branch chain diameter d versus length l for a mushroom spine. ", "caption_bbox": [59, 822, 360, 852]}, {"image_id": 5, "file_name": "329_05.png", "page": 7, "dpi": 300, "bbox": [97, 98, 655, 570], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualization of spine identification and spine classification probabilities.", "caption_bbox": [164, 574, 583, 589]}], "330": [{"image_id": 0, "file_name": "330_00.png", "page": 1, "dpi": 300, "bbox": [395, 740, 691, 842], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Component arrangements: (a) A histology section of the mouse mammary gland showing several duct cross- sections. (b) Ductal tissue has a concentric arrangement of epithelial cells. (c) Color-mapped 2-pcf feature values. ", "caption_bbox": [390, 853, 691, 914]}, {"image_id": 1, "file_name": "330_01.png", "page": 1, "dpi": 300, "bbox": [58, 310, 378, 627], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Component distributions: A 2D slice of a histol- ogy stained mouse placenta is shown. Tissue layers differ in terms of characteristic microstructural component distribu- tions. ", "caption_bbox": [58, 636, 359, 697]}, {"image_id": 2, "file_name": "330_02.png", "page": 2, "dpi": 300, "bbox": [393, 198, 693, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Component densities: Phase-contrast microscopy images of mutated cell colonies that are rapidly proliferating in culture. Each colony is marked by a dense packing of cells. ", "caption_bbox": [390, 301, 691, 347]}, {"image_id": 3, "file_name": "330_03.png", "page": 3, "dpi": 300, "bbox": [65, 172, 357, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) RGB histograms of the placenta section are shown to be approximately having a normal distribution. (b) Identified component labels of the placenta image shown in Figure 1. (c) Individual cells identified in the clonal colony images from Figure 3a. ", "caption_bbox": [58, 310, 359, 386]}, {"image_id": 4, "file_name": "330_04.png", "page": 3, "dpi": 300, "bbox": [390, 374, 693, 518], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The figure shows four different microstructure en- sembles composed of 2-phase components, namely, phase 0 (black) and phase 1 (white). A plot of the orientation- averaged function P00 k for varying k reveals different char- acteristic signatures. ", "caption_bbox": [390, 529, 691, 605]}, {"image_id": 5, "file_name": "330_05.png", "page": 5, "dpi": 300, "bbox": [390, 141, 693, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) Cropped placenta image with the bound- ary between labyrinth and maternal layer outlined in black, the interface between and labyrinth and spon- giotropoblast marked as white, and glycogen demarcated by gray. (b) Image classification of a single placenta image; Red-spongiotrophoplast. Light gray-glycogen. Light blue- background. Dark blue -labyrinth. ", "caption_bbox": [390, 338, 691, 444]}, {"image_id": 6, "file_name": "330_06.png", "page": 5, "dpi": 300, "bbox": [68, 75, 378, 323], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) A normal RGB rendering of a 3D placenta dataset. (b) The dataset is cropped along two orthogonal planes. Note that the tissue layers and the interface are hard to distinguish. (c) A zoomed section at full resolution with manually marked tissue layers. Visualizations showing the tissue layer intermixing in the labyrinth-spongiotrophoblast interface of (d) normal and (e) mutant mice placenta. (f) Opacity and color transfer function applied on the prob- abilistic volume P to highlight the interface region. Note the presence of bimodal peaks in the histogram from the labyrinth and spongiotrophoblast layers. ", "caption_bbox": [58, 334, 359, 501]}, {"image_id": 7, "file_name": "330_07.png", "page": 6, "dpi": 300, "bbox": [63, 411, 358, 552], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) Raw RGB data showing a duct that manually assembled from 3D slices. (b) The same duct was automati- cally highlighted by using a transfer function. (c) The outer iso-surface of the ductal tissue. ", "caption_bbox": [58, 563, 359, 624]}, {"image_id": 8, "file_name": "330_08.png", "page": 7, "dpi": 300, "bbox": [58, 75, 378, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Sensitivity/specificity values for colony tracking", "caption_bbox": [65, 745, 350, 760]}, {"image_id": 9, "file_name": "330_09.png", "page": 7, "dpi": 300, "bbox": [375, 75, 693, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: (a) 2-pcf evaluated on the first frame shown in Figure 3a. (b) Voronoi segmentation on the 2-pcf mani- fold based on colony boundaries of the preceding frame. (c) Colony segmentations. ", "caption_bbox": [390, 206, 691, 267]}], "331": [{"image_id": 0, "file_name": "331_00.png", "page": 2, "dpi": 300, "bbox": [71, 98, 681, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Parameters of the IHA.", "caption_bbox": [460, 399, 623, 412]}, {"image_id": 1, "file_name": "331_01.png", "page": 2, "dpi": 300, "bbox": [136, 391, 286, 503], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Instantaneous helical axis (IHA) for a moving, rigid body. ", "caption_bbox": [58, 515, 359, 543]}, {"image_id": 2, "file_name": "331_02.png", "page": 4, "dpi": 300, "bbox": [97, 98, 322, 204], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visual encodings for IHA parameters. Left: angu- lar velocity. Right: sliding velocity. ", "caption_bbox": [58, 214, 359, 242]}, {"image_id": 3, "file_name": "331_03.png", "page": 5, "dpi": 300, "bbox": [58, 98, 362, 307], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: View of the IHA extended forward and back- ward in time. The location of the IHA moves up toward the condyles and angular velocity increases during this closing phase of chewing. ", "caption_bbox": [58, 318, 359, 377]}, {"image_id": 4, "file_name": "331_04.png", "page": 5, "dpi": 300, "bbox": [390, 98, 694, 307], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: After selecting a point of interest on the bone (marked with a small cyan sphere), the relative effect of IHA sliding and rotation parameters with respect to this point is visualized on the axes. ", "caption_bbox": [391, 318, 692, 377]}, {"image_id": 5, "file_name": "331_05.png", "page": 6, "dpi": 300, "bbox": [168, 98, 579, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The mandibular foramen and condyle on both the left and right sides are selected to produce plots of distance to the IHA during one jaw closing motion. This analysis is relevant to the hypothesis described in section 5.2. ", "caption_bbox": [58, 264, 691, 292]}, {"image_id": 6, "file_name": "331_06.png", "page": 7, "dpi": 300, "bbox": [200, 98, 552, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The dot product of IHA direction u\u0302 with a user-selected reference axis. Frame 10: The dot product is near minus one, as the jaw rotates open. Frame 30: The motion has reversed, the dot product is near one, the jaw is closing. Frame 50: The IHA is nearly perpendicular to the reference axis while the mandible undergoes lateral movement to grind the food. ", "caption_bbox": [58, 261, 691, 305]}], "332": [{"image_id": 0, "file_name": "332_00.png", "page": 2, "dpi": 300, "bbox": [390, 680, 694, 906], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example of a combined MRI-fMRI visualization rendered with our system. ", "caption_bbox": [391, 916, 692, 944]}, {"image_id": 1, "file_name": "332_01.png", "page": 3, "dpi": 300, "bbox": [93, 71, 693, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Hybrid Mesh and Volume Rendering. Left: A schematic view of the scene. The camera is set to orthographic projection for simplicity, but the presented concepts are equally applicable to perspective projection. The near clipping plane is left out for visual clarity. Right: The scene is split up into six layers. The thick, colored lines on the cortex surface denote the parts of the mesh that are topmost in the framebuffer after the respective layer has been rendered. ", "caption_bbox": [59, 278, 692, 337]}, {"image_id": 2, "file_name": "332_02.png", "page": 4, "dpi": 300, "bbox": [58, 71, 378, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Results for the normal similarity (left) and depth gradient magnitude (right) computations. ", "caption_bbox": [59, 236, 360, 264]}, {"image_id": 3, "file_name": "332_03.png", "page": 4, "dpi": 300, "bbox": [390, 423, 694, 673], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Top: Coloring of the different surface areas. Bot- tom: Combined diffuse light and ambient occlusion shading. 1000 samples per vertex have been used to compute the am- bient occlusion values. ", "caption_bbox": [391, 683, 692, 742]}, {"image_id": 4, "file_name": "332_04.png", "page": 4, "dpi": 300, "bbox": [65, 520, 369, 581], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: We classify pixels into three different categories depending on their position on the cortex surface and the white matter / gray matter boundary. ", "caption_bbox": [59, 597, 360, 640]}, {"image_id": 5, "file_name": "332_05.png", "page": 4, "dpi": 300, "bbox": [70, 667, 352, 745], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Left: Pixel categories stored when rendering the lower surface. Right: The result of the edge detection on the inner two categories. ", "caption_bbox": [59, 760, 360, 803]}, {"image_id": 6, "file_name": "332_06.png", "page": 5, "dpi": 300, "bbox": [375, 71, 694, 323], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) When using the FreeSurfer cortex segmen- tation directly, the output suffers from the low spatial reso- lution of the volume texture. (b) Expanded cortex segmen- tation. (c) Same as (b), except the output is confined to the actual gray matter cortex area using the stored pixel cate- gories from Figure 5. ", "caption_bbox": [391, 341, 692, 430]}, {"image_id": 7, "file_name": "332_07.png", "page": 5, "dpi": 300, "bbox": [58, 180, 362, 352], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) The clipping plane introduces banding arti- facts in the display of activation areas. (b) When using the soft clipping approach, the artifacts disappear. ", "caption_bbox": [59, 362, 360, 405]}, {"image_id": 8, "file_name": "332_08.png", "page": 6, "dpi": 300, "bbox": [390, 350, 694, 549], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Only the currently selected area is rendered with full saturation. This allows the user to focus on a specific part of the data. ", "caption_bbox": [391, 559, 692, 602]}, {"image_id": 9, "file_name": "332_09.png", "page": 6, "dpi": 300, "bbox": [61, 239, 360, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Intuitive Clipping Plane Rotation. (a) o denotes the world origin, s is the scene center and r is the clipping plane rotation center that is computed by projecting s onto the clipping plane. (b) Once a rotation is initiated, the rota- tion center r is held constant. When the rotation stops, the rotation center is recomputed (r0 ). ", "caption_bbox": [59, 390, 360, 479]}, {"image_id": 10, "file_name": "332_10.png", "page": 6, "dpi": 300, "bbox": [375, 72, 660, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: fMRI volume segmentation results for different                                                          1 1 pre-flood heights. From left to right, top to bottom: 0, 50 , 25      1 and 5 of the maximal voxel intensity is used. ", "caption_bbox": [391, 287, 692, 333]}, {"image_id": 11, "file_name": "332_11.png", "page": 6, "dpi": 300, "bbox": [58, 495, 362, 701], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Different clipping plane orientations reveal dif- ferent parts of the cortex folding structure. ", "caption_bbox": [59, 712, 360, 740]}, {"image_id": 12, "file_name": "332_12.png", "page": 7, "dpi": 300, "bbox": [58, 662, 362, 883], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Cortex Area Labels are displayed for orientation purposes. Only one brain hemisphere is rendered to allow for the inspection of otherwise occluded cortex parts. ", "caption_bbox": [59, 894, 360, 937]}, {"image_id": 13, "file_name": "332_13.png", "page": 7, "dpi": 300, "bbox": [58, 369, 362, 601], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Both a surface point and an activation area are selected. A ruler is used to show the distance (in mm). ", "caption_bbox": [59, 612, 360, 640]}, {"image_id": 14, "file_name": "332_14.png", "page": 7, "dpi": 300, "bbox": [58, 72, 378, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Surface point selection. The surface point moves 1 pixel to the right from (a) to (b). In (a), it lies on top of the gyrus, in (b), it has \u201cdescended\u201d into the sulcus. ", "caption_bbox": [59, 302, 360, 345]}], "333": [{"image_id": 0, "file_name": "333_00.png", "page": 2, "dpi": 300, "bbox": [58, 72, 656, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Outline of the presented semantics driven rendering framework: The different types of semantics guide the generation of the interactive illustration. ", "caption_bbox": [59, 361, 692, 389]}, {"image_id": 1, "file_name": "333_01.png", "page": 3, "dpi": 300, "bbox": [407, 321, 673, 607], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The fuzzy logic rule base is parsed and trans- lated into shader code on the CPU. Membership functions and pre-calculated fuzzy logic functions are encoded in 1D texture arrays. The GPU makes use of the generated shader program and the texture arrays to perform interactive se- mantics driven illustrative rendering. ", "caption_bbox": [391, 612, 692, 701]}, {"image_id": 2, "file_name": "333_02.png", "page": 4, "dpi": 300, "bbox": [59, 455, 359, 676], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Shader code generation for the evaluation of an- tecedents. An expression tree and the corresponding shader code are generated from a simple rule. ", "caption_bbox": [59, 688, 360, 732]}, {"image_id": 3, "file_name": "333_03.png", "page": 5, "dpi": 300, "bbox": [418, 99, 661, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Example for the compositing of two styles is shown. The exemplary sample has a value of 0.8 for style a and a value of 0.4 for style b. The corresponding spheres are outlined in yellow. ", "caption_bbox": [391, 286, 692, 345]}, {"image_id": 4, "file_name": "333_04.png", "page": 6, "dpi": 300, "bbox": [89, 534, 332, 623], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Example renderings using different values of the flatness parameter. The inner cube has higher priority and is therefore shown for a flatness parameter greater than zero. ", "caption_bbox": [59, 636, 360, 680]}, {"image_id": 5, "file_name": "333_05.png", "page": 6, "dpi": 300, "bbox": [58, 72, 378, 202], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The flat rendering mode favors samples of higher priority during ray casting. The yellow line depicts a view- ing ray. Along the ray common compositing is done until a region of higher priority is reached. The composited color is deemphasized according to the flatness parameter. ", "caption_bbox": [59, 213, 360, 287]}, {"image_id": 6, "file_name": "333_06.png", "page": 6, "dpi": 300, "bbox": [375, 74, 677, 473], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Rendering of the visible human dataset. A slice plane of the histological data is shown. The CT-data is used for the volume rendering providing the context for the slice plane. ", "caption_bbox": [391, 485, 692, 544]}, {"image_id": 7, "file_name": "333_07.png", "page": 7, "dpi": 300, "bbox": [87, 106, 329, 494], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The mouse cursor defines the user focus. Depend- ing on the user focus the illustrative rendering is altered. ", "caption_bbox": [59, 498, 360, 526]}, {"image_id": 8, "file_name": "333_08.png", "page": 8, "dpi": 300, "bbox": [58, 72, 628, 420], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Rendering of a CT-scan of a human leg. The distance to the slicing plane influences the rendering styles and the flatness parameter. The left rendering shows the flat rendering mode fully applied ignoring the spatial relations. ", "caption_bbox": [59, 428, 692, 456]}], "334": [{"image_id": 0, "file_name": "334_00.png", "page": 2, "dpi": 300, "bbox": [391, 677, 693, 857], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Sphere-Hemisphere parameterization of the light field. The volume object is enclosed in the blue bounding sphere. Virtual cameras are positioned at the vertices of the camera sphere (green). Each camera is recording the oppos- ing hemisphere. ", "caption_bbox": [391, 868, 692, 942]}, {"image_id": 1, "file_name": "334_01.png", "page": 3, "dpi": 300, "bbox": [58, 74, 693, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Seven image samples taken for a spherical light field with 162 cameras. Each image represents a parabolic mapping of the hemisphere for color (top row) and depth (bottom row). ", "caption_bbox": [58, 301, 691, 329]}, {"image_id": 2, "file_name": "334_02.png", "page": 5, "dpi": 300, "bbox": [58, 74, 694, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Multi light field composed of different layers generated from the CT angiography data set: Separate light fields for bone/vessels, skin and brain were generated. The individual layers are depth sorted at pixel level during compositing. The user may interactively adjust the transparency of different layers. Light Fields generated fully automatically from a slice-based volume renderer using semantics described in [RSKK06] ", "caption_bbox": [58, 296, 691, 355]}, {"image_id": 3, "file_name": "334_03.png", "page": 5, "dpi": 300, "bbox": [420, 788, 663, 887], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Odd-even merge-sorting network for eight values. Arrows represent compare-and-swap operations. For sorting four values only the blue arrows are necessary. ", "caption_bbox": [391, 898, 692, 942]}, {"image_id": 4, "file_name": "334_04.png", "page": 6, "dpi": 300, "bbox": [58, 74, 378, 134], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Light field data sets are generated separately for different ray segments. ", "caption_bbox": [58, 145, 359, 173]}, {"image_id": 5, "file_name": "334_05.png", "page": 6, "dpi": 300, "bbox": [58, 635, 362, 841], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Different layers generated from the chameleon data set (5123 ,16 bit): High-quality isosurface of the skin (left), Transparent skin with soft tissue and scattering (mid- dle), bone structures isosurface (right). All renderings were illuminated with an environment cube map and an ambient occlusion term for soft shadows. ", "caption_bbox": [58, 853, 359, 942]}, {"image_id": 6, "file_name": "334_06.png", "page": 7, "dpi": 300, "bbox": [59, 74, 693, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Evaluation of the light field data structure for different camera resolutions and texture compression schemes for source images of 512 \u00d7 512. ", "caption_bbox": [58, 575, 691, 605]}], "335": [{"image_id": 0, "file_name": "335_00.png", "page": 2, "dpi": 300, "bbox": [390, 215, 694, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Code structure visualization pipeline", "caption_bbox": [422, 324, 660, 337]}, {"image_id": 1, "file_name": "335_01.png", "page": 3, "dpi": 300, "bbox": [59, 303, 362, 652], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visualizing code evolution: source code (top), matched trees (middle), and visualization layout (bottom). ", "caption_bbox": [58, 667, 359, 695]}, {"image_id": 2, "file_name": "335_02.png", "page": 4, "dpi": 300, "bbox": [60, 592, 362, 782], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Code-flow tube design: a) shaded; b) textured", "caption_bbox": [68, 792, 350, 805]}, {"image_id": 3, "file_name": "335_03.png", "page": 4, "dpi": 300, "bbox": [186, 99, 567, 546], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparison: original method (left) and improved code flow visualization (right)", "caption_bbox": [148, 556, 602, 569]}, {"image_id": 4, "file_name": "335_04.png", "page": 5, "dpi": 300, "bbox": [85, 98, 335, 373], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Structure tracking. Flow graph edges are green, AST edges are blue. Red nodes indicate a tracked code flow. ", "caption_bbox": [58, 383, 359, 412]}, {"image_id": 5, "file_name": "335_05.png", "page": 8, "dpi": 300, "bbox": [58, 100, 694, 793], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A complex example of events of interest visualized using code flows", "caption_bbox": [181, 803, 569, 816]}], "336": [{"image_id": 0, "file_name": "336_00.png", "page": 2, "dpi": 300, "bbox": [428, 373, 653, 648], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: TimeRadarTree of a sequence of graphs.", "caption_bbox": [414, 662, 669, 675]}, {"image_id": 1, "file_name": "336_01.png", "page": 2, "dpi": 300, "bbox": [392, 215, 692, 325], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Node-link diagrams of a sequence of graphs.", "caption_bbox": [403, 336, 680, 349]}, {"image_id": 2, "file_name": "336_02.png", "page": 2, "dpi": 300, "bbox": [58, 72, 378, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Node-link diagram of a graph.", "caption_bbox": [106, 199, 312, 212]}, {"image_id": 3, "file_name": "336_03.png", "page": 2, "dpi": 300, "bbox": [109, 485, 312, 775], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: TimeRadarTree of a single graph.", "caption_bbox": [98, 786, 319, 799]}, {"image_id": 4, "file_name": "336_04.png", "page": 3, "dpi": 300, "bbox": [155, 201, 264, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Node-link diagram of a compound graph.", "caption_bbox": [79, 364, 340, 377]}, {"image_id": 5, "file_name": "336_05.png", "page": 3, "dpi": 300, "bbox": [375, 72, 693, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Node-link diagrams of a sequence of compound graphs. ", "caption_bbox": [391, 300, 692, 328]}, {"image_id": 6, "file_name": "336_06.png", "page": 3, "dpi": 300, "bbox": [446, 369, 637, 565], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: TimeRadarTree of a sequence of compound graphs. ", "caption_bbox": [391, 577, 692, 605]}, {"image_id": 7, "file_name": "336_07.png", "page": 3, "dpi": 300, "bbox": [109, 405, 311, 612], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: TimeRadarTree of a compound graph.", "caption_bbox": [87, 624, 331, 637]}, {"image_id": 8, "file_name": "336_08.png", "page": 3, "dpi": 300, "bbox": [491, 821, 596, 918], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Node-link diagram of a weighted graph.", "caption_bbox": [414, 929, 668, 942]}, {"image_id": 9, "file_name": "336_09.png", "page": 4, "dpi": 300, "bbox": [58, 72, 378, 279], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: TimeRadarTree of a weighted graph.", "caption_bbox": [87, 290, 330, 303]}, {"image_id": 10, "file_name": "336_10.png", "page": 4, "dpi": 300, "bbox": [401, 591, 689, 883], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: A Comparison: Soccer matches of national teams in Central Europe. ", "caption_bbox": [391, 893, 692, 921]}, {"image_id": 11, "file_name": "336_11.png", "page": 5, "dpi": 300, "bbox": [58, 72, 693, 726], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: A Comparison: Soccer matches between national teams of Central Europe and South America.", "caption_bbox": [109, 743, 642, 756]}, {"image_id": 12, "file_name": "336_12.png", "page": 6, "dpi": 300, "bbox": [58, 72, 378, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Soccer matches of national teams in the whole world between 1992 and 2005. ", "caption_bbox": [58, 405, 359, 433]}, {"image_id": 13, "file_name": "336_13.png", "page": 6, "dpi": 300, "bbox": [375, 74, 672, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: The first 10000 triplets of the gene sequence of a salmonella in a stacked view. ", "caption_bbox": [391, 393, 692, 421]}, {"image_id": 14, "file_name": "336_14.png", "page": 7, "dpi": 300, "bbox": [58, 74, 378, 368], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Commonly checked-in files of a part of the JEDIT Open Source Project. ", "caption_bbox": [58, 379, 359, 407]}, {"image_id": 15, "file_name": "336_15.png", "page": 7, "dpi": 300, "bbox": [58, 431, 362, 714], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Exported fuel of the worlds countries in thousand dollars. ", "caption_bbox": [58, 725, 359, 753]}], "337": [{"image_id": 0, "file_name": "337_00.png", "page": 2, "dpi": 300, "bbox": [375, 72, 694, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A portion of a reference trace (left) and its visual- ization. The access pattern is stride-1 in region v1 (top), and stride-2 in region v2 (bottom). ", "caption_bbox": [391, 281, 692, 325]}, {"image_id": 1, "file_name": "337_01.png", "page": 2, "dpi": 300, "bbox": [58, 71, 378, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Screenshot of the Memory Trace Visualizer.", "caption_bbox": [74, 296, 343, 309]}, {"image_id": 2, "file_name": "337_02.png", "page": 3, "dpi": 300, "bbox": [375, 71, 694, 205], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A single memory region visualized as a linear se- quence in memory (right) and as a 2D matrix (left). The read and write accesses are indicated by coloring the region line cyan or orange. Corresponding cache hits and misses are displayed in blue and red. Fading access lines indicate the passage of time. ", "caption_bbox": [391, 216, 692, 305]}, {"image_id": 3, "file_name": "337_03.png", "page": 4, "dpi": 300, "bbox": [58, 490, 359, 687], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Left: A visualization of the entire process address space. Right: A single memory region and the cache (labeled L1 and L2). ", "caption_bbox": [58, 697, 359, 741]}, {"image_id": 4, "file_name": "337_04.png", "page": 5, "dpi": 300, "bbox": [58, 72, 378, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The source code corresponding to the current memory access is highlighted, providing a direct relation- ship between memory access and source code. ", "caption_bbox": [58, 290, 359, 334]}, {"image_id": 5, "file_name": "337_05.png", "page": 5, "dpi": 300, "bbox": [375, 71, 694, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The cache event map provides a global view of the cache simulation by showing the cache status for each time step, and a clickable time navigation interface. The time dimension starts at the upper left of the map and proceeds across the image in English text order. ", "caption_bbox": [391, 330, 692, 404]}, {"image_id": 6, "file_name": "337_06.png", "page": 6, "dpi": 300, "bbox": [390, 382, 694, 709], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Naive matrix multiply (top) and blocked matrix multiply (bottom). ", "caption_bbox": [391, 719, 692, 747]}, {"image_id": 7, "file_name": "337_07.png", "page": 6, "dpi": 300, "bbox": [58, 71, 378, 203], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Striding a two dimensional array in different or- ders produces a marked difference in performance. ", "caption_bbox": [58, 214, 359, 242]}, {"image_id": 8, "file_name": "337_08.png", "page": 8, "dpi": 300, "bbox": [58, 71, 646, 429], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: MPM Horizontal (top) and Vertical (bottom).", "caption_bbox": [235, 439, 514, 452]}], "338": [{"image_id": 0, "file_name": "338_00.png", "page": 1, "dpi": 300, "bbox": [375, 356, 693, 784], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Turbine Blade (882K) dataset.", "caption_bbox": [438, 795, 643, 808]}, {"image_id": 1, "file_name": "338_01.png", "page": 3, "dpi": 300, "bbox": [113, 250, 307, 502], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Flow diagram of our parallel reconstruction al- gorithm. CPU steps are shown in red and GPUs in blue. ", "caption_bbox": [58, 513, 359, 541]}, {"image_id": 2, "file_name": "338_02.png", "page": 4, "dpi": 300, "bbox": [408, 548, 676, 754], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: GLT uses a ring to check all neighbours in par- allel, discarding invalid points in each iteration. Here, only one point is shown: given a point and its neighbours (1), this is checked for invalidity (2) and then updates its neighbours (3). Iterations stop when no invalid points are detected. ", "caption_bbox": [391, 766, 692, 840]}, {"image_id": 3, "file_name": "338_03.png", "page": 5, "dpi": 300, "bbox": [89, 333, 330, 444], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: is_Voronoi never invalidates Voronoi neighbours.", "caption_bbox": [59, 455, 359, 468]}, {"image_id": 4, "file_name": "338_04.png", "page": 5, "dpi": 300, "bbox": [449, 469, 635, 621], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: EG 2007 Phlegmatic Dragon (240K) detail.", "caption_bbox": [405, 631, 677, 644]}, {"image_id": 5, "file_name": "338_05.png", "page": 5, "dpi": 300, "bbox": [453, 677, 631, 826], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Noisy dataset \u2013 Foot (20K).", "caption_bbox": [445, 838, 636, 851]}, {"image_id": 6, "file_name": "338_06.png", "page": 6, "dpi": 300, "bbox": [96, 409, 655, 669], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparative graphics of GLT (machines A and B) and [GKS00] (machine A). As some models, such as the Hand and the Dragon, may need more neighbours to reconstruct properly, they need higher k values. ", "caption_bbox": [58, 686, 691, 714]}, {"image_id": 7, "file_name": "338_07.png", "page": 8, "dpi": 300, "bbox": [64, 98, 688, 886], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Some reconstructed models using the GLT proposed in this work. See Table 1 for detailed times.", "caption_bbox": [109, 892, 641, 905]}], "339": [{"image_id": 0, "file_name": "339_00.png", "page": 3, "dpi": 300, "bbox": [375, 72, 693, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Four possible cases. Depending upon the spa- tial relationship between microtriangle and cells in vol- ume space, four different situations may occur. No addi- tional work has to be done for the first two cases (a) and (b), whereas some relatively nontrivial computation must be done in the fourth case (d) to test if the microtriangle over- laps its neighboring cells. This costly case usually occurs, however, with a low frequency, as shown experimentally in Table 2. ", "caption_bbox": [391, 306, 692, 426]}, {"image_id": 1, "file_name": "339_01.png", "page": 3, "dpi": 300, "bbox": [64, 253, 362, 389], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Generation of mi- spect to the unit cell in crotriangles. Each triangle of \u03a3. In case a minification a given triangular mesh is situation occurs, in other subdivided into microtriangles words, when the trian- that can fit into a unit cube. gles from M are mostly ", "caption_bbox": [58, 388, 359, 455]}, {"image_id": 2, "file_name": "339_02.png", "page": 4, "dpi": 300, "bbox": [396, 476, 694, 638], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Cell scan order. if d \u2264 12 , there is no need to", "caption_bbox": [391, 637, 692, 657]}, {"image_id": 3, "file_name": "339_03.png", "page": 4, "dpi": 300, "bbox": [375, 73, 660, 218], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Definition of the local cells and layer level. (a) By the local cells, we denote the boundary cells plus their non- boundary 6-neighbors. (b) Starting at a cell containing a se- lected voxel, the surrounding cells are piled upon each other like the layers of an onion, approximating to circular bands in voxel space. Refer to Figure 6 to see a three-dimensional illustration of the level-1 and level-2 layers. ", "caption_bbox": [391, 231, 692, 324]}, {"image_id": 4, "file_name": "339_04.png", "page": 4, "dpi": 300, "bbox": [65, 539, 362, 648], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "                process for the black microtriangles. The Figure 3: Black reason for this is that after processing the and white mi- white microtriangles, there is no need to crotriangles    conduct the third test case (I = 1) for the ", "caption_bbox": [58, 647, 359, 696]}, {"image_id": 5, "file_name": "339_05.png", "page": 5, "dpi": 300, "bbox": [72, 72, 693, 205], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The minimum distances of layer cells. Figures (a) and (b) illustrate the level-1 layer cells, while the remaining figures display the level-2 layer cells. These layer cells are classified according to their minimum distance to the center cell\u2019s voxel. They are used to cull unnecessary voxel-to-triangle computations during the distance computation stage. ", "caption_bbox": [58, 218, 691, 258]}, {"image_id": 6, "file_name": "339_06.png", "page": 8, "dpi": 300, "bbox": [89, 323, 330, 465], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Global signed distance field. The global signed distance function d = d(x), discretized by the sweeping method combined with our method, is color-coded, increas- ing from red to green to blue to white. ", "caption_bbox": [58, 478, 359, 531]}, {"image_id": 7, "file_name": "339_07.png", "page": 8, "dpi": 300, "bbox": [58, 72, 378, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Local signed distance field. Three axis-aligned slices, illustrating the computed local signed distance field, are superimposed on the sample meshes. ", "caption_bbox": [58, 263, 359, 303]}], "340": [{"image_id": 0, "file_name": "340_00.png", "page": 2, "dpi": 300, "bbox": [395, 98, 690, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Isosurface from fuel data set (www.volvis.org), isovalue 80. a) Marching Cubes isosurface. b) SnapMC iso- surface (snap parameter 0.3.) ", "caption_bbox": [391, 245, 692, 293]}, {"image_id": 1, "file_name": "340_01.png", "page": 2, "dpi": 300, "bbox": [123, 107, 297, 179], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: a) Grid cube with one vertex with scalar value four and all others with scalar values two. The grid cube has a single \u2019+\u2019 vertex when the isovalue is four. b) Lookup table isosurface patch for configuration with a single \u2019+\u2019 vertex. ", "caption_bbox": [59, 190, 360, 253]}, {"image_id": 2, "file_name": "340_02.png", "page": 3, "dpi": 300, "bbox": [132, 102, 293, 157], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: 2D illustration of isosurface patch construction. a) Square vertices labelled \u2019+\u2019, \u2019\u2212\u2019 and \u2019=\u2019. b) The convex hull of the midpoint of the bipolar edges and the \u2019+\u2019 and \u2019=\u2019 vertices. c) The line segment on the boundary of the convex hull which is not on the square boundary. ", "caption_bbox": [59, 170, 360, 248]}, {"image_id": 3, "file_name": "340_03.png", "page": 3, "dpi": 300, "bbox": [391, 99, 706, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Isosuface patch construction in a convex polyhe- dron \u03a6. ", "caption_bbox": [391, 356, 692, 389]}, {"image_id": 4, "file_name": "340_04.png", "page": 4, "dpi": 300, "bbox": [80, 112, 330, 176], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Grid facet with duplicate isosurface triangles. Identical (but oppositely oriented) isosurface triangles are created in each of the cubes incident on the facet. ", "caption_bbox": [59, 187, 360, 235]}, {"image_id": 5, "file_name": "340_05.png", "page": 5, "dpi": 300, "bbox": [423, 102, 659, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Extremal configurations. a) Min. edge length for all snap parameters. Min. area for \u03b3 = 0.1, 0.2, 0.3. b) Min. area for \u03b3 = 0.4. c) Min. angle for \u03b3 = 0.1, 0.2. d) Min. angle for \u03b3 = 0.3. e) Min. angle for \u03b3 = 0.4. f) Max. angle for \u03b3 = 0.1, 0.2. g) Max. angle for \u03b3 = 0.3, 0.4. ", "caption_bbox": [391, 251, 692, 330]}, {"image_id": 6, "file_name": "340_06.png", "page": 5, "dpi": 300, "bbox": [58, 99, 362, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Min. edge lengths, min. area, and min. and max. angles for different values of \u03b3 on a grid with unit edge length L = 1. Angles are in degrees. ", "caption_bbox": [59, 531, 360, 579]}, {"image_id": 7, "file_name": "340_07.png", "page": 6, "dpi": 300, "bbox": [77, 98, 690, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Measurements of lobster isosurface. Min. edge length, min. area, min. and max. triangle angles, directed Hausdorff distance, mean directed distance and root mean squared directed distance. Measurements are for the isosur- face with isovalue 20 except for the distances which com- pared isosurfaces with isovalue 20.01. ", "caption_bbox": [391, 606, 692, 699]}, {"image_id": 8, "file_name": "340_08.png", "page": 7, "dpi": 300, "bbox": [86, 98, 641, 284], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 4: Measurements on SnapMC isosurfaces. Snap parameter \u03b3 = 0.3. The minimum radius ratio is the minimum ratio of the inscribed to circumscribed circle for any isosurface triangle. Directed Hausdorff distance was computed on isosurfaces with isovalue 0.01 greater than the isovalues listed in column two. ", "caption_bbox": [59, 471, 691, 519]}], "341": [{"image_id": 0, "file_name": "341_00.png", "page": 2, "dpi": 300, "bbox": [58, 67, 628, 485], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Images we created using ncBrowse (http://www.epic.noaa.gov/java/ncBrowse/) from single variables of the jet com- bustion dataset (a)-(e). Image created by our method fusing high valued ranges of each of the single variable images (f). ", "caption_bbox": [58, 515, 691, 543]}, {"image_id": 1, "file_name": "341_01.png", "page": 3, "dpi": 300, "bbox": [435, 498, 649, 714], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Simple 3 point dataset. (b) The distance from target values (distance set) for each attribute. (c) The dis- tance from median of distance set: notice P1\u2019s second value is closer to its target value, but its first value is chosen be- cause it is much closer relative to how close the rest of the points\u2019 first values are to A1\u2019s target value. (d) The new vol- ume, the starting point for the redistribution of open spaces. (e) Key for Figures 2 and 3. ", "caption_bbox": [391, 724, 692, 844]}, {"image_id": 2, "file_name": "341_02.png", "page": 4, "dpi": 300, "bbox": [375, 67, 634, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Detailed calculation of P1\u2019s radius of influence. In this example, there are only 4 points remaining after thresh- olding a a 2-D 9x9 dataset (81 is the total area of the space). Note: Equation 1 is for radius calculation in 3-D. ", "caption_bbox": [391, 305, 692, 364]}, {"image_id": 3, "file_name": "341_03.png", "page": 5, "dpi": 300, "bbox": [375, 67, 693, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: To avoid the inaccuracy of linear filtering and the coarse appearance of nearest filtering, tags are interpolated at subvoxel precision with a hybrid filtering approach. (a) The tag and gradient are retrieved using linear interpola- tion for the encircled fragment. (b) The tag is retrieved for the same fragment using nearest filtering. Additionally, the nearest tag along the gradient is retrieved. (c) The final fil- tered tag is determined by using the linear tag to find the closer of the gradient\u2019s and fragment\u2019s nearest tags. In this case, the nearest tag is chosen. ", "caption_bbox": [391, 247, 692, 397]}, {"image_id": 4, "file_name": "341_04.png", "page": 6, "dpi": 300, "bbox": [375, 67, 642, 390], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a)Rendering of the jet combustion dataset with attributes\u2019 maximum values used for attribute target values, and all but 4.7% of points thresholded. (b) Attribute coloring key for combustion dataset images. ", "caption_bbox": [391, 402, 692, 461]}, {"image_id": 5, "file_name": "341_05.png", "page": 6, "dpi": 300, "bbox": [58, 67, 378, 583], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Rendering of the jet combustion dataset with the attributes\u2019 average values (a) and attributes\u2019 maximum val- ues (b) used for the attribute target values. Attribute color key included in Figure 6 ", "caption_bbox": [58, 597, 359, 656]}, {"image_id": 6, "file_name": "341_06.png", "page": 7, "dpi": 300, "bbox": [375, 67, 694, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Concurrent rendering of 10 timesteps of the CO2 measurement dataset (a). A sample gray-scale image of Jan. 1, 1890, the highest ranked attribute (b). The rankings of all 10 timesteps (c). ", "caption_bbox": [391, 290, 692, 349]}, {"image_id": 7, "file_name": "341_07.png", "page": 7, "dpi": 300, "bbox": [95, 67, 378, 480], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Climate dataset with maximum attribute target values. Default (a) and full (b) thresholding. (c) Attribute coloring key. ", "caption_bbox": [58, 490, 359, 534]}], "342": [{"image_id": 0, "file_name": "342_00.png", "page": 2, "dpi": 300, "bbox": [410, 682, 681, 810], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Two different color blending approaches (combin- ing red representing doid , green dois , and yellow doic ) are illustrated. The top-left triangle of each side shows our com- positing scheme using \u03b1s , \u03b1d , and \u03b1c whereas the lower- right parts apply standard alpha compositing using dois , doid , and doic as weights. Note that especially along the diagonal and the borders a brownish tint is introduced by standard alpha compositing because of color mixing. ", "caption_bbox": [395, 824, 696, 944]}, {"image_id": 1, "file_name": "342_01.png", "page": 2, "dpi": 300, "bbox": [62, 76, 378, 218], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The structure of the FDL tree (right) and the op- timized blending scheme for color coding (left). The three colors represent different levels of the FDL tree. ", "caption_bbox": [63, 232, 364, 276]}, {"image_id": 2, "file_name": "342_02.png", "page": 3, "dpi": 300, "bbox": [67, 105, 694, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The first stage of our rendering pipeline rasterizes parallelograms (each representing multiple function graph seg- ments) and generates multiple output images which are used by the post processing stage. Here different image based algorithms are applied in order to create three different effects (shading, coloring, and LIC), which are combined in the compositing stage. ", "caption_bbox": [63, 274, 696, 318]}, {"image_id": 3, "file_name": "342_03.png", "page": 4, "dpi": 300, "bbox": [107, 786, 320, 888], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: This figure illustrates the duality between bins in a binmap and function graph segments in the corresponding function graph space. ", "caption_bbox": [63, 901, 364, 944]}, {"image_id": 4, "file_name": "342_04.png", "page": 5, "dpi": 300, "bbox": [66, 710, 362, 850], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Cutout images from figure 3. Shading (a) is used to emphasize \"edges\" in the DOI and frequency images whereas the application of our compositing scheme trans- lates the three different DOI attributations into easily recog- nizable colors (b). Additionally LIC is applied to a flow field representing the average function graph directions (c). ", "caption_bbox": [63, 855, 364, 944]}, {"image_id": 5, "file_name": "342_05.png", "page": 5, "dpi": 300, "bbox": [394, 101, 698, 196], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: This figure shows brushing results based on two different similarity measures. In (a) no data transformation is used whereas in (b) a gradient based distance is evaluated which is invariant to vertical translation. ", "caption_bbox": [393, 205, 694, 264]}, {"image_id": 6, "file_name": "342_06.png", "page": 6, "dpi": 300, "bbox": [375, 76, 679, 187], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) Time-intensity curves (TICs) typical for con- trast agent accumulation in breast tissue. The continuous gentle inclination of the blue curve is characteristic for healthy tissue. The green and red curves are suspicious due to their high early enhancement. The red curve is especially suspicious because of its subsequent rapid wash-out, which is typical for malignant tumors. (b) TICs typical for contrast agent accumulation in the gray matter of the brain. The blue curve shows normal brain perfusion whereas the green and red curves show decreased and delayed perfusion around an infarction. ", "caption_bbox": [393, 200, 694, 365]}, {"image_id": 7, "file_name": "342_07.png", "page": 6, "dpi": 300, "bbox": [121, 836, 303, 909], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Computing smooth DOI values based on distance values by linearly interpolating between two thresholds. ", "caption_bbox": [63, 916, 364, 944]}, {"image_id": 8, "file_name": "342_08.png", "page": 7, "dpi": 300, "bbox": [62, 711, 362, 822], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Detection of suspicious structures in breast tu- mor diagnosis. In our function graph visualization (a), a smooth similarity brush (blue) has been defined that resem- bles a curve pattern which is typical for malignant tumors. The resulting selection is visualized in the context of the en- tire right mamma in (b). Two suspicious structures Slarge and Ssmall are revealed. The color indicates the accumulation speed during the early phase of the contrast agent passage (Slope). ", "caption_bbox": [64, 821, 365, 956]}, {"image_id": 9, "file_name": "342_09.png", "page": 7, "dpi": 300, "bbox": [62, 104, 694, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A feature set containing two different features has been defined in two function graph visualizations. In (a), a smooth similarity brush (blue) has been defined such that tissue with no significant signal enhancement is selected in the first feature (shown in its 3D context in the inlet). In (b), a similarity brush has been used to specify a second feature representing tissue exhibiting reduced and delayed perfusion. Candidate areas of this tissue at risk are revealed around the core (inlet). In (c) and (d) the overall feature set is visualized. The color is modified according to the time it takes until the maximum amount of contrast agent is delivered for a particular voxel (TTP). ", "caption_bbox": [63, 309, 696, 398]}], "343": [{"image_id": 0, "file_name": "343_00.png", "page": 2, "dpi": 300, "bbox": [58, 72, 664, 284], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The configuration space: (a) Neighboring values (orange stripe) in the previous time-step are used to compute the value at the current position (orange circle). (b-c) Cone-configurations are extracted from the field and stored in the configura- tion space. ", "caption_bbox": [58, 297, 691, 341]}, {"image_id": 1, "file_name": "343_01.png", "page": 3, "dpi": 300, "bbox": [69, 72, 694, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Density-driven Voronoi tessellation: (a) The configuration space is quantized first and the number of configurations in each cell are counted. (b) Starting from the cells with most configurations, region growing is performed. (c) The final partitioning captures regions of high density. (d) Voronoi tessellation of the configuration space. ", "caption_bbox": [58, 268, 691, 312]}, {"image_id": 2, "file_name": "343_02.png", "page": 4, "dpi": 300, "bbox": [58, 72, 378, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The Voronoi tessellation of the past configuration space (Fig. 2(d)) tells in which class each past-cone con- figuration in the field is (b-top). The same computation is performed for the future configurations (b-bottom). (c) Af- terwards local statistical complexity is computed for each causal state (top) and positions in the past field are marked respectively (bottom). ", "caption_bbox": [58, 281, 359, 386]}, {"image_id": 3, "file_name": "343_03.png", "page": 5, "dpi": 300, "bbox": [63, 72, 693, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Flow around a cuboid: (a) Streamlines illustrating the data-set. (b) An isosurface of \u03bb2 = 0. (c,d) Volumerendering of LSC values in the upper third of the range. ", "caption_bbox": [58, 244, 691, 275]}, {"image_id": 4, "file_name": "343_04.png", "page": 6, "dpi": 300, "bbox": [58, 72, 687, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Delta Wing: (a) The interesting structures in the delta wing are three vortices on either side of the wing illustrated using streamlines in different colors. Recirculating bubbles can be observed at the ends of the primary vortices. (b) Sujudi- Haimes of the vector field. (c) \u03bb2 -criterion applied to the Jacobian of the velocity field. (d) Isosurface of the vorticity magnitude. (e-h) Local statistical complexity applied to different fields. ", "caption_bbox": [58, 392, 691, 451]}, {"image_id": 5, "file_name": "343_05.png", "page": 7, "dpi": 300, "bbox": [83, 72, 693, 428], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Time-step 60 of the Hurricane Data-set", "caption_bbox": [250, 441, 500, 454]}], "344": [{"image_id": 0, "file_name": "344_00.png", "page": 4, "dpi": 300, "bbox": [262, 72, 693, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Bundling enabled at all levels; (b) deactivation of bundling at L1 re- sults in shifting of the control polygon points corresponding to that level (shown in blue). This effectively disables bundling at L1; (c) and (d) show how (de)activation of bundling at certain levels can be used to specify whether splits / joins (as encircled in (c)) should be shown at these levels. ", "caption_bbox": [267, 294, 691, 356]}, {"image_id": 1, "file_name": "344_01.png", "page": 5, "dpi": 300, "bbox": [108, 71, 693, 461], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) through (f) Sorting both hierarchies with respect to each other is performed by means of crossing reduction (CR) of inter-hierarchy relations. Individual steps required to prepare hierarchies for CR and to restore hierarchy structure after CR are shown. S(M(T)) = Stretched(Matched(T)); (g) and (h) Collapse of levels L4 to L3 results in inter-hierarchy relations between elements of L3 to be aggregated up one level to produce inter-hierarchy relations between elements of L4. ", "caption_bbox": [59, 465, 692, 515]}, {"image_id": 2, "file_name": "344_02.png", "page": 6, "dpi": 300, "bbox": [58, 71, 694, 269], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An SE increases the bundling strength to get insight in the high-level correspondence between hierarchies; (a) straight lines only show correspondence between leaf elements; (b) & (c) increasing the bundling strength shows splits / joins that pertain to high-level changes in a software system as well. ", "caption_bbox": [59, 282, 692, 319]}, {"image_id": 3, "file_name": "344_03.png", "page": 6, "dpi": 300, "bbox": [66, 326, 687, 587], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Bundling at speci ed levels; (a) the Philips data (top) was substantially reorganized by Bunch (bottom). Whether substantial Unit reorganization was performed is not directly clear, since bundling at the Layer level (encircled) partially ob- scures this information; (b) disabling Layer-level bundling still leaves many splits / joins at the Unit level (encircled), indicating that substantial reorganization was performed at the Unit level as well. ", "caption_bbox": [59, 587, 692, 637]}, {"image_id": 4, "file_name": "344_04.png", "page": 7, "dpi": 300, "bbox": [61, 71, 694, 269], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: User interaction by means of crossing. (a) Original FEI data (top) is compared to a Bunch-reorganized version (bottom). An area of interest is encircled; (b) crossing of the encircled bundles results in highlighting of the inter-hierarchy relations and shading of the nodes pertaining to the selected relations; (c) automatic animated zooming is performed after crossing to give an SE a more detailed view of the inter-hierarchy relations and parts of the hierarchy that are involved. ", "caption_bbox": [59, 282, 692, 332]}], "345": [{"image_id": 0, "file_name": "345_00.png", "page": 5, "dpi": 300, "bbox": [395, 422, 679, 638], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3. Path, shape configurations. Position and", "caption_bbox": [403, 648, 675, 661]}, {"image_id": 1, "file_name": "345_01.png", "page": 6, "dpi": 300, "bbox": [67, 663, 330, 765], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. Significant effects", "caption_bbox": [78, 766, 219, 779]}], "346": [{"image_id": 0, "file_name": "346_00.png", "page": 2, "dpi": 300, "bbox": [390, 170, 694, 276], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The RGB cube, the HSV cone, the HLS double- cone and displayable CIELUV space ", "caption_bbox": [391, 286, 692, 314]}, {"image_id": 1, "file_name": "346_01.png", "page": 2, "dpi": 300, "bbox": [67, 719, 357, 785], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Examples of non perceptual uniformity in HLS. Left: Three colors of equal lightness. Middle: Two pairs of colors with equal hue distance. Right: Two pairs of colors with equal lightness distance. ", "caption_bbox": [59, 800, 360, 859]}, {"image_id": 2, "file_name": "346_02.png", "page": 3, "dpi": 300, "bbox": [58, 68, 693, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The volume of displayable colors in CIELUV space, three hue slices of CIELUV space generated with PaletteView and the triangle that approximates the boundary of the displayable colors of a hue slice ", "caption_bbox": [58, 276, 691, 304]}, {"image_id": 3, "file_name": "346_03.png", "page": 4, "dpi": 300, "bbox": [58, 68, 692, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Left: Three Brewer palettes plotted in LCHuv space with PaletteView. Center: The RGB cube with all MSCs.                                                \u2217 Right: Colors at equal distance according to \u2206Euv , CIE94, CIEDE2000, and the L function. ", "caption_bbox": [59, 265, 692, 293]}, {"image_id": 4, "file_name": "346_04.png", "page": 4, "dpi": 300, "bbox": [411, 384, 677, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Left: the CIELUV displayable color volume with a cylinder that defines all colors of similar saturation. Right: the corresponding saturation slice generated with Palette- View. The path of the MSCs of all hues is shown, indicating the lightness of each MSC. ", "caption_bbox": [391, 544, 692, 618]}, {"image_id": 5, "file_name": "346_05.png", "page": 5, "dpi": 300, "bbox": [58, 321, 362, 473], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Left: seven palettes made by Brewer. Right: seven generated palettes with varying contrast ", "caption_bbox": [59, 483, 360, 511]}, {"image_id": 6, "file_name": "346_06.png", "page": 5, "dpi": 300, "bbox": [58, 68, 693, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Single-hue sequential palette model.", "caption_bbox": [425, 319, 654, 332]}, {"image_id": 7, "file_name": "346_07.png", "page": 6, "dpi": 300, "bbox": [390, 176, 694, 470], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: User interface for editing palettes in MagnaView.", "caption_bbox": [391, 480, 691, 493]}, {"image_id": 8, "file_name": "346_08.png", "page": 7, "dpi": 300, "bbox": [58, 68, 694, 236], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Pairs of palettes of which the left palettes are defined by Brewer, and the right palettes are generated with Pseq .", "caption_bbox": [73, 247, 678, 261]}, {"image_id": 9, "file_name": "346_09.png", "page": 8, "dpi": 300, "bbox": [58, 68, 631, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Examples of generated palettes, taken from the set of preset palettes.", "caption_bbox": [175, 403, 576, 416]}], "347": [{"image_id": 0, "file_name": "347_00.png", "page": 2, "dpi": 300, "bbox": [375, 76, 693, 396], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The elevation profile of a landscape as seen from above. Lines depict the partition of the landscape into hills, valleys and their intersection, the MS complex. Blue, red and green dots represent minima, maxima and saddles. Bottom row: simplifications of the MS complex by different types of cancellations and their influence on vanishing 1-cells. ", "caption_bbox": [391, 408, 692, 497]}, {"image_id": 1, "file_name": "347_01.png", "page": 3, "dpi": 300, "bbox": [58, 75, 378, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Forman\u2019s discrete gradient vector field of the height function of an elevation profile is shown with red max- ima, green saddles and blue minima in (a). Red lines are gradient curves ascending to maxima, blue lines are gradi- ent curves descending to minima. In (b) its smooth analogue is shown, being discontinuous and constant on triangles. ", "caption_bbox": [59, 204, 360, 293]}, {"image_id": 2, "file_name": "347_02.png", "page": 4, "dpi": 300, "bbox": [58, 76, 693, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Ascending 1-cells of the initial MS complex of \u03ba1 on the rocker arm are a candidate set of convex feature lines in (a). 3, 600 persistence cancellations lead to the line set depicted in (b). Clearly, all feature lines are still contained. After 3, 650 cancellations, one of the main features is broken by persistence cancellation in (c). In contrast, feature line preserving cancellation as proposed in this paper maintains the main features in (d). ", "caption_bbox": [59, 217, 692, 276]}, {"image_id": 3, "file_name": "347_03.png", "page": 4, "dpi": 300, "bbox": [58, 282, 694, 406], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Quantification of 1-cell deletion: the average curvature on the 1-cell is compared to the average curvature on the shaded area, and 1-cells with a larger difference are considered more salient, i.e., they are canceled later. ", "caption_bbox": [59, 411, 692, 439]}, {"image_id": 4, "file_name": "347_04.png", "page": 5, "dpi": 300, "bbox": [58, 75, 378, 205], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Cancellation of a terminal 1-cell forking off the outer ring feature of the rocker arm colored by \u03ba1 . The 1- cell emanating from the left saddle ends at the maximum on the high curvature area, but only the part up to the branching point is being deleted by the cancellation. ", "caption_bbox": [58, 211, 359, 285]}, {"image_id": 5, "file_name": "347_05.png", "page": 6, "dpi": 300, "bbox": [59, 254, 690, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Timings of our method for various datasets and scalar feature indicators. In rows 3\u20135, the number of can- cellations, the time in seconds to construct the initial MS complex, and for performing all cancellations are shown. ", "caption_bbox": [391, 564, 692, 623]}, {"image_id": 6, "file_name": "347_06.png", "page": 6, "dpi": 300, "bbox": [58, 76, 693, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The extraction of maximal features of the Curvedness indicator yields both convex and concave feature lines in one. It depends on just one parameter, compared to two for the linked treatment of \u03ba1 and \u03ba2 and is therefore our preferred technique. ", "caption_bbox": [59, 398, 692, 427]}, {"image_id": 7, "file_name": "347_07.png", "page": 7, "dpi": 300, "bbox": [58, 531, 361, 865], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Adding Gaussian noise scales to the rockerarm shows the stability of our method. The feature lines just ap- pear disconnected due to occlusion by surface spikes. ", "caption_bbox": [59, 877, 360, 921]}, {"image_id": 8, "file_name": "347_08.png", "page": 7, "dpi": 300, "bbox": [69, 76, 692, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Concave feature lines are extracted on the Stanford bunny with 280K triangles. The initial MS complex of \u03ba2 consists of 71, 577 cancellations, and its descending 1-cells are densely spread over the bunny. The kept concave features identify it. ", "caption_bbox": [58, 272, 691, 301]}, {"image_id": 9, "file_name": "347_09.png", "page": 7, "dpi": 300, "bbox": [58, 309, 693, 467], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Feature lines on the cow at fine, medium and coarse scale after 12, 451, 13, 116 and 13, 491 cancellations respectively. The coarse scale suffices to reflect the geometry, and fine scale features add more and more expression to the cow\u2019s face. ", "caption_bbox": [58, 472, 691, 500]}, {"image_id": 10, "file_name": "347_10.png", "page": 8, "dpi": 300, "bbox": [58, 76, 693, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Feature lines on the lion vase. The one parameter our method depends on is traversed logarithmically. A user has to decide for less lines until the coarse level of detail he is interested in is reached. One further step removes a detail regarded as interesting. This way a good overview of the various level of details contained in the dataset is acquired in a few steps. ", "caption_bbox": [58, 229, 691, 272]}], "348": [{"image_id": 0, "file_name": "348_00.png", "page": 2, "dpi": 300, "bbox": [58, 74, 662, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization of a synthetic flow exhibiting a splitting behavior. Left: dense texture visualization using GPU- FLIC [LTH06]. Middle: dye advection visualization by the semi-Lagrangian texture advection scheme. The pattern appears to be divergent and diffusive. Right: accurate visualization by the physically-based control volume dye advection scheme. ", "caption_bbox": [59, 303, 692, 346]}, {"image_id": 1, "file_name": "348_01.png", "page": 3, "dpi": 300, "bbox": [58, 75, 378, 245], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visual artifacts in non-physical texture advection. Left: numerical diffusion in the semi-Lagrangian texture ad- vection scheme. Right: clamping-based correction schemes can cause unnaturally sharp patterns. If the correction is applied periodically, popping artifacts can occur due to pat- terns that alternatively exhibit blurring and sharp bound- aries. ", "caption_bbox": [59, 255, 360, 359]}, {"image_id": 2, "file_name": "348_02.png", "page": 4, "dpi": 300, "bbox": [375, 75, 677, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Material transport via control volume integration. The total mass contained in Vi (shaded in orange) is com- puted by integrating \u03a6 at t n\u22121 . ", "caption_bbox": [391, 268, 692, 312]}, {"image_id": 3, "file_name": "348_03.png", "page": 4, "dpi": 300, "bbox": [58, 74, 378, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: 1D illustration of the non-conservative nature of the semi-Lagrangian texture advection scheme. The to- tal mass in the system can either decrease (top) or increase (bottom) depending on the behavior of the flow. ", "caption_bbox": [59, 324, 360, 383]}, {"image_id": 4, "file_name": "348_04.png", "page": 5, "dpi": 300, "bbox": [73, 75, 378, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Dataset statistics and timing numbers.", "caption_bbox": [421, 176, 660, 189]}, {"image_id": 5, "file_name": "348_05.png", "page": 6, "dpi": 300, "bbox": [58, 74, 633, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Control volume advection and mass transport in 2D. (a) The spatial domain is discretized into control volumes sharing corner points. (b) Control volume Vinj advected back in time. Intersecting cells are shaded in light blue. (c) Intersection regions of Vi,n\u22121                j . (d) The local density distribution function is integrated over the intersection region using Riemann sum on sample points (purple). ", "caption_bbox": [58, 255, 691, 317]}, {"image_id": 6, "file_name": "348_06.png", "page": 7, "dpi": 300, "bbox": [89, 74, 693, 550], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visualization of the JP8 dataset using dye advection. Top row: physically-based dye advection. Middle row: texture advection method. Bottom row: level-set method. The time sequence is from left to right. ", "caption_bbox": [59, 560, 692, 588]}, {"image_id": 7, "file_name": "348_07.png", "page": 8, "dpi": 300, "bbox": [58, 74, 667, 390], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visualization of the Karman dataset using dye advection. Left column: physically-based dye advection. Middle col- umn: texture advection method. Right column: level-set method. The time sequence is from top to bottom. ", "caption_bbox": [59, 400, 692, 428]}], "349": [{"image_id": 0, "file_name": "349_00.png", "page": 1, "dpi": 300, "bbox": [375, 369, 694, 747], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Dye advection of a spherical volume in a time- dependent sine wave. The injection volume is marked in red. The flow spreads the dye over time and the resulting trace depends on the computation of this process. Diffusive advec- tion (a), level set advection (b), PLS advection (c) \u2013 (643 grid, 262,144 particles, rendering speed: 78.2, 55.9, 36.6 FPS). ", "caption_bbox": [391, 757, 692, 862]}, {"image_id": 1, "file_name": "349_01.png", "page": 4, "dpi": 300, "bbox": [79, 95, 342, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The data flow in the GPU-based PLS framework. The use of double buffering is marked by cyclic, blue arrows. Numbers indicate steps in Alg. 1. (Step 7 is omitted.) ", "caption_bbox": [58, 296, 359, 340]}, {"image_id": 2, "file_name": "349_02.png", "page": 5, "dpi": 300, "bbox": [377, 75, 694, 269], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparing particle radii using tri-linear distance interpolation and neighborhood-sampling the nearest refer- ence point. Left: A notched sphere (1a) is rotated 8 times, with reseeding 5 percent of the particles in each step using interpolated radii (1b) and nearest reference (1c). Middle and right: Two (2D) cases where interpolation (2a and 2b) leads to a larger error than nearest reference (3a and 3b). ", "caption_bbox": [391, 279, 692, 384]}, {"image_id": 3, "file_name": "349_03.png", "page": 6, "dpi": 300, "bbox": [101, 96, 319, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Left: A path volume is pushed into a tight band around a flow source. Due to numerical diffusion, the LS volume disappears . In contrast, PLS maintains the volume. Right: A difficult case where the streak volume reaches the injection volume. Both: The injection is marked in red. ", "caption_bbox": [58, 210, 359, 284]}, {"image_id": 4, "file_name": "349_04.png", "page": 6, "dpi": 300, "bbox": [399, 96, 685, 162], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Two cases (in 2D) where particles must be re- moved or reseeded when generating streak volumes ((a): in- jected particles, (b): old particles). ", "caption_bbox": [391, 172, 692, 216]}, {"image_id": 5, "file_name": "349_05.png", "page": 7, "dpi": 300, "bbox": [61, 256, 353, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparison of traditional PLS (trad.) and our method (enh.) for Zalesak\u2019s sphere (same logarithmic scale for both) \u2013 643 grid, no particle reseeding ", "caption_bbox": [59, 437, 360, 481]}, {"image_id": 6, "file_name": "349_06.png", "page": 7, "dpi": 300, "bbox": [85, 76, 378, 171], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Top row: Time surface after 190 evolutions. Start- ing geometry (1a), ground-truth using 1283 LS (1b), 643 LS (1c), our enhanced 643 PLS (1d), 262,144 particles (FPS for 1b\u20131d: 10.6, 19.1, 16.5, time without rendering (in ms): 51.6, 11.1, 22.1). Second row: Streak volume after 275 ad- vections, same parameters (FPS for 2b\u20132d: 12.5, 28.2, 22.1, time without rendering (in ms): 52.1, 10.1, 19.7). Both: The starting/injection shape is marked in red. ", "caption_bbox": [390, 261, 691, 381]}, {"image_id": 7, "file_name": "349_07.png", "page": 7, "dpi": 300, "bbox": [377, 75, 693, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Run-time of the steps involved in the PLS algorithm. Object: Zalesak\u2019s sphere (see Fig. 6), 262,144 particles. In each frame, 5 percent of the particles are reinitialized. ", "caption_bbox": [390, 415, 691, 459]}], "350": [{"image_id": 0, "file_name": "350_00.png", "page": 3, "dpi": 300, "bbox": [161, 134, 731, 523], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The graphical environment consists of two main panes. The left pane is a workspace for exploring the sentence, while the right pane consists of multiple tabs that provide additional functionalities. The workspace displays the machine translation (leftmost column), source sentence, and alignments between them; the source sentence is annotated with its parse tree (colored brackets), its word and character glosses (two right columns). Currently displayed in the right pane is the example tab, showing the search results (highlighted in pink) for the selected Chinese phrase (highlighted in the left pane in green). ", "caption_bbox": [96, 533, 729, 607]}, {"image_id": 1, "file_name": "350_01.png", "page": 4, "dpi": 300, "bbox": [412, 136, 732, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Source to target alignment showing the MT map- pings between source words in Arabic and target words in English. POS-tags label the parse tree, although novice users tend to focus on the tree structure and at most the first letter of each label: NP (noun phrase), NN (single noun), VBD (verb past tense), DT (determiner) etc. ", "caption_bbox": [428, 356, 729, 445]}, {"image_id": 2, "file_name": "350_02.png", "page": 4, "dpi": 300, "bbox": [96, 134, 415, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Source text segmentation: the ideograms for \u2019eye\u2019 and \u2019light\u2019 or \u2019ray\u2019 form the word \u2019sight\u2019. ", "caption_bbox": [96, 261, 397, 289]}, {"image_id": 3, "file_name": "350_03.png", "page": 6, "dpi": 300, "bbox": [96, 534, 400, 773], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The interface for users who are correcting trans- lations without the Chinese Room; they have access to the document view, but they do not have access to any of the other resources. ", "caption_bbox": [96, 784, 397, 843]}, {"image_id": 4, "file_name": "350_04.png", "page": 6, "dpi": 300, "bbox": [96, 134, 727, 413], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Two views of the visual analysis window, showing the actions of two users (ric and nick) as they worked on the same document 4, both using the Chinese Room. Left: action timeline view: right: cumulative action view. The MT researcher quickly saw that the first user (ric) used a wide variety of resources, while the second user relied almost exclusively on searching for similar examples. Both users took a similar approach of working their way through each example sentence one by one without skipping around much, and relying instead on local context. ", "caption_bbox": [96, 423, 729, 497]}], "351": [{"image_id": 0, "file_name": "351_00.png", "page": 2, "dpi": 300, "bbox": [96, 134, 415, 471], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: DocuBurst of a science textbook rooted at {idea}. A search query for words starting with \u2018pl\u2019 has been per- formed. Nodes matching the query are highlighted in gold. ", "caption_bbox": [96, 492, 397, 536]}, {"image_id": 1, "file_name": "351_01.png", "page": 2, "dpi": 300, "bbox": [415, 136, 730, 375], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Comparison of features available (Y), possible with a trivial extension (P), or not possible (N) in document visualizations. * denotes cases that only visualize a selected subset of words; + denotes a coordinated visualization. ", "caption_bbox": [428, 387, 729, 446]}, {"image_id": 2, "file_name": "351_02.png", "page": 4, "dpi": 300, "bbox": [96, 134, 728, 435], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: DocuBurst of a science textbook rooted at \u2018thought\u2019; node hue distinguishes the synsets containing \u2018thought\u2019.", "caption_bbox": [115, 451, 710, 464]}, {"image_id": 3, "file_name": "351_03.png", "page": 5, "dpi": 300, "bbox": [102, 134, 731, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: DocuBurst of a general science textbook rooted at {animal}. Single-node colouring and occurrence count sizing were used with zero-occurrence synsets hidden. Mouse hover point is revealed by blue trace-to-root colouring. (a) Synset {cattle, cows, kine, oxen} highlighted. (b) Synset {world, human race, humanity, mankind, man, ...} highlighted. (c) Detail of the dynamic legend, showing, from top to bottom, no selection, selection from (a), and (b). ", "caption_bbox": [96, 373, 729, 432]}, {"image_id": 4, "file_name": "351_04.png", "page": 5, "dpi": 300, "bbox": [97, 466, 396, 615], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: DocuBurst of a general science textbook rooted at {energy}. At right, mouse wheel interaction was used to shrink the angular width of the subtree rooted at {radiation} and expand the subtree under {electricity} exposing the pre- viously illegible node {signal}. ", "caption_bbox": [96, 626, 397, 700]}, {"image_id": 5, "file_name": "351_05.png", "page": 6, "dpi": 300, "bbox": [96, 134, 621, 683], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A search for \u2018electricity\u2019 reveals synsets containing that word (gold). On selecting a node, the distribution of the word is revealed in the tile browser. Selecting a tile reveals the text with occurrences of the selected synset highlighted. ", "caption_bbox": [96, 696, 729, 724]}, {"image_id": 6, "file_name": "351_06.png", "page": 7, "dpi": 300, "bbox": [103, 136, 415, 325], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: DocuBursts rooted at {skill worker} reveal the traditional US focus on military officers and veterans was eclipsed in the third US Presidential debate by discussions of plumbers. ", "caption_bbox": [96, 340, 397, 399]}], "352": [{"image_id": 0, "file_name": "352_00.png", "page": 1, "dpi": 300, "bbox": [428, 703, 731, 877], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Two users collaborate around Cambiera, imple- mented on a Microsoft Surface. ", "caption_bbox": [428, 888, 729, 916]}, {"image_id": 1, "file_name": "352_01.png", "page": 3, "dpi": 300, "bbox": [428, 561, 731, 762], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Interaction starts with a search. Each user is as- signed a color, which is reflected in the search button (top) and keyboard (bottom). ", "caption_bbox": [428, 773, 729, 816]}, {"image_id": 2, "file_name": "352_02.png", "page": 4, "dpi": 300, "bbox": [96, 413, 399, 552], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Initial search result overview. One closed search box (top), and one opened search box showing five result details (bottom). ", "caption_bbox": [96, 563, 397, 606]}, {"image_id": 3, "file_name": "352_03.png", "page": 4, "dpi": 300, "bbox": [163, 912, 332, 964], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Color scales to encode search terms. Each ana- lyst\u2019s searches receive one hue of their base color. ", "caption_bbox": [96, 974, 397, 1002]}, {"image_id": 4, "file_name": "352_04.png", "page": 4, "dpi": 300, "bbox": [428, 536, 731, 643], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Detail-on-demand is shown for the document un- der the finger. It shows that \u201cbse\u201d also found this document (top-left), a document timestamp, title, and sentences that include the search term (white text, right). ", "caption_bbox": [428, 653, 729, 712]}, {"image_id": 5, "file_name": "352_05.png", "page": 5, "dpi": 300, "bbox": [431, 710, 728, 943], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Minimized document representation (top left) and the full document reader (right). The reader is opened by resizing the minimized representation (bottom left). ", "caption_bbox": [428, 953, 729, 996]}, {"image_id": 6, "file_name": "352_06.png", "page": 5, "dpi": 300, "bbox": [428, 335, 731, 486], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Ana drags a single result up and out of the search box, and so creates a floating representation of a document. Note that this representation shares the striping pattern of the search result. ", "caption_bbox": [428, 496, 729, 555]}, {"image_id": 7, "file_name": "352_07.png", "page": 5, "dpi": 300, "bbox": [135, 807, 360, 930], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Ana and Ben have both searched for \u201cmad cow.\u201d The search box has both blue and orange marks under it; the stripe that corresponds to the term is split and shows both their colors. ", "caption_bbox": [96, 941, 397, 1000]}, {"image_id": 8, "file_name": "352_08.png", "page": 5, "dpi": 300, "bbox": [96, 280, 399, 427], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Different base-colored stripes show when searches from other users have found the same documents: Ana has search lists for \u201ccity hall\u201d and \u201cluthor\u201d. ", "caption_bbox": [96, 438, 397, 481]}, {"image_id": 9, "file_name": "352_09.png", "page": 6, "dpi": 300, "bbox": [96, 588, 399, 726], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: A darker background for individual documents indicate that a document has been opened in the document reader. A darker color indicate repeated document access. ", "caption_bbox": [96, 736, 397, 779]}, {"image_id": 10, "file_name": "352_10.png", "page": 8, "dpi": 300, "bbox": [96, 134, 681, 437], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Overview of the workspace during an analysis session. Both analysts have arranged several search boxes and documents in the space related to their current hypotheses. ", "caption_bbox": [96, 447, 729, 475]}], "353": [{"image_id": 0, "file_name": "353_00.png", "page": 4, "dpi": 300, "bbox": [437, 357, 721, 524], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview of the EM implementation. Illustration adapted by permission [BDCM05]. ", "caption_bbox": [428, 535, 729, 563]}, {"image_id": 1, "file_name": "353_01.png", "page": 5, "dpi": 300, "bbox": [142, 158, 352, 259], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a): A BCC lattice is formed by two CC lattices (red and blue). (b): 2D scheme of the BCC lattice. (c): In memory, every odd (blue) row (i.e., slice in 3D) is shifted to the center of the \"even\" (red) CC lattice. ", "caption_bbox": [96, 273, 397, 332]}, {"image_id": 2, "file_name": "353_02.png", "page": 6, "dpi": 300, "bbox": [412, 135, 720, 248], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Small spheres reconstructed using (a) NN inter- polation, and (b) the tricubic B-spline. ", "caption_bbox": [428, 261, 729, 289]}, {"image_id": 3, "file_name": "353_03.png", "page": 6, "dpi": 300, "bbox": [107, 215, 388, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Analytically computed projections with different noise levels of the 3D SL phantom. ", "caption_bbox": [96, 339, 397, 367]}, {"image_id": 4, "file_name": "353_04.png", "page": 6, "dpi": 300, "bbox": [458, 316, 686, 513], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: RMSE after iteration 30 for different noise levels and filters. ", "caption_bbox": [428, 541, 729, 569]}, {"image_id": 5, "file_name": "353_05.png", "page": 6, "dpi": 300, "bbox": [448, 795, 695, 940], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: RMSE curves for iteration 10 to 30 for three dif- ferent noise levels (noiseless, PSNR 32.19, PSNR 22.19) for the BCC and CC lattice. ", "caption_bbox": [428, 952, 729, 996]}, {"image_id": 6, "file_name": "353_06.png", "page": 7, "dpi": 300, "bbox": [507, 234, 651, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Volume rendering of the mouse embryo which was acquired from 400 OPT scans on a BCC lattice (321 \u00d7 474 \u00d7 642). Red areas indicate the most dense tissue. ", "caption_bbox": [428, 438, 729, 482]}, {"image_id": 7, "file_name": "353_07.png", "page": 7, "dpi": 300, "bbox": [435, 488, 724, 874], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a): CC slice of the reconstructed volume. (b): corresponding BCC slice. (c): upscaled verion of (b). Sec- ond row: corresponding ground truths. Last row: intensity profiles indicated by the red lines in (d-f). ", "caption_bbox": [428, 887, 729, 946]}], "354": [{"image_id": 0, "file_name": "354_00.png", "page": 3, "dpi": 300, "bbox": [473, 159, 686, 412], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The first neighbors cell of the BCC lattice is a rhombic dodecahedron which is the support of the linear box spline. ", "caption_bbox": [428, 421, 729, 465]}, {"image_id": 1, "file_name": "354_01.png", "page": 6, "dpi": 300, "bbox": [104, 169, 727, 469], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Reconstruction of the ML dataset. First column: Sampled ML dataset on the Cartesian lattice at the resolution of 41 \u00d7 41 \u00d7 41. Second column: sampled the ML dataset using the functional in Equation 8 on the same resolution Cartesian lattice. Third column: Sampled ML dataset on the BCC lattice at the resolution of 32 \u00d7 32 \u00d7 64. Fourth column: sampled on the same BCC lattice resolution, using the functional in Equation 7. The first row illustrates the volume rendering of the sampled data using the tricubic B-spline on the Cartesian and our quintic box spline on the BCC dataset. The second row illustrates the corresponding angular errors in estimating the gradient on the iso-surface from the reconstruction process. An angular error of .3 radians is mapped to white. The darker error image of the BCC data confirms smaller errors and more accurate reconstruction. The quasi-interpolation has improved the quality of reconstruction significantly. ", "caption_bbox": [96, 477, 729, 597]}, {"image_id": 2, "file_name": "354_02.png", "page": 6, "dpi": 300, "bbox": [96, 655, 399, 885], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Benchmark datasets. Top image: ML dataset that is widely used for evaluation of reconstruction filters. The bottom image: carp dataset at a high resolution of 256 \u00d7 256 \u00d7 256. ", "caption_bbox": [96, 895, 397, 954]}, {"image_id": 3, "file_name": "354_03.png", "page": 8, "dpi": 300, "bbox": [104, 450, 723, 699], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Reconstruction of Carp dataset at a resolution of 6% of the ground truth in Figure 2. Zoomed in view of Figure 4. First row the raw dataset is rendered and second row quasi-interpolation is employed. The Cartesian column are rendered with tricubic B-spline and BCC column with quintic box spline. ", "caption_bbox": [96, 707, 729, 753]}, {"image_id": 4, "file_name": "354_04.png", "page": 8, "dpi": 300, "bbox": [104, 158, 723, 376], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Reconstruction of Carp dataset at a resolution of 6% of the ground truth in Figure 2. First row the raw dataset is rendered and second row quasi-interpolation is employed. The Cartesian column are rendered with tricubic B-spline and BCC column with quintic box spline. ", "caption_bbox": [96, 383, 729, 429]}], "355": [{"image_id": 0, "file_name": "355_00.png", "page": 5, "dpi": 300, "bbox": [111, 381, 373, 552], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Graph showing relation of RMS to \u03c3avg for the Bypass dataset. A hairline shows the suggested threshold of \u03c3avg ", "caption_bbox": [96, 562, 397, 606]}, {"image_id": 1, "file_name": "355_01.png", "page": 6, "dpi": 300, "bbox": [158, 363, 694, 535], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Renderings of the Tooth dataset: a) original uniform dataset, b) reconstruction from 2,110,259 non-uniform points using our method. The resolution of reconstruction is selected to be the same as in the original 256x256x160 dataset. The RMS error is 0.19 at the input points, and 0.18 at the entire uniform volume, c) reconstruction from the same set of input points using RBFs proposed in [JWH\u2217 04]. The RMS error is 1.26 at input points, and 2.87 for the entire volume, and d) reconstruction from the same set of input points using EBFs as proposed in [JBL\u2217 06]. The RMS error is 0.76 at input points, and 2.45 at the entire uniform volume. ", "caption_bbox": [96, 546, 729, 632]}, {"image_id": 2, "file_name": "355_02.png", "page": 7, "dpi": 300, "bbox": [95, 655, 399, 781], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The X38 aircraft dataset consisting of 323, 192 non-uniform points rendered with our multi-resolution scheme using two levels of hierarchy. ", "caption_bbox": [96, 788, 397, 833]}, {"image_id": 3, "file_name": "355_03.png", "page": 7, "dpi": 300, "bbox": [136, 133, 731, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Renderings of the Chirp dataset: a) the original uniform data, b) reconstruction from 75,000 non-uniform points using regularization as defined in Eq. 6 (\u03bb = 0.3), RMS is 1.12 with a reconstruction time of 0.08 min, and c) reconstruction from 75,000 non-uniform points using regularization as defined in Eq. 7 (\u03bbx = \u03bby = 0.3, \u03bbz = 1.0), RMS is 0.51 with a reconstruction time of 0.08 min. ", "caption_bbox": [96, 337, 729, 394]}, {"image_id": 4, "file_name": "355_04.png", "page": 7, "dpi": 300, "bbox": [96, 396, 730, 528], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Renderings of the Bypass dataset consisting of 7,929,856 non-uniform points, reconstructed using our BMRP scheme (finest resolution 1024x120x256): a) coarse representation reconstructed from c(2) coefficients, RMS is 4.55, b) finer represen-                                               (1) tation reconstructed from ce(1) = U j c(2) + e p , where we used 20% of the points from the e(1) error volume, RMS is 2.69, c)                                                               (0) finest representation reconstructed from ce(0) = U j ce(1) + e p , where we used 20% of the points from the error volume e(0) , RMS is 0.6, and d) finest representation reconstructed where we used 100% of the points from the error volumes e(0) and e(1) , RMS is 0.4. ", "caption_bbox": [96, 544, 729, 644]}], "356": [{"image_id": 0, "file_name": "356_00.png", "page": 2, "dpi": 300, "bbox": [141, 171, 702, 429], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Different visualizations of two point clusters (colored red and blue) from the 2008 IEEE Visualization Design Contest data. The clusters were found using density-based clustering of the multidimensional feature space and were projected to a 3D visual space using a linear projection. Additionally to the cluster points a), three types of enclosing surfaces are shown. b) Isosurface extraction from distance field computed using a 3D discrete Voronoi diagram of resolution 256 \u00d7 256 \u00d7 256. c) Hull of the cluster computed from the isosurface of the distance field. d) Isosurface extraction from the distance field to the hull in c). ", "caption_bbox": [96, 438, 729, 512]}, {"image_id": 1, "file_name": "356_01.png", "page": 4, "dpi": 300, "bbox": [435, 426, 723, 608], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Approximating one sheet of a 2D cone by layers of 1D conic sections. ", "caption_bbox": [428, 620, 729, 648]}, {"image_id": 2, "file_name": "356_02.png", "page": 5, "dpi": 300, "bbox": [103, 162, 391, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Generation of a one-dimensional layer of a two- dimensional discrete Voronoi diagram. For each sample point one conic section is rendered above the layer with re- spect to the distance of the point to the layer. Using the depth buffer and orthogonal projection results in an approximation of the discrete Voronoi diagram in the current layer. ", "caption_bbox": [96, 297, 397, 386]}, {"image_id": 3, "file_name": "356_03.png", "page": 5, "dpi": 300, "bbox": [440, 160, 717, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Illustration of triangulated conic sections with dif- ferent distances d to the current layer. ", "caption_bbox": [428, 312, 729, 340]}, {"image_id": 4, "file_name": "356_04.png", "page": 5, "dpi": 300, "bbox": [106, 487, 390, 639], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Projections of different triangulations for a conic section. The triangulation assures rotational symmetry of the conic section. All points lie on circles with growing radii. The number of triangles is determined by the number of tri- angles in the innermost ring: a) 3, b) 6. ", "caption_bbox": [96, 648, 397, 722]}, {"image_id": 5, "file_name": "356_05.png", "page": 6, "dpi": 300, "bbox": [106, 702, 389, 874], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Hull generation for a point cluster: a) Extract- ing an isosurface from the distance field to the point clus- ter. Voronoi regions on the isosurface induce neighborhoods. b) Neighbors are connected to form a hull. The image also shows an isosurface extracted from the distance field to the hull. ", "caption_bbox": [96, 883, 397, 972]}, {"image_id": 6, "file_name": "356_06.png", "page": 6, "dpi": 300, "bbox": [128, 160, 368, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Correct 1D discrete Voronoi diagram generation for a line and a point. The intersection of the black line with the hyperbola of the green point, gives a wrong border (cyan point) of the discrete Voronoi diagram. The correct line to render would be the red one. We approximate the red line by discretizing the black line with point samples (indicated as hyperbolae). ", "caption_bbox": [96, 315, 397, 420]}, {"image_id": 7, "file_name": "356_07.png", "page": 7, "dpi": 300, "bbox": [115, 774, 385, 910], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Enclosing surface of a cluster from the \"out5d\" data set. The hull of the cluster was generated as well as a distance field to it. We show isosurfaces extracted from that distance field with two different isovalues fiso . ", "caption_bbox": [96, 917, 397, 978]}, {"image_id": 8, "file_name": "356_08.png", "page": 8, "dpi": 300, "bbox": [116, 165, 714, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Computation times for generating the distance field to the points and for generating a distance field to the hull of the points including hull computation. For each point cluster, the number of points is given together with the dimensions of the used grid and the number of cells the cluster occupies in the grid. ", "caption_bbox": [96, 441, 729, 485]}], "357": [{"image_id": 0, "file_name": "357_00.png", "page": 3, "dpi": 300, "bbox": [412, 134, 731, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The total displacement of nodes due to projec- tion of all constraints for the first 15 iterations of layout for the citric acid cycle graph (Fig. 4), with m = 10 iterations of cyclically satisfying constraints for each layout iteration. Each \u201cspike\u201d corresponds to the increase in error on con- straints after taking an unconstrained step in a descent di- rection of the energy function which is rapidly reduced as the constraints are projected. Note that the units of displace- ment are proportional to the ideal edge length and that the Displacement axis is log-scale. For the first 10 iterations the circular cycle constraint is rotating, hence the \u201cstep-down\u201d in displacement once it is oriented such that the edges con- necting it to the rest of the graph are close to their ideal lengths. ", "caption_bbox": [428, 394, 729, 605]}, {"image_id": 1, "file_name": "357_01.png", "page": 3, "dpi": 300, "bbox": [170, 136, 415, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Projection of the constraint |p\u2212q| = d. The small- est position delta required to satisfy the constraint is r. ", "caption_bbox": [96, 276, 397, 305]}, {"image_id": 2, "file_name": "357_02.png", "page": 4, "dpi": 300, "bbox": [96, 134, 415, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Construction of distance constraints to position nodes equidistantly around a circle. ", "caption_bbox": [96, 323, 397, 351]}, {"image_id": 3, "file_name": "357_03.png", "page": 4, "dpi": 300, "bbox": [412, 136, 731, 480], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A metabolic pathway using constraints of the form (3) to require directed edges (not involved in a cycle) to point downwards and using a wheel constraint to make the cycle circular. ", "caption_bbox": [428, 491, 729, 550]}, {"image_id": 4, "file_name": "357_04.png", "page": 5, "dpi": 300, "bbox": [102, 136, 415, 457], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A 400 node lattice with the outside nodes con- strained to a circle. ", "caption_bbox": [96, 471, 397, 499]}, {"image_id": 5, "file_name": "357_05.png", "page": 5, "dpi": 300, "bbox": [412, 134, 731, 456], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A large biological pathway with non-overlapping convex hull boundaries around clusters. The clusters indi- cate functional partitions, such as parts of the carbohy- drate metabolism (glycolysis, gluconeogenesis) and several amino acid synthesis pathways derived from the MetaCrop database. Network courtesy Falk Schreiber. ", "caption_bbox": [428, 467, 729, 556]}, {"image_id": 6, "file_name": "357_06.png", "page": 6, "dpi": 300, "bbox": [96, 134, 415, 452], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A randomly generated tree with 768 nodes and several small clusters. Fixed orientation constraints are used to require the edges to point downwards and constraints are generated to prevent overlap between the convex-hulls of clusters. ", "caption_bbox": [96, 463, 397, 537]}, {"image_id": 7, "file_name": "357_07.png", "page": 7, "dpi": 300, "bbox": [98, 358, 399, 608], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The Bus1138 graph from [DKM06] with down- ward pointing edge constraints and non-overlapping rectan- gular node boundaries. The graph has 1,138 nodes, 1,458 edges and therefore 1,458 oriented distance constraints. Layout subject to constraints took 4.09 seconds. Layout ad- justment subject to rectangular non-overlap constraints then took 4.31 seconds. ", "caption_bbox": [96, 618, 397, 722]}], "358": [{"image_id": 0, "file_name": "358_00.png", "page": 3, "dpi": 300, "bbox": [412, 134, 731, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Two interacting edges P and Q. The spring forces Fs and the electrostatic force Fe that are exerted on subdivi- sion point p2 by p1 , p3 , and q2 are shown. ", "caption_bbox": [428, 311, 729, 356]}, {"image_id": 1, "file_name": "358_01.png", "page": 4, "dpi": 300, "bbox": [96, 134, 730, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Part of (a) a straight-line graph that is bundled (b) without and (c) with edge compatibility measures. These measures reduce the amount of bundling between incompatible edges while retaining it in parts of the graph where this is desirable. ", "caption_bbox": [96, 310, 729, 338]}, {"image_id": 2, "file_name": "358_02.png", "page": 4, "dpi": 300, "bbox": [96, 344, 731, 441], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Geometric concepts and situations necessary to illustrate the edge compatibility measures (a) angle compatibility Ca , (b) scale compatibility Cs , (c) position compatibility C p , and (d) visibility compatibility Cv . ", "caption_bbox": [95, 447, 729, 476]}, {"image_id": 3, "file_name": "358_03.png", "page": 4, "dpi": 300, "bbox": [448, 493, 707, 560], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Bundling edges that differ considerably in length can result in noticeable stretching and curving of short edges. Original edges, curved edges and attracting forces are shown in black, blue, and red, respectively. ", "caption_bbox": [428, 564, 729, 623]}, {"image_id": 4, "file_name": "358_04.png", "page": 5, "dpi": 300, "bbox": [428, 361, 732, 501], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Part of a bundled graph at (a) 0%, (b) 25%, and (c) 50% smoothing. A small amount of smoothing makes edges less jagged resulting in bundles that are easy to follow. ", "caption_bbox": [428, 503, 729, 546]}, {"image_id": 5, "file_name": "358_05.png", "page": 6, "dpi": 300, "bbox": [96, 756, 732, 851], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A low amount of straightening provides an indication of the number of edges comprising a bundle by widening the bundle. (a) s = 0, (b) s = 10, and (c) s = 40. If s is 0, color more clearly indicates the number of edges comprising a bundle. ", "caption_bbox": [96, 856, 729, 884]}, {"image_id": 6, "file_name": "358_06.png", "page": 6, "dpi": 300, "bbox": [110, 457, 713, 718], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: US migration graph (1715 nodes, 9780 edges) (a) not bundled and bundled using (b) FDEB with inverse-linear model, (c) GBEB, and (d) FDEB with inverse-quadratic model. The same migration flow is highlighted in each graph. ", "caption_bbox": [96, 721, 729, 749]}, {"image_id": 7, "file_name": "358_07.png", "page": 6, "dpi": 300, "bbox": [96, 134, 713, 420], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: US airlines graph (235 nodes, 2101 edges) (a) not bundled and bundled using (b) FDEB with inverse-linear model, (c) GBEB, and (d) FDEB with inverse-quadratic model. ", "caption_bbox": [96, 422, 729, 450]}], "359": [{"image_id": 0, "file_name": "359_00.png", "page": 2, "dpi": 300, "bbox": [513, 528, 646, 674], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Node-link diagram of a directed graph with weighted edges. Each edge is annotated with its weight. ", "caption_bbox": [428, 688, 729, 716]}, {"image_id": 1, "file_name": "359_01.png", "page": 3, "dpi": 300, "bbox": [133, 159, 362, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Node-link diagram of a directed weighted graph in a TimeArcTrees representation. The weighted edges are represented by colored arcs. ", "caption_bbox": [96, 348, 397, 391]}, {"image_id": 2, "file_name": "359_02.png", "page": 3, "dpi": 300, "bbox": [104, 412, 403, 489], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Incoming and outgoing edge ports", "caption_bbox": [132, 504, 360, 517]}, {"image_id": 3, "file_name": "359_03.png", "page": 3, "dpi": 300, "bbox": [452, 159, 707, 334], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A graph in a TimeArcTrees representation: The hierarchy is shown on the left hand side. In this example, the hierarchy is completely expanded. ", "caption_bbox": [428, 349, 729, 392]}, {"image_id": 4, "file_name": "359_04.png", "page": 3, "dpi": 300, "bbox": [460, 528, 698, 704], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Parts of the hierarchy can be expanded or col- lapsed to an interactively selectable level. In this example, the complete subtree with root 136 is collapsed and all in- coming, outgoing and inner edges of this subtree are aggre- gated. ", "caption_bbox": [428, 719, 729, 793]}, {"image_id": 5, "file_name": "359_05.png", "page": 4, "dpi": 300, "bbox": [96, 481, 409, 715], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The TimeArcTrees visualization for a sequence of three graphs with the information hierarchy. Graph sep- arators are interactive widgets that can be used to change the horizontal space for each graph, as well as to aggregate several subsequent graphs. ", "caption_bbox": [96, 725, 397, 799]}, {"image_id": 6, "file_name": "359_06.png", "page": 4, "dpi": 300, "bbox": [415, 136, 723, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The second and third graph are aggregated to a single graph. The graph separator between the two original graphs was removed. ", "caption_bbox": [428, 360, 729, 403]}, {"image_id": 7, "file_name": "359_07.png", "page": 4, "dpi": 300, "bbox": [96, 214, 415, 351], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A sequence of graphs in a traditional node-link representation. ", "caption_bbox": [96, 361, 397, 389]}, {"image_id": 8, "file_name": "359_08.png", "page": 5, "dpi": 300, "bbox": [428, 508, 741, 947], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: A sequence of maps showing the shortest paths at different points of time. In the lower right map all paths are shown at once. ", "caption_bbox": [428, 961, 729, 1004]}, {"image_id": 9, "file_name": "359_09.png", "page": 5, "dpi": 300, "bbox": [97, 657, 409, 726], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The start node for shortest path visualization is selected by clicking at the green circle sector of a node. The target node can be selected with the red circle sector. ", "caption_bbox": [96, 736, 397, 779]}, {"image_id": 10, "file_name": "359_10.png", "page": 5, "dpi": 300, "bbox": [96, 159, 410, 378], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Excerpt of the German Autobahn map: The map is divided into four regions. The start node for our shortest path example is indicated by a green flag. The target node by a red one. ", "caption_bbox": [96, 388, 397, 447]}, {"image_id": 11, "file_name": "359_11.png", "page": 5, "dpi": 300, "bbox": [517, 164, 640, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The costs accumulated along the shortest path from the start node up to this node are represented by a cir- cular bar. ", "caption_bbox": [428, 283, 729, 326]}], "360": [{"image_id": 0, "file_name": "360_00.png", "page": 1, "dpi": 300, "bbox": [412, 376, 731, 874], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example of an Euler diagram rendered with our approach. The red set contains world monuments, the green set contains things that are typically Italian, and the blue set contains things that are typically French. The red set shares the element \u201cColosseum\u201d with the green set and the element \u201cEiffel Tower\u201d with the blue set as demonstrated through overlaps of the regions. ", "caption_bbox": [428, 888, 729, 992]}, {"image_id": 1, "file_name": "360_01.png", "page": 2, "dpi": 300, "bbox": [412, 136, 729, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Classes, zones, and labelling conventions. (a) We use capital letters to denote classes. In this example, M de- notes the set of monuments, I the set of Italian things, and F the set of French ones. (b) We use sequences of lower case letters to label zones. For example, the intersection between I and M is labelled im. ", "caption_bbox": [428, 315, 729, 404]}, {"image_id": 2, "file_name": "360_02.png", "page": 3, "dpi": 300, "bbox": [161, 134, 731, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: High-level procedure for drawing Euler diagrams. First, construct the intersection graph. Second, draw the intersec- tion graph using a planar graph drawing algorithm. Third, draw the set boundaries around all nodes in the same class. ", "caption_bbox": [96, 326, 729, 354]}, {"image_id": 3, "file_name": "360_03.png", "page": 4, "dpi": 300, "bbox": [96, 134, 729, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Overview of our drawing algorithm. (a) Initial output of the FPP algorithm. This layout of the intersection graph is unsatisfactory in appearance. (b) The algorithm draws the intersection graph with PrEd [Ber99]. (c) The algorithm constructs a grid graph around the layout of the intersection graph. (d) Elements of the sets are added to the drawing, and the algorithm runs several iterations of PrEd. In the four subfigures, nodes of the intersection graph are red, the nodes of the grid graph are green, and the elements of the sets are blue. ", "caption_bbox": [96, 351, 729, 425]}, {"image_id": 4, "file_name": "360_04.png", "page": 5, "dpi": 300, "bbox": [96, 136, 415, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Constructing a node-region. (a) The edges inci- dent to the node of the intersection graph define three sec- tors, bounded by (e1 , e2 ), (e2 , e3 ), and (e3 , e1 ). (b) Consider- ing only the red sector, we are able to define the vectors f1 , f2 \u03b4 radians apart. (c) The intersections between the vectors fi and the circumference of the circle are taken as vertices of the node-region. ", "caption_bbox": [96, 307, 397, 411]}, {"image_id": 5, "file_name": "360_05.png", "page": 5, "dpi": 300, "bbox": [412, 134, 730, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Construction of an edge-region. An edge of the intersection graph divides the circles into the sectors A, B and C. The polygon vertices computed in the previous step are ordered clockwise and anticlockwise. In the diagram, the edges of the grid graph which define the edge-region of e are: (a4 , a1 ), (b2 , c1 ), (a4 , c1 ), and (b2 , a1 ). ", "caption_bbox": [428, 307, 729, 396]}, {"image_id": 6, "file_name": "360_06.png", "page": 6, "dpi": 300, "bbox": [412, 136, 721, 451], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A diagram showing sixty highest rated movies in IMDB with full credited cast. ", "caption_bbox": [428, 464, 729, 492]}, {"image_id": 7, "file_name": "360_07.png", "page": 6, "dpi": 300, "bbox": [96, 134, 415, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Construction of smooth B\u00e9zier curves at grid graph vertices. (a) Case 1: if two incident edges e1 and e2 of the grid graph share the same set of classes, the orientation of l is given by the line perpendicular to the bisector of the angle between e1 and e2 . (b) Case 2: if three or more inci- dent edges, ei , i = 1 . . . n, are associated with different sets of classes, and there exists an edge ek that is the union of all these classes, the orientation of l is the orientation of ek (c) Case 3: if neither of the above-cases apply, we cannot have continuous B\u00e9zier curves at this grid graph vertex. Thus, we place the control points along their associated grid graph edges. That way, no new boundary intersections are intro- duced. ", "caption_bbox": [96, 291, 397, 487]}, {"image_id": 8, "file_name": "360_08.png", "page": 7, "dpi": 300, "bbox": [429, 721, 732, 900], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Cast of the trilogy \u201cThe Lord of the Rings\u201d. (a) The diagram generated. \u201cThe Fellowship of the Ring\u201d is red, \u201cThe Two Towers\u201d is green, and \u201cThe Return of the King\u201d is blue. (b) The zone shared by all three films. In these figures, images of the actors are shown when they are available in the directory. ", "caption_bbox": [428, 913, 729, 1002]}, {"image_id": 9, "file_name": "360_09.png", "page": 7, "dpi": 300, "bbox": [140, 134, 731, 433], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: An Euler diagram of IMDB movies composed by about twenty movies. (b) An overall look. The sets have been labelled with capital letters. A - The Lord of the Rings - Part II (2002). B - The Lord of the Rings - Part I (2001). C - The Lord of the Rings - Part III (2003). D - American History X (1998). E - The Matrix (1999). F - Taxi Driver (1976). G - Goodfellas (1990). H - The Godfather: Part II (1974). I - Fight Club (1999). J - Raiders of the Lost Ark (1981). K - Apocalypse Now (1979). L - The Godfather (1972). M - Se7en (1995). N - Star Wars: Episode V (1980). O - The Shawshank Redemption (1994). P - The Dark Knight (2008). Q - Star Wars (1977). R - The Usual Suspects (1995). S - American Beauty (1999). T - L\u00e9on (1994). Capital letters labelling sets are placed manually, but every other part of the diagram generation was automatic. (b) A close-up of part of the diagram. In these figures, images of the actors are shown when they are available in the directory. ", "caption_bbox": [96, 446, 729, 566]}, {"image_id": 10, "file_name": "360_10.png", "page": 8, "dpi": 300, "bbox": [96, 134, 415, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Direction for future work. The original diagram can be improved simplifying the shape of the curves. This mock-up was created with a version of the algorithm that is under development. As seen in this picture, at the moment we cannot guarantee that new regions will not be created. ", "caption_bbox": [96, 322, 397, 396]}], "361": [{"image_id": 0, "file_name": "361_00.png", "page": 3, "dpi": 300, "bbox": [99, 137, 415, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Convolution. a) At constant speed. b) Accelerated.", "caption_bbox": [96, 239, 397, 252]}, {"image_id": 1, "file_name": "361_01.png", "page": 4, "dpi": 300, "bbox": [95, 135, 731, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Computation in various spaces: a) grid space. b) geographic space. c) image space.", "caption_bbox": [177, 308, 649, 321]}, {"image_id": 2, "file_name": "361_02.png", "page": 6, "dpi": 300, "bbox": [95, 135, 730, 464], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Vessel density on a logarithmic scale in front of the harbour of Rotterdam, The Netherlands, of a single day convolved with a kernel of 1.5km. The multi-scale density is decorated with convolved trajectories with a kernel of 100m. a) Density with continuous color mapping . b) Density with discrete color mapping. c) Multi-scale density with continuous color mapping. d) Multi-scale density with discrete color mapping. ", "caption_bbox": [96, 476, 729, 535]}, {"image_id": 3, "file_name": "361_03.png", "page": 7, "dpi": 300, "bbox": [96, 135, 731, 821], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: a) Vessel density of the Dutch coast: Trajectories of a week covering 160,000km2 , and convolved with kernels of 5km and 200m. The picture represents 3.5GB of data. The anchor zone and yielding ferry inset are renderings of a day using kernels of 1.5km and 100m. b) Vessel density of a stormy day: northwest wind with force 8 on the Beaufort scale change the movement pattern of vessels. c) Vessel density of areas where vessels sail less than 3 knot during smooth weather. ", "caption_bbox": [96, 828, 729, 890]}, {"image_id": 4, "file_name": "361_04.png", "page": 8, "dpi": 300, "bbox": [95, 135, 730, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison of convolution with 15 knot fixed speed (a) and velocity adjusted vessel density (b). The colored boxes annotate some of the visible differences between the convolution methods. ", "caption_bbox": [96, 381, 729, 409]}], "362": [{"image_id": 0, "file_name": "362_00.png", "page": 2, "dpi": 300, "bbox": [105, 252, 356, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Stacking approach used in Primavera Project Planner. Two activities are delayed and one activity is added in Schedule B. ", "caption_bbox": [98, 357, 381, 399]}, {"image_id": 1, "file_name": "362_01.png", "page": 3, "dpi": 300, "bbox": [431, 161, 737, 331], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overlap view in Schedule A\u2019s window. (a) Activity in Schedule B is delayed compared to Schedule A; (b) Activity in Schedule B does not exist in Schedule A; (c) Activity in Schedule B has shorter duration than in Schedule A; (d) Early Start; (e) Late Start; (f) Early Finish; (g) Late Finish. ", "caption_bbox": [428, 330, 731, 415]}, {"image_id": 2, "file_name": "362_02.png", "page": 4, "dpi": 300, "bbox": [93, 136, 711, 440], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparing two schedules: (a) Title shows that schedule A (left) is compared to Schedule B (right); (b) Focus scope shown by black box in sidebar; (c) InfoBox with details of both schedules; (d) Corresponding highlight; (e) Sidebar. ", "caption_bbox": [94, 439, 707, 480]}, {"image_id": 3, "file_name": "362_03.png", "page": 5, "dpi": 300, "bbox": [116, 191, 715, 570], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparing three schedules with TbarView: (I) File section panel; (II) Widget panel; (III) Tbar comparison; (a) Colors to distinguish schedules on Gantt chart title bars and in the file selection panel; (b) Select range by dragging out a box; (c) Corresponding highlight; (d) Duration variances; (e) End Date variances. ", "caption_bbox": [109, 571, 715, 613]}, {"image_id": 4, "file_name": "362_04.png", "page": 6, "dpi": 300, "bbox": [430, 815, 729, 974], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Task completion time compared between TbarView and Multiple Window approaches ", "caption_bbox": [428, 977, 727, 1004]}, {"image_id": 5, "file_name": "362_05.png", "page": 6, "dpi": 300, "bbox": [101, 839, 397, 999], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Task completion time compared between overlap and side-by-side approaches ", "caption_bbox": [99, 1000, 398, 1027]}], "363": [{"image_id": 0, "file_name": "363_00.png", "page": 4, "dpi": 300, "bbox": [412, 136, 717, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Finding circuit breakers (leftmost highlighted component) connected to the focused component (rightmost highlighted component). ", "caption_bbox": [428, 287, 729, 330]}, {"image_id": 1, "file_name": "363_01.png", "page": 4, "dpi": 300, "bbox": [96, 134, 415, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Contextual information preserved between a schematic (left) and the related wiring (right) diagrams in our system. ", "caption_bbox": [96, 323, 397, 366]}, {"image_id": 2, "file_name": "363_02.png", "page": 5, "dpi": 300, "bbox": [99, 134, 731, 312], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Transition by blending from a schematic diagram to a related wiring diagram preserving spatial information of a selected component. (a) Schematic diagram, (b) initial view of Transition by blending combined with our Relational lens, (c) 60% blending, and (d) final transition to the related wiring diagram. ", "caption_bbox": [96, 325, 729, 368]}, {"image_id": 3, "file_name": "363_03.png", "page": 5, "dpi": 300, "bbox": [443, 392, 717, 537], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Highlighting components and connections in var- ious colors (green: marked as working status, red: marked as not-working status, cyan: locked focusing, purple: high- lighted as a neighbor) and with different marks (switch on/off, working/not-working status). ", "caption_bbox": [428, 549, 729, 623]}, {"image_id": 4, "file_name": "363_04.png", "page": 6, "dpi": 300, "bbox": [96, 134, 723, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Relational lens applied to the focused component in (a) a schematic diagram and (c) a wiring diagram to see more detail wiring information. (b) The wiring information shown through the Relational lens in a schematic diagram, and (d) more detail wiring information shown through the Relational lens in a wiring diagram. ", "caption_bbox": [96, 331, 729, 374]}, {"image_id": 5, "file_name": "363_05.png", "page": 6, "dpi": 300, "bbox": [443, 821, 717, 938], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Flow animation mapped with an arrow texture an- imated along the flow direction. ", "caption_bbox": [428, 949, 729, 977]}, {"image_id": 6, "file_name": "363_06.png", "page": 7, "dpi": 300, "bbox": [102, 134, 731, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Results from the field study by 7 senior students in the school of Aviation Technology at Purdue University. (a) Usability for each function, and (b) usefulness for each feature from the field study. ", "caption_bbox": [96, 371, 729, 399]}], "364": [{"image_id": 0, "file_name": "364_00.png", "page": 3, "dpi": 300, "bbox": [442, 160, 718, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Deriving the texture for a petal in a digital lily. (a) gives a standard HSB color circle. (b) shows how to deriving the texture for the petal in Fig. 1.(a) by mapping the texture of the circle shown in (a) to the petal shape. ", "caption_bbox": [428, 313, 729, 372]}, {"image_id": 1, "file_name": "364_01.png", "page": 3, "dpi": 300, "bbox": [124, 160, 371, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The composition of a digital lily. (a) shows the dig- ital lily derived from the handwriting in Fig. 7(I-O1 ). (b) il- lustrates the procedure to determine the contour of the petal in (a). ", "caption_bbox": [96, 320, 397, 379]}, {"image_id": 2, "file_name": "364_02.png", "page": 3, "dpi": 300, "bbox": [510, 862, 648, 980], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Determining the shape of a pistil.", "caption_bbox": [469, 991, 689, 1004]}, {"image_id": 3, "file_name": "364_03.png", "page": 4, "dpi": 300, "bbox": [412, 136, 729, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Determining the shape of an anther flake (a) and its interior texture (b). ", "caption_bbox": [428, 301, 729, 329]}, {"image_id": 4, "file_name": "364_04.png", "page": 5, "dpi": 300, "bbox": [103, 160, 391, 307], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Two pairs of simple handwriting pieces by two persons, where the second person tries to facsimile the writ- ing of the first one. The first row shows their handwritings, which look very similar; the second row shows their corre- sponding digital lilies, which appear very different. ", "caption_bbox": [96, 314, 397, 388]}, {"image_id": 5, "file_name": "364_05.png", "page": 5, "dpi": 300, "bbox": [104, 413, 392, 560], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Two pairs of digital handwritings and their corre- sponding digital lilies. (I-a) is written with higher pressure than (I-b) and (II-a) is written in a faster speed than (II-b). ", "caption_bbox": [96, 569, 397, 613]}, {"image_id": 6, "file_name": "364_06.png", "page": 8, "dpi": 300, "bbox": [96, 136, 726, 966], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Three groups of authentic digital signatures and their facsimiles. (O) stands for the authentic signatures by the original person and (F) stands for facsimiled results by others. ", "caption_bbox": [96, 971, 729, 999]}], "365": [{"image_id": 0, "file_name": "365_00.png", "page": 2, "dpi": 300, "bbox": [147, 282, 354, 410], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: RadViz inspired visualization from our project (top-half view). Data is unevenly distributed. ", "caption_bbox": [96, 421, 397, 449]}, {"image_id": 1, "file_name": "365_01.png", "page": 3, "dpi": 300, "bbox": [443, 536, 717, 854], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The \"probe state\" above shows only labels and summary statistics. The \"detail state\" below provides addi- tional details and interactive filtering. ", "caption_bbox": [428, 867, 729, 910]}, {"image_id": 2, "file_name": "365_02.png", "page": 4, "dpi": 300, "bbox": [114, 704, 381, 838], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The pie segments over the lens allow users to scroll the list of labels. ", "caption_bbox": [96, 849, 397, 877]}, {"image_id": 3, "file_name": "365_03.png", "page": 5, "dpi": 300, "bbox": [111, 162, 377, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The size of the lens automatically changes ac- cording to data density. ", "caption_bbox": [96, 403, 397, 431]}, {"image_id": 4, "file_name": "365_04.png", "page": 5, "dpi": 300, "bbox": [464, 409, 717, 541], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Label filtering: only the labels of applications used in 3 departments are shown. ", "caption_bbox": [428, 553, 729, 581]}, {"image_id": 5, "file_name": "365_05.png", "page": 6, "dpi": 300, "bbox": [412, 136, 714, 379], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Comparison of layout and sorting strategies: ra- dial ordering on the top and data dimension ordering below. ", "caption_bbox": [428, 390, 729, 418]}, {"image_id": 6, "file_name": "365_06.png", "page": 7, "dpi": 300, "bbox": [113, 833, 382, 878], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Average rating of the perceived usefulness and usability. ", "caption_bbox": [96, 892, 397, 920]}], "366": [{"image_id": 0, "file_name": "366_00.png", "page": 3, "dpi": 300, "bbox": [428, 799, 732, 1026], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Color matching task display layout for all conditions (Mouse, Pen, and Slider). ", "caption_bbox": [428, 1025, 695, 1052]}, {"image_id": 1, "file_name": "366_01.png", "page": 3, "dpi": 300, "bbox": [428, 151, 732, 321], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Color matching task apparatus. The physical slider board was removed for Mouse & Pen conditions. ", "caption_bbox": [428, 320, 708, 347]}, {"image_id": 2, "file_name": "366_02.png", "page": 5, "dpi": 300, "bbox": [98, 788, 402, 969], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Boxplot Visual Fixations on UI Control Region.", "caption_bbox": [95, 968, 392, 981]}, {"image_id": 3, "file_name": "366_03.png", "page": 5, "dpi": 300, "bbox": [431, 446, 734, 623], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Boxplot Match Times(s) for each Control", "caption_bbox": [428, 626, 692, 639]}, {"image_id": 4, "file_name": "366_04.png", "page": 5, "dpi": 300, "bbox": [98, 371, 402, 551], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Boxplot Visual Fixations on Color Target.", "caption_bbox": [95, 551, 364, 564]}, {"image_id": 5, "file_name": "366_05.png", "page": 5, "dpi": 300, "bbox": [98, 573, 402, 765], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Boxplot Visual Fixations on each UI Control.", "caption_bbox": [98, 767, 383, 780]}, {"image_id": 6, "file_name": "366_06.png", "page": 6, "dpi": 300, "bbox": [98, 530, 407, 729], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Travel Distances (mm) for each Control.", "caption_bbox": [95, 731, 353, 744]}, {"image_id": 7, "file_name": "366_07.png", "page": 6, "dpi": 300, "bbox": [95, 134, 415, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Summary of Differences between Individual Controls (\u2018Easy\u2019: cL*, & ct vs. \u2018Difficult\u2019: ca* & cb*) and UI Conditions (\u2018Graphic\u2019: UImouse & UIpen vs. \u2018Physical\u2019: ", "caption_bbox": [428, 296, 736, 338]}], "367": [{"image_id": 0, "file_name": "367_00.png", "page": 3, "dpi": 300, "bbox": [203, 134, 731, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: During our pre-experiment questionnaires, we asked participants to rate five visual metaphors for hierarchies, based on common visualizations of hierarchy data. Participants were given a description of a simple tree structure and asked to rank these images from one to five in terms of how well they depicted the structure. ", "caption_bbox": [96, 294, 729, 337]}, {"image_id": 1, "file_name": "367_01.png", "page": 3, "dpi": 300, "bbox": [441, 820, 731, 977], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The visualizations used in the study.", "caption_bbox": [461, 989, 697, 1002]}, {"image_id": 2, "file_name": "367_02.png", "page": 5, "dpi": 300, "bbox": [141, 136, 415, 372], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) There was an overall significant effect of question compatibility on response correctness. Participants were generally more likely to answer compatible questions correctly and incompatible questions incorrectly. However, there was no such significant difference for participants with above-average spatial ability, participants who scored highly on the personality dimension of Openness, or partic- ipants who reported no verbal metaphor preference. ", "caption_bbox": [96, 387, 397, 507]}, {"image_id": 3, "file_name": "367_03.png", "page": 6, "dpi": 300, "bbox": [96, 134, 712, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) While these differences are not significant, patterns of self-reported verbal metaphor preference can be seen among participants who ranked a given visual metaphor (Figure 1) as the best depiction of a hierarchy. Contrary to our hypothesis, users who ranked the node-link diagram highest as well as those who ranked the treemap highest tend to prefer containers verbal metaphors. Those who ranked an icicle plot highest mostly preferred levels verbal metaphors, although this is a small group. Non-significant but notable gender differences also emerged in self-reported metaphor preference. (b) While women wore more likely than men to report a preference for verbal metaphors of containers, (c) they were also less likely to choose a treemap as the best visual metaphor for a hierarchy. ", "caption_bbox": [96, 371, 729, 475]}, {"image_id": 4, "file_name": "367_04.png", "page": 7, "dpi": 300, "bbox": [179, 134, 731, 355], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: While we expected users to respond faster to questions in their self-reported preferred verbal metaphor, this pattern only emerged for women. Men responded significantly faster to levels questions no matter what their self-reported metaphor preference. Women who did not prefer one verbal metaphor over another tended to respond faster to containers questions. ", "caption_bbox": [96, 368, 729, 411]}], "368": [{"image_id": 0, "file_name": "368_00.png", "page": 2, "dpi": 300, "bbox": [428, 166, 736, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An overview of the visual analytics tool for exam- ining the temporal aspects of fMRI data. ", "caption_bbox": [428, 390, 729, 420]}, {"image_id": 1, "file_name": "368_01.png", "page": 4, "dpi": 300, "bbox": [113, 437, 388, 750], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Fig.(a) The shape of a few typical hemodynam- ical response function (HRF). However, in reality, the ex- act shape of HRF is highly variable. Fig.(b) The raw time- courses (mean shifted) through two voxels (blue and red), both presumably activated. The solid line shows the mea- sured time course, the dashed line is an estimate of the base- line drift of the intensity over time. Fig.(c) The stimulus func- tion p(t) as a Dirac-\u03b4 train (dark blue). A few curves rhi from the response set, obtained by convolving p(t) with a theoretical HRF hi (t) ", "caption_bbox": [96, 761, 397, 915]}, {"image_id": 2, "file_name": "368_02.png", "page": 6, "dpi": 300, "bbox": [431, 159, 740, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Fig. (a) The main window showing the structural volume overlaid with the clusters in 3D and 2D orthographic views. Fig. (b) Cluster time-series displays. Fig. (c) Naviga- tion pane for the cluster hierarchy. ", "caption_bbox": [428, 544, 729, 605]}, {"image_id": 3, "file_name": "368_03.png", "page": 7, "dpi": 300, "bbox": [431, 378, 733, 781], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Fig. (a) Six VOIs (as 3D blobs) overlaid on the three orthogonal planes (cutting planes) through the struc- tural volume. Fig. (b) The corresponding mean time-courses through the selected VOIs, along with their \u00b11 std. dev. en- velopes. Here, a temporal cascade (green lines) in activation can be seen. ", "caption_bbox": [428, 791, 729, 882]}, {"image_id": 4, "file_name": "368_04.png", "page": 7, "dpi": 300, "bbox": [103, 224, 393, 671], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Fig. (a)-(b) Maximum intensity projections of the activity maps for two different settings of the analysis proce- dures. Darker shades of grey indicates higher levels of ac- tivation. Fig. (c) A VOI selected from the set generated by the tool. Fig. (d) The mean time-course of the VOI and its \u00b11 std. dev. envelope, suggesting that this region of the brain is not activated. Fig. (e) Another VOI selected from the set generated by the tool. Fig. (f) The mean time-course of the VOI and its \u00b11 std. dev. envelope, suggesting that this region of the brain may be activated ", "caption_bbox": [96, 681, 397, 833]}], "369": [{"image_id": 0, "file_name": "369_00.png", "page": 3, "dpi": 300, "bbox": [428, 159, 732, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Pipeline for visual analysis of aneurysm flow fea- tures. The orange fields cover the application area of our approach. ", "caption_bbox": [428, 268, 729, 311]}, {"image_id": 1, "file_name": "369_01.png", "page": 4, "dpi": 300, "bbox": [412, 136, 732, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A: Cube Map: an axis-aligned cube is positioned at the center C of the aneurysm and the aneurysm\u2019s surface is projected onto five cube sides (dotted lines). B: The map zones created from the cube sides (color-coded to clarify the orientation coherence). C: Redundant feature depiction at cube borders. ", "caption_bbox": [428, 262, 729, 351]}, {"image_id": 2, "file_name": "369_02.png", "page": 4, "dpi": 300, "bbox": [458, 369, 697, 544], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Map Layout: Colored arrows depict transitions between map borders. Black arrows show the transition paths towards the focus area (C\u2019). Surface point A lies op- posite to point B. Their map locations exhibit a linear co- herence: A\u2019-C\u2019-B\u2019. ", "caption_bbox": [428, 554, 729, 628]}, {"image_id": 3, "file_name": "369_03.png", "page": 5, "dpi": 300, "bbox": [126, 159, 370, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Distortion: An icosahedron is used to visualize the non-conformal, spherical distortion of the map. ", "caption_bbox": [96, 333, 397, 361]}, {"image_id": 4, "file_name": "369_04.png", "page": 5, "dpi": 300, "bbox": [465, 159, 702, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Interaction: The chosen path to translate (T) a map feature results into a comprehensible aligned rotation (R) of the model. Right: An example for the interactive tran- sition of a feature (red triangle) from map to model. A simi- lar feature orientation on map and model can be observed. ", "caption_bbox": [428, 320, 729, 394]}, {"image_id": 5, "file_name": "369_05.png", "page": 6, "dpi": 300, "bbox": [412, 136, 709, 210], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Correlation Tool: If a point A on the map is se- lected, it is marked on the map and the surface, as well as the opposite point B. ", "caption_bbox": [428, 220, 729, 263]}, {"image_id": 6, "file_name": "369_06.png", "page": 6, "dpi": 300, "bbox": [96, 134, 415, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Data for Correlation Tool: The surface colors of the model (A) encode world coordinates used to link them with map coordinates (B). ", "caption_bbox": [96, 254, 397, 297]}, {"image_id": 7, "file_name": "369_07.png", "page": 7, "dpi": 300, "bbox": [96, 420, 729, 607], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: The rating from 1 (good) to 5 (bad) of different characteristics: the effort to understand the visualization, the complexity of interaction, the overview and the corre- lation between map and model without (NT) and with (T) usage of the correlation tool. ", "caption_bbox": [96, 808, 397, 882]}, {"image_id": 8, "file_name": "369_08.png", "page": 7, "dpi": 300, "bbox": [96, 159, 729, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Saccular Aneurysm AN01: Left: Areas of high WSS at the lower (1) and upper (2) side of the aneurysm and a small, defined WSS feature at the backside (3). Correlation Tool: A landmark placed at a local area of higher WSS (4). The related point A and its opposing point B were marked. Right: Vessels that occlude the map are rendered in a semi-transparent, silhouette-enhancing toon style (5). Low WSS (6) at the backside, opposite to the area of higher WSS in the focus (7). ", "caption_bbox": [96, 617, 729, 676]}, {"image_id": 9, "file_name": "369_09.png", "page": 8, "dpi": 300, "bbox": [96, 134, 415, 269], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: A selection of the color maps that were discussed in the evaluation: Optimized Color Map (A), Heated Object Color Map (B), both combined in a Split Color Map (C) and the color map that resulted from the discussion (D). ", "caption_bbox": [96, 279, 397, 338]}], "370": [{"image_id": 0, "file_name": "370_00.png", "page": 3, "dpi": 300, "bbox": [440, 519, 718, 676], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: In the image plane, five points are labeled as three classes. Other points are unlabeled. ", "caption_bbox": [428, 687, 729, 715]}, {"image_id": 1, "file_name": "370_01.png", "page": 3, "dpi": 300, "bbox": [135, 134, 731, 351], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The conceptual overview of our approach.", "caption_bbox": [280, 362, 544, 375]}, {"image_id": 2, "file_name": "370_02.png", "page": 4, "dpi": 300, "bbox": [125, 220, 369, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration of our semi-supervised classifica- tion algorithm. Various glyphs are used to encode different classes. ", "caption_bbox": [96, 317, 397, 361]}, {"image_id": 3, "file_name": "370_03.png", "page": 5, "dpi": 300, "bbox": [114, 299, 381, 591], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Widgets used for modeling the muscle geometry. (a) The slicing metaphor; (b) The shape generator in a slic- ing plane; (c) The shape generator in a volume rendering window; (d) The position editor. ", "caption_bbox": [96, 600, 397, 659]}, {"image_id": 4, "file_name": "370_04.png", "page": 5, "dpi": 300, "bbox": [412, 134, 732, 412], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Designing fibers (a) without and (b) with prevent- ing the penetration. In both cases, the red lines indicate pro- hibited drawings. ", "caption_bbox": [428, 421, 729, 465]}, {"image_id": 5, "file_name": "370_05.png", "page": 5, "dpi": 300, "bbox": [469, 776, 691, 960], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Generating the outlier shape and internal fibers of a skeletal muscle. ", "caption_bbox": [428, 969, 729, 998]}, {"image_id": 6, "file_name": "370_06.png", "page": 6, "dpi": 300, "bbox": [442, 516, 716, 884], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Top row: the classification results with a conven- tional transfer function. The other pictures show six consec- utive classification results with our approach. Each result is associated with a specific user indication in the image plane. ", "caption_bbox": [428, 894, 729, 953]}, {"image_id": 7, "file_name": "370_07.png", "page": 7, "dpi": 300, "bbox": [457, 497, 701, 695], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Top left: a hand-drawn illustra- tion.(Image courtesy of Medical Multimedia Group, www.medicalmultimediagroup.com); bottom left: a conven- tional volume illustration; right: a volume illustration with the modeled muscle. ", "caption_bbox": [428, 706, 729, 780]}, {"image_id": 8, "file_name": "370_08.png", "page": 7, "dpi": 300, "bbox": [133, 134, 415, 480], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Top left: a hand-drawn illustration.(Image cour- tesy of Zygote Media Group, www.3DScience.com); bottom left: the modeled fiber bundles with our approach; right: a volume illustration of the Hand dataset with the modeled muscle. Please note the white tendon in the fibers. ", "caption_bbox": [96, 490, 397, 564]}, {"image_id": 9, "file_name": "370_09.png", "page": 7, "dpi": 300, "bbox": [412, 134, 731, 389], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Top left: a hand-drawn illustra- tion.(Image courtesy of Medical Multimedia Group, www.medicalmultimediagroup.com); bottom left: the mod- eled fiber bundles with our approach; right: a volume illustration of the Knee dataset and the modeled muscle. ", "caption_bbox": [428, 399, 729, 473]}, {"image_id": 10, "file_name": "370_10.png", "page": 8, "dpi": 300, "bbox": [96, 134, 415, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Classification results for the Abdomen dataset with a well-tuned transfer function (left) and with our ap- proach (right). The region (denoted by a red circle) of a colon and two kidneys can not be separated with the transfer function while ours can. ", "caption_bbox": [96, 304, 397, 378]}], "371": [{"image_id": 0, "file_name": "371_00.png", "page": 2, "dpi": 300, "bbox": [412, 136, 675, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: 2D tensor deformation for b = 1.", "caption_bbox": [469, 272, 687, 285]}, {"image_id": 1, "file_name": "371_01.png", "page": 3, "dpi": 300, "bbox": [182, 294, 309, 367], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Matrix multiplication scheme showing direction of multiplication, storage target and indices of accumulated tensors. ", "caption_bbox": [96, 378, 397, 421]}, {"image_id": 2, "file_name": "371_02.png", "page": 3, "dpi": 300, "bbox": [448, 380, 708, 515], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Initial sphere Sr with P \u2208 sur f (Sr ) is transformed into ellipsoid. ", "caption_bbox": [428, 524, 729, 553]}, {"image_id": 3, "file_name": "371_03.png", "page": 6, "dpi": 300, "bbox": [96, 134, 415, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A segment of a streakline is fitted to boundary ge- ometry, after an intersection was detected. ", "caption_bbox": [96, 276, 397, 304]}, {"image_id": 4, "file_name": "371_04.png", "page": 7, "dpi": 300, "bbox": [457, 614, 699, 793], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visualization of periodic streak areas in a Karman vortex street with boundary streakline. Periodicity, frequency and form of the deformations give an impression of the final material composition. ", "caption_bbox": [428, 804, 729, 863]}, {"image_id": 5, "file_name": "371_05.png", "page": 7, "dpi": 300, "bbox": [96, 424, 396, 703], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: 3D streakline with ellipsoids in a sequence of four consecutive time steps. Clinching, stretching as well as rota- tional behavior over time and space can be observed. Col- oring indicates areas with heavily deformed volumes. ", "caption_bbox": [96, 713, 397, 772]}, {"image_id": 6, "file_name": "371_06.png", "page": 7, "dpi": 300, "bbox": [115, 159, 374, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Four 2D streaklines integrated past a spherical- obstacle. High resolution of lines gives a homogeneous im- pression, while low point resolution gives a good impression of general deformation properties. ", "caption_bbox": [96, 341, 397, 400]}, {"image_id": 7, "file_name": "371_07.png", "page": 7, "dpi": 300, "bbox": [457, 310, 699, 490], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visualization of streak areas in a sequence of three time steps. Bending, stretching, thinning and thickening de- formations in all areas are visible. Area analysis near the right border of the dataset provides information about out- put material distributions. ", "caption_bbox": [428, 501, 729, 575]}, {"image_id": 8, "file_name": "371_08.png", "page": 8, "dpi": 300, "bbox": [96, 888, 396, 972], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Visualization of multiple stream volumes.", "caption_bbox": [114, 989, 379, 1002]}, {"image_id": 9, "file_name": "371_09.png", "page": 8, "dpi": 300, "bbox": [96, 354, 396, 420], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Visualization of a single volume passing through a mixing device, displaying twisting and stretching deforma- tions. ", "caption_bbox": [96, 430, 397, 473]}, {"image_id": 10, "file_name": "371_10.png", "page": 8, "dpi": 300, "bbox": [96, 134, 415, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Visualization of two streamsurfaces (red, blue) originating from different separation lines located on edges of obstacles. For volume composition such surfaces are in- tersected and split. ", "caption_bbox": [96, 264, 397, 323]}], "372": [{"image_id": 0, "file_name": "372_00.png", "page": 2, "dpi": 300, "bbox": [96, 134, 415, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Parameterisation of stream surfaces.", "caption_bbox": [128, 277, 365, 290]}, {"image_id": 1, "file_name": "372_01.png", "page": 3, "dpi": 300, "bbox": [141, 137, 415, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Hermite interpolation.", "caption_bbox": [164, 303, 330, 316]}, {"image_id": 2, "file_name": "372_02.png", "page": 4, "dpi": 300, "bbox": [96, 134, 415, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Interpolation Schemes.", "caption_bbox": [162, 275, 330, 288]}, {"image_id": 3, "file_name": "372_03.png", "page": 4, "dpi": 300, "bbox": [443, 399, 716, 563], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Refinement of stream surface near a linear saddle point using distance based refinement. ", "caption_bbox": [428, 575, 729, 603]}, {"image_id": 4, "file_name": "372_04.png", "page": 5, "dpi": 300, "bbox": [187, 134, 731, 372], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Overview of computed stream surfaces for the numerical experiments", "caption_bbox": [213, 385, 612, 398]}, {"image_id": 5, "file_name": "372_05.png", "page": 6, "dpi": 300, "bbox": [157, 409, 669, 605], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The diagrams show the resolution of the last time line for a given precision.", "caption_bbox": [196, 617, 629, 630]}, {"image_id": 6, "file_name": "372_06.png", "page": 6, "dpi": 300, "bbox": [96, 134, 672, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Numerical comparison of accuracy and field evaluations.", "caption_bbox": [243, 371, 582, 384]}, {"image_id": 7, "file_name": "372_07.png", "page": 7, "dpi": 300, "bbox": [128, 137, 415, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The diagram shows the number of starting stream lines versus the number of field evaluations for a constant local error bound of 0.00002. ", "caption_bbox": [96, 343, 397, 387]}, {"image_id": 8, "file_name": "372_08.png", "page": 8, "dpi": 300, "bbox": [412, 137, 730, 471], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Stream surfaces in car dataset constructed using 10 stream lines. The upper image shows a surface obtained with linear interpolation. The lower image shows a surface obtained with Hermite interpolation. The difference in the visual quality is striking. ", "caption_bbox": [428, 486, 729, 560]}, {"image_id": 9, "file_name": "372_09.png", "page": 8, "dpi": 300, "bbox": [96, 134, 415, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparison of accuracy of stream surfaces in car dataset constructed using 10 stream lines. The left image shows the surface for the Hultquist like method, the right im- age shows the surface constructed using the new Hermite in- terpolation based technique. The green lines represent time lines of the approximated surfaces. The red line is a time line from a high quality surface representing the ground truth for comparison. The comparison shows the greatly improved ac- curacy of the new method. ", "caption_bbox": [96, 289, 397, 424]}], "373": [{"image_id": 0, "file_name": "373_00.png", "page": 1, "dpi": 300, "bbox": [412, 378, 734, 798], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Hierarchical vortex regions resulting from a su- perposition of Oseen vortices. Distinct vortex regions are colored differently. ", "caption_bbox": [427, 809, 728, 852]}, {"image_id": 1, "file_name": "373_01.png", "page": 3, "dpi": 300, "bbox": [117, 450, 375, 583], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Linear vector fields from divergence-free (top- left) to curl-free (bottom-right), created by rotating vectors of a divergence-free field up to \u03c0/2. The yellow ellipses in- tersect the vector fields in a constant angle. ", "caption_bbox": [94, 351, 395, 410]}, {"image_id": 2, "file_name": "373_02.png", "page": 3, "dpi": 300, "bbox": [135, 585, 357, 815], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Complex-shaped vortex region with divergence (a), streamlines converge towards the critical point. Vector field decomposition induced by the lines of constant incident angle in a divergence-free (b) and curl-free part (c). ", "caption_bbox": [94, 818, 395, 877]}, {"image_id": 3, "file_name": "373_03.png", "page": 4, "dpi": 300, "bbox": [96, 134, 415, 449], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The LIC visualization in the background depicts the streamlines of some vector field V . The white line \u03b3\u03c6 is a closed streamline in the rotated vector field V\u03c6 . Eight streamlines \u0393 k\u03c0 and \u03930k\u03c0 are simultaneously tracked in V k\u03c0 ,                   2         2                                  2 (k = 0, ..., 3). In this example the streamlines \u0393 \u03c02 and \u0393\u03c0 can- not cross the white line, so they necessarily intersect, or both end at the same critical point in the center of the region. ", "caption_bbox": [94, 459, 395, 567]}, {"image_id": 4, "file_name": "373_04.png", "page": 5, "dpi": 300, "bbox": [434, 500, 722, 911], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison of our method (a) to other meth- ods (b)-(d) and to vector field topology (e). Star-shaped re- gions are extracted and smoothed according to the indi- cated method. The displayed slice of the data set consists of 140 \u00d7 45 vectors. ", "caption_bbox": [427, 914, 728, 988]}, {"image_id": 5, "file_name": "373_05.png", "page": 5, "dpi": 300, "bbox": [101, 137, 415, 378], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Closed lines that are detected from 3 saddle points. The 3 solid white boundary loops are detected di- rectly. The black line consists of two streamlines that end at the same cluster, and thus clusters the 3 solid loops. The outer dashed line is detected after that clustering, and finally the inner dotted line. ", "caption_bbox": [94, 388, 395, 477]}, {"image_id": 6, "file_name": "373_06.png", "page": 5, "dpi": 300, "bbox": [412, 134, 731, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Tip vortices of a ship propeller are visualized as boundary contours of 2D vortex regions of the velocity field projected onto planes rotated around the axis of the ship pro- peller. The LIC image depicts such a projected 2D velocity field. Note that such a field is not divergence free. ", "caption_bbox": [427, 402, 728, 476]}, {"image_id": 7, "file_name": "373_07.png", "page": 6, "dpi": 300, "bbox": [96, 134, 724, 400], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Extracted vortex regions in snapshots of a time-dependent flow behind a cylinder showing a vortex splitting event. Very thin regions around inner vortices are due to small divergence of the field. ", "caption_bbox": [94, 410, 727, 438]}, {"image_id": 8, "file_name": "373_08.png", "page": 7, "dpi": 300, "bbox": [101, 137, 415, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Outline of four Rankine based vortex regions. Color coded is the average tangential velocity along the loops of a vortex region. The white color denotes the local maximum, defining the Rankine based vortex region. ", "caption_bbox": [94, 325, 395, 384]}, {"image_id": 9, "file_name": "373_09.png", "page": 8, "dpi": 300, "bbox": [96, 134, 716, 385], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Comparison of the geometry based iconic vortex visualization of Sadarjoen and Post [SP00] to the hierarchical vortex regions. The depicted slices are slightly different. Sadarjoen and Post used a horizontal slice (k=9) in the (i,j,k) indexed parameter space; we use a horizontal slice in physical space. ", "caption_bbox": [94, 396, 727, 439]}], "374": [{"image_id": 0, "file_name": "374_00.png", "page": 3, "dpi": 300, "bbox": [101, 316, 394, 433], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: a) The geometric setup of the proposed direct occlusion shading model showing the conical subset of the sphere used to compute the occlusion. b) The setup used for the interactive computation of the occlusion factors. ", "caption_bbox": [96, 446, 397, 505]}, {"image_id": 1, "file_name": "374_01.png", "page": 4, "dpi": 300, "bbox": [96, 133, 722, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The stag beetle data set rendered using a) Monte-Carlo integration of Equation 7, with an isotropic phase function b) Monte-Carlo integration of Equation 7, with a cone phase function of aperture angle \u03b8 = 80\u25e6 and c) interactive directional occlusion shading with 1046 slices and an aperture of 80\u25e6 . ", "caption_bbox": [96, 376, 729, 420]}, {"image_id": 2, "file_name": "374_02.png", "page": 6, "dpi": 300, "bbox": [105, 575, 722, 782], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: a) Visible male data set with occlusion of solid and transparent materials (512 \u00d7 512 \u00d7 302 voxels, 962 slices) b) CT scan of an engine block where a clipping plane was used to show the exhaust port (256 \u00d7 256 \u00d7 128 voxels, 679 slices) c) Tree data set of which complex features are exposed by the ambient occlusion approximation (512 \u00d7 512 \u00d7 512 voxels, 1563 slices) ", "caption_bbox": [96, 791, 729, 836]}, {"image_id": 3, "file_name": "374_03.png", "page": 6, "dpi": 300, "bbox": [96, 133, 723, 469], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Various data sets showing the difference between directional occlusion shading (top row) and diffuse Lambertian shading (bottom row) for different data sets. Two-dimensional transfer functions have been used to highlight different features of an MRI scan of a brain with a resolution of 256 \u00d7 256 \u00d7 160 voxels, a CT scan of a head with a resolution of 128 \u00d7 256 \u00d7 256 voxels, a CT scan of a carp with a resolution of 256 \u00d7 288 \u00d7 512 voxels and a CT scan of a hand with a resolution of 244 \u00d7 124 \u00d7 257 voxels. The number of slices used to render each image are 1000, 1458, 220 and 619 respectively. ", "caption_bbox": [96, 480, 729, 555]}, {"image_id": 4, "file_name": "374_04.png", "page": 7, "dpi": 300, "bbox": [100, 282, 395, 576], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The value of \u03b8 (top row: \u03b8 = 50\u25e6 , bottom row: \u03b8 = 85\u25e6 ) and the resolution of the sampling grid (left col- umn: 2 \u00d7 2, right column: 13 \u00d7 13) determine the effect of surrounding features. In the two images at the top, the base of the cone covers between 0.8 and 1.3 texels for a 512 \u00d7 512 view port. In the two images at the bottom, the base of the cone covers between 8.5 and 12.7 texels, for the same view port resolution. The images were rendered with 619 slices. ", "caption_bbox": [96, 583, 397, 707]}], "375": [{"image_id": 0, "file_name": "375_00.png", "page": 3, "dpi": 300, "bbox": [413, 134, 731, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Binary Space Partitioning is used on a test case in two dimensions to generate region representations for two polygons with the rightmost polygons containing a bricked subdivision. Geometrical Homogeneity is introduced as a means to stop the recursive process. Cells (a), (b) and (c) are geometrically homogeneous. ", "caption_bbox": [428, 287, 729, 376]}, {"image_id": 1, "file_name": "375_01.png", "page": 4, "dpi": 300, "bbox": [96, 134, 415, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: BSP-tree (right) and Volume polyhedra (left). Our fusion solution uses Binary Space Partitioning to generate a region based scene description of multiple overlapping vol- umes by finding spatial representations for all individual re- gions in the intersection pattern. The resulting volume poly- hedra are then used directly in the rendering or for the cre- ation of intermediate proxy geometry. ", "caption_bbox": [96, 394, 397, 498]}, {"image_id": 2, "file_name": "375_02.png", "page": 5, "dpi": 300, "bbox": [413, 134, 730, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Traversal for a region with multiple volumes us- ing a single ray. Distance to next sample for each volume depicted in red and actual ray step length is the minimum of these. ", "caption_bbox": [428, 247, 729, 306]}, {"image_id": 3, "file_name": "375_03.png", "page": 8, "dpi": 300, "bbox": [112, 720, 716, 921], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Case 3: Visualizing a US probe in the context of two CT data sets depicting the lower body of a woman. The non-axis alignment of the modalities is evident and motion of the ultrasound probe gives no detectable difference in rendering speed. The visualization is performed at 40-43Hz at a cost of 0.17ms for generating the BSP-tree. ", "caption_bbox": [96, 931, 729, 974]}, {"image_id": 4, "file_name": "375_04.png", "page": 8, "dpi": 300, "bbox": [112, 439, 716, 640], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Case 2: Super-sampling of a high resolution heart within two low resolution body parts (shoulders and chest). Using two opposing clip planes to cut away redundant information we are able to sustain a high sampling rate of for the heart while still maintaining 37-45Hz with 0.14ms spent on BSP-tree generation. ", "caption_bbox": [96, 651, 729, 694]}, {"image_id": 5, "file_name": "375_05.png", "page": 8, "dpi": 300, "bbox": [96, 134, 716, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Case 1: Visualizing an fMRI scan depicting brain activity inside the context providing CT scan of a human head at 24-27Hz. Using two separate volumes allows us to lower the sampling rate and apply different shading on the bone structure and the BSP-tree generation time was 0.08ms. Empty space leaping is applied individually on both volumes. ", "caption_bbox": [96, 370, 729, 413]}], "376": [{"image_id": 0, "file_name": "376_00.png", "page": 2, "dpi": 300, "bbox": [438, 538, 721, 682], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A ray casting through a volume dataset. A and D are the start and end points on the volume bounds; B and C are the first-hit and last-hit points. The ray segments produced by our algorithm,                                   \u2212                                   \u2192 \u2212 \u2192       \u2212                                               \u2192 [MRH08] and the benchmark are BC, BD and AD, respectively. ", "caption_bbox": [428, 692, 729, 750]}, {"image_id": 1, "file_name": "376_01.png", "page": 3, "dpi": 300, "bbox": [449, 218, 711, 401], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Runtime flowchart. The two ellipses represent user in- teraction. The red box represents all the computations on GPU. The spheres represent the data and textures stored in video memory. The green arrows designate data flow. The blue box, containing the rasterising and raycasting passes, is executed constantly for each frame, while the HistoPyramid building takes place only when the transfer function is changed. ", "caption_bbox": [428, 412, 729, 516]}, {"image_id": 2, "file_name": "376_02.png", "page": 4, "dpi": 300, "bbox": [96, 134, 415, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The top figure shows a 1D transfer function using 3 seg- ments to classify data; the bottom figure shows a 2D transfer func- tion (based on intensity and gradient magnitude) using 3 scalable and translatable box widgets overlaid on a histogram of a volume data. Tmin is the minimum intensity value of the leftmost widget. ", "caption_bbox": [96, 336, 397, 410]}, {"image_id": 3, "file_name": "376_03.png", "page": 4, "dpi": 300, "bbox": [428, 469, 731, 820], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The first 2 rows show the rasterising results of the proxy spheres at 3 different levels of block granularity (Bgranu =16, 8 and 2, respectively, from left to right) with the first-hit points shown in the top row and the last-hit points shown in the middle row. The bottom row shows the final rendering results from our method (left) and the benchmark (right); the rendering quality of the two methods is identical, but the former (43.6fps) is 5.2 times faster than the latter (8.5fps). ", "caption_bbox": [428, 826, 729, 945]}, {"image_id": 4, "file_name": "376_04.png", "page": 5, "dpi": 300, "bbox": [142, 580, 353, 772], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The original two z-buffers store C and D as lying on the two green lines, which are the rasterising results of the two red spheres. For each fragment A on the image plane, we need to expand C backwards along the ray by a distance R, and expand D forwards by the same distance R. As a result, the final first-hit and last-hit points will be B and E, respectively, which lie on the two blue lines. ", "caption_bbox": [95, 784, 396, 873]}, {"image_id": 5, "file_name": "376_05.png", "page": 6, "dpi": 300, "bbox": [96, 134, 727, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Performances (in fps) for different data sets using our method (changing both the transfer function and the viewing para- meters continuously) and the benchmark. The columns also indicate Bgranu , the number (#) of active blocks extracted, and the resulting speed-up factor s of our method over the benchmark (cube). All the frame rates here are for the images in Figures 4, 6 and 7. ", "caption_bbox": [96, 513, 397, 602]}, {"image_id": 6, "file_name": "376_06.png", "page": 8, "dpi": 300, "bbox": [96, 134, 731, 843], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Rendering results for different dense and sparse data sets. See performance statistics in Table 2 and Table 3", "caption_bbox": [146, 849, 677, 862]}], "377": [{"image_id": 0, "file_name": "377_00.png", "page": 2, "dpi": 300, "bbox": [460, 161, 698, 407], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Mapping a high-dimensional data space into a low-dimensional space leads in the worst case to a mislead- ing picture of the clusters hidden in the data \u2013 the 1\u2013D axis parallel projection of the 2\u2013D cluster model (red and green points) along the x and y axes results in two different views of the data. Although there are two clusters visible in both pro- jections (two peaks in the histograms), only the projection along the x-dimension is consistent with the clusters. The projection in y-direction merges the two clusters and hence is not consistent. ", "caption_bbox": [428, 426, 729, 577]}, {"image_id": 1, "file_name": "377_01.png", "page": 3, "dpi": 300, "bbox": [103, 167, 404, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Consistent (=Good) vs. Non-Consistent (=Poor) View \u2013 The data set contains three clusters representing three classes of wine, and 13 attributes describing chemical properties of the wine. The left \ufb01gure shows the scatterplot for dimensions alcohol and \ufb02avanoids. The classes are sep- arated in this view and most data points are located close to class centers, resulting in a consistent view. In the right \ufb01gure in contrast, in the scatterplot of dimensions ash and magnesium classes are cluttered and not separated, result- ing in a poor consistency rating. ", "caption_bbox": [96, 335, 397, 486]}, {"image_id": 2, "file_name": "377_02.png", "page": 5, "dpi": 300, "bbox": [116, 168, 380, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Basic Idea of Distribution Consistency \u2013 Top row: hypothetical spatial distributions of projected data, with two classes represented as red and green. Bottom row: hypothetical histograms showing the proportion of data of each class in a small region such as a pixel. (a) The classes are clearly separated. (b) Classes are overlapping, and the histogram has higher entropy as a result. (c) Classes are overlapping in the indicated region, but the amount of data is small. The contribution of this region is weakly weighted. (d) Classes are spatially interleaved on a \ufb01ne scale. Although each individual pixel contains only one class of data, the distribution has low distribution consistency when class pro- portions are estimated over a small window. ", "caption_bbox": [96, 325, 397, 521]}, {"image_id": 3, "file_name": "377_03.png", "page": 6, "dpi": 300, "bbox": [107, 162, 726, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Rating of several synthetic patterns by distribution consistency \u2013 the distribution consistency score is indicated below each \ufb01gure. From left to right: (a) separate distributions, (b) separate non-convex distributions, (c) distributions partially overlap, (d) concentric distributions (same center, different variance), (e) identical distributions. ", "caption_bbox": [96, 282, 729, 326]}, {"image_id": 4, "file_name": "377_04.png", "page": 7, "dpi": 300, "bbox": [432, 482, 721, 616], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Precision and Recall \u2013 even for a large number of dimensions the automatically detected good views correlates to over 50% with people\u2019s judgement of good views. Addi- tionally we see that our distance consistency violates the hu- man understanding of a good view only in a small number of views. ", "caption_bbox": [428, 634, 729, 724]}, {"image_id": 5, "file_name": "377_05.png", "page": 7, "dpi": 300, "bbox": [121, 161, 374, 555], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Interactive Selection of good scatterplots \u2013 in- teractive threshold sliders to fade out poor views supports to \ufb01nd good views interactively (a) . In this example, views be- low DSC = 80 are faded out. The projection of dimensions (1, 11) for example has a high consistency of DSC = 86, as shown in (a2). (b) In the WHO example, views below DC = 80 are faded out. Many irrelevant views are faded- out and the number of views to look at can be interactively reduced to a manageable size. ", "caption_bbox": [96, 563, 397, 698]}, {"image_id": 6, "file_name": "377_06.png", "page": 7, "dpi": 300, "bbox": [433, 180, 721, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Normalized max and mean distance consistency for Iris (a), Olive (b), Wine (c), Boston Housing (d), Bul- garia Health [Bul08] (e), Health [NHBM98] (f), Arti\ufb01cial (g), WHO (h) \u2013 it shows that the number of good views de- creases but our technique identi\ufb01es a number of good 2\u2013D views for these data sets (left). For the Boston Housing data, the consistency decreases with increasing number of clusters due to the decreasing separation between clusters (right). ", "caption_bbox": [428, 323, 729, 443]}], "378": [{"image_id": 0, "file_name": "378_00.png", "page": 4, "dpi": 300, "bbox": [473, 491, 686, 600], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (Left) Neighborhood of the red cell in a two- dimensional space, (Right) Cluster tree with 4 modes shown as leaves of the tree. ", "caption_bbox": [428, 611, 729, 655]}, {"image_id": 1, "file_name": "378_01.png", "page": 5, "dpi": 300, "bbox": [125, 443, 369, 562], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Radial layout of a cluster tree. (Left) An annulus wedge domain W = (r, \u03b1, \u03b2). (Middle) Splitting the annual wedge for placing three subtrees. (Right) Placing internal nodes of cluster tree. ", "caption_bbox": [96, 573, 397, 632]}, {"image_id": 2, "file_name": "378_02.png", "page": 6, "dpi": 300, "bbox": [110, 488, 383, 626], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Linking cluster tree visualization with parallel co- ordinates. (Left) Radial layout of hierarchical density clus- ter tree. (Right) Interactively selected cluster is visualized in parallel coordinates. ", "caption_bbox": [96, 637, 397, 696]}, {"image_id": 3, "file_name": "378_03.png", "page": 6, "dpi": 300, "bbox": [412, 136, 714, 416], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Linking cluster tree visualization with parallel co- ordinates and object space rendering. (Upper) Selected clus- ters in parallel coordinates (feature space). (Left) Radial layout of hierarchical density cluster tree. (Right) Selected clusters in volumetric object space (physical space). ", "caption_bbox": [428, 430, 729, 504]}, {"image_id": 4, "file_name": "378_04.png", "page": 7, "dpi": 300, "bbox": [465, 456, 693, 676], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Focus+context technique for integrated visualiza- tion with cluster tree and circular parallel coordinates. ", "caption_bbox": [428, 688, 729, 716]}, {"image_id": 5, "file_name": "378_05.png", "page": 7, "dpi": 300, "bbox": [415, 134, 731, 389], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Integrated circular parallel coordinates in clusters tree visualization for data set with hierarchical clusters. ", "caption_bbox": [428, 403, 729, 431]}, {"image_id": 6, "file_name": "378_06.png", "page": 7, "dpi": 300, "bbox": [141, 257, 358, 477], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Integrated circular parallel coordinates in clusters tree visualization for data set with 14 mode clusters. ", "caption_bbox": [96, 490, 397, 519]}], "379": [{"image_id": 0, "file_name": "379_00.png", "page": 2, "dpi": 300, "bbox": [96, 134, 731, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Annotated acceleration data from an Imperial Cormorant. The three axes are presented as separate line graphs showing the sway (red), heave (green) and surge (blue) data, over 33 minutes (vertical reference lines indicate minutes). Sections of the signal have been manually identified by a biologist as (a) walking, (b) washing, (c) flying and (d) diving behaviours. ", "caption_bbox": [96, 364, 729, 407]}, {"image_id": 1, "file_name": "379_01.png", "page": 3, "dpi": 300, "bbox": [98, 136, 415, 336], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Surge, sway and heave acceleration during a single cormorant dive. Changes in posture during descent, swimming, and ascent are evident as shifts in the baseline values of the surge and heave axes. Dynamic acceleration resulting from individual foot-kicks are identifiable as regu- lar deviations from the static value, as shown in the insert. ", "caption_bbox": [96, 347, 397, 436]}, {"image_id": 2, "file_name": "379_02.png", "page": 4, "dpi": 300, "bbox": [96, 134, 415, 488], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Scatterplots of 9 hours of cormorant activity data. (a) a raw data, (b) Savitzky-Golay filtered (window size is 32), (c) normalised windowed mean, (i.e. orientation vec- tors), and (d) time based colouring of the filtered data, with the colour changing from red to yellow with time. In all im- ages the three axes of the scatterplot relate to the three axes of the accelerometer, and are colour coded to agree with fig- ure 1. ", "caption_bbox": [96, 501, 397, 621]}, {"image_id": 3, "file_name": "379_03.png", "page": 4, "dpi": 300, "bbox": [412, 136, 696, 521], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Multi-attribute visualisation of 9 hours of cor- morant behaviour. (a) windowed mean of acceleration data, (b) normalised acceleration projected from the surface ac- cording to pressure (an overlay) with pressure also mapped to colour, (c) pressure replaced with signal energy, and (d) orientation, pressure (overlay) and signal energy (colour) visualised together. Note, successive points are connected with line segments to indicate temporal relation. ", "caption_bbox": [428, 534, 729, 654]}, {"image_id": 4, "file_name": "379_04.png", "page": 5, "dpi": 300, "bbox": [96, 136, 415, 502], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Using attributed data to isolate activities. Orien- tation and pressure (overlay and colour) illustrate a single dive performed by the cormorant over four minutes, along with the 2D time-series. ", "caption_bbox": [96, 512, 397, 571]}, {"image_id": 5, "file_name": "379_05.png", "page": 5, "dpi": 300, "bbox": [412, 134, 731, 518], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Spherical histogram of orientation data. (a) un- derlying acceleration vector data (b) large, (c) medium, and (d) small bin sizes. Intervals on the bars denote a minute of data, height and colour indicates bin-count. ", "caption_bbox": [428, 531, 729, 590]}, {"image_id": 6, "file_name": "379_06.png", "page": 6, "dpi": 300, "bbox": [412, 136, 727, 500], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Utilising data clustering methods. (a) Data are coloured according to c-means clustering of acceleration and signal energy values, (b) The posture transition graph for 9 hours of cormorant behaviour, (c) average behavioural tortuosity of transitions depicted with a helix, and (d) ab- stract transitions replaced with the actual transitions in the data, with an overlay of pressure data (figure 4(b)). ", "caption_bbox": [428, 513, 729, 617]}, {"image_id": 7, "file_name": "379_07.png", "page": 8, "dpi": 300, "bbox": [96, 134, 699, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visualisations of accelerometry from other animals. (a) A Leatherback Turtle with a Daily Diary device attached to the carapace, (b) Four hours of the turtles\u2019 behaviour visualised with our method. Two minutes of rolling behaviour can be seen as deviations from the vertical column. (c) Nineteen hours of albatross data showing soaring behaviour. the bird rolls its\u2019 body to fly efficiently for long periods, resulting in an arc across the top of the sphere. (d) Pressure overlay and colouring of 16 hours of penguin data containing diving behaviour. This can be compared with figure 4(b), to observe similarities in diving depiction, and dissimilarities in behaviour (e.g. angles of descent and ascent). ", "caption_bbox": [96, 342, 729, 431]}], "380": [{"image_id": 0, "file_name": "380_00.png", "page": 3, "dpi": 300, "bbox": [492, 604, 667, 779], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Geodesics in the xy-plane. Example geodesics (black) and the rotational symmetry of the spacetime illus- trate the existence of an optical horizon. An object (orange) can be seen twice. ", "caption_bbox": [428, 790, 729, 849]}, {"image_id": 1, "file_name": "380_01.png", "page": 4, "dpi": 300, "bbox": [135, 163, 368, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Light paths from a small object (orange) to an observer located at the origin. An infinite number of possible light paths exists with any number of windings. The variables \u03bbi, j serve to distinguish the different geodesics and will be properly introduced in Sect. 5.2. ", "caption_bbox": [96, 305, 397, 379]}, {"image_id": 2, "file_name": "380_02.png", "page": 4, "dpi": 300, "bbox": [95, 402, 399, 498], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Optical appearance of an infinitely often visible sphere (only a finite number of representations shown) lo- cated within the G\u00f6del horizon (z > 0). ", "caption_bbox": [96, 509, 397, 553]}, {"image_id": 3, "file_name": "380_03.png", "page": 5, "dpi": 300, "bbox": [182, 590, 321, 704], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The starting direction of the geodesic is formu- lated with respect to the angular coordinates \u03d1 and \u03d5 of a spherical coordinate set. ", "caption_bbox": [96, 719, 397, 763]}, {"image_id": 4, "file_name": "380_04.png", "page": 6, "dpi": 300, "bbox": [433, 683, 726, 846], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Concatenation of isometric transformations. The yellow object denotes an observer or a light source, the gray object resembles an arbitrary visualized object. ", "caption_bbox": [428, 853, 729, 897]}, {"image_id": 5, "file_name": "380_05.png", "page": 8, "dpi": 300, "bbox": [95, 328, 399, 483], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: High quality image of multiply appearing objects and a point light source (white) rendered in 730 ms. ", "caption_bbox": [96, 493, 397, 521]}], "381": [{"image_id": 0, "file_name": "381_00.png", "page": 3, "dpi": 300, "bbox": [125, 158, 369, 379], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualizing deformation fields", "caption_bbox": [145, 390, 347, 403]}, {"image_id": 1, "file_name": "381_01.png", "page": 3, "dpi": 300, "bbox": [454, 158, 708, 296], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visualizations of a synthetic 643 vector field. The left figure only shows vector magnitude (in orange), while the right figure shows our growth measure (yellow for nega- tive values, blue for positive), giving a more detailed repre- sentation of deformation. ", "caption_bbox": [428, 307, 729, 386]}, {"image_id": 2, "file_name": "381_02.png", "page": 5, "dpi": 300, "bbox": [161, 158, 671, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Deformation visualization elements", "caption_bbox": [297, 340, 528, 353]}, {"image_id": 3, "file_name": "381_03.png", "page": 6, "dpi": 300, "bbox": [137, 158, 348, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Combined visualization of focus and context fea- tures in a 512 \u00d7 512 \u00d7 80 knee dataset. Jacobians were com- puted with a kernel radius of 4 \u00d7 4 \u00d7 0.6 voxels. Growth fea- tures are shown for |g| > 0.14. ", "caption_bbox": [96, 367, 397, 426]}, {"image_id": 4, "file_name": "381_04.png", "page": 6, "dpi": 300, "bbox": [457, 158, 701, 385], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Using a layered approach for GPU-based multi- volume raycasting ", "caption_bbox": [428, 395, 729, 423]}, {"image_id": 5, "file_name": "381_05.png", "page": 7, "dpi": 300, "bbox": [115, 158, 711, 296], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Enhancing the visualization with texture reveals various properties of the deformation field, such as a rotational component in this synthetic saddle point deformation (1283 ). Colors in the last two figures go from blue (low) to orange (high). ", "caption_bbox": [96, 309, 729, 337]}, {"image_id": 6, "file_name": "381_06.png", "page": 8, "dpi": 300, "bbox": [130, 159, 359, 402], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visualization of deformation due to changing white matter lesions in a brain MRI dataset of 181 \u00d7 217 \u00d7 179 voxels. Jacobians were computed with a kernel radius of 2 voxels. Growth features are shown for |g| > 0.09. ", "caption_bbox": [96, 412, 397, 471]}], "382": [{"image_id": 0, "file_name": "382_00.png", "page": 2, "dpi": 300, "bbox": [503, 751, 657, 873], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The process of temporal sequencing to create a transfer function. ", "caption_bbox": [428, 886, 729, 914]}, {"image_id": 1, "file_name": "382_01.png", "page": 2, "dpi": 300, "bbox": [96, 134, 415, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A combustion data set of two time steps, left to right, with different transfer functions applied to it. The top images use a single static transfer function, and the feature appears to vanish over time. The bottom images use a dy- namic transfer function created through time-series analy- sis. ", "caption_bbox": [96, 472, 397, 561]}, {"image_id": 2, "file_name": "382_02.png", "page": 3, "dpi": 300, "bbox": [499, 532, 659, 635], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Four graphed time activity curves (TAC) for four data points. The 1st, 3rd, and 4th data points have similar temporal activity in a time window, and would be in one cluster for that time window. ", "caption_bbox": [428, 647, 729, 706]}, {"image_id": 3, "file_name": "382_03.png", "page": 4, "dpi": 300, "bbox": [499, 208, 659, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An abstract representation of a cluster graph af- ter edge culling. Each node is a cluster found in clustering process per time step. Remaining edges represent high prob- ability that a cluster is the same cluster (feature) over time. Sequences are paths through the graph that do not reverse direction in time, which represent a feature evolving over time. ", "caption_bbox": [428, 343, 729, 448]}, {"image_id": 4, "file_name": "382_04.png", "page": 5, "dpi": 300, "bbox": [97, 137, 415, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The left image shows a series of clusters over time, shown as small multiples of time histograms, from the argon bubble data set. Even though clusters share value ranges over time, they are separated into two distinct activ- ity classes. An abstract representation of a time histogram is shown on the right. ", "caption_bbox": [96, 343, 397, 432]}, {"image_id": 5, "file_name": "382_05.png", "page": 5, "dpi": 300, "bbox": [487, 563, 672, 824], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: After the data is analyzed, the sequences are vi- sualized by the user. In this interface, the user can see the results of the clustering and sequencing process. An abstract example of the visualization is shown on the bottom. ", "caption_bbox": [428, 839, 729, 898]}, {"image_id": 6, "file_name": "382_06.png", "page": 6, "dpi": 300, "bbox": [429, 492, 730, 643], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visualization of CCMS temperature data. The left image uses a uniformly distributed color and opacity map. The right image uses histogram equalized color and opacity map based a temporal sequence, focusing in on the sequence of interest. ", "caption_bbox": [428, 654, 729, 728]}, {"image_id": 7, "file_name": "382_07.png", "page": 7, "dpi": 300, "bbox": [429, 553, 730, 705], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The argon bubble data set, visualized with a dy- namic color/static opacity transfer function. The right image uses a cluster mask to only show the data points that are ex- actly part of the sequence. ", "caption_bbox": [428, 715, 729, 774]}, {"image_id": 8, "file_name": "382_08.png", "page": 7, "dpi": 300, "bbox": [412, 134, 731, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The earthquake data set with different transfer functions computed on a temporal sequence. Top row is static color, bottom row is dynamic color. Left column is static opacity, right column is dynamic opacity. ", "caption_bbox": [428, 472, 729, 531]}, {"image_id": 9, "file_name": "382_09.png", "page": 8, "dpi": 300, "bbox": [97, 575, 398, 727], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Visualizations using transfer functions generated via clustering and sequencing. ", "caption_bbox": [96, 737, 397, 765]}], "383": [{"image_id": 0, "file_name": "383_00.png", "page": 2, "dpi": 300, "bbox": [95, 452, 399, 600], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Rendering of the Bluntfin dataset with different pre-integrated rendering algorithms. (a) One-dimensional transfer function; (b) two-dimensional transfer function. Corresponding transfer functions are shown in the upper left-hand corners of the images. Homogeneous areas are made transparent by 2D transfer functions in (b) therefore the features can be better separated and visualized. ", "caption_bbox": [96, 611, 397, 716]}, {"image_id": 1, "file_name": "383_01.png", "page": 2, "dpi": 300, "bbox": [104, 158, 732, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Four widgets used in two-dimensional transfer function design: (a) Uniform; (b) Gaussian; (c) Triangle wave; (d) Sine wave. ", "caption_bbox": [96, 332, 729, 360]}, {"image_id": 2, "file_name": "383_02.png", "page": 3, "dpi": 300, "bbox": [107, 600, 406, 948], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) The inside case; (b) The outside case; (c) The integral in a tetrahedron. ", "caption_bbox": [96, 960, 397, 988]}, {"image_id": 3, "file_name": "383_03.png", "page": 4, "dpi": 300, "bbox": [432, 482, 728, 619], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Three cases of the relationship between a value range in a ray segment and a two-dimensional transfer func- tion widget. ", "caption_bbox": [428, 630, 729, 674]}, {"image_id": 4, "file_name": "383_04.png", "page": 5, "dpi": 300, "bbox": [428, 337, 731, 466], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) Applying a uniform 2D transfer function to the M6 Wing dataset. (b) Two-dimensional Gaussian trans- fer function applied to the NASA X38 dataset and the vortex tubes and bow shock of the flow are clearly shown in this image. ", "caption_bbox": [428, 478, 729, 552]}, {"image_id": 5, "file_name": "383_05.png", "page": 6, "dpi": 300, "bbox": [428, 589, 731, 728], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Rendering results of the NASA X38 dataset with the analytic form (left) and approximated pre-integration mode (right). A two-dimensional Gaussian transfer function is used. ", "caption_bbox": [428, 738, 729, 797]}, {"image_id": 6, "file_name": "383_06.png", "page": 6, "dpi": 300, "bbox": [95, 448, 399, 606], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Volume rendering on the Heatsink dataset with (a)a banded triangle wave transfer function with no lighting; (b) a banded sinusoid wave transfer function with gradient- based diffuse lighting. ", "caption_bbox": [96, 618, 397, 677]}, {"image_id": 7, "file_name": "383_07.png", "page": 7, "dpi": 300, "bbox": [428, 267, 731, 627], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Illustrative rendering effects for the Delta Wing dataset: (top) semi-transparent rendering based on a banded triangle wave transfer function; (bottom) view-dependent enhancement using a bivariate triangle wave transfer func- tions. ", "caption_bbox": [428, 638, 729, 712]}, {"image_id": 8, "file_name": "383_08.png", "page": 7, "dpi": 300, "bbox": [95, 525, 399, 693], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Rendering the Cylinder dataset using (a) an one- dimensional transfer function [SET\u2217 06]; (b) our approxi- mated bivariate sinusoid transfer function. ", "caption_bbox": [96, 705, 397, 749]}], "384": [{"image_id": 0, "file_name": "384_00.png", "page": 3, "dpi": 300, "bbox": [145, 158, 682, 535], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Full body CT angiography rendered using (a) DVR, (b) MIDA, and (c) MIP. Data set courtesy of the OsiriX Founda- tion (http://www.osirix-viewer.com). ", "caption_bbox": [96, 545, 729, 573]}, {"image_id": 1, "file_name": "384_01.png", "page": 4, "dpi": 300, "bbox": [164, 164, 663, 616], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Typical ray profiles for (a) DVR, (b) MIDA, and (c) MIP.", "caption_bbox": [245, 630, 580, 643]}, {"image_id": 2, "file_name": "384_02.png", "page": 5, "dpi": 300, "bbox": [98, 158, 729, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Cranial MRI angiography rendered using (a) MIP without shading, (b) MIP with gradient-based shading, and (c) MIDA with gradient-based shading. ", "caption_bbox": [96, 336, 729, 365]}, {"image_id": 3, "file_name": "384_03.png", "page": 7, "dpi": 300, "bbox": [98, 439, 729, 612], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Ultramicroscopy of a mouse embryo rendered using (a) DVR, (b) MIDA, and (c) MIP. Data set courtesy of Dodt et al. [DLS\u2217 07]. ", "caption_bbox": [96, 622, 729, 651]}, {"image_id": 4, "file_name": "384_04.png", "page": 7, "dpi": 300, "bbox": [98, 158, 729, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: MRI scan rendered using (a) DVR, (b) MIDA, and (c) MIP. Data set courtesy of the OsiriX Foundation (http://www.osirix-viewer.com). ", "caption_bbox": [96, 390, 729, 418]}, {"image_id": 5, "file_name": "384_05.png", "page": 8, "dpi": 300, "bbox": [98, 158, 729, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: CT scan of a backpack filled with various items rendered using (a) DVR, (b) MIDA, and (c) MIP. Data set courtesy of Kevin Kreeger, Viatronix Inc. (http://www.volvis.org). ", "caption_bbox": [96, 361, 729, 390]}], "385": [{"image_id": 0, "file_name": "385_00.png", "page": 2, "dpi": 300, "bbox": [111, 748, 384, 852], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Illustration of principal component analysis. High-dimensional data (a) are plotted with respect to their first three Principal Components (PCs) (b) and first two PCs (c). ", "caption_bbox": [96, 865, 397, 924]}, {"image_id": 1, "file_name": "385_01.png", "page": 3, "dpi": 300, "bbox": [138, 159, 689, 454], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The system overview (left) showing the four views and the two control panels with the E. Coli dataset, and three examples with the Iris dataset (right). (A) Projection view. Data items are projected onto the two user-selected eigenvectors (in this case, the primary and secondary principle components). (B) Eigenvector view. Each eigenvector is treated as a dimension in this parallel coordinates view, and every data item is drawn as a line. (C) Data view. Another parallel coordinates view, but this time each dimension represents the dimensions in the original data, and each line represents each data item. (D) Correlation view. Pearson-correlation coefficient and the relationships (scatter plot) between each pair of variables are represented. (E) Dimension sliders. Each slider controls the amount of contribution of a dimension in the PCA calculation. (F) Control options. (G) shows the result of diminishing the first dimension (Sepal length) of the Iris dataset from 100% to 0%. The trails show how the data points move in PCA space in response to the change. The images (H) and (I) show 10% uncertainty in the data (in all dimensions). The possible locations for each data point are drawn in a hypercube (H) and in outlines (I) corresponding to the number of data item(s) selected. ", "caption_bbox": [96, 464, 729, 629]}, {"image_id": 2, "file_name": "385_02.png", "page": 6, "dpi": 300, "bbox": [96, 134, 729, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Average time spent in solving each task.", "caption_bbox": [455, 899, 702, 912]}, {"image_id": 3, "file_name": "385_03.png", "page": 7, "dpi": 300, "bbox": [462, 404, 697, 551], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: At the end of the evaluation, each participant grades the systems on a scale of \u2018A\u2019 to \u2018F\u2019. ", "caption_bbox": [428, 562, 729, 590]}, {"image_id": 4, "file_name": "385_04.png", "page": 7, "dpi": 300, "bbox": [97, 159, 731, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Participants\u2019 responses to a post-application questionnaire, filled out after solving all four tasks using one of the systems. (a) How well do you understand the application now? (b) How well do you understand PCA now? (c) How well do you understand the data you worked with now? (d) How useful was the system? (e) How difficult or easy was the system to learn? ", "caption_bbox": [96, 324, 729, 367]}], "386": [{"image_id": 0, "file_name": "386_00.png", "page": 2, "dpi": 300, "bbox": [412, 134, 726, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Splatting framework overview.", "caption_bbox": [476, 371, 681, 384]}, {"image_id": 1, "file_name": "386_01.png", "page": 3, "dpi": 300, "bbox": [104, 134, 731, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Intermediate frames during a polyline splatting animation: (a) original plot; (b)-(d) splatting in N-dimensional space with iteration 200, 800, and 1400 respectively. The cluster d in (b) is further divided into two neighboring clusters highlighted by the orange lines in (c). ", "caption_bbox": [96, 264, 729, 308]}, {"image_id": 2, "file_name": "386_02.png", "page": 3, "dpi": 300, "bbox": [430, 351, 723, 448], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Splatting in 2-dimensional subspaces: (a) formed by axis 1 and 2; (b) formed by axis 2 and 3. ", "caption_bbox": [428, 461, 729, 489]}, {"image_id": 3, "file_name": "386_03.png", "page": 4, "dpi": 300, "bbox": [412, 134, 650, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Highlighted clusters with different colors.", "caption_bbox": [448, 252, 709, 265]}, {"image_id": 4, "file_name": "386_04.png", "page": 5, "dpi": 300, "bbox": [412, 134, 731, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: An example when cluster k\u2019s center falls into clus- ter g\u2019s force circle area. ", "caption_bbox": [428, 274, 729, 302]}, {"image_id": 5, "file_name": "386_05.png", "page": 5, "dpi": 300, "bbox": [441, 332, 712, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Color diffusion examples between two clusters: (a) with small interaction angle; (b) with large interaction angle; (c) with long distance; (d) with short distance. ", "caption_bbox": [428, 406, 729, 450]}, {"image_id": 6, "file_name": "386_06.png", "page": 6, "dpi": 300, "bbox": [412, 134, 725, 422], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Experiments on a synthesized dataset. (a) original plot; (b) after 800 iterations; (c) after 2000 iterations; (d) splatting result with colors indicating different clusters; (e) hierarchical parallel coordinates result; (f) visual clustering result. (e) and (f) are Courtesy of Hong et al. [ZYQ\u2217 08]. ", "caption_bbox": [428, 435, 729, 509]}, {"image_id": 7, "file_name": "386_07.png", "page": 7, "dpi": 300, "bbox": [99, 361, 393, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Splatting experiments on the out5d dataset. (a) original plot; (b) after 12800 iterations. ", "caption_bbox": [96, 475, 397, 503]}, {"image_id": 8, "file_name": "386_08.png", "page": 7, "dpi": 300, "bbox": [107, 134, 731, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Segment splatting results on the same dataset used in Fig. 2: (a) w1 = 0, w2 = 1.0, w3 = 1.0, w4 = 0; (b) w1 = 0, w2 = 1.0, w3 = 1.0, w4 = 1.0; (c) w1 = 1.0, w2 = 1.0, w3 = 1.0, w4 = 0. ", "caption_bbox": [96, 286, 729, 319]}, {"image_id": 9, "file_name": "386_09.png", "page": 8, "dpi": 300, "bbox": [96, 134, 724, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Segment splatting results on the out5d dataset.", "caption_bbox": [267, 300, 559, 313]}], "387": [{"image_id": 0, "file_name": "387_00.png", "page": 2, "dpi": 300, "bbox": [95, 158, 731, 320], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A Lorenz attractor. Left: traditional 3D scatterplot; middle: illuminated scatterplot; right: linear, planar, and spher- ical structures highlighted through mapping to green, red, and blue colors respectively. The base colors are chosen to have equal intensity. ", "caption_bbox": [96, 330, 729, 374]}, {"image_id": 1, "file_name": "387_01.png", "page": 3, "dpi": 300, "bbox": [428, 158, 731, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Scatterplot showing the effect of modifying the weight factors for the linear, planar, and spherical cases. The triangle in the lower left corner of each plot shows the user input. Starting from the upper left, clockwise: a) empha- sizing spherical structures, b) emphasizing linear structures, c) emphasizing planar structures, d) suppressing spherical structures. The color coding is as follows: red corresponds to planar, green to linear, and blue to spherical. ", "caption_bbox": [428, 398, 729, 518]}, {"image_id": 2, "file_name": "387_02.png", "page": 4, "dpi": 300, "bbox": [428, 158, 731, 614], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Scatterplot with different kernel sizes. n = 20 , 21 , 22 , 23 , 24 , 25 , 212 , 213 from top to bottom, left to right. ", "caption_bbox": [428, 624, 729, 653]}, {"image_id": 3, "file_name": "387_03.png", "page": 5, "dpi": 300, "bbox": [95, 158, 399, 312], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Scatterplot showing samples uniformly distributed in a cube (left) and on 2D surfaces of a cube (right). The edges of the box as well as the faces are distinguishable and illuminated by the algorithm (left). Similarly, the boundaries of the 2D surfaces are distinguishable as well (right). An oblique clip plane is applied to show the interior of both images. ", "caption_bbox": [96, 322, 397, 427]}, {"image_id": 4, "file_name": "387_04.png", "page": 5, "dpi": 300, "bbox": [428, 158, 731, 612], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Mapping depth to color: near to red, far to blue. Point size is adjusted according to depth. Halos are drawn around individual samples in the foreground. Upper image: without illumination; lower: with illumination. ", "caption_bbox": [428, 623, 729, 682]}, {"image_id": 5, "file_name": "387_05.png", "page": 6, "dpi": 300, "bbox": [96, 158, 399, 612], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualization of the Lorenz attractor with additive blending. Upper: without illumination; lower: with illumi- nation. ", "caption_bbox": [96, 623, 397, 667]}, {"image_id": 6, "file_name": "387_06.png", "page": 7, "dpi": 300, "bbox": [428, 158, 731, 615], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Several time steps from an animation displaying the transition between two scatterplot displays. The bucky- ball dataset is visualized without illumination (left) and with illumination (right). The top image shows the first derivative and the scalar value. The bottom image shows the second derivative and the scalar value. ", "caption_bbox": [428, 626, 729, 715]}, {"image_id": 7, "file_name": "387_07.png", "page": 7, "dpi": 300, "bbox": [103, 398, 392, 582], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Bucky-ball dataset, showing the first and second derivatives over the scalar values (green, blue, and red axes respectively). ", "caption_bbox": [96, 592, 397, 636]}, {"image_id": 8, "file_name": "387_08.png", "page": 7, "dpi": 300, "bbox": [95, 158, 399, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Scatterplot showing the covtype dataset mapped to 3-space by the FastMap algorithm. Colors represent differ- ent wilderness areas. Left: without illumination; right: with illumination. ", "caption_bbox": [96, 320, 397, 379]}, {"image_id": 9, "file_name": "387_09.png", "page": 8, "dpi": 300, "bbox": [96, 158, 399, 386], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Virgo dataset, rendered with additive blending. Green, red, and blue colors are used for linear, planar, and spherical structures respectively. Lighting is disabled. ", "caption_bbox": [96, 397, 397, 441]}], "388": [{"image_id": 0, "file_name": "388_00.png", "page": 3, "dpi": 300, "bbox": [96, 159, 399, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Illustration of the approximation of \u03a6. Projecting a hexahedron from the spatial domain to the data domain results in eight points located in the data domain. The stip- pled lines indicate the shape that is constructed to represent \u03a6: an axis-aligned rectangle or the convex hull of the eight points. ", "caption_bbox": [96, 296, 397, 385]}, {"image_id": 1, "file_name": "388_01.png", "page": 4, "dpi": 300, "bbox": [96, 300, 399, 561], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Pseudo code for the subdivision approach. For the subdivision step, we use trilinear interpolation. The area \u03a6 can be represented by the convex hull of the projected points or by an axis-aligned rectangle. ", "caption_bbox": [96, 571, 397, 630]}, {"image_id": 2, "file_name": "388_02.png", "page": 4, "dpi": 300, "bbox": [428, 300, 731, 561], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Pseudo code that traverses the octree. Once a leaf is reached, the same subdivision is used as in Fig. 2. ", "caption_bbox": [428, 571, 729, 599]}, {"image_id": 3, "file_name": "388_03.png", "page": 5, "dpi": 300, "bbox": [220, 159, 607, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: As a reference, the conventional scatterplot of the \u201cTooth\u201d data set is shown (left image). The continuous version (right image) is created with the original continuous scatterplot algorithm [BW08]. ", "caption_bbox": [96, 316, 729, 344]}, {"image_id": 4, "file_name": "388_04.png", "page": 6, "dpi": 300, "bbox": [412, 136, 715, 454], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The upper plot shows the L2 norm for the \u201cTooth\u201d data set, the lower plot for the \u201cEngine\u201d data set. For both data sets, the hierarchical octree approach (\u201cHierarchical\u201d) and the subdivion approach that uses the convex hull (\u201cSub- division\u201d) are analyzed. Please note that the scale of x-axis is not uniform. Also, the vertical axis use different scalings for the two different approaches. ", "caption_bbox": [428, 474, 729, 578]}, {"image_id": 5, "file_name": "388_05.png", "page": 8, "dpi": 300, "bbox": [96, 134, 703, 464], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: These continuous scatterplots were created with the subdivision approach for the \u201cTooth\u201d data set. The pictures in the upper row show results of the subdivision approach using a convex hull to represent \u03a6 in the data domain. On the left side, \u03a6 is allowed to span up to 200 pixels in each dimension. The picture in the middle is created with a threshold of 100 pixels, whereas the right-most picture uses a threshold of 50 pixels. The lower row shows the same data set, but this time the subdivision approach uses axis-aligned rectangles to represent \u03a6. The same thresholds as for the upper row are applied. ", "caption_bbox": [96, 475, 729, 549]}, {"image_id": 6, "file_name": "388_06.png", "page": 8, "dpi": 300, "bbox": [124, 597, 703, 744], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: These continuous scatterplots were created with the octree approach for the \u201cEngine\u201d data set. The effect of different thresholds is shown. The left picture shows a coarse approximation with a threshold that allows \u03a6 to extend up to 200 pixels in each dimension. The picture in the middle uses a decreased threshold of 100 pixels. The right-most picture shows a good approximation since the threshold is lowered to 50 pixels. ", "caption_bbox": [96, 754, 729, 813]}], "389": [{"image_id": 0, "file_name": "389_00.png", "page": 2, "dpi": 300, "bbox": [430, 535, 729, 701], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Indicators of our reference coloring", "caption_bbox": [465, 705, 692, 718]}, {"image_id": 1, "file_name": "389_01.png", "page": 3, "dpi": 300, "bbox": [124, 385, 368, 490], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Our reference coloring on the Riemann sphere", "caption_bbox": [106, 495, 387, 508]}, {"image_id": 2, "file_name": "389_02.png", "page": 3, "dpi": 300, "bbox": [118, 734, 377, 993], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Plot of the rational function f1", "caption_bbox": [146, 1009, 348, 1024]}, {"image_id": 3, "file_name": "389_03.png", "page": 4, "dpi": 300, "bbox": [96, 134, 415, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Typical pattern of a multiple zero zk and a multiple pole z\u2212k ", "caption_bbox": [96, 333, 397, 365]}, {"image_id": 4, "file_name": "389_04.png", "page": 4, "dpi": 300, "bbox": [430, 464, 729, 630], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Essential singularities", "caption_bbox": [499, 641, 658, 654]}, {"image_id": 5, "file_name": "389_05.png", "page": 5, "dpi": 300, "bbox": [412, 134, 731, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Inversion acting on \u201cmomentum\u201d", "caption_bbox": [470, 396, 687, 409]}, {"image_id": 6, "file_name": "389_06.png", "page": 6, "dpi": 300, "bbox": [430, 690, 729, 856], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Weierstrass \u2118-functions", "caption_bbox": [494, 867, 664, 880]}, {"image_id": 7, "file_name": "389_07.png", "page": 6, "dpi": 300, "bbox": [412, 136, 729, 522], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visualizing the Schwarz reflection principle", "caption_bbox": [444, 531, 713, 544]}, {"image_id": 8, "file_name": "389_08.png", "page": 6, "dpi": 300, "bbox": [96, 134, 415, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Unit roots of f2 (z) = z5 \u2212 1 (left) and f3 (z) = z\u22125 \u2212 1 ", "caption_bbox": [96, 344, 397, 376]}, {"image_id": 9, "file_name": "389_09.png", "page": 7, "dpi": 300, "bbox": [462, 524, 694, 849], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "  Figure 12: Riemann surface for f8  1. By circling around one of these points, one  the other layer in order to preserve continuity. ", "caption_bbox": [490, 858, 730, 907]}, {"image_id": 10, "file_name": "389_10.png", "page": 7, "dpi": 300, "bbox": [99, 250, 396, 488], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Discontinuity arising from square roots ( f6 , f8 ) and logarithms ( f7 ) ", "caption_bbox": [96, 496, 397, 526]}, {"image_id": 11, "file_name": "389_11.png", "page": 8, "dpi": 300, "bbox": [412, 136, 739, 757], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Domain colored Gauss maps", "caption_bbox": [479, 761, 679, 774]}], "390": [{"image_id": 0, "file_name": "390_00.png", "page": 1, "dpi": 300, "bbox": [468, 817, 691, 950], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Hyperspectral images are spatially two- dimensional, with pixels that are sampled functions of ra- diance (or re\ufb02ectance) versus wavelength. ", "caption_bbox": [428, 960, 729, 1004]}, {"image_id": 1, "file_name": "390_01.png", "page": 4, "dpi": 300, "bbox": [440, 172, 715, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Our approach creates a Voronoi-like tessellation of the function \ufb01eld range space (i.e., space of functions). Each \u201ccell\u201d of the tessellation is assigned its own colormap for visualization. The color of a point p is determined by the location of its corresponding function f p within the range- space segmentation. ", "caption_bbox": [428, 340, 729, 429]}, {"image_id": 2, "file_name": "390_02.png", "page": 5, "dpi": 300, "bbox": [100, 154, 728, 534], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visualizations of a hyperspectral image of Moffett Field and the San Francisco Bay. The leftmost set of images shows the construction of a range-space segmentation with 1, 2, 3, and 4 probes. On the right are images generated by mapping PCA components to RGB (top), and by Vector Quantization (VQ) clustering (bottom). ", "caption_bbox": [96, 537, 729, 584]}, {"image_id": 3, "file_name": "390_03.png", "page": 6, "dpi": 300, "bbox": [136, 158, 359, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Timings for range-space segmentation creation.", "caption_bbox": [436, 166, 722, 179]}, {"image_id": 4, "file_name": "390_04.png", "page": 8, "dpi": 300, "bbox": [99, 482, 733, 916], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Range-space segmentation of the CRPAQS dataset using multiple probes in different timesteps: the \ufb01rst two probes are in timestep 0, while the third probe is in the last timestep. In (a) we use these probes to visualize the movement of high (red) and moderate (blue) SO4 concentration features over time through the San Joaquin Valley. In (b), we show a closeup of the \ufb01rst timestep, while (c) shows the segmentation of high, moderate, and low concentration regions. ", "caption_bbox": [96, 928, 729, 987]}, {"image_id": 5, "file_name": "390_05.png", "page": 8, "dpi": 300, "bbox": [100, 179, 730, 403], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Volume renderings produced from range-space segmentations of the National H2 O particulate concentration dataset. By using multiple probes, and simple transfer functions, users are able to create renderings that meaningfully highlight different aspects of the same dataset. ", "caption_bbox": [96, 415, 729, 459]}], "391": [{"image_id": 0, "file_name": "391_00.png", "page": 1, "dpi": 300, "bbox": [97, 754, 378, 879], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Original problem materials (left) and the volume fractions of the blue material in each cell (right). ", "caption_bbox": [85, 878, 389, 910]}, {"image_id": 1, "file_name": "391_01.png", "page": 2, "dpi": 300, "bbox": [423, 394, 717, 519], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Intersection points for red/yellow evaluation (left) and the clipped volumes (right). ", "caption_bbox": [417, 518, 721, 550]}, {"image_id": 2, "file_name": "391_02.png", "page": 2, "dpi": 300, "bbox": [93, 708, 383, 838], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Volume fractions for each material (left) are averaged to the vertices of the mesh (right). ", "caption_bbox": [85, 837, 389, 869]}, {"image_id": 3, "file_name": "391_03.png", "page": 3, "dpi": 300, "bbox": [507, 185, 633, 296], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The final reconstruction for all three materials.", "caption_bbox": [427, 295, 718, 313]}, {"image_id": 4, "file_name": "391_04.png", "page": 3, "dpi": 300, "bbox": [99, 625, 377, 723], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Evaluating the third (blue) material against the first (yellow) and second (red) materials. ", "caption_bbox": [85, 722, 389, 754]}, {"image_id": 5, "file_name": "391_05.png", "page": 4, "dpi": 300, "bbox": [501, 417, 639, 492], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) Volumetric PLIC reconstruction. (b) Surface- only PLIC reconstruction leaves holes. (c) Generating surfaces from volumetric reconstructions leave duplicate geometry. (d) An ideal result has sharp angles and requires additional expense to generate. Duplicate partial surface removal (d) is not a standard part of PLIC reconstructions, we implemented it for the comparisons in this paper. ", "caption_bbox": [417, 491, 721, 593]}, {"image_id": 6, "file_name": "391_06.png", "page": 5, "dpi": 300, "bbox": [86, 184, 388, 397], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Thin-shell torus test data set. Close-up of reconstruction using (a) PLIC (b) Discrete (c) Isovolume (d) Equi-T (e) Equi-Z (f) Equi-Z/i20. ", "caption_bbox": [85, 397, 389, 443]}, {"image_id": 7, "file_name": "391_07.png", "page": 5, "dpi": 300, "bbox": [418, 285, 721, 524], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Unstructured mesh ovoid reconstruction using (a) PLIC (b) Isovolume (c) Equi-T (d) Equi-Z/i5. ", "caption_bbox": [417, 525, 721, 557]}, {"image_id": 8, "file_name": "391_08.png", "page": 6, "dpi": 300, "bbox": [84, 339, 393, 920], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: (a) Unstructured dataset from ALE3D simulation showing material velocities. (b) Close-up of zoom region showing velocities. Reconstructions shown in zoom region are (c) PLIC, (d) Isovolume, (e) Equi-Z, (f) Equi-Z/i30. 4.5   Volume fraction accuracy ", "caption_bbox": [85, 919, 389, 1001]}, {"image_id": 9, "file_name": "391_09.png", "page": 6, "dpi": 300, "bbox": [419, 255, 722, 788], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: \u201cRect3D\u201d Regular grid data set of nested spheres reconstructed with (a) PLIC (b) Discrete/10sec, (c) Discrete/60sec, (d) Isovolume, (e) Equi-Z, (f) Equi-Z/i5. ", "caption_bbox": [417, 788, 721, 834]}, {"image_id": 10, "file_name": "391_10.png", "page": 7, "dpi": 300, "bbox": [86, 342, 390, 520], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Close zoom of a blue circle against a green", "caption_bbox": [93, 519, 389, 537]}, {"image_id": 11, "file_name": "391_11.png", "page": 7, "dpi": 300, "bbox": [90, 705, 385, 883], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Area of a unit circle material sampled onto a grid as reconstructed by each algorithm for a sequence of increasing resolutions. The correct answer is !. ", "caption_bbox": [85, 883, 389, 929]}, {"image_id": 12, "file_name": "391_12.png", "page": 7, "dpi": 300, "bbox": [436, 279, 704, 476], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Relative error of material volume on the \u201c50x50 Circle\u201d test data set for various convergence parameters in the Equi-Z/iterative algorithm. ", "caption_bbox": [417, 480, 720, 526]}, {"image_id": 13, "file_name": "391_13.png", "page": 7, "dpi": 300, "bbox": [435, 664, 703, 868], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Maximum relative error for any single cell in", "caption_bbox": [425, 867, 721, 885]}, {"image_id": 14, "file_name": "391_14.png", "page": 8, "dpi": 300, "bbox": [447, 432, 695, 569], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Average number of 2D polygons and lines created in each domain for material 3 in the 2D ALE3D data set. ", "caption_bbox": [417, 782, 721, 814]}, {"image_id": 15, "file_name": "391_15.png", "page": 8, "dpi": 300, "bbox": [86, 371, 388, 543], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Sum of absolute value of exterior angles in Circle boundary at increasing resolutions. A convex polygon has value 2!; each jagged edge results in a negative angle, in turn resulting in an increase in this sum. 4.7   Memory complexity ", "caption_bbox": [417, 570, 721, 652]}], "392": [{"image_id": 0, "file_name": "392_00.png", "page": 3, "dpi": 300, "bbox": [108, 580, 387, 682], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A schematic view of the algorithm. Black arrows des- ignate control flow, and green arrows designate data flow with the ellipses standing for the textures or images in video memory. ", "caption_bbox": [96, 694, 397, 737]}, {"image_id": 1, "file_name": "392_01.png", "page": 3, "dpi": 300, "bbox": [111, 294, 384, 421], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The active cells (red) enclose some isosurfaces (blue). For the upper ray, A, our approach generates 2 valid ray segments                        \u2212\u2212\u2192        \u2212\u2212\u2192 in near-to-far order: A1 A2 and A3 A4 ; while for the lower ray, B, our                                                                   \u2212\u2212\u2192 approach generates 2 valid ray segments in the same order: B1 B2       \u2212\u2212\u2192 and B3 B4 . Previous object-order algorithms, which used only the first-hit and last-hit points, generated one coarse ray segment per              \u2212\u2212\u2192       \u2212\u2212\u2192 ray, that is A1 A4 and B1 B4 for rays A and B, respectively, as a result                                                  \u2212\u2212\u2192        \u2212\u2212\u2192 they cannot skip interior empty space, such as A2 A3 and B2 B3 . ", "caption_bbox": [96, 433, 397, 552]}, {"image_id": 2, "file_name": "392_02.png", "page": 4, "dpi": 300, "bbox": [481, 238, 678, 400], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: If the camera is aligned with the major axis (blue ar- row), then Seqcell for cells A and B are 1 and 3, respectively; while if the camera direction is in the negative direction of the major axis (orange arrow), then Seqcell for cells A and B are 2 and 0, respec- tively, before flipping, while they are 1 and 3 after flipping. So finally the bitmasks for cells A and B are 0x2 and 0x8, respectively. Here TotalSlice is 4. ", "caption_bbox": [428, 412, 729, 516]}, {"image_id": 3, "file_name": "392_03.png", "page": 5, "dpi": 300, "bbox": [412, 132, 739, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The bitmask here is \"0011000\", so there is only one set bit-segment, whose start and end indices are originally 3 and 4, respectively. The left figure shows the case when the camera points along the major axis Z, so startVoxelindex = 3 and we need only to offset the end index by 1: endVoxelindex = 4 + 1 = 5; while the right figure shows the case when the camera points in the opposite direction to the major axis Z, in which case we need to flip both indices: startVoxelindex = TotalSlice \u2212 3 = 4 and endVoxelindex = TotalSlice \u2212 1 \u2212 4 = 2, where TotalSlice = 7 in this case. ", "caption_bbox": [428, 364, 729, 499]}, {"image_id": 4, "file_name": "392_04.png", "page": 6, "dpi": 300, "bbox": [96, 697, 399, 850], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Transparent rendering results. The left image shows the nucleon dataset (with resolution of 643 ) rendered at 71.9 fps; the right image shows the anatomia dataset (with resolution of 5123 ) rendered at 21.3 fps. ", "caption_bbox": [96, 855, 397, 913]}, {"image_id": 5, "file_name": "392_05.png", "page": 8, "dpi": 300, "bbox": [96, 132, 731, 599], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Quality comparison between kd jump, our algorithm and cuda_mc, using the fuel and hydrogenAtom datasets. The rendering quality of cuda_mc is worse than ours due to its faceted appearance (diamond artefacts); kd jump uses only uniform stepping to find the intersection; while our algorithm uses a similar uniform stepping, but this is followed by a binary search to refine the intersection. Hence our results are slightly smoother than those of kd jump. Furthermore, kd jump uses only simple diffuse lighting, while ours uses full Phong shading. ", "caption_bbox": [96, 604, 729, 662]}, {"image_id": 6, "file_name": "392_06.png", "page": 9, "dpi": 300, "bbox": [108, 132, 732, 813], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Rendering results of our algorithm for different dense and sparse data sets. For these viewing configurations, the corresponding performance statistics of our algorithm, kdjump and cuda_mc are shown in Tables 1, 2 and 3. ", "caption_bbox": [96, 819, 729, 847]}], "393": [{"image_id": 0, "file_name": "393_00.png", "page": 2, "dpi": 300, "bbox": [95, 164, 731, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The Pressure data set. The top row shows the noisy input scalar field, and the bottom row our results. The original topology contains spurious critical points which have low persistence values and are removed by the simplification process. The persistence histogram on the right shows the number of topological simplification operations (cancellations) as function of their persistence; the obvious drop in the histogram around a persistence value of 0.01 hints the user at the appropriate noise threshold. The peak signal-to-noise ratio (PSNR) between noisy input and smoothed result is 30.8 dB. ", "caption_bbox": [96, 352, 729, 423]}, {"image_id": 1, "file_name": "393_01.png", "page": 4, "dpi": 300, "bbox": [428, 164, 731, 307], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Persistence-based simplification by removing pairs of critical points. ", "caption_bbox": [428, 320, 729, 348]}, {"image_id": 2, "file_name": "393_02.png", "page": 4, "dpi": 300, "bbox": [95, 157, 399, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Topological concepts.", "caption_bbox": [165, 443, 327, 456]}, {"image_id": 3, "file_name": "393_03.png", "page": 5, "dpi": 300, "bbox": [427, 157, 731, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Constructing a faithful preview of the smoothed scalar field. The abstract connectivity of the simplified Morse-Smale complex (top left) is supplied with valid val- ues by linearly interpolating between the endpoints of each separatrix (top right). A harmonic function is then computed with the separatrices as boundary conditions (bottom). Refer to Figure 9a for the input scalar field. ", "caption_bbox": [428, 400, 729, 501]}, {"image_id": 4, "file_name": "393_04.png", "page": 6, "dpi": 300, "bbox": [95, 157, 399, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The parametric embedding of the simplified sep- aratrices may be jaggy (left) and is smoothed by Laplacian mesh optimization (right). ", "caption_bbox": [96, 290, 397, 332]}, {"image_id": 5, "file_name": "393_05.png", "page": 7, "dpi": 300, "bbox": [427, 157, 731, 221], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Original function (left) has been reconstructed based on the topology shown using the C0 preview scheme (middle, Section 5) and the C1 method (right, Section 6). ", "caption_bbox": [428, 231, 729, 273]}, {"image_id": 6, "file_name": "393_06.png", "page": 8, "dpi": 300, "bbox": [95, 333, 399, 466], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Electrostatic field of the Benzene molecule. The original data set (left) has been reconstructed (right) without topological simplification. The PSNR is 50.8 dB. ", "caption_bbox": [96, 476, 397, 518]}, {"image_id": 7, "file_name": "393_07.png", "page": 9, "dpi": 300, "bbox": [95, 157, 399, 619], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Experimentally measured data set showing the instantaneous vorticity at the outlet of a combustor (flow di- rection from top to bottom). The size and overall shape of the major features at the burner outlet (top) are preserved while the noise has been successfully removed. ", "caption_bbox": [96, 631, 397, 702]}], "394": [{"image_id": 0, "file_name": "394_00.png", "page": 4, "dpi": 300, "bbox": [130, 798, 364, 921], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Narrow band construction on unstructured sam- ples. A circle of radius \u03b1 around each isopoint (blue) marks samples that belong to the band (green) and neglects the ones that lie outside (red). Simultaneously, we establish a list of closest isopoints for each marked sample. ", "caption_bbox": [96, 936, 397, 1010]}, {"image_id": 1, "file_name": "394_01.png", "page": 4, "dpi": 300, "bbox": [146, 233, 317, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Direct extraction of isopoints by Rosenthal and Linsen [RL06]. A set of isopoints (blue) is found by means of linear interpolation between neighboring samples with pos- itive (green) and negative (red) scalar values. ", "caption_bbox": [96, 166, 397, 225]}, {"image_id": 2, "file_name": "394_02.png", "page": 5, "dpi": 300, "bbox": [412, 132, 731, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Vanishing MLS weights due to small differences in distances to neighbors. The nearest neighbors of the sample x lie on a perfect sphere; the isosurface close to the sample y is oversampled. ", "caption_bbox": [428, 319, 729, 378]}, {"image_id": 3, "file_name": "394_03.png", "page": 6, "dpi": 300, "bbox": [96, 132, 415, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Accurate choice of neighbors. Sheet separation (left) is characterized by large angle between normals of neighbors (red vectors). To distinguish sharp features (right) we use an additional criterion. Neighbor isopoints of a sam- ple (green disc) have normals with large angle discrepancy (red arrows). However we do not treat it as sheet layer, since the angle between the pointing vectors \u03b3 is small. ", "caption_bbox": [96, 288, 397, 394]}, {"image_id": 4, "file_name": "394_04.png", "page": 7, "dpi": 300, "bbox": [132, 132, 415, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Left: a sample (red) lying in a layer between two spheres and a plane has its nearest neighbors (blue) belong- ing to different objects (test 2). Thus, two fitting spheres were generated (light blue and light green) to detect the closest isosurface. Right: Fitting a sphere for a torus represented as a set of randomly distributed points (test 3). The sphere (light green) is found using positions and normals of iso- points (blue) close to the point of interest (red). ", "caption_bbox": [428, 304, 729, 424]}, {"image_id": 5, "file_name": "394_05.png", "page": 7, "dpi": 300, "bbox": [412, 132, 732, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Accuracy and efficiency of SDF approximations by naive approach \u03d50 , weighted sum formula \u03d51 , and our proposed algorithm \u03d5 . Average and maximal error \u03b5 is measured for three test isosurfaces with uniformly sampled points: a sphere (test 1), two spheres and a plane (test 2) and a torus (test 3). The efficiency is characterized by the time of SDF computation (1) with the lists of closest isopoints from the \u03b1 -band construction: t, and (2) with the pre-computed 24 closest isopoints for all \u03b1 -band samples: \u03c4 . ", "caption_bbox": [428, 764, 729, 900]}, {"image_id": 6, "file_name": "394_06.png", "page": 8, "dpi": 300, "bbox": [412, 132, 713, 355], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Several isosurfaces of the SDF field constructed for the dragon dataset with 437k surface points. ", "caption_bbox": [428, 373, 729, 401]}, {"image_id": 7, "file_name": "394_07.png", "page": 9, "dpi": 300, "bbox": [114, 132, 415, 780], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Several isosurfaces of the SDF fields constructed for the skeleton hand (327k surface points) and the bunny (35k surface points) datasets. ", "caption_bbox": [96, 794, 397, 838]}, {"image_id": 8, "file_name": "394_08.png", "page": 9, "dpi": 300, "bbox": [412, 132, 732, 284], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Left: The White Dwarf dataset with 500k data points. Right: The samples on the isosurface with fiso = 0.0001 extracted from the signed distance field ap- proximated in a dense \u03b1 -band with about 5M samples. (Data set courtesy of Stephan Rosswog, Jacobs University, Bremen, Germany.) ", "caption_bbox": [428, 304, 729, 393]}], "395": [{"image_id": 0, "file_name": "395_00.png", "page": 3, "dpi": 300, "bbox": [219, 170, 599, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example of scatterplots used in the discrimination task. Observers were asked to choose which scatterplot is more highly correlated. In this example, base correlation is 0.8; jnd is from above. ", "caption_bbox": [106, 309, 698, 337]}, {"image_id": 1, "file_name": "395_01.png", "page": 3, "dpi": 300, "bbox": [107, 753, 721, 956], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Schematic of threshold algorithm. The distance from base correlation is adjusted until the variance of the averages of the sub-windows is 0.25 of the average variance within the sub-windows. ", "caption_bbox": [106, 962, 692, 989]}, {"image_id": 2, "file_name": "395_02.png", "page": 4, "dpi": 300, "bbox": [105, 170, 689, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Example of scatterplots used in the direct estimation task. Observers adjusted the correlation of the central test plot, until its correlation was halfway between those of the two reference plots. Here, adjusted value of the test plot is r=0.74, which corresponds to the subjective midpoint. ", "caption_bbox": [106, 338, 708, 380]}, {"image_id": 3, "file_name": "395_03.png", "page": 5, "dpi": 300, "bbox": [114, 681, 364, 946], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Jnd as a function of adjusted correlation rA. Error bars denote standard error of the mean. ", "caption_bbox": [106, 950, 398, 977]}, {"image_id": 4, "file_name": "395_04.png", "page": 5, "dpi": 300, "bbox": [111, 171, 370, 432], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Jnd as a function of raw correlation r. Error bars denote standard error of the mean ", "caption_bbox": [106, 436, 398, 464]}, {"image_id": 5, "file_name": "395_05.png", "page": 6, "dpi": 300, "bbox": [120, 488, 389, 745], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Results of direct estimation. Vertical error bars show one jnd; horizontal error bars standard error. Curve is g(r) = ln(1\u2013br) / ln(1-b), with b = 0.875. ", "caption_bbox": [106, 750, 398, 792]}], "396": [{"image_id": 0, "file_name": "396_00.png", "page": 1, "dpi": 300, "bbox": [412, 417, 731, 791], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Standard widgets (left), interactive legends (right)", "caption_bbox": [428, 805, 729, 818]}, {"image_id": 1, "file_name": "396_01.png", "page": 3, "dpi": 300, "bbox": [118, 134, 415, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Interactive legends for color and opacity. Categor- ical color (left), ordinal opacity without and with handles to modify ranges (middle), numerical opacity (right). ", "caption_bbox": [96, 319, 397, 362]}, {"image_id": 2, "file_name": "396_02.png", "page": 3, "dpi": 300, "bbox": [412, 132, 731, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Combined interactive legends for color+opacity. Categorical color and ordinal opacity (left), feedback on filtered elements (middle), categorical color and numerical opacity (right). ", "caption_bbox": [428, 321, 729, 380]}, {"image_id": 3, "file_name": "396_03.png", "page": 5, "dpi": 300, "bbox": [95, 747, 722, 949], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Interactive legend for controling the size. Handles are provided to filter interactively the visualization.", "caption_bbox": [131, 959, 693, 972]}, {"image_id": 4, "file_name": "396_04.png", "page": 5, "dpi": 300, "bbox": [105, 132, 732, 667], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Experimental software. The top of the screen contains the task and start button. The center of the screen contains the visualization including an interactive legend or a standard widget depending on the experimental condition. ", "caption_bbox": [96, 693, 729, 721]}, {"image_id": 5, "file_name": "396_05.png", "page": 6, "dpi": 300, "bbox": [412, 134, 729, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Mean and standard deviation for accuracy and time for each of the four techniques for experiment 1. ", "caption_bbox": [428, 459, 729, 487]}, {"image_id": 6, "file_name": "396_06.png", "page": 8, "dpi": 300, "bbox": [96, 132, 721, 351], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Bar charts presenting the mean answer (left) and mean time including errors (right) for the eight conditions.", "caption_bbox": [113, 354, 707, 367]}], "397": [{"image_id": 0, "file_name": "397_00.png", "page": 2, "dpi": 300, "bbox": [96, 132, 415, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization-based importance: (a) Relevant structures in the (b) visualization as defined by the visual- izer, where black areas are most relevant. (c) Visual salience of the image in (b). ", "caption_bbox": [96, 290, 397, 349]}, {"image_id": 1, "file_name": "397_01.png", "page": 4, "dpi": 300, "bbox": [96, 132, 695, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Matching of user defined relevance and salience map: (a) Difference field between the relevance mask and the salience map. (b) corresponding color map. (c) The quality chart provides an intuitive quality rating. ", "caption_bbox": [96, 313, 729, 341]}, {"image_id": 2, "file_name": "397_02.png", "page": 5, "dpi": 300, "bbox": [135, 132, 732, 493], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Two TagCloud visualizations (InfoVis): The TagClouds represent keywords of (a) the InfoVis Wiki (courtesy of In- foVis:Wiki team) and (b) communication. (b,e) Overlay of the original image with the salience map. (c,f) Contribution maps (color opponency (red), intensity change (gray) and orientation (blue)). ", "caption_bbox": [96, 498, 729, 541]}, {"image_id": 3, "file_name": "397_03.png", "page": 6, "dpi": 300, "bbox": [412, 134, 725, 655], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Volume rendering of engine dataset: (a) Direct volume rendering and (b) perception-based transparency optimization of the same data set (images courtesy of M.- Y. Chan [CWM\u2217 09]). (c,d) Overlay of the original image with the salience map. Dark blue regions indicate highest salience. (e,f) Contribution maps for color opponency (red), intensity change (gray) and orientation (blue). ", "caption_bbox": [428, 667, 729, 771]}, {"image_id": 4, "file_name": "397_04.png", "page": 7, "dpi": 300, "bbox": [98, 132, 732, 682], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Flow visualizations: (top) The same field is depicted using different techniques (req courtesy of D. Laidlaw [LKJ\u2217 05]). (2nd row) Salient structures are colored in blue. (3rd row) Contribution maps, red for intensity-band, grey for intensity and blue for orientation. (bottom) Difference between the salience map and the relevance mask. Color coding as given in Figure 2(b). ", "caption_bbox": [96, 692, 729, 739]}, {"image_id": 5, "file_name": "397_05.png", "page": 8, "dpi": 300, "bbox": [412, 134, 734, 609], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Match statistics for the flow visualizations: Each chart gives an overview over the relevance classes as defined by the user (lower bar) and the salience map (central bar), as well as the match between the two classifications (upper bar). See Figure 2(c) for a more detailed explanation. ", "caption_bbox": [428, 625, 729, 699]}, {"image_id": 6, "file_name": "397_06.png", "page": 8, "dpi": 300, "bbox": [96, 132, 415, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Relevant structures in the flow visualization data set. (a) Depiction of the interesting features. (b) Relevance mask as designed by the visualizer. ", "caption_bbox": [96, 317, 397, 360]}], "398": [{"image_id": 0, "file_name": "398_00.png", "page": 3, "dpi": 300, "bbox": [228, 157, 599, 647], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The experiment interface. The question was shown in the upper right corner of the screen. When the participant thought they had the right answer, the participant selected a radio button on the right and clicked valider ma r\u00e9ponse (or \u201cconfirm answer\u201d. (a) The NC condition interface on the Internet medium data. (b) The PPC condition interface on the Internet medium data. Both interfaces are showing the same version of question 1 used in the experiment. ", "caption_bbox": [96, 660, 729, 719]}, {"image_id": 1, "file_name": "398_01.png", "page": 4, "dpi": 300, "bbox": [97, 132, 415, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Open/closed metanodes in the experiment. (a) The gold metanode is closed. (b) The gold metanode is open. ", "caption_bbox": [96, 289, 397, 317]}, {"image_id": 2, "file_name": "398_02.png", "page": 5, "dpi": 300, "bbox": [159, 163, 668, 622], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Four of the six data sets under the PPC and NC conditions. (a) The NC condition of the small version of Internet. (b) The PPC condition of the large version of Internet. (c) The PPC condition of the small version of IMDB. (d) The NC condition of the large version of IMDB. ", "caption_bbox": [96, 634, 729, 678]}, {"image_id": 3, "file_name": "398_03.png", "page": 7, "dpi": 300, "bbox": [156, 132, 732, 391], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Mean response time and errors, comparing NC to PPC. In this and all subsequent bar charts, lines indicate where significance is found. The mean and median values, separated by a dash, are written below each bar of the chart. ", "caption_bbox": [96, 396, 729, 424]}, {"image_id": 4, "file_name": "398_04.png", "page": 7, "dpi": 300, "bbox": [427, 461, 736, 695], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Mean response time and errors, comparing NC to PPC, for small, medium, and large data sets. ", "caption_bbox": [428, 700, 729, 729]}, {"image_id": 5, "file_name": "398_05.png", "page": 8, "dpi": 300, "bbox": [437, 736, 722, 807], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Qualitative preference data: overall and by ques- tion. No preference indicates the participant had no prefer- ence or felt it depended on the situation/question. ", "caption_bbox": [428, 812, 729, 856]}, {"image_id": 6, "file_name": "398_06.png", "page": 8, "dpi": 300, "bbox": [475, 446, 683, 680], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Mean response time and errors, comparing NC to PPC, for low and high connectivity data sets. ", "caption_bbox": [428, 685, 729, 713]}, {"image_id": 7, "file_name": "398_07.png", "page": 8, "dpi": 300, "bbox": [208, 157, 618, 391], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Mean response time and errors, comparing NC to PPC, for the medium data sets.", "caption_bbox": [182, 396, 642, 409]}, {"image_id": 8, "file_name": "398_08.png", "page": 9, "dpi": 300, "bbox": [95, 157, 400, 228], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The number of nodes/metanodes and edges pre- sented in the PPC version of each data set. |N| is the number of nodes/metanodes while |E| is the number of edges. ", "caption_bbox": [96, 233, 397, 277]}], "399": [{"image_id": 0, "file_name": "399_00.png", "page": 5, "dpi": 300, "bbox": [463, 311, 696, 456], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Computation of unsteadiness. The unsteadiness as defined in Equation 6 can be computed by the combination of a spatial and temporal filter. ", "caption_bbox": [428, 473, 729, 516]}, {"image_id": 1, "file_name": "399_01.png", "page": 6, "dpi": 300, "bbox": [97, 549, 399, 646], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: \u201cDouble gyre\u201d field at t = 0 and t = 2.5.", "caption_bbox": [117, 658, 375, 671]}, {"image_id": 2, "file_name": "399_02.png", "page": 6, "dpi": 300, "bbox": [432, 384, 727, 682], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Velocity magnitude (a) shows critical points in blue. The one in the bottom center is the saddle point to be studied. The minimum of acceleration magnitude (b) is shifted to the right. The same quantities, but Gaussian- filtered over the time range [\u2212 32 , 32 ] (c,d), show a minimum somewhere in between. Unsteadiness (e) has a clear mini- mum and FTLE (f) a clear maximum at the same spot. The transfer functions are chosen such that minima (blue) and maxima (red) are clearly distinguishable. ", "caption_bbox": [428, 695, 729, 830]}, {"image_id": 3, "file_name": "399_03.png", "page": 7, "dpi": 300, "bbox": [101, 134, 415, 432], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparison of methods on the dynamic sad- dle point on the x-axis of the \u201cdouble gyre\u201d. The x co- ordinate is plotted against the time for a full period. All methods based on a time window (solid lines) essentially agree. The unsteadiness minimum (red) almost equals the minimum of velocity magnitude (black), while the FTLE maximum (green) and the minimum of acceleration magni- tude (blue) have slight offsets. The instantaneous methods (dashed lines) clearly deviate from these. The zero of the ac- celeration (blue) has mainly an amplitude error, while the critical point (black) also has a phase error of about 0.8. ", "caption_bbox": [96, 448, 397, 613]}, {"image_id": 4, "file_name": "399_04.png", "page": 7, "dpi": 300, "bbox": [125, 636, 369, 757], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: \u201cPetri Dish\u201d field at t = 0 and t = \u03c0/2.", "caption_bbox": [121, 767, 372, 780]}, {"image_id": 5, "file_name": "399_05.png", "page": 7, "dpi": 300, "bbox": [431, 555, 727, 741], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Top row: extrema of FTLE (a), unsteadiness (b), acceleration magnitude (c), and velocity magnitude (d) us- ing a temporal filter with support [-1.5, 1.5]. Bottom row: The same with temporal filter support [-5.0,5.0]. Now, (e) and (f) almost coincide, while in (g) and (h) the extremum has disappeared. Color maps are chosen to isolate the local extremum. ", "caption_bbox": [428, 753, 729, 857]}, {"image_id": 6, "file_name": "399_06.png", "page": 8, "dpi": 300, "bbox": [412, 134, 731, 751], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: By subtracting a constant (empirically found) ve- locity, the vortices appear in the background LIC images used in (a)-(d). Minima of (temporally filtered) acceleration magnitude and unsteadiness (b) are able to detect the vor- tex centers, in contrast to velocity magnitude (c) and FTLE (d). The color maps have been chosen such that the local ex- trema become visible. In addition, the set of extrema (after thresholding) is depicted by the white crosses. ", "caption_bbox": [428, 764, 729, 884]}, {"image_id": 7, "file_name": "399_07.png", "page": 8, "dpi": 300, "bbox": [96, 132, 415, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Summary of the evaluation results.", "caption_bbox": [136, 977, 357, 990]}], "400": [{"image_id": 0, "file_name": "400_00.png", "page": 2, "dpi": 300, "bbox": [96, 132, 415, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Illustration of different types of 3D vector field saddles. Node saddle (left) and spiral saddle (right). ", "caption_bbox": [96, 273, 397, 301]}, {"image_id": 1, "file_name": "400_01.png", "page": 3, "dpi": 300, "bbox": [100, 160, 395, 344], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Stream surface in linear vector field with highly diverging stream lines where the angle criterion (130 de- grees) fails because the surface does not run into the saddle. The red part of the surface would have been left out if the angle criterion were to be used. ", "caption_bbox": [96, 357, 397, 431]}, {"image_id": 2, "file_name": "400_02.png", "page": 3, "dpi": 300, "bbox": [427, 160, 740, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Stalling\u2019s algorithm applied to a spiral saddle. When the angle between flow vectors exceeds 150 degrees the saddle is incorporated leading to visual artifacts such as the red triangle. ", "caption_bbox": [428, 357, 729, 416]}, {"image_id": 3, "file_name": "400_03.png", "page": 3, "dpi": 300, "bbox": [476, 443, 683, 616], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Figure 3 viewed from the side. The approximation of the spiral by the red triangle in Fig. 3 leads to helix like structures in the stream surface. ", "caption_bbox": [428, 628, 729, 672]}, {"image_id": 4, "file_name": "400_04.png", "page": 4, "dpi": 300, "bbox": [412, 133, 726, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Left: Incorporation of a sink into a stream surface. Right: Depiction of a node saddle where two new stream lines are inserted along the repelling eigenvector. ", "caption_bbox": [428, 274, 729, 318]}, {"image_id": 5, "file_name": "400_05.png", "page": 5, "dpi": 300, "bbox": [412, 132, 732, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Illustration of the algorithm for finding a seeding position Ps of a stream line inserted near a focus saddle. ", "caption_bbox": [428, 309, 729, 338]}, {"image_id": 6, "file_name": "400_06.png", "page": 7, "dpi": 300, "bbox": [427, 818, 732, 931], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparison between standard and topology aware algorithm for the Draft Tube dataset. As can be seen, our algorithm produces considerably fewer stream lines. ", "caption_bbox": [428, 943, 729, 987]}, {"image_id": 7, "file_name": "400_07.png", "page": 7, "dpi": 300, "bbox": [100, 466, 726, 627], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Close ups of the saddle region showing the triangulation. Left: Stream surface generated by the standard algorithm continuously refining the stream surface near the saddle. The visual artifacts from the refining process are clearly visible. Right: Stream surface computed with our algorithm incorporating the saddle cleanly into the surface. ", "caption_bbox": [96, 639, 729, 683]}, {"image_id": 8, "file_name": "400_08.png", "page": 7, "dpi": 300, "bbox": [118, 160, 711, 406], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Negative time stream surface in Draft Tube dataset Left: Location of the surface in the dataset. Right: Overview of the topology-aware stream surface running into a node saddle. Close ups of the saddle region can be seen below in Fig. 8. ", "caption_bbox": [96, 416, 729, 445]}, {"image_id": 9, "file_name": "400_09.png", "page": 8, "dpi": 300, "bbox": [427, 862, 732, 960], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Comparison between standard and topology aware arc-length integration for the Delta Wing dataset. ", "caption_bbox": [428, 972, 729, 1000]}, {"image_id": 10, "file_name": "400_10.png", "page": 8, "dpi": 300, "bbox": [100, 416, 726, 617], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Close ups of Fig. 10. Both surfaces consist of a similar amount of streamlines (approx. 8300) and have the same integration time of 0.035. Left: Close up of the surface generated by the standard algorithm showing artifacts of the refinement process and the resulting broken surface approximation. Right: Close up of the surface computed with our topology aware algorithm with t f = \u03c02 . ", "caption_bbox": [96, 627, 729, 686]}, {"image_id": 11, "file_name": "400_11.png", "page": 8, "dpi": 300, "bbox": [96, 132, 731, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: High quality rendering of the 2D unstable manifold stream surface of the left breakdown bubble in the Delta Wing dataset running into the opposing focus saddle point. Red eigenvectors indicate repelling behavior whereas blue eigenvectors indicate attracting behavior as communicated by the arrow directions. ", "caption_bbox": [96, 351, 729, 395]}], "401": [{"image_id": 0, "file_name": "401_00.png", "page": 1, "dpi": 300, "bbox": [412, 374, 731, 756], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Polar plots (a) make it difficult to see the shape and orientation of peaks, which is readily revealed by our HOME glyphs (b). In applications like HARDI, algebraic surfaces (c) are counter-intuitive. ", "caption_bbox": [428, 770, 729, 829]}, {"image_id": 1, "file_name": "401_01.png", "page": 3, "dpi": 300, "bbox": [140, 157, 354, 243], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Sharp peaks can cause self-intersections in the HOME glyph (b) even if the homogeneous form is positive, as revealed by the polar plot (a). This problem cannot occur if the tensor has a positive rank-1 decomposition. ", "caption_bbox": [96, 253, 397, 312]}, {"image_id": 2, "file_name": "401_02.png", "page": 3, "dpi": 300, "bbox": [440, 157, 720, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The polar plot p(v) preserves the angles between vectors v that are distributed uniformly over the unit circle (a). In the tensor ellipse t(v) and the HOME glyph h(v), the vectors are deflected towards maxima. ", "caption_bbox": [428, 257, 729, 316]}, {"image_id": 3, "file_name": "401_03.png", "page": 4, "dpi": 300, "bbox": [96, 132, 415, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Coloring based on surface partitioning (b) con- veys the number and direction of maxima more clearly than simple rainbow coloring (a). An additional smoothing step (c) blurs the boundaries between regions. ", "caption_bbox": [96, 226, 397, 285]}, {"image_id": 4, "file_name": "401_04.png", "page": 5, "dpi": 300, "bbox": [96, 158, 384, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Time needed to generate 5577 glyphs, on a quad- core and on a single-core CPU (in brackets). ", "caption_bbox": [428, 215, 729, 244]}, {"image_id": 5, "file_name": "401_05.png", "page": 6, "dpi": 300, "bbox": [412, 134, 730, 222], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Even when the polar plot hardly shows a differ- ence between the original ODF and a positive rank-k ap- proximation (a), this step is indispensible for an intersection- free visualization of HOME glyphs (b). ", "caption_bbox": [428, 233, 729, 292]}, {"image_id": 6, "file_name": "401_06.png", "page": 7, "dpi": 300, "bbox": [441, 158, 713, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Sixth-order tensors showing a fiber with small, larger, and anisotropic spread (from left to right). The HOME glyphs (bottom) make it much easier to distinguish these cases than the polar plot (top). ", "caption_bbox": [428, 398, 729, 457]}, {"image_id": 7, "file_name": "401_07.png", "page": 7, "dpi": 300, "bbox": [100, 158, 394, 276], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Fourth-order tensors from a HARDI dataset. The relatively flat appearance of the HOME glyphs (bottom) with respect to the polar plot (top) conveys the fact that the dis- played fiber distributions stay mostly within the image plane. ", "caption_bbox": [96, 288, 397, 347]}, {"image_id": 8, "file_name": "401_08.png", "page": 8, "dpi": 300, "bbox": [412, 134, 727, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: In real data (order six), sharp peaks of the HOME glyph (a) correspond well to rank-1 terms. Wide lobes can be interpreted as fiber spread (b) or as unresolved crossings (c). ", "caption_bbox": [428, 262, 729, 321]}, {"image_id": 9, "file_name": "401_09.png", "page": 8, "dpi": 300, "bbox": [96, 132, 415, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Results on synthetic crossings show that sharp peaks of the HOME glyph (left) are well-aligned with true fiber directions (gray lines). When maxima are biased (right), glyph shape emphasizes them less. ", "caption_bbox": [96, 398, 397, 457]}], "402": [{"image_id": 0, "file_name": "402_00.png", "page": 2, "dpi": 300, "bbox": [96, 132, 415, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The four major configuration of a nematic liq- uid crystal system. From left to right: Positive Uniaxial, Isotropic, Biaxial, Negative Uniaxial. ", "caption_bbox": [96, 266, 397, 310]}, {"image_id": 1, "file_name": "402_01.png", "page": 2, "dpi": 300, "bbox": [412, 133, 731, 817], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Glyph types used in the study with given unaxial- ity (vertical axis), biaxiality (horizontal axis), and orienta- tion levels (horizontal groups). Gaps represent invalid tensor values. See Section 3.2 for their construction. ", "caption_bbox": [428, 826, 729, 885]}, {"image_id": 2, "file_name": "402_02.png", "page": 3, "dpi": 300, "bbox": [95, 442, 399, 657], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Screen shot of the user interface.", "caption_bbox": [138, 668, 355, 681]}, {"image_id": 3, "file_name": "402_03.png", "page": 6, "dpi": 300, "bbox": [431, 764, 729, 961], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Orientation vs. mean orientation error by glyph type. Error bars for all charts are one standard error. ", "caption_bbox": [428, 973, 729, 1001]}, {"image_id": 4, "file_name": "402_04.png", "page": 7, "dpi": 300, "bbox": [431, 779, 729, 976], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Orientation vs. mean total error by glyph type.", "caption_bbox": [435, 988, 721, 1001]}, {"image_id": 5, "file_name": "402_05.png", "page": 7, "dpi": 300, "bbox": [412, 132, 732, 355], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Orientation vs. mean biaxial error by glyph type.", "caption_bbox": [430, 367, 727, 380]}, {"image_id": 6, "file_name": "402_06.png", "page": 7, "dpi": 300, "bbox": [97, 133, 415, 355], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 4: Descriptive statistics and post-hoc significance of marginal means for total error; significant differences high- lighted (\u03b1 = 0.05). Adjustments for multiple comparison made using the Bonferroni correction. ", "caption_bbox": [428, 496, 729, 555]}, {"image_id": 7, "file_name": "402_07.png", "page": 9, "dpi": 300, "bbox": [97, 133, 415, 549], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Plot of total error vs. response time with linear fit, first experiment (top) and second experiment (bottom). ", "caption_bbox": [96, 563, 397, 591]}], "403": [{"image_id": 0, "file_name": "403_00.png", "page": 2, "dpi": 300, "bbox": [96, 132, 413, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An example of three angle-angle plots. These plots show the relation between elevation of the arm (abduction) and other angles of three joints of nine subjects. Image cour- tesy of Frans Steenbrink. ", "caption_bbox": [96, 305, 397, 364]}, {"image_id": 1, "file_name": "403_01.png", "page": 3, "dpi": 300, "bbox": [428, 161, 727, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visualisation concepts that were presented to the participants of the questionnaire. Participants were asked to rate several aspects with regards to clarity and usefulness before and after an explanation was given. See Section 3.1 for a description of the subfigures. ", "caption_bbox": [428, 371, 729, 445]}, {"image_id": 2, "file_name": "403_02.png", "page": 4, "dpi": 300, "bbox": [96, 132, 413, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The FobVis motion tracking software. Sensors are attached to the skin and depicted by red spheres. Subse- quently, bony landmarks are registered relative to these sen- sors and depicted by yellow spheres. The surface models are rigidly transformed in accordance with the sensors and their respective bony landmarks. ", "caption_bbox": [96, 403, 397, 492]}, {"image_id": 3, "file_name": "403_03.png", "page": 5, "dpi": 300, "bbox": [104, 164, 393, 492], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Kinematic model as used within our system. The chain of rotations along various axes begins at the spine and terminates at the hand. The character g refers to the global coordinate system; t, c, s, h and f refer to the tho- rax, clavicle, scapula, humerus and forearm coordinate sys- tem respectively. The model is completely described in Wu et al. [WvV\u2217 05]. ", "caption_bbox": [96, 505, 397, 610]}, {"image_id": 4, "file_name": "403_04.png", "page": 6, "dpi": 300, "bbox": [442, 617, 716, 790], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Spline curve visualisation. This visualisation can be used to inspect a time window around a specific pose. An advantage of this visualisation method is that it shows how a subject reached for a specific area. ", "caption_bbox": [428, 800, 729, 859]}, {"image_id": 5, "file_name": "403_05.png", "page": 6, "dpi": 300, "bbox": [96, 132, 700, 511], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A screenshot of the system. The DOF View visualises the individual DOFs of the different joints on demand. The Pose View shows the recorded poses and thus visualises the functional range of motion. The parallel coodinates plot visualises the interrelationships between DOFs. At the bottom of the interface 2D plots of data values over time can be added. Lastly, a number of scatter plots can be in visualised in a separate frame. ", "caption_bbox": [96, 522, 729, 581]}, {"image_id": 6, "file_name": "403_06.png", "page": 6, "dpi": 300, "bbox": [110, 617, 384, 790], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The DOF View. Initially this 3D view only displays the silhouette of a human torso with a schematic represen- tation of the predefined connected joints. By selecting joints the user can add visual representations of the range of mo- tion of the DOFs as defined by the applied kinematic model. For each of these DOFs a joint widget is added that includes a blue and a yellow bar representing the range of motion of two different datasets. The orange pie-shaped parts are DOF filters, used to display only a part of the data in the linked views. To prevent clutter joint widgets can be collapsed by selecting their centerpoint. ", "caption_bbox": [96, 800, 397, 965]}, {"image_id": 7, "file_name": "403_07.png", "page": 7, "dpi": 300, "bbox": [427, 157, 731, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The Pose View filter. The hand can be dragged to a position in space. This position is then used for an inverse query to determine how a subject reached for that position. Note that the subject of the yellow dataset reached for the point in a different manner compared to the subject of the blue dataset. Also notice that the blue lines of the upper arm are showing a larger amplitude, indicating that the axial ro- tation of the upper arm of this subject had a greater magni- tude. ", "caption_bbox": [428, 360, 729, 495]}, {"image_id": 8, "file_name": "403_08.png", "page": 7, "dpi": 300, "bbox": [111, 159, 384, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Axial rotation visualisation. (a) Segments that consist of a single line, for example the upper arm, have ax- ial rotation that is not visible using the standard line draw- ing. (b, c) Optionally these segments can be replaced by corkscrew lines, spiraling inward or outward depending on the sign and magnitude of the axial rotation. See Figure 9 for an example of this visualisation. ", "caption_bbox": [96, 322, 397, 427]}, {"image_id": 9, "file_name": "403_09.png", "page": 8, "dpi": 300, "bbox": [427, 439, 731, 591], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Approach to answering the research questions, further explained in Section 4. ", "caption_bbox": [428, 602, 729, 630]}, {"image_id": 10, "file_name": "403_10.png", "page": 8, "dpi": 300, "bbox": [96, 132, 700, 364], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Parallel coordinates plot for two sets of motion recordings. The plotted parameters can be customised. Below the parallel coordinates plot are two 2D plots of a specific parameter, in this case global elevation, over time for each dataset. ", "caption_bbox": [96, 374, 729, 402]}, {"image_id": 11, "file_name": "403_11.png", "page": 9, "dpi": 300, "bbox": [95, 158, 399, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Parallel coordinates plot of the mirrored for- merly fractured shoulder (yellow) and the healthy shoulder (blue). The top subfigure shows the complete collection of splines, each one representing a recorded pose. The remain- ing subfigures show the same plot with different DOF filters for the global elevation parameter. The filters are visible on the left of the image. Notice the different values of scapula protraction and tilt at different global elevation angles, in- dicating that the scapula hardly compensates for the loss of humeral range of motion. ", "caption_bbox": [96, 364, 397, 514]}], "404": [{"image_id": 0, "file_name": "404_00.png", "page": 3, "dpi": 300, "bbox": [436, 438, 741, 505], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Synthetic example. a) piecewise constant image, b) blurred with a Gaussian kernel, c) Gaussian noise added, d) two-suspicious regions added. ", "caption_bbox": [428, 515, 729, 559]}, {"image_id": 1, "file_name": "404_01.png", "page": 3, "dpi": 300, "bbox": [98, 169, 724, 386], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: ProbExplorer consists of three main steps: preprocessing, voxel selection, and highlighting and editing.", "caption_bbox": [127, 396, 696, 409]}, {"image_id": 2, "file_name": "404_02.png", "page": 3, "dpi": 300, "bbox": [444, 747, 718, 871], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Mixture of Gaussians used to segment the image in Fig. 2(d). a) unnormalized mixture of Gaussians, b) nor- malized mixture of Gaussians. The magenta and orange bars represent the intensity values of the two small suspicious, tumor-like regions. ", "caption_bbox": [428, 884, 729, 958]}, {"image_id": 3, "file_name": "404_03.png", "page": 4, "dpi": 300, "bbox": [96, 132, 415, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Segmentation of synthetic example. a) ground truth segmentation, b) crisp segmentation result showing dif- ferent misclassification artifacts as well as inability to high- light the suspicious regions. ", "caption_bbox": [96, 261, 397, 320]}, {"image_id": 4, "file_name": "404_04.png", "page": 5, "dpi": 300, "bbox": [147, 160, 341, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Interaction overview widget. a) ROI selection de- marcated by a red border, b) interaction overview widget. Each node represents a specific class with size proportional to the number of voxels in that class in the image. The edges represent the connectivity between classes. ", "caption_bbox": [96, 265, 397, 339]}, {"image_id": 5, "file_name": "404_05.png", "page": 5, "dpi": 300, "bbox": [442, 204, 715, 399], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The uncertainty interaction overview widget rep- resents different tissue interactions with their summary statistics extracted from the probabilistic information. Each row represents a specific interaction. a) 1-way (unary) inter- action where blue marks FBG, b) 2-way interaction where red marks FBG and green marks SBG, c) 3-way interaction where green marks FBG, black marks SBG and red marks TBG, d) row filtering using a specific tissue interaction (1- way, 2-way, and 3-way), e) row filtering using a specific class, f) summary statistics, such as number of voxels in that interaction, mean maxP, mean M, and mean M23 . ", "caption_bbox": [428, 413, 729, 580]}, {"image_id": 6, "file_name": "404_06.png", "page": 6, "dpi": 300, "bbox": [431, 352, 728, 566], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Suspicious region highlighting. a) ROI over the upper left quarter, b) normalized distance transform map with respect to the green material, c) thresholding the dis- tance transform map to obtain the core of the organ, d) 2D log normalized histogram of maxP vs M representing the normalized number of voxels with a colormap, e) selection in magenta, f) suspicious region pops out in magenta. ", "caption_bbox": [428, 579, 729, 684]}, {"image_id": 7, "file_name": "404_07.png", "page": 6, "dpi": 300, "bbox": [96, 132, 415, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Uncertainty interaction overview filtering and sorting for the ROI shown in Fig. 5(a). a) uncertainty inter- action overview showing only two-way interactions for the red material, b) sorting all one-way interactions in an as- cending order by the mean maxP (fifth column). ", "caption_bbox": [96, 346, 397, 420]}, {"image_id": 8, "file_name": "404_08.png", "page": 6, "dpi": 300, "bbox": [412, 133, 678, 282], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: MaxP vs. M model. The green cross on the top right represents the one-way interaction. The blue line rep- resents the two-way interaction. The red line represent the three-way interaction for a constant third best guess. ", "caption_bbox": [428, 292, 729, 351]}, {"image_id": 9, "file_name": "404_09.png", "page": 7, "dpi": 300, "bbox": [433, 585, 725, 810], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Uncertainty-based segmentation editing. a) ROI over the lower half, b) selecting the implausible regions, c) source class set (SCS) on the left and destination class set (DCS) on the right with push action, d) changing the editing threshold \u03b4, e) \u03b4 = 0.7, f) \u03b4 = 1.0. ", "caption_bbox": [428, 823, 729, 898]}, {"image_id": 10, "file_name": "404_10.png", "page": 7, "dpi": 300, "bbox": [412, 132, 732, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Suspicious region highlighting. a) ROI selected, b) normalized distance transform map with respect to the blue material, c) thresholding the distance transform map to obtain the core of the organ, d) 2D log normalized his- togram between maxP vs. grey-level representing the nor- malized number of voxels with a colormap, e) selection in orange, f) suspicious region pops out in orange. ", "caption_bbox": [428, 372, 729, 477]}, {"image_id": 11, "file_name": "404_11.png", "page": 8, "dpi": 300, "bbox": [101, 408, 393, 588], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Dynamic SPECT case study with abnormal re- nal behavior in the lower third of the left kidney. a) 2D coro- nal slice out of the 4D dataset, b) uncertainty interaction overview widget, c) ROI over the left kidney, d) voxels that are labeled left kidney and SBG is right kidney that corre- spond to row 2, e) voxels that are labeled left kidney and SBG is abdomen that correspond to row 3. ", "caption_bbox": [96, 601, 397, 706]}, {"image_id": 12, "file_name": "404_12.png", "page": 9, "dpi": 300, "bbox": [436, 159, 723, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Simulated brain MRI data from the brainweb database multiple sclerosis lesion. a) maxP vs. M of the white matter, b) white matter highlighted in a 2D slice, c) a 3D image of the white matter, d) selecting the outlier pat- tern from the main two-way interaction line, e) a 2D slice of the white matter with the lesion highlighted in green, f) a 3D image of the white matter with the lesion highlighted. ", "caption_bbox": [428, 396, 729, 501]}, {"image_id": 13, "file_name": "404_13.png", "page": 9, "dpi": 300, "bbox": [108, 613, 386, 915], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Dynamic PET case study with over-segmented putamen showing the efficiency of segmentation editing. a) 2D axial slice of the 4D dataset, b) a 3D image, c) over- segmented putamen, d) uncertainty interaction overview widget, e) voxels that have white matter as SBG, f) classi- fication after two editing iterations. ", "caption_bbox": [96, 928, 397, 1017]}, {"image_id": 14, "file_name": "404_14.png", "page": 9, "dpi": 300, "bbox": [103, 157, 392, 510], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: PET study showing a cervical tumor. a) ROI around the neck area, b) two-way interaction overview, c) voxels labeled inactive that have SBG active, d) M vs maxP, e) grey-level vs. maxP, f) selection, g) zoomed-in version of the outer shell of the tumor, h) selection, i) zoomed-in ver- sion of the inner core of the tumor. ", "caption_bbox": [96, 523, 397, 612]}], "405": [{"image_id": 0, "file_name": "405_00.png", "page": 7, "dpi": 300, "bbox": [412, 132, 732, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Keystates in an application. The horizontal list at the bottom contains all keystates. Keystates can be loaded from older datasets or created new automatically (red framed) and manually (green border). Keystates can be dragged in the storyboard and arbitrary arranged. If a ro- tation around one keystate must be performed this can be activated by a double click. ", "caption_bbox": [428, 356, 729, 461]}, {"image_id": 1, "file_name": "405_01.png", "page": 8, "dpi": 300, "bbox": [412, 133, 731, 461], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Animated transition between a 3D scene and a 2D slice view. The slice is blended in the 3D scene, the cam- era is moved above the slice and the 3D structures are cross- faded into 2D overlays. ", "caption_bbox": [428, 472, 729, 531]}, {"image_id": 2, "file_name": "405_02.png", "page": 9, "dpi": 300, "bbox": [111, 133, 415, 788], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Example for reusing keystates for liver surgery planning. Each column represents a dataset. For some keystates, multiple instances were created and some keystates were omitted, since the addressed structure of in- terest (the resection proposal) did not exist in \u2019Case 3\u2019. ", "caption_bbox": [96, 798, 397, 872]}], "406": [{"image_id": 0, "file_name": "406_00.png", "page": 3, "dpi": 300, "bbox": [428, 769, 731, 859], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The goal of radio frequency ablation: destruction of all tumor cells. Assessment: evaluation of ablation result. ", "caption_bbox": [428, 870, 729, 898]}, {"image_id": 1, "file_name": "406_01.png", "page": 4, "dpi": 300, "bbox": [412, 134, 731, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visualization of the ablation zones in 2D, (a) with the pre-interventinal image and (b) the registered post- interventional image. ", "caption_bbox": [428, 341, 729, 384]}, {"image_id": 2, "file_name": "406_02.png", "page": 4, "dpi": 300, "bbox": [103, 484, 395, 596], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The color scheme of the coagulation zones. Red: not ablated tumor tissue, yellow: tissue outside of margin, green: tissue inside of margin. ", "caption_bbox": [96, 611, 397, 654]}, {"image_id": 3, "file_name": "406_03.png", "page": 5, "dpi": 300, "bbox": [95, 134, 415, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The volume rendering of the ROI. Anatomical structures such as vessels and spinal cord are clearly vis- ible but do not occlude the tumor with color scheme and coagulation. ", "caption_bbox": [96, 395, 397, 454]}, {"image_id": 4, "file_name": "406_04.png", "page": 5, "dpi": 300, "bbox": [429, 339, 729, 456], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The used longitude\u2013latitude cylindrical mapping.", "caption_bbox": [429, 469, 728, 482]}, {"image_id": 5, "file_name": "406_05.png", "page": 6, "dpi": 300, "bbox": [428, 552, 731, 644], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The sinusoidal projection (a) and the Mollweide projection (b) with color-coded texture coordinates (x = red channel, y = green channel). ", "caption_bbox": [428, 657, 729, 700]}, {"image_id": 6, "file_name": "406_06.png", "page": 6, "dpi": 300, "bbox": [95, 573, 399, 665], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The distortion in the map increases in vertical direction (a). After compensation for the distortions, the checker board is regularly spaced (b). ", "caption_bbox": [96, 679, 397, 722]}, {"image_id": 7, "file_name": "406_07.png", "page": 6, "dpi": 300, "bbox": [96, 132, 415, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Illustration of the rendering of the rectangular map. The values dcoagulation and dcenter are stored in the map. ", "caption_bbox": [96, 312, 397, 355]}, {"image_id": 8, "file_name": "406_08.png", "page": 7, "dpi": 300, "bbox": [96, 132, 732, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The images above show the corresponding tumor maps of the volume rendering in figure 4. The equirectangular longitude\u2013latitude mapping layout with high horizontal distortions at the poles (a). The tumor map with sinusoidal mapping layout (b) is equal-area, as is the Mollweide projection (c). ", "caption_bbox": [96, 298, 729, 341]}, {"image_id": 9, "file_name": "406_09.png", "page": 8, "dpi": 300, "bbox": [436, 395, 724, 530], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Boxplot (a) shows significantly lower times and variance with expressive features and no significant differ- ences without features (b). ", "caption_bbox": [428, 544, 729, 587]}, {"image_id": 10, "file_name": "406_10.png", "page": 9, "dpi": 300, "bbox": [95, 132, 731, 414], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Integrated tumor map and visualization of tumor and coagulation with color scheme in our clinical software assis- tant. Case (a) with necrosis at the liver\u2019s capsule (Mollweide projection), case (b) with successfully ablated tumor (equirectan- gular projection). The plot above the tumor map displays relative distances from tumor to coagulation stored in the map. ", "caption_bbox": [96, 427, 729, 470]}], "407": [{"image_id": 0, "file_name": "407_00.png", "page": 3, "dpi": 300, "bbox": [430, 483, 727, 542], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Sample image and corresponding sequences L, R, S obtained with a Hilbert scan. ", "caption_bbox": [428, 552, 729, 580]}, {"image_id": 1, "file_name": "407_01.png", "page": 4, "dpi": 300, "bbox": [96, 132, 415, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Partition of L into uniform blocks defining a non- uniform partition on its compressed version S. ", "caption_bbox": [96, 245, 397, 273]}, {"image_id": 2, "file_name": "407_02.png", "page": 4, "dpi": 300, "bbox": [412, 134, 732, 555], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Impact of the block size on (a) final compression ratio and (b) average number of texture lookups required to decode a texel. Test images are shown in Figure 4. ", "caption_bbox": [428, 568, 729, 611]}, {"image_id": 3, "file_name": "407_03.png", "page": 6, "dpi": 300, "bbox": [427, 563, 731, 688], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparison with alternative compressed for- mats: (a) our lossless compression, i.e. identical to the in- put image; (b) our quasi-lossless compression; (c) DTX1 fast compression; (d) DXT1 high quality; (e) DXT1 highest qual- ity; (f) ETC. Images differences have been amplified 10\u00d7. ", "caption_bbox": [428, 701, 729, 775]}, {"image_id": 4, "file_name": "407_04.png", "page": 6, "dpi": 300, "bbox": [112, 764, 382, 856], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Close-up views showing the ability of our scheme to perform adaptive compression. Input image (left), detail (middle), and color-coded runs (right). ", "caption_bbox": [96, 866, 397, 909]}, {"image_id": 5, "file_name": "407_05.png", "page": 6, "dpi": 300, "bbox": [435, 391, 728, 490], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Relative frequencies of run-lengths (left) and per- centage of input texels per run (right) for image 1. ", "caption_bbox": [428, 505, 729, 533]}, {"image_id": 6, "file_name": "407_06.png", "page": 7, "dpi": 300, "bbox": [131, 132, 732, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 4: Compression performance", "caption_bbox": [488, 482, 668, 495]}, {"image_id": 7, "file_name": "407_07.png", "page": 8, "dpi": 300, "bbox": [438, 785, 720, 857], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: We apply bilinear filtering only to highly-detailed regions (shown in black). Homogeneous regions (with at least L=16, 8 and 4 texels, respectively) can be recon- structed without additional texture accesses. ", "caption_bbox": [428, 868, 729, 927]}, {"image_id": 8, "file_name": "407_08.png", "page": 8, "dpi": 300, "bbox": [96, 132, 415, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 5: Quadtree subdivision vs our approach. Column pixels shows the average number of pixels per leaf node (quadtrees) or texel run (our approach). TL is the average number of texture lookups required to decode a single texel. ", "caption_bbox": [96, 449, 397, 508]}, {"image_id": 9, "file_name": "407_09.png", "page": 9, "dpi": 300, "bbox": [451, 262, 708, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Interpolation using nearest-neighbor (a,d), bi- linear filtering (b), and our modified bilinear filtering (c,e). ", "caption_bbox": [428, 335, 729, 363]}, {"image_id": 10, "file_name": "407_10.png", "page": 9, "dpi": 300, "bbox": [412, 132, 731, 208], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Bilinear interpolation inside a texel quadrant.", "caption_bbox": [431, 220, 723, 233]}], "408": [{"image_id": 0, "file_name": "408_00.png", "page": 3, "dpi": 300, "bbox": [155, 134, 415, 312], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Executives are classified based on their updating scope and policy (a) a centralized push model handling (b) a centralized pull model handling (c) a distributed push model handling a data request (d) a distributed pull model ", "caption_bbox": [96, 325, 397, 384]}, {"image_id": 1, "file_name": "408_01.png", "page": 4, "dpi": 300, "bbox": [412, 134, 701, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An overview of our system architecture", "caption_bbox": [454, 284, 702, 297]}, {"image_id": 2, "file_name": "408_02.png", "page": 5, "dpi": 300, "bbox": [155, 134, 415, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Streaming priority assignments by our scheduler", "caption_bbox": [98, 289, 394, 302]}, {"image_id": 3, "file_name": "408_03.png", "page": 7, "dpi": 300, "bbox": [95, 134, 415, 811], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The Gaussian smooth pipeline and its perfor- mance analysis (a) VTK pipeline without streaming; (b) the same pipeline with streaming (c) our streaming pipeline; (d) CPU usage 1-8 threads; (e) Strong scaling (f) Efficiency ", "caption_bbox": [96, 822, 397, 881]}, {"image_id": 4, "file_name": "408_04.png", "page": 8, "dpi": 300, "bbox": [412, 134, 731, 632], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Two ViSUS pipelines performing: (a) the 12- Month Average, (b) Multi-View selective rendering and (c) the scalability plot of their performances. ", "caption_bbox": [428, 646, 729, 689]}, {"image_id": 5, "file_name": "408_05.png", "page": 9, "dpi": 300, "bbox": [95, 134, 415, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 4: Simplifiation time for achieving 10% resolution", "caption_bbox": [436, 253, 720, 266]}], "409": [{"image_id": 0, "file_name": "409_00.png", "page": 2, "dpi": 300, "bbox": [95, 156, 399, 453], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Top: This shows our 8 projector (2 \u00d7 4 array) cylindrical display setup. The camera used to register the display is also shown in the image. Bottom: The same display registered using 7 camera views. Please zoom in to see the registration quality. ", "caption_bbox": [96, 458, 397, 512]}, {"image_id": 1, "file_name": "409_01.png", "page": 3, "dpi": 300, "bbox": [429, 156, 728, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: This shows the images taken from one of the multiple camera views for one of the projectors (all except the top one). We use 20 blobs per projector and hence we need 6 frames to detect the binary coded IDs of the blobs. We have similar images for all projectors that fall within the FOV of this camera view. In addition, we take one picture of the screen with no projectors turned on (top). ", "caption_bbox": [428, 363, 729, 445]}, {"image_id": 2, "file_name": "409_02.png", "page": 3, "dpi": 300, "bbox": [97, 158, 396, 410], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: This figure illustrates the 3D coordinates of a cylindrical display with aspect ratio \u03b1 and two camera views Vi and V j . The top and bottom 3D curves lie on the Y = 0 and Y = 1 planes respectively. The 3D coordinates of the four corners of the display are (\u2212 \u03b12 , 1, 0), ( \u03b12 , 1, 0), ( \u03b12 , 0, 0), and (\u2212 \u03b12 , 0, 0) (clockwise from top left). The blue and purple points on the image plane of Vi and V j are the sampled 2D points on the top boundary. These are back projected to give the cyan and gray 3D points. These are then translated by (0, -1, 0) to give the orange and lime points respectively. These are then reprojected to give the red and green points respectively. ", "caption_bbox": [96, 413, 397, 550]}, {"image_id": 3, "file_name": "409_03.png", "page": 5, "dpi": 300, "bbox": [120, 158, 369, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: This figure illustrates the constraint used to recover the focal length and hence the intrinsic parameter matrix of the camera. ", "caption_bbox": [96, 332, 397, 359]}, {"image_id": 4, "file_name": "409_04.png", "page": 5, "dpi": 300, "bbox": [451, 161, 700, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: This figure illustrates the recovery of Ri . Each camera view Vi is a node of the graph. A non-null Si, j forms an edge shown by black dashed lines. Each edge is associated with a weight wi j . To find Ri relating any Vi to the reference camera V1 , we find the single source shortest path from V1 shown by the red lines. Concatenation of the Ri j s on the path from V1 to Vi in this graph provides Ri . ", "caption_bbox": [428, 297, 729, 380]}, {"image_id": 5, "file_name": "409_05.png", "page": 6, "dpi": 300, "bbox": [109, 156, 715, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Top: Our registered 8 projector display registered using 7 camera views (left) and 3 camera views (right). For the right one, we only registered the images geometrically intentionally leaving out the final color calibration step to show the presence of eight projectors. Note the content is very testing for geometric registration since it has text and fine line illustrations. Please zoom in to see the registration quality. ", "caption_bbox": [96, 280, 729, 321]}, {"image_id": 6, "file_name": "409_06.png", "page": 7, "dpi": 300, "bbox": [96, 159, 396, 473], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Here we show that the quality of our multi-view registra- tion (top) is comparable with the quality of registration achieved by a single camera view presented in [SM09] (second). We also show that we do not compromise the accuracy of our multi-view regis- tration when using a low-resolution webcam (third), as opposed to a high-resolution SLR camera (top). Finally, we show the quality of our registration in the presence of severe non-linear distortion (bottom). In this image, we do not apply color calibration to show the distortions, evident from the curved projector boundaries. The zoomed in view on the right shows the quality of registration in four and two projector overlap area. Please zoom in to see the details. ", "caption_bbox": [96, 484, 397, 635]}, {"image_id": 7, "file_name": "409_07.png", "page": 7, "dpi": 300, "bbox": [447, 160, 711, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Here we show the reconstructed camera views for the two multi-view registrations shown in Figure 6 - the seven views and the three views used for registering the left and right images in Figure 6 respectively. We also show the corresponding graphs and the spanning tree used to find the camera pose and orientations. ", "caption_bbox": [428, 396, 729, 464]}, {"image_id": 8, "file_name": "409_08.png", "page": 8, "dpi": 300, "bbox": [110, 156, 384, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: This shows the applicability of our method when han- dling multiple cameras (instead of multiple views from same cam- era). The display on top is registered using three translated camera views with known focal length for the camera. The recovered camera pose and orientation along with the graph are shown in the bottom. Please zoom in to check the quality of the registration. ", "caption_bbox": [96, 396, 397, 478]}], "410": [{"image_id": 0, "file_name": "410_00.png", "page": 2, "dpi": 300, "bbox": [96, 132, 709, 478], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example frames extracted six typical snooker skill training videos. (a-d) represent different actions that are inter- esting to snooker coaches. (e-f) represent two video sequences showing different spin avoidance actions (both available as supplementary materials). ", "caption_bbox": [96, 486, 729, 530]}, {"image_id": 1, "file_name": "410_01.png", "page": 4, "dpi": 300, "bbox": [95, 132, 731, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The basic steps of the video processing pipeline.", "caption_bbox": [264, 311, 558, 324]}, {"image_id": 2, "file_name": "410_02.png", "page": 5, "dpi": 300, "bbox": [95, 740, 398, 862], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visualizing non-spatial attributes. The radius of the yellow tube-like object shows the temporally varying ra- tio of white pixels on the black-white cue ball. ", "caption_bbox": [96, 870, 397, 914]}, {"image_id": 3, "file_name": "410_03.png", "page": 5, "dpi": 300, "bbox": [95, 159, 398, 692], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visualizing four different types of spatial at- tributes. ", "caption_bbox": [96, 707, 397, 735]}, {"image_id": 4, "file_name": "410_04.png", "page": 7, "dpi": 300, "bbox": [95, 159, 399, 446], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A VPG that combines object silhouette volume and trajectories of color segments. ", "caption_bbox": [96, 454, 397, 482]}, {"image_id": 5, "file_name": "410_05.png", "page": 8, "dpi": 300, "bbox": [96, 132, 246, 1012], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A multi-strand", "caption_bbox": [246, 158, 259, 285]}], "411": [{"image_id": 0, "file_name": "411_00.png", "page": 4, "dpi": 300, "bbox": [96, 132, 654, 559], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Pathline, an interactive tool for the visualization of comparative functional genomics data. The left side shows the linearized pathways, whereas the right side shows the curvemap. Here, four different pathways are shown. This image, as well as all other images in this paper, can be found online at http://www.pathline.org/. ", "caption_bbox": [96, 558, 729, 601]}, {"image_id": 1, "file_name": "411_01.png", "page": 5, "dpi": 300, "bbox": [412, 132, 732, 370], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Linearizing a pathway. (a) The node-link repre- sentation of the directed graph includes both a branch and cycle. (b) Loops are unrolled and branches are disconnected. (c) Branches are reinserted just above their reconnection points. (d) The pathway is represented as a grey segment, with genes encoded spatially with points and metabolites as lines. Short breaks in the pathway segment indicate branch points, along with stylized marks to the left of the blocks. Cy- cle start points are also shown to the left with another mark. ", "caption_bbox": [428, 371, 729, 506]}, {"image_id": 2, "file_name": "411_02.png", "page": 9, "dpi": 300, "bbox": [99, 134, 413, 641], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) The metabolites along the P1 and P2 path- ways show a general decline except for the outlier m19. (b) Using this curvemap view of the genes g5, g6, and g7 the biologists confirmed known trends and discovered unknown gene duplication in the s7 species. ", "caption_bbox": [96, 651, 397, 725]}], "412": [{"image_id": 0, "file_name": "412_00.png", "page": 2, "dpi": 300, "bbox": [96, 132, 700, 538], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: This is the overview of the entire system, including views for Microsoft Virtual Earth(center), Parallel Coordinates (top corners), Scatter Plots (middle left), Temporal Analysis (third row right), and the original data (bottom row). Per-Bridge Detail View(middle right). Several items are highlighted with colors. ", "caption_bbox": [96, 564, 729, 607]}, {"image_id": 1, "file_name": "412_01.png", "page": 5, "dpi": 300, "bbox": [427, 586, 731, 778], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The Small Multiples view with Squarified Treemap layout. Bridges are grouped by their main structure types. For each cell, the x axis represents different inspection cy- cles and the y axis represents the structural attribute values selected by the user. ", "caption_bbox": [428, 789, 729, 863]}, {"image_id": 2, "file_name": "412_02.png", "page": 5, "dpi": 300, "bbox": [96, 606, 399, 792], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The Detail View for Bridge (A) An interactive Bridge Schematic Diagram; (B) A Line graph for monitor- ing temporal changes for major bridge structures; (C) Image Analysis Results for cracks on pavements; (D) Inspection Imageries that suggests the structural damage of the sup- porting piles of this bridge. ", "caption_bbox": [96, 804, 397, 893]}, {"image_id": 3, "file_name": "412_03.png", "page": 6, "dpi": 300, "bbox": [427, 591, 731, 784], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (A) A significant downward temporal trending indicates an unusual pattern (B) Using PCView to com- pare different structural attributes (C) Examining a certain bridge on SPView, indicating this is the earliest constructed bridge in the database (D) The Geospatial view shows that this bridge is constructed on top of a river stream. ", "caption_bbox": [428, 795, 729, 884]}], "413": [{"image_id": 0, "file_name": "413_00.png", "page": 1, "dpi": 300, "bbox": [412, 374, 730, 850], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example of visualizing DTI fiber tracts in situ.", "caption_bbox": [435, 863, 720, 876]}, {"image_id": 1, "file_name": "413_01.png", "page": 3, "dpi": 300, "bbox": [95, 132, 731, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Hand-drawn pen-and-ink illustrations of the brain, from [HP60], \u00a9 1960 McGraw-Hill, used with permission.", "caption_bbox": [109, 331, 714, 344]}, {"image_id": 2, "file_name": "413_02.png", "page": 4, "dpi": 300, "bbox": [94, 132, 414, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Slice-based hatching using the GPU.", "caption_bbox": [126, 323, 364, 336]}, {"image_id": 3, "file_name": "413_03.png", "page": 4, "dpi": 300, "bbox": [412, 134, 730, 316], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Adaptation of the line density to the zoom level.", "caption_bbox": [432, 323, 722, 336]}, {"image_id": 4, "file_name": "413_04.png", "page": 4, "dpi": 300, "bbox": [426, 353, 730, 513], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Precise line control.", "caption_bbox": [500, 518, 654, 531]}, {"image_id": 5, "file_name": "413_05.png", "page": 5, "dpi": 300, "bbox": [94, 369, 398, 519], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Use of stippling to illustrate gray matter.", "caption_bbox": [117, 525, 373, 538]}, {"image_id": 6, "file_name": "413_06.png", "page": 5, "dpi": 300, "bbox": [94, 134, 415, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Use of ambient occlusion to control the hatching; SSAO image in (a) enhanced for illustration purposes. ", "caption_bbox": [95, 323, 398, 351]}, {"image_id": 7, "file_name": "413_07.png", "page": 6, "dpi": 300, "bbox": [94, 540, 398, 863], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Compositing of the individual parts.", "caption_bbox": [128, 869, 362, 882]}, {"image_id": 8, "file_name": "413_08.png", "page": 6, "dpi": 300, "bbox": [412, 134, 730, 657], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Composited illustration with halo. Notice that the fiber tracts are actually located inside the brain\u2019s sur- face, an effect that is better visible in animations or in the anaglyphic 3D image (b). ", "caption_bbox": [427, 663, 731, 722]}, {"image_id": 9, "file_name": "413_09.png", "page": 6, "dpi": 300, "bbox": [95, 132, 414, 498], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The data pipeline employed in our approach.", "caption_bbox": [106, 509, 384, 522]}, {"image_id": 10, "file_name": "413_10.png", "page": 7, "dpi": 300, "bbox": [94, 386, 398, 593], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Example visualization to show fibers in the con- text of the brain and skull using cutting planes and a halo. ", "caption_bbox": [95, 603, 399, 631]}, {"image_id": 11, "file_name": "413_11.png", "page": 7, "dpi": 300, "bbox": [412, 132, 732, 402], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Anaglyphic rendering of the illustration in Fig. 1 with two cutting planes and a slight halo around the fibers. ", "caption_bbox": [426, 413, 727, 441]}, {"image_id": 12, "file_name": "413_12.png", "page": 7, "dpi": 300, "bbox": [94, 134, 415, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: De-emphasis of the context to visually emphasize the fibers in the focus, depending on type of reproduction. ", "caption_bbox": [95, 339, 396, 367]}, {"image_id": 13, "file_name": "413_13.png", "page": 8, "dpi": 300, "bbox": [96, 132, 414, 411], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Measurements of rendering performance (in fps); 2D\u2014regular image, 3D\u2014anaglyphic image, AA\u2014with anti- aliasing, OH\u2014only hatching (i. e., no fibers, no stippling). ", "caption_bbox": [94, 507, 398, 550]}], "414": [{"image_id": 0, "file_name": "414_00.png", "page": 2, "dpi": 300, "bbox": [140, 402, 380, 586], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Hand drawn illustration from Wenger et al. [WKZL03] ", "caption_bbox": [96, 598, 397, 626]}, {"image_id": 1, "file_name": "414_01.png", "page": 2, "dpi": 300, "bbox": [96, 132, 415, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Results of hierarchical clustering where 49 clusters are rendered using color coding. ", "caption_bbox": [96, 365, 397, 393]}, {"image_id": 2, "file_name": "414_02.png", "page": 2, "dpi": 300, "bbox": [412, 134, 702, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: 49 illustrative clusters using the techniques pre- sented in this paper ", "caption_bbox": [428, 363, 729, 391]}, {"image_id": 3, "file_name": "414_03.png", "page": 3, "dpi": 300, "bbox": [103, 132, 731, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Examples of the components of our illustrative cluster visualization", "caption_bbox": [219, 333, 606, 346]}, {"image_id": 4, "file_name": "414_04.png", "page": 4, "dpi": 300, "bbox": [412, 134, 731, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The compound structuring element is shown at two different pixels (a). The corresponding silhouette pixel (light) and outline pixel (dark) (b). The result after full com- pound dilation (c). ", "caption_bbox": [428, 303, 729, 362]}, {"image_id": 5, "file_name": "414_05.png", "page": 4, "dpi": 300, "bbox": [102, 468, 398, 553], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Culling fibers using halos", "caption_bbox": [157, 558, 335, 571]}, {"image_id": 6, "file_name": "414_06.png", "page": 5, "dpi": 300, "bbox": [111, 134, 415, 437], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Compound dilation cases at pixel p showing the new color and depth for p where s = DS p <t D p (silhouette in front of p) and o = DO p <t D p (contour in front of p) ", "caption_bbox": [428, 230, 729, 274]}, {"image_id": 7, "file_name": "414_07.png", "page": 6, "dpi": 300, "bbox": [96, 132, 668, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: GPU implementation pipeline", "caption_bbox": [312, 369, 512, 382]}, {"image_id": 8, "file_name": "414_08.png", "page": 7, "dpi": 300, "bbox": [112, 419, 385, 528], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Basic idea behind our focus+context technique", "caption_bbox": [101, 533, 391, 546]}, {"image_id": 9, "file_name": "414_09.png", "page": 7, "dpi": 300, "bbox": [412, 132, 732, 356], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Construction of the displacement \u03b4a along direc- tion d based on the penetration depth pa along axis a. d is the direction from the center of OBBF to the center of OBBB . ", "caption_bbox": [428, 368, 729, 413]}, {"image_id": 10, "file_name": "414_10.png", "page": 7, "dpi": 300, "bbox": [117, 134, 415, 375], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Multiple illustrative fiber bundles", "caption_bbox": [138, 397, 355, 410]}, {"image_id": 11, "file_name": "414_11.png", "page": 9, "dpi": 300, "bbox": [98, 132, 731, 644], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Focus+context examples using different styles for context and focus, and showing the effect of the exploded views.", "caption_bbox": [97, 650, 726, 663]}], "415": [{"image_id": 0, "file_name": "415_00.png", "page": 2, "dpi": 300, "bbox": [96, 132, 726, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) Standard filament and surface visualization of three nerves in a bee brain. (b) The filaments are colored by their surrounding surfaces. Additionally, ring-shaped glyphs are placed at filament-surface intersections indicating, for example, registration errors. To improve the perception of which line lies in front of another, a halo effect is used. ", "caption_bbox": [96, 367, 729, 410]}, {"image_id": 1, "file_name": "415_01.png", "page": 3, "dpi": 300, "bbox": [99, 689, 394, 906], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Examples for visualization methods. (a) Filament- surface intersections are emphasized using green cylinders. (b) Filaments outside the surface are colored white; fila- ments inside are colored dark grey. (c) The filament seg- ments are colored according to their surrounding material. (d) Depth-dependent contrast enhancement (halo). ", "caption_bbox": [96, 919, 397, 1008]}, {"image_id": 2, "file_name": "415_02.png", "page": 5, "dpi": 300, "bbox": [99, 132, 732, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Example images from the first user study. Participants were asked to rate if (b), compared to (a), improves the recognition whether filaments lie behind or in front of each other. In (c) they were asked to rate to the quality of depth perception. ", "caption_bbox": [96, 337, 729, 365]}, {"image_id": 3, "file_name": "415_03.png", "page": 6, "dpi": 300, "bbox": [439, 376, 720, 714], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualization rating. Average rating for standard visualization (top) compared to average rating for a visual- ization using a combination of material coloring and halos (bottom). Bar colors represent question types from Figure 4. ", "caption_bbox": [428, 728, 729, 787]}, {"image_id": 4, "file_name": "415_04.png", "page": 6, "dpi": 300, "bbox": [96, 132, 700, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Overview of the exploratory study\u2019s rating and comparison tasks with visualization techniques in rows and question types in columns. Neglected technique-question combinations are grayed out. 0s represent no improvements over the standard. The + symbols are used to indicate enhancements when applying the technique. Each time a technique was preferred, the number of + is increased. For example, regarding object traversal, binary and material coloring performed better than the standard visualization (both receiving a +); in direct comparison, material was preferred over binary coloring (leading to ++). ", "caption_bbox": [96, 284, 729, 358]}, {"image_id": 5, "file_name": "415_05.png", "page": 8, "dpi": 300, "bbox": [427, 646, 728, 715], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Absolute mean rank differences between the stim- uli variations. A value above dcrit = 0.745 (highlighted in green) is statistically significant. ", "caption_bbox": [428, 725, 729, 768]}, {"image_id": 6, "file_name": "415_06.png", "page": 8, "dpi": 300, "bbox": [96, 132, 723, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Example stimuli. (a) Baseline visualization. (b) Intersection points of tube and volumetric structures are displayed using rings. (c) Tube coloring by surrounding material. (d) Combined intersection display and coloring by material. ", "caption_bbox": [96, 288, 729, 316]}, {"image_id": 7, "file_name": "415_07.png", "page": 9, "dpi": 300, "bbox": [100, 132, 731, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Number of correct responses and response times for all participants. (a) The diagram shows the absolute frequency of participants for the percentaged number of correct responses. (b) Average response times per participant ranged between 1.3 and 5.3 seconds. We show the absolute frequency of people having a certain average response time. (c) Average number of correct responses with 95% confidence intervals for each tested visualization technique. (d) Average response times together with their 95% confidence intervals for each tested visualization technique. ", "caption_bbox": [96, 339, 729, 413]}], "416": [{"image_id": 0, "file_name": "416_00.png", "page": 2, "dpi": 300, "bbox": [412, 134, 692, 447], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) The graph of a terrain f : IR2 \u2192 IR, (b) its contour tree and (c) its corresponding contours at critical points. The dark-shaded and light-shaded regions in (a) and (c) are the topological components for edges ac and cd, re- spectively. ", "caption_bbox": [428, 450, 729, 527]}, {"image_id": 1, "file_name": "416_01.png", "page": 3, "dpi": 300, "bbox": [161, 132, 731, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: In (a), v is either a lower-leaf (left, a local minimum) or upper-leaf (right, a local maximum). Its local config-type is minc or maxc, respectively. Note, the contours Ct , Cu and Cv adopt the nesting relationship as specified by the directed path from t to u to v. (b) An example of a merge-1 local config-type. The contour Cu corresponding to the saddle u has two components. (c) An example of a merge-2 local config-type where Cu has two components (loops) with one contained inside the other. The split-1 / 2 local config-types are similar to merge-1 / 2, but occur at tree nodes whose up-degree is two. ", "caption_bbox": [95, 366, 728, 440]}, {"image_id": 2, "file_name": "416_02.png", "page": 4, "dpi": 300, "bbox": [96, 132, 415, 475], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) A contour tree T . A directed tree induced by choosing z1 , z2 , or z3 as the root is shown in (b), (c), and (d), respectively, where z3 is an internal node. Edge directions indicate the inclusion relationships of the contours when em- bedded. The red thick path in (c) are edges whose directions are inverted as we change the root from z1 to z2 . ", "caption_bbox": [96, 488, 397, 577]}, {"image_id": 3, "file_name": "416_03.png", "page": 5, "dpi": 300, "bbox": [134, 134, 415, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Red dotted lines indicate the contour tree. (a) Set- ting u to be the point at infinity induces a merge-1 local config-type at v. (b) Setting w to be the point at infinity in- duces a merge-2 local config-type at v which resembles a volcano with edge (x, v) corresponding to its crater. ", "caption_bbox": [96, 299, 397, 373]}, {"image_id": 4, "file_name": "416_04.png", "page": 5, "dpi": 300, "bbox": [473, 323, 684, 529], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Schemes for generating the terrain layout. The re- gion between contours Cu and Cv equals to the volume of the topological component corresponding to edge euv . ", "caption_bbox": [428, 542, 729, 586]}, {"image_id": 5, "file_name": "416_05.png", "page": 7, "dpi": 300, "bbox": [109, 132, 732, 455], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Analysis of a 3D volumetric dataset. (a) A terrain visualization generated using the proposed algorithm. (b) Contour tree of the dataset. (c)\u2013(d) The outer boundary of the terrain corresponds to the large empty region around the combustion chamber. (e)\u2013(f) (g)\u2013(h) Structures on the generated terrain and their corresponding components in the volume. (i) Result of [WBP07] (image copied from [WBP07]). ", "caption_bbox": [96, 467, 729, 526]}, {"image_id": 6, "file_name": "416_06.png", "page": 8, "dpi": 300, "bbox": [449, 641, 709, 784], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: An energy landscape produced by PCA. (a) Ter- rain produced from Delaunay triangulation of first two prin- cipal components of high-dimensional protein conformation point cloud. (b) Closeup view of the landscape emphasizing the jagged distortion around the global minimum. ", "caption_bbox": [428, 797, 729, 871]}, {"image_id": 7, "file_name": "416_07.png", "page": 8, "dpi": 300, "bbox": [126, 362, 370, 490], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) Slice-and-dice and (b) Voronoi treemap lay- outs of terrains in Figure 6. ", "caption_bbox": [96, 503, 397, 531]}, {"image_id": 8, "file_name": "416_08.png", "page": 8, "dpi": 300, "bbox": [96, 132, 415, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) An alternative terrain model in which the com- ponent containing the global minimum is converted from an annulus to a convex interior region (dark gray region in cen- ter). (b) Embedded space of terrain configurations. ", "caption_bbox": [96, 295, 397, 354]}, {"image_id": 9, "file_name": "416_09.png", "page": 9, "dpi": 300, "bbox": [412, 132, 736, 835], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: (a) Space of terrain configurations for the protein dataset. (b)\u2013(c) Terrains generated from mapping the global minimum and maximum to the boundary, respectively. While (c) reveals a funnel structure around the lowest-energy con- formation, it neglects the global structure of the sampled conformational space. (d) Terrain providing the most faith- ful representation of the conformational space. (e) Result of [WBP07] which maps the global minimum to the bound- ary of the terrain, and is directly comparable to (b). (f) Side view of (d). (g) Side view of the terrain model generated us- ing PCA embedding of Figure 9. ", "caption_bbox": [428, 847, 729, 1012]}], "417": [{"image_id": 0, "file_name": "417_00.png", "page": 3, "dpi": 300, "bbox": [126, 132, 731, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The layout of HyperMoVal for a real model predicting torque given four parameters. The focal point F is set to a validation data point with a significant deviation. The matrix contains all paraxial 2D slices at F in the 5D model space. ", "caption_bbox": [96, 535, 729, 563]}, {"image_id": 1, "file_name": "417_01.png", "page": 4, "dpi": 300, "bbox": [412, 134, 731, 259], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Altering the relevance threshold t changes the shown subset of data points around the visualized slice. ", "caption_bbox": [428, 269, 729, 297]}, {"image_id": 2, "file_name": "417_02.png", "page": 4, "dpi": 300, "bbox": [96, 132, 415, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The region around two slices in which points are considered relevant for the respective plot. The color inten- sity depends on the distance to the slice. ", "caption_bbox": [96, 333, 397, 377]}, {"image_id": 3, "file_name": "417_03.png", "page": 4, "dpi": 300, "bbox": [97, 381, 398, 490], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Altering F in one dimension changes the func- tion graph and the relevance of data points for all plots not displayed in that dimension. Continuous modifications make the points fade in and out smoothly around the graph. ", "caption_bbox": [96, 499, 397, 558]}, {"image_id": 4, "file_name": "417_04.png", "page": 4, "dpi": 300, "bbox": [429, 304, 731, 488], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Varying the parameter \"Engine Speed\" generates a family of iso-contours and explicit function graphs. ", "caption_bbox": [428, 498, 729, 526]}, {"image_id": 5, "file_name": "417_05.png", "page": 5, "dpi": 300, "bbox": [412, 132, 732, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: 2D and 3D visualizations of the same surface plots. Due to the additional visual dimension, the set of rel- evant points is typically larger in 3D. ", "caption_bbox": [428, 436, 729, 480]}, {"image_id": 6, "file_name": "417_06.png", "page": 6, "dpi": 300, "bbox": [412, 134, 731, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Linked views of derived model attributes: (a) com- paring the deviations of different models by brushing large residuals; (b) mapping absolute deviations of one model to color in a 2D representation of the parameter space; (c) plotting residuals (Y-axis) against known results (X-axis). ", "caption_bbox": [428, 370, 729, 444]}, {"image_id": 7, "file_name": "417_07.png", "page": 6, "dpi": 300, "bbox": [96, 132, 415, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparison of two models predicting torque. The models are discriminated by the line style (dashed and solid) and show a very different prediction quality at F. \"Intake- Pressure\" is a parameter of Model 2 only. ", "caption_bbox": [96, 340, 397, 399]}, {"image_id": 8, "file_name": "417_08.png", "page": 8, "dpi": 300, "bbox": [96, 132, 731, 595], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: An exemplary workflow for model building. (a) Assessing a 2D model also reveals implausible validation data; (b + c) a 3D model still does not sufficiently cover a jump in torque for low values of speed; (d) ranking potential input parameters by means of correlation to the result; (e) quantifying multiple models with respect to their residuals (in Nm); (f) comparing residuals for two model candiates; (g) comparing the candidates with respect to the plausibility of extrapolations. ", "caption_bbox": [96, 601, 729, 660]}], "418": [{"image_id": 0, "file_name": "418_00.png", "page": 3, "dpi": 300, "bbox": [457, 155, 701, 406], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Prototype implementation of our multi-view ex- ploration approach, showing the shape space, object space and evolution views. Due to screen space constraints, the latter can be switched between the configurations shown in figure 4. Multiple evolution views can be added if preferred. ", "caption_bbox": [428, 417, 729, 491]}, {"image_id": 1, "file_name": "418_01.png", "page": 4, "dpi": 300, "bbox": [132, 180, 362, 316], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The shape space scatter plot view, visualizing a population of segmentations of the human scapula. Colors indicate the likelihood of each shape with respect to the Gaussian model, which itself is visualized by ellipses rep- resenting multiples of the standard deviation. ", "caption_bbox": [96, 345, 397, 419]}, {"image_id": 2, "file_name": "418_02.png", "page": 5, "dpi": 300, "bbox": [159, 168, 360, 323], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The object space 3D view, here showing per-point reconstruction errors for a brain ventricle shape using a color map. Blue indicates areas where the actual shape is larger than the reconstructed surface, yellow indicates simi- lar size and red indicates areas where it is smaller. ", "caption_bbox": [96, 345, 397, 419]}, {"image_id": 3, "file_name": "418_03.png", "page": 6, "dpi": 300, "bbox": [117, 158, 704, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The shape evolution view and its configurations, used to examine variation in the scapula and brain ventricle datasets. (a) Side-by-side display of a subset of the brain ventricle population, ordered by projection along the first principal component. (b) Overlaid contours for a side view of the scapula population, demonstrating that most variation occurs in the acromion and coracoid process. Ordering along the first principal component is visualized using a black-to-white scale. (c) Shape stack visualization of the shapes in (a), showing an increasing trend in the overall size of the shapes along the first eigenvector. ", "caption_bbox": [96, 317, 729, 391]}, {"image_id": 4, "file_name": "418_04.png", "page": 7, "dpi": 300, "bbox": [132, 159, 361, 366], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Rendering the Voronoi tessellation of a set of points (shown in yellow) using cones. When viewed from the top, standard depth-buffering ensures the pixels covered by a cone belong to the Voronoi area for the corresponding point. ", "caption_bbox": [96, 381, 397, 440]}, {"image_id": 5, "file_name": "418_05.png", "page": 7, "dpi": 300, "bbox": [460, 158, 699, 370], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Weights for natural neighbor interpolation are computed as the ratio between the area of the Voronoi cell corresponding to a given point if it were inserted into the tessellation (orange), and the overlap between this cell and each of the existing cells in the diagram (gray). ", "caption_bbox": [428, 381, 729, 455]}, {"image_id": 6, "file_name": "418_06.png", "page": 8, "dpi": 300, "bbox": [447, 165, 710, 331], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Inspecting compactness of the shape model by varying the number of axes. Shapes are colored by their reconstruction error, based on a reconstruction using the axes shown. When reducing the number of parameters of the model from 5 (top left) to 2 (bottom right), the number of shapes with high reconstruction errors (yellow) visibly in- creases. ", "caption_bbox": [428, 350, 729, 455]}, {"image_id": 7, "file_name": "418_07.png", "page": 8, "dpi": 300, "bbox": [114, 171, 380, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Outliers in the population can be highlighted in the shape space view, both by selecting an appropriate pro- jection and by coloring shapes according to their likelihood. High-valued shapes are yellow, low values are blue. ", "caption_bbox": [96, 364, 397, 423]}, {"image_id": 8, "file_name": "418_08.png", "page": 9, "dpi": 300, "bbox": [125, 155, 369, 370], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The evolution view can be used to explore trends on a local level. Here, reconstruction errors for the scapula dataset are explored on a local level and compared over the population by showing a shape stack highlighting errors above a user-defined threshold. ", "caption_bbox": [96, 380, 397, 454]}], "419": [{"image_id": 0, "file_name": "419_00.png", "page": 2, "dpi": 300, "bbox": [458, 684, 700, 751], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A quadtree using an underlying sparse matrix representation to fill in any \"holes\" (dotted red lines). ", "caption_bbox": [428, 762, 729, 790]}, {"image_id": 1, "file_name": "419_01.png", "page": 3, "dpi": 300, "bbox": [412, 132, 731, 407], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An example showing child, parent, and neighbor relationships. Binary indices are shown beneath select nodes to illustrate common ancestor computation between black and pink nodes. We first compute black\u2019s ancestor at the same level as pink - blue. We then examine the bits between blue and pink to discover that red is the common ancestor. ", "caption_bbox": [428, 420, 729, 509]}, {"image_id": 2, "file_name": "419_02.png", "page": 6, "dpi": 300, "bbox": [96, 132, 695, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Graphs of the equation in section 5.1 (sidx1 = 4). The left table shows when the nodes contain data, the right table is when they do not. If our matrix dimensions, n, and sparsity ratio, m/n, fall into the area below the line that matches the size parameters from the tables, we will save space using the sparse matrix representation. ", "caption_bbox": [96, 284, 729, 327]}, {"image_id": 3, "file_name": "419_03.png", "page": 7, "dpi": 300, "bbox": [412, 132, 732, 488], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: a) A quadtree with its underlying matrix types and vectors. b) When translating to the GPU, we concatenate the vectors from the CPU and create auxiliary helper vectors. ", "caption_bbox": [428, 515, 729, 558]}, {"image_id": 4, "file_name": "419_04.png", "page": 8, "dpi": 300, "bbox": [428, 741, 739, 937], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The geometry for the high speed train (left) and delta wing (right). A cut plane of the 3D cells is shown along with surface triangle sizes mapped to a logarithmic BGR color scheme (blue indicates smaller, red larger). ", "caption_bbox": [428, 943, 729, 1002]}, {"image_id": 5, "file_name": "419_05.png", "page": 8, "dpi": 300, "bbox": [96, 132, 726, 364], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The data elements are 4-byte floats to facilitate interpolation on the GPU. Size information for min/max values is not included. Tree properties are expressed in 100,000s of elements, data in MBs. Abbreviations: Non-leaf nodes (NLN), matrix based tree data structure overhead (MAT), pointer-based overhead (PTR). ", "caption_bbox": [96, 369, 729, 412]}, {"image_id": 6, "file_name": "419_06.png", "page": 8, "dpi": 300, "bbox": [99, 449, 396, 705], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Graphs showing ray cast render times.", "caption_bbox": [120, 717, 370, 730]}, {"image_id": 7, "file_name": "419_07.png", "page": 9, "dpi": 300, "bbox": [103, 132, 731, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Data is the average of 1,000,000 random point queries. Tree traversal times and total overall times (in \u00b5s) are shown.", "caption_bbox": [96, 245, 729, 258]}], "420": [{"image_id": 0, "file_name": "420_00.png", "page": 2, "dpi": 300, "bbox": [95, 132, 415, 387], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Data set D4 showing a laser ablation simulation with 48 million atoms. Using our two-level occlusion culling method, a common workstation can interactively render this data set with up to 12 FPS (given the whole data set is visible and no frustum culling is applied). ", "caption_bbox": [96, 397, 397, 471]}, {"image_id": 1, "file_name": "420_01.png", "page": 3, "dpi": 300, "bbox": [140, 134, 415, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Data set D1 obtained from a small laser ablation simulation (107,391 atoms). Although the number of atoms is small, a brute-force raycasting of the atoms as spheres re- sults in low performance (27 fps) due to the large number of depth replacements caused by the highly overlapping glyphs. ", "caption_bbox": [96, 376, 397, 450]}, {"image_id": 2, "file_name": "420_02.png", "page": 4, "dpi": 300, "bbox": [96, 132, 731, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The stages of our method: 1. initialization of the depth buffer with known occluders in Ot\u22121 , 2. start of occlusion queries for all grid cells by testing against the bounding boxes, 3. generation of maximum-depth mipmap, 4.1. collection of occlusion queries, updating of list Ot of visible cells, and rendering of remaining visible glyphs. Stages 1 and 4.1 can output raycast glyphs, or points if the glyphs become to small in image-space, 4.2. deferred shading: image-space calculation of normals and phong lighting. Note that the rendering in stage 1 initializes the depth buffer with a conservative depth splat for the maximum-depth mipmap, as well as for subsequent render passes. ", "caption_bbox": [96, 372, 729, 461]}, {"image_id": 3, "file_name": "420_03.png", "page": 4, "dpi": 300, "bbox": [428, 761, 731, 932], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Data set D2 is a molecular dynamics simulation of a crack propagation in solid media. Due to the crack, inner cells of the grid can become visible depending on the view point. ", "caption_bbox": [428, 943, 729, 1002]}, {"image_id": 4, "file_name": "420_04.png", "page": 5, "dpi": 300, "bbox": [95, 134, 415, 387], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A sparse data set obtained from a thermodynam- ics molecular dynamics simulation of a mixture of ethanol (C2 H6 O) and heptafluoropropane (C3 HF7 ). In such data sets there is almost no occlusion, hence our approach can only reduce small glyphs to points and provide frustum culling based on the grid structure. ", "caption_bbox": [96, 397, 397, 486]}, {"image_id": 5, "file_name": "420_05.png", "page": 6, "dpi": 300, "bbox": [95, 132, 731, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Comparison between standard and deferred shading (please zoom the electronic version). Left: standard, na\u00efve raycasting of spheres. Middle: 8 \u00d7 8 super-sampling of raycast spheres. Right: deferred shading with artificial normals. ", "caption_bbox": [96, 435, 729, 464]}, {"image_id": 6, "file_name": "420_06.png", "page": 7, "dpi": 300, "bbox": [415, 132, 732, 406], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The rendering performance results from Table 2 without any culling (no cull.), cell-level culling only (cell cull.), vertex-level culling only (vertex cull.), both culling techniques together (both cull.), and both culling techniques and the deferred shading pass (def. shad.). Both culling tech- niques together result in the best performance, while for pure point representations the share of the vertex-level culling is negligible. This is due to a change of the limiting bottleneck from rendering to data transfer. The overhead of the deferred shading pass is very small. Note that the bars of data set D1 are truncated (see Table 2 for the values) to keep the focus on the values of the larger and more interesting data sets. ", "caption_bbox": [428, 423, 729, 603]}], "421": [{"image_id": 0, "file_name": "421_00.png", "page": 2, "dpi": 300, "bbox": [412, 136, 731, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Surface definitions in 2D. Left: The fine continu- ous line is the vdW surface. The SAS is represented by the thick dashed line and the SES by the thick continuous line. Two positions of the probe (gray) are depicted. Right: MSS with mixed complex. ", "caption_bbox": [428, 395, 729, 469]}, {"image_id": 1, "file_name": "421_01.png", "page": 4, "dpi": 300, "bbox": [95, 134, 415, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: SAS and SES. Left: The complete contours of the SAS and the SES are depicted. Each contour arc represents a saddle (or toroidal) patch (yellow), and each vertex, the point where three arcs meet, creates a concave spherical patch (red). Right: Detailed view of the contour. The gray sphere shows a position of the sphere. ", "caption_bbox": [96, 332, 397, 421]}, {"image_id": 2, "file_name": "421_02.png", "page": 4, "dpi": 300, "bbox": [412, 136, 730, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Stepwise creation of the contour of the red atom. (a) Start contour (circle) created by the first neighboring atom. (b) The second circle splits the first circle, thereby cre- ating two arcs. (c) Both arcs are cut by the third circle, one at the end point and one at the starting point. (d) The fourth circle deletes some arcs and cuts the starting and end points of one arc. (e, f, g) Analogously to (c). (h) Complete contour of the red atom. ", "caption_bbox": [428, 303, 729, 423]}, {"image_id": 3, "file_name": "421_03.png", "page": 4, "dpi": 300, "bbox": [427, 430, 731, 553], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Flexible 3-dimensional grid for neighborhood search. Two examples are given for different atom positions of the same molecule. ", "caption_bbox": [428, 578, 729, 621]}, {"image_id": 4, "file_name": "421_04.png", "page": 6, "dpi": 300, "bbox": [95, 134, 415, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Ray casting of saddle patches. First, we compute the intersection point with the bounding cone. We use this point as starting point for sphere tracing. The distance to the surface determines the step size. ", "caption_bbox": [96, 342, 397, 401]}, {"image_id": 5, "file_name": "421_05.png", "page": 6, "dpi": 300, "bbox": [412, 136, 707, 395], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Computation of a tight planar object that includes a cylinder after rasterization (d). In (a) and (b), two pos- sibilities for the outer points of the cylinder are depicted. (c) displays how the outer points are used to span the object. ", "caption_bbox": [428, 403, 729, 462]}, {"image_id": 6, "file_name": "421_06.png", "page": 7, "dpi": 300, "bbox": [109, 136, 415, 416], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Update times in ms of the OpenMP versions with 1 and 8 cores. For the SES, we used the contour-buildup al- gorithm (CB) and for the MSS, the approximate Voronoi di- agram (AVD) algorithm. The last column shows the update times for the reduced surface (RS) given in [KBE09]. ", "caption_bbox": [428, 298, 729, 372]}, {"image_id": 7, "file_name": "421_07.png", "page": 8, "dpi": 300, "bbox": [95, 134, 730, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 4: Approximate speedups of SES and MSS compared to previous approaches, and speedup of SES over MSS. ", "caption_bbox": [428, 739, 729, 767]}, {"image_id": 8, "file_name": "421_08.png", "page": 9, "dpi": 300, "bbox": [145, 134, 729, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Visualization techniques. In the left image, the SES of molecule 1AON is rendered with depth-dependent lighting. The middle image shows the colored MSS (s = 0.3) of molecule 1X5V with surface silhouettes. In the right image, the SES of molecule 2JQC is blended with its ball-and-stick representation. ", "caption_bbox": [96, 327, 729, 370]}], "422": [{"image_id": 0, "file_name": "422_00.png", "page": 2, "dpi": 300, "bbox": [96, 132, 730, 438], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Comparison of the results produced by our recoloring technique and by Kuhn et al.\u2019s [KOF08a] for a set of scientific visualization images. The \"Dichromat\" column shows the simulated perception of dichromats for the corresponding \"Reference\" image obtained using the approach of Machado et al. [MOF09]. The simulation and recolorings of the Flame and Nebula images are for deuteranopes, while the Tornado ones are for protanopes. ", "caption_bbox": [96, 449, 729, 508]}, {"image_id": 1, "file_name": "422_01.png", "page": 4, "dpi": 300, "bbox": [96, 132, 415, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Planar approximation for the color gamut of dichromats in the CIE L\u2217 a\u2217 b\u2217 color space [KOF08a]. (a) Protanope (\u03b8 p = \u221211.48\u25e6 ). (b) Deuteranope (\u03b8d = \u22128.11\u25e6 ). (c) Tritanope (\u03b8t = 46.37\u25e6 ). ", "caption_bbox": [96, 258, 397, 318]}, {"image_id": 2, "file_name": "422_02.png", "page": 5, "dpi": 300, "bbox": [111, 132, 732, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The steps of our recoloring algorithm. (a) Colors c1 to c4 are perceived by a dichromat as c01 to c04 , respectively (their projections on the dichromat\u2019s gamut plane). The relative loss of contrast experienced by a dichromat for a pair of colors (ci , c j ) is given by l(ci ,c j ) = (kci \u2212 c j k \u2212 kc0i \u2212 c0j k)/(kci \u2212 c j k), which happens along the direction \u03d1i j = ci \u2212 c j . (b) Direction vab (shown in blue) that maximizes the loss of local contrast (in a least-square sense) is computed as the main eigenvector of the matrix M T M, where M is defined in Equation 3. (c) Projection of the original colors on the plane defined by vab and L\u2217 . (d) Final colors obtained after rotating the projected colors c00                              \u2217                                                                          k in (c) around L so that they align with the dichromat\u2019s plane. ", "caption_bbox": [96, 315, 729, 408]}, {"image_id": 3, "file_name": "422_03.png", "page": 6, "dpi": 300, "bbox": [96, 132, 729, 434], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparison of the results produced by our technique and by Kuhn et al.\u2019s. First row, from left to right: reference image, simulated perception of a deuteranope, and recolored images using various algorithms. Second row: Perceptual errors according to the DRIM metric. Third row: Local contrast differences according to the RMS metric of Equation 4 (for k = 100). According to both metrics, our recoloring technique is less prone to noticeable changes in contrast. ", "caption_bbox": [96, 449, 729, 508]}, {"image_id": 4, "file_name": "422_04.png", "page": 6, "dpi": 300, "bbox": [430, 597, 739, 731], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Recoloring of information visualization images for protanopes. ", "caption_bbox": [428, 751, 729, 779]}, {"image_id": 5, "file_name": "422_05.png", "page": 7, "dpi": 300, "bbox": [108, 132, 732, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Integration of our technique with an existing visualization application. (left) Reference image as perceived by an individual with normal color vision. (center) Simulation of the perception of a deuteranope for the reference image using the model of Machado et al. [MOF09]. (right) Recolored image for a deuteranope using our technique. ", "caption_bbox": [96, 323, 729, 366]}, {"image_id": 6, "file_name": "422_06.png", "page": 8, "dpi": 300, "bbox": [96, 132, 699, 279], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Times (in sec.) for the quantization and reconstruc- tion phases of the technique of Kuhn et al. [KOF08a] for sev- eral images. K-means used in the CPU version of the tech- nique, and uniform quantization used in its GPU version. The column Clusters shows the number of clusters identified in the quantization phase. ", "caption_bbox": [96, 783, 397, 872]}, {"image_id": 7, "file_name": "422_07.png", "page": 9, "dpi": 300, "bbox": [119, 132, 731, 794], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison of the results produced by our technique and the ones obtained with Kuhn et al.\u2019s approach for a set of medical visualization images. The even rows show the estimated changes in contrast perceived by an observer in the recolored images (with respect to the reference images), according to the DRIM metric. Green indicates loss of contrast, blue represents contrast amplification, and red shows regions with contrast reversal. The metric favors our results in all examples. ", "caption_bbox": [96, 804, 729, 863]}], "423": [{"image_id": 0, "file_name": "423_00.png", "page": 3, "dpi": 300, "bbox": [412, 133, 728, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An example workspace in our application.", "caption_bbox": [443, 353, 709, 366]}, {"image_id": 1, "file_name": "423_01.png", "page": 4, "dpi": 300, "bbox": [92, 133, 415, 227], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An example plot from the overview panel showing the distribution of eight regions in terms of average income. Notice that the green region has been flagged as a potentially problematic outlier, and that the user has measured its deviation from the main cluster. ", "caption_bbox": [93, 226, 396, 297]}, {"image_id": 2, "file_name": "423_02.png", "page": 4, "dpi": 300, "bbox": [93, 669, 397, 852], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An example view of the MAUP overview panel.", "caption_bbox": [99, 851, 389, 864]}, {"image_id": 3, "file_name": "423_03.png", "page": 4, "dpi": 300, "bbox": [413, 136, 728, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An example view of the MAUP adjustment panel.", "caption_bbox": [426, 302, 726, 315]}, {"image_id": 4, "file_name": "423_04.png", "page": 4, "dpi": 300, "bbox": [425, 758, 729, 833], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Before and after an add area adjustment of a city boundary (orange) within a constraint (thick black line) set for the county boundary that the city must remain inside. ", "caption_bbox": [425, 832, 728, 874]}, {"image_id": 5, "file_name": "423_05.png", "page": 5, "dpi": 300, "bbox": [424, 523, 728, 638], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Before and after a trade area adjustment of two regions to make their populations equal. The thick black line is a constraint used to force the regions to stay within their non-shared boundaries. ", "caption_bbox": [425, 637, 728, 694]}, {"image_id": 6, "file_name": "423_06.png", "page": 5, "dpi": 300, "bbox": [93, 724, 397, 955], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A grow/shrink adjustment of four regions to bring the population of each to be within ~1000 people of the mean.     Above are the original predefined city ", "caption_bbox": [93, 954, 396, 996]}, {"image_id": 7, "file_name": "423_07.png", "page": 5, "dpi": 300, "bbox": [93, 136, 415, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Before and after a remove area adjustment is made to remove protected wild lands (darkest green). ", "caption_bbox": [93, 267, 396, 295]}, {"image_id": 8, "file_name": "423_08.png", "page": 6, "dpi": 300, "bbox": [413, 136, 728, 485], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The process of calculating search masks for adding or removing area from a region. (a) is the region- of-interest to be adjusted on the map, (b) is the binary image mask for the area inside this region, (c) is the dilated mask, (d) is the eroded mask, (e) is the dilation search mask, and (f) is the erosion search mask. Notice that (e) = ( (c) - (b) ) and that (f) = ( (b) - (d) ). ", "caption_bbox": [425, 484, 728, 584]}, {"image_id": 9, "file_name": "423_09.png", "page": 7, "dpi": 300, "bbox": [412, 133, 728, 545], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The process of creating candidate adjustment masks. (a) & (b) are the dilation and erosion search masks generated as in Figure 9. (c) is a sample of one of the many slice masks that are used to divide up the search masks. (d) & (e) show the slice mask superimposed on each search mask to show the Boolean operations. (f) & (g) are the resulting masks, representing candidate adjustments. ", "caption_bbox": [425, 544, 728, 644]}, {"image_id": 10, "file_name": "423_10.png", "page": 8, "dpi": 300, "bbox": [425, 782, 729, 993], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The selected regions in the example scenario.", "caption_bbox": [432, 992, 720, 1005]}, {"image_id": 11, "file_name": "423_11.png", "page": 9, "dpi": 300, "bbox": [93, 734, 397, 919], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Pie charts showing the ratio of developed (light green) and undeveloped (dark green) land in each of the regions in the scenario. (a) shows the original regions depicted Figure 11. (b) shows the same regions after adjustment to remove excess water and protected land. Notice the significant changes in the 3rd and 7th regions. ", "caption_bbox": [93, 918, 396, 1003]}, {"image_id": 12, "file_name": "423_12.png", "page": 9, "dpi": 300, "bbox": [93, 359, 397, 484], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: The MAUP adjustment panel from the scenario.", "caption_bbox": [94, 483, 394, 496]}, {"image_id": 13, "file_name": "423_13.png", "page": 9, "dpi": 300, "bbox": [93, 136, 415, 334], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: The MAUP overview panel from the scenario.", "caption_bbox": [99, 333, 390, 346]}, {"image_id": 14, "file_name": "423_14.png", "page": 9, "dpi": 300, "bbox": [93, 508, 397, 681], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Regions before (left) and after (right) the adjustments made in the example scenario. Notice the removal of water (top) and protected land (bottom). ", "caption_bbox": [93, 680, 396, 722]}], "424": [{"image_id": 0, "file_name": "424_00.png", "page": 4, "dpi": 300, "bbox": [95, 132, 415, 546], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Possible appearances of cells in a SOM matrix. Left: space-in-time SOM (grouping of spatial situations). Right: time-in-space SOM (grouping of places according to temporal variations of attribute values). A,B: one attribute with values for 41 years. C,D: 7 attributes with values for 41 years. E,F: one attribute with values for 7x24 hours. The upper image in each cell is the feature image, the lower im- age is the index image. ", "caption_bbox": [96, 557, 397, 677]}, {"image_id": 1, "file_name": "424_01.png", "page": 5, "dpi": 300, "bbox": [95, 134, 415, 257], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An additional window displays the content of a cell of a time-in-space SOM. ", "caption_bbox": [96, 268, 397, 296]}, {"image_id": 2, "file_name": "424_02.png", "page": 6, "dpi": 300, "bbox": [412, 134, 694, 325], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The Time Arranger exposes periodic temporal patterns in the evolution of the traffic situation in Milan over the week. The columns correspond to the 24 hourly intervals of a day and the rows to the 7 days from Sunday to Saturday. The pixels have the colors of the SOM cells (Figure 3) in which the respective time units belong. ", "caption_bbox": [428, 336, 729, 425]}, {"image_id": 3, "file_name": "424_03.png", "page": 6, "dpi": 300, "bbox": [95, 132, 415, 442], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The space-in-time SOM matrix with the hourly traffic situations in Milan characterized in terms of the mean speeds in the spatial compartments. ", "caption_bbox": [96, 452, 397, 495]}, {"image_id": 4, "file_name": "424_04.png", "page": 7, "dpi": 300, "bbox": [412, 132, 732, 367], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The map of Milan with the places colored as the cells of the time-in-space SOM (Figure 5) they belong in. ", "caption_bbox": [428, 378, 729, 406]}, {"image_id": 5, "file_name": "424_05.png", "page": 7, "dpi": 300, "bbox": [95, 134, 415, 428], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The time-in-space SOM matrix with the local tem- poral variations of the mean speeds in the spatial compart- ments in Milan. ", "caption_bbox": [96, 438, 397, 481]}, {"image_id": 6, "file_name": "424_06.png", "page": 8, "dpi": 300, "bbox": [412, 134, 731, 427], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A) A fragment of the time graph display where the original data have been transformed to normalized dif- ferences from the mean values. The background painting of the time intervals uses the cell colors from the space-in-time SOM in Figure 8. B) The data have been further transformed to the differences with respect to the previous years. Instead of the lines of the individual states, the 0th, 20th, 40th, 60th, 80th, and 100th percentiles in each year are indicated by the vertical positions of the edges of the alternating stripes with lighter and darker shading, as suggested in [AA05a]. ", "caption_bbox": [428, 438, 729, 588]}, {"image_id": 7, "file_name": "424_07.png", "page": 8, "dpi": 300, "bbox": [95, 355, 399, 558], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The space-in-time SOM matrix of the yearly crime situations in the USA. ", "caption_bbox": [96, 568, 397, 596]}, {"image_id": 8, "file_name": "424_08.png", "page": 8, "dpi": 300, "bbox": [95, 132, 415, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A fragment of the time graph display of the tem- poral variations of the crime rates. ", "caption_bbox": [96, 306, 397, 334]}, {"image_id": 9, "file_name": "424_09.png", "page": 9, "dpi": 300, "bbox": [95, 134, 415, 477], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Top: the time-in-space SOM matrix grouping and arranging the states of the USA according to the tempo- ral variations of the values of 7 crime attributes. Bottom: the map of the USA with the states painted in the colors of the matrix cells. ", "caption_bbox": [96, 487, 397, 561]}], "425": [{"image_id": 0, "file_name": "425_00.png", "page": 1, "dpi": 300, "bbox": [412, 388, 731, 911], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The Fighter dataset rendered with our algorithm \u2013 Hardware-Assisted Projected Tetrahedra (HAPT) \u2013 using direct and indirect volume rendering. ", "caption_bbox": [428, 924, 729, 968]}, {"image_id": 1, "file_name": "425_01.png", "page": 2, "dpi": 300, "bbox": [412, 133, 701, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: One example of class 1 projection of the PT algo- rithm, where three triangles are generated. ", "caption_bbox": [428, 356, 729, 384]}, {"image_id": 2, "file_name": "425_02.png", "page": 3, "dpi": 300, "bbox": [473, 559, 699, 825], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: HAPT\u2019s Framework divided into vertex (VS), ge- ometry (GS) and fragment (FS) shaders. Any sorting method can be used prior to rendering, for example: quicksort in CUDA; STL-based introsort on the CPU; or the MPVONC algorithm on the CPU (see Section 3.1 for details). ", "caption_bbox": [428, 835, 729, 909]}, {"image_id": 3, "file_name": "425_03.png", "page": 4, "dpi": 300, "bbox": [96, 132, 689, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Error between centroid sorting and MPVONC.", "caption_bbox": [435, 980, 719, 993]}, {"image_id": 4, "file_name": "425_04.png", "page": 5, "dpi": 300, "bbox": [430, 359, 720, 589], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Direct volume rendering of the spx2 dataset.", "caption_bbox": [438, 610, 716, 623]}, {"image_id": 5, "file_name": "425_05.png", "page": 6, "dpi": 300, "bbox": [412, 133, 716, 478], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Two of the 150 frames from the time-varying tur- bulent jet dataset (1 M tet per frame) rendered with HAPT. ", "caption_bbox": [428, 518, 729, 546]}, {"image_id": 6, "file_name": "425_06.png", "page": 6, "dpi": 300, "bbox": [96, 132, 415, 334], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Torso dataset rendered with direct volume render- ing and iso-surfaces with (a) and without (b) illumination. ", "caption_bbox": [96, 339, 397, 367]}, {"image_id": 7, "file_name": "425_07.png", "page": 7, "dpi": 300, "bbox": [100, 363, 395, 700], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Direct volume rendering of the torso dataset (without iso-surfaces). ", "caption_bbox": [96, 711, 397, 739]}, {"image_id": 8, "file_name": "425_08.png", "page": 9, "dpi": 300, "bbox": [434, 579, 724, 949], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Direct volume rendering and illuminated iso- surfaces of the delta dataset. ", "caption_bbox": [428, 959, 729, 987]}, {"image_id": 9, "file_name": "425_09.png", "page": 9, "dpi": 300, "bbox": [117, 132, 731, 368], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Direct volume rendering with illuminated iso-surfaces: (a) post; (b) blunt; (c) fighter (front view of Figure 1).", "caption_bbox": [113, 374, 712, 387]}], "426": [{"image_id": 0, "file_name": "426_00.png", "page": 5, "dpi": 300, "bbox": [97, 132, 732, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: SNR, p-q landscape, where each image was generated using a fixed step size s = 2, and compared to a reference with: a) s = 100, p = 100 and q = 100, and b) s = 2, p = 100 and q = 100 . c) A typical error landscape for scenarios with varying p and s using a fixed data quantization q = 8, and a reference with s = 100, p = 100 and q = 8. ", "caption_bbox": [96, 351, 729, 394]}, {"image_id": 1, "file_name": "426_01.png", "page": 7, "dpi": 300, "bbox": [118, 132, 732, 518], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Mean, standard deviation, maximum and minimum over extracted parameters from the training scenarios. ", "caption_bbox": [428, 805, 729, 832]}, {"image_id": 2, "file_name": "426_02.png", "page": 8, "dpi": 300, "bbox": [96, 132, 729, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 4: Mean error in dB, standard deviation (std. dev.) and number of rendered images (#img) for model estimation of validation scenarios. For the Hybrid model 9 images have been rendered with varied setting for s at p = 24 for each validation scenario. ", "caption_bbox": [96, 515, 729, 542]}, {"image_id": 3, "file_name": "426_03.png", "page": 9, "dpi": 300, "bbox": [128, 132, 731, 347], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Upper row: Greyscale images of Hydrogen atom rendered using 6, 7, 8, 9, and 10 bits of pipeline precision at two steps/voxel. Bottom row: Color images of Golden Lady rendered with a 512x512 pixel resolution using two steps/voxel, From the left: Rendered using 10 bits of pipeline precision, the normalized difference image between 8 and 12 bits and close ups of images using 7, 8, 9, and 10 bits of precision ", "caption_bbox": [96, 356, 729, 396]}], "427": [{"image_id": 0, "file_name": "427_00.png", "page": 2, "dpi": 300, "bbox": [112, 167, 712, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualizations of a human hand using raycasting (a), and sliced-based volume rendering (b), both using the Phong illumination. Directional occlusion shading model with a headlamp illumination setup (c) and illumination from the top left (d). Illumination with the top-left light position causes that the fingers cast soft shadows on the body and evoke strong depth- perception cues. ", "caption_bbox": [96, 352, 729, 413]}, {"image_id": 1, "file_name": "427_01.png", "page": 3, "dpi": 300, "bbox": [431, 746, 728, 898], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Conical phase function setup: a selected point in space x scatters light which we approximate by a tilted cone (\u03b1 = tilt, \u03b8 = aperture). The axis of the cone is parallel to the light direction. The projection of the light energy leaves an elliptical footprint \u03b5 on a selected viewing plane. ", "caption_bbox": [428, 924, 729, 1000]}, {"image_id": 2, "file_name": "427_02.png", "page": 4, "dpi": 300, "bbox": [99, 175, 388, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Incremental blurring of the opacity buffer. We use a view-aligned slice stack composited in the front-to-back order. ", "caption_bbox": [96, 375, 397, 421]}, {"image_id": 3, "file_name": "427_03.png", "page": 4, "dpi": 300, "bbox": [431, 161, 727, 366], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A geometrical description of the cone-shaped phase function: the elliptical cone-section defines a circle \u03ba centered in S and intersecting the center C of the ellipse \u03b5. A side view (a) and a 3D view (b) of the planar cone-section. ", "caption_bbox": [428, 377, 729, 438]}, {"image_id": 4, "file_name": "427_04.png", "page": 5, "dpi": 300, "bbox": [497, 845, 661, 944], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Elliptical kernels used for incremental blurring of the opacity buffer: with linear fall-off (a) and Gaussian fall-off of the weighting function (b). ", "caption_bbox": [428, 955, 729, 1001]}, {"image_id": 5, "file_name": "427_05.png", "page": 5, "dpi": 300, "bbox": [96, 157, 398, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A detailed side view of the intersection of ellipse \u03b5 and circle \u03ba. ", "caption_bbox": [96, 313, 397, 344]}, {"image_id": 6, "file_name": "427_06.png", "page": 5, "dpi": 300, "bbox": [431, 166, 727, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: We introduce new literals for selected primi- tives: (a) the triangle \u25b3 SCO, (b) the triangle \u25b3 XV2\u2032V2 and (b) the circle \u03ba. These primitves are defined in Figures 4 and 5 by the same color encoding. Note, that ||CC\u2032 || = B which is the minor axis of the ellipse \u03b5. ", "caption_bbox": [428, 303, 729, 379]}, {"image_id": 7, "file_name": "427_07.png", "page": 6, "dpi": 300, "bbox": [108, 357, 720, 452], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Visualizations of the carp CT dataset using the directional occlusion shading model with a headlamp illumination setup (a) and using illumination setup conventional to medical illustrations (b). ", "caption_bbox": [96, 473, 729, 504]}, {"image_id": 8, "file_name": "427_08.png", "page": 6, "dpi": 300, "bbox": [123, 164, 707, 276], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visualizations of the gecko CT dataset with different setup of aperture \u03b8 and tilt angle \u03b1: \u03b8 = 10\u25e6 and \u03b1 = 37\u25e6 (a), \u03b8 = 40\u25e6 and \u03b1 = 37\u25e6 (b), and \u03b8 = 40\u25e6 and \u03b1 = 5\u25e6 (c). Light is coming from the right for all images. ", "caption_bbox": [96, 288, 729, 319]}, {"image_id": 9, "file_name": "427_09.png", "page": 7, "dpi": 300, "bbox": [107, 429, 718, 545], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Visualizations of a human foot acquired by computer tomography using the directional occlusion shading model: using the Phong illumination model with the headlamp illumination setup (a) and with the top-left lighting (b). Visualizations (c) and (d) use the diffuse illumination model with the headlamp and the top-left light source setup respectively. ", "caption_bbox": [96, 556, 729, 602]}, {"image_id": 10, "file_name": "427_10.png", "page": 7, "dpi": 300, "bbox": [101, 166, 723, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Visualizations of computer tomography data using the directional occlusion shading model with a headlamp illumi- nation setup (a) and (c) using the illumination setup conventional to medical illustrations (b) and (d). ", "caption_bbox": [96, 370, 729, 401]}, {"image_id": 11, "file_name": "427_11.png", "page": 8, "dpi": 300, "bbox": [99, 727, 395, 823], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Visualizations of the bonsai dataset: slice-based volume rendering using a view-aligned slice stack (a) and using a half-angle-aligned slice stack (b). ", "caption_bbox": [96, 833, 397, 879]}, {"image_id": 12, "file_name": "427_12.png", "page": 8, "dpi": 300, "bbox": [103, 434, 726, 611], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Visualizations of 3D ultrasound of cardiac data: user interface of a 3D cardiac ultrasound workstation (a), a clipped 3D cardiac ultrasound visualization using direct volume rendering and Phong illumination model, rendered with a raycaster (b), clipped 3D cardiac ultrasound visualization using the multidirectional occlusion shading model with light coming from the top left (c) and the bottom left (d). ", "caption_bbox": [96, 622, 729, 683]}, {"image_id": 13, "file_name": "427_13.png", "page": 8, "dpi": 300, "bbox": [109, 167, 718, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Visualizations of a human thorax we used for user study: using raycasting (a), sliced-based volume rendering (b), both using the Phong illumination followed by the directional occlusion shading model with the headlamp illumination setup (c) and illuminated from the top left (d). ", "caption_bbox": [96, 360, 729, 406]}], "428": [{"image_id": 0, "file_name": "428_00.png", "page": 3, "dpi": 300, "bbox": [84, 156, 411, 225], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An example of the scheme in [CGG\u2217 05, SS06a] where the triangle cannot be simplified at all levels shown. ", "caption_bbox": [96, 232, 397, 264]}, {"image_id": 1, "file_name": "428_01.png", "page": 4, "dpi": 300, "bbox": [85, 155, 410, 255], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The firewall. For sub-volume V , the outer- boundary is shown in green and the firewall is shown in red. (a) After the global simplification on V ; the firewall is iden- tified at this point. (b) After the internal simplification on V , i.e., the base mesh of V . (c) After the global simplification of neighbor sub-volume U. The boundary edge collapses of U are propagated to V to simplify the outer-boundary of V . Note that the firewall is intact. ", "caption_bbox": [95, 266, 397, 386]}, {"image_id": 2, "file_name": "428_02.png", "page": 5, "dpi": 300, "bbox": [117, 155, 368, 538], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An example of constructing the merge tree M. The left column shows the construction forest of each stage. Each tree node is associated with an error range [\u03b5l , \u03b5u ]. Note that the new nodes are created in the order of increas- ing \u03b5l . From (e), if we query \u03b5 against the \u03b5l values, as we sweep \u03b5 from 0 to \u221e, we see that there are five dis- tinct LOD cuts with their \u03b5 values falling in five intervals [0, 2), [2, 4), [4, 6), [6, 8), [8, \u221e). These LODs are exactly the cuts (shown in green lines, together with their \u03b5-value ranges in green) formed by the root nodes of the construction forests in stages (a)\u2013(e). The right column shows the corresponding connectivity graphs. ", "caption_bbox": [96, 551, 397, 732]}, {"image_id": 3, "file_name": "428_03.png", "page": 8, "dpi": 300, "bbox": [93, 155, 397, 527], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Rendering results using uniform LODs with 1.5GB of RAM for both out-of-core (top part) and in-core (bot- tom part) methods. Out-of-core HAVS (under the same RAM size) is also compared for single-resolution meshes. \u201cOOC\u201d means out-of-core. All images are of size 512 \u00d7 512. ", "caption_bbox": [428, 460, 729, 535]}, {"image_id": 4, "file_name": "428_04.png", "page": 9, "dpi": 300, "bbox": [82, 156, 745, 490], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 4: Out-of-core rendering results using selective re- finement LODs with 1.5GB of RAM. Meanings of some entries: Ave. LOD res.: Average LOD resolution; No. sel. nodes: number of selected nodes in the LOD cut. All images are of size 512 \u00d7 512. ", "caption_bbox": [96, 707, 397, 782]}], "429": [{"image_id": 0, "file_name": "429_00.png", "page": 1, "dpi": 300, "bbox": [92, 653, 727, 881], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Exploration of the InfoVis 2004 Contest co-authorship dataset using GraphDice. On the left is the main visualization window of GraphDice including (a) an overview plot matrix, (b) a selection history tool, (c) a selection query window, (d) a main plot, and (e) a toolbar. Overlapping nodes in the main plot are drawn using jitter (visible in the yellow selection query). On the right are actor (f) and link (g) tables with query data entries highlighted in the corresponding color. ", "caption_bbox": [92, 578, 725, 637]}, {"image_id": 1, "file_name": "429_01.png", "page": 5, "dpi": 300, "bbox": [412, 133, 726, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Link directionality in a migration network of cities in 2 discrete administrative departments. The excentric label is used to focus on a single node and its links. ", "caption_bbox": [423, 444, 724, 487]}, {"image_id": 2, "file_name": "429_02.png", "page": 5, "dpi": 300, "bbox": [91, 134, 415, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An edge e:year attribute (x-axis) projected as an interval node attribute (straight lines along x-axis, 1 per au- thor). The author nodes (y-axis) are ordered so that similar intervals are close to each other. In this co-authorship net- work (a), we use an excentric label to focus on part of the network (b). Notice hooks at ends of intervals. ", "caption_bbox": [91, 289, 392, 378]}, {"image_id": 3, "file_name": "429_03.png", "page": 6, "dpi": 300, "bbox": [92, 133, 415, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) A consensus 3D curve is built by extruding the initial and final links and averaging them. (b) When links are splines whose intermediary control points are kept unchanged in terms of height and relative x-position, this method reduces to a 3D curve reconstruction. ", "caption_bbox": [91, 268, 392, 342]}, {"image_id": 4, "file_name": "429_04.png", "page": 7, "dpi": 300, "bbox": [121, 133, 726, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) X,Y layout for a graph and queries. Menu navigation: (a) Using the right mouse button the user invokes the dimension menu, with the currently selected dimensions marked in red. (b) As the user drags over a menu the new vertical dimension is highlighted in green. If the user releases the menu, a default speed animation transitions to the new centrality dimension (d). (c) If the user continues dragging, a fast slider appears allowing the user to control the animation speed. ", "caption_bbox": [91, 303, 724, 362]}], "430": [{"image_id": 0, "file_name": "430_00.png", "page": 4, "dpi": 300, "bbox": [96, 132, 725, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Grid graphs generated on the 2000 Air Traffic (AT) network with (a) a quad tree (37395 nodes/69102 edges), (b) a Voronoi diagram (4531 nodes/13558 edges) and (c) the hybrid quad tree/Vorono\u00ef approach (10146 nodes/30315 edges). ", "caption_bbox": [96, 393, 729, 421]}, {"image_id": 1, "file_name": "430_01.png", "page": 5, "dpi": 300, "bbox": [99, 132, 732, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Computation time of our method applied : (a) on the US migration graph used by [Hv09, CZQ\u2217 08] (1715 vertices/9780 edges), (b) on the 2000 air traffic network (1525 vertices/16479) and (c) on the call graph (5741 vertices/11442 edges). ", "caption_bbox": [96, 322, 729, 367]}, {"image_id": 2, "file_name": "430_02.png", "page": 6, "dpi": 300, "bbox": [96, 132, 720, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Different clutter reductions of a graph representation (a), using edge-edge clutter reduction method (b), avoiding node-edge overlap (c) and uncluttering dense zones (d). ", "caption_bbox": [96, 366, 729, 394]}, {"image_id": 3, "file_name": "430_03.png", "page": 7, "dpi": 300, "bbox": [107, 132, 732, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparison between two representations of an edge-bundled graph. In (a), edges are drawn as polylines while in (b) they are drawn as B\u00e9zier curves. When edges are rendered as B\u00e9zier curves, their shapes are smooth and a nice impression of flows between different regions of the graph emerges from the drawing. However, edges can overlap nodes due to the lack of local control proper to B\u00e9zier curves. ", "caption_bbox": [96, 322, 729, 381]}, {"image_id": 4, "file_name": "430_04.png", "page": 7, "dpi": 300, "bbox": [428, 420, 729, 552], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Linear edge splatting generated with a Gaussian kernel of radius 5 and standard deviation 3. ", "caption_bbox": [428, 564, 729, 592]}, {"image_id": 5, "file_name": "430_05.png", "page": 9, "dpi": 300, "bbox": [210, 132, 731, 607], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Illustrations of the bump mapping based rendering of edge splatting with the edge-bundled representations of the US migration graph and 2000 AT network. Strong bundles appears higher than other ones with this technique making them visually emerge from the graph drawing. For the US migration graph, heights are linearly mapped to the splat field and the diffuse map used for the bump mapping rendering corresponds to the splat field linear color mapping. For the AT graph, heights are logarithmically mapped to the splat field and the original edges colors are used as diffuse map. ", "caption_bbox": [96, 620, 729, 694]}], "431": [{"image_id": 0, "file_name": "431_00.png", "page": 3, "dpi": 300, "bbox": [473, 832, 685, 956], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Splatting algorithm details", "caption_bbox": [484, 967, 671, 980]}, {"image_id": 1, "file_name": "431_01.png", "page": 3, "dpi": 300, "bbox": [96, 132, 732, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Image-based edge bundle (IBEB) visualization pipeline", "caption_bbox": [248, 295, 577, 308]}, {"image_id": 2, "file_name": "431_02.png", "page": 4, "dpi": 300, "bbox": [96, 132, 636, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Shape shading styles (see Secs. 3.4,3.5)", "caption_bbox": [455, 464, 700, 477]}, {"image_id": 3, "file_name": "431_03.png", "page": 5, "dpi": 300, "bbox": [159, 132, 732, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Shading pipeline (Sec. 3.4). Edges in a cluster (a) and their binary shape I and skeleton Sk (b) and shading profile H (c). Convex shading with shape thickness as function of the splat size (d,e) and shading profile thresholding (f) ", "caption_bbox": [96, 545, 728, 574]}, {"image_id": 4, "file_name": "431_04.png", "page": 6, "dpi": 300, "bbox": [96, 556, 400, 855], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Bundle visual separation using halos", "caption_bbox": [128, 866, 366, 879]}, {"image_id": 5, "file_name": "431_05.png", "page": 6, "dpi": 300, "bbox": [96, 132, 677, 509], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Rendering styles: convex shapes (b), density-luminance (c), density-saturation (d), bi-level (e), and outlines (f).", "caption_bbox": [109, 519, 716, 532]}, {"image_id": 6, "file_name": "431_06.png", "page": 7, "dpi": 300, "bbox": [143, 132, 732, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The digging lens is used to interactively explore areas where shapes overlap. Insets show zoomed-in details.", "caption_bbox": [116, 341, 708, 354]}, {"image_id": 7, "file_name": "431_07.png", "page": 8, "dpi": 300, "bbox": [96, 345, 728, 636], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Image-based visualization of force-directed bundling (FDB) layouts", "caption_bbox": [216, 647, 608, 660]}, {"image_id": 8, "file_name": "431_08.png", "page": 8, "dpi": 300, "bbox": [96, 132, 730, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Software dependency graph exploration with IBEB (see Sec. 4)", "caption_bbox": [229, 327, 596, 340]}], "432": [{"image_id": 0, "file_name": "432_00.png", "page": 2, "dpi": 300, "bbox": [100, 166, 389, 417], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Screenshot of the SmallWorlds Facebook Applica- tion. ", "caption_bbox": [110, 423, 383, 447]}, {"image_id": 1, "file_name": "432_01.png", "page": 5, "dpi": 300, "bbox": [95, 156, 726, 584], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The SmallWorlds recommendation interface for an active user x. Node i2a represents an item in the active user\u2019s profile. Position of this node within layer 2 determines a preference weighting ItemWeight(i2a ). Node u3a represents a friend who has items in common with the active user. Position of this node within layer 3 is computed by UserSimilarity(u3a , x). The dashed line F(un , un+1 ) represents a repelling force between nodes, present in all layers. Node i4a represents a recommended item with a position within layer 4 computed by Score(x, i4a ). The remainder of the active user\u2019s friend nodes are placed in layers 5 and higher based on their graph distance from the active user\u2019s node. The solid red arrows give an example of the effects of moving item nodes in layer 2, such as i2a . ", "caption_bbox": [110, 589, 715, 664]}, {"image_id": 2, "file_name": "432_02.png", "page": 6, "dpi": 300, "bbox": [95, 156, 399, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Example of a concentric layout for item recommen- dation. As profile or friend nodes are dragged, item nodes move relatively based on the weighting and interaction mod- els. ", "caption_bbox": [110, 382, 383, 431]}, {"image_id": 3, "file_name": "432_03.png", "page": 7, "dpi": 300, "bbox": [428, 156, 731, 410], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Likert Scale Questions from the User Survey.", "caption_bbox": [458, 591, 699, 603]}, {"image_id": 4, "file_name": "432_04.png", "page": 8, "dpi": 300, "bbox": [428, 156, 731, 558], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Satisfaction ratings of item predictions for Movielens and for SmallWorlds with and without user interactions. ", "caption_bbox": [442, 625, 715, 649]}, {"image_id": 5, "file_name": "432_05.png", "page": 9, "dpi": 300, "bbox": [431, 159, 729, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Relation between satisfaction with recommenda- tions and number of Facebook friends. ", "caption_bbox": [442, 361, 715, 385]}], "433": [{"image_id": 0, "file_name": "433_00.png", "page": 2, "dpi": 300, "bbox": [458, 156, 701, 375], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Variations on the box plot. a) Abbreviated box plot. b) Range plot [Spe52]. c) Box plot [Tuk77]. d) In- terquartile plot [Tuf83]. e) Variable width and notched box plots [MTL78] expressing sample sizes and confidence lev- els. f) Hist plot [Ben88] g) Vase plot [Ben88] h) Box- percentile plot [EB03]. i) Violin plot [HN98]. j) Skew and modality plots [CM05]. ", "caption_bbox": [428, 385, 729, 490]}, {"image_id": 1, "file_name": "433_01.png", "page": 3, "dpi": 300, "bbox": [96, 156, 398, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Anatomy of the summary plot. The abbreviated box plot displays the range of the data distribution. The mo- ment plot shows higher order statistics which describe fea- ture characteristics. The histogram estimates the density of the distribution and is displayed using a symmetric display and a redundant colormap. Distribution fitting allows the user to compare the data against well-known distributions. ", "caption_bbox": [96, 399, 397, 504]}, {"image_id": 2, "file_name": "433_02.png", "page": 4, "dpi": 300, "bbox": [122, 157, 374, 224], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Moment arm abstraction from which we designed the moment plot. Using the balance bean metaphor, each glyph is placed so as to stabilize the weight on the beam. ", "caption_bbox": [96, 236, 397, 280]}, {"image_id": 3, "file_name": "433_03.png", "page": 4, "dpi": 300, "bbox": [113, 665, 383, 752], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The mean is represented by a red cross and the median by dark grey lines on the left and right. The mean and median glyphs align when the values are equal, thus easing visual comparison to normal distributions. ", "caption_bbox": [96, 764, 397, 823]}, {"image_id": 4, "file_name": "433_04.png", "page": 4, "dpi": 300, "bbox": [435, 246, 723, 447], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Glyphs for the higher-order central moments. Each triplet of distributions shows negative, close to zero, and positive values for the respective moment. Each higher- order moment is relative to the moments of a Gaussian dis- tribution, which is the central distribution in each set. ", "caption_bbox": [428, 457, 729, 531]}, {"image_id": 5, "file_name": "433_05.png", "page": 5, "dpi": 300, "bbox": [453, 254, 708, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Joint summary for two 1D categorical data sets. The red and blue lines show the joint mean and standard deviation, respectively. The joint histogram is shown as col- ormapped, jittered quadrilaterals emphasizing where both data sets express density. Covariance and skew variance are shown as glyphs centrally located within the area created by the lines of standard deviation. These glyphs show how much the two data sets vary together, as well as how much they are skewed in the same direction. ", "caption_bbox": [428, 544, 729, 679]}, {"image_id": 6, "file_name": "433_06.png", "page": 5, "dpi": 300, "bbox": [119, 617, 372, 734], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The results of fitting 3 canonical distributions to a single data set are shown as dotted lines on either side of the plot. ", "caption_bbox": [96, 752, 397, 796]}, {"image_id": 7, "file_name": "433_07.png", "page": 7, "dpi": 300, "bbox": [124, 155, 702, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Temperature at 2M above ground at valid forecast hour 27. Color refers to the mean (leftmost) and standard deviation (center) of the ensemble computed at each grid point. Rightmost, results of k-medoids clustering algorithm [Bis06] on the temperature data. The domain is colormapped based cluster membership. ", "caption_bbox": [96, 324, 729, 368]}, {"image_id": 8, "file_name": "433_08.png", "page": 7, "dpi": 300, "bbox": [95, 380, 731, 792], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Summary plots for the points resulting from the clustering algorithm. Inset: (left to right) Histogram density estima- tion using 20 bins, and kernel density estimation. ", "caption_bbox": [96, 804, 729, 832]}, {"image_id": 9, "file_name": "433_09.png", "page": 8, "dpi": 300, "bbox": [95, 161, 720, 555], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: (Left, top) Close-up of the joint summary plot for multiple categorical datasets. While the joint histogram display induces some visual clutter, the cloud-like nature of the display gives a general feel of the density trend across the data. The covariance and skew variance glyphs help distinguish between each joint summary plot. (Left, bottom) A dialog box from the user interface. (Right) 2D summary plot of temperature and humidity averaged across altitude slices. The trend of both variables to condense as altitude increases is visible through the compaction of the joint density display and the reduction of the size of the covariance glyph. The changes in orientation of the skew variance glyphs highlight the dominance of the temperature variable at higher altitudes. ", "caption_bbox": [96, 575, 729, 680]}], "434": [{"image_id": 0, "file_name": "434_00.png", "page": 5, "dpi": 300, "bbox": [96, 134, 415, 444], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Different quantile plots show distributions of multi-run data: a shows the original temperature values. The distances to the distribution\u2019s median are shown in b. This view is normalized by the MAD in d to identify outliers. The individual distributions in a are normalized to [0, 1] in c. Views in b, c, d result from view transformations T of view a. ", "caption_bbox": [96, 457, 397, 548]}, {"image_id": 1, "file_name": "434_01.png", "page": 6, "dpi": 300, "bbox": [95, 132, 415, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A Q\u2013Q (quantile-quantile) plot in a compares the sample distribution to a standard normal distribution. Ap- plying a view transformation, deviations from the indicated line are investigated in a detrended Q\u2013Q plot in b. ", "caption_bbox": [96, 317, 397, 376]}, {"image_id": 2, "file_name": "434_02.png", "page": 6, "dpi": 300, "bbox": [412, 134, 730, 445], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Basic view setup showing combinations of all four moments in a, b, d (aggregated data part). The quantile plot in c is utilized to identify possible outliers. Interesting distri- butions are brushed and highlighted in color. ", "caption_bbox": [428, 457, 729, 516]}, {"image_id": 3, "file_name": "434_03.png", "page": 7, "dpi": 300, "bbox": [412, 132, 732, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparing traditional vs. median/MAD-based vs. octile-based skewness. Some of the green highlighted points with positive skewoct selected in b even have a negative value for the traditional skewness in b. ", "caption_bbox": [428, 316, 729, 375]}, {"image_id": 4, "file_name": "434_04.png", "page": 7, "dpi": 300, "bbox": [95, 134, 415, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Traditional vs. octile-based measures for skewness and kurtosis: High skewness values are brushed in a and ap- parently result from outliers since the corresponding robust measures in b (green) yield values closer to zero. ", "caption_bbox": [96, 317, 397, 376]}, {"image_id": 5, "file_name": "434_05.png", "page": 8, "dpi": 300, "bbox": [412, 134, 730, 446], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The 3D atmosphere is shown in a, encoding mean, standard deviation, and skewness at timestep 80. Interesting data characteristics are brushed in b and refined in the inset, the corresponding distributions are investigated in a quan- tile plot in c. A robustified version of b is shown in d. ", "caption_bbox": [428, 458, 729, 532]}, {"image_id": 6, "file_name": "434_06.png", "page": 8, "dpi": 300, "bbox": [96, 132, 415, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: a shows the result of a relating transformation applied to a standard deviation vs. IQR plot. Items along the diagonals are selected in a transformed view (inset) and correspond to distributions with a peaked shape in b. ", "caption_bbox": [96, 315, 397, 374]}, {"image_id": 7, "file_name": "434_07.png", "page": 9, "dpi": 300, "bbox": [96, 134, 415, 382], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Negative outliers selected in a form a repetitive pattern with respect to the run parameter (highlighted green in the inset). Positive outliers (red) form a repetitive pattern in the mean vs. standard deviation plot in b. The temporal evolution can be seen in a function graphs view in c. ", "caption_bbox": [96, 393, 397, 467]}], "435": [{"image_id": 0, "file_name": "435_00.png", "page": 2, "dpi": 300, "bbox": [412, 134, 709, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A Select & Slice table showing the distribution of items of the four zones across different subsets of two datasets (Data_1992 and Data_2004). The length of a bar in a cell represents the number of nations. ", "caption_bbox": [428, 301, 729, 360]}, {"image_id": 1, "file_name": "435_01.png", "page": 2, "dpi": 300, "bbox": [96, 132, 415, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Four semantic zones shown in two visualizations. A zone has either a data selection specification or a set of items extracted using a data selection specification. It has a label provided by a user. ", "caption_bbox": [96, 350, 397, 409]}, {"image_id": 2, "file_name": "435_02.png", "page": 4, "dpi": 300, "bbox": [96, 132, 668, 506], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The Select & Slice Table is shown as a part of the knowledge view in the Aruvi visualization system. A filter (a) and a brush (b) are combined to define the current zone (c). Users can define a new zone by dragging the current zone, an existing zone or a cell on to the \u2018new zone\u2019 place holder (d). (e) The new zone composition menu. ", "caption_bbox": [96, 516, 729, 559]}, {"image_id": 3, "file_name": "435_03.png", "page": 5, "dpi": 300, "bbox": [125, 134, 415, 402], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) A new Select & Slice Table. (b) The table with a new zone (highlighted in green), and three new subsets of the data based on attribute slicing (highlighted in red). ", "caption_bbox": [96, 413, 397, 456]}, {"image_id": 4, "file_name": "435_04.png", "page": 5, "dpi": 300, "bbox": [412, 132, 732, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Data subset definition interface. (a) A list of avail- able datasets using unique dataset identifiers provided by the user. (b) A list of subsets of datasets. The labels for the sub- sets are automatically generated by combining the dataset identifier, and the attribute name that is used for subset- ting. Users can rearrange, show, hide or remove a selected dataset from the list. (c) A subset definition panel. (d) The subsets of a selected dataset. An ordinal interval is rep- resented using a standard interval notation; where [3, 6) means 3 <= x < 6. ", "caption_bbox": [428, 348, 729, 498]}, {"image_id": 5, "file_name": "435_05.png", "page": 6, "dpi": 300, "bbox": [428, 499, 701, 768], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) Keyword search interface. (b) An item sugges- tion list. (c) Search results are visualized using colored dots in cells. A dot is colored based on its corresponding key- word\u2019s color in the search interface. ", "caption_bbox": [428, 778, 729, 837]}, {"image_id": 6, "file_name": "435_06.png", "page": 6, "dpi": 300, "bbox": [412, 134, 724, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Set comparison view shows the distribution of Japanese cars (a). (b) One-fourth of the \u2018cars having good acceleration\u2019 are Japanese in the dataset; these Japanese cars (50 out of 51 cars) have between 3 and 6 cylinders. (c) All these 51 Japanese cars weigh less than 3000 pounds. ", "caption_bbox": [428, 387, 729, 461]}, {"image_id": 7, "file_name": "435_07.png", "page": 6, "dpi": 300, "bbox": [96, 132, 415, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Semantic zone editor. (a) Zone composition editor with a parse tree completion assistant. (b) A list of selection specifications (filters and brushes) that defines a semantic zone. ", "caption_bbox": [96, 339, 397, 398]}, {"image_id": 8, "file_name": "435_08.png", "page": 7, "dpi": 300, "bbox": [412, 132, 732, 619], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Support for drill-down analysis. The selected cells 1, 2 and 3 highlighted in green, blue and red respectively compose a brush \u2013 \u2018American cars with 8 cylinders that are not heavy\u2019. These cars are highlighted in the scatterplot (a). (b) Detailed information about those cars. ", "caption_bbox": [428, 629, 729, 703]}, {"image_id": 9, "file_name": "435_09.png", "page": 8, "dpi": 300, "bbox": [412, 134, 706, 624], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Socio-economic data investigation. (a) Medical Expenses trend analysis and (b) The relationship between illiteracy and the seven zones helped the analyst to identify the intrinsic vulnerable slums. ", "caption_bbox": [428, 635, 729, 694]}, {"image_id": 10, "file_name": "435_10.png", "page": 8, "dpi": 300, "bbox": [96, 132, 415, 537], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Software quality analysis. (a) Comparison of two different versions of the JBoss, an enterprise application server. (b) Comparison of two different financial manage- ment software systems. ", "caption_bbox": [96, 547, 397, 606]}], "436": [{"image_id": 0, "file_name": "436_00.png", "page": 4, "dpi": 300, "bbox": [96, 132, 415, 352], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Scatter plots embedded into a PCP. Red arrows denote the direction of the a1 axis in each visualization. ", "caption_bbox": [96, 356, 397, 385]}, {"image_id": 1, "file_name": "436_01.png", "page": 4, "dpi": 300, "bbox": [430, 649, 725, 873], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Polyline crossing ambiguity (a,b) is not solved by (c) curves crossing PCP axes orthogonally. (d) Our ap- proach resolves this ambiguity while minimizing curvature. ", "caption_bbox": [428, 873, 729, 916]}, {"image_id": 2, "file_name": "436_02.png", "page": 5, "dpi": 300, "bbox": [105, 132, 732, 399], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The six non-animated PCP variations that were evaluated: (a) standard PCP, (b) scatter plots embedded into a PCP, (c) colored polylines, (d) blended polylines, (e) colored and blended polylines, and (f) curves instead of polylines. ", "caption_bbox": [96, 402, 729, 430]}, {"image_id": 3, "file_name": "436_03.png", "page": 5, "dpi": 300, "bbox": [105, 435, 718, 541], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Five frames of a random tour animation show the movement of two clusters. Initially (dotted lines), clusters exhibit considerable overlap, making it hard to distinguish them. Parallax introduced by animation helps to visually separate clusters. ", "caption_bbox": [96, 543, 729, 571]}, {"image_id": 4, "file_name": "436_04.png", "page": 7, "dpi": 300, "bbox": [96, 733, 395, 904], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Response time and correctness plotted against cluster count show similar patterns for all PCP variations. ", "caption_bbox": [96, 913, 397, 941]}, {"image_id": 5, "file_name": "436_05.png", "page": 7, "dpi": 300, "bbox": [451, 613, 706, 786], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Average response time for each of the PCP varia- tions (shown with a 95% confidence interval). ", "caption_bbox": [428, 790, 729, 818]}, {"image_id": 6, "file_name": "436_06.png", "page": 7, "dpi": 300, "bbox": [461, 231, 695, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: There is a strong correlation (r = \u22120.88) be- tween response time and correctness. Each point represents a unique combination of PCP variation and cluster count. ", "caption_bbox": [428, 412, 729, 456]}, {"image_id": 7, "file_name": "436_07.png", "page": 8, "dpi": 300, "bbox": [96, 132, 415, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Tukey\u2019s HSD test results. For \u03b1 = 0.05, 9 treat- ments, and a within-groups df > 1000 (2691 in our case), all values > 4.39 (bold and green) show a significant difference. ", "caption_bbox": [96, 295, 397, 338]}], "437": [{"image_id": 0, "file_name": "437_00.png", "page": 2, "dpi": 300, "bbox": [95, 134, 700, 558], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Coherent Visualization of an argon bubble-shockwave interaction. (a) Three time steps rendered using a local transfer function. Although a local transfer function enhances different structures, they are not coherent, as values depicted in red do not necessarily correspond to the same values in all three time steps. This is misleading to the scientist. (b) The global transfer function provides a coherent visualization, as seen in the apparent dissipation of the gas bubble. Obtaining such result requires another complete traversal of the full simulation sequence. (c) With our approach, we remap the results in (a) to the global transfer function without the need to access the volume data. Compare to (b) for accuracy. (d) In addition, the scientist might adjust the global color map to bring out the ring details in the third time step. Other time steps can be re-adjusted with little cost. Ray Attenuation Functions : For the time step in second column, we show a 16-bin ray attenuation function for a given pixel as a logarithmic bar chart. In (b), we see that the attenuation function is a rescaled and biased version of the function in (a). This transformation is more clear when we see the attenuation function discretized in 32 bins. (c) We exploit this behavior to remap the attenuation function from (a) to the global range. Compare this histogram to the actual 32-bin function in (b). ", "caption_bbox": [96, 568, 729, 734]}, {"image_id": 1, "file_name": "437_01.png", "page": 4, "dpi": 300, "bbox": [95, 134, 415, 468], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Ray Attenuation Functions (RAF) are ob- tained by adding the attenuation of intensity values grouped into a finite set of bins. (b) RAF Properties. Left: The RAF for a given pixel is visualized as a logarithmic bar chart. Middle: when we simulate a data range change that doubles in size (and use an equivalent transfer function), the result- ing RAF is a scaled and biased version of the one on the left. Right: when we decrease the opacity of the two outer- most features, the resulting RAF is a modulated version of the original on the left, where some bins decrease in total attenuation (the ones that decrease in opacity), while others increase. ", "caption_bbox": [96, 477, 397, 658]}, {"image_id": 2, "file_name": "437_02.png", "page": 6, "dpi": 300, "bbox": [107, 406, 387, 720], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Attenuation Propagation. (a) Original volume rendered image. (b) Volume rendered image after reducing the opacity of two intensity ranges. (c) Reconstruction us- ing the RAF without attenuation propagation is incorrect. (d) Reconstruction using the RAF with correct attenuation propagation provides accurate results. Compare to (b). ", "caption_bbox": [96, 727, 397, 816]}, {"image_id": 3, "file_name": "437_03.png", "page": 6, "dpi": 300, "bbox": [95, 134, 715, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Coherent visualization process overview. Simulation data is read from disk and classified using local transfer func- tions. For each time step, we generate a compact representation - ray attenuation functions. We can remap the transfer function by scaling and biasing the function to the global range. The resulting visualization is now coherent. Further operations on the transfer function can be performed on the RAF without the need to retrieve the original 3D volume data. ", "caption_bbox": [96, 314, 729, 373]}, {"image_id": 4, "file_name": "437_04.png", "page": 7, "dpi": 300, "bbox": [99, 134, 731, 501], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Coherent transfer function operations performed on a combustion data set (three time steps are shown). (a) Results of reconstruction using attenuation functions. Compare the ground truth volume rendering (second column) to the image recon- structed using attenuation functions (third column). (b) The scientist adjusts the opacity of several features to avoid ambiguity in one of the regions, especially the structures in yellow and orange. (c) Finally, the user applies a new color map to highlight the variation in the interval previously colored yellow, which appeared flat. Now, the scientist can see a more intricate structure. ", "caption_bbox": [96, 511, 729, 585]}, {"image_id": 5, "file_name": "437_05.png", "page": 8, "dpi": 300, "bbox": [95, 134, 415, 423], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Ray Attenuation Function adjustment. (a) A com- bustion data set and (b) inset view. (c) Without RAF adjust- ment, the reconstructed volume is not smooth and has sharp color boundaries. (d) With RAF adjustment (using a linear function), the boundaries are smooth. Compare to (b). ", "caption_bbox": [96, 431, 397, 505]}, {"image_id": 6, "file_name": "437_06.png", "page": 9, "dpi": 300, "bbox": [99, 396, 730, 588], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Left: Accuracy plot for three data sets as we change the opacity of a given interval. We see a smooth increase in error (and in its standard deviation) as modulation goes from 1 (meaning no opacity change) to 0 (meaning that the outermost features are completely transparent). Right: Accuracy plot as we increase the number of bins in the RAF. ", "caption_bbox": [96, 599, 729, 643]}, {"image_id": 7, "file_name": "437_07.png", "page": 9, "dpi": 300, "bbox": [98, 134, 729, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Timing comparison for three data sets. Since our method is pixel-bound, i.e. it depends on image size, we compare time vs. effective pixel area of the volume. We compare direct volume rendering (blue), computation of the RAF (orange), and compositing of the RAF (green). The cost of computing the attenuation function is well outweighed by the benefit of re- compositing using the RAF (green plot). ", "caption_bbox": [96, 317, 729, 376]}], "438": [{"image_id": 0, "file_name": "438_00.png", "page": 4, "dpi": 300, "bbox": [95, 134, 689, 663], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example of our isosurface similarity measure. Row (1): column (a) shows an image of three concentric circles, in column (b) the innermost sphere is replaced by a square of approximately equal area, and columns (c) and (d) show the same two images with added noise. In row (2) the respective histograms are shown. Row (3) depicts the corresponding isosurface similarity maps. Row (4) shows the isosurface similarity distributions. ", "caption_bbox": [96, 671, 729, 730]}, {"image_id": 1, "file_name": "438_01.png", "page": 5, "dpi": 300, "bbox": [108, 134, 730, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Result images for similarity-enhanced isosurface visualization are shown in (a) and (b), (c) depicts the isosurface similarity map of the data set, and (d) shows the isosurface similarity distribution for the highlighted region in the similarity map. The isovalues depicted in (a) and (b) are marked with corresponding colors in (c) and (d). ", "caption_bbox": [96, 350, 729, 393]}, {"image_id": 2, "file_name": "438_02.png", "page": 6, "dpi": 300, "bbox": [95, 134, 684, 398], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Transition using linear mapping MLV (x) (top row) and similarity-based mapping MSV (x) (bottom row) for x \u2208 [0.22, 0.32]. ", "caption_bbox": [96, 408, 729, 437]}, {"image_id": 3, "file_name": "438_03.png", "page": 6, "dpi": 300, "bbox": [428, 476, 731, 618], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Similarity-based isovalue remapping. (a) Isosur- face similarity map for the data set shown in Figure 3 \u2013 the highlighted area indicates the interval of isovalues in the transition. (b) Plot of the difference between the linear mapping function MLV (x) and the similarity-based mapping function MSV (x) for x \u2208 [0.22, 0.32]. ", "caption_bbox": [428, 626, 729, 715]}, {"image_id": 4, "file_name": "438_04.png", "page": 7, "dpi": 300, "bbox": [178, 134, 730, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Representative isovalue selection algorithm applied to a CT data set. The isosurface similarity map is shown on the left and the six most representative isovalues are marked. The corresponding isosurfaces are depicted in the middle section numbered from one to six with decreasing relevance. The image on the right shows a cutaway view of the data set classified according to maximum similarity with the six isovalues. ", "caption_bbox": [96, 338, 729, 397]}, {"image_id": 5, "file_name": "438_05.png", "page": 7, "dpi": 300, "bbox": [457, 434, 701, 655], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Automatically classified CT data set using the eight most representative isovalues. ", "caption_bbox": [428, 666, 729, 694]}, {"image_id": 6, "file_name": "438_06.png", "page": 8, "dpi": 300, "bbox": [95, 134, 726, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Representative isovalue selection algorithm applied to an MRI angiography data set. The isosurface similarity map is shown on the left and the eight most representative isovalues are marked. The corresponding isosurfaces are depicted in the middle section numbered from one to eight with decreasing relevance. The image on the right shows a cutaway view of the data set classified according to maximum similarity with the eight isovalues. ", "caption_bbox": [96, 338, 729, 397]}, {"image_id": 7, "file_name": "438_07.png", "page": 9, "dpi": 300, "bbox": [103, 136, 415, 491], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison of isosurface similarity maps com- puted with different distance transform resolutions for the data set shown in Figure 5. The total compuation times (in minutes) were (a) 569.1, (b) 35.8, (c) 22.1, and (d) 20.6. ", "caption_bbox": [96, 499, 397, 558]}], "439": [{"image_id": 0, "file_name": "439_00.png", "page": 1, "dpi": 300, "bbox": [72, 339, 680, 554], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Left: Reconstruction of our dome geometry and the camera parameters for our 4 projector front projection dome; Center: Our dome with view-dependent registration for flow simulation; Right: Our dome with view-independent registration of a visualization of early internet backbone, using orthographic map projection techniques. ", "caption_bbox": [59, 564, 692, 608]}, {"image_id": 1, "file_name": "439_01.png", "page": 3, "dpi": 300, "bbox": [61, 55, 378, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: This illustrates the world coordinate system and the display surface and camera setup with respect to it. The captured image of the boundary of the screen is shown in the picture (cyan ellipse) and also the reprojected bound- ary on the image plane of the estimated camera (dashed red ellipse). Also one of the projected sets of points which are collinear in the projector space is shown. The 3D position of the detected points is estimated using ray-shooting and then tested for coplanarity (constraint 4). ", "caption_bbox": [59, 340, 360, 475]}, {"image_id": 2, "file_name": "439_02.png", "page": 3, "dpi": 300, "bbox": [375, 55, 694, 370], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Image of our 4 projector dome setup. The cali- brating camera can be seen at the bottom. ", "caption_bbox": [391, 376, 692, 404]}, {"image_id": 3, "file_name": "439_03.png", "page": 4, "dpi": 300, "bbox": [58, 55, 376, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The images used for calibrating our 4 projector dome. One image from the dome and one image for each projector are used. ", "caption_bbox": [59, 204, 360, 248]}, {"image_id": 4, "file_name": "439_04.png", "page": 4, "dpi": 300, "bbox": [120, 255, 298, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The pipeline of our algorithm.", "caption_bbox": [105, 439, 309, 452]}, {"image_id": 5, "file_name": "439_05.png", "page": 6, "dpi": 300, "bbox": [60, 55, 659, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Left: View-dependent registration for a gaming application while the capturing camera is located at the virtual viewpoint. Middle: View-dependent registration of the same scene when the capturing camera is away from the virtual viewpoint and hence the visible distortions of the straight lines of the buildings and on the pathway. Right: View-independent registration for a planetarium like setup using stereographic projection. ", "caption_bbox": [59, 273, 692, 332]}, {"image_id": 6, "file_name": "439_06.png", "page": 7, "dpi": 300, "bbox": [58, 368, 362, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Left: Reconstruction of our non-hemispherical dome and the camera view frustum. Right: Registration of a map data on the non-hemispherical dome. ", "caption_bbox": [59, 558, 360, 602]}, {"image_id": 7, "file_name": "439_07.png", "page": 7, "dpi": 300, "bbox": [58, 55, 693, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) Reconstruction of the display and the camera view-frustums. (b)-(f) Images of the boundary of the screen captured for multi-view registration. The colors of the borders of the images and the view-frustums show which image is captured from which view. (g) A registered image on the display using this multi-view registration. ", "caption_bbox": [59, 303, 692, 347]}, {"image_id": 8, "file_name": "439_08.png", "page": 8, "dpi": 300, "bbox": [375, 55, 694, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Comparison between the accuracy of the recov- ered extrinsic parameters using our method and the method proposed by Sajadi et. al. [SM10c] for setups with 4 to 10 camera views. The results show considerable improvement when the distance between the center of rotation of the PTU and the COP of the camera is larger than 0.01 which is the case for our setups in practice. ", "caption_bbox": [391, 294, 692, 398]}, {"image_id": 9, "file_name": "439_09.png", "page": 8, "dpi": 300, "bbox": [60, 55, 376, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Here we compare the geometric registration us- ing our high-end SLR camera (13 Megapixels) (top) with that achieved with our low resolution webcam (1.3 Megapix- els)(bottom). Note that there is no degradation in the accu- racy of registration, even for challenging contents like text and single pixel lines for latitudes and longitudes. ", "caption_bbox": [59, 376, 360, 465]}, {"image_id": 10, "file_name": "439_10.png", "page": 9, "dpi": 300, "bbox": [375, 55, 694, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Accuracy of camera parameter estimation in presence of projector non-linearity. ", "caption_bbox": [391, 279, 692, 307]}, {"image_id": 11, "file_name": "439_11.png", "page": 9, "dpi": 300, "bbox": [62, 55, 378, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Accuracy of camera parameter estimation in presence of deviation of the screen from being a dome. ", "caption_bbox": [59, 279, 360, 307]}], "440": [{"image_id": 0, "file_name": "440_00.png", "page": 1, "dpi": 300, "bbox": [91, 380, 661, 524], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An example of particle data from the MC3 dark matter simulation. The images show the comparison between full resolution data and statistically-based level-of-detail data samples generated via in-situ sampling. ", "caption_bbox": [58, 532, 691, 560]}, {"image_id": 1, "file_name": "440_01.png", "page": 2, "dpi": 300, "bbox": [73, 735, 347, 798], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The end-to-end pipeline from data generation to ex- ploratory post-analysis of large-scale particle data. ", "caption_bbox": [58, 807, 359, 834]}, {"image_id": 2, "file_name": "440_02.png", "page": 3, "dpi": 300, "bbox": [419, 464, 665, 549], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The left tree shows 1D particle data being sorted into a kd-tree. The right tree shows the generation of a four particle ran- dom sample of the data. One random sample (red numbers) is taken per stratum (leaf nodes) and joined into one aggregate sample. ", "caption_bbox": [391, 559, 692, 613]}, {"image_id": 3, "file_name": "440_03.png", "page": 4, "dpi": 300, "bbox": [88, 362, 332, 485], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The creation of a two-level LOD hierarchy with sample size of four per block (black nodes at top), for 1D particle data on one processor. At the bottom of the kd-tree are the finest grain strata and the red numbers are the random samples for the bottom of the LOD hierarchy. The green numbers are samples propagated to a lower resolution level (one random sample per k samples, this case 2). We ensure that the lowest resolution sample (top of the tree) only has one sample per stratum (color coded nodes and numbers). ", "caption_bbox": [58, 494, 359, 604]}, {"image_id": 4, "file_name": "440_04.png", "page": 4, "dpi": 300, "bbox": [141, 624, 280, 726], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Completion (reduction) of an LOD hierarchy with sam- ple size of four per block, for 1D particle data across four pro- cessors. The green numbers are the random samples propagated to lower resolution levels (one random sample per k samples, this case 2). ", "caption_bbox": [58, 735, 359, 803]}, {"image_id": 5, "file_name": "440_05.png", "page": 5, "dpi": 300, "bbox": [435, 122, 648, 192], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An abstract depiction of LOD particle data under in- creasing resolution with visual continuity. The particles in the lower resolution data are always present in the higher resolution data. ", "caption_bbox": [391, 202, 692, 243]}, {"image_id": 6, "file_name": "440_06.png", "page": 6, "dpi": 300, "bbox": [60, 55, 378, 187], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: An intermediate resolution between two stored levels can be created by a partial block. The top node is a low-resolution block created from the green particles sampled from two high-resolution blocks. The blue particles are particles duplicated in a lower reso- lution block (not shown). The red particles are the particles that are only duplicated in higher resolution blocks. To simulate a finer-grain LOD level, we render all of the blue particles and incrementally add red particles. ", "caption_bbox": [58, 197, 359, 307]}, {"image_id": 7, "file_name": "440_07.png", "page": 7, "dpi": 300, "bbox": [423, 226, 655, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The halo mass function for different sample sizes of 2563 particles. The black curve is the original data. The red, green, and blue curves are .19%, 1.6%, and 12.5% samples, respectively. ", "caption_bbox": [391, 373, 692, 414]}, {"image_id": 8, "file_name": "440_08.png", "page": 7, "dpi": 300, "bbox": [62, 607, 358, 724], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Graphs showing a 32768 sample (red curve) of a 2563 MC3 particle data set (black curve). Both curves exist in all graphs; they occlude each other. Top row is the histogram of the velocity components (vx, vy, vz, left to right). Bottom row is the average value of the velocity component across space (vx in x, vy in y, vz in z, left to right). In both cases, the curves overlap each other showing that the sample is a good approximation (the black occludes the red curve in the top graphs, and vice-versa on the bottom graphs). ", "caption_bbox": [58, 733, 359, 844]}, {"image_id": 9, "file_name": "440_09.png", "page": 7, "dpi": 300, "bbox": [61, 55, 378, 179], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A halo in a low density region is visually located in a low resolution sample by velocity variance color highlighting. LOD resolution increases left to right with zooming. ", "caption_bbox": [58, 188, 359, 229]}, {"image_id": 10, "file_name": "440_10.png", "page": 8, "dpi": 300, "bbox": [405, 428, 675, 588], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Time taken to sample and write the MC3 particle data in-situ per time slice. The left-most bar is the original write time. The other bars are LOD storage with particle duplication. ", "caption_bbox": [391, 596, 692, 638]}, {"image_id": 11, "file_name": "440_11.png", "page": 9, "dpi": 300, "bbox": [73, 493, 348, 681], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Ratio of of our LOD write method time compared to the original write method time. ", "caption_bbox": [58, 690, 359, 717]}, {"image_id": 12, "file_name": "440_12.png", "page": 9, "dpi": 300, "bbox": [73, 55, 378, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Simulation time savings per time slice in different LOD configurations. ", "caption_bbox": [58, 267, 359, 294]}, {"image_id": 13, "file_name": "440_13.png", "page": 9, "dpi": 300, "bbox": [375, 55, 693, 227], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Read block (sample size) I/O times, which vary based on partial read (striding) from a single mechanical disk. Peak throughput on a linear read is approximately 110MB/s on this disk. ", "caption_bbox": [391, 241, 692, 282]}], "441": [{"image_id": 0, "file_name": "441_00.png", "page": 1, "dpi": 300, "bbox": [375, 367, 693, 702], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Fictional distributions of scientists by domain of expertise for two countries. Comparison of weights between these trees is difficult: weight representations are far apart, and there are many visual obstacles in between. ", "caption_bbox": [391, 713, 692, 772]}, {"image_id": 1, "file_name": "441_01.png", "page": 3, "dpi": 300, "bbox": [98, 57, 377, 176], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Left: Abstract depiction of the views and their lay- out. Right: The data types, functions, and view dependen- cies. ", "caption_bbox": [58, 187, 359, 231]}, {"image_id": 2, "file_name": "441_02.png", "page": 4, "dpi": 300, "bbox": [60, 57, 692, 363], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Left: The hierarchy representation of the main view as applied to the novels data set, where cells display the names of their nodes (in this case entity classes). Right: The same representation, but where cells display instance weights with heat maps (every horizontal line represents a novel). The weights are scaled by groups of siblings, which in this case enables the identification of overall abundant words. For example, most novels contain less words that describe something physical than those that describe something abstract, and words that refer to some form of matter mostly refer to a substance. ", "caption_bbox": [58, 375, 691, 449]}, {"image_id": 3, "file_name": "441_03.png", "page": 5, "dpi": 300, "bbox": [58, 554, 362, 778], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Left: Heat map that is hovered over in the main view, it depicts the frequency of words that belong to the \u2018fuel\u2019 class per novel, where novels are ordered by genre. Right: Instance view, showing meta-data for two properties, and frequencies as bars. For illustrative purposes, the entire main view tree is not shown, and the blue lines have been added to show the relation between the low-detail heat map and high-detail instance view. Observe that drama novels make less mention of fuel than adventure novels. ", "caption_bbox": [58, 789, 359, 924]}, {"image_id": 4, "file_name": "441_04.png", "page": 6, "dpi": 300, "bbox": [59, 57, 694, 364], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Combined use of the main, instance, and structure views to analyze the novels data set. The novels have been reordered via hierarchical clustering of the sub-classes of the \u2018psychological feature\u2019 class: \u2018cognition\u2019, \u2018event\u2019, and \u2018motivation\u2019. The \u2018motivation\u2019 class, which is being hovered, shows an interesting pattern that is inspected with the instance view. The high weights appear to be correlated with the genre of the novels, specifically the drama genre. The motivation class has been expanded to inspect the decomposition of its weights over its sub-classes. Because the pattern is interesting, a similarity score has been computed for the motivation class to find classes with similar weights. The colored glyphs and structure view suggest that this weight pattern is not specific to the motivation class or classes that are close to it in the hierarchy. ", "caption_bbox": [58, 376, 691, 481]}, {"image_id": 5, "file_name": "441_05.png", "page": 8, "dpi": 300, "bbox": [378, 57, 691, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The steps taken to project information about the inhabitants of an environment onto a taxonomy. ", "caption_bbox": [391, 223, 692, 251]}, {"image_id": 6, "file_name": "441_06.png", "page": 9, "dpi": 300, "bbox": [88, 57, 377, 227], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Left: Main view node depicting the decomposition of microbe abundance over multiple classes, where samples have an arbitrary order. Center: The same classes, sorted by a meta-data field. The weights of the three right-most classes appear similar while the left-most stands out. Right: The same samples, clustered hierarchically by their weights. Areas of high and low abundance are more clear, improving identification of microbe competition. ", "caption_bbox": [58, 237, 359, 357]}], "442": [{"image_id": 0, "file_name": "442_00.png", "page": 1, "dpi": 300, "bbox": [66, 533, 354, 732], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Mobile devices. (a) Laptop. (b) Smartphone. (c) Tablet. (The figure shows commercial devices, and their screen sizes are 11.6, 4.0, and 7.0 inches, respectively. In the figure, the proportion of the screen sizes is made similar to that of the real devices.) ", "caption_bbox": [59, 744, 360, 818]}, {"image_id": 1, "file_name": "442_01.png", "page": 2, "dpi": 300, "bbox": [66, 442, 354, 557], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Space-optimized tree representations [MR10]. (a) Treemaps. (b) Icicle. (c) SunBurst. ", "caption_bbox": [59, 569, 360, 597]}, {"image_id": 2, "file_name": "442_02.png", "page": 3, "dpi": 300, "bbox": [375, 57, 693, 171], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Hierarchy visualization. (a) Traditional node-link structure. (b) Tablorer. ", "caption_bbox": [391, 183, 692, 211]}, {"image_id": 3, "file_name": "442_03.png", "page": 3, "dpi": 300, "bbox": [65, 57, 378, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: File system navigation. (a) Top down traversal. (b) Backtracking. ", "caption_bbox": [59, 211, 360, 239]}, {"image_id": 4, "file_name": "442_04.png", "page": 3, "dpi": 300, "bbox": [88, 416, 332, 566], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Context and focus areas.", "caption_bbox": [119, 576, 299, 589]}, {"image_id": 5, "file_name": "442_05.png", "page": 4, "dpi": 300, "bbox": [90, 436, 662, 797], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Cyclic permutation relocates the newly selected node n to the first place in the sibling block.", "caption_bbox": [118, 807, 632, 820]}, {"image_id": 6, "file_name": "442_06.png", "page": 4, "dpi": 300, "bbox": [60, 57, 662, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Interactive expansion. (a) Initial layout. (b) Node a is selected. (c) Node l is selected.", "caption_bbox": [134, 402, 617, 415]}, {"image_id": 7, "file_name": "442_07.png", "page": 5, "dpi": 300, "bbox": [90, 57, 693, 471], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Context panning and focus scrolling. (a) The viewing window has been automatically panned to show more informa- tion from the focus area. (b) The context area (with the dotted-line boundaries) would be considered too large. Then, the context area can be reduced, and the focus area can be enlarged, through manual context panning. (c) The focus area is scrolled. In this example, scrolling is limited to the vertical direction because the upper level of the focus area is located at the left. If the upper level is located at the top, the focus area is scrolled horizontally. (d) Not the entire focus area but just the lower level is scrolled. The upper level remains fixed. ", "caption_bbox": [59, 482, 692, 571]}, {"image_id": 8, "file_name": "442_08.png", "page": 6, "dpi": 300, "bbox": [60, 57, 662, 471], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Tablorer views. (a) Default view. (b) Grid view. (c) List view.", "caption_bbox": [197, 483, 552, 496]}, {"image_id": 9, "file_name": "442_09.png", "page": 7, "dpi": 300, "bbox": [158, 57, 693, 538], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Screen shots of visualization models. (a) Tablorer. (b) Treeview. (c) Vertical tree. (d) Horizontal tree. Treeview is provided by Prefuse toolkit, and we implemented Tablorer, Vertical tree, and Horizontal tree also using Prefuse toolkit. The experiments with Tablorer used the default view shown in Fig. 9-(a). ", "caption_bbox": [59, 550, 692, 593]}, {"image_id": 10, "file_name": "442_10.png", "page": 8, "dpi": 300, "bbox": [58, 57, 694, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Comparison of experiment results with four visualization models. (a) Click counts. (b) Panning distances. (c) Completion times. ", "caption_bbox": [59, 326, 692, 354]}, {"image_id": 11, "file_name": "442_11.png", "page": 9, "dpi": 300, "bbox": [73, 57, 378, 447], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Illustration of the expanding mechanisms in four visualization models. ", "caption_bbox": [59, 458, 360, 486]}], "443": [{"image_id": 0, "file_name": "443_00.png", "page": 4, "dpi": 300, "bbox": [60, 57, 676, 222], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Structure-based Ordering for PCP.", "caption_bbox": [262, 232, 489, 245]}, {"image_id": 1, "file_name": "443_01.png", "page": 5, "dpi": 300, "bbox": [375, 57, 699, 284], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Synthetic dataset 1 (see section 5.1.1). From top to bottom: (first) original ordering: rendered with the PCP version of Blaas et al.; structures are visible but high- dimensional structures are hard to identify; (second) the clutter based method of Peng et al. is unable to put the proper dimensions together to visualize the 6D subspace with two clusters and the 3D subspace with four clusters present in the dataset; (third) Ankerst\u2019s method: the two clusters in the 6D subspace are visualized properly but the more complex four clusters in the 3D subspace are missed; (fourth) order- ing with our SBF method: dimensions are ordered in such a way that clusters in both the 6D and 3D subspaces are visible. ", "caption_bbox": [391, 310, 692, 506]}, {"image_id": 2, "file_name": "443_02.png", "page": 5, "dpi": 300, "bbox": [399, 522, 694, 641], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The method of Tatu et al. (Left) Synthetic dataset 1. The first 4 dimensions, with the worst (top) and best (bot- tom) ranked visualization. In the best ranked visualization, the first two dimensions (dim5 and dim10) belong to the 6D subspace with two clusters and the others (dim4 and dim9) are two of the dimensions of the 3D subspace with four clus- ters. (Right) millMillennium dataset. The first four dimen- sions, with the worst (top) and best (bottom) ranked visu- alization. No structures can be observed in the best ranked view. (Image courtesy: Tatu et al. ) ", "caption_bbox": [391, 657, 692, 807]}, {"image_id": 3, "file_name": "443_03.png", "page": 7, "dpi": 300, "bbox": [74, 57, 378, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Dimension hierarchy obtained with Yang\u2019s method and visualized with InterRing [YWR02]. Left: for synthetic dataset 1, the dimensions (dim 3-1-5-8-10-12) of the 6D sub- space with two clusters without any noise are in one clus- ter; however, two of the dimensions (dim4 and dim7) of the 3D subspace with four clusters present in the dataset do not form any \u2018dimension cluster\u2019, and another dimension (dim9) of this 3D subspace forms a \u2018dimension cluster\u2019 with two noise dimensions. Right: millMillennium dataset; similarly to Ankerst\u2019s method, the x, y, z-components of velocity and colors form \u2018dimension clusters\u2019. ", "caption_bbox": [59, 237, 360, 402]}, {"image_id": 4, "file_name": "443_04.png", "page": 7, "dpi": 300, "bbox": [67, 421, 370, 598], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: millMillennium dataset. Top: original ordering. Second from top: ordering by Peng\u2019s clutter-based method. Third from top: reordering by Ankerst\u2019s method. Bottom: SBF reordering. Bimodality of the galaxies is better visible in the SBF ordering. ", "caption_bbox": [59, 626, 360, 700]}, {"image_id": 5, "file_name": "443_05.png", "page": 8, "dpi": 300, "bbox": [92, 316, 329, 532], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: millMillennium dataset. Two of the subspaces re- vealed by SBP reordering. Top: two clusters in a 5D sub- space (VR_dust, lCentralMvir, BV_dust, lvvir, ldiskRadius) can be observed. Bottom: two clusters in a 3D subspace (lrvir, lCentralMvir, VR_dust) are visible. For better visu- alization, clusters of red galaxies are colored in orange by manual selection. ", "caption_bbox": [59, 549, 360, 653]}, {"image_id": 6, "file_name": "443_06.png", "page": 8, "dpi": 300, "bbox": [60, 57, 378, 185], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Synthetic dataset 2 (see section 5.1.1). Two of the subspaces revealed by the SBP reordering method. Top: three clusters in a 5D subspace can be observed. Bottom: four clusters in a 4D subspace are visible. ", "caption_bbox": [59, 205, 360, 264]}, {"image_id": 7, "file_name": "443_07.png", "page": 9, "dpi": 300, "bbox": [87, 513, 329, 689], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: SBF reordering of synthetic dataset 2. Top: for PCP. Bottom: for SPM. Two groups of dimensions, one with three clusters in a 5D subspace and one with four clusters in a 3D subspace, are better visible in PCP than in SPM. ", "caption_bbox": [59, 699, 360, 758]}, {"image_id": 8, "file_name": "443_08.png", "page": 9, "dpi": 300, "bbox": [103, 319, 346, 412], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: milliMillennium dataset: dimensions lxrayLum vs. lvvir. Left: visualized with PCP. Right: visualized with SPM. The presence of three dense clusters is apparent in SPM but less obvious in PCP. ", "caption_bbox": [59, 430, 360, 489]}, {"image_id": 9, "file_name": "443_09.png", "page": 9, "dpi": 300, "bbox": [105, 57, 693, 222], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: SPM visualization of synthetic dataset 2. Left: original ordering. Middle: ordering by the clutter-based method of Peng et al.; some grouping of cluster and noise dimensions can be observed. Right: ordering by the SBS method after filtering; only cluster dimensions are visualized since all the noise dimensions are filtered out by the method. ", "caption_bbox": [59, 235, 692, 278]}], "444": [{"image_id": 0, "file_name": "444_00.png", "page": 4, "dpi": 300, "bbox": [375, 57, 671, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Fulfilling of the individual tasks with 2D (red) vs. 3D projections (blue). ", "caption_bbox": [391, 372, 692, 400]}, {"image_id": 1, "file_name": "444_01.png", "page": 4, "dpi": 300, "bbox": [60, 57, 376, 422], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Increased precision of 3D LSP as compared to 2D LSP, measured by Neighborhood Hit and Neighborhood Preservation, for a corpus of scientific papers. ", "caption_bbox": [58, 435, 359, 479]}, {"image_id": 2, "file_name": "444_02.png", "page": 6, "dpi": 300, "bbox": [60, 57, 682, 471], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Projection, clustering, and surface generation in visual space of a 3D LSP on a data set with papers in four areas of knowledge. ", "caption_bbox": [58, 484, 691, 512]}, {"image_id": 3, "file_name": "444_03.png", "page": 6, "dpi": 300, "bbox": [67, 533, 684, 652], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Tasks with the four different surface visualizations (Interface 1-4) and color-coded point clouds (Interface 5).", "caption_bbox": [76, 665, 674, 678]}, {"image_id": 4, "file_name": "444_04.png", "page": 7, "dpi": 300, "bbox": [396, 140, 687, 624], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Coordinating 2D and 3D views for data explo- ration. ", "caption_bbox": [391, 637, 692, 665]}, {"image_id": 5, "file_name": "444_05.png", "page": 8, "dpi": 300, "bbox": [60, 57, 653, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Hierarchical clustering.", "caption_bbox": [288, 266, 461, 279]}, {"image_id": 6, "file_name": "444_06.png", "page": 9, "dpi": 300, "bbox": [88, 465, 332, 809], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visualizations of the feature space of the parti- cle simulation data. Star Coordinates views on the left, LSP views on the right. ", "caption_bbox": [58, 821, 359, 865]}, {"image_id": 7, "file_name": "444_07.png", "page": 9, "dpi": 300, "bbox": [83, 57, 693, 403], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Photo features projections. Color is target class.", "caption_bbox": [228, 416, 523, 429]}], "445": [{"image_id": 0, "file_name": "445_00.png", "page": 3, "dpi": 300, "bbox": [130, 57, 378, 187], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Piecewise-linear function defined on a triangle in a 2D mesh. ", "caption_bbox": [58, 201, 359, 231]}, {"image_id": 1, "file_name": "445_01.png", "page": 4, "dpi": 300, "bbox": [60, 57, 698, 227], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Multifield comparison              F                               p measure \u03b7 computed for synthetic        functions defined on a 2D grid with the center as origin. (a) Two functions f1 (x, y) = (x \u2212 0.25) + y and f2 (x, y) = (x + 0.25)2 + y2 . The measure \u03b7 F attains high values on the                                            2     2                                                                 p Jacobi set and low values where the gradients are orthogonal. (b) The sinusoidal function f1 (x, y) = sin(3(x + y)) and the linear                                                                                  \u221a                              \u221a function f2 (x, y) = y. (c) Three functions f1 (x, y) = x + y2 , f2 (x, y) = 12 ( 3x + y), and f3 (x, y) = 12 (\u2212 3x + y). (d) One                                                        p                                                          2 hundred different scalar functions, whose gradient vectors have unit magnitude and directions are chosen uniformly at random at points on the two axes and are chosen to be some constant at remaining points on the plane. ", "caption_bbox": [58, 241, 691, 335]}, {"image_id": 2, "file_name": "445_02.png", "page": 4, "dpi": 300, "bbox": [128, 365, 292, 481], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Two pairs of equivalent configurations of gradients of three functions described in Figure 2c. Gradient vectors subtend an angle of 120\u25e6 at points along the Y -axis (top) and are more closely aligned with each other at points along the X-axis. ", "caption_bbox": [58, 492, 359, 568]}, {"image_id": 3, "file_name": "445_03.png", "page": 5, "dpi": 300, "bbox": [375, 57, 706, 211], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) The hurricane track released by the US Na- tional Hurricane Center (source: http://www.nhc.noaa.gov). The track relevant to the period of simulation is between point 17 and point 19 when the hurricane struck the coast. (b) Multifield comparison measure computed for nine pres- sure fields. The region in red with high values of the com- parison measure corresponds to the trace of the eye of the hurricane. Land is shown in green. ", "caption_bbox": [391, 225, 692, 347]}, {"image_id": 4, "file_name": "445_04.png", "page": 6, "dpi": 300, "bbox": [60, 57, 692, 228], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Fronts in Hurricane Isabel at hour 10. (a) Region of simulation. Land mass is shown in red. (b) Volume rendering (top view) of horizontal wind speed Uf. (c) Volume rendering (top view) of horizontal wind speed Vf. (d) Volume rendering (top view) of multifield comparison measure \u03b7 F computed for Uf and Vf showing the rainbands at different fronts. The location of the fronts is not available from the individual scalar fields Uf and Vf. ", "caption_bbox": [58, 242, 691, 303]}, {"image_id": 5, "file_name": "445_05.png", "page": 6, "dpi": 300, "bbox": [72, 315, 686, 459], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Fronts in Hurricane Isabel at hour 40. (a) Volume rendering (top view) of horizontal wind speed Uf. (b) Volume rendering (top view) of horizontal wind speed Vf. (c) Volume rendering (top view) of multifield comparison measure \u03b7 F computed for Uf and Vf showing the rainbands at different fronts. The cold front leads the warm front resulting in an occlusion. (d) Volume rendering from a different viewpoint . ", "caption_bbox": [58, 473, 691, 534]}, {"image_id": 6, "file_name": "445_06.png", "page": 8, "dpi": 300, "bbox": [60, 57, 667, 597], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Multifield comparison measure \u03b7 F computed for wind velocities over the years 1960-2009, where the comparison is over a set of six hundred 3D vector fields. (a) Map of world showing wind patterns (source: Wikipedia) (b) Distribution of \u03b7 F over surface corresponding to pressure elevation 925 hPa. The dark red regions correspond to the wind patterns. (c) Distribution of \u03b7 F over surface corresponding to pressure elevation 300 hPa. The temperate regions exhibit higher values. (d) Storm track for the years 1985-2005 (source: Wikipedia) (e) Distribution of \u03b7 F after removing regions with low mean temperature (< 27\u25e6 C). Red regions correspond to the storm tracks. The world map is overlaid for clarity. ", "caption_bbox": [58, 610, 691, 702]}, {"image_id": 7, "file_name": "445_07.png", "page": 9, "dpi": 300, "bbox": [64, 428, 353, 560], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Stability in the comparison measure for Isabel. (a) Volume rendering (top view) of multifield comparison measure \u03b7 F computed after adding Gaussian noise (standard deviation = 1) to the fields Uf and Vf. The rain bands are still clearly visible. (b) Graph showing near linear relation- ship between the standard deviation of the noise in the input \u03c3in , and the mean deviation of the comparison measure \u03c3\u03b7 F . ", "caption_bbox": [58, 574, 359, 682]}, {"image_id": 8, "file_name": "445_08.png", "page": 9, "dpi": 300, "bbox": [65, 57, 378, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Analyzing phases of combustion using an aggre- gate \u03b7 F,t of the multifield comparison measure over the do- main within a time step t. The set F = {H2 , O2 , HO2 }. The plot of \u03b7 F,t (blue) over time captures more phases of the ", "caption_bbox": [58, 274, 359, 329]}], "446": [{"image_id": 0, "file_name": "446_00.png", "page": 4, "dpi": 300, "bbox": [375, 57, 691, 216], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Left: Control points from all Di simultaneously embedded in the visual space and used to constrain the Laplacian systems of PLP. Right: Projection from a single global Laplacian system constrained by the same control points used on the left. PLP (left) is more accurate (lower stress) and faster. ", "caption_bbox": [391, 228, 692, 317]}, {"image_id": 1, "file_name": "446_01.png", "page": 5, "dpi": 300, "bbox": [74, 57, 693, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Given a projection (a) the user can drag and reposition projected instances (b). Neighborhood graphs are updated to reflect the user defined neighborhood relationship (c), thus modifying the Laplacian matrices and the projection (d). ", "caption_bbox": [59, 266, 692, 294]}, {"image_id": 2, "file_name": "446_02.png", "page": 6, "dpi": 300, "bbox": [60, 57, 699, 558], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: original-distance \u00d7 projected-distance scatter plots. From left to right PLP, PLMP [PSN10], Fastmap [FL95], Hybrid [JM04], Landmarks MDS [dST04], L-Isomap [dST03], LSP [PNML08], Pekalska [PdRDK99], Pivot- MDS [BP07], Random Projection [Ach03] and Glimmer [IMO09]. Top-left numbers are respectively the normalized stress and computational time in seconds. ", "caption_bbox": [58, 568, 691, 627]}, {"image_id": 3, "file_name": "446_03.png", "page": 7, "dpi": 300, "bbox": [63, 57, 375, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Unfolding problem. (a) The Swiss Roll data set. (b) PLP using force-scheme and Euclidean distances to em- bed control points. (c) PLP using Isomap to embed control points. (d) PLMP using Isomap to embed representative in- stances. ", "caption_bbox": [59, 366, 360, 440]}, {"image_id": 4, "file_name": "446_04.png", "page": 7, "dpi": 300, "bbox": [375, 57, 693, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Changing the projection map by repositioning control points. Top right window shows the position of the control points. (a) Projection generated by PLP; control points embedding by force scheme. (b) PLP after reposition- ing control points in accordance with its classes. (c) and (d) Projections generated by PLMP and LSP respectively using the same control points as in (b). ", "caption_bbox": [391, 444, 692, 548]}, {"image_id": 5, "file_name": "446_05.png", "page": 8, "dpi": 300, "bbox": [375, 57, 681, 576], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) Projection of image collection. Control point positioning by force scheme. Color border is class. Separa- tion is not good. (b) New projection repositioning control points. Separation is good. Top right window is position of control points. ", "caption_bbox": [391, 589, 692, 663]}, {"image_id": 6, "file_name": "446_06.png", "page": 8, "dpi": 300, "bbox": [60, 57, 377, 454], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Stress and computational times boxplots.", "caption_bbox": [80, 467, 338, 480]}, {"image_id": 7, "file_name": "446_07.png", "page": 9, "dpi": 300, "bbox": [62, 57, 375, 578], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Playlist maker: User selects seed tracks (top-left). Control points are embedded in the visual space and some of them are displayed (a). User interacts with control points grouping the most similar ones (b). Projection of the whole data set and playlists creation(c). ", "caption_bbox": [59, 588, 360, 662]}], "447": [{"image_id": 0, "file_name": "447_00.png", "page": 3, "dpi": 300, "bbox": [116, 57, 378, 372], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview of system workflow. The user selects a node and the interaction is logged. Collaborative filter- ing, relevance filtering, or a combination of both approaches are used to generate recommendations. Finally, recommen- dations are passed to the suggestion-aware layout algorithm and displayed to the user. ", "caption_bbox": [59, 386, 360, 475]}, {"image_id": 1, "file_name": "447_01.png", "page": 4, "dpi": 300, "bbox": [375, 57, 675, 216], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The suggestion-aware layout first calculates node positions based on outer edge connections, then improves node positions by looking at inner edge connections. The layout minimizes edge crossings and edge-node bisections (middle panel). ", "caption_bbox": [391, 230, 692, 304]}, {"image_id": 2, "file_name": "447_02.png", "page": 4, "dpi": 300, "bbox": [60, 57, 377, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Components of our network visualization. When a node is selected, up to eight recommended nodes (red rings) are displayed in a circle around it. Recommendations are based on interaction history across the current user and all previous users (collaborative filtering), as well as centrality and similarity metrics. Explicit edges are direct connections that exist in the network, while implicit edges are indirect connections. Note that for an implicitly linked node to be recommended, it must be in the top eight most relevant nodes for the current selection. ", "caption_bbox": [59, 307, 360, 457]}, {"image_id": 3, "file_name": "447_03.png", "page": 5, "dpi": 300, "bbox": [90, 57, 693, 366], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The user interface. The left panel is an overview of the graph. The center panel is our recommendation system with suggestion-aware layout. An ontology graph of all node properties is in the upper right. The bottom right panel allows users to restrict displayed nodes to specified search terms. ", "caption_bbox": [59, 376, 692, 419]}, {"image_id": 4, "file_name": "447_04.png", "page": 6, "dpi": 300, "bbox": [58, 57, 377, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The implicit link viewer shows how the implicit link between Euripides and Heraclitus is formed by display- ing a path in the upper right corner. ", "caption_bbox": [59, 264, 360, 307]}, {"image_id": 5, "file_name": "447_05.png", "page": 7, "dpi": 300, "bbox": [375, 57, 693, 437], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) Navigating from 200 to 1 and (b) from 200 to 5 show similar recommendations of high centrality (306, 309). (c, d) Investigating 306 and 309 reveals only one new recommendation common to both, phone #300. ", "caption_bbox": [391, 450, 692, 509]}, {"image_id": 6, "file_name": "447_06.png", "page": 7, "dpi": 300, "bbox": [133, 486, 287, 633], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Device #200 has both implicit and explicit con- nections with its recommendations. ", "caption_bbox": [59, 644, 360, 672]}, {"image_id": 7, "file_name": "447_07.png", "page": 7, "dpi": 300, "bbox": [73, 57, 378, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Overview of a fictional criminal organization phone call network. Nodes represent cell phones and edges represent calls made between them. Nodes are colored by centrality (green: high centrality; blue: low centrality). Aside from several nodes with high centrality, it is difficult to distinguish any clusters or patterns in the network. The or- ganization leader\u2019s cell phone (arrow) is indistinguishable from other cell phones. ", "caption_bbox": [59, 345, 360, 465]}, {"image_id": 8, "file_name": "447_08.png", "page": 8, "dpi": 300, "bbox": [134, 377, 284, 555], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Overview of Political Blogosphere dataset. Lib- eral blogs cluster together above and conservative blogs cluster together below. ", "caption_bbox": [59, 565, 360, 608]}, {"image_id": 9, "file_name": "447_09.png", "page": 8, "dpi": 300, "bbox": [60, 57, 377, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Overview filtered to show only nodes that connect to group 1 (0, 1, 2, 3, 5, 200) and group 2 (300, 306, 309, 360, 397). ", "caption_bbox": [59, 307, 360, 350]}, {"image_id": 10, "file_name": "447_10.png", "page": 9, "dpi": 300, "bbox": [64, 57, 693, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: (a) Despite division in the blog network across party lines, selecting dailywarnews.blogspot.com shows recommen- dations for both liberal (blue) and conservative (red) blogs. (b) Navigation of conservative blogs shows many repeat recom- mendations, while (c) navigation of liberal blogs shows many unique recommendations, indicating that conservative blogs are more centralized than liberal blogs. (d) When windsofchange.net is selected, only conservative blogs are recommended. This may indicate that it was misclassified as a liberal blog. ", "caption_bbox": [59, 246, 692, 320]}], "448": [{"image_id": 0, "file_name": "448_00.png", "page": 3, "dpi": 300, "bbox": [61, 57, 378, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Maximal movement in PrEd. (a) The maximal movement sectors of v. (b) The corresponding Mv , contain- ing the radius of each sector. (c) Movement limitation during the node displacement phase. Fv belongs to A5v , so its mod- ule will be clamped to M5v . ", "caption_bbox": [58, 238, 359, 312]}, {"image_id": 1, "file_name": "448_01.png", "page": 4, "dpi": 300, "bbox": [60, 57, 687, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Surrounding edge computation. (a) An example of plane graph. (b) The graph is divided into connected components. These components are organised into a hierarchy via containment. (c) The surrounding edges Sv are computed as the edges of the faces in \u03a6v = {F, H}, that contain v. The edges e \u2208                                                       / Sv are dashed. (d) The disconnected boundary of the face F is computed from the connected boundaries F\u0304, according to Figure 2b. ", "caption_bbox": [59, 254, 692, 313]}, {"image_id": 2, "file_name": "448_02.png", "page": 4, "dpi": 300, "bbox": [60, 358, 356, 467], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Surrounding edge detection for non-plane graphs. (a) A non-plane graph G. (b) Generation and labelling of G\u0302. (c) The surrounding edges are computed using the labels. ", "caption_bbox": [59, 482, 360, 526]}, {"image_id": 3, "file_name": "448_03.png", "page": 5, "dpi": 300, "bbox": [59, 57, 378, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Maximal movement computation when ve \u2208 e. The dashed sectors are unlimited. (a) The result with PrEd\u2019s rules. (b) The result with ImPrEd\u2019s rules. ", "caption_bbox": [58, 276, 359, 320]}, {"image_id": 4, "file_name": "448_04.png", "page": 5, "dpi": 300, "bbox": [59, 351, 362, 493], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Maximal movement computation when ve \u2208  / e. The dashed sectors are unlimited. (a) The result with PrEd\u2019s rules. (b) The result with ImPrEd\u2019s rules. ", "caption_bbox": [58, 507, 359, 551]}, {"image_id": 5, "file_name": "448_05.png", "page": 6, "dpi": 300, "bbox": [58, 57, 378, 183], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Stability to the input parameters of PrEd and Im- PrEd. (a) PrEd with \u03b4 = 5 and \u03b3 = 2. (b) PrEd with \u03b4 = 2 and \u03b3 = 5. (c) ImPrEd with \u03b4 = 5 and \u03b3 = 2. (d) ImPrEd with \u03b4 = 2 and \u03b3 = 5. ", "caption_bbox": [59, 198, 360, 257]}, {"image_id": 6, "file_name": "448_06.png", "page": 7, "dpi": 300, "bbox": [375, 57, 693, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Average running times of PrEd and ImPrEd for 100, 250 and 500 iterations, over the Euler diagrams gen- eration graphs described in Section 6. ImPrEd (PP) is the pre-processing step (Section 4.1). We only applied ImPrEd to gGraphB as the input includes edges marked as crossable, which cannot be handled by PrEd. Green numbers indicate improvements, red numbers indicate slower execution. ", "caption_bbox": [391, 579, 692, 683]}, {"image_id": 7, "file_name": "448_07.png", "page": 7, "dpi": 300, "bbox": [61, 57, 378, 181], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Growth of the average computation time for single iteration, with respect to the size of the random graphs presented in Section 6. a) Random plane graphs. b) Ran- dom non-plane graphs. ImPrEd (F) has not be applied to the non-plane graphs as flexible edges should not cross. ", "caption_bbox": [391, 277, 692, 351]}, {"image_id": 8, "file_name": "448_08.png", "page": 8, "dpi": 300, "bbox": [97, 298, 322, 442], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Result of the application of ImPrEd on gGraphB. In this graph, black edges represent the set bound- aries and have been labelled as flexible. Grey edges represent element relationships and have been labeled as crossable. ", "caption_bbox": [59, 456, 360, 515]}, {"image_id": 9, "file_name": "448_09.png", "page": 8, "dpi": 300, "bbox": [58, 57, 378, 214], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Layout improvement of PrEd\u2019s example graph. Both algorithms executed 100 iterations. a) Using PrEd [Ber00, Figure 1a]. b) Using ImPrEd (R). ", "caption_bbox": [59, 229, 360, 273]}, {"image_id": 10, "file_name": "448_10.png", "page": 9, "dpi": 300, "bbox": [60, 362, 693, 684], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Layout improvement of graphs involved in the generation of Euler diagrams. In the first row, iGraphA. Parameters: \u03b4 = 27, \u03b3 = 21, 250 iterations. The node diameter is set to 10 to better show the graph proportions. In the second row, gGraphA. Parameters: \u03b4 = 5, \u03b3 = 4, 250 iterations. a,d) Using PrEd. b,e) Using ImPrEd (R). c,f) Using ImPrEd (F). ", "caption_bbox": [59, 699, 692, 743]}, {"image_id": 11, "file_name": "448_11.png", "page": 9, "dpi": 300, "bbox": [82, 57, 693, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Layout improvement of a randomly generated plane graph. All algorithms used the parameters \u03b4 = 10, \u03b3 = 10, 250 iterations. a) Using PrEd. b) Using ImPrEd (R). c) Using ImPrEd (F). ", "caption_bbox": [58, 304, 691, 333]}], "449": [{"image_id": 0, "file_name": "449_00.png", "page": 4, "dpi": 300, "bbox": [60, 56, 661, 184], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Simplified example of community identification. In timestep T1 there are two communities: orange and purple. In timestep T2, C remains affiliated with the orange community despite its transient interaction with Q and R. On the other hand, X and Y split from the purple community to form the green community ", "caption_bbox": [58, 197, 691, 241]}, {"image_id": 1, "file_name": "449_01.png", "page": 5, "dpi": 300, "bbox": [59, 614, 362, 757], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visualization of the example presented in Figure 1. There are two communities at timesteps T1 and T2. At T3 two individuals, X and Y, leave their community to form a new community at T3. ", "caption_bbox": [58, 771, 359, 830]}, {"image_id": 2, "file_name": "449_02.png", "page": 6, "dpi": 300, "bbox": [60, 56, 631, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Portion of US House of Representatives roll call votes covering the period of March 3 through 18, 2010. Red threads represent Republicans while the blue threads represent Democratic representatives. Hovering over the timeline with the mouse brings up a description of the proposed resolution at the highlighted timestep. ", "caption_bbox": [58, 324, 691, 368]}, {"image_id": 3, "file_name": "449_03.png", "page": 7, "dpi": 300, "bbox": [420, 672, 664, 870], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Selection of a single thread enables one to see the corresponding individual\u2019s affiliation over time within the context of the community structure. ", "caption_bbox": [391, 880, 692, 924]}, {"image_id": 4, "file_name": "449_04.png", "page": 7, "dpi": 300, "bbox": [375, 56, 693, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Detailed view of the community structure of the House of Representatives between March 11 and 15, 2010. ", "caption_bbox": [391, 410, 692, 438]}, {"image_id": 5, "file_name": "449_05.png", "page": 8, "dpi": 300, "bbox": [60, 56, 599, 269], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The visualization environment used in the user study showing the Grevy\u2019s zebra dataset. The left view is the space- time cube showing movement of zebra communities in space-time, while the view on the right shows the community structure timeline. Color pins in the community structure timeline (to the left of community labels) associate a unique color with every community for cross-reference with the space-time cube. Individuals were labeled with an ID number followed by their sex code (F/M). The size of individual lines have been increased to make them more clear. ", "caption_bbox": [58, 279, 691, 353]}], "450": [{"image_id": 0, "file_name": "450_00.png", "page": 1, "dpi": 300, "bbox": [375, 310, 693, 849], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization of the prostate gland and surround- ing anatomy. The prostate is between the rectum (shown in burnt orange) and the pelvic bone. Suspected areas of can- cer and hemorrhages in the gland are indicated by blue and red, respectively, and the seminal vesicles are in green. ", "caption_bbox": [391, 860, 692, 934]}, {"image_id": 1, "file_name": "450_01.png", "page": 3, "dpi": 300, "bbox": [375, 56, 693, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Natural alignment of three T2 -w MR slices, with axial tinted red, sagittal blue, and coronal green. The pro- static capsule aligns well between slices (yellow circles). ", "caption_bbox": [391, 248, 692, 292]}, {"image_id": 2, "file_name": "450_02.png", "page": 4, "dpi": 300, "bbox": [375, 56, 693, 210], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Integrating the score volume with slice-based viewing. The score information is overlaid on the MR slices, with blue indicating T2 scores and red indicating T1 scores. ", "caption_bbox": [391, 218, 692, 263]}, {"image_id": 3, "file_name": "450_03.png", "page": 5, "dpi": 300, "bbox": [58, 56, 693, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Rendering examples of individual score values. (a) The T2 score values with blue indicating cancer. (b) The T1 score values with red indicating hemorrhages. (c) The MRSI score values with purple indicating elevated ratios. ", "caption_bbox": [58, 241, 691, 269]}, {"image_id": 4, "file_name": "450_04.png", "page": 5, "dpi": 300, "bbox": [435, 290, 649, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Seminal vesicles indicating bilateral invasion.", "caption_bbox": [399, 365, 682, 378]}, {"image_id": 5, "file_name": "450_05.png", "page": 6, "dpi": 300, "bbox": [77, 254, 676, 403], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Rendering example of T2 (blue) and T1 (red) scores with visibility persistence for the T2 score (green).", "caption_bbox": [95, 409, 656, 424]}, {"image_id": 6, "file_name": "450_06.png", "page": 6, "dpi": 300, "bbox": [58, 56, 693, 219], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Rendering examples of the score values with various levels of transparency.", "caption_bbox": [160, 224, 590, 237]}, {"image_id": 7, "file_name": "450_07.png", "page": 7, "dpi": 300, "bbox": [375, 56, 693, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Screenshot of the user interface with examples of light blue user painted regions in both 3D and 2D views. ", "caption_bbox": [391, 302, 692, 330]}, {"image_id": 8, "file_name": "450_08.png", "page": 7, "dpi": 300, "bbox": [109, 56, 378, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Viewing the angle between the prostate and the rectum (endorectal coil), looking towards the patient\u2019s head. ", "caption_bbox": [58, 252, 359, 280]}, {"image_id": 9, "file_name": "450_09.png", "page": 8, "dpi": 300, "bbox": [60, 56, 689, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Typical dataset properties.", "caption_bbox": [285, 267, 465, 280]}], "451": [{"image_id": 0, "file_name": "451_00.png", "page": 1, "dpi": 300, "bbox": [375, 340, 694, 759], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Anatomic features of parent vessel and ostium.", "caption_bbox": [397, 771, 686, 784]}, {"image_id": 1, "file_name": "451_01.png", "page": 3, "dpi": 300, "bbox": [58, 57, 378, 200], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overall exploration workflow with application examples. The step our approach belongs to is highlighted in orange. ", "caption_bbox": [59, 212, 360, 255]}, {"image_id": 2, "file_name": "451_02.png", "page": 4, "dpi": 300, "bbox": [375, 57, 673, 211], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The ostium plane before and after remeshing.", "caption_bbox": [401, 225, 681, 238]}, {"image_id": 3, "file_name": "451_03.png", "page": 6, "dpi": 300, "bbox": [60, 57, 691, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Global Scope Overview (upper row - overview, lower row - details): By applying the slow flow enhancement, the flow structures within the aneurysm become visible. A slower inner vortex is enclosed by a faster one while the surface near flow is slow again (A). The fast flow enhancement shows how the flow changes from laminar (C) to turbulent (B). When only representing one of the flow directions, structures like regurgitations (D) or the change of the vortex orientation (E - F) due to the collision with the parent vessel flow become visible. The arrows encode the flow direction. ", "caption_bbox": [59, 371, 692, 445]}, {"image_id": 4, "file_name": "451_04.png", "page": 7, "dpi": 300, "bbox": [61, 57, 694, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Ostium Scope Overview: At the first level of detail, velocity (color coded) and volumetric flow rate (contour lines) are represented, while the red contour separates in- from outflow (a). Short streamlines and cone-glyphs provide directional information; structures like vortices become visible (b). Blurred contextual streamlines help to relate between global scope vortex and ostium plane vortex - view from below (c). ", "caption_bbox": [59, 304, 692, 363]}, {"image_id": 5, "file_name": "451_05.png", "page": 7, "dpi": 300, "bbox": [61, 390, 691, 574], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Local Scope Overview: The context for the parent vessel widget is provided by blurred global scope centerlines. A height field represents the velocity profile (A) while a LIC on the backsides conveys flow characteristics (B). The aneurysm widget provides two transformation modes: Translation along the central aneurysm axis (C) and rotation around the widget center (D). By selecting a point on the widget plane, additional probing planes can be added (E). In (E) blurred streamlines are added as context while in (C) and (D) glyphs encode the flow direction. ", "caption_bbox": [59, 586, 692, 660]}, {"image_id": 6, "file_name": "451_06.png", "page": 9, "dpi": 300, "bbox": [61, 57, 693, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Exploration of different datasets: The aneurysm exploration widget in translation mode in a large basilar aneurysm(a). The VISC dataset has a complex bifurcation below the aneurysm, the in-/outflow enhancement exhibits a cen- tral inflow (b). The parent vessel widget (c) and the ostium scope (d) applied to measured flow data. ", "caption_bbox": [59, 285, 692, 328]}], "452": [{"image_id": 0, "file_name": "452_00.png", "page": 3, "dpi": 300, "bbox": [391, 576, 693, 710], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Three layers of the rendering pipeline. Pipeline steps are in the top layer, which are subdivided into a subset of pipeline functions. The GLSL code itself is located below, in the shader function code layer. ", "caption_bbox": [391, 726, 692, 785]}, {"image_id": 1, "file_name": "452_01.png", "page": 4, "dpi": 300, "bbox": [54, 220, 367, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Pipeline function to obtain shading from a light source using a library function. The function reads the gra- dients from the global struct and writes both, diffuse and specular multipliers back into the struct. ", "caption_bbox": [59, 397, 360, 456]}, {"image_id": 2, "file_name": "452_02.png", "page": 4, "dpi": 300, "bbox": [54, 682, 367, 793], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The library function returns diffuse and specular multipliers as a vec2 required for volume shading. ", "caption_bbox": [59, 807, 360, 835]}, {"image_id": 3, "file_name": "452_03.png", "page": 5, "dpi": 300, "bbox": [59, 57, 376, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Overview of the composed SuperShader code of the pipeline with library and pipeline function. (b) The 16 pipeline steps are grouped in four main rendering steps. ", "caption_bbox": [59, 421, 360, 464]}, {"image_id": 4, "file_name": "452_04.png", "page": 5, "dpi": 300, "bbox": [392, 514, 693, 591], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Illustration of the shader generation process which has to be repeated for every frame. ", "caption_bbox": [391, 603, 692, 631]}, {"image_id": 5, "file_name": "452_05.png", "page": 6, "dpi": 300, "bbox": [391, 716, 692, 770], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The GUIs of three shader parameter nodes.", "caption_bbox": [406, 781, 677, 794]}, {"image_id": 6, "file_name": "452_06.png", "page": 6, "dpi": 300, "bbox": [375, 57, 693, 336], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The GUI of the custom shader function node. In this example, the function calculates a clip plane and modi- fies the color of the specified volume. Note that the character $ is a wildcard for the current volume name. ", "caption_bbox": [391, 347, 692, 406]}, {"image_id": 7, "file_name": "452_07.png", "page": 6, "dpi": 300, "bbox": [59, 57, 377, 166], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Custom pipeline functions (orange) can be at- tached before or after, or replace the pipeline functions of a selected pipeline step. ", "caption_bbox": [59, 177, 360, 220]}, {"image_id": 8, "file_name": "452_08.png", "page": 7, "dpi": 300, "bbox": [391, 536, 693, 721], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: An illustration of the scene graph used for the visualization of the ablation zone. Varying shader functions are used for the correct composition of the alpha value of the 2D and 3D viewers, respectively. ", "caption_bbox": [391, 732, 692, 791]}, {"image_id": 9, "file_name": "452_09.png", "page": 7, "dpi": 300, "bbox": [60, 129, 361, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The GUI of the shader include node. The function GetEllipsoid() is added into the fragment shader header. ", "caption_bbox": [59, 313, 360, 341]}, {"image_id": 10, "file_name": "452_10.png", "page": 8, "dpi": 300, "bbox": [60, 57, 693, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Image (a) shows a multi-modal rendering of three MR data sets and a defined clip plane. The vessel data sets (red arteries, Time-of-Flight MRI; blue veins, contrast enhanced T1 MRI) are excluded from clipping (b). Image (c) shows enabled shading of all data sets. In (d), additional clip planes are defined to clip the vessels. Data sets courtesy by Lahey Clinic, Boston. ", "caption_bbox": [59, 284, 692, 327]}, {"image_id": 11, "file_name": "452_11.png", "page": 9, "dpi": 300, "bbox": [58, 57, 693, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Two RF applicators are positioned into a tumor. Image (a) shows a 2D visualization of a single slice, cutting the upper located applicator. Image (b) shows the corresponding 3D volume rendering of the same data set. Using the shader pipeline, for each representation, varying visual features are applied (colors, silhouettes, transparency), but the underlying information is equal (ellipsoid properties, image data, tumor mask). Data sets courtesy by RWTH Aachen University Hospital. ", "caption_bbox": [59, 326, 692, 385]}], "453": [{"image_id": 0, "file_name": "453_00.png", "page": 3, "dpi": 300, "bbox": [58, 57, 694, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Drawing pipeline of our method. First step turns an overlapping decomposition into a partition, then nodes are laid out and finally edges linking different clusters are routed using an edge bundling technique. ", "caption_bbox": [58, 231, 691, 259]}, {"image_id": 1, "file_name": "453_01.png", "page": 4, "dpi": 300, "bbox": [60, 57, 682, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of the partitioning process. First, an independent set of pathways is computed and metabolites/reactions without pathways are clustered. Next, connected components are computed (see red surrounded nodes). Finally, topological structures are detected within each cluster. ", "caption_bbox": [58, 310, 691, 354]}, {"image_id": 2, "file_name": "453_02.png", "page": 4, "dpi": 300, "bbox": [438, 387, 641, 571], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Multilevel compound graph associated with graph of Figure 2 and the computed multilevel hierarchy tree. ", "caption_bbox": [391, 581, 692, 609]}, {"image_id": 3, "file_name": "453_03.png", "page": 5, "dpi": 300, "bbox": [68, 689, 351, 777], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Zoomed view on yeast metabolic network (a) bun- dled with the original algorithm of Lambert et al. [LBA10], (b) only using a quadtree. ", "caption_bbox": [58, 790, 359, 834]}, {"image_id": 4, "file_name": "453_04.png", "page": 6, "dpi": 300, "bbox": [391, 647, 693, 792], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Boxplots of computation times in seconds for the 113 organisms of MetExplore DataBaBase [CWV\u2217 10]. ", "caption_bbox": [391, 803, 692, 832]}, {"image_id": 5, "file_name": "453_05.png", "page": 6, "dpi": 300, "bbox": [60, 57, 630, 414], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Yeast metabolic network drawn using our method and driving the set of independent pathways by adding the TCA cycle pathway (pathway responsible for aerobic respiration) in it. In the zoomed view, one can see that the cycle of reactions contained in the TCA cycle pathway has been correctly detected and represented. ", "caption_bbox": [58, 423, 691, 469]}, {"image_id": 6, "file_name": "453_06.png", "page": 7, "dpi": 300, "bbox": [70, 57, 693, 400], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Yeast metabolic network (a) after duplication of nodes belonging to more than 3 pathways -204 nodes have been duplicated- and (b) after duplication of all nodes -835 nodes have been duplicated and one is not belonging to any pathway. Pathways have been surrounded by concave hulls (see section 4) ", "caption_bbox": [58, 411, 691, 457]}, {"image_id": 7, "file_name": "453_07.png", "page": 8, "dpi": 300, "bbox": [404, 334, 680, 485], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Illustrations of the focus+context technique used to emphasize a subgraph pattern in a network. (a) A simple subgraph extracted from a network with two nodes and one edge. The area on which the 3D deformation will be applied is represented. (b) Result of the technique when focusing on the subgraph introduced in (a). ", "caption_bbox": [391, 498, 692, 587]}, {"image_id": 8, "file_name": "453_08.png", "page": 8, "dpi": 300, "bbox": [60, 57, 680, 218], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Illustration of the concave hulls generation process. (a) Subgraph pattern to emphasize. (b) Off-screen rendering of the pattern with all colors set to white. (c) Normalized scalar field obtained by convolving (b) with a Gaussian kernel. (d) Hulls extracted with a threshold of 0.1 when running Marching Square on (c). (e) Hulls extracted with a threshold of 0.5 when running Marching Square on (c). ", "caption_bbox": [58, 231, 691, 290]}, {"image_id": 9, "file_name": "453_09.png", "page": 9, "dpi": 300, "bbox": [61, 57, 693, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Retrieving pathways information using dedicated focus+context interaction techniques. (a) By selecting an element in the network, all pathways containing it are surrounded by concave hulls. (b) and (c) Focusing on a single pathway containing the selected element (colored in red) using a 3D deformation when rendering the network. ", "caption_bbox": [58, 315, 691, 359]}], "454": [{"image_id": 0, "file_name": "454_00.png", "page": 2, "dpi": 300, "bbox": [120, 517, 300, 587], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A Simple Pedigree Error for a Single Marker.", "caption_bbox": [67, 596, 351, 615]}, {"image_id": 1, "file_name": "454_01.png", "page": 4, "dpi": 300, "bbox": [124, 602, 635, 874], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2. The GenotypeChecker visualisation, with individual animals organised along rows and markers along columns. Colour coding is used to indicate errors and uncertainties No account however is made for pedigree structure making it impossible to track the cascading of errors inferred through the inheritance hierarchy. ", "caption_bbox": [58, 883, 671, 931]}, {"image_id": 2, "file_name": "454_02.png", "page": 5, "dpi": 300, "bbox": [392, 218, 690, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A general graph display of a pedigree with 1,792 individuals. The graph concentrates around a few males and the sense of \u2018direction\u2019 in the pedigree is lost. ", "caption_bbox": [390, 439, 688, 486]}, {"image_id": 3, "file_name": "454_03.png", "page": 6, "dpi": 300, "bbox": [61, 238, 360, 443], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A restricted graph layout of a pedigree as seen in many traditional pedigree representations. ", "caption_bbox": [59, 451, 358, 484]}, {"image_id": 4, "file_name": "454_04.png", "page": 6, "dpi": 300, "bbox": [392, 253, 691, 496], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The wide fan-out of animal pedigrees causes problems for many visualisations that handle human pedi- grees well, e.g in the GeneaQuilts system, the number of offspring for some males overwhelms the navigation aid. ", "caption_bbox": [390, 504, 689, 566]}, {"image_id": 5, "file_name": "454_05.png", "page": 7, "dpi": 300, "bbox": [61, 391, 358, 603], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The multiple matrix visualisation was still com- posed of mainly empty cells. ", "caption_bbox": [59, 612, 351, 645]}, {"image_id": 6, "file_name": "454_06.png", "page": 8, "dpi": 300, "bbox": [61, 641, 347, 747], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A hexagonal glyph and colour-coded sections.", "caption_bbox": [66, 771, 352, 790]}, {"image_id": 7, "file_name": "454_07.png", "page": 8, "dpi": 300, "bbox": [60, 59, 688, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A sandwich visualisation of two adjacent generations. Parents are assigned to rows by gender with offspring in- between. Some of the cells in the top row have extended to cover multiple matings with partners. A progressively darker shading of blue indicates individuals with more errors. ", "caption_bbox": [59, 204, 686, 251]}, {"image_id": 8, "file_name": "454_08.png", "page": 9, "dpi": 300, "bbox": [122, 743, 625, 898], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Systematic errors between the bottom two generations. Chosen individuals can be passed to the node-link view.", "caption_bbox": [59, 905, 677, 924]}, {"image_id": 9, "file_name": "454_09.png", "page": 9, "dpi": 300, "bbox": [112, 59, 690, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Aggregated error indicators across a three-generation pedigree with a cut-off that can be controlled through his- tograms with sliders. Here, with the few most troublesome markers excluded, three sires\u2019 offspring are revealed as particu- larly problematic, and the descendants of one sire (12291) selected and highlighted in yellow. ", "caption_bbox": [59, 347, 681, 394]}], "455": [{"image_id": 0, "file_name": "455_00.png", "page": 2, "dpi": 300, "bbox": [60, 55, 667, 351], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) A typical flexibility-response plot showing allosteric response for the CheY protein [MJL10]. A color index at i, j is the response of residue j occurring due to a perturbation at residue i. (b) Analyzing subtle patterns within flexibility measures for a single plot are difficult and placing them in context makes the problem worse. The plot to the left is highlighted in green. ", "caption_bbox": [58, 362, 691, 406]}, {"image_id": 1, "file_name": "455_01.png", "page": 4, "dpi": 300, "bbox": [60, 55, 633, 686], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) A section of the Jigsaw layout is identified for further analysis based on similar global features (2 decompositions). A known plot is highlighted in green. (b) Closer examination of features reveals noticeable differences. Circled regions indicate a point of difference in one parameter set (lower right). (c) The coordinated lens reveals the pattern that the features emphasize. (d) A larger view of the lens shown for clarity. (e) Plot coordinates for the region of interest are found during reconstruction. (f) Detailed analysis allows further mapping of flexibility values to residue numbers among multiple plots. ", "caption_bbox": [58, 698, 691, 772]}, {"image_id": 2, "file_name": "455_02.png", "page": 6, "dpi": 300, "bbox": [60, 55, 378, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Three cooperativity correlation plots [LJ06], [MXJL09] depicting the correlation of flexibil- ity changes. Original correlation values are shown on the top row. Blue indicates co-rigid regions and red indicates co-flexible regions. The data after wavelet transformation (3 decompositions) are on the bottom row and corresponding regions are bounded in red. Orange highlights positive cor- relation changes and green highlights negative correlation changes in all except the last pair. (a) Row patterns are preserved while indicating changes along columns. Because this data set is symmetric, the LH and HL subbands are redundant. Only the LH subband is shown here. (b) Areas of change along both rows and columns are detected. (c) Coarse-grain characteristics are preserved for the entire data set. ", "caption_bbox": [58, 308, 359, 534]}, {"image_id": 3, "file_name": "455_03.png", "page": 7, "dpi": 300, "bbox": [68, 55, 693, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Clustering features for a section of the (a) MDS and (b) Jigsaw layouts. The HH subband after 2 decompositions identifies places of change along both rows and columns while simultaneously reducing the number of data points. In both configurations, the data is separated into areas with plots having many points of change (left side of each layout) and plots with fewer points of change (right side of each layout). ", "caption_bbox": [58, 257, 691, 316]}, {"image_id": 4, "file_name": "455_04.png", "page": 8, "dpi": 300, "bbox": [60, 55, 682, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) A coordinated lens allows simultaneous examination of multiple plots while relating features to the original data. (b) Reconstruction further bridges the feature and original data. Coordinates are marked in the large plot showing the original data and in the context window. A bounding box marks where the features occur in the data before transformation. Coordinates are propagated to the detail view. (c) Detailed analysis occurs for a column section across multiple plots. Left, right, up, and down buttons facilitate navigation during reconstruction and detailed analysis. ", "caption_bbox": [58, 264, 691, 338]}], "456": [{"image_id": 0, "file_name": "456_00.png", "page": 2, "dpi": 300, "bbox": [59, 57, 671, 386], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) The Okubo-Weiss parameter, a standard metric in oceanography for extracting two-dimenisonal vortices, at the ocean surface in the North Atlantic. In order to keep scaling consistent, the Okubo-Weiss value is normalized to its standard deviation. Red regions are those dominated by vorticity, while blue regions are those dominated by strain. The Okubo-Weiss parameter easily identifies several eddies as red circles, but non-eddy meanders in the Gulf Stream are detected as well. (b) The Okubo-Weiss parameter visualized at depth by removing all low-vorticity points. The three-dimensional shapes of the eddies are now made clear: in the region containing the Gulf Stream, several strong eddies reach very deeply into the ocean, while smaller eddies remain near the surface, and the Gulf Stream itself only dominates near the surface. ", "caption_bbox": [58, 394, 691, 499]}, {"image_id": 1, "file_name": "456_01.png", "page": 3, "dpi": 300, "bbox": [73, 57, 693, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: High-vorticity features extracted from the North Atlantic. (a) Features are colored by Okubo-Weiss value, with high- speed water in translucent gray. Where the Gulf Stream turns, additional non-eddy but high-vorticity features appear. We would like to filter out these spurious features. (b) The same features, colored based on the angle each point\u2019s velocity vector makes with an east-pointing vector. Angles are discretized into four domains: angles between east and north (0\u25e6 and 90\u25e6 , colored purple), north to west (90\u25e6 to 180\u25e6 , green), west to south (180\u25e6 to 270\u25e6 , yellow), and south to east (270\u25e6 to 360\u25e6 , red). Features that are definitely eddies contain a nearly equal mixture of all four angle domains, while meanders move primarily in one or two directions and are dominated by one or two angle domains. (c) To use angle domains as a discriminator, we determine for each high-vorticity feature what percentage of its total volume is flowing in each angle domain. We consider only the minimum: if the feature is perfectly balanced between the four domains (eddy-like), the minimum percentage of any domain will be 25%. If the feature contains no points in a domain (non-eddy), its minimum percentage will be 0%. We determined experimentally that requiring a minimum of 8% (colored green) in each domain discriminates well between eddies and spurious high-vorticity features\u2014so features colored green here pass the criterion, while features colored red do not. ", "caption_bbox": [58, 280, 691, 461]}, {"image_id": 2, "file_name": "456_02.png", "page": 7, "dpi": 300, "bbox": [81, 57, 693, 376], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Sea surface height variability in centimeters, defined as the root mean square of the difference between the instanta- neous height of the sea surface and its time-mean, can be used as a proxy measurement for eddy activity. To compare model to observational data directly, we first show sea surface height variability from (a) POP ocean model data and (b) observational data from the AVISO processing of satellite altimetry. In these images, the simulation shows exceptionally good agreement to observation. (c) Our global eddy census, showing the average number of eddies per 1\u25e6 of latitude and longitude, averaged across 350 daily snapshots. Note that the color bar of (c) is reversed relative to that of (a) and (b). Relating the numerical den- sity of eddies in (c) to sea surface height variability, both measures indicate high levels of eddy activity in the same locations. (d) Average eddy thickness in meters as a function of latitude and longitude. We use thickness to refer to the distance from the top of an eddy to the bottom. Notably, thick eddies only have a significant signal in the regions of the same three big currents, the Gulf Stream, Kuroshio Current, and Antarctic Circumpolar Current, where they can get as thick as 5000m. ", "caption_bbox": [58, 384, 691, 534]}, {"image_id": 3, "file_name": "456_03.png", "page": 8, "dpi": 300, "bbox": [81, 390, 670, 603], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) Skeletonized view of the eddy field in the Southern Atlantic, from \u221270\u25e6 to 0\u25e6 longitude and \u221270\u25e6 to 0\u25e6 latitude. The thermocline in this region of the ocean is taken to be 500m. (b) Two-dimensional map of the same eddy field. ", "caption_bbox": [58, 609, 691, 640]}, {"image_id": 4, "file_name": "456_04.png", "page": 8, "dpi": 300, "bbox": [59, 57, 670, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Skeletonized view of the eddy field in the northwest Atlantic, from \u221280\u25e6 to \u221230\u25e6 longitude and 20\u25e6 to 50\u25e6 latitude. Eddies are pictured as blue or red cylinders of vertical extent, with black lines projecting subsurface eddies onto the ocean surface to aid in visual alignment. Blue eddies have positive vorticity (counterclockwise spin), while red eddies have negative vorticity (clockwise spin). The green translucent layer approximates the thermocline. (b) Two-dimensional map of the same eddy field. Eddies that penetrate the thermocline (i.e., that have their minimum depth above the thermocline and their maximum depth below) are represented as colored boxes; these are the eddies that can couple the upper and deep ocean. Coloration is the same used in the skeletonized view: blue for counterclockwise and red for clockwise. Eddies that exist entirely above or below the thermocline are gray diamonds. For this region of the Atlantic, the thermocline is at about 700m [AMM\u2217 10]. ", "caption_bbox": [58, 245, 691, 367]}], "457": [{"image_id": 0, "file_name": "457_00.png", "page": 2, "dpi": 300, "bbox": [59, 57, 682, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Two classic visualizations in geography: (a) plotting the relative frontal positions of 10 calving glaciers as time series, (b) using color-coding glyphs to represent different scales of relative frontal positions, and visualizing temporal changes by juxtapositions (the background color of figure (b) represent sea surface temperature, the glyphs legends goes from red for the furthest retreat to blue for the most advanced position). ", "caption_bbox": [59, 272, 692, 331]}, {"image_id": 1, "file_name": "457_01.png", "page": 3, "dpi": 300, "bbox": [375, 57, 694, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Nine design options presented in the evaluation. Participants were asked to score [0-5] against 7 criteria. (Vi- sualizations generated using Tableux [Tab11].) ", "caption_bbox": [391, 246, 692, 290]}, {"image_id": 2, "file_name": "457_02.png", "page": 6, "dpi": 300, "bbox": [59, 57, 378, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: a) Center of radial projection based on the largest convex polygon inside B (in green); b) snapping of all the termini points (shown as crosses) onto B. ", "caption_bbox": [59, 261, 360, 305]}, {"image_id": 3, "file_name": "457_03.png", "page": 6, "dpi": 300, "bbox": [375, 57, 693, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Spatial mapping algorithm: a) uniform distribution of P loses visual cues; b) distance-based distribution does not help orientation visual cue; c) fixing key references may cause cluttering; d) relaxing angular coordinates produces a radial projection with both distance and orientation cues . ", "caption_bbox": [391, 444, 692, 518]}, {"image_id": 4, "file_name": "457_04.png", "page": 8, "dpi": 300, "bbox": [58, 57, 694, 731], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Radial design example. Area plot of the relative frontal positions of 199 calving glaciers over 10 years (rings). The background image of Greenland is a false color mosaic of Landsat images. ", "caption_bbox": [59, 742, 692, 770]}, {"image_id": 5, "file_name": "457_05.png", "page": 9, "dpi": 300, "bbox": [82, 57, 378, 632], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Radial designs close up. Relative frontal positions of calving glaciers: a) area style plot; b) tube style plot. ", "caption_bbox": [59, 646, 360, 674]}], "458": [{"image_id": 0, "file_name": "458_00.png", "page": 3, "dpi": 300, "bbox": [58, 57, 694, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Flows of refugees are shown between East Africa and Western Europe. Flows having their origin in Sudan are highlighted. The heatmap shows the flow magnitudes by year and origin-destination. By following the lines of the heatmap it is possible to see the flows\u2019 origins, destinations and the changes of the magnitudes over time. Different temporal patterns are visually salient, such as a consistently high number of refugees from Sudan to the United Kingdom and the Netherlands, a marginal decrease to Denmark, Norway and Germany, and an increase to Ireland and Italy. ", "caption_bbox": [59, 452, 692, 526]}, {"image_id": 1, "file_name": "458_01.png", "page": 4, "dpi": 300, "bbox": [58, 57, 378, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Selecting origins using lasso: When a selection is made, the heatmap is updated, so that only the flows between the selected origins and destinations are displayed. ", "caption_bbox": [59, 252, 360, 295]}, {"image_id": 2, "file_name": "458_02.png", "page": 4, "dpi": 300, "bbox": [58, 319, 362, 460], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Selecting a year: Here the year 2001 is selected in the heatmap header, so the countries in the geographic maps are colored according to the total magnitudes of the outgoing and incoming flows in 2001. The heatmap rows are sorted by the maximum (over time) total magnitudes for the origin countries, and by the max magnitude in each row within the same origin country. ", "caption_bbox": [59, 485, 360, 589]}, {"image_id": 3, "file_name": "458_03.png", "page": 6, "dpi": 300, "bbox": [58, 57, 694, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Flow line coloring: The flow lines of a selection of countries are colored by the flow origins, using a qualitative color map. The heatmap rows are sorted by the vertical positions of the origins, so that flows from the same origins are grouped together. This makes it easy to see the parts of the heatmap which represent the flows originated in the selected locations. Iran is selected in the origins map, therefore the lines from Iran are highlighted and are more opaque than the others. ", "caption_bbox": [59, 406, 692, 465]}, {"image_id": 4, "file_name": "458_04.png", "page": 6, "dpi": 300, "bbox": [58, 491, 694, 667], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Flow aggregation: Here all the individual flows between the world\u2019s countries were aggregated by the geographic region of the origin country, so that we could see the totals of the magnitudes of the flows originated in each region. We selected Southern Asia in 2008 in the heatmap, thus the maps are colorized showing the outgoing totals for the countries of Southern Asia and the incoming totals for the countries the flows from Southern Asia went to in 2008. Here we also sorted the heatmap rows by the average magnitude in each row. In 1995, there was apparently a problem with the data acquisition, because flows for many countries are missing. ", "caption_bbox": [59, 693, 692, 782]}, {"image_id": 5, "file_name": "458_05.png", "page": 7, "dpi": 300, "bbox": [58, 57, 694, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Refugees from Ethiopia: The enlarged heatmap shows the differences between the pairs of subsequent years (red shows an increase and blue a decrease in the number of refugees). The rows are sorted by the average number of refugees (over the whole range of years). Ethiopia is selected so that we only see flows from this country. Somalia is highlighted, therefore the flow Ethiopia\u2192Somalia is more opaque than the others. The blue rectangle drawn over the heatmap highlights an interesting \u201cstaircase\u201d pattern. Here we first used the geographical maps making visual queries to select countries. Then we used the heatmap to find the curious temporal pattern, referred back to the geographical maps to see where the other relevant locations are and found out that most of them were neighboring countries. ", "caption_bbox": [59, 406, 692, 510]}, {"image_id": 6, "file_name": "458_06.png", "page": 8, "dpi": 300, "bbox": [58, 57, 694, 307], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Commuters in Slovenia: to Ljubljana and Maribor, the two largest cities. Here we see the differences between the number of commuters in each pair of subsequent years (hence, there are no values for 2000). Red corresponds to an increase and blue to a decrease in the number of commuters. Only the most significant flows are shown here (filtered by the average magnitude). The numbers of non-commuters (the half-blue rows of the heatmap labeled as Maribor to Maribor, and Ljubljana to Ljubljana) were decreasing from 2001 to 2005 and increasing significantly from 2006 to 2008, whereas the number of commuters from almost all the other places were steadily increasing all the time. The flows to Ljubljana come from more distant locations than the flows to Maribor, which all come from nearby towns and villages. ", "caption_bbox": [59, 336, 692, 440]}], "459": [{"image_id": 0, "file_name": "459_00.png", "page": 3, "dpi": 300, "bbox": [84, 286, 336, 424], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Interaction diagram between CPU and GPU.", "caption_bbox": [68, 435, 350, 448]}, {"image_id": 1, "file_name": "459_01.png", "page": 4, "dpi": 300, "bbox": [58, 168, 363, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: In (a) and (b), we show cases that are avoided by edge locking, while (c) shows a conflict between triangles of different fronts. ", "caption_bbox": [59, 276, 360, 319]}, {"image_id": 2, "file_name": "459_02.png", "page": 4, "dpi": 300, "bbox": [58, 510, 363, 656], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) A bridging active edge and (b) an active edge that is part of an existing triangle. Neighbor active edges are shown in green. The dashed red lines are examples of possible perpendicular advancing directions. ", "caption_bbox": [59, 671, 360, 730]}, {"image_id": 3, "file_name": "459_03.png", "page": 4, "dpi": 300, "bbox": [390, 408, 690, 678], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Examples of various cases that are encountered while computing the advancing direction. ", "caption_bbox": [391, 693, 692, 721]}, {"image_id": 4, "file_name": "459_04.png", "page": 5, "dpi": 300, "bbox": [58, 57, 378, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A triangle growing over successive iterations.", "caption_bbox": [66, 270, 351, 283]}, {"image_id": 5, "file_name": "459_05.png", "page": 5, "dpi": 300, "bbox": [432, 710, 655, 812], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A 2D slice of the surface is shown, \u0393. The max- imum distance between \u0393 and the line, l, can only occur where the tangent of \u0393 is parallel to l. ", "caption_bbox": [391, 823, 692, 867]}, {"image_id": 6, "file_name": "459_06.png", "page": 7, "dpi": 300, "bbox": [391, 286, 694, 555], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Our extracted mesh for the jet dataset colored with the distance to the mesh extracted using the method de- scribed in [STS10]. The distance is relative to the longest volume side. ", "caption_bbox": [391, 565, 692, 624]}, {"image_id": 7, "file_name": "459_07.png", "page": 7, "dpi": 300, "bbox": [61, 651, 357, 805], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Extracted mesh for the ridges of FTLE field in ABC flow [Hal01]. ", "caption_bbox": [59, 817, 360, 845]}, {"image_id": 8, "file_name": "459_08.png", "page": 7, "dpi": 300, "bbox": [58, 254, 362, 442], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Mesh extracted for a synthetic test case.", "caption_bbox": [81, 454, 337, 467]}, {"image_id": 9, "file_name": "459_09.png", "page": 8, "dpi": 300, "bbox": [375, 57, 691, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Results of our method compared to two variations of [STS10]. \"S1\" uses the same resolution as our method, while \"S2\" is doubled along each axis. The percentage of dis- carded triangles for our method was 8.6%, 32.7%, 29.4%, and 27.5% for the Cube, ABC, Jet, and Brain data sets, re- spectively. ", "caption_bbox": [391, 430, 692, 519]}, {"image_id": 10, "file_name": "459_10.png", "page": 8, "dpi": 300, "bbox": [59, 57, 378, 563], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Complete ridge surfaces (LCS) of the FTLE field in a turbulent jet. The maximum edge length is set to 10\u03b5 compared to 5\u03b5 for Fig. 9. ", "caption_bbox": [59, 576, 360, 619]}], "460": [{"image_id": 0, "file_name": "460_00.png", "page": 2, "dpi": 300, "bbox": [58, 57, 694, 200], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Volume visualization of isosurface crossing probabilities in uncertain 3D scalar fields (absorption is proportional to probability, distance to mean-surface is color-coded from green (low) to red (high)). (a) Our approach with sample correlations incorporated. (b) Probabilities are vastly overestimated when correlations are not considered. (c) Our approach supports view- independent uncertainty perception by using color to indicate spatial distance. (d) Color mapping based on stochastic distance. ", "caption_bbox": [59, 210, 692, 269]}, {"image_id": 1, "file_name": "460_01.png", "page": 5, "dpi": 300, "bbox": [390, 202, 694, 381], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The sampling along a ray (black) on a 2D slicing plane in a 3D dataset is shown. Negative values (red) are separated from positive values (green) by an 0-isosurface (blue). Its uncertainty is indicated by the blue area, repre- senting the isosurface positions for up to \u00b1\u03c3. The lower illustration shows the positive first crossing probabilities P(Ci+ ) as computed by our IFCP algorithm for each inter- val and under the assumption of zero (green) and maximum (blue) correlation between consecutive sample points. ", "caption_bbox": [391, 391, 692, 526]}, {"image_id": 2, "file_name": "460_02.png", "page": 6, "dpi": 300, "bbox": [375, 57, 694, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: This illustration shows the mean isosurface (green) of a 2D dataset, as well as three positive SDF sur- faces. SDF normal curves (blue) are displayed for several points on the \u03d1\u03b8 (3) surface. Points on the SDF surfaces are color coded with respect to the length of their normal curve to the intersection point with \u03d1\u03b8 (0) - from green (small dis- tance) to red (large distance). The magnitude of the numbers on the axes and on the color bar are related to Euclidean distances in the 2D domain. ", "caption_bbox": [391, 228, 692, 363]}, {"image_id": 3, "file_name": "460_03.png", "page": 7, "dpi": 300, "bbox": [58, 254, 362, 410], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An uncertain 3D signed distance field to a 2D topographic height map is shown. Multiple instances to a randomly displaced height map were generated, and the mean and standard deviations where computed from these instances. SDF isocontours on slicing planes indicate the set \u03d1\u03b8 (0) (blue) and the sets \u03d1\u03b8 (\u00b1i) with decreasing opac- ity and saturation. Note the relation between converging iso- contours and low spatial distance (green) in (1) and between diverging contours and high spatial distance (red) in (2) ", "caption_bbox": [59, 421, 360, 556]}, {"image_id": 4, "file_name": "460_04.png", "page": 8, "dpi": 300, "bbox": [58, 57, 694, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) The mean surface for a temperature isovalue in the ATMOS dataset. (b) The IFCP algorithm in combination with distance dependent color mapping. (c) SDF surfaces \u03d1(\u00b12) emphasize the uncertainty in isosurface shape. ", "caption_bbox": [59, 205, 692, 234]}, {"image_id": 5, "file_name": "460_05.png", "page": 9, "dpi": 300, "bbox": [58, 57, 694, 507], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) A separating isosurface in a seismic tomography dataset is shown. (b) The IFCP algorithm in combination with distance dependent color mapping (homogeneous correlation of \u03c1i = 1) reveals a possible topological link in (1). (c) SDF surfaces \u03d1(\u00b12) emphasis the isosurface uncertainty with respect to shape. (d) An anisotropic correlation decrease is assumed. Compared to (b), higher crossing probabilities are determined in (2), but correlation based saturation reveals high stochastic independence rather than high local positional isosurface variability as major cause. ", "caption_bbox": [59, 518, 692, 592]}], "461": [{"image_id": 0, "file_name": "461_00.png", "page": 1, "dpi": 300, "bbox": [59, 567, 693, 735], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The backpack data set with 512 \u00d7 512 \u00d7 373 voxels rendered a) with Phong shading only; and b) with depth of field with \u03b1 = 30.9\u25e6 focused on the spray can in the foreground, c) on the wires behind it and d) on the boxes with the other spray can in the background. In each image 1469 slices were taken and gradients were estimated on the fly. ", "caption_bbox": [59, 515, 692, 559]}, {"image_id": 1, "file_name": "461_01.png", "page": 4, "dpi": 300, "bbox": [59, 57, 651, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: a) Illustration of the basic geometric setup for the depth of field scene with the lens and rays for calculating the view space circle of confusion C of an unfocused object at distance z, when the lens is focused at the distance z f . b) Illustration of the diameter of the circle of confusion c(z) in image space as a function of the distance z of an object to the lens with the focal plane at z f . ", "caption_bbox": [59, 301, 692, 360]}, {"image_id": 2, "file_name": "461_02.png", "page": 6, "dpi": 300, "bbox": [59, 57, 688, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: a) Geometric setup of computing depth of field effects by traversing the slices of a direct volume rendering system in two separate passes; those in front of the focal plane in front-to-back order and those behind the focal plane in back-to-front order. The bases of the yellow cones denote the regions from which samples are taken from the previous buffer during the incremental filtering. Slices are scaled in screen space to guarantee that the contribution of a slice is correctly considered by the incremental filtering of subsequent slices, due to linearly increasing circles of confusion Ci , which are 0 at the slice closest to the focal distance z f . b) The proposed simplified depth of field model with the user specified parameter \u03b1 describing the rate of change with which the circle of confusion changes in view space as a function of the distance d to the focal plane situated at z f for a slice at distance z in front of the focal plane z f and b) for a slice at distance z behind the focal plane z f . ", "caption_bbox": [59, 235, 692, 355]}, {"image_id": 3, "file_name": "461_03.png", "page": 7, "dpi": 300, "bbox": [66, 57, 693, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The abdomen part of the visible human data set with 512 \u00d7 512 \u00d7 512 voxels rendered with a) Phong shading and b) a depth of field effect created by an offline Monte-Carlo raytracer c) a depth of field effect with the presented interactive method with \u03b1 = 44.6\u25e6 and 2 \u00d7 2 samples taken during the incremental filtering and d) which is similar to image c), but here, 81 samples following a Poisson distribution were used during the incremental filtering. The focus is on the spine, the skin is rendered semi-transparently for additional context. In the images, 853 slices were taken and gradients were computed on the fly. ", "caption_bbox": [59, 253, 692, 343]}, {"image_id": 4, "file_name": "461_04.png", "page": 8, "dpi": 300, "bbox": [66, 326, 686, 482], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The aneurysm data set with 256 \u00d7 256 \u00d7 256 voxels rendered with Phong shading and a) no depth of field, b) depth of field with focus on the damaged blood vessel and \u03b1 = 57.6\u25e6 and c) focused at the same plane but a stronger depth of field effect by setting \u03b1 = 161.2\u25e6 , and d) which is similar to the previous image, but a sample grid resolution of 4 \u00d7 4 compared to the 2 \u00d7 2 grid used in the previous images. For each image, 655 slices were taken and gradients were precomputed and fetched from a 3D texture during rendering. ", "caption_bbox": [58, 492, 691, 567]}, {"image_id": 5, "file_name": "461_05.png", "page": 8, "dpi": 300, "bbox": [59, 57, 683, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A 1024 \u00d7 1024 \u00d7 384 voxel subset of the Richtmyer-Meshkov data set rendered with a) Phong shading and subse- quently DOF with \u03b1 = 105.7\u25e6 and focus on b) an eddy in the front, c) the center eddy and d) the far yellow eddy. In each image 1350 slices were taken and gradients were computed on the fly due to memory constraints. ", "caption_bbox": [59, 253, 692, 297]}], "462": [{"image_id": 0, "file_name": "462_00.png", "page": 4, "dpi": 300, "bbox": [59, 57, 686, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example for the 1D case (edge): (a) The marginal distributions at the grid points are shown in blue. Exemplarily, one realization of the linear interpolant is shown (green solid line); other realizations with lower probability are indicated (green transparent lines). In the depicted case the \u03d1-level crossing probability is relatively high. In (b) a density plot of the joint distribution with a correlation coefficient of 0.75 is displayed. The quadrants constituting the integration domain for the computation of the level crossing probability are indicated by the hatched grey area. In (c) the impact of changing covariance between two adjacent grid points on the level crossing probability is shown for two pairs of input distributions with \u03c3i = 1. As the covariance increases the probability decreases slightly for the first case and significantly for the second case. ", "caption_bbox": [59, 302, 692, 406]}, {"image_id": 1, "file_name": "462_01.png", "page": 5, "dpi": 300, "bbox": [59, 57, 378, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Example for the computation of a level cross- ing probability in 2D: The marginal distributions at the grid points are shown in blue. Exemplarily, one realization of the bilinear interpolant is shown in green (the particular one, where all random variables take the value of their means). The \u03d1-level crossing probability of the interpolant is rela- tively low in this specific case. ", "caption_bbox": [59, 248, 360, 352]}, {"image_id": 2, "file_name": "462_02.png", "page": 5, "dpi": 300, "bbox": [103, 373, 317, 423], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Four distinct configurations for the marching squares algorithm. The other configurations can be con- structed by inverting, rotating and mirroring the grid points. The integrals of the probabilistic formulation correspond to these cases. ", "caption_bbox": [59, 434, 360, 508]}, {"image_id": 3, "file_name": "462_03.png", "page": 6, "dpi": 300, "bbox": [59, 57, 378, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Assessment of normality for 5 randomly chosen distributions from the temperature field ensemble using a Q- Q-Plot. The distributions do not show severe deviations from the normal distribution, i.e. small differences compared to a linear shape. ", "caption_bbox": [59, 320, 360, 394]}, {"image_id": 4, "file_name": "462_04.png", "page": 7, "dpi": 300, "bbox": [139, 57, 693, 334], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Uncertain isolines for a synthetic 2D dataset. The expected values conform to a sine pattern (with a low amount of noise added) on the left that gradually approaches a plateau on the right as seen in (a). The variances and covariances are constant. In (b) the probabilities for \u03d1 = 0 are color mapped while the crisp isoline of the expected values is shown in black. While the computation of isolines is ill-conditioned at critical points (especially plateaus) the probabilistic ansatz does not suffer from this problem and calculates high probabilities for the whole plateau. ", "caption_bbox": [59, 342, 692, 416]}, {"image_id": 5, "file_name": "462_05.png", "page": 7, "dpi": 300, "bbox": [62, 452, 689, 631], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Uncertain isosurfaces in a synthetic 3D dataset. The expected values are given by an analytic formula and the variances are constant. The correlation coefficient is globally set to 0 in (a), to 0.65 in (b) and to 0.95 in (c). The probabilities are displayed using direct volume rendering and a crisp isosurface of the expected values is shown in white. The results show that increasing correlation between the grid points (from left to right) decreases the level crossing probabilities in the proximity of the mean surface and leads to more localized spatial distributions of uncertain isocontours. ", "caption_bbox": [58, 639, 691, 713]}, {"image_id": 6, "file_name": "462_06.png", "page": 8, "dpi": 300, "bbox": [59, 57, 664, 443], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Results for a 2 metre temperature field from climate simulations: The ensemble means are shown in (a). The level crossing probabilities for \u03d1 = 0\u25e6 C are colormapped in (b). For comparison the relative count of crisp isolines in the 63 ensemble members crossing the respective grid cell is shown in (c). The results computed according to [PH10] (not considering correlation) are shown in (d). While the latter result overestimates the spatial distribution of the uncertain isoline the distribution in (b) is more localized and similar to (c). ", "caption_bbox": [58, 451, 691, 525]}, {"image_id": 7, "file_name": "462_07.png", "page": 9, "dpi": 300, "bbox": [162, 57, 693, 619], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Uncertain isosurfaces \u03d1 = 0\u25e6 C in a 3D temperature field. In Fig. (a) the probabilities computed using the formulation in [PH10] (not considering correlation) are shown. For Fig. (b) correlation was considered and the level crossing probabilities reveal a more localized spatial distribution of the uncertain isosurface. ", "caption_bbox": [59, 624, 692, 671]}], "463": [{"image_id": 0, "file_name": "463_00.png", "page": 3, "dpi": 300, "bbox": [64, 437, 356, 728], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A point P = (d j,1 , ..., d j,8 ) \u2208 R8 is projected by the star coordinate system by the linear combination of its dimension anchors C1 , ...,C8 with the point\u2019s coordinates as coefficients [Kan01]. However, many points can be projected to the same location, making this representation highly am- biguous if linear combinations are not shown. ", "caption_bbox": [59, 743, 360, 835]}, {"image_id": 1, "file_name": "463_01.png", "page": 4, "dpi": 300, "bbox": [59, 57, 690, 215], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: By the representation through dimensional anchors alone (left), a simple but ambiguous view is achieved. Ambiguity may be solved by the display of the point\u2019s dimension contributions (center). However, this presentation highly clutters the view due to many and redundant line segments. A tree embedding, based on the structural composition of the data, achieves a trade-off in form of an unambiguous and less cluttered view (right). ", "caption_bbox": [59, 232, 692, 291]}, {"image_id": 2, "file_name": "463_02.png", "page": 5, "dpi": 300, "bbox": [68, 675, 360, 765], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: 2D data points without (left) hierarchically clus- tered by a shortest distance criterion (center). Spatial dis- tortion with this metric leads to the tendency to low decom- position points and thus, to high redundancies. Clustering based on the criterion of the highest minimum commonality (right) achieves an embedding that minimizes redundancies, and shows no such spatial distortion effects. ", "caption_bbox": [59, 779, 360, 883]}, {"image_id": 3, "file_name": "463_03.png", "page": 6, "dpi": 300, "bbox": [392, 634, 694, 834], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A 5-D data set with 5 point-clouds is shown. SDTs best display differences and commonalities within the structural assembly of the data. Further analysis can be con- ducted by adjusting the projection, highlighting, or filtering. ", "caption_bbox": [391, 845, 692, 904]}, {"image_id": 4, "file_name": "463_04.png", "page": 8, "dpi": 300, "bbox": [59, 57, 692, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Artificial data sets: (a) 3 tori in R10 , (b) 4 ellipsoids in R10 , (c) 5 point clouds in R15 ; Benchmark data sets: (d) Iris and (e) Cars data set. ", "caption_bbox": [59, 346, 692, 377]}, {"image_id": 5, "file_name": "463_05.png", "page": 9, "dpi": 300, "bbox": [67, 57, 693, 372], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Structural decomposition tree of 1000 data points obtained from three different air particle sampling campaigns: (a) Initial projection. The coloring of nodes is used for illustration purposes only (red: Pittsburgh, 2002; blue: Fresno, 2007; green: Fresno, 2009). Dimension highlighting applied to dimensions C, Po (b), and NOx (c). Adjusting the projection by moving the anchors corresponding to dimension C24 (d) and C36 (e). An inverse correlation to C could be revealed by moving the anchor of dimension C36 to one of its variance points (f). Options for filtering ((g); analog to (b)) as well as zoom and pan (h) allow to further adjust the view to current needs. ", "caption_bbox": [59, 381, 692, 470]}], "464": [{"image_id": 0, "file_name": "464_00.png", "page": 3, "dpi": 300, "bbox": [375, 57, 693, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a and b) 2D scatterplots represent F as a mov- able crosshair and the associated prediction as a point; (c) parallel coordinates represent both as connected lines. ", "caption_bbox": [391, 354, 692, 398]}, {"image_id": 1, "file_name": "464_01.png", "page": 4, "dpi": 300, "bbox": [375, 57, 693, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Star sampling varies a single parameter at a time. The mapping to Y shows a high local sensitivity of torque to IVO_shift. Combustion noise mostly depends on ROI_shift. ", "caption_bbox": [391, 369, 692, 413]}, {"image_id": 2, "file_name": "464_02.png", "page": 5, "dpi": 300, "bbox": [59, 57, 378, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Stochastic sampling varies multiple parameters at once. The distribution in Y suggests a small local impact of EVO_shift compared to ROI_shift and Vane_p. ", "caption_bbox": [58, 243, 359, 287]}, {"image_id": 3, "file_name": "464_03.png", "page": 5, "dpi": 300, "bbox": [375, 57, 693, 495], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Mapping the \u03b5 neighborhood of three targets into X shows their sensitivities to combined changes of IVO_shift and EVO_shift. Increasing both parameters locally mini- mizes trapped fuel but also torque. ", "caption_bbox": [391, 499, 692, 561]}, {"image_id": 4, "file_name": "464_04.png", "page": 6, "dpi": 300, "bbox": [375, 57, 693, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Box plots uniformly visualize uncertainties of model- and NN-based predictors. For POWER_PF, a wide spread indicates a highly uncertain prediction. ", "caption_bbox": [391, 372, 692, 416]}, {"image_id": 5, "file_name": "464_05.png", "page": 7, "dpi": 300, "bbox": [59, 57, 378, 232], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualizing NN-based predictors in terms of sam- ple weights. The used samples show a high variance for POWER_PF. The 2D scatterplot also indicates a significant deviation from the nearest sample in X having most weight. ", "caption_bbox": [58, 232, 359, 291]}, {"image_id": 6, "file_name": "464_06.png", "page": 8, "dpi": 300, "bbox": [59, 57, 675, 528], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Exemplary workflow. (a) Clicking a candidate sample sets F to the values shown in (b). (c) Parameter variation reveals an improvement for torque and fuel consumption. (d) Variations at the new F indicate a possibility to trade torque against lower trapped fuel. (e) Changing IVO_shift and ROI_shift reduces trapped fuel, keeps torque constant and slightly increases noise. (f) Comparing the target predictions to the initial values. (g) The uncertainty box plot for torque indicates a probable under-estimation. (h) Areas show a reasonable behavior of all targets for changing operating parameters. ", "caption_bbox": [58, 533, 691, 607]}], "465": [{"image_id": 0, "file_name": "465_00.png", "page": 1, "dpi": 300, "bbox": [397, 764, 684, 896], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Conventional time series visualization of one mea- surement (mouth height) of a particular feature. ", "caption_bbox": [391, 910, 692, 938]}, {"image_id": 1, "file_name": "465_01.png", "page": 2, "dpi": 300, "bbox": [58, 57, 694, 312], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A parallel coordinates visualization depicting the parameter space of facial measurements in relation to 4 different types of expression. These parameters can be chosen from the left panel. Four parameters are augmented with scatter plots. ", "caption_bbox": [59, 324, 692, 352]}, {"image_id": 2, "file_name": "465_02.png", "page": 4, "dpi": 300, "bbox": [59, 57, 378, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: 14 Facial feature measurements", "caption_bbox": [439, 692, 642, 705]}, {"image_id": 3, "file_name": "465_03.png", "page": 6, "dpi": 300, "bbox": [59, 57, 378, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Visual observation of the levels of variations in the measurement of the 14 facial features. ", "caption_bbox": [391, 676, 692, 704]}, {"image_id": 4, "file_name": "465_04.png", "page": 7, "dpi": 300, "bbox": [58, 750, 362, 865], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: From Figure 7, smile 1905 in (a) and anger 1931 in (c) are identified as outliers of their groups. The correspond- ing video frames reveal their similarity to surprise 1807 in (b) and sadness 1943 in (d) respectively. ", "caption_bbox": [59, 872, 360, 931]}, {"image_id": 5, "file_name": "465_05.png", "page": 7, "dpi": 300, "bbox": [62, 57, 695, 440], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Identifying clusters and non-clusters with parallel coordinate and scatter plot visualization", "caption_bbox": [125, 446, 624, 459]}, {"image_id": 6, "file_name": "465_06.png", "page": 8, "dpi": 300, "bbox": [397, 604, 684, 785], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Decision tree generated from visualization", "caption_bbox": [410, 794, 672, 807]}, {"image_id": 7, "file_name": "465_07.png", "page": 8, "dpi": 300, "bbox": [83, 351, 669, 567], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Decision making with parallel coordinates and brushes", "caption_bbox": [213, 573, 537, 586]}, {"image_id": 8, "file_name": "465_08.png", "page": 8, "dpi": 300, "bbox": [59, 57, 693, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Parallel coordinates help identify outliers in time series classification. In (a) Smile 1905 is an outlier. A time-series in a different class, Surprise 1807, exhibits a similar set of parameters. In (b), Anger 1931 is an outlier, which is very similar to Sadness 1943 in parameter space. ", "caption_bbox": [59, 292, 692, 336]}, {"image_id": 9, "file_name": "465_09.png", "page": 9, "dpi": 300, "bbox": [58, 716, 361, 917], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Decision tree obtained from C4.5 algorithm", "caption_bbox": [72, 929, 347, 942]}], "466": [{"image_id": 0, "file_name": "466_00.png", "page": 2, "dpi": 300, "bbox": [59, 57, 653, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Two meaningful data descriptors of biochemical data and their comparison. Each descriptor captures different data properties (atom resp. nitrogen count). Left: The input data is sorted according to each descriptor. Center: Color is mapped to the first ordering. The sorting is compared using connectors. Right: Compact comparison view. Color mapping based on object identity revealing descriptor correspondence. ", "caption_bbox": [59, 280, 692, 339]}, {"image_id": 1, "file_name": "466_01.png", "page": 4, "dpi": 300, "bbox": [61, 669, 360, 734], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Schema of the descriptor selection process. Every step (blue) encompasses automatic data processing and vi- sualization part. The input consists of many descriptors for one data set. These are compared and filtered resulting in a proposed set of independent descriptors. This is an interac- tive, guided analysis process. Feedback loops allow the user to refine results on demand. ", "caption_bbox": [59, 747, 360, 851]}, {"image_id": 2, "file_name": "466_02.png", "page": 4, "dpi": 300, "bbox": [403, 505, 684, 589], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The visualization approaches. a) Scatterplot with overplotting for large data sets. b) Grid-based view showing inhomogeneous data distribution across display and empty space. The color coding denotes data density in each cell - green (low) to red (high)). c) SOM view with homogeneous data distribution and good usage of the display space. ", "caption_bbox": [391, 602, 692, 691]}, {"image_id": 3, "file_name": "466_03.png", "page": 5, "dpi": 300, "bbox": [407, 328, 676, 554], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Scatterplot-based descriptor comparison visual- ization. Top: Object coloring. Bottom: The descriptor com- parison. a) The reference color scheme mapped to the back- ground and b) to the objects in the reference space. c) The homogeneous color gradient indicates a high similarity, d) the inhomogeneous gradient shows differing descriptors. ", "caption_bbox": [391, 567, 692, 656]}, {"image_id": 4, "file_name": "466_04.png", "page": 6, "dpi": 300, "bbox": [76, 295, 344, 386], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Schema of the SOM comparison coloring. Left: An unambiguous color assignment, where all cell members from the compared SOM are grouped in one cell of the reference SOM. Right: The color assignment using majority principle \u2013 the cell color is used where the most elements are situated. ", "caption_bbox": [59, 398, 360, 472]}, {"image_id": 5, "file_name": "466_05.png", "page": 6, "dpi": 300, "bbox": [86, 502, 334, 716], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Grid-based descriptor comparison visualization using SOM. a) The reference color scheme, b) homogeneous color gradient indicating a high similarity, c) the inhomoge- neous coloring for differing descriptors, d) locally homoge- neous coloring showing descriptors well discriminating sub- groups of objects. ", "caption_bbox": [59, 729, 360, 818]}, {"image_id": 6, "file_name": "466_06.png", "page": 7, "dpi": 300, "bbox": [394, 583, 690, 772], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visual extensions. Top: Illustration of improve- ment of visual display. Bottom: Display of coloring quality in SOM comparison. The columns show examples of SOMs. Left: a reference SOM, center: a homogeneous SOM, right: an inhomogeneous SOM. ", "caption_bbox": [391, 784, 692, 858]}, {"image_id": 7, "file_name": "466_07.png", "page": 7, "dpi": 300, "bbox": [58, 57, 694, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visual descriptor comparison. Left: Initial overview of pairwise descriptor correspondence. Right: The result view after descriptor filtering. The top row shows the selected descriptors with the data views. The bottom row shows the comparisons of one descriptor with related descriptors (in yellow). This supports understanding of the filtering decisions. ", "caption_bbox": [59, 283, 692, 326]}, {"image_id": 8, "file_name": "466_08.png", "page": 8, "dpi": 300, "bbox": [375, 57, 693, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparsion of colormaps for a 18x12 SOM grid. a) Rectangular cut out of the CIELab color space at L=55. b) Skewed rectangle cut (CIELab, L=55). c), d) and e) Two channels of RGB mapped to x and y axis, leaving the third constant. f) and g) Three channel RGB color scheme, diago- nally cutting the RGB color cube [Him00]. h) Color scheme in XYZ color space. ", "caption_bbox": [391, 278, 692, 382]}, {"image_id": 9, "file_name": "466_09.png", "page": 9, "dpi": 300, "bbox": [375, 57, 693, 206], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: a) Comparison of the weight to an atom count descriptor. The homogeneous color gradient validates the expected correlation of the descriptors. b) The 1-D Wiener- Number descriptor shows a high separability for molecules which are all in one cell in the SOM of the 26-D Exten- dendFingerprint. ", "caption_bbox": [391, 219, 692, 308]}, {"image_id": 10, "file_name": "466_10.png", "page": 9, "dpi": 300, "bbox": [63, 503, 357, 621], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: a) Comparison of the 79-D EState fingerprint with the 307-D substructure fingerprint, showing their simi- larity. b) Matrix view on the group of 7 similar descriptors. ", "caption_bbox": [59, 634, 360, 677]}], "467": [{"image_id": 0, "file_name": "467_00.png", "page": 2, "dpi": 300, "bbox": [58, 57, 378, 562], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (A) Finding specific towns in this large map is dif- ficult. (B) Detail-in-context magnification lenses reveal the towns but obscure the railway connections. (C) An undis- tort lens clarifies the railway connections in the transition region between the magnification lenses. The arrows point out the magnification lenses (I & II), a road obscured by the lens\u2019 drop-off (III), the selected region to undistort (IV), the undistort lens connection (V), and displayed undistorted in- formation (VI). ", "caption_bbox": [59, 572, 360, 707]}, {"image_id": 1, "file_name": "467_01.png", "page": 3, "dpi": 300, "bbox": [390, 341, 694, 511], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Undistort lenses can have a rectangular, square, or circular shape. ", "caption_bbox": [391, 521, 692, 549]}, {"image_id": 2, "file_name": "467_02.png", "page": 3, "dpi": 300, "bbox": [375, 57, 694, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The base of the undistort lens can either be di- rectly under the distorted area (a) or connected (b) with a line between the region of interest and the undistort lens\u2019 display. The region shown within the undistort lens is indi- cated by an outline (c). ", "caption_bbox": [391, 260, 692, 334]}, {"image_id": 3, "file_name": "467_03.png", "page": 4, "dpi": 300, "bbox": [390, 390, 694, 576], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Lookup textures (x-map and y-map, left column) encode x and y coordinates in RGB image values. Data is distorted by a function f , that is also applied to the lookup textures (middle column). To find the original coordinates of a point (i, j) on the distorted presentation (red circle, right column) we examine the channel values of pixel (i, j) in the x-map and y-map to determine the undisorted x and y re- spectively. ", "caption_bbox": [391, 587, 692, 707]}, {"image_id": 4, "file_name": "467_04.png", "page": 4, "dpi": 300, "bbox": [375, 57, 692, 227], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Left: width coordinates encoded into red (top) and green (bottom) channels of a lookup texture. While normally combined into a single image, these channels have been pre- sented as separate images to make changes in the red chan- nel easily visible; blue and alpha channels are not shown. The black bands in the green channel mark where 8-bit over- flow causes an increment in the red channel. Right: width lookup texture channels after deformation by top-left quar- ter of a Sinusoidal map projection [Sny97]. ", "caption_bbox": [391, 241, 692, 376]}, {"image_id": 5, "file_name": "467_05.png", "page": 5, "dpi": 300, "bbox": [375, 57, 694, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An undistort lens used with a Melange-like space fold. ", "caption_bbox": [391, 342, 692, 370]}, {"image_id": 6, "file_name": "467_06.png", "page": 5, "dpi": 300, "bbox": [390, 380, 694, 486], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A sigma-type lens is positioned over the north sea with an undistort lens centered on Olso. ", "caption_bbox": [391, 497, 692, 525]}, {"image_id": 7, "file_name": "467_07.png", "page": 5, "dpi": 300, "bbox": [390, 533, 694, 714], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: An undistort lens is used to clarify the details on Great Britain which was currently less clear on the side of a sigma-type lens. ", "caption_bbox": [391, 724, 692, 767]}, {"image_id": 8, "file_name": "467_08.png", "page": 6, "dpi": 300, "bbox": [58, 57, 378, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A wedge lens positioned to fit the angle formed by a fork in the railway. An undistort lens presents a region on either side of a sharp, Manhattan-style drop-off. ", "caption_bbox": [59, 337, 360, 380]}, {"image_id": 9, "file_name": "467_09.png", "page": 6, "dpi": 300, "bbox": [375, 57, 694, 398], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: A simple example of annotation where a point is marked (red) in an area magnified by a context and detail lens (top). Then lens is then moved but the red marker retains its position with respect to the underlying image despite the change in the distortion (bottom). ", "caption_bbox": [391, 408, 692, 482]}, {"image_id": 10, "file_name": "467_10.png", "page": 6, "dpi": 300, "bbox": [58, 387, 362, 592], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Exploration of high magnification imagery (The Arnofini Portrait by Jan van Eyck, oil on oak, 1434) with an EPF detail and context lens and an undistort lens. The detail and context lens features 10X magnification and a power function dropoff with a parameter value of 2 as per [CLP04]. One undistort lens is used to clarify the position of the high magnification area in the original scene, the other is used to make text legible. ", "caption_bbox": [59, 602, 360, 722]}, {"image_id": 11, "file_name": "467_11.png", "page": 7, "dpi": 300, "bbox": [63, 57, 693, 192], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: A photograph is edited to remove a cloud. Edits performed at high magnification should be examined at normal magnification to ensure that they blend in. Left: original. Middle: poorly blended edit. Right: well blended edit. ", "caption_bbox": [59, 202, 692, 230]}, {"image_id": 12, "file_name": "467_12.png", "page": 7, "dpi": 300, "bbox": [63, 238, 689, 385], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Mock-up of editing with a 4X magnification detail and context lens with assistance from an undistort lens. Left: original image; middle: poorly blended local editing; right: well blended local editing. A grid has been super-imposed to reveal the detail and context lens as shading causes greater disruption to colour values necessary for photo editing. ", "caption_bbox": [59, 396, 692, 439]}, {"image_id": 13, "file_name": "467_13.png", "page": 8, "dpi": 300, "bbox": [58, 57, 694, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Exploring the differences between a Winkel Tripel projection and the original image data (a cylindrical projection).", "caption_bbox": [59, 405, 692, 418]}, {"image_id": 14, "file_name": "467_14.png", "page": 8, "dpi": 300, "bbox": [103, 443, 317, 633], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Use of the undistort lens to present a cylindrical projection next to a 3D globe. ", "caption_bbox": [59, 644, 360, 672]}, {"image_id": 15, "file_name": "467_15.png", "page": 9, "dpi": 300, "bbox": [390, 663, 694, 818], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 18: A detail-in-context lens that automatically ori- ents towards the nearest screen edge based on how the lens has been folded. The undistort lens and its frame make clear the orientation of the focus of the detail and context lens rel- ative to the context. ", "caption_bbox": [391, 828, 692, 902]}, {"image_id": 16, "file_name": "467_16.png", "page": 9, "dpi": 300, "bbox": [390, 414, 694, 582], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 17: A detail-in-context lens where the focus can be arbitrarily oriented. The undistort lens can clarify data\u2019s original orientation. ", "caption_bbox": [391, 593, 692, 636]}, {"image_id": 17, "file_name": "467_17.png", "page": 9, "dpi": 300, "bbox": [58, 57, 694, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Two 4.5 magnification lenses that have been folded over to compare two separated areas of a map. Two undistort lenses assist in understanding the distortions, reading labels, and revealing obscured areas. ", "caption_bbox": [59, 349, 692, 377]}], "468": [{"image_id": 0, "file_name": "468_00.png", "page": 2, "dpi": 300, "bbox": [375, 57, 697, 165], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visual boosting with halos. Halos may be pain- ted with semi-transparent or opaque colors. As the halos may overlap each other, the painting order is important. (a) Without visual boosting, (b) Boosting with semi-transparent halos, (c) Boosting with opaque halos. ", "caption_bbox": [391, 178, 692, 252]}, {"image_id": 1, "file_name": "468_01.png", "page": 5, "dpi": 300, "bbox": [64, 57, 712, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visual boosting of customer feedback data. Positively mentioned features are colored in blue, negatively mentioned ones in red. In (b) background coloring is used to emphasize the local trend and outliers are boosted with halos. ", "caption_bbox": [59, 314, 692, 342]}, {"image_id": 2, "file_name": "468_02.png", "page": 6, "dpi": 300, "bbox": [59, 57, 647, 362], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visual boosting of search results. The visual saliency of sparse pixels is increased by halos.", "caption_bbox": [121, 374, 629, 387]}, {"image_id": 3, "file_name": "468_03.png", "page": 6, "dpi": 300, "bbox": [405, 425, 679, 560], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Boosting of single points with circular halos. This approach induces overplotting, which has to be dealt with in more dense data sets. ", "caption_bbox": [391, 570, 692, 613]}, {"image_id": 4, "file_name": "468_04.png", "page": 7, "dpi": 300, "bbox": [103, 57, 693, 583], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visual boosting of transcriptome data of Escherichia coli O157:H7 EDL933 using the SOLiD 4.0 technology. Shown are genes L7065 overlapping L7066, and L7071 from the plasmid pO157 (NC_007414). Bacteria were grown in M9 minimal medium. ", "caption_bbox": [59, 595, 692, 638]}, {"image_id": 5, "file_name": "468_05.png", "page": 8, "dpi": 300, "bbox": [58, 57, 694, 269], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparison of different boosting methods. + means the technique is well applicable for the specific task and o denotes medium effectiveness. Boosting techniques rated with - should not be applied to the respective application problem. ", "caption_bbox": [59, 295, 692, 323]}, {"image_id": 6, "file_name": "468_06.png", "page": 8, "dpi": 300, "bbox": [74, 359, 347, 639], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Boosting of the strongest earthquakes with halos while reducing data- and halo-induced overlap. Color was mapped to magnitude, halos use less saturated colors. ", "caption_bbox": [59, 650, 360, 693]}], "469": [{"image_id": 0, "file_name": "469_00.png", "page": 1, "dpi": 300, "bbox": [58, 314, 694, 564], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The Dynamic Insets technique for a map of the Chicago area showing insets for off-screen nodes with their context.", "caption_bbox": [61, 574, 690, 587]}, {"image_id": 1, "file_name": "469_01.png", "page": 3, "dpi": 300, "bbox": [58, 57, 693, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Dynamic construction of insets for a simple graph consisting of 7 nodes and 8 edges. A is the source node (ns ).", "caption_bbox": [72, 282, 678, 296]}, {"image_id": 2, "file_name": "469_02.png", "page": 4, "dpi": 300, "bbox": [390, 225, 694, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Insets that overlap are stacked so that all insets are visible. This allows them to be paged through by hover- ing the mouse over the visible part, bringing it to the top. ", "caption_bbox": [391, 315, 692, 358]}, {"image_id": 3, "file_name": "469_03.png", "page": 5, "dpi": 300, "bbox": [58, 57, 378, 157], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Interaction sequence for the drag-to-fan tech- nique. The user presses and holds the mouse button on an inset, then drags to fan the insets along the perimeter of a semi-circle. Releasing the button over an inset will execute the configured action (travel to, bring to top, etc). ", "caption_bbox": [58, 168, 359, 242]}, {"image_id": 4, "file_name": "469_04.png", "page": 5, "dpi": 300, "bbox": [58, 528, 361, 604], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Four distance visualizations: (a) actual number, (b) border color, (c) inset transparency, and (d) inset size. ", "caption_bbox": [58, 615, 359, 643]}, {"image_id": 5, "file_name": "469_05.png", "page": 6, "dpi": 300, "bbox": [67, 624, 350, 745], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Effects of factors on errors (logistic regression).", "caption_bbox": [398, 901, 684, 914]}, {"image_id": 6, "file_name": "469_06.png", "page": 8, "dpi": 300, "bbox": [59, 57, 686, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Subjective ratings for follow-up studies (Likert scale 1-5 averages, standard deviations in parentheses). ", "caption_bbox": [58, 879, 359, 907]}, {"image_id": 7, "file_name": "469_07.png", "page": 9, "dpi": 300, "bbox": [390, 322, 694, 547], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Social network for the AVI co-authorship dataset. This application was used in one of the follow-up studies. ", "caption_bbox": [391, 557, 692, 585]}], "470": [{"image_id": 0, "file_name": "470_00.png", "page": 3, "dpi": 300, "bbox": [83, 55, 693, 172], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Edges of types C, E, I, CE, CI and CEI. Blue squares represent vectors assigned to the two incident triangles. Examples of these vectors are shown as black arrows. ", "caption_bbox": [58, 178, 691, 206]}, {"image_id": 1, "file_name": "470_01.png", "page": 4, "dpi": 300, "bbox": [59, 55, 378, 167], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Computing F(e). Left: two triangles with their as- signed set of vectors. Center: the two set of vectors are trans- lated so that they are anchored at the same point. Right: the convex hull of F(\u22060 ) \u222a F(\u22061 ). F(e) consists of vectors start- ing at a and ending in the intersection of the hull and E. ", "caption_bbox": [58, 173, 359, 247]}, {"image_id": 2, "file_name": "470_02.png", "page": 4, "dpi": 300, "bbox": [112, 271, 309, 343], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An example of a triangle \u2206 with nonempty stable and unstable bundles. The clipped bundles S\u2206 and U\u2206 are shown in green and red (respectively). For any such trian- gle, each of the bundles contains vectors running along an edge of \u2206 incident to v. Note that the sector between the two bundles is always hyperbolic (in the sector, the flow vector field points from the stable to the unstable bundle). ", "caption_bbox": [58, 349, 359, 454]}, {"image_id": 3, "file_name": "470_03.png", "page": 5, "dpi": 300, "bbox": [62, 55, 378, 171], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Sector analysis of a vertex. Left: F(\u2206) for each incident triangle and flow direction along any incident im- ploding or exploding edge (black arrows pointing along the edge). Direction of the flow crossing the two crossing edges is indicated by a thin black arrow. Center: All stable and unstable directions. Unstable ones point into the red areas and along the red edge. There is one stable direction along the green edge. Right: Sectors: stable parabolic (green \u2013 this one consists of only one direction), unstable parabolic (red) and two hyperbolic (blue). ", "caption_bbox": [58, 176, 359, 326]}, {"image_id": 4, "file_name": "470_04.png", "page": 5, "dpi": 300, "bbox": [61, 347, 359, 439], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Sector analysis of a vertex. The CVPC vector field and stable and unstable direction are shown as in Figure 4. In the right image, the elliptic sector is shown in brown. ", "caption_bbox": [58, 445, 359, 489]}, {"image_id": 5, "file_name": "470_05.png", "page": 5, "dpi": 300, "bbox": [375, 55, 693, 366], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Top row: arcs of the coarse super-transition graph generated for a triangle \u2206 = \u2206abc with edges e, g, h. e and g are crossing edges and h is a CEI edge with the flow di- rection from b to a. No vertex of \u2206 is critical. The coarse transition graph arcs associated with \u2206abc and its edges are shown on the right (type T - in blue, type E - in green). Ex- amples of refinement operations are shown in the lower two rows. First, the edge g is split into two edge pieces (middle). Note that g0 is not connected to h in the refined graph since there is no straight line path from g0 to h following a di- rection belonging to F(\u2206). Then, h is split into two pieces (bottom). The arc h0 \u2192 h1 belongs to the graph since F(h) contains a vector pointing from b to c. ", "caption_bbox": [391, 373, 692, 569]}, {"image_id": 6, "file_name": "470_06.png", "page": 6, "dpi": 300, "bbox": [59, 55, 378, 165], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Test dataset sizes", "caption_bbox": [474, 168, 607, 181]}, {"image_id": 7, "file_name": "470_07.png", "page": 7, "dpi": 300, "bbox": [375, 55, 693, 283], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Morse decomposition for the gas engine dataset, valid for all 4% perturbations. (a): Morse set of type (0, +) that does not contain a stationary point; any feasible vector field contains a periodic orbit running around the ring. A re- pelling periodic orbit can be thought of as a simplified model of all features in the ring. (b): Morse set of type (1, \u2212). Any feasible vector field contains a fixed point in this area. A sink is a valid (but, possibly, simplified) model of features within it for any feasible vector field. (c): Morse set of type (1, +); similar to (b), but a source is a valid simplified model. (d): Trivial Morse sets; They may contain topological features for some feasible vector fields (in fact, they do), but all of them cancel each other. The algorithm was not able to find any common nontrivial feature in this area. (e): A Morse set of type (\u22121, 0). It must contain a stationary point and a sad- dle is a simplified model for features in this area. ", "caption_bbox": [391, 287, 692, 529]}, {"image_id": 8, "file_name": "470_08.png", "page": 8, "dpi": 300, "bbox": [465, 679, 618, 794], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Two trajectory segments of g, starting and ending on the boundary of a triangle \u2206, are shown in blue. For the trajectory on the right, n-sets containing the starting point and the endpoint are connected by an arc in G, since the green vector connecting the trajectory\u2019s endpoints is a pos- itive multiple of a vector in F(\u2206). For the trajectory on the left, they may not be connected directly, but they are certainly connected by a path of edge pieces contained in a\u0304b. ", "caption_bbox": [391, 800, 692, 920]}, {"image_id": 9, "file_name": "470_09.png", "page": 8, "dpi": 300, "bbox": [67, 272, 685, 363], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: A zoomed in view on small features in the cooling jacket dataset. Results valid for 0.1%, 0.25%, 0.5%, 1% and 2.5% perturbations and 10, 9, 8, 7 and 6 refinement iterations (respectively). Many of the blue Morse sets indicate possible homoclinic orbits at saddles. ", "caption_bbox": [58, 369, 691, 413]}, {"image_id": 10, "file_name": "470_10.png", "page": 8, "dpi": 300, "bbox": [59, 55, 684, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The cooling jacket dataset. Results valid for 0.1%, 0.5%, 1%, 2%, 5% perturbations obtained using 10, 8, 7, 6 and 5 refinement operations. The number of nontrivial Morse sets is 557, 497, 448, 393 and 283, respectively. ", "caption_bbox": [58, 223, 691, 252]}, {"image_id": 11, "file_name": "470_11.png", "page": 8, "dpi": 300, "bbox": [390, 446, 681, 596], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Estimate of stability of the large periodic orbit in the diesel engine dataset. Left: 2.5% perturbation, right: 2.6% perturbation. In both cases, 8 refinement iterations were used. ", "caption_bbox": [391, 601, 692, 660]}, {"image_id": 12, "file_name": "470_12.png", "page": 8, "dpi": 300, "bbox": [59, 447, 345, 613], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Results for the gas engine dataset, valid for all 10% and 11% perturbations (based on 7 refinement itera- tions of the super-transition graph). (a): A large periodic or- bit is guaranteed to exist for any vector field within 10% of the input. However, the algorithm failed to provide the same guarantee for 11% perturbation. Note that the Morse set (a) merges with the sink-like one it encloses to form one similar to a source: this can be viewed as a counterpart of the Hopf bifurcation [HK91] for Morse sets. The sink-like and saddle- like sets (b) cancel to produce a trivial Morse set in the right image. The large blue Morse sets contain saddles with possi- ble homoclinic orbits that may exist for some feasible vector fields (note that homoclinic orbits are structurally unstable so they do not influence the Morse set type). ", "caption_bbox": [58, 619, 359, 830]}, {"image_id": 13, "file_name": "470_13.png", "page": 9, "dpi": 300, "bbox": [59, 55, 378, 205], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Results for envelopes of the gas engine dataset. The left image shows the Morse sets obtained for the dataset of the original resolution. In this case, the algorithm fails to find a Morse set corresponding to the large periodic orbit. However, that Morse set does show up for the subdivided versions of the same dataset (the image shows results for 1, 2 and 3 subdivision iterations). 8 refinement iterations were applied to obtain the first three images and 7 \u2013 to obtain the image on the right (because of our limits on memory usage: note that three subdivisions increase the size of the mesh to over 1.6 million triangles). It is interesting to note that the Morse sets in the right image appear smaller despite using a coarser graph. This is because they are computed using a CVPC vector field closer to the original PL vector field. ", "caption_bbox": [58, 210, 359, 421]}, {"image_id": 14, "file_name": "470_14.png", "page": 9, "dpi": 300, "bbox": [64, 444, 356, 589], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Morse sets of envelopes of the diesel engine and a slice of the hurricane Isabel datasets. In both cases, Morse sets that capture periodic orbits of the PL vector field have been found. Mesh subdivision was not necessary. ", "caption_bbox": [58, 595, 359, 654]}], "471": [{"image_id": 0, "file_name": "471_00.png", "page": 5, "dpi": 300, "bbox": [66, 57, 376, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Even though these higher-order tensors are not isotropic, they do not have a unique decomposition into ge- ometrically constrained rank-1 terms. All other degenerate cases can be derived from the examples visualized here. ", "caption_bbox": [59, 301, 360, 360]}, {"image_id": 1, "file_name": "471_01.png", "page": 6, "dpi": 300, "bbox": [376, 57, 691, 248], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Major (blue), medium (cyan), and minor (green) lines of discontinuity on bilinear cells; tensors at the corners are shown with glyphs, degenerate points with red dots. ", "caption_bbox": [391, 253, 692, 296]}, {"image_id": 2, "file_name": "471_02.png", "page": 6, "dpi": 300, "bbox": [59, 57, 377, 236], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Around degenerate points (yellow/red), it is im- possible to partition the vectors from the decomposition into continuous vector fields. ", "caption_bbox": [59, 241, 360, 284]}, {"image_id": 3, "file_name": "471_03.png", "page": 8, "dpi": 300, "bbox": [376, 57, 687, 573], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Degeneracies in third-order derivatives provide feature points that are fairly robust under rotation and typi- cal MR image degradations. For comparison, points from (a) are overlaid on (b) and (c) as circles. ", "caption_bbox": [391, 582, 692, 641]}, {"image_id": 4, "file_name": "471_04.png", "page": 9, "dpi": 300, "bbox": [64, 57, 376, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The major lines of discontinuity in the higher- order structure tensor field of a given image (a) indicate meaningful regions at different scales (b/d). ", "caption_bbox": [59, 416, 360, 459]}], "472": [{"image_id": 0, "file_name": "472_00.png", "page": 3, "dpi": 300, "bbox": [67, 57, 378, 189], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) Cuboid with piecewise constant tensor field (red tensor lines). All degenerate points fall into vertices. Result for analytic datasets (b) trisector degenerate point (c) wedge degenerate point, both found in virtual vertex cells. Degenerate points depicted as spheres, separatrices as red and blue lines. ", "caption_bbox": [59, 197, 360, 286]}, {"image_id": 1, "file_name": "472_01.png", "page": 5, "dpi": 300, "bbox": [90, 57, 693, 196], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Model for transition bridges: (a) the triangle normals transform along the bridge into each other, (b) transition bridge flattened, choice of local coordinate system for common parametrization of tensors, (c) virtual vertex cell defined as cell bounded by adjacent virtual edge cells. (a,b,c) Jordan curves are colored in red. Different colors of Di , i = 1, .., n emphasize different tensors for same vertex point but different triangles. ", "caption_bbox": [59, 206, 692, 265]}, {"image_id": 2, "file_name": "472_02.png", "page": 6, "dpi": 300, "bbox": [59, 57, 378, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Calculation of tensor index around (a) edge with wedge (b) vertex with trisector. Separatrices depicted in red and blue lines. (a) below: determination of rotation angle across transition bridge. ", "caption_bbox": [59, 271, 360, 330]}, {"image_id": 3, "file_name": "472_03.png", "page": 7, "dpi": 300, "bbox": [375, 57, 693, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Separatrix S converges into edge e due to different signs of angles \u2206\u03b11 and \u2206\u03b12 . ", "caption_bbox": [391, 206, 692, 235]}, {"image_id": 4, "file_name": "472_04.png", "page": 8, "dpi": 300, "bbox": [59, 57, 378, 210], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Analytic one point load dataset cut with sphere given as piecewise linear tensor field, (c) is a schematic il- lustration of the dataset. Figure(a) renders the topological graph without, Figure(b) with additional consideration of locations of discontinuity. In Figure(b) the additional degen- erate point is indicated as large sphere and only its separa- trices as thick lines. ", "caption_bbox": [59, 218, 360, 322]}, {"image_id": 5, "file_name": "472_05.png", "page": 8, "dpi": 300, "bbox": [393, 334, 694, 637], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Simulated two point load cut with a sphere, schematic illustration in top right corner. Virtual degenerate points are depicted as larger spheres and associated separa- trices as thick lines. ", "caption_bbox": [391, 652, 692, 711]}, {"image_id": 6, "file_name": "472_06.png", "page": 9, "dpi": 300, "bbox": [58, 443, 361, 765], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Derived rate of strain tensor field on an aneurysm dataset. Top right corner: the streamlines on the surface ren- der the initial velocity gradient vector field. ", "caption_bbox": [59, 776, 360, 819]}], "473": [{"image_id": 0, "file_name": "473_00.png", "page": 2, "dpi": 300, "bbox": [58, 56, 712, 206], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Results of using four illustration techniques to show the statistical morphological properties of an SDM model generated from the lumbar vertebrae of 20 subjects. (a-b) Results of using likelihood volumes to illustrate the probabilistic properties of a group of images. (c-d) Results of using deformable grids to show statistical deformation properties and characterize regions with high variability. (e) Results of using spherical glyphs to annotate the variability of different areas of the vertebra. (f) Results of using line-based glyphs to illustrate deformation range and morphological variability. ", "caption_bbox": [58, 215, 691, 283]}, {"image_id": 1, "file_name": "473_01.png", "page": 3, "dpi": 300, "bbox": [375, 56, 694, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (top) Sample of one of the synthetic datasets used to test the different illustration techniques. Note that since the images are in order, we can easily see the deformation pattern of this collection. (bottom) Results of using four illustration techniques to show the statistical properties of our SDM model which was generated from 42 different 3D images. Results of using (a) Likelihood Volumes, (b) Deformation Grids, (c) Line Glyphs, and (d) Spherical Glyphs. ", "caption_bbox": [391, 397, 692, 493]}, {"image_id": 2, "file_name": "473_02.png", "page": 5, "dpi": 300, "bbox": [58, 56, 378, 386], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (top) A set of longitudinal images of a patient with low- grade gliomas which are often analyzed by physicians to measure deformation properties. (center) Sample annotations that can be used to summarize and analyze the statistical deformation proper- ties of a group. (bottom) [a-c] Sample of the femur dataset also used within the survey. ", "caption_bbox": [58, 395, 359, 477]}, {"image_id": 3, "file_name": "473_03.png", "page": 7, "dpi": 300, "bbox": [375, 56, 693, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Plots with 95% CIs of the user preferences when analyz- ing synthetic data versus medical images. We found that spherical glyphs are promising in the medical imaging domain. Specifically, from a significance test we found a P-value of 0.001 when compar- ing the user preferences between synthetic and medical images. ", "caption_bbox": [391, 277, 692, 345]}, {"image_id": 4, "file_name": "473_04.png", "page": 7, "dpi": 300, "bbox": [412, 375, 675, 549], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Plot of the overall user performance. We found that, on average, users are more accurate when exploring and analyzing statistical deformation properties with deformation grids. ", "caption_bbox": [391, 565, 692, 606]}, {"image_id": 5, "file_name": "473_05.png", "page": 7, "dpi": 300, "bbox": [80, 56, 378, 585], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (top) Plot of the average user preferences and the 95% confidence intervals (CIs). We found that, on average, users tend to prefer likelihood volumes. (bottom) Plot of the user prefer- ences across population. We found a significant difference between how much computer scientists prefer deformable grids over non- engineers subjects. ", "caption_bbox": [58, 621, 359, 703]}, {"image_id": 6, "file_name": "473_06.png", "page": 8, "dpi": 300, "bbox": [59, 56, 378, 445], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (top) Plot illustrating the average user confidence per annotation technique and the 95% CIs. (bottom) Plot illustrating the average time required to answer questions about each annotation technique. Note that analyzing raw data was clearly the technique that required the most effort to answer. ", "caption_bbox": [58, 461, 359, 529]}], "474": [{"image_id": 0, "file_name": "474_00.png", "page": 3, "dpi": 300, "bbox": [59, 193, 362, 351], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Three visualization techniques for displaying blood flow along with the vascular anatomy. ", "caption_bbox": [59, 364, 360, 392]}, {"image_id": 1, "file_name": "474_01.png", "page": 4, "dpi": 300, "bbox": [59, 57, 647, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Our visualizations techniques are evaluated by means of five datasets. These five 3D aneurysm models are visualized with the ghosted view with depth enhancement. ", "caption_bbox": [59, 212, 692, 240]}, {"image_id": 2, "file_name": "474_02.png", "page": 5, "dpi": 300, "bbox": [65, 57, 378, 200], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) The ghosting with depth enhancement (GD) and (b) the full-color shaded opaque surface. The gauge is a small ellipse representing a disc and a single line. ", "caption_bbox": [59, 213, 360, 256]}, {"image_id": 3, "file_name": "474_03.png", "page": 5, "dpi": 300, "bbox": [405, 332, 679, 438], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A stimulus with (a) the ghosted view with depth enhancement (GD) and (b) just the flow visualization. The pink rectangle defines the region for which the participant had to estimate the average flow color. ", "caption_bbox": [391, 451, 692, 510]}, {"image_id": 4, "file_name": "474_04.png", "page": 6, "dpi": 300, "bbox": [74, 468, 346, 582], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Spatial stimuli for one model and one technique. (a) Both vessel branches have the same distance to the viewer. (b) The model rotated by 10 degrees and (c) 20 de- grees, whereas the vessel branch B is closer to the viewer. ", "caption_bbox": [59, 595, 360, 654]}, {"image_id": 5, "file_name": "474_05.png", "page": 7, "dpi": 300, "bbox": [408, 408, 677, 550], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Average response times and error bars (95% con- fidence intervals) of the shape experiment. ", "caption_bbox": [391, 563, 692, 591]}, {"image_id": 6, "file_name": "474_06.png", "page": 7, "dpi": 300, "bbox": [62, 57, 693, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The average results and error bars (95% confidence intervals) for (a) the shape experiment (group -RO and group +RO), (b) the color distance of the smart visibility experiment, (c) all correct responses for the spatial experiment, and (d) separated for each rotation angle. ", "caption_bbox": [59, 260, 692, 303]}, {"image_id": 7, "file_name": "474_07.png", "page": 8, "dpi": 300, "bbox": [83, 487, 338, 647], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Average (a) smart visibility and (b) spatial re- sponse times and error bars (95% confidence intervals). ", "caption_bbox": [59, 660, 360, 688]}, {"image_id": 8, "file_name": "474_08.png", "page": 9, "dpi": 300, "bbox": [59, 57, 693, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Participants were asked to rate and compare the techniques pairwise.", "caption_bbox": [175, 280, 575, 293]}], "475": [{"image_id": 0, "file_name": "475_00.png", "page": 3, "dpi": 300, "bbox": [105, 687, 311, 868], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Real-world versus synthetic movement data, with visual clutter resulting from simple (ships in a sea lane) or complex (pedestrians in a street [vdSvS08]) trajectories. ", "caption_bbox": [59, 880, 360, 924]}, {"image_id": 1, "file_name": "475_01.png", "page": 5, "dpi": 300, "bbox": [72, 57, 699, 603], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A table showing all movement features with all visualizations. Each data set with a certain movement feature contains the same lanes with trajectories, but the order is changing in each trial and hence in each visualization shown. ", "caption_bbox": [59, 613, 692, 641]}, {"image_id": 2, "file_name": "475_02.png", "page": 5, "dpi": 300, "bbox": [59, 667, 692, 843], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Scatter plots with the mean correctness and mean response time per subject. The Pearson\u2019s correlation coefficients are shown in the bottom right corner. From left to right: All data and data grouped by M lanes , M f ast , and M stop . ", "caption_bbox": [59, 854, 692, 882]}, {"image_id": 3, "file_name": "475_03.png", "page": 7, "dpi": 300, "bbox": [63, 57, 378, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 4: Tukey\u2019s HSD post hoc test results. For \u03b1 = 0.05, 3 treatments (visualizations), and a within-groups df>1000 (for our data df=1017), all values larger than 3.31 are shown in bold and have a significant difference. ", "caption_bbox": [58, 576, 359, 637]}, {"image_id": 4, "file_name": "475_04.png", "page": 8, "dpi": 300, "bbox": [59, 57, 657, 479], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A tree showing in each node subsets of the test data given by the filter criteria. For each node the homogeneous subsets of visualizations (A=Vanim , C=Vcube , D=Vdens ) are given, which are obtained by conducting an ANOVA test with correctness as a dependent variable and visualization as an independent variable with Tukey\u2019s HSD post hoc tests for \u03b1 = 0.05. ", "caption_bbox": [59, 490, 692, 534]}], "476": [{"image_id": 0, "file_name": "476_00.png", "page": 2, "dpi": 300, "bbox": [59, 57, 688, 200], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The cognitive and memory model of a single trial", "caption_bbox": [225, 207, 524, 220]}, {"image_id": 1, "file_name": "476_01.png", "page": 3, "dpi": 300, "bbox": [59, 57, 378, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The combination of germane, intrinsic, and extra- neous load to form working memory capacity and the im- pact of higher cognitive load (bottom curve) on task perfor- mance(top curve). Note that cognitive load peaks prior to the user\u2019s response to the task. ", "caption_bbox": [59, 293, 360, 367]}, {"image_id": 2, "file_name": "476_02.png", "page": 3, "dpi": 300, "bbox": [375, 57, 704, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An example of extraneous cognitive load. Both figures represent the underlying data; however, the visual nature the box plot facilitates understanding by taxing the working memory system less than the numerical description. ", "caption_bbox": [391, 245, 692, 304]}, {"image_id": 3, "file_name": "476_03.png", "page": 4, "dpi": 300, "bbox": [375, 57, 655, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The plots used in the study. The left 3 plots are variations of the box plot: a) The Box Plot [Tuk77], b) Ab- breviated Box Plot [PKRJ10], c) Interquartile Plot [Tuf83]. The right 3 are box plots with additional density informa- tion: d) Vase Plot [Ben88], e) Density Plot [PKRJ10], f) Vi- olin Plot [HN98]. ", "caption_bbox": [391, 240, 692, 329]}, {"image_id": 4, "file_name": "476_04.png", "page": 5, "dpi": 300, "bbox": [95, 57, 378, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A participant is fit with the EEG headset to moni- tor brain activity for the duration of the 100 trial experiment. Distribution visualization pairs are presented side-by-side during each trial and a keyboard is used to enter responses. ", "caption_bbox": [59, 265, 360, 324]}, {"image_id": 5, "file_name": "476_05.png", "page": 5, "dpi": 300, "bbox": [375, 57, 693, 397], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The experimental data collection and analysis workflow. EEG is collected during each of the 100 trials and then segmented into Baseline and Stimulus Epochs. These epochs are then processed using the S-Transform for each sensor. The resulting time-frequency planes are further pro- cessed to extract the gravity frequency and energy density for the theta and alpha bands of frequencies in each epoch. These values are combined in the Cognitive Analysis result- ing in a single time series of cognitive load for each sensor. These time series are then combined through spatially-aware averaging to form the overall cognitive load for the trial. ", "caption_bbox": [391, 406, 692, 571]}, {"image_id": 6, "file_name": "476_06.png", "page": 6, "dpi": 300, "bbox": [59, 57, 378, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Sensor placement around the prefrontal cortex of the 14 data channels in the Emotiv EEG. The regions in red show the Gaussian weighting used to emphasize the regions of the brain most related to working memory. ", "caption_bbox": [59, 288, 360, 347]}, {"image_id": 7, "file_name": "476_07.png", "page": 7, "dpi": 300, "bbox": [63, 57, 378, 245], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Computed cognitive load for each plot type. Con- stant and Gaussian spatial averaging are shown. Lowest cognitive load scores are highlighted in bold while highest scores are italicized. ", "caption_bbox": [391, 134, 692, 193]}], "477": [{"image_id": 0, "file_name": "477_00.png", "page": 3, "dpi": 300, "bbox": [413, 321, 671, 386], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Sources of error in flow vis. (left to right): missing information, interpolation, quantization, noise ", "caption_bbox": [391, 397, 692, 425]}, {"image_id": 1, "file_name": "477_01.png", "page": 3, "dpi": 300, "bbox": [92, 57, 693, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Comparative visualization models based on (a) differences on the data level, (b) differences in extracted features, (c) different visualizations, (d) user studies, and (e) the reconstructability of the underlying data. ", "caption_bbox": [59, 272, 692, 300]}, {"image_id": 2, "file_name": "477_02.png", "page": 4, "dpi": 300, "bbox": [59, 57, 378, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Simulated CFD datasets", "caption_bbox": [121, 320, 296, 333]}, {"image_id": 3, "file_name": "477_03.png", "page": 5, "dpi": 300, "bbox": [58, 57, 694, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Reconstruction pipelines: (top) The reconstruction of texture-based visualizations uses Gabor filters to quantify local orientations of the texture. (bottom) The reconstruction of line-type structures is based on the Hough transform. ", "caption_bbox": [59, 269, 692, 297]}, {"image_id": 4, "file_name": "477_04.png", "page": 6, "dpi": 300, "bbox": [375, 57, 691, 325], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Error computation: To compare the (a) original data and the (b) reconstructed values, a joint version of the two grids (d) and (e) has to be computed. The joint grid (f) comprises all vertices and edges as given in (d) and (e). ", "caption_bbox": [391, 338, 692, 397]}, {"image_id": 5, "file_name": "477_05.png", "page": 7, "dpi": 300, "bbox": [377, 57, 694, 566], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Reconstruction of the cavity dataset: Fig. (a) shows the original grid along with the normalized vector data. A colormap of the direction of the vector field is given in (b). (f,i,l) Three visualization techniques and (g,j,m) the reconstructed directions. (h,k,n) The difference of the direc- tions of the original and the reconstructed field in degrees. ", "caption_bbox": [391, 579, 692, 668]}, {"image_id": 6, "file_name": "477_06.png", "page": 8, "dpi": 300, "bbox": [59, 57, 378, 363], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Reconstruction of the H-block dataset: For each technique (glyphs, streamlines, LIC), column (a) gives the flow visualization, column (b) the reconstructed data, and column (d) the reconstruction error in degree. ", "caption_bbox": [59, 377, 360, 436]}, {"image_id": 7, "file_name": "477_07.png", "page": 9, "dpi": 300, "bbox": [411, 235, 670, 541], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Visualizations with different parameters.", "caption_bbox": [413, 550, 668, 563]}, {"image_id": 8, "file_name": "477_08.png", "page": 9, "dpi": 300, "bbox": [67, 57, 693, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Errors for the three techniques (left to right: vector glyphs, streamlines, and LIC) and different parameter settings.", "caption_bbox": [63, 198, 687, 211]}], "478": [{"image_id": 0, "file_name": "478_00.png", "page": 2, "dpi": 300, "bbox": [375, 58, 694, 336], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Comparison of the feature extraction pipeline fol- lowing classical approaches to the left and the pipeline ac- cording to our approach to the right ", "caption_bbox": [391, 346, 692, 390]}, {"image_id": 1, "file_name": "478_01.png", "page": 5, "dpi": 300, "bbox": [58, 57, 694, 182], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Flow in a T-junction and its POD modes, constructed from 100 snapshots. From left to right: the actual flow (inflow from the left and top), its first and 6th POD mode. The background color is the norm of the point wise contribution of the respective mode to the reconstruction in the respective time step. We see that the mode with the highest energy content gives a simpler instantaneous flow pattern that the flow itself and reveals structures buried under other scales. The arrows are scaled according to norm of the respective vectors in the single modes ", "caption_bbox": [58, 193, 691, 267]}, {"image_id": 2, "file_name": "478_02.png", "page": 6, "dpi": 300, "bbox": [59, 57, 378, 366], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) The relative energy and precision gain of the i-th order approximation compared to the (i \u2212 1)st approxi- mation. The precision is calculated using the time averaged relative L2 -error of the respective approximations. (b) The function graph of the L2 -error plotted against time for sev- eral approximations ", "caption_bbox": [58, 379, 359, 469]}, {"image_id": 3, "file_name": "478_03.png", "page": 6, "dpi": 300, "bbox": [375, 58, 694, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Vorticity method: Both figures show the same threshold, but the scalar vorticity field has been computed from the original field (top) and the 5th approximation (bot- tom), respectively. We see a strong reduction of the structures in the back of the top picture when taking the most dominant modes only. In the outflow, the vorticity field based on the most dominant modes reveals one instead of two vortices. This effect is called vortex braiding. For further discussion we refer to the text. ", "caption_bbox": [391, 338, 692, 473]}, {"image_id": 4, "file_name": "478_04.png", "page": 7, "dpi": 300, "bbox": [79, 58, 378, 504], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) The relative energy and precision gain of the ith order approximation compared to the (i \u2212 1)st approxi- mation. The precision is calculated using the time averaged relative L2 -error of the respective approximations. (b) The function graph of the L2 -error plotted against time for sev- eral approximations. (c) Box plot of the integrative error of the 8-th order approximation. The groups represent particles seeded at all cell centers and advected for n \u00b7 dt, dt being the constant time-sampling distance of the data set. ", "caption_bbox": [58, 516, 359, 651]}, {"image_id": 5, "file_name": "478_05.png", "page": 7, "dpi": 300, "bbox": [375, 57, 694, 421], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Vorticity: Both figures show the scalar vorticity field, using the same color scale, but the fields has been com- puted from the original field (top) and the 4-th approxima- tion (middle), respectively. The bottom row shows the orig- inal and the approximated field on the back-facing clipping plane, to the left and right, respectively. On of the most in- teresting observations is the behavior of the three features in the bottom right corner. For discussion of this and further features we refer to the text. ", "caption_bbox": [391, 432, 692, 567]}, {"image_id": 6, "file_name": "478_06.png", "page": 8, "dpi": 300, "bbox": [375, 58, 694, 414], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: FTLE: As in for the local methods, we keep the color map unvaried for all three figures, but the FTLE field visualized has been computed from the original field (top), the 2nd (middle) and the 4th approximation (bottom). Ob- serve that the focusing on the energetically most dominant scales of motion energy yields a more crispy and detailed output with finer lobes. Adding two more modes does not chance the output, even though just two modes where used for the first approximation. This indicates that the dissipa- tive scales have to be interpreted as \u201cnoise\u201d in the context of integration-based feature extraction. We refer to the text for further discussion. ", "caption_bbox": [391, 428, 692, 609]}], "479": [{"image_id": 0, "file_name": "479_00.png", "page": 1, "dpi": 300, "bbox": [90, 289, 662, 438], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Scalar field on a space-time parameterization of a cylinder flow. All separating structures in space-time are described by this field. The dark lines are 5 different path lines. ", "caption_bbox": [58, 449, 691, 477]}, {"image_id": 1, "file_name": "479_01.png", "page": 2, "dpi": 300, "bbox": [375, 55, 694, 189], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) The stream line integration of p\u0304 starting from (x0 ,t0 ) over the integration time T ends at (\u03c6(x0 ,t0 , T ),t0 + T ). (b) Example of domains of a 2D flow: D is rectangular, D\u0304 is a (volumetric) box, \u03b4D\u0304 is the surface of the box, \u03b4D\u0304in denotes regions of inflow, \u03b4D\u0304out denotes regions of outflow. ", "caption_bbox": [391, 198, 692, 273]}, {"image_id": 2, "file_name": "479_02.png", "page": 3, "dpi": 300, "bbox": [375, 55, 693, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Construction of a field w such that (x0 ,t0 ) is on a ridge but (x1 ,t1 ) is not. Hence the ridge is not a material structure. ", "caption_bbox": [391, 299, 692, 343]}, {"image_id": 3, "file_name": "479_03.png", "page": 3, "dpi": 300, "bbox": [390, 363, 694, 458], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: FTLE field of the cylinder data set. The black lines indicate the ridges that we analyzed for cross flux. ", "caption_bbox": [391, 468, 692, 496]}, {"image_id": 4, "file_name": "479_04.png", "page": 4, "dpi": 300, "bbox": [58, 320, 362, 673], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Flux across FTLE ridges: the black line consists of particles integrated in the vector field, at (a) T = \u221232, (b) T = 0 and (c) T = 32. ", "caption_bbox": [58, 681, 359, 725]}, {"image_id": 5, "file_name": "479_05.png", "page": 4, "dpi": 300, "bbox": [375, 55, 693, 178], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Three parameterizations of the path lines of a 1D time-dependent vector field: (a) P\u0304ts ; (b) P\u0304te ; (c) P\u0304t with ts < t < te . The green lines are the parameterizations: integrating from them covers the whole domain. ", "caption_bbox": [390, 186, 691, 245]}, {"image_id": 6, "file_name": "479_06.png", "page": 4, "dpi": 300, "bbox": [59, 55, 378, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Percentage of the flux crossing the five ridges from figure 4, plotted against ridge arc length. ", "caption_bbox": [58, 270, 359, 298]}, {"image_id": 7, "file_name": "479_07.png", "page": 5, "dpi": 300, "bbox": [58, 55, 378, 196], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) Integrating p\u0304 from (x,t) leaves D\u0304 in (xin ,tin ) and (xout ,tout ). (b) Separating structures of MSF on \u03b4D\u0304in and \u03b4D\u0304out are connected by path lines. ", "caption_bbox": [58, 203, 359, 248]}, {"image_id": 8, "file_name": "479_08.png", "page": 6, "dpi": 300, "bbox": [58, 431, 360, 510], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Color scheme", "caption_bbox": [145, 516, 274, 529]}, {"image_id": 9, "file_name": "479_09.png", "page": 6, "dpi": 300, "bbox": [58, 55, 378, 366], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Time periods of interest for the MSF at t = 240: (a) heat map for t = 240, (b) t poi = [0, 240], (c) t poi = [240, 480], (d) t poi = [120, 240] ", "caption_bbox": [58, 374, 359, 420]}, {"image_id": 10, "file_name": "479_10.png", "page": 7, "dpi": 300, "bbox": [392, 584, 676, 691], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Plot of f (k) (equation 17) against k: (a) double gyre with a maximum of f (k) at a MSF value of k = 0.06, (b) cylinder with a maximum of f (k) at k = 0.046. ", "caption_bbox": [391, 698, 692, 743]}, {"image_id": 11, "file_name": "479_11.png", "page": 7, "dpi": 300, "bbox": [390, 357, 694, 511], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Double period of the double gyre (t=[0,20]) at t=10. The more periods are considered, the more the sepa- rating structures cross. ", "caption_bbox": [391, 521, 692, 565]}, {"image_id": 12, "file_name": "479_12.png", "page": 7, "dpi": 300, "bbox": [58, 55, 694, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Double Gyre example: (a) MSF, (b) MSF separating structures. The black and red crosses show particles advected by the flow. ", "caption_bbox": [58, 308, 691, 336]}, {"image_id": 13, "file_name": "479_13.png", "page": 8, "dpi": 300, "bbox": [375, 55, 694, 494], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: MSF on parameterization subdomains of cylin- der flow: (a) \u03b4D\u0304in , (b) P\u0304t based time slice t = 240, (c) \u03b4D\u0304out . The dark lines are 5 different path lines. ", "caption_bbox": [391, 503, 692, 547]}, {"image_id": 14, "file_name": "479_14.png", "page": 9, "dpi": 300, "bbox": [58, 55, 694, 457], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Flow around a circular cylinder: (a) MSF, (b) MSF separating structures. The black and red crosses show particles advected by the flow. ", "caption_bbox": [58, 466, 691, 494]}], "480": [{"image_id": 0, "file_name": "480_00.png", "page": 2, "dpi": 300, "bbox": [59, 57, 686, 146], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Extracted valleys (blue) from the density value of a discontinuous Galerkin CFD dataset composed of 34,534 cells.", "caption_bbox": [59, 157, 685, 170]}, {"image_id": 1, "file_name": "480_01.png", "page": 6, "dpi": 300, "bbox": [375, 57, 693, 131], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Quadtree face list: (1) using arbitrary sequence. (2) grouping parallel, reduces execution divergence. ", "caption_bbox": [391, 144, 692, 172]}, {"image_id": 2, "file_name": "480_02.png", "page": 6, "dpi": 300, "bbox": [59, 57, 378, 428], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Computation pipeline for extracting PV features from higher-order data. After each iteration, our CUDA im- plementation applies a compaction step (represented by the \u2019R\u2019 box) to remove gaps in the list of primitives. ", "caption_bbox": [59, 438, 360, 497]}, {"image_id": 3, "file_name": "480_03.png", "page": 7, "dpi": 300, "bbox": [108, 57, 693, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Performance measurements obtained with our feature extraction method for the sphere dataset (34,535 elements). Ordinate represents performance measurements in minutes while abscissa represents the value of \u03b5F (smaller \u03b5F implies higher octree refinement). For all tests \u03b5S = \u03b5F /2, to force quadtree subdivisions. Top row: Measurements obtained with octree refine- ment towards feature lines. Bottom row: Measurements obtained with octree refinement towards single points on closed feature lines (as proposed by Theisel et al. [TSW\u2217 05]). Columns present timings for the processing of 2 (left), 4 (center), and 8 (right) dataset elements in parallel. Colored lines represent performance measurements for the octree subdivision (orange), quadtree subdivision (yellow), seed refinement with 2D Newton (green), feature tracing (brown), and total time to extract raw features (blue). ", "caption_bbox": [59, 316, 692, 436]}, {"image_id": 4, "file_name": "480_04.png", "page": 7, "dpi": 300, "bbox": [122, 437, 630, 657], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Performance measurements obtained with our feature extraction method for the shock channel dataset (119 elements). Ordinate represents performance measurements in seconds. For more details, see caption of Figure 4. ", "caption_bbox": [59, 668, 692, 696]}, {"image_id": 5, "file_name": "480_05.png", "page": 8, "dpi": 300, "bbox": [59, 57, 667, 536], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Shock-channel dataset. (a) Raw features extracted from a single element: ridges (red) and valleys (blue) (\u03b5F = 1, \u03b5S = 0.01). No octree subdivision. (b) Same as (a), with \u03b5F = 0.0625, \u03b5S = 10\u22123 . Octree leaves at depth 4. (c) Same as (a), with \u03b5F = 0.0019, \u03b5S = 10\u22123 . Octree leaves at depth 8. (d) Connector curves (white) for all dataset elements (\u03b5F = 10\u22121 , \u03b5S = 10\u22122 ). (e) Filtered valley lines from (d). Minimum scalar value = 1 and maximum = 1.9995. Angle between gradient and FFF tangent vector \u2264 27 degrees. ", "caption_bbox": [58, 549, 691, 623]}, {"image_id": 6, "file_name": "480_06.png", "page": 9, "dpi": 300, "bbox": [69, 57, 693, 185], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Extracted line-type features from the sphere dataset. Left: Unfiltered ridges (red), valleys (blue), and connector curves (white). Right: Isosurface rendering along the valley lines filtered with angle (\u2264 3.1 degrees) and maximum isovalue (\u2264 0.998) criteria. For both images \u03b5F = 3 and \u03b5S = 10\u22122 . ", "caption_bbox": [58, 195, 691, 239]}], "481": [{"image_id": 0, "file_name": "481_00.png", "page": 3, "dpi": 300, "bbox": [60, 57, 693, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: System overview: the system has three major components: a preprocessing component for extracting keywords and creating a preliminary layout, a word cloud generation component for creating compact and semantic-preserving word clouds, and a visualization component for visualizing the word clouds. ", "caption_bbox": [58, 350, 691, 394]}, {"image_id": 1, "file_name": "481_01.png", "page": 4, "dpi": 300, "bbox": [59, 57, 692, 190], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration for Seam Carving: (a) a sparse word cloud layout with a Gaussian importance field; (b) layout partitioned by the bounding boxes of the words; (c) an optimal seam (marked in blue), a connected path of zones, from left to right is selected; (d) seam pruning to obtain a seam with an identical width (yellow seam); (e) the word cloud layout after removing the yellow seam in (d); (f) the resulting compact and semantic-preserving word cloud after the seam carving optimization. ", "caption_bbox": [58, 200, 691, 259]}, {"image_id": 2, "file_name": "481_02.png", "page": 7, "dpi": 300, "bbox": [61, 485, 359, 818], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparison of different seam-carving techniques. (a) a word cloud generated by seam-carving by pixels; (b) a word cloud generated by seam-carving by zones. The two re- sults are almost the same, but the zone-based seam-carving runs much faster than the pixel-based technique. ", "caption_bbox": [58, 830, 359, 904]}, {"image_id": 3, "file_name": "481_03.png", "page": 7, "dpi": 300, "bbox": [58, 57, 693, 366], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration for split and merge interactions: (a) and (b) two selected word clouds to be merged; (c) a resulting word cloud created by merging (a) and (b); (d) a word cloud to be split, i.e., a group of keywords in red are selected to be separated from (d); (e) and (f) two resulting word clouds generated by splitting the keywords in (d). ", "caption_bbox": [58, 400, 691, 444]}, {"image_id": 4, "file_name": "481_04.png", "page": 8, "dpi": 300, "bbox": [67, 523, 681, 841], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a)-(c) semantic-preserving word clouds of the IEEE Vis/InfoVis paper abstracts at 1999, 2005, and 2010; (d)-(f) semantic-preserving word clouds of the EuroVis paper abstracts at 1999, 2005, and 2010. ", "caption_bbox": [58, 853, 691, 882]}, {"image_id": 5, "file_name": "481_05.png", "page": 8, "dpi": 300, "bbox": [59, 57, 689, 447], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison of two algorithms. (a) a preliminary sparse word cloud layout for the AIG data; (b)-(c) word clouds created by our previous work [CWL\u2217 10]; (d)-(e) word clouds created by our seam carving algorithm. ", "caption_bbox": [58, 461, 691, 490]}], "482": [{"image_id": 0, "file_name": "482_00.png", "page": 5, "dpi": 300, "bbox": [78, 57, 693, 692], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A view of the CorpusSeparator tool after importing a corpus of 300 16th and 17th century English plays. 1. The upper left panel displays filtering information and principal component options, as well as options to save a weighted sum of tags as a combination of one or two principal components for later use by the TextViewer. One can scalar multiply each axis\u2019 principal component by 0, -1, or +1. Both multiplied axes are then added together to generate an ad-hoc saliency metric. 2. The composition of the corpus (in terms of blocks of different groups). Users can color based on a priori groups like genre, but also metadata such as composition year or author. ", "caption_bbox": [59, 708, 692, 797]}, {"image_id": 1, "file_name": "482_01.png", "page": 6, "dpi": 300, "bbox": [59, 57, 660, 373], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Two views of the TextViewer tool on Shakespeare\u2019s \u201cA Midsummer Night\u2019s Dream.\u201d The left view shows an initial view of the text, whereas the right view shows the same location in the text after a threshold has been set. Lines with scores at or above the threshold are in focus. This creates bubbles of salient passages that are in focus, while the rest of the text recedes. 1. The left panel of each image is the raw text, with colored underlines for text that has been tagged. ", "caption_bbox": [59, 386, 692, 445]}, {"image_id": 2, "file_name": "482_02.png", "page": 7, "dpi": 300, "bbox": [58, 57, 378, 248], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An example of the accordion view of per tag \u201ccards\u201d in CorpusSeparator. When a mouse is over a card, it expands into a cumulative distribution histogram of a par- ticular tag. The count of a particular tag\u2019s appearance in each text is represented by a block. Lines for the mean and the standard deviation in both directions are represented by red lines. To exclude outliers users can drag thresholds up or down, removing texts outside of the threshold from con- sideration in any future Principal Component Analysis. Col- lapsed cards represent distribution as saturation values of blocks of color, allowing tags with outliers to be seen at a glance without having to expand every card. ", "caption_bbox": [59, 274, 360, 454]}, {"image_id": 3, "file_name": "482_03.png", "page": 8, "dpi": 300, "bbox": [58, 57, 378, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Court Masques (highlighted in red) vs. Shake- speare, in views from CorpusSeparator. The masques are \u201cpushed\u201d leftward as a result of the current choice of prin- cipal components. We can see that certain tags (such as the FirstPer tag) do a good job of distinguishing the two groups, with all of one type clustered at one end or another of the distribution. TextViewer allows users to zoom in and see \u201cmasque-like\u201d vs. \u201cShakespeare-like\u201d passages. ", "caption_bbox": [59, 299, 360, 419]}], "483": [{"image_id": 0, "file_name": "483_00.png", "page": 4, "dpi": 300, "bbox": [59, 57, 615, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The user interface of PaperVis. The central area, region E, is for primary visualization. Region A contains the configuration options, while region B is used for displaying the viewing history. Data filtering and selection controls are placed in region C. Finally, details of the currently selected paper are shown in region D. ", "caption_bbox": [59, 363, 692, 407]}, {"image_id": 1, "file_name": "483_01.png", "page": 5, "dpi": 300, "bbox": [392, 613, 693, 778], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Examples of Citation-Reference Mode. (a) The vi- sualization result after a paper of interest being selected. The bin circles, marked in yellow and black, are expanded accordingly to accommodate the nodes in those bins. (b) In a refocused view, colored boundaries of nodes show their status in the previous view. ", "caption_bbox": [391, 788, 692, 877]}, {"image_id": 2, "file_name": "483_02.png", "page": 6, "dpi": 300, "bbox": [390, 228, 690, 469], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Results from (a) CaseCluster ,(b) FP-tree and (c) PaperVis. Compared with CaseCluster and FP-tree, our pro- posed algorithm keeps the largest common keyword sets be- tween 2 papers. Paper A and paper B have 3 keywords in common in this example. ", "caption_bbox": [391, 480, 692, 554]}, {"image_id": 3, "file_name": "483_03.png", "page": 7, "dpi": 300, "bbox": [377, 57, 694, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Examples in the Mixed Mode. (a) Exploring pa- pers with 2 common keywords within a paper\u2019s bibliographic data. (b) The associate result after a node in (a) is double- clicked. The paper nodes in the outer circle refer to the pa- pers having no keywords in common with the center one. ", "caption_bbox": [391, 254, 692, 328]}, {"image_id": 4, "file_name": "483_04.png", "page": 7, "dpi": 300, "bbox": [59, 197, 360, 362], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Examples in the Keyword Mode. (a) Start with the papers containing the keyword information retrieval, and find their common keyword sets with 3 keywords in common. (b) The associate result after a node in (a) is double-clicked. ", "caption_bbox": [59, 375, 360, 434]}, {"image_id": 5, "file_name": "483_05.png", "page": 8, "dpi": 300, "bbox": [390, 564, 694, 671], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Results of Case Study 3. (a) There are 15 out of the selected paper\u2019s 30 references or citations share the same keyword. (b) After refocusing the view, we found that the pa- pers with higher importance have bigger correlation among each other. (c) Refocusing with the largest red node in (b), and several patterns can be observed as well. ", "caption_bbox": [391, 681, 692, 770]}, {"image_id": 6, "file_name": "483_06.png", "page": 8, "dpi": 300, "bbox": [390, 295, 693, 452], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Results of Case Study 2. (a) The numbers of pa- pers contain the keyword information visualization and have 3 keywords in common are visualized. (b) The view is refo- cused with the node hypertext(3) in (a). More information could be dug out by expanding the citation/reference rela- tionships of the 3 nodes in the inner circle. ", "caption_bbox": [391, 464, 692, 554]}, {"image_id": 7, "file_name": "483_07.png", "page": 9, "dpi": 300, "bbox": [58, 57, 693, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Results of Case Study 1. (a) The paper entitled Managing multiple focal levels in Table Lens is selected. And two evident patterns could be easily observed. (b) Expanding the citation/reference relationships of the node with the largest size. (c) Expanding the citation/reference relationships of the node which is the closest to the central node. (d) Refocusing on the node selected in (c). And some interesting things can also be found by inspecting the nodes with colored boundaries. ", "caption_bbox": [59, 253, 692, 312]}], "484": [{"image_id": 0, "file_name": "484_00.png", "page": 2, "dpi": 300, "bbox": [59, 56, 378, 179], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An example of structural changes in clusters of temporal data. Two well-separated clusters (at t0 ) merge into a single group at t1 and split into two groups again at t2 . ", "caption_bbox": [58, 190, 359, 235]}, {"image_id": 1, "file_name": "484_01.png", "page": 3, "dpi": 300, "bbox": [375, 56, 693, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An overview of our approach. A subset of tem- poral clusters are analyzed using our techniques and con- ventional IVA tools in terms of their structural changes and quality variations. Plausible clusters are analyzed to derive more insight on data. Low quality clusters are updated or discarded. ", "caption_bbox": [391, 320, 692, 409]}, {"image_id": 2, "file_name": "484_02.png", "page": 4, "dpi": 300, "bbox": [59, 56, 378, 218], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: In this artificial dataset, two groups move towards each other following the paths 1 and 2. One point follows path 3 and one item shortly gets away from its group (4). ", "caption_bbox": [58, 232, 359, 276]}, {"image_id": 3, "file_name": "484_03.png", "page": 5, "dpi": 300, "bbox": [59, 56, 378, 376], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Five clusterings visualized in the cluster view. The temporal span of each clustering is visualized on top. Brushes b1 and b2 are made to select two clusters. (b) Color coding for silhouette values. ", "caption_bbox": [58, 385, 359, 444]}, {"image_id": 4, "file_name": "484_04.png", "page": 5, "dpi": 300, "bbox": [375, 56, 693, 397], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Ordering cluster view improves the overall per- ception of cluster quality. Before (a) and after ordering (b). ", "caption_bbox": [391, 408, 692, 436]}, {"image_id": 5, "file_name": "484_05.png", "page": 6, "dpi": 300, "bbox": [59, 56, 378, 172], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: For four 2D points (a), we compute minimum dis- tances (b), maximum distances (c), and vicinity measure V (d). V is the sum of neighboring items within a sphere of radius D (0 + 0 + 1 + 1 = 2). ", "caption_bbox": [58, 183, 359, 242]}, {"image_id": 6, "file_name": "484_06.png", "page": 7, "dpi": 300, "bbox": [59, 382, 361, 602], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Variation of silhouette values. Group structures change as items move over time. These variations are clearly visible in cluster view by observing the color changes. ", "caption_bbox": [58, 612, 359, 656]}, {"image_id": 7, "file_name": "484_07.png", "page": 7, "dpi": 300, "bbox": [59, 56, 693, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Left: Temporal signatures view. The upper bound represents maximum average distance, the lower represents min- imum average distance and the vicinity measure is represented with the color map depicted on the bottom right. The dotted line represents the threshold distance D. The standard deviation is rendered through the transparent green color. Circles mark changes due to movement 4 in Fig. 3. Right: Signature views computed for clusters c1 , c2 and c1 \u222a c2 over time interval [t0 ,t1 ]. ", "caption_bbox": [58, 285, 691, 346]}, {"image_id": 8, "file_name": "484_08.png", "page": 8, "dpi": 300, "bbox": [58, 56, 693, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: a) Cluster merging-splitting behavior. A cluster is selected with b1 and the time selection is enlarged by brushes b2 and b3 . Merging occurs around the smaller band in the middle, which gets larger at end of the sequence due to splitting in signature view. b) Searching for a plausible cluster. Two good signatures are identified (circles). The dashed circle is discarded due to its structural instability in cluster view (shown with the selection on the right). The red circled cluster is picked for further analysis. Moreover, the observed signatures allow to discard clusters (X) according their structure. ", "caption_bbox": [58, 382, 691, 456]}, {"image_id": 9, "file_name": "484_09.png", "page": 9, "dpi": 300, "bbox": [59, 56, 693, 325], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Lipid cluster development. Top left: Coherent cluster c = b1 in all clusterings, C1\u22125 . Bottom left: The signature view for c with extended time interval to showcase signatures in remaining clustering intervals TL = [TC1 \u222a TC5 ], where it expresses high stability. Top right: We extend TL to search for \"existing\" boundaries (arrow) for cluster c, where we mark another coherent interval TC6 . We add cluster C6 , where we observe that items in b1 reforms cluster c again at TC6 (circle). ", "caption_bbox": [58, 335, 691, 396]}], "485": [{"image_id": 0, "file_name": "485_00.png", "page": 3, "dpi": 300, "bbox": [143, 56, 693, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: 6 cycles of ECG data [ECG] projected using star glyphs, a window size of 20, an overlap of 19, and no sampling. Note the similarities and differences in shape and position between the color coded cycles. One cycle definitely diverges from the others. ", "caption_bbox": [58, 353, 691, 397]}, {"image_id": 1, "file_name": "485_01.png", "page": 4, "dpi": 300, "bbox": [402, 666, 682, 765], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Two glyph types used: stars and profiles.", "caption_bbox": [411, 775, 667, 788]}, {"image_id": 2, "file_name": "485_02.png", "page": 5, "dpi": 300, "bbox": [375, 56, 693, 389], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Color mapped across the entire time-series (upper image) versus across each cycle (lower image) of a ECG dataset [ECG], with window size 20, slide size 19, and no sampling. ", "caption_bbox": [391, 422, 692, 481]}, {"image_id": 3, "file_name": "485_03.png", "page": 5, "dpi": 300, "bbox": [398, 503, 686, 589], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The Time-Line View of 6 cycles of ECG data [ECG]. ", "caption_bbox": [391, 599, 692, 627]}, {"image_id": 4, "file_name": "485_04.png", "page": 7, "dpi": 300, "bbox": [400, 278, 685, 651], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Similar and different shapes in the Dow Jones data [Dow] (window size = 30, overlap = 29, no sampling, cycle = 10 years, color by year within cycle). Early data is to the right. The highlighted (black) region is an unusual down- ward lobe from the 1980\u2019s. A zoomed region of the time-line view is shown below. ", "caption_bbox": [391, 681, 692, 770]}, {"image_id": 5, "file_name": "485_05.png", "page": 7, "dpi": 300, "bbox": [66, 507, 354, 740], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A divergence in the glyph positions reveals a vari- ation on the slope and height in the ECG data [ECG] (win- dow size = 32, overlap = 31, no sampling, color across cy- cles). ", "caption_bbox": [58, 771, 359, 830]}, {"image_id": 6, "file_name": "485_06.png", "page": 7, "dpi": 300, "bbox": [65, 56, 378, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: An analysis of 100 years of daily Dow Jones Aver- ages [Dow] (window size = 40, overlap = 39, no sampling, color by time) using relative changes reveals a period of time in the 1930s with significant variability. Selecting the central cluster in the glyph view and coloring the glyphs blue reveals that most outliers come from that period (yellow). ", "caption_bbox": [58, 381, 359, 470]}, {"image_id": 7, "file_name": "485_07.png", "page": 8, "dpi": 300, "bbox": [66, 144, 354, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The upper display shows the first derivative of the ECG data [ECG] (window size = 8, overlap = 7, no sam- pling), with color mapped to position in the cycle. Selecting the values in the central cluster and de-emphasizing them (make more transparent) does a nice job of revealing where in the cycle the larger changes were centered (mostly green), as can be confirmed in the time-line view. ", "caption_bbox": [58, 413, 359, 518]}, {"image_id": 8, "file_name": "485_08.png", "page": 8, "dpi": 300, "bbox": [375, 56, 684, 420], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Six days of traffic data [DOT], with color mapped to the position in the cycle (time of day), window size = 20, and sampling rate of 25%.. The blue/purple colors are around the peak time, and yellow/green colors are from pe- riods of light traffic. The right-most part of the image shows some red glyphs moving into the low traffic region of the dis- play. The stacked cycle view confirms this as well as reveals other patterns of interest. ", "caption_bbox": [391, 452, 692, 572]}, {"image_id": 9, "file_name": "485_09.png", "page": 9, "dpi": 300, "bbox": [139, 56, 693, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Looking for dominant shapes in the ECG data [ECG] (window size = 8, overlap = 7, sampling = 50%). By scaling up the profile glyph sizes, we can see the majority of shapes are relatively flat, with a small percentage representing peaks, valleys, and upward/downward trends. ", "caption_bbox": [58, 366, 691, 410]}], "486": [{"image_id": 0, "file_name": "486_00.png", "page": 1, "dpi": 300, "bbox": [90, 299, 655, 605], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visual prediction of next day\u2019s power consumption KW from historical data in a data center.", "caption_bbox": [120, 614, 624, 629]}, {"image_id": 1, "file_name": "486_01.png", "page": 3, "dpi": 300, "bbox": [394, 229, 669, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": " Figure 2: Visual Peak-Preserving Prediction Process. Both peak-preserving smoothing and peak-preserving prediction are automated methods for generating better ", "caption_bbox": [390, 317, 664, 364]}, {"image_id": 2, "file_name": "486_02.png", "page": 4, "dpi": 300, "bbox": [394, 173, 669, 545], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparison of Peak-Preserving Smoothing to Weighted Moving Average Smoothing. ", "caption_bbox": [393, 566, 657, 595]}, {"image_id": 3, "file_name": "486_03.png", "page": 4, "dpi": 300, "bbox": [82, 249, 356, 667], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A variant version of Douglas-Peucker algorithm. ", "caption_bbox": [89, 670, 363, 699]}, {"image_id": 4, "file_name": "486_04.png", "page": 5, "dpi": 300, "bbox": [88, 251, 372, 520], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Algorithm for prediction based on daily patterns.", "caption_bbox": [98, 519, 357, 533]}, {"image_id": 5, "file_name": "486_05.png", "page": 6, "dpi": 300, "bbox": [113, 592, 654, 828], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Brushing and linking predicted data to their past occurrences      Different shades of gray indicate the degree of significance            (dark: high significance; light: low significance) ", "caption_bbox": [207, 827, 555, 870]}, {"image_id": 6, "file_name": "486_06.png", "page": 8, "dpi": 300, "bbox": [90, 632, 366, 814], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison of Holt Winters method with our peak-preserving prediction. Peak removed in Holt Winters. Our prediction handles the peak better than Holt Winters method. ", "caption_bbox": [89, 818, 353, 874]}, {"image_id": 7, "file_name": "486_07.png", "page": 8, "dpi": 300, "bbox": [89, 57, 667, 431], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visual prediction of daily SAP server utilization on Server A in a IT-Services center", "caption_bbox": [158, 434, 621, 449]}, {"image_id": 8, "file_name": "486_08.png", "page": 9, "dpi": 300, "bbox": [94, 301, 363, 573], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Prediction accuracy comparison between              actual and predicted data     (blue: predicted values / red: actual values) ", "caption_bbox": [95, 577, 347, 619]}], "487": [{"image_id": 0, "file_name": "487_00.png", "page": 1, "dpi": 300, "bbox": [375, 323, 695, 774], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Protein with selective structural abstraction, medium \u2018illustrativeness,\u2019 and support of spatial perception. ", "caption_bbox": [392, 784, 695, 812]}, {"image_id": 1, "file_name": "487_01.png", "page": 3, "dpi": 300, "bbox": [59, 57, 698, 200], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Structural abstraction stages: (a) space fill, (b) balls-and-sticks, (c) licorice, (d) backbone, and (e) ribbon.", "caption_bbox": [85, 208, 668, 221]}, {"image_id": 2, "file_name": "487_02.png", "page": 5, "dpi": 300, "bbox": [59, 57, 698, 182], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Stages of support of spatial perception: (b)\u2013(c) ambient occlusion and object attenuation and (d)\u2013(e) added halos.", "caption_bbox": [65, 187, 688, 200]}, {"image_id": 3, "file_name": "487_03.png", "page": 5, "dpi": 300, "bbox": [59, 231, 363, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The two extremes of support of spatial perception applied to a fully stylized visualization with full structural ab- straction. Notice the halos and line/ribbon attenuation (b). ", "caption_bbox": [60, 350, 364, 393]}, {"image_id": 4, "file_name": "487_04.png", "page": 5, "dpi": 300, "bbox": [59, 415, 363, 564], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Abstraction along \u2018illustrativeness\u2019: (a) \u2018photore- alistic,\u2019 (b) cel shading, and (c) black-and-white. ", "caption_bbox": [60, 575, 364, 603]}, {"image_id": 5, "file_name": "487_05.png", "page": 6, "dpi": 300, "bbox": [59, 57, 695, 456], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A selection of results: in (a) a focus is placed on the secondary structure of a chain while showing the back part of the molecule as context, (b) shows the same molecule but now with three structural abstraction levels: balls-and-sticks, ribbon, and licorice; the visualizations in (c) and (d) demonstrate how illustrativeness can be used to guide attention. ", "caption_bbox": [60, 464, 695, 507]}], "488": [{"image_id": 0, "file_name": "488_00.png", "page": 2, "dpi": 300, "bbox": [59, 57, 378, 364], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A screenshot of our application. The components are: \u00c0 3D visualization; \u00c1 clipping plane view; \u00c2 graph showing the cavity size over time; \u00c3 text console. ", "caption_bbox": [58, 376, 359, 421]}, {"image_id": 1, "file_name": "488_01.png", "page": 2, "dpi": 300, "bbox": [375, 57, 634, 243], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Solvent Excluded Surface of a small protein (iso- merase FKBP12, blue) with a ligand (red). The ligand is docked to the protein, i.e. it is not intersecting the protein surface but rather fits like a key to the lock. ", "caption_bbox": [391, 254, 692, 313]}, {"image_id": 2, "file_name": "488_02.png", "page": 3, "dpi": 300, "bbox": [375, 57, 694, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Volume isosurface of a hydrolase combined with a Cartoon (a) and a Ball-and-Stick (b) model. ", "caption_bbox": [391, 254, 692, 282]}, {"image_id": 3, "file_name": "488_03.png", "page": 4, "dpi": 300, "bbox": [375, 57, 657, 197], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An example graph plotted for the first 50 frames of a trajectory. The interesting points in time, where a notable change of the cavity\u2019s volume occurs, are labeled. ", "caption_bbox": [391, 208, 692, 252]}, {"image_id": 4, "file_name": "488_04.png", "page": 4, "dpi": 300, "bbox": [59, 57, 378, 259], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Clipping plane view used for cavity selection. The two cavities (circled red) are clearly discernible. ", "caption_bbox": [59, 271, 360, 299]}, {"image_id": 5, "file_name": "488_05.png", "page": 4, "dpi": 300, "bbox": [96, 627, 323, 875], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Illustration of a segmentation result (circled yel- low). The selected cavity inside the isomerase is visualized by yellow spheres for each voxel. ", "caption_bbox": [59, 887, 360, 931]}, {"image_id": 6, "file_name": "488_06.png", "page": 5, "dpi": 300, "bbox": [58, 57, 693, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Different views of an open cavity. The segmentation has reached the environment and a notable change in cavity volume has been detected, resulting in a cyan coloring of the cavity (a). The shape and size of the substrate channel is clearly observable, especially when a clipping plane is applied (b). Without the visualization of the segmentation, the cavity is not easily discernible (c), even with the clipping plane applied. (d) shows the clipping plane with the substrate channel circled red. ", "caption_bbox": [59, 304, 692, 363]}, {"image_id": 7, "file_name": "488_07.png", "page": 6, "dpi": 300, "bbox": [375, 57, 649, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The opacity of the isosurface is set to zero, how- ever, due to the increasing opacity for regions perpendicular to the view direction, bordering regions of the molecule are still visible (Insulin, PDB-ID: 1RWE, \u223c1.000 atoms, col- ored by amino acid chain). ", "caption_bbox": [391, 254, 692, 328]}, {"image_id": 8, "file_name": "488_08.png", "page": 6, "dpi": 300, "bbox": [65, 491, 357, 619], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Semi-transparent renderings of the volumetric sur- face (left) and SES (right) of an enterotoxin (PDB-ID: 1TII, \u223c5.500 atoms), colored by B-factor. ", "caption_bbox": [59, 631, 360, 675]}, {"image_id": 9, "file_name": "488_09.png", "page": 6, "dpi": 300, "bbox": [59, 57, 378, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: SES approximation with an isosurface (blue). The probe, which would define the SES, is depicted in green. The density field is computed from two (left) and three (right) atoms (yellow). r indicates the van der Waals radius and the approximation error is highlighted in red. ", "caption_bbox": [59, 202, 360, 276]}, {"image_id": 10, "file_name": "488_10.png", "page": 7, "dpi": 300, "bbox": [375, 57, 693, 184], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The curve plotted for the simulation of CALA. The two pairs of short-term openings are clearly visible. The last, long plateau reaching to the end indicates the formation of a stable substrate channel (also visible in the 3D view). ", "caption_bbox": [391, 199, 692, 258]}, {"image_id": 11, "file_name": "488_11.png", "page": 8, "dpi": 300, "bbox": [59, 57, 692, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Performance measurements for various data sets. SC denotes the percentage of the screen, which is covered by the protein. VR denotes the volume resolution. (\u2217) marks data sets obtained from the PDB. ", "caption_bbox": [391, 331, 692, 390]}, {"image_id": 12, "file_name": "488_12.png", "page": 9, "dpi": 300, "bbox": [111, 715, 309, 890], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Hemoglobin A (PDB-ID: 1BIJ) colored with a rainbow color scheme. ", "caption_bbox": [59, 902, 360, 930]}], "489": [{"image_id": 0, "file_name": "489_00.png", "page": 1, "dpi": 300, "bbox": [58, 590, 693, 803], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A 2D graph showing the topology of the 3D potential energy function of a complex of formic and acetic acids, which depends on the positions of constituting atoms. Blue and red dots represent minimum energy configurations and lowest barriers connecting neighboring minima, respectively. Edges represent the energy cost of a particular transformation, with darker and wider edges corresponding to transformations through lower barriers (more likely transformations). Two vertical branches corresponding to different positions of protons are visible on the left and right side of the graph. Energy barriers for transforming the right branch into left one are lower than for the reverse transformation. ", "caption_bbox": [59, 491, 692, 580]}, {"image_id": 1, "file_name": "489_01.png", "page": 2, "dpi": 300, "bbox": [375, 57, 685, 474], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Chemical system configuration of a dimer of formic and acetic acid. (b) Energy of the system in Hartrees (y-axis) as a function of the methyl group rotation angle be- tween 0 to 360 degrees (x-axis). Blue and red dots mark en- ergy minima and barriers, respectively. (c) Naive graph rep- resentation of transformation pathways. (d) Proposed graph representation, where the top row of a energy minima label displays its coordinate and the bottom row its energy value. ", "caption_bbox": [391, 479, 692, 599]}, {"image_id": 2, "file_name": "489_02.png", "page": 7, "dpi": 300, "bbox": [90, 57, 693, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Energy functions of DFA along the (a) first dimension, (b) second dimension, (c) third dimension, and (d) forth dimension, and respective graphs for (e) the third dimension, showing the periodic nature of the dimension and (f) the fourth dimension, where it correctly handles the special case of periodicity. All labels in (e) and (f) use the convention from Figure 2. ", "caption_bbox": [59, 374, 692, 418]}, {"image_id": 3, "file_name": "489_03.png", "page": 7, "dpi": 300, "bbox": [62, 439, 352, 668], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Two-dimensional energy function landscapes of DFA and corresponding graphs: (a) F12 \u2212 M12 (b) F34 \u2212 M34 . Constructed graph easily visualizes all possible paths, while in case of direct visualization it might be not obvious. ", "caption_bbox": [59, 682, 360, 741]}, {"image_id": 4, "file_name": "489_04.png", "page": 7, "dpi": 300, "bbox": [403, 439, 690, 729], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Three-dimensional energy function volume render- ings of DFA and corresponding graphs: (a) F123 \u2212 M123 (b) F124 \u2212 M124 . As the number of dimensions grows, direct vi- sualization becomes complicated. ", "caption_bbox": [391, 744, 692, 803]}, {"image_id": 5, "file_name": "489_05.png", "page": 8, "dpi": 300, "bbox": [490, 359, 634, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Persistence diagram of the energy function of a CH4 guest molecule in porous material. ", "caption_bbox": [390, 478, 691, 506]}, {"image_id": 6, "file_name": "489_06.png", "page": 8, "dpi": 300, "bbox": [375, 57, 633, 232], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Picture of (a) methane (b) LTA zeolite struc- ture. The orange isosurface highlights the closest distance to which the center of the guest molecule center can approach. The large cage is located in the center of the unit cell. The small cage is shared among eight cells and is visible in the corners of the unit cell. ", "caption_bbox": [391, 253, 692, 342]}, {"image_id": 7, "file_name": "489_07.png", "page": 8, "dpi": 300, "bbox": [59, 57, 378, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Graph of the 4D energy function of DFA. Nodes are labeled A1 to A9 and B1 to B6 to highlight two sub- graphs. A1-A9 correspond to minima with coordinates of 0.95\u00c5 along the first and second dimension. The remain- ing third and fourth coordinates are (45,345), (180,345), (60,180), (285,345), (180,180), (60,0), (300,180), (180,0), and (300,0) for A1 to A9, respectively. Similarly, the first and second coordinate for B1-B6 are 1.75\u00c5. The remain- ing coordinates are (60,345), (180,345), (300,345), (60,0), (180,0), (300,0) for B1 to B6, respectively. ", "caption_bbox": [59, 250, 360, 400]}, {"image_id": 8, "file_name": "489_08.png", "page": 9, "dpi": 300, "bbox": [58, 57, 378, 519], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: (a) Volume rendering of the energy function of a CH4 molecule in an LTA zeolite and lowest energy paths connecting neighboring minima. (b) Corresponding graph showing lowest energy paths (an edge going through a face of the periodic box marked with arrows). ", "caption_bbox": [58, 531, 359, 605]}], "490": [{"image_id": 0, "file_name": "490_00.png", "page": 4, "dpi": 300, "bbox": [59, 56, 636, 269], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A spherical reconstruction kernel in the spatial domain (left) maps to an ellipse in the scatterplot domain (middle) and a hyperbola in the parallel-coordinates domain (right). ", "caption_bbox": [58, 274, 691, 302]}, {"image_id": 1, "file_name": "490_01.png", "page": 6, "dpi": 300, "bbox": [375, 56, 672, 372], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Rendering performance for splatted continuous scatterplots of the \u201cbucky ball\u201d dataset depending on splat size and sampling frequency. From the plot, a linear de- pendancy between sampling resolution and frames per sec- ond can be concluded. Note that, for comparison, the per- formance of traditional discrete scatterplots rendered with point-size one and of continuous scatterplots rendered with the projected tetrahedra algorithm are included. The tradi- tional scatterplots are limited to 60 frames per second by the frame refresh rate of the test-hardware. In contrast, the fram- erate of continuous scatterplots lies well below one frame per second. ", "caption_bbox": [391, 385, 692, 566]}, {"image_id": 2, "file_name": "490_02.png", "page": 7, "dpi": 300, "bbox": [61, 56, 693, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The \u201cbucky ball\u201d dataset rendered using three different approaches for scatterplots: Discrete scatterplot (left), splat- ted densities (middle), and the original continuous approach using projected tetrahedra (right). Density is represented by color, where black denotes low density and white denotes high density. Although the splatted and discrete plots use exactly the same samples, the splatted image provides a better approximation to a continuous density distribution. Please note that the plots are not supposed to be identical, as the original approach uses a piecewise linear interpolation model on a tetrahedral grid, whereas the discrete and splatted versions are based on piecewise trilinear interpolation on a uniform grid. Nevertheless, the plots show an almost identical density distribution, where the prominent arc is an indicator for a material boundary. ", "caption_bbox": [58, 281, 691, 386]}, {"image_id": 3, "file_name": "490_03.png", "page": 8, "dpi": 300, "bbox": [59, 56, 661, 642], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The effect of the sampling resolution and the kernel size parameter with respect to the overall coarseness of the plot. In the matrix shown above, the number of samples increases from top to bottom while the splat size increases from left to right. In both cases, the corresponding images become smoother. At the same time, however, increasing splat sizes result in less accurate plots, as can be seen in the rightmost column. Here, the blur introduced by larger splats makes the image appear \u201cwider\u201d. The bottom row shows the L2 error of densities from the splatted plots with respect to a traditional, discrete scatterplot rendered with 107 samples of point-size four. While the convergence behavior is similar for all columns, the total error decreases with increasing smoothing factor k. ", "caption_bbox": [58, 648, 691, 753]}, {"image_id": 4, "file_name": "490_04.png", "page": 9, "dpi": 300, "bbox": [60, 56, 695, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Splatted parallel coordinates (103 samples, left) and discrete parallel coordinates (2.5 \u00d7 104 samples, right) showing", "caption_bbox": [58, 247, 691, 272]}], "491": [{"image_id": 0, "file_name": "491_00.png", "page": 2, "dpi": 300, "bbox": [59, 57, 662, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Comparison between parallel-coordinates plots where line density is linearly/logarithmically mapped to brightness (first/second column, respectively), and color (third column), respectively. Each bottom-row image has been generated by ap- plying our technique to the corresponding top-row plot. In the first and second columns, color is used for distinguishing between focus (red) and context (grey-scale), respectively. Regions where line density does not vary strongly are improved most visibly. The coherent noise texture employed by our method provides important information on line orientations that is otherwise lost. ", "caption_bbox": [58, 346, 691, 420]}, {"image_id": 1, "file_name": "491_01.png", "page": 4, "dpi": 300, "bbox": [59, 57, 693, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The rendering pipeline that we use to synthesize the final coherent noise texture. Except for the line rasterization stage itself, all operations are image-based. This makes the technique scalable to very large data sizes. The steps indicated in yellow can be used to merge input from multiple subsets of the data set in order to accommodate focus+context visualizations. ", "caption_bbox": [58, 310, 691, 354]}, {"image_id": 2, "file_name": "491_02.png", "page": 5, "dpi": 300, "bbox": [90, 57, 378, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparison of the influence of the contrast en- hancement parameter \u03b2, and the number of iterations for diffusion, respectively. A small number of iterations requires higher values of \u03b2 in order to generate comparable image contrast. The reason for this is that the influence of the con- trast enhancement function f increases over time. ", "caption_bbox": [58, 258, 359, 347]}, {"image_id": 3, "file_name": "491_03.png", "page": 5, "dpi": 300, "bbox": [375, 57, 693, 194], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Two different resolution levels of a coherent noise texture synthesized with our technique. The input were two sets of crossing lines. The set of lines that are packed tightly together is represented well by the high-frequency noise (left image), whereas the set of lines spread out more broadly is also represented by low-frequency noise (right image). ", "caption_bbox": [391, 206, 692, 295]}, {"image_id": 4, "file_name": "491_04.png", "page": 7, "dpi": 300, "bbox": [375, 57, 693, 204], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Difference of blending the focus and the context, at different stages in our rendering pipeline. (a) the two ten- sor fields have been created separately for focus and context during line rasterization, but are then immediately combined to form a single composite field. (b) the entire rendering pipeline is executed for both tensor fields separately, until the final image compositing step merges their coherent noise textures into the result image. ", "caption_bbox": [391, 217, 692, 337]}, {"image_id": 5, "file_name": "491_05.png", "page": 8, "dpi": 300, "bbox": [391, 727, 693, 853], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Enhancing phase-space diagrams with our method (right image). The focus data is the same as in Fig- ure 6. For comparison, the original visualization is shown in the left image. ", "caption_bbox": [391, 866, 692, 925]}, {"image_id": 6, "file_name": "491_06.png", "page": 8, "dpi": 300, "bbox": [59, 57, 378, 259], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Comparison between an original time series vi- sualization (top), and our enhanced version (bottom). The structure that is added by our technique helps the user to discern general line orientation, especially in regions of low image contrast. Here, the scalar attribute represents the amount of soot within a CFD cell. The user-defined selection highlights portions of soot that initially burns at a fast rate. ", "caption_bbox": [58, 273, 359, 377]}, {"image_id": 7, "file_name": "491_07.png", "page": 9, "dpi": 300, "bbox": [375, 57, 692, 146], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison of our method (b, d) and the tech- nique proposed by Zachow et al. [ZMH\u2217 09] (a, c). ", "caption_bbox": [391, 157, 692, 185]}], "492": [{"image_id": 0, "file_name": "492_00.png", "page": 1, "dpi": 300, "bbox": [58, 540, 693, 739], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The Curve Density Estimate of a high frequency sine curve with a normalized histogram of evaluated values densely sampled along the x axis. Our continuous representation of this curve closely matches that of the histogram. ", "caption_bbox": [58, 504, 691, 532]}, {"image_id": 1, "file_name": "492_01.png", "page": 2, "dpi": 300, "bbox": [57, 57, 378, 488], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Figures displaying the sine curve from zero to 1000\u03c0. In the top figure, a, an opaque line is used, and be- cause of overdraw, displays only the extent of the function. In the second figure, b, a transparent line is used. The third figure, c, is a scatter-plot of the samples drawn transparent, and shows the same distribution as the histogram. The fourth figure, d, is aggregated with moving mean, standard devia- tion and extent. As opposed to Figure 4, this data is unsuit- able for this type of aggregation. In the bottom figure, our technique, the Curve Density Estimate, is applied, and the distribution corresponds with that found in the histogram in Figure 3. ", "caption_bbox": [58, 493, 359, 674]}, {"image_id": 2, "file_name": "492_02.png", "page": 2, "dpi": 300, "bbox": [375, 57, 688, 187], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: 30 bins histogram of y = sin(x) for regularly sam- pled values of x. ", "caption_bbox": [390, 197, 691, 229]}, {"image_id": 3, "file_name": "492_03.png", "page": 2, "dpi": 300, "bbox": [393, 251, 692, 348], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Intel opening stock price with a moving average, standard deviation and extent. ", "caption_bbox": [390, 362, 691, 390]}, {"image_id": 4, "file_name": "492_04.png", "page": 5, "dpi": 300, "bbox": [58, 57, 694, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: 100 cumulative random curves with a slight bimodal trend. The top graph show the curves with slight transparency. All the samples at the green line, at x = 90, are drawn using a histogram and a 1D KDE in to the right. The graph to the bottom shows the CDE. Note how the 1D KDE corresponds to the green line drawn over the CDE as well. ", "caption_bbox": [58, 371, 691, 415]}, {"image_id": 5, "file_name": "492_05.png", "page": 6, "dpi": 300, "bbox": [59, 57, 378, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Two coinciding curves splitting up, in a, and the rasterized result after normalization, in b. Note that all columns sum up to one. ", "caption_bbox": [58, 310, 359, 354]}, {"image_id": 6, "file_name": "492_06.png", "page": 6, "dpi": 300, "bbox": [375, 57, 688, 202], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The three different proxy geometry schemes for reconstructing line kernels. The circles indicate the vertices needed. The colored curves below, depicts the evaluated ker- nel in the corresponding cross-sections above (not normal- ized). ", "caption_bbox": [390, 217, 691, 291]}, {"image_id": 7, "file_name": "492_07.png", "page": 6, "dpi": 300, "bbox": [58, 375, 362, 479], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Two different curves, on the left, and their corre- sponding views, on right, after being rescaled down to one column. ", "caption_bbox": [58, 489, 359, 533]}, {"image_id": 8, "file_name": "492_08.png", "page": 8, "dpi": 300, "bbox": [57, 591, 361, 689], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: By compressing time with a semi-logarithmic scale, a high level of detail can be read out on recent values, while an overview is available. The logarithmic exponent is given on the x axis. ", "caption_bbox": [58, 700, 359, 759]}, {"image_id": 9, "file_name": "492_09.png", "page": 8, "dpi": 300, "bbox": [57, 57, 694, 485], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Beethoven, Symphony No. 5 shown using CDE on the full waveform. The top image show five minutes and thirty seconds. The gray box in this top figure shows the timespan zoomed into for the second figure. The second figure shows an interesting feature, spanning three seconds, where a bassoon is playing. The third figure spans 50 milliseconds, zoomed into from the second figure. The bottom figure shows the same span as the second, but using Audacity\u2019 viewer [Aud] ", "caption_bbox": [58, 496, 691, 555]}, {"image_id": 10, "file_name": "492_10.png", "page": 9, "dpi": 300, "bbox": [62, 652, 689, 760], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Process data from a drilling operation showing hook-load in tonnes over time in seconds. The right view shows the moving mean, standard deviation and extent, which for this bimodal distribution works particularly bad. The left view displays the curve density estimate of the same data. ", "caption_bbox": [58, 771, 691, 815]}, {"image_id": 11, "file_name": "492_11.png", "page": 9, "dpi": 300, "bbox": [58, 57, 693, 560], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Temperature readings by station nr. 50500 at Flesland, Norway, years 2000 through 2009 with month on the x axis. The top image using CDE, the middle image smoothing using a moving mean and standard deviation, and output by Microsoft ExcelTM on the bottom. Notice that the uncertainty/spread of temperature is greater in the winter months Nov. to Feb., than the rest of the year, shown clearly in the CDE. June contains the most stable temperature, represented as the high density there. ", "caption_bbox": [58, 572, 691, 631]}], "493": [{"image_id": 0, "file_name": "493_00.png", "page": 3, "dpi": 300, "bbox": [69, 56, 693, 479], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The MarketAnalyzer interface. MarketAnalyzer consists of multiple coordinated views linked with interactive filters: (a) Company filter, (b) Store filter, (c) Products filter, (d) Legend view, (e) (Sorted) Matrix view for sales, trends, and growth rates. (f) Stacked bar view, (g) Geographical view, (h) and (i) Line graph small multiples views, (j) and (k) Time slider widgets and aggregation tools for temporal comparison. (l) Tooltip. (m) Filter. In the legends, the blue indicates positive and the red represents negative measurements in sales, trends, or growth rates. ", "caption_bbox": [59, 490, 692, 564]}, {"image_id": 1, "file_name": "493_01.png", "page": 4, "dpi": 300, "bbox": [59, 56, 647, 225], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (top-left) Magnification is applied for detailed comparison, (top-right) the CUSUM filtering method with the strict option is applied on Feb 2010, (bottom-left) SimulSort is applied to the sales view, (bottom-right) Proportional legend. ", "caption_bbox": [59, 237, 691, 265]}, {"image_id": 2, "file_name": "493_02.png", "page": 5, "dpi": 300, "bbox": [106, 56, 693, 189], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) The stacked bars represent trends in individual products. Analysts can see sudden increase in sales of product P3 in May. Note that M1 and M6 indicate company names. (b) Competitive advantages in February\u2013May 2010 are linked on the maps to represent regional competitions for sales (left), trends (middle), and growth rates (right) compared to the past time interval, March\u2013June 2009. ", "caption_bbox": [59, 200, 692, 259]}, {"image_id": 3, "file_name": "493_03.png", "page": 6, "dpi": 300, "bbox": [59, 56, 645, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a)\u2013(f) Analysis from the geographical view. The sales row shows the process of losing competitive advantage while the trends row presents forecasts for each column interval (August 2009\u2013May 2010). The blue color represents good perfor- mance while the red color represents bad performance for the primary company compared to its competitor. (g) The trend view helps an analyst design short term tactics such as promotions. This example shows a decreasing overall sales trend of the competitor in some stores. The analyst notes that the competitor has the worst downward trend in products P7 and P12 . (h) The red box represents possible new markets for the new company M6th but its competitor Mwin has already started its business in various products. ", "caption_bbox": [59, 308, 692, 412]}, {"image_id": 4, "file_name": "493_04.png", "page": 7, "dpi": 300, "bbox": [108, 56, 693, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Our pixel-based matrix views using the comparative mode. Each row of the matrix represents a product, and each column represents the store selling the product. The three views present three types of information (from top to bottom): sales, trend, and growth rate comparisons between two selected companies. Note that gray color indicates zero. The blue color presents positive and the red color represents negative in difference of the two measurements. ", "caption_bbox": [59, 341, 692, 400]}, {"image_id": 5, "file_name": "493_05.png", "page": 8, "dpi": 300, "bbox": [59, 56, 651, 386], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The matrix view under comparative mode with sorting provides direct information for the competition. These matrices imply a possible strategic failure that could cause the loss of a big market. ", "caption_bbox": [59, 400, 692, 428]}, {"image_id": 6, "file_name": "493_06.png", "page": 9, "dpi": 300, "bbox": [63, 56, 693, 128], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: 288x36 resized pixels with assumptions of 63 (left), 126 (middle), and 252 (right) products in 1000 stores.", "caption_bbox": [83, 140, 663, 153]}], "494": [{"image_id": 0, "file_name": "494_00.png", "page": 3, "dpi": 300, "bbox": [58, 80, 362, 346], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The simulation model used by Vismon takes two inputs, known as management options, and produces groups of output, called indicators. The running example has three groups of indicators, with a median, average, CV value, and a percentage of simulated years with undesireable behaviour. The data underlying each summarized indicator are from 500 Monte Carlo trials. ", "caption_bbox": [58, 349, 359, 455]}, {"image_id": 1, "file_name": "494_01.png", "page": 5, "dpi": 300, "bbox": [121, 79, 631, 368], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The Vismon interface: (a) Constraint pane, top-left, shows the list of management options and indicators in separate tabs; (b) Contour Plot Matrix pane, top-right, shows the contour plots of indicators as functions of the two management options and supports scenario selection; (c) Trade-offs pane, bottom, shows detail with the indicators for the selected scenarios; (d) Separate sliders are assigned to management options and indicators in Constraint pane. ", "caption_bbox": [58, 371, 691, 432]}, {"image_id": 2, "file_name": "494_02.png", "page": 6, "dpi": 300, "bbox": [59, 56, 375, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The Constraint pane sliders become scented widgets showing histograms on demand. (a) MC Trials shows the distribution of all indicator values across all Monte Carlo trials (500 in our example data). (b) Selecting a scenario shows its distribution vs. the full distribution, log- scaled vertically. (c) Probabilistic Objectives al- lows the user to set a second probabilistic constraint. ", "caption_bbox": [58, 289, 359, 395]}, {"image_id": 3, "file_name": "494_03.png", "page": 6, "dpi": 300, "bbox": [375, 56, 694, 163], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Contour plots can show (a) small points showing the underlying 11 \u00d7 11 grid of our example data that is the basis for isocontour interpolation, (b) the points size coded in two directions to summarize the underlying uncertainty as two numbers, (c) a histogram showing the full probability distribution for the point under the cursor, (d) the X\u2019d out region from probabilistic constraints, for comparison to the greyed-out region from the deterministic constraints. ", "caption_bbox": [391, 165, 692, 287]}, {"image_id": 4, "file_name": "494_04.png", "page": 7, "dpi": 300, "bbox": [390, 79, 694, 160], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The Trade-offs pane can show uncertainty infor- mation on bars in four ways. (a) None. (b) Error bars. (c) Box plots. (d) Shaded distributions. ", "caption_bbox": [391, 163, 692, 209]}, {"image_id": 5, "file_name": "494_05.png", "page": 9, "dpi": 300, "bbox": [58, 80, 362, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Case study.", "caption_bbox": [154, 309, 264, 324]}], "495": [{"image_id": 0, "file_name": "495_00.png", "page": 1, "dpi": 300, "bbox": [375, 328, 693, 778], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Our direct-touch fluid flow exploration tool in use.", "caption_bbox": [390, 788, 693, 801]}, {"image_id": 1, "file_name": "495_01.png", "page": 3, "dpi": 300, "bbox": [375, 56, 693, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Slice of a scalar FTLE field in Matlab, show- ing material divergence between close-by particles. The flow moves from the left to the right over the cavity; red lines in- dicate material frontiers through which mass fluxes are null. ", "caption_bbox": [390, 264, 694, 323]}, {"image_id": 2, "file_name": "495_02.png", "page": 4, "dpi": 300, "bbox": [375, 57, 693, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: General interface design with two data views, showing the iso-surface and volumetric visualizations of the scalar FTLE field using the domain-specific Jet colormap. ", "caption_bbox": [390, 264, 693, 307]}, {"image_id": 3, "file_name": "495_03.png", "page": 5, "dpi": 300, "bbox": [57, 57, 378, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Cutting plane interaction with bi-manual control.", "caption_bbox": [58, 284, 358, 297]}, {"image_id": 4, "file_name": "495_04.png", "page": 5, "dpi": 300, "bbox": [375, 56, 693, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Drilling interaction (left) with bi-manual control; the \u2018drilling core\u2019 with its iso-values is shown both in the 3D view as well as in an undistorted way on its left side. ", "caption_bbox": [390, 264, 693, 307]}, {"image_id": 5, "file_name": "495_05.png", "page": 6, "dpi": 300, "bbox": [375, 57, 693, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Bi-manual control of the seeding density.", "caption_bbox": [412, 275, 670, 288]}, {"image_id": 6, "file_name": "495_06.png", "page": 6, "dpi": 300, "bbox": [57, 56, 378, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Specifying seeds in the 2D cut view (two touches/ hands, right) to interactively place 3D streamlines (left). ", "caption_bbox": [58, 264, 359, 292]}, {"image_id": 7, "file_name": "495_07.png", "page": 7, "dpi": 300, "bbox": [57, 57, 378, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Co-located collaboration between two experts.", "caption_bbox": [65, 239, 352, 252]}], "496": [{"image_id": 0, "file_name": "496_00.png", "page": 2, "dpi": 300, "bbox": [80, 78, 339, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Studying the biomechanics of the human spine re- quires analyzing complex motions of the vertebrae. ", "caption_bbox": [58, 264, 359, 292]}, {"image_id": 1, "file_name": "496_01.png", "page": 3, "dpi": 300, "bbox": [121, 78, 631, 210], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Three of the eight visualization designs studied. Left: Interactive Space, Animated Time \u2013 A 3D input device controls scene rotation; the time dimension is controlled automatically via animation. Center: Static Space, Interactive Time \u2013 The scene does not move but 3D projection planes are included to facilitate spatial judgments; time is controlled interactively by touching a widget on the table. Right: Animated Space, Static Time \u2013 Space is animated by automatically rotating the objects back and forth; time is presented statically through a timeline of key 3D poses of the motion. ", "caption_bbox": [58, 221, 691, 295]}, {"image_id": 2, "file_name": "496_02.png", "page": 3, "dpi": 300, "bbox": [390, 332, 692, 492], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Motion visualization design taxonomy.", "caption_bbox": [418, 509, 664, 522]}, {"image_id": 3, "file_name": "496_03.png", "page": 4, "dpi": 300, "bbox": [117, 78, 303, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The 3D \u201cbumpy disc\u201d forms with highlighted sur- face features used in the motion visualization experiment. ", "caption_bbox": [58, 244, 359, 272]}, {"image_id": 4, "file_name": "496_04.png", "page": 5, "dpi": 300, "bbox": [58, 78, 364, 187], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The Static Time designs use sets of 3D key poses to convey change over time. ", "caption_bbox": [58, 197, 359, 225]}, {"image_id": 5, "file_name": "496_05.png", "page": 7, "dpi": 300, "bbox": [391, 78, 693, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Experimental results for Number of Errors and Time Taken. Pairwise significantly different measures are in- dicated via dashed lines. Error bars are +/- 2 SE. ", "caption_bbox": [391, 356, 692, 400]}, {"image_id": 6, "file_name": "496_06.png", "page": 8, "dpi": 300, "bbox": [396, 78, 687, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: An application of the Static Space, Interactive Time design to data from a spinal kinematics study \u2013 one of the eight designs we evaluated qualitatively together with domain scientist collaborators. ", "caption_bbox": [391, 250, 692, 309]}], "497": [{"image_id": 0, "file_name": "497_00.png", "page": 5, "dpi": 300, "bbox": [375, 56, 693, 379], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Correctness for task and number of entities.", "caption_bbox": [405, 392, 677, 405]}, {"image_id": 1, "file_name": "497_01.png", "page": 6, "dpi": 300, "bbox": [375, 57, 690, 379], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Cognitive load for task and number of entities.", "caption_bbox": [398, 392, 684, 405]}, {"image_id": 2, "file_name": "497_02.png", "page": 8, "dpi": 300, "bbox": [391, 302, 694, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Significant pairwise differences (p < .05) for cog- nitive load. Each box represents a combination of Target Separations and Node Speeds. Arrows signify that the source has significantly less cognitive load than the destination. ", "caption_bbox": [391, 388, 692, 447]}, {"image_id": 3, "file_name": "497_03.png", "page": 8, "dpi": 300, "bbox": [58, 302, 359, 375], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Significant pairwise differences (p < .05) for cor- rectness. Each box represents a combination of Target Sep- arations and Node Velocities. Arrows signify that the source has significantly more correctness than the destination. ", "caption_bbox": [59, 388, 360, 447]}, {"image_id": 4, "file_name": "497_04.png", "page": 8, "dpi": 300, "bbox": [375, 57, 694, 237], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Cognitive load as a function of Target Separation S and Node Speed V (presented as S/V in labels). ", "caption_bbox": [391, 248, 692, 276]}, {"image_id": 5, "file_name": "497_05.png", "page": 8, "dpi": 300, "bbox": [58, 56, 378, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Correctness as a function of Target Separation S and Node Velcity V (presented as S/V in labels). ", "caption_bbox": [59, 249, 360, 277]}], "498": [{"image_id": 0, "file_name": "498_00.png", "page": 3, "dpi": 300, "bbox": [88, 56, 693, 374], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview of the design: (a) the member-oriented overview employing feature-based placement (b) for 524 2D func- tions; (c) the mid-level focus of 31 selected members; (d) the domain-oriented overview showing the point-wise range of the selected subset; (e) the 3D surface plot of a single member. The arrows indicate key interactions for linking the parts. ", "caption_bbox": [58, 379, 691, 423]}, {"image_id": 1, "file_name": "498_01.png", "page": 4, "dpi": 300, "bbox": [59, 56, 378, 170], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Comparison of downsampling strategies on a small icon (30 x 14 pixels): (a) averaging blurs the two peaks; (b) maximum-preserving loses the gap between the peaks; (c) extrema-preserving keeps minima and maxima. ", "caption_bbox": [58, 172, 359, 231]}, {"image_id": 2, "file_name": "498_02.png", "page": 5, "dpi": 300, "bbox": [58, 56, 694, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The mid-level focus for different distributions: (a, b) sparse distribution where most focus icons are close to or above their base icon without occluding non-selected base icons; (c) the affiliation is still visible for densely clustered base icons. ", "caption_bbox": [58, 218, 691, 246]}, {"image_id": 3, "file_name": "498_03.png", "page": 6, "dpi": 300, "bbox": [60, 93, 361, 373], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The comparison mode: (a) 11 outliers are com- pared to a reference function (grayscale icon) being the point-wise average of a cluster; (b) detailed 3D compari- son of a single member (colored surface) to the reference function (transparent grid). ", "caption_bbox": [58, 375, 359, 449]}, {"image_id": 4, "file_name": "498_04.png", "page": 7, "dpi": 300, "bbox": [58, 57, 378, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Analysis of 1D slices at a user-defined position within the 2D domain. Color discriminates the envelopes of two selections. ", "caption_bbox": [58, 282, 359, 326]}, {"image_id": 5, "file_name": "498_05.png", "page": 8, "dpi": 300, "bbox": [59, 56, 694, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An exemplary workflow: (a) filtering the domain-space focuses on a central peak; (b) most icons reveal the peak if the parameter \"force scale\" exceeds 1; (c) after revising the model, 11 outliers still show a central peak; (d) linking+brushing confirms that peaks in the domain-space of one 2D function ensemble correspond to clusters in the feature-space of another one; (e) slicing reveals that the outliers (red envelope) drop earlier but form additional peaks; (f) linked parallel coordinates indicate a problematic interplay of the design parameters \"bore diameter\" and \"radial clearance\". ", "caption_bbox": [58, 357, 691, 431]}], "499": [{"image_id": 0, "file_name": "499_00.png", "page": 2, "dpi": 300, "bbox": [375, 57, 694, 456], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Porosity visualization pipeline for interactive ex- ploration and visual analysis of porosity in CFRP speci- mens, consisting of three stages: (1) Data Acquisition (2) Pre-computation and (3) Visual Analysis of Porosity. ", "caption_bbox": [391, 466, 692, 525]}, {"image_id": 1, "file_name": "499_01.png", "page": 4, "dpi": 300, "bbox": [58, 56, 378, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: XCT xy slices of specimens PrePreg 1 (a), PrePreg 2 (b), PrePreg 3 (c) contain pores in black. The gray areas indicate the epoxy resin and the fiber bundles. ", "caption_bbox": [59, 306, 360, 349]}, {"image_id": 2, "file_name": "499_02.png", "page": 5, "dpi": 300, "bbox": [58, 278, 362, 403], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Illustration of porosity map calculation step. (b) View Maximum Color Mapping (VMCM) of a small re- gion in specimen PrePreg 1 in xz view. The porosity map values are encoded as the number of pore voxels. ", "caption_bbox": [59, 413, 360, 472]}, {"image_id": 3, "file_name": "499_03.png", "page": 5, "dpi": 300, "bbox": [58, 57, 378, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Quantitative porosity info graph showing the global properties volume, number of pores and porosity sep- arately for specimen, region of interest (ROI) and parallel- coordinates selection. ", "caption_bbox": [59, 199, 360, 258]}, {"image_id": 4, "file_name": "499_04.png", "page": 6, "dpi": 300, "bbox": [58, 56, 694, 446], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visual analysis of porosity in a sample specimen. The interactive exploration and visualization with a drill-down approach is shown in three stages: (1) Visualization of all pores and fast evaluation of the specimen based on porosity maps, where the values are encoded as the number of pore voxels. (2) Highlighted visualization of pores in a region of interest. (3) Accentuation of specific pores in the region of interest. (a) Porosity maps interaction with a cuboid region of interest. (b) Further filtering of pores based on their local properties using parallel coordinates. ", "caption_bbox": [59, 456, 692, 530]}, {"image_id": 5, "file_name": "499_05.png", "page": 7, "dpi": 300, "bbox": [58, 57, 378, 617], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) Best-viewpoint calculation by varying the viewpoint in steps of 10 \u25e6 in \u03b1 and \u03b2. (b) For each po- sition P\u03b1,\u03b2 on the sphere the viewpoint is evaluated. (c) Histogram-based best-viewpoint calculation showing three different viewpoints. Histograms are divided into the three classes of critical (1), borderline (2) and not critical (3) pix- els. ", "caption_bbox": [58, 627, 359, 731]}, {"image_id": 6, "file_name": "499_06.png", "page": 8, "dpi": 300, "bbox": [58, 205, 694, 321], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) PrePreg 1 specimen after porosity determination in a 3D volume view (b) as well as in a xz view (c) and a xz porosity-map view. The porosity map values are encoded as the number of pore voxels. (d) Porosity evaluation of a region of interest in specimen PrePreg 1. Different pore classifications are shown using parallel-coordinates interaction. The biggest pore in the region is selected and highlighted. (e) Only the long and thin micro pores in the fiber bundles are highlighted. ", "caption_bbox": [59, 331, 692, 390]}, {"image_id": 7, "file_name": "499_07.png", "page": 9, "dpi": 300, "bbox": [58, 567, 361, 691], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Best-viewpoint widgets with color mapping on a sphere (a) and cylinder sticks (b). The color mapping ranges from green, indicating a good viewpoint, to red visualizing unfavorable viewpoints. ", "caption_bbox": [59, 701, 360, 760]}, {"image_id": 8, "file_name": "499_08.png", "page": 9, "dpi": 300, "bbox": [58, 57, 378, 400], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison of active thermography images (a),(c) and (e) to porosity maps (b), (d) and (f) of the speci- mens PrePreg 4-6. PrePreg 4 shows a porosity of 1.81 % (a) and (b), PrePreg 5 shows a porosity of 3.53 % (c) and (d) and PrePreg 6 shows a porosity of 7.20 % (e) and (f). The porosity map values are encoded as the number of pore vox- els. Based on the thermal diffusivity model high values in the active thermography images depict a high porosity, which is encoded as the observation time in seconds. ", "caption_bbox": [59, 410, 360, 545]}], "500": [{"image_id": 0, "file_name": "500_00.png", "page": 4, "dpi": 300, "bbox": [390, 623, 691, 819], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The two modes of the dataset nodes in the Data- View Integrator. (a) In the detail mode, the patient stratifi- cations and gene clusterings are displayed as a matrix of possible combinations. By selecting one of the gray matrix cells, the user can interactively create a combination (cyan). (b) A view node connected to two dataset nodes that are in compact mode, listing only the existing combinations. ", "caption_bbox": [391, 832, 692, 936]}, {"image_id": 1, "file_name": "500_01.png", "page": 5, "dpi": 300, "bbox": [90, 56, 693, 376], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The Data-View Integrator showing the relationships between datasets as well as their association to views for the application scenario. Datasets and stratifications are shown at the bottom with the views placed above. Relationships between a selected dataset and all others are shown. Note that some views can show only one stratification, while others, like StratomeX, can show multiple. ", "caption_bbox": [59, 387, 692, 446]}, {"image_id": 2, "file_name": "500_02.png", "page": 5, "dpi": 300, "bbox": [390, 558, 694, 775], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Schematic comparison of five columns. The first three columns show groupings of tabular data, where the second and third show the same data only with different stratifications. The fourth, orange column represents a cat- egorization. The rightmost column illustrates the concept of dependent subsets, where the groups are based on the strat- ification of another column. The ribbons between the sub- sets indicate how many patients are shared between them. For instance, all patients of BI1 are contained in BII1. BII1, however, also contains patients from BI2. ", "caption_bbox": [391, 786, 692, 936]}, {"image_id": 3, "file_name": "500_03.png", "page": 7, "dpi": 300, "bbox": [58, 56, 694, 448], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: StratomeX configured as illustrated in Figure 3. The heatmaps in the bricks allow the investigator to judge the homogeneity of the subsets. The header bricks at the top show the name of the column and an overview of the data in the column. In the fourth column, a stratification based on the categories for copy number variation of EGFR can be seen. The rightmost column shows Kaplan-Meier plots for \u201cdays to death\u201d as dependent bricks for the copy number-based stratification. Note that patients with amplifications of EGFR have far worse outcomes compared to patients with two copies. ", "caption_bbox": [59, 459, 692, 533]}, {"image_id": 4, "file_name": "500_04.png", "page": 8, "dpi": 300, "bbox": [375, 57, 694, 321], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Methylation subtypes. Column 1 shows mRNA gene expression subtypes identified by Verhaak et al. Col- umn 2 shows patient survival outcomes (days to death) and was created as a dependent column of Column 3, which shows a stratification of methylation data. The stratification of Column 3 was created by splitting off a part of the orig- inal clusters based on the mutation status of IDH1, shown in Column 5, which reveals a characteristic expression pat- tern overlooked by the algorithm. Only in the eight-cluster case, shown in Column 4, the clustering algorithm was able to detect this pattern. ", "caption_bbox": [391, 331, 692, 496]}, {"image_id": 5, "file_name": "500_05.png", "page": 8, "dpi": 300, "bbox": [58, 56, 378, 321], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Clustering comparisons. Columns 1, 2, and 4 show clusterings from the analysis pipeline with three, four, and five clusters respectively. Column 3 shows a stratifica- tion of the patients based on subtypes identified by Verhaak et al. (from top: mesenchymal, proneural, neural, classical). ", "caption_bbox": [59, 331, 360, 405]}, {"image_id": 6, "file_name": "500_06.png", "page": 9, "dpi": 300, "bbox": [375, 56, 694, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Subtypes in the context of pathways. Column 1 shows mRNA gene expression subtypes identified by Ver- haak et al. (from top: neural, mesenchymal, proneural, clas- sical). The dependent Column 2 shows small multiples of the \u201cGlioma\u201d pathway from KEGG overlaid with the average gene expression levels for each subtype. The detail view in the center shows the same pathway enlarged with the gene expression levels for the classical subtype. The arrows indi- cate a part of the pathway where we observed notable differ- ences in gene expression levels between the subtypes. Note that not all genes in the pathway have been mapped since the gene expression data matrix only contained a subset of the most variable 1,500 genes in the dataset. ", "caption_bbox": [391, 304, 692, 500]}], "501": [{"image_id": 0, "file_name": "501_00.png", "page": 2, "dpi": 300, "bbox": [59, 56, 684, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An example of a distorted thumbnail. a) The original thumbnail with highlights. b) The thumbnail generated with the zooming technique described in [BHDH95] c) The thumbnail generated with the proposed distortion technique. ", "caption_bbox": [59, 397, 692, 426]}, {"image_id": 1, "file_name": "501_01.png", "page": 3, "dpi": 300, "bbox": [375, 56, 694, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Results of the segmentation on different pages. The created segments are marked in red. ", "caption_bbox": [391, 308, 692, 337]}, {"image_id": 2, "file_name": "501_02.png", "page": 4, "dpi": 300, "bbox": [59, 56, 378, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The horizontal intervals of a simple line. a) shows the bounding boxes of the words and b) shows the created intervals. The blue boxes are the interesting ones and the saturation corresponds to the degree of interest. ", "caption_bbox": [59, 250, 360, 309]}, {"image_id": 3, "file_name": "501_03.png", "page": 5, "dpi": 300, "bbox": [59, 94, 694, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Example of the distortion of three lines. The saturation of the blue color shows the degree of interest of the different boxes. ", "caption_bbox": [59, 303, 692, 332]}, {"image_id": 4, "file_name": "501_04.png", "page": 6, "dpi": 300, "bbox": [59, 56, 683, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The area factor over different distribution of interesting terms.", "caption_bbox": [195, 309, 554, 323]}, {"image_id": 5, "file_name": "501_05.png", "page": 6, "dpi": 300, "bbox": [61, 362, 683, 551], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The area factor for different kernel sizes.", "caption_bbox": [248, 565, 501, 579]}, {"image_id": 6, "file_name": "501_06.png", "page": 8, "dpi": 300, "bbox": [59, 56, 679, 911], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Distorted page thumbnails created for one of the EuroVis2011 papers [vdZLBI11]. The thumbnails show the distribu- tion of the title terms in the document. ", "caption_bbox": [59, 922, 692, 951]}], "502": [{"image_id": 0, "file_name": "502_00.png", "page": 3, "dpi": 300, "bbox": [375, 56, 693, 203], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Graphical model representation of LDA.", "caption_bbox": [417, 215, 666, 228]}, {"image_id": 1, "file_name": "502_01.png", "page": 5, "dpi": 300, "bbox": [390, 582, 693, 700], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: X-ray mode: (A) Cluster node\u2019s X-ray mode. It shows document grids with the color spectrum. (B) Parallel Coordinates\u2019 X-ray mode with the selected cluster. (C) Paral- lel Coordinates\u2019 X-ray mode with the selected document. ", "caption_bbox": [391, 712, 692, 770]}, {"image_id": 2, "file_name": "502_02.png", "page": 5, "dpi": 300, "bbox": [58, 56, 694, 460], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The overview of the system. The InfoVis and VAST papers data set is used. (A) Cluster Relation View. Visualizes clustering results in a graph-based layout. (B) Cluster Tree View. Maintains the hierarchical cluster structure with user-defined topics. (C) Cluster Summary View. A simplified version of the Cluster Relation View. (D) Parallel Coordinates View. The topic distribution of each document is visualized. (E) Term-Weight View. Visualizes term weights of each topic and can modifying its value. (F) Document Tracer View. The number of documents which changed its cluster membership is shown as a heat map and those documents are accessible. (G) Document View. The original document is shown with keywords highlighted. ", "caption_bbox": [58, 477, 691, 566]}, {"image_id": 3, "file_name": "502_03.png", "page": 7, "dpi": 300, "bbox": [62, 56, 693, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Interactive clustering by filtering noisy data. Filtering out noisy documents leads to a clear clustering results.", "caption_bbox": [84, 326, 666, 339]}, {"image_id": 4, "file_name": "502_04.png", "page": 9, "dpi": 300, "bbox": [61, 392, 689, 569], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Interactive clustering by sub-clustering and merging. Document exploration in the Cluster Relation View.", "caption_bbox": [94, 581, 657, 594]}, {"image_id": 5, "file_name": "502_05.png", "page": 9, "dpi": 300, "bbox": [58, 56, 693, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Interactive clustering by refining topics. Users focus on the arrow-pointed terms, and either increase or decrease the term weights in their topic. The result is shown with three documents as an example. ", "caption_bbox": [58, 342, 691, 370]}], "503": [{"image_id": 0, "file_name": "503_00.png", "page": 5, "dpi": 300, "bbox": [117, 56, 693, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization of a document collection generated automatically by ProjCloud from a collection of scientific papers in four different areas of knowledge. ", "caption_bbox": [59, 383, 692, 411]}, {"image_id": 1, "file_name": "503_01.png", "page": 5, "dpi": 300, "bbox": [129, 437, 629, 704], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: ProjCloud behavior for complex polygon shapes.", "caption_bbox": [226, 720, 524, 733]}, {"image_id": 2, "file_name": "503_02.png", "page": 6, "dpi": 300, "bbox": [59, 56, 378, 818], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparison between ProjCloud, Wordle, and the approach proposed by Seifert et al. [SKK\u2217 08] when visual- izing the RSS news feed dataset. The semantic information conveyed by ProjCloud, which is not preserved by Wordle and the Seifert\u2019s approaches, makes it easy to interpret the content of this document collection. ", "caption_bbox": [58, 831, 359, 920]}, {"image_id": 3, "file_name": "503_03.png", "page": 7, "dpi": 300, "bbox": [103, 56, 693, 411], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparison between ProjCloud (first line), Wordle (second line) and Seifert et al. [SKK\u2217 08] approaches (third line) for layouts when visualizing RSS news feeds from focused groups. ", "caption_bbox": [59, 425, 692, 457]}, {"image_id": 4, "file_name": "503_04.png", "page": 8, "dpi": 300, "bbox": [59, 56, 378, 612], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A user can interactively draw a region (polygon) containing a subset of documents of interest (top figure). Keywords are extracted from the selected document and their corresponding word could is built inside the user-defined re- gion (bottom figure). ", "caption_bbox": [59, 618, 360, 692]}], "504": [{"image_id": 0, "file_name": "504_00.png", "page": 2, "dpi": 300, "bbox": [407, 381, 680, 417], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overlap removal in Box2D: Solving body-to-body constraints by pushing bodies away from each other with applied forces. ", "caption_bbox": [391, 427, 692, 471]}, {"image_id": 1, "file_name": "504_01.png", "page": 2, "dpi": 300, "bbox": [59, 56, 631, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: For local overlap evasion methods, different approaches for ordering the elements are shown. ManiWordle (a) uses a size-dependent ordering. We suggest to use a scan-line based linear order (in (b) from left to right) or a concentric order (c). ", "caption_bbox": [59, 277, 692, 305]}, {"image_id": 2, "file_name": "504_02.png", "page": 3, "dpi": 300, "bbox": [64, 56, 693, 232], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Layouts for a synthetic scenario of 120 rectangular representatives. The scenario is shown before overlap removal (a) and after overlap removal (b)\u2013(f) for the described algorithms. The Euclidean Distance for each item is mapped to intensity of red. Box2D and VPSC show a clear stretching along the y axis. PRISM leaves unused white space within the layout. ManiWordle places partially correct but towards the outer bound, displacement increases. Both RWordle approaches distributes the Euclidean Displacement more homogeneously. ", "caption_bbox": [59, 245, 692, 319]}, {"image_id": 3, "file_name": "504_03.png", "page": 3, "dpi": 300, "bbox": [407, 783, 680, 834], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Wordle greedy layout algorithm: In case of over- lap, search in a circular manner for a new position. ", "caption_bbox": [391, 844, 692, 872]}, {"image_id": 4, "file_name": "504_04.png", "page": 4, "dpi": 300, "bbox": [70, 315, 353, 403], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Overlap removal in the same direction may lead to a stacking problem (center) even if another, more compact layout would be preferable (right). ", "caption_bbox": [59, 413, 360, 457]}, {"image_id": 5, "file_name": "504_05.png", "page": 5, "dpi": 300, "bbox": [391, 283, 691, 385], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The length of rays from the center of mass of the convex hull intersected with the convex hull are used to de- scribe the shape of the object distribution. ", "caption_bbox": [391, 402, 692, 446]}, {"image_id": 6, "file_name": "504_06.png", "page": 7, "dpi": 300, "bbox": [77, 56, 693, 888], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Detailed measures for the described algorithms with increasing density. On the left hand side for square representa- tives, on the right hand side for non-square representatives (w > h). A canvas with the size of 400\u00d7400 and an average element area of 160 is used. ", "caption_bbox": [59, 903, 692, 947]}, {"image_id": 7, "file_name": "504_07.png", "page": 8, "dpi": 300, "bbox": [124, 307, 628, 485], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The shape (w > h, square, w < h) of initial distribution of non-square representatives affects the Euclidean Distance measure for VPSC and Box2D heavily. RWordle is more stable w.r.t. this measure and delivers good results for ED and SP. ", "caption_bbox": [58, 499, 691, 528]}, {"image_id": 8, "file_name": "504_08.png", "page": 8, "dpi": 300, "bbox": [59, 56, 607, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The influence of the angle of the scan-line direction on the linear approach (RWordle-L). Both measures correlate with the angle, but are not as good as for the concentric approach (RWordle-C). ", "caption_bbox": [59, 249, 692, 277]}, {"image_id": 9, "file_name": "504_09.png", "page": 9, "dpi": 300, "bbox": [173, 528, 579, 888], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Representatives of molecule structure and additional informations (e.g. ID, water solubility) are mapped into the 2D plane according to their structural similarity. We applied our algorithm RWordle-C to remove overlap. ", "caption_bbox": [59, 899, 692, 927]}, {"image_id": 10, "file_name": "504_10.png", "page": 9, "dpi": 300, "bbox": [156, 56, 693, 471], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The different overlap removal algorithms applied to the map of England. The number of inhabitants is logarithmically mapped to the font size. (f) shows overlaps removed with text shapes instead of bounding boxes. ", "caption_bbox": [59, 485, 692, 513]}], "505": [{"image_id": 0, "file_name": "505_00.png", "page": 3, "dpi": 300, "bbox": [66, 80, 355, 574], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Sea surface temperature in the vicinity of the Gulf Stream, computed by two different models. The top plot is from a simulation with a spatial resolution of 1\u25e6 , while the                                                           1 \u25e6 bottom is made from POP, at a spatial resolution of 10        . In both images, the Gulf Stream itself appears as a yellow- ish line coming north from the Gulf of Mexico. In the high- resolution simulation, the Gulf Stream departs the coast of the United States near the state of North Carolina, while in the low-resolution simulation, the Gulf Stream continues hugging the coast of the United States. This incorrect path of the Gulf Stream is a well-known problem with low-resolution simulations. One important difference between a 1\u25e6 model         1 \u25e6 and a 10    model is that the former does not have sufficient resolution for eddies to appear, hence, the emergence of ed- dies is a possible cause for higher-resolution simulations producing the Gulf Stream with the correct shape. ", "caption_bbox": [58, 584, 359, 825]}, {"image_id": 1, "file_name": "505_01.png", "page": 5, "dpi": 300, "bbox": [121, 80, 631, 745], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Inside and outside temperatures of eddies. Using both eddy identification and tracking, we computed the distribu- tion of temperature both inside (red) and outside (blue) three eddies from different locations around the world. Also, quartile distance is mapped to alpha, with the median at full opacity, the lower and upper quartiles at 50% opacity, and the minimum and maximum values at no opacity. Thus, where the two distributions overlap, they appear magenta. The temperature distribu- tions for each eddy are shown at depths of 5m, 58m, 112m, and 580m, in order to make sure that the results are not skewed by differences between surface behavior, mixed layer behavior, and the deep ocean. The relationships that are seen between temperatures inside and outside of the eddy must be maintained in order to preserve the dynamics that support the eddy (as explained further in the text), but it is unclear whether this is primarily due to containment of waters inside the eddy, or whether substantial leakage is compensated by vertical motion of the water column. In the particular case of the Australian eddy at a depth of 58m, these effects are confounded by fluctuations in the mixed layer depth (the upper layer of the ocean, characterized by large amounts of turbulent mixing) that are known to occur in this region. Thus, we need a better metric to help to distinguish between these scenarios. ", "caption_bbox": [58, 755, 691, 936]}, {"image_id": 2, "file_name": "505_02.png", "page": 6, "dpi": 300, "bbox": [375, 57, 693, 145], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Decomposition of the velocity field inside an eddy: the eddy is imposed on a background flow, the core of the eddy is translating, water inside the eddy is circulating, and exchange is occurring along its boundary. ", "caption_bbox": [391, 155, 692, 214]}, {"image_id": 3, "file_name": "505_03.png", "page": 7, "dpi": 300, "bbox": [398, 80, 687, 433], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Stable and chaotic behavior of Agulhas Rings and a Loop Current Ring. After applying time aggregation, the interface transport field is too chaotic in most locations for effective visualization using glyphs. However, the Agulhas Rings (top) and Loop Current Ring (bottom) are sufficiently powerful and isolated so that their effects dominate the in- terface transport in their vicinity of the ocean. Both images are overlaid on a snapshot of the Q-criterion from the middle of the time range (specifically, April 15), but these overlays are only meant to serve as a visual reference. The Agulhas Ring shows a remarkably stable pattern, pulling in heat from the southeast and pushing it out to the west, and pulling in heat from the northwest and pushing it out to the east. The Loop Current Ring is far more chaotic, though in general it seems to be transporting heat to the southwest, against the usual clockwise flow of water along the edge of the Gulf of Mexico. ", "caption_bbox": [391, 443, 692, 700]}, {"image_id": 4, "file_name": "505_04.png", "page": 7, "dpi": 300, "bbox": [66, 80, 355, 610], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Close-up visualizations of interface exchange be- havior. We apply the interface exchange metric to a sin- gle time step, focusing on three eddies engaging in partic- ular strong interface exchange at this point in time. The red surfaces are contours of the Q-criterion, so they are what we consider the eddy boundaries, while arrows indicate the magnitude (in both color and arrow size) and direction of heat transport. The three eddies pictured are, from top to bottom: an Agulhas Ring, a long-lived eddy moving west across the South Atlantic from the southern tip of Africa; a Loop Current Ring, a long-lived eddy generated in the Gulf of Mexico; and a Gulf Stream Ring, a short-lived eddy as- sociated with the Gulf Stream in the North Atlantic. The im- age of the Agulhas Ring has a camera oriented in the north- ern direction; the image of the Loop Current Ring is looking northwest toward the US state of Texas; and the image of the Gulf Stream Ring is oriented in the western direction. The Agulhas Ring and Loop Current Ring appear to be con- tributing to a long-term, stable heat transport, see also Fig- ure 5, while the Gulf Stream Ring appears to be contributing to heat transport primarily where it undergoes deformation, when large exchanges of heat may occur. ", "caption_bbox": [58, 620, 359, 953]}, {"image_id": 5, "file_name": "505_05.png", "page": 9, "dpi": 300, "bbox": [90, 80, 662, 777], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Interface exchange aggregation. After aggregating the interface exchange over three months, we downsample it by a factor of ten in order to bring out the dominant trends. These trends are then visualized with streamtubes, with radius proportional to the transport magnitude. Additionally, directed cones on the streamtubes indicate the direction that transport is occurring. The images are also overlaid on the temperature field averaged over the month of April, in order to provide a reference map. In the vicinity of the Gulf Stream, interface exchange is primarily moving water to the west, opposite to the eastward flow of the Gulf Stream. In the Gulf of Mexico itself, the eddies are moving water to the southwest, against the dominant flow of heat through the Gulf. The behavior near the Kuroshio Current, off the coast of Japan, is less straightforward. Eddies do, however, appear to be pushing heat along contours of heat, indicating they may be involved in shaping those contours. It should also be noted that these images only consider the ocean surface, where wind and solar forcing are in effect. ", "caption_bbox": [58, 787, 691, 922]}], "506": [{"image_id": 0, "file_name": "506_00.png", "page": 3, "dpi": 300, "bbox": [446, 223, 638, 320], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Problems that arise when defining trajectories of PC vector fields. Red arrows show vectors assigned to the cubes (3D cells). Left: the standard definition can be easily adopted to this case: trajectories (e.g. the blue line) cross the face F between the two cubes. Center: no standard tra- jectory starting at a point in F exists. Right: flow based on standard trajectories is discontinuous. Trajectories starting close to the blue point on F in the upper (lower) cube diverge upward (downward, respectively). Note that similar issues appear at grid edges and vertices. ", "caption_bbox": [391, 322, 692, 472]}, {"image_id": 1, "file_name": "506_01.png", "page": 3, "dpi": 300, "bbox": [432, 79, 652, 157], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Approximation of a 2D vertex based vector field (left) with a PC vector field (right). We use the same method for 3D regular grids. ", "caption_bbox": [391, 159, 692, 203]}, {"image_id": 2, "file_name": "506_02.png", "page": 4, "dpi": 300, "bbox": [435, 78, 649, 129], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Example trajectories (blue lines) near a 2D face F that exhibits problems illustrated in Figure 2, center and right. Red arrows represent vectors assigned to the two 3D faces and to F. In the case shown in the left, trajectories enter F and move along it until they reach its boundary. In the case shown on the right, they can enter F only through its boundary. They follow F until they reach its boundary or leave F at any point into one of the incident 3D faces. ", "caption_bbox": [391, 132, 692, 252]}, {"image_id": 3, "file_name": "506_03.png", "page": 5, "dpi": 300, "bbox": [58, 78, 362, 164], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Attracting and repelling faces. (a) A parallel pro- jection of a 3D cell P in the direction of f (P), pointing to- ward the viewer. The back faces ( pqtu,  qsuw and  tuvw) for that projection repel the flow in P. Edges (1D cells) that                              \u00af and u\u0304w. The only 0D cell that                           \u00af tu repel the flow in P are qu, repels the flow in P is u. Faces that attract the flow in P are  pqrs,  prtv,  rsvw, pr,  \u00af rs,                              \u00af rv \u00af and r. (b) A 2D cell R with nonempty f (R) shown as the red vector. In this case, faces                                  \u00af qs that attract the flow in R are pq,   \u00af and q. Faces that repel                     \u00af rs the flow in R are pr,   \u00af and r. (c) A 1D cell, edge pq,\u00af with  f ( pq)                                        ~ In this case,       \u00af containing only positive multiples of qp. q is the only face that repels the flow and p \u2013 the only face that attracts the flow. (d) An edge such that f ( pq)                                                     \u00af contains vectors pointing both from p to q and from q to p. In this case, p and q both attract and repel the flow in pq.\u00af ", "caption_bbox": [58, 165, 359, 391]}, {"image_id": 4, "file_name": "506_04.png", "page": 6, "dpi": 300, "bbox": [168, 79, 252, 170], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A 2D cell C (black rectangle) with a nonempty  f (C), containing the red vector. C and its edges are nodes of the coarse graph. Let\u2019s say that the bottom edge has been refined (split into two equal halves). Now, the node corre- sponding to C is being refined (split into quarters as shown by the blue lines). We would not like to include the arc A \u2192 B in the refined graph, since there is no simple trajectory seg- ment defined on a time interval of positive length starting in A and ending in B. This is the purpose of the tweaked subdi- vision rule (note that \u03c0C (A) and \u03c0C (B) intersect). ", "caption_bbox": [58, 174, 359, 325]}, {"image_id": 5, "file_name": "506_05.png", "page": 6, "dpi": 300, "bbox": [444, 78, 639, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Contribution of a 2D cell Q with f (Q) 6= \u2205 to the transition graph. Red dashed lines are parallel to the only vector in f (Q). The line perpendicular to that vector is shown in blue. N-sets contained in Q are vertices I . . . L, edge pieces R . . . Z and face pieces A . . . G. Note that Y fol- lows edges of two face pieces, D and F \u2013 this is allowed since edge pieces and face pieces are refined independently. If the configuration shown here is obtained by means of re- finement operations from the coarse graph, R, S, T , U and K are connected to face pieces that contain endpoints of sim- ple segments with carrier Q starting in them. Similarly, face pieces that are connected to V , W , X, Y , Z and J by a sim- ple segment are also connected to these n-sets with graph arcs. For example, arcs ending at E are T \u2192 E and U \u2192 E. The only arc out of E is E \u2192 Y . Arcs out of U are U \u2192 C, U \u2192 E, U \u2192 F and U \u2192 G. There is no need to include arcs connecting face pieces connected by simple segments. This is because vectors in both 3D cells incident to Q either point toward or away from it. If both point toward Q, trajectories can only leave Q through one of its faces that attracts the flow in Q. If both point away from Q, trajectories can enter Q only through its faces that repel the flow in Q. Hence any simple segment contributing to a \u2018full\u2019 trajectory has to pass through the boundary of Q. ", "caption_bbox": [390, 270, 692, 634]}, {"image_id": 6, "file_name": "506_06.png", "page": 7, "dpi": 300, "bbox": [88, 291, 332, 421], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Largest nearly recurrent component for the Lorenz system with \u03c3 = 10, \u03b2 = 8/3 and \u03c1 = 350 (magenta). A tubu- lar neighborhood (of diameter equal to the grid size) of the periodic trajectory proven to exist in [MP02], approximated numerically, is shown in red. Note that it closely follows the loop formed by the nearly recurrent component. In this case, we used a regular 24 \u00d7 24 \u00d7 24 cubical grid on the domain [\u2212150, 150] \u00d7 [\u2212150, 150] \u00d7 [200, 500] and 7 refinement it- erations. The computation time was 470 seconds. ", "caption_bbox": [58, 424, 359, 559]}, {"image_id": 7, "file_name": "506_07.png", "page": 7, "dpi": 300, "bbox": [58, 78, 694, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The largest nearly recurrent component for a PC approximation of the Lorenz system. The boxes show different views of its 3D model, obtained using 0, 2, 4 and 6 refinement iterations. The computation times were 16, 66, 188 and 592 seconds (respectively). We used a PC approximation defined on the 48 \u00d7 48 \u00d7 48 cubical grid on the domain [\u221230, 30] \u00d7 [\u221230, 30] \u00d7 [\u221210, 50]. The value in a 3D cell was obtained by evaluating the Lorenz vector field at its center. ", "caption_bbox": [58, 196, 691, 255]}, {"image_id": 8, "file_name": "506_08.png", "page": 8, "dpi": 300, "bbox": [397, 78, 687, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Left: largest nearly recurrent components in a 50 \u00d7 50 \u00d7 33 version of the hurricane Isabel dataset, for 4 refinement iterations. The computation time was about 9 minutes. The core vortex of the hurricane corresponds to the green component. In the images on the right, we color-coded the points on the nearly recurrent components based on a local estimate of the turning direction of trajectories (red: clockwise, blue: counterclockwise). The bottom image shows a view from below. Trajectories spin mostly counterclock- wise in the component at low altitude and clockwise in the one at a high altitude, which is consistent with the high level model of a mature cyclone [Ter07]. Roughly speaking, the circulation on higher altitude represents the exhaust system of the hurricane. As an estimate of the spinning direction, we used the sign of the z-coordinate of the sum of cross products of horizontal components of vectors connecting consecutive samples obtained using the Runge-Kutta method. ", "caption_bbox": [391, 213, 692, 470]}, {"image_id": 9, "file_name": "506_09.png", "page": 8, "dpi": 300, "bbox": [108, 82, 312, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Result for the flow behind a square cylinder, seen from downstream direction, reveals interesting three- dimensional structure of the flow, in particular the small symmetric areas of close to circulating flow in the upper part of the image. ", "caption_bbox": [58, 271, 359, 345]}, {"image_id": 10, "file_name": "506_10.png", "page": 9, "dpi": 300, "bbox": [61, 359, 691, 444], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Results for consecutive time slices of the resampled version of the flow behind square cylinder data set. The cylinder shaped recurrent components in the back (seen in the first, third and fifth image) represent vortices that separate from the two large nearly recurrent components on top and on the bottom in an alternating fashion. Note that the while the vortices right behind the cylinder are not captured by separate nearly recurrent components, the geometry of the large components clearly shows their location as well as provides information on the extent of the circulation. ", "caption_bbox": [58, 447, 691, 521]}, {"image_id": 11, "file_name": "506_11.png", "page": 9, "dpi": 300, "bbox": [90, 78, 662, 202], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Results for the B\u00e9rnard-Rayleigh convection data set, obtained using 4 refinement iterations. The result on the left was obtained using the complete subsampled data set. Since the PC approximation cannot reproduce no-slip boundary conditions, it should be interpreted as an approximation of regions where the flow is close to circulating and does not approach the boundary. The components are large because the flow circulates everywhere in the domain. The results in the middle and on the right was obtained from the data set with one and two layers of voxels near the ceiling and the floor removed (respectively), and hence they represent nearly recurrent flow that stays sufficiently far from the floor and ceiling. The results highlight the convection cell structure. In particular, the result shown on the right indicates that the particles near the 2D section through the middle of the data set tend to quickly get close to floor or ceiling as they circulate throughout the domain, which results in segmentation into 8 roughly symmetric nearly recurrent components. The computation times were 451, 309 and 170 seconds (respectively). ", "caption_bbox": [58, 203, 691, 338]}], "507": [{"image_id": 0, "file_name": "507_00.png", "page": 3, "dpi": 300, "bbox": [421, 79, 668, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Flow over a \u201cblunt body\u201d (front to back). Advec- tion of dye without diffusion model (top, with a streak line for comparison). Active diffusion (bottom) mimics diffusion of smoke in experimental analysis. Resolution 600\u00d7125\u00d7121. ", "caption_bbox": [391, 308, 692, 367]}, {"image_id": 1, "file_name": "507_01.png", "page": 4, "dpi": 300, "bbox": [66, 82, 683, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Unsteady buoyant air flow (CFD) in a closed container heated at bottom (red plate, 75\u25e6 C) and cooled at the top (blue plate, 5\u25e6 C). Two isosurfaces, one at 38\u25e6 C (blue) and one at 42\u25e6 C (red). Advected dye (green, without diffusion model) seeded at center (black box). Finite volume method using WENO reconstruction at both dye resolutions 244 \u00d7 124 \u00d7 244 (a) and 122 \u00d7 62 \u00d7 122 (b) exhibits much lower numerical diffusion than trilinear reconstruction at 244 \u00d7 124 \u00d7 244 (c). ", "caption_bbox": [58, 260, 691, 321]}, {"image_id": 2, "file_name": "507_02.png", "page": 5, "dpi": 300, "bbox": [60, 80, 359, 202], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Diffusivity adjustment in buoyant flow example (vertical cross section, low temperature - blue, high temper- ature - red). Virtual dye (green, mixed with color from tem- perature) seeded at hot plate at lower image border. Using D\u03c6 = 1.11 \u00b7 10\u22125 (a), D\u03c6 = 1.65 \u00b7 10\u22125 (b), and (theoreti- cal) diffusivity from simulation D\u03c6 = 2.19 \u00b7 10\u22125 (c). In (a) the dye region is too small, in (c) too large, and in (b) the reduced diffusivity compensates numerical diffusion well. ", "caption_bbox": [58, 210, 359, 332]}, {"image_id": 3, "file_name": "507_03.png", "page": 5, "dpi": 300, "bbox": [405, 81, 676, 245], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Example of 1D WENO reconstruction. Cell cen- ters x with cell-averaged values \u03c6 and reconstruction poly- nomials \u03c6(x). Resulting WENO reconstruction \u03c6WENO (x) for cells i \u2212 1 and i (bold). Note that neither \u03c6(x) nor \u03c6WENO (x) pass through the values at the centers. ", "caption_bbox": [391, 244, 692, 319]}, {"image_id": 4, "file_name": "507_04.png", "page": 6, "dpi": 300, "bbox": [71, 80, 349, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Riemann solution for fluxes ((a) and (b)). WENO reconstruction (bold) exhibits discontinuities at cell faces. Flux (transparent rectangle) is determined from advection direction u, choosing \u201cdonor\u201d side. For diffusion (c), gradi- ent at faces is computed from central reconstruction polyno- mial (green, blue) and averaged (black) (cf. Figure 4). ", "caption_bbox": [58, 204, 359, 293]}, {"image_id": 5, "file_name": "507_05.png", "page": 7, "dpi": 300, "bbox": [397, 85, 680, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) Advection-diffusion procedure. Operations in blue blocks are performed on CPU, OpenGL is used in or- ange blocks, green blocks are done in CUDA on GPU. (b) Blocking if dye grid dimension exceeds GPU shared mem- ory. Number of prediction steps and order of WENO recon- struction define the number of ghost cells. For efficiency, blocks should be large, e.g., contain 128 output cells. ", "caption_bbox": [391, 389, 692, 494]}, {"image_id": 6, "file_name": "507_06.png", "page": 8, "dpi": 300, "bbox": [423, 82, 686, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Buoyant flow example at different configurations (no lighting and no isosurfaces). 1) Single dye at resolution 122 \u00d7 62 \u00d7 122 with early rejection (worst case in brackets), and 2) without. 3) Two independent dyes, and 4) one dye at 244 \u00d7 124 \u00d7 244. See also the accompanying video. ", "caption_bbox": [391, 757, 692, 832]}, {"image_id": 7, "file_name": "507_07.png", "page": 8, "dpi": 300, "bbox": [60, 82, 336, 209], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Performance comparison between WENO and PBDA for the von K\u00e1rm\u00e1n vortex street. Time for one step (Comp. time) vs. the whole simulation (Total time). ", "caption_bbox": [58, 770, 359, 814]}, {"image_id": 8, "file_name": "507_08.png", "page": 9, "dpi": 300, "bbox": [401, 346, 679, 435], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Evaporating drop example with isosurfaces at vapor concentration 0.0001 and 0.005 (blue), drop located to the left. Dye (green) is seeded once (a) and continuously (b) at the drop. Transport outward the drop is revealed by passive diffusion only (a). However, due to the high drop speed, advection dominates the transport behavior (b). ", "caption_bbox": [391, 444, 692, 533]}, {"image_id": 9, "file_name": "507_09.png", "page": 9, "dpi": 300, "bbox": [65, 82, 682, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Buoyant unsteady flow example (with clipping) by green dye seeded at the hot (red) plate. Pure advection (a), only diffusion flux (b) (passive diffusion), and both advective and diffusion flux (c) (passive advection-diffusion). In (b), diffusion flux transports the dye outward hot air (red) and toward cold air (blue). In (c), the dye reveals the true transport of heat: it is diffusing toward the cold plume and partially leaving at the cold (blue) plate before it is advected downward by the cold plume. ", "caption_bbox": [58, 247, 691, 306]}, {"image_id": 10, "file_name": "507_10.png", "page": 9, "dpi": 300, "bbox": [62, 351, 358, 538], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Heating coil example. Air flow from bottom to top, dye (green) seeded at two points at lower side of coil, and isosurfaces of temperature (red). Dye advection by ad- vection only (a) vs. dye advection by advection-diffusion of heat (b). It is apparent that heat is repelling the dye from the coil and transporting it to the cooled walls in (b). ", "caption_bbox": [58, 547, 359, 636]}], "508": [{"image_id": 0, "file_name": "508_00.png", "page": 4, "dpi": 300, "bbox": [383, 888, 693, 983], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A 2D slice taken at the center of the Tornado simulation. Velocity is mapped to color where blue is minimum velocity and red      Position For position we use the elliptic error function by Telea is max. This illustrates the velocity gradient initially increasing and and Van Wijk [TvW99]. For consistency our user controlled coef- then decreasing away from the center of the vortex.                     \ufb01cient \u03b7\u03c8 corresponds to B, and \u03b5\u03c8 (\u03b7\u03c8 ) corresponds to s where ", "caption_bbox": [48, 839, 702, 889]}, {"image_id": 1, "file_name": "508_01.png", "page": 4, "dpi": 300, "bbox": [47, 56, 646, 191], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: This Figure demonstrates parameters of the elliptic error functions. The clustering is applied to the Bernard \ufb02ow data [WSE05]. The glyphs visualize the representative vector at the cluster location. The parameters of the top left image are A = 0.1, B = 0.25 and sl = 100. The glyphs are fairly evenly distributed. The parameters of the top right image are A = 0.1, B = 0.75 and sl = 100. The glyphs are fairly evenly distributed around the rotating areas of \ufb02ow. The parameters of the bottom left image are A = 0.9, B = 0.25 and sl = 100. The glyphs are concentrated around the rotating areas of \ufb02ow. The parameters of the bottom right image are A = 0.9, B = 0.75 and sl = 100. The glyphs are fairly evenly distributed. ", "caption_bbox": [48, 190, 702, 266]}, {"image_id": 2, "file_name": "508_02.png", "page": 5, "dpi": 300, "bbox": [138, 56, 705, 142], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The left image is the Bernard \ufb02ow simulation visualized with \u03b7\u03c8 = 0.25, \u03b7\u03b4 = 0.0 \u03b7\u03bc = 0.5 and sl = 27. The glyphs demonstrate clustering in the vicinity of the velocity gradient associated with the vortices. The right image demonstrates cluster representations focusing around cores of the vortices. This is achieved using parameters which emphasize clustering of vectors with orthogonal directions. sl = 27, ", "caption_bbox": [48, 141, 702, 183]}, {"image_id": 3, "file_name": "508_03.png", "page": 6, "dpi": 300, "bbox": [77, 761, 329, 851], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: These \ufb01gures show that the seeding curve length is pro- portional to the volume weighted average of the clusters children. The left \ufb01gure is represented by 4 clusters and the right \ufb01gure by 1. ", "caption_bbox": [48, 851, 367, 888]}, {"image_id": 4, "file_name": "508_04.png", "page": 6, "dpi": 300, "bbox": [375, 57, 659, 150], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: These illustrations demonstrate straight seeding curves vs integrated seeding curves. The representative vectors and loca- tions are visualized with arrow glyphs. The left image shows the seeding curves crossing each other when aligned with the curva- ture vector. The right image shows the seeding curves following the curvature, not crossing, and remain orthogonal to the \ufb02ow. ", "caption_bbox": [383, 152, 702, 226]}, {"image_id": 5, "file_name": "508_05.png", "page": 6, "dpi": 300, "bbox": [421, 704, 663, 852], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: This illustration of the Bernard simulation demonstrates the seeding curve following the \ufb02ow structure. The seeding location derived from the clustering is at the center of the curve (black). ", "caption_bbox": [383, 851, 702, 888]}, {"image_id": 6, "file_name": "508_06.png", "page": 7, "dpi": 300, "bbox": [81, 671, 333, 802], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Hurricane Isabel data visualized with automatic stream surfaces. Color is mapped to velocity, and opacity is mapped to vector \ufb01eld curvature. This visualization emphasizes the eye of the hurricane captured by stream surfaces rendered with edge high- lighting and view dependent color saturation. The inner structure of the vortex tends away from blue as the velocity increases away from the center to the vortex. ", "caption_bbox": [48, 802, 367, 889]}, {"image_id": 7, "file_name": "508_07.png", "page": 7, "dpi": 300, "bbox": [416, 679, 668, 814], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Hurricane Isabel visualized using settings designed to give a broader representation. A second smaller vortex like struc- ture can be seen on the coast in the mid left of this still image. Stream surfaces are rendered with edge highlighting and view de- pendent color saturation. The inner structures of the simulation are viewed with additional transparency. ", "caption_bbox": [383, 814, 702, 888]}, {"image_id": 8, "file_name": "508_08.png", "page": 8, "dpi": 300, "bbox": [47, 56, 378, 215], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Clustering performance of a range of simulations.", "caption_bbox": [66, 794, 349, 807]}, {"image_id": 9, "file_name": "508_09.png", "page": 8, "dpi": 300, "bbox": [375, 57, 668, 215], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: This image highlights the ability of our algorithm to provide both overview and feature-centered within the same visual- ization. The vortex shedding is represented by the stream surfaces along with its relation to the rest of the \ufb02ow \ufb01eld. ", "caption_bbox": [383, 215, 702, 265]}, {"image_id": 10, "file_name": "508_10.png", "page": 8, "dpi": 300, "bbox": [416, 675, 668, 803], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: The Bernard Flow numerical simulation visualized us- ing our algorithm. The seeding locations are derived from the clus- tering process using the feature-centered parameters and sl = 4. The four main vortex structures are clearly emphasized. The ther- mal motion of the \ufb02ow \ufb01eld is captured with our framework. The \ufb01gure shows the surfaces rendered with transparency mapped to \u03b1c and \u03b1v . ", "caption_bbox": [383, 803, 702, 890]}, {"image_id": 11, "file_name": "508_11.png", "page": 9, "dpi": 300, "bbox": [59, 890, 482, 978], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "                                                                   [DH93] D ELMARCELLE T., H ESSELINK L.: Visualizing Second-order Figure 17: A naive seeding approach to the \ufb02ow past a cuboid sim-    Tensor Fields with Hyperstream lines. IEEE Computer Graphics and ulation. Although the range of illustrative techniques are applied   Applications 13, 4 (July 1993), 25\u201333. 2 the perception of the \ufb02ow characteristics is limited. The surfaces [EML\u2217 11] E DMUNDS M., M C L OUGHLIN T., L ARAMEE R. S., C HEN are seeded at regular intervals at a consistent orientation across   G., Z HANG E., M AX N.: Automatic Stream Surfaces Seeding. In EU- the domain.                                                          ROGRAPHICS 2011 Short Papers (Llandudno, Wales, UK, April 11\u201315 ", "caption_bbox": [48, 822, 702, 891]}], "509": [{"image_id": 0, "file_name": "509_00.png", "page": 3, "dpi": 300, "bbox": [377, 56, 693, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Biopsy Planner - conceptual overview.", "caption_bbox": [417, 359, 666, 372]}, {"image_id": 1, "file_name": "509_01.png", "page": 4, "dpi": 300, "bbox": [59, 56, 656, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Biopsy Planner overview.", "caption_bbox": [283, 361, 467, 374]}, {"image_id": 2, "file_name": "509_02.png", "page": 5, "dpi": 300, "bbox": [377, 56, 693, 201], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Entry points stability map. Areas in red indicate pathways that are too close to a blood vessel. Green areas represent the entry points regions that respect the required minimum distance to any surrounding blood vessel. White contours represent the boundary areas between the safe re- gions and the less safe ones. ", "caption_bbox": [391, 212, 692, 301]}, {"image_id": 3, "file_name": "509_03.png", "page": 6, "dpi": 300, "bbox": [378, 57, 687, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Augmented 2D slice orthogonal to the needle direction. For validation purposes, a visual representation showing the distance and the direction to the closest blood vessel is introduced. ", "caption_bbox": [391, 285, 692, 344]}, {"image_id": 4, "file_name": "509_04.png", "page": 6, "dpi": 300, "bbox": [59, 56, 378, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Needle pathway distance graph. For every point of the needle pathway, the distance to the closest blood ves- sel is shown. The needle radius and the required minimum distance to any surrounding blood vessel are presented with dotted gray and green lines. The blue dotted line represents the point where the biopsy needle is entering the tumor. ", "caption_bbox": [59, 272, 360, 361]}, {"image_id": 5, "file_name": "509_05.png", "page": 7, "dpi": 300, "bbox": [377, 56, 693, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: 3D view and 2D slice views. All views are linked together to synchronize any changes made in the position of the currently inspected point on the needle pathway. The slice positions are visible in the 3D view to provide a better spatial understanding of the biopsy procedure. ", "caption_bbox": [391, 356, 692, 430]}], "510": [{"image_id": 0, "file_name": "510_00.png", "page": 4, "dpi": 300, "bbox": [397, 309, 684, 631], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: LAMP projections from distinct feature spaces. Their silhouette coefficients are 0.5054 (a), 0.5482 (b) and 0.5494 (c), indicating that the combination of spatial and curvature features render the best discrimination amongst the groups of classified fibers. ", "caption_bbox": [391, 644, 692, 718]}, {"image_id": 1, "file_name": "510_01.png", "page": 5, "dpi": 300, "bbox": [75, 57, 378, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Comparison of fiber visualizations using conven- tional lines, tubes, and our surface approach. The depth in- formation provided by surfaces is a helpful hint to identifi- cation of intricate fiber bundle geometries. ", "caption_bbox": [59, 302, 360, 361]}, {"image_id": 2, "file_name": "510_02.png", "page": 6, "dpi": 300, "bbox": [59, 56, 375, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Coordination from projected 2D space (a) to ob- ject 3D space (b). ", "caption_bbox": [59, 254, 360, 282]}, {"image_id": 3, "file_name": "510_03.png", "page": 6, "dpi": 300, "bbox": [375, 57, 693, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Example of an exploratory scenario of a large brain fiber dataset. Transparency can be used to enhance the ability to locate dense regions on projections. ", "caption_bbox": [391, 313, 692, 356]}, {"image_id": 4, "file_name": "510_04.png", "page": 6, "dpi": 300, "bbox": [60, 311, 357, 657], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Two-way coordination between the object and projected spaces to guide the selection of similar fibers. ", "caption_bbox": [59, 669, 360, 697]}, {"image_id": 5, "file_name": "510_05.png", "page": 7, "dpi": 300, "bbox": [375, 56, 699, 787], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Exploring a large fiber dataset using a sampling strategy via LAMP. In (a) and (b) The user starts by pro- jecting and exploring a small portion of the dataset. Groups can be set apart or joined together (b). Then the rest of the dataset is projected and colored using these changes as guid- ance (d). ", "caption_bbox": [391, 806, 692, 895]}, {"image_id": 6, "file_name": "510_06.png", "page": 8, "dpi": 300, "bbox": [396, 556, 688, 718], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Distance plots for our approach (a) and [CDZ\u2217 09] (b), both based on our feature space. ", "caption_bbox": [391, 731, 692, 759]}, {"image_id": 7, "file_name": "510_07.png", "page": 8, "dpi": 300, "bbox": [59, 56, 375, 413], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: An alternative sample projection manipulation for exploration shown in Figure 6. Even though the samples in red and green groups belong to the same class, LAMP is capable of preserving the layout established by the user. ", "caption_bbox": [59, 426, 360, 485]}, {"image_id": 8, "file_name": "510_08.png", "page": 8, "dpi": 300, "bbox": [375, 57, 688, 438], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Projections created using our approach (a) and the method in [CDZ\u2217 09] (b), yielding similar point place- ments with highly differing processing times. (c) shows the highlighted fibers with the same colors employed in the pro- jections. ", "caption_bbox": [391, 451, 692, 525]}, {"image_id": 9, "file_name": "510_09.png", "page": 9, "dpi": 300, "bbox": [58, 540, 362, 781], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Main window of the developed system to explore fiber tracts datasets. ", "caption_bbox": [59, 807, 360, 835]}], "511": [{"image_id": 0, "file_name": "511_00.png", "page": 2, "dpi": 300, "bbox": [377, 57, 666, 197], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Hierarchical clustering allows for intuitive level- of-detail selection, without a priori knowledge of the data domain. ", "caption_bbox": [391, 208, 692, 251]}, {"image_id": 1, "file_name": "511_01.png", "page": 2, "dpi": 300, "bbox": [58, 56, 378, 196], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A sagittal slice of one phase of the 4D PC-MRI blood-flow velocity data, showing the acquired directions. (a) Right-to-left, (b) anterior-to-posterior, (c) feet-to-head. ", "caption_bbox": [58, 209, 359, 252]}, {"image_id": 2, "file_name": "511_02.png", "page": 3, "dpi": 300, "bbox": [87, 56, 693, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Overview of the visualization framework, based on spatiotemporal hierarchical clustering. The gray dashed arrows depict pre-processing steps. (1) A tMIP volume is generated, and (2) an iso-threshold captures the voxels that are clustered. (3) Next, the cluster hierarchy is constructed. (4) Using the cluster tree, labels are generated per cardiac phase. After pre- processing, the real-time visualization is generated using the available data structures, as depicted by the solid blue arrow. ", "caption_bbox": [58, 318, 691, 377]}, {"image_id": 3, "file_name": "511_03.png", "page": 4, "dpi": 300, "bbox": [59, 56, 378, 192], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The clustering yields different results, using va- rious dissimilarity measures. (a) An artificial vector field is clustered using: (b) the elliptical dissimilarity (\u03b1 = 0.9, \u03c9 = 0.9), and (c) the local linear expansion dissimilarity. ", "caption_bbox": [58, 205, 359, 266]}, {"image_id": 4, "file_name": "511_04.png", "page": 4, "dpi": 300, "bbox": [71, 749, 353, 882], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Schematic depiction of a bottom-up generation of a full cluster hierarchy. Tree nodes are merged, iteratively processing the two clusters with the smallest dissimilarity. ", "caption_bbox": [58, 895, 359, 938]}, {"image_id": 5, "file_name": "511_05.png", "page": 4, "dpi": 300, "bbox": [403, 749, 685, 864], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Schematic depiction of a coarse bottom-up gene- ration of the cluster hierarchy, requiring half the number of iterations in comparison to a full cluster tree generation. ", "caption_bbox": [391, 895, 692, 938]}, {"image_id": 6, "file_name": "511_06.png", "page": 5, "dpi": 300, "bbox": [108, 693, 312, 836], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Qualitative comparison of the cluster boundari- es, based on a planar reformat through the volunteer PC- MRI blood-flow data at 330ms. The selected hierarchy level is 99.98%. (a) A full hierarchical clustering, in comparison to (b) the coarse hierarchical clustering (CHC) approach, with a threshold increment of \u2206dth = 0.01. ", "caption_bbox": [58, 849, 359, 940]}, {"image_id": 7, "file_name": "511_07.png", "page": 6, "dpi": 300, "bbox": [393, 664, 691, 827], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Close-up of 4D-seeded patharrows. (a) A time co- lor coding reveals the temporal character. (b) Color may al- so convey the flow speed. (c) The pathlines are employed for animation. The color is desaturated, except for a sliding window around the animation time-point. (d) Alternatively, small patharrows may represent the sliding window. Note the color correspondence between (b), (c), and (d). ", "caption_bbox": [391, 841, 692, 945]}, {"image_id": 8, "file_name": "511_08.png", "page": 6, "dpi": 300, "bbox": [59, 56, 378, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Simplified representation of the patharrow see- ding. The horizontal axis shows the time, while the spatial domain is represented on the vertical axis. One time-frame is highlighted in yellow. (a) For 3D seeding, a spatial cen- ter is computed for each existing cluster, and short pathlines are traced interactively. (b) For 4D seeding, a spatiotempo- ral center is computed, and long pathlines are precomputed. ", "caption_bbox": [58, 225, 359, 329]}, {"image_id": 9, "file_name": "511_09.png", "page": 7, "dpi": 300, "bbox": [376, 56, 693, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Aortic dissection with pathological flow. (a) Ana- tomical context based on a tMIP does not show the seconda- ry system (dashed line). (b) A 4D-seeded patharrow anima- tion highlights patterns. A window around 320 ms is shown. ", "caption_bbox": [391, 331, 692, 390]}, {"image_id": 10, "file_name": "511_10.png", "page": 7, "dpi": 300, "bbox": [94, 57, 378, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Blood-flow depicted by 3D-seeded patharrows with anatomical context. (a) A cel shaded surface with con- tours based on the surface curvature. (b) Opacity modulati- on of the frontfaces ensures visibility of the patharrows. ", "caption_bbox": [58, 331, 359, 390]}, {"image_id": 11, "file_name": "511_11.png", "page": 8, "dpi": 300, "bbox": [377, 57, 663, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: A CFD simulation of a cerebral aneurysm, de- picted by static patharrows, based on 4D seed positions. A high-speed in- and outflow is observed from the parent ves- sel. Recirculating patterns occur within the aneurysm, which are more clearly conveyed through animation. ", "caption_bbox": [391, 352, 692, 426]}, {"image_id": 12, "file_name": "511_12.png", "page": 8, "dpi": 300, "bbox": [59, 56, 378, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Aortic dissection with pathological blood flow, depicted by long patharrows, based on 250 clusters using the elliptical dissimilarity. The 4D-seeded short patharrows convey the spatiotemporal structure, revealing flow patterns during animation. The notable regions are indicated. ", "caption_bbox": [58, 352, 359, 426]}], "512": [{"image_id": 0, "file_name": "512_00.png", "page": 2, "dpi": 300, "bbox": [392, 702, 692, 815], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Left: An abdominal and pelvic artery mesh gen- erated with RAMVAS. Center & Right: Interior views from the point of view indicated in the left image. Free-form con- tours (white dotted lines) of two unbranched vessel sections contributing to the bifurcation are displayed. Since contours may partially lie inside adjacent vessel, a simple interpola- tion leads to undesirable inner structures. ", "caption_bbox": [391, 826, 692, 930]}, {"image_id": 1, "file_name": "512_01.png", "page": 3, "dpi": 300, "bbox": [390, 672, 694, 876], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: By computing their minimum the local ADFs fi are combined to form the Boolean union volume F. Note the distance peaks of F inside the union volume. ", "caption_bbox": [391, 887, 692, 931]}, {"image_id": 2, "file_name": "512_02.png", "page": 4, "dpi": 300, "bbox": [59, 56, 378, 249], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A vessels branch modelled with clipped cones (blue) and clipped spheres (red). One radius ri is given per centerline node pi . ri and ri+1 are interpolated along the centerline. Gaps between clipped cones are filled by placing clipped spheres at the inner nodes. ", "caption_bbox": [59, 265, 360, 339]}, {"image_id": 3, "file_name": "512_03.png", "page": 4, "dpi": 300, "bbox": [391, 668, 693, 860], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Left: RAMVAS reconstruction of an arterial tree computed form free-form contours. A subset of contours is shown in the image. Right: Reconstructions of two individ- ual segments defined by pairs of contours Ci and Ci+1 . ", "caption_bbox": [391, 872, 692, 931]}, {"image_id": 4, "file_name": "512_04.png", "page": 5, "dpi": 300, "bbox": [392, 394, 692, 797], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Mapping of neighboring free-form contour pairs to normalized shapes. A non-rigid thin plate spline transfor- mation T PS to a topologically equivalent simple object is performed to compute local ADF f by an easily computable approximation f\u02dc in the normalized space. For our free-form vessel models the topology of each neighboring contour pair is classified as non-intersecting, touching at 1 contour posi- tion or intersecting at 2 contour positions as displayed. ", "caption_bbox": [391, 811, 692, 931]}, {"image_id": 5, "file_name": "512_05.png", "page": 6, "dpi": 300, "bbox": [3, 639, 59, 879], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Left: for a topologically reliable sampling of a sphere of radius rmin the edges must be shorter than rmin \u00b7 \u221a2 .                                                               3 Right: although containing portions of the surface all cell vertices lie outside the volume. Pruning the cell prohibits                                                         \u221a                                                              the                                                           3 reconstruction of the highlighted area. If |F(vc )| > 2 \u00b7 sc holds the surface does not run through the cell. ", "caption_bbox": [58, 836, 359, 931]}, {"image_id": 6, "file_name": "512_06.png", "page": 6, "dpi": 300, "bbox": [375, 57, 694, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Topological degeneracies occur if the size thresh- old for the octree cells is violated. Quality parameters Q from left to right are 0,5, 0,9 and 1. A quality parameter of Q >= 1 guarantees a topologically reliable reconstruction. ", "caption_bbox": [391, 246, 692, 305]}, {"image_id": 7, "file_name": "512_07.png", "page": 7, "dpi": 300, "bbox": [375, 56, 694, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Top left: artifacts occur if the roots of F are lin- early interpolated. Top right: using a bisection method the actual roots are identified and the reconstruction is correct. Bottom: the corresponding scalar fields. Left: rab is interpo- lated at the wrong position because of the distance peak in- side the volume. Right: the bisection method iteratively finds the correct root positions indicated in green. ", "caption_bbox": [391, 280, 692, 384]}, {"image_id": 8, "file_name": "512_08.png", "page": 8, "dpi": 300, "bbox": [390, 551, 698, 830], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Two reconstructions of a bronchial tree with close-up views. Left: CS reconstruction. The main bronchus is sampled in unnecessary detail. Right: RAMVAS recon- struction with quality parameter Q = 1,5. Even though both meshes consist of \u2248 120 000 triangles RAMVAS is able to represent thin structures more accurately. ", "caption_bbox": [391, 841, 692, 930]}, {"image_id": 9, "file_name": "512_09.png", "page": 8, "dpi": 300, "bbox": [59, 56, 378, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Mesh generation times (in milliseconds) and trian- gle counts for CS [OP05] and RAMVAS, taken on an Intel Xeon CPU with 4 physical cores @2.80GHz and 8GB RAM. ", "caption_bbox": [391, 371, 692, 415]}, {"image_id": 10, "file_name": "512_10.png", "page": 9, "dpi": 300, "bbox": [59, 732, 360, 830], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Projections of CS meshes displayed in solid black. The differences to the same surface generated with RAMVAS are color-coded. Red areas are not present in RAMVAS and green areas are not present in the CS mesh. Left: the differences at vessel ends arise from our ability to model non-spherical ends. ", "caption_bbox": [59, 841, 360, 930]}, {"image_id": 11, "file_name": "512_11.png", "page": 9, "dpi": 300, "bbox": [58, 57, 378, 179], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Two close-ups of a thin vessel branching from a large one (LT dataset, left: Q = 1, right: Q = 2). Our ap- proach is able to handle such situations as the octree is re- fined to very small cells in the vicinity of the small branch. ", "caption_bbox": [59, 190, 360, 249]}], "513": [{"image_id": 0, "file_name": "513_00.png", "page": 2, "dpi": 300, "bbox": [375, 57, 692, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Illustration for the star of a vertex c in a trian- gulated domain with uncertain vectors defined per triangle. The marginal PDFs are indicated for each vector. The local correlated random vector Vc consists of all vector compo- nents of the neighborhood of c. ", "caption_bbox": [391, 252, 692, 326]}, {"image_id": 1, "file_name": "513_01.png", "page": 3, "dpi": 300, "bbox": [413, 382, 671, 503], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Winding number calculation of a saddle point in a piecewise constant triangulated vector field. Following vectors in counter-clockwise direction from v0 to v4 , vectors rotate clockwise, yielding the winding number of \u22121. ", "caption_bbox": [391, 513, 692, 572]}, {"image_id": 2, "file_name": "513_02.png", "page": 4, "dpi": 300, "bbox": [375, 57, 692, 204], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Star of a curved surface, incident angles around the center sum to less than 2\u03c0. Vector angles are measured in flattened space. ", "caption_bbox": [391, 205, 692, 248]}, {"image_id": 3, "file_name": "513_03.png", "page": 5, "dpi": 300, "bbox": [67, 56, 693, 395], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Synthetic dataset. From left to right: sources, saddles and sinks; top: correlation considered, bottom: correlation neglected. Note that the ranges of probabilities differ between the correlated and uncorrelated case and have been scaled for visualization. LIC visualizations display the mean field \u00b5. ", "caption_bbox": [59, 403, 692, 446]}, {"image_id": 4, "file_name": "513_04.png", "page": 6, "dpi": 300, "bbox": [57, 56, 696, 245], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Color coded probabilities for singularities in the wall shear stress vector field from a simulated cerebral aneurysm blood flow at a single simulation time step. The mean wall shear stress vector field \u00b5 is indicated by a low-contrast LIC visualization. Probabilities for the different critical point types are encoded by different colors: sinks in violet, sources in green and saddles in blue. Intensities are scaled by the probabilities. Colors are blended additively. Depicted are: All critical points of the 9 ensemble members (a), probabilities considering spatial correlations (b), probabilities with correlations of vector components only (c) and probabilities with correlations neglected (d). ", "caption_bbox": [59, 253, 692, 342]}, {"image_id": 5, "file_name": "513_05.png", "page": 6, "dpi": 300, "bbox": [104, 377, 665, 488], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Critical point probabilities of the aneurysm wall-shear stress vector field at three subsequent time steps.", "caption_bbox": [86, 496, 661, 509]}, {"image_id": 6, "file_name": "513_06.png", "page": 7, "dpi": 300, "bbox": [63, 56, 693, 487], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Uncertain flow features over a full heart cycle in a cerebral aneurysm visualized by nested semi-transparent isosur- faces. Streamlines of the mean vector field reveals some context. (a) Critical point probabilities with Poincar\u00e9 index > 0 (blue) and < 0 (violet). (b) Probabilities for swirling motion cores. ", "caption_bbox": [58, 495, 691, 539]}, {"image_id": 7, "file_name": "513_07.png", "page": 8, "dpi": 300, "bbox": [375, 57, 659, 607], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Cutout of the probability fields for sinks: (a) With correlations, (b) just vector-wise correlations, (c) without consideration of correlations. ", "caption_bbox": [391, 615, 692, 658]}, {"image_id": 8, "file_name": "513_08.png", "page": 8, "dpi": 300, "bbox": [59, 56, 378, 601], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Probabilities for singularities in the daily aver- age wind vector field from the climate simulation dataset are shown as a heightfield with colormapping. (a) sources, (b) saddles, (c) sinks. ", "caption_bbox": [59, 609, 360, 668]}], "514": [{"image_id": 0, "file_name": "514_00.png", "page": 3, "dpi": 300, "bbox": [59, 56, 693, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Uncertain velocity and acceleration at grid point (60, 50) of the PIV data set using uncorrelated Gaussian distribu- tions. a) sample vectors vi, j,k as red dots and marginal density distribution as red curves; uncorrelated Gaussian reconstruction and marginal density distribution as green point cloud and curve; b) sampled acceleration and marginal distribution as red point cloud and curves; Monte Carlo sampling of acceleration by using uncorrelated Gaussian at grid points as green point cloud and curves: the red and green curves do not coincide. ", "caption_bbox": [58, 375, 691, 449]}, {"image_id": 1, "file_name": "514_01.png", "page": 4, "dpi": 300, "bbox": [59, 56, 664, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Uncertain velocity and acceleration at grid point (60, 50) of the PIV data set using correlated Gaussian distributions. a) sample vectors vi, j,k as red dots and marginal density distribution as red curves; correlated Gaussian reconstruction and marginal density distribution as blue point cloud and curve; b) sampled acceleration and marginal distribution as red point cloud and curves; Monte Carlo sampling of acceleration by using correlated Gaussian at grid points as blue point cloud and curves: the red and blue curves coincide. ", "caption_bbox": [58, 375, 691, 449]}, {"image_id": 2, "file_name": "514_02.png", "page": 5, "dpi": 300, "bbox": [124, 57, 378, 184], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (left) Scheme of the support regions for discrete vortex core line computations in 3D space. The cell we want to evaluate is colored black. (right) Scheme of the support region of vortex region. ", "caption_bbox": [59, 198, 360, 257]}, {"image_id": 3, "file_name": "514_03.png", "page": 7, "dpi": 300, "bbox": [58, 56, 694, 869], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Cylinder data set: (a,d,g,j,m) time step 98, (b,e,h,k,n) time step 99, (c,f,i,l,o) time step 100, (a,b,c) volume rendering of the maximal standard deviation, (d,e,f) isosurfaces of the probability field P(\u03bb2 < \u22120.003) with iso values 0.05 and 0.95, (g,h,i) cross section of the probability field P(\u03bb2 < \u22120.003) at z = 0 (j,k,l) isosurfaces of the probability field P(Q > 0.003) with iso values 0.05 and 0.95, (m,n,o) cross section of the probability field P(Q > 0.003) at z = 0. ", "caption_bbox": [58, 877, 691, 936]}, {"image_id": 4, "file_name": "514_04.png", "page": 8, "dpi": 300, "bbox": [59, 56, 694, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Cylinder data set: (a,d) time step 98, (b,e) time step 99, (c,f) time step 100, (a,b,c) volume rendering of the of the vortex core probability field, (d,e,f) cross section of this field at z = 0. ", "caption_bbox": [58, 343, 691, 372]}, {"image_id": 5, "file_name": "514_05.png", "page": 8, "dpi": 300, "bbox": [88, 594, 332, 836], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Cylinder data set time step 100: (top) cross section of the probability field P(\u03bb2 < \u22120.003) and (bottom) P(Q > 0.003) at z = 0 compared with isolines of the input data. ", "caption_bbox": [58, 846, 359, 890]}, {"image_id": 6, "file_name": "514_06.png", "page": 8, "dpi": 300, "bbox": [62, 395, 690, 519], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Cylinder data set time step 100: (left) vortex cores of the input vector fields , (middle) isosurfaces of P(a\u03c1 k \u03c1) \u2265 0.01 (light blue) and 0.1 (blue), (right) isosuface 0.1 (blue) with vortex cores of the mean vector field (orange). ", "caption_bbox": [58, 529, 691, 558]}, {"image_id": 7, "file_name": "514_07.png", "page": 9, "dpi": 300, "bbox": [59, 57, 378, 532], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: CMIP5 data set: (top) showing P(\u03bb2 < \u22120.003) , (middle) P(Q > 0.003) , and (bottom) the probability of vortex cores . ", "caption_bbox": [58, 542, 359, 586]}, {"image_id": 8, "file_name": "514_08.png", "page": 9, "dpi": 300, "bbox": [375, 56, 693, 452], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Flow around a backward facing step: (a) and (b) are two examples of reconstructed vector fields of the PIV measurements; (c) P(Q > 0), (d) P(\u03bb2 < 0), (e) Q criterion of the mean vector field, (f) \u03bb2 criterion of the mean vector field. ", "caption_bbox": [391, 463, 692, 537]}], "515": [{"image_id": 0, "file_name": "515_00.png", "page": 2, "dpi": 300, "bbox": [58, 56, 694, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) Mean surface in an ensemble temperature field over a 2D domain. (b) Disjoint clusters contain surface points where the uncertainty has a correlation higher than \u03c11 = 0.4 to the uncertainty at the cluster centroids (black dots). (c) Clusters are subdivided using \u03c12 = 0.9 and extruded along the third dimension according to the standard deviation at the member points. ", "caption_bbox": [59, 252, 692, 296]}, {"image_id": 1, "file_name": "515_01.png", "page": 4, "dpi": 300, "bbox": [375, 57, 694, 378], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Positive correlation clusters for \u03c11 = 0.3 are visualized on the ECMWF mean surface. (b) Clustering for \u03c11 = 0.7 indicates strong local correlation in regions (1) and (2), and weak stochastic dependence in regions (3) and (4). ", "caption_bbox": [391, 388, 692, 447]}, {"image_id": 2, "file_name": "515_02.png", "page": 5, "dpi": 300, "bbox": [58, 57, 378, 225], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Clusters for \u03c11 = 0.4 and corresponding sub- clusters for \u03c12 = 0.9 show isotropic and anisotropic corre- lation structures in (1) and (2), respectively. Severe cluster shrinkage indicates low correlation strength in (3). ", "caption_bbox": [59, 235, 360, 294]}, {"image_id": 3, "file_name": "515_03.png", "page": 5, "dpi": 300, "bbox": [390, 527, 694, 825], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Correlation between cluster points and centers is mapped from [\u03c11 , 1] to [blue, red]. (b) CHVD is mapped from [0, \u03b4max ] to [blue, red]. High correlation anisotropy around the center point is shown in (3). In (4), high anisotropy is only present close to the center point, while correlation is more isotropic with increasing distance. ", "caption_bbox": [391, 835, 692, 924]}, {"image_id": 4, "file_name": "515_04.png", "page": 6, "dpi": 300, "bbox": [390, 369, 694, 514], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Positive clusters are shown in gray, inverse clus- ters for \u03c1\u0302 = \u22120.3 are color coded. Clusters with the same color but different stripe orientation are inversely correlated. ", "caption_bbox": [391, 524, 692, 567]}, {"image_id": 5, "file_name": "515_05.png", "page": 7, "dpi": 300, "bbox": [58, 461, 362, 823], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) Positive, subdivided correlation clusters are shown for \u03c11 = 0.5 and \u03c12 = 0.9. Cluster extrusion until a selected SDF level reveals low positional variability in (1) and strong positional variabilities in (2) and (3). (b) Inverse extruded cluster partners for \u03c1\u0302 = \u22120.5 are shown. ", "caption_bbox": [58, 833, 359, 907]}, {"image_id": 6, "file_name": "515_06.png", "page": 8, "dpi": 300, "bbox": [59, 56, 694, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) Geophysical setup to determine the depth of a material discontinuity (red) in the earth\u2019s interior by measuring travel times of artificial pressure waves (emitted along black lines). A material layer between emitters and discontinuity structure simulates a Gaussian error distribution in wave velocities. (b) Correlation clusters are color coded on the mean surface in the simulated data ensemble. (c) Visualization of standard deviation shows equally strong uncertainty in quadrants (1),(2),(3) and low uncertainty in (4). (d) One possible solution (realization) of the depth structure. High structural variability is seen in quadrant (3), which is indicated by low correlations and high standard deviations in (b) and (c). ", "caption_bbox": [59, 237, 692, 326]}, {"image_id": 7, "file_name": "515_07.png", "page": 9, "dpi": 300, "bbox": [58, 56, 694, 203], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) Mohorovic\u030cic\u0301 discontinuity below Australia. (b) Strong correlation clusters close to the domain boundaries indicate strong regularizations in the simulation algorithm. (c) Close-up view reveals high and low uncertainties, respectively, at the boundaries and in the center, as well as high local correlations at (1) and (2). (d) Inverse clustering shows that strong inverse correlation takes place on a local rather than a global scale. ", "caption_bbox": [59, 213, 692, 272]}], "516": [{"image_id": 0, "file_name": "516_00.png", "page": 3, "dpi": 300, "bbox": [59, 57, 694, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The proposed taxonomy of visual uncertainty in parallel coordinates. The shaded area indicates the level at which it maps to the stages in typical visualization pipelines. ", "caption_bbox": [59, 298, 692, 326]}, {"image_id": 1, "file_name": "516_01.png", "page": 4, "dpi": 300, "bbox": [59, 57, 378, 219], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Completeness: Choosing not to include an entire axis (a) or single values (b) prevents the user from seeing some of the data, causing uncertainty about it. ", "caption_bbox": [59, 229, 360, 272]}, {"image_id": 2, "file_name": "516_02.png", "page": 4, "dpi": 300, "bbox": [378, 57, 689, 221], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Configuration: a) Patterns can be missed when not all possible pairs of axes are represented; b) leaving out individual data values prevents the user from seeing parts of the data;. ", "caption_bbox": [391, 230, 692, 289]}, {"image_id": 3, "file_name": "516_03.png", "page": 5, "dpi": 300, "bbox": [67, 57, 377, 222], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Precision: a) Pixel binning leads to a loss in pre- cision, which makes it impossible to read values precisely; b) the colors of lines drawn over each other make it diffi- cult to see brushing and the precise number of lines (when transparency is used). ", "caption_bbox": [58, 232, 359, 306]}, {"image_id": 4, "file_name": "516_04.png", "page": 5, "dpi": 300, "bbox": [67, 312, 356, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Granularity: a) Clustering of values hides infor- mation about the internal structure of the cluster and po- tentially the number of items in each cluster; b) the same is true for the internal structure of the cluster and the actual locations of the original data points. ", "caption_bbox": [58, 472, 359, 546]}, {"image_id": 5, "file_name": "516_05.png", "page": 6, "dpi": 300, "bbox": [59, 57, 596, 231], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Traceability: a) Single lines are easily hidden among others, leading to uncertainty about the exact number of lines and fine details in the data; b) lines meeting in single points, or in very small neighborhoods, on axes cause ambiguity about the multi-dimensional nature of the data; c) clusters show similar issues and are difficult to trace across multiple dimensions. ", "caption_bbox": [59, 241, 692, 284]}, {"image_id": 6, "file_name": "516_06.png", "page": 7, "dpi": 300, "bbox": [473, 740, 611, 877], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Pattern Complexity: More complex patterns in the visualization lead to more difficulty in reading and un- derstanding the underlying data patterns. ", "caption_bbox": [391, 889, 692, 932]}, {"image_id": 7, "file_name": "516_07.png", "page": 7, "dpi": 300, "bbox": [67, 649, 361, 848], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Lack of Knowledge: a) Not knowing how to read the sometimes complex patterns in parallel coordinates leads to uncertainty about the represented pattern; b) incon- sistent axis scaling, in particular because of the different lo- cations of the zero, can lead to issues in interpretation. ", "caption_bbox": [58, 858, 359, 932]}, {"image_id": 8, "file_name": "516_08.png", "page": 7, "dpi": 300, "bbox": [155, 57, 692, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Identity: a) Color mixing leading to confusion among identity of lines; b) overlapping clusters leading to clutter; c) color mixing among clusters lead to confusion among clusters ", "caption_bbox": [59, 243, 692, 271]}, {"image_id": 9, "file_name": "516_09.png", "page": 9, "dpi": 300, "bbox": [376, 57, 693, 218], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: While the traditional visualization pipeline has a linear structure, analysis of visual uncertainty provides a feedback loop for iterative refinement of the visual represen- tation and the associated interaction techniques. ", "caption_bbox": [391, 244, 692, 303]}, {"image_id": 10, "file_name": "516_10.png", "page": 9, "dpi": 300, "bbox": [89, 57, 377, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Privacy-preserving parallel coordinates are an example for the usefulness of controlled uncertainty [DK11]. ", "caption_bbox": [59, 223, 360, 251]}], "517": [{"image_id": 0, "file_name": "517_00.png", "page": 4, "dpi": 300, "bbox": [59, 56, 615, 417], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: ANIM condition (the animated view) representing migration flows between the world\u2019s countries. The subjects were asked to interact with the view and make findings about the dataset entering them in the text field below the view. ", "caption_bbox": [59, 428, 692, 456]}, {"image_id": 1, "file_name": "517_01.png", "page": 4, "dpi": 300, "bbox": [390, 492, 694, 684], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The \u201cdifference view\u201d of the ANIM condition which shows positive and negative changes of the flow mag- nitudes between the currently selected and the previous years. The study participants had the possibility to switch between the original view and the difference view at any time in both ANIM and SM. ", "caption_bbox": [391, 695, 692, 784]}, {"image_id": 2, "file_name": "517_02.png", "page": 5, "dpi": 300, "bbox": [121, 56, 693, 439], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: SM condition (the small-multiples view). The condition supported zooming synchronously in all years\u2019 views (with the mouse wheel) and highlighting (by hovering mouse over a flow line). Here the user zoomed in to see Africa in more detail. ", "caption_bbox": [59, 452, 692, 480]}, {"image_id": 3, "file_name": "517_03.png", "page": 6, "dpi": 300, "bbox": [375, 57, 686, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Resolving disagreements during manual coding of the findings. Each row corresponds to a finding, each col- umn with squares to a property. The square positions rep- resent different classes which the could be chosen for each property. A green square shows an agreement indicating the number of those of us who agreed on a class, a red square is shown when there was a disagreement. ", "caption_bbox": [391, 291, 692, 395]}, {"image_id": 4, "file_name": "517_04.png", "page": 6, "dpi": 300, "bbox": [390, 527, 694, 694], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Our web-based tool which we collaboratively used for establishing the coding categories by manually group- ing the findings. Each finding is a small label which can be drag-and-dropped between categories. Categories are not predefined, but can be added and removed during the pro- cess. Here the categories are arranged in columns by their temporal scope, so that \u201cone year\u201d findings are placed in the leftmost column and \u201call time\u201d findings in the rightmost column. ", "caption_bbox": [391, 705, 692, 840]}, {"image_id": 5, "file_name": "517_05.png", "page": 7, "dpi": 300, "bbox": [391, 340, 721, 544], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Geographic scope of the findings made in the first round in each of the views. ", "caption_bbox": [391, 554, 692, 582]}, {"image_id": 6, "file_name": "517_06.png", "page": 7, "dpi": 300, "bbox": [375, 56, 725, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Temporal scope of the findings made in the first round in each of the views. ", "caption_bbox": [391, 300, 692, 328]}, {"image_id": 7, "file_name": "517_07.png", "page": 8, "dpi": 300, "bbox": [58, 362, 360, 554], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparison of the temporal scopes of the findings made in the first and the second round depending on the sub- ject group (i.e. the order in which the subjects were using the views). ", "caption_bbox": [59, 562, 360, 621]}, {"image_id": 8, "file_name": "517_08.png", "page": 8, "dpi": 300, "bbox": [53, 56, 378, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison of the geographic scopes of the find- ings made in the first and the second round depending on the subject group (i.e. the order in which the subjects were using the views). ", "caption_bbox": [59, 300, 360, 359]}, {"image_id": 9, "file_name": "517_09.png", "page": 9, "dpi": 300, "bbox": [59, 147, 362, 376], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Gantt chart showing a timeline of the findings (large bars) made by the 8 participants who used ANIM in the 1st round. Along with the findings we see the history of the animation-related actions (red and thin green bars) and the \u201cchange-year\u201d slider action (thicker green bars) which the participants used to make these findings. ", "caption_bbox": [59, 389, 360, 478]}], "518": [{"image_id": 0, "file_name": "518_00.png", "page": 2, "dpi": 300, "bbox": [58, 56, 378, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Smoothly integrated visualization of qualitative abstrac- tions and quantitative data at different zoom levels [BSM04]. The representation depends on the available vertical display space, which is assigned interactively by the user. ", "caption_bbox": [59, 344, 360, 398]}, {"image_id": 1, "file_name": "518_01.png", "page": 5, "dpi": 300, "bbox": [149, 56, 693, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Screenshot of the STZ prototype during an evaluation session. A legend at the bottom explains the color assignments of the qualitative levels. The task shown here was to find the first time-interval where both, pre-breakfast and pre-lunch blood glucose are in the elevated level (cf. Table 1, Task 2). The test persons had to select the time interval by dragging the mouse over the time axis to complete the task. ", "caption_bbox": [59, 249, 692, 289]}, {"image_id": 2, "file_name": "518_02.png", "page": 5, "dpi": 300, "bbox": [153, 293, 599, 534], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Screenshot of the prototype of the benchmark visualization technique based on the visual representations used in the KNAVE-II framework. The task shown here was to find the value of the next measured data point of pre-supper blood glucose when overall blood glucose leaves the normal state the first time (cf. Table 1, Task 8). The test persons had to enter the read value of the data point (tooltip) in the text box on the right side of the window. ", "caption_bbox": [59, 546, 692, 600]}, {"image_id": 3, "file_name": "518_03.png", "page": 7, "dpi": 300, "bbox": [59, 669, 361, 910], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Box plots for completion times per task set/round", "caption_bbox": [75, 929, 342, 941]}], "519": [{"image_id": 0, "file_name": "519_00.png", "page": 1, "dpi": 300, "bbox": [102, 303, 650, 536], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Navigation in a large graph from the medical domain [GCV\u2217 07] using signposts to provide context for the nodes in focus (as used in our user study). The focus is derived from the focal nodes (encircled in red). ", "caption_bbox": [58, 542, 691, 574]}, {"image_id": 1, "file_name": "519_01.png", "page": 5, "dpi": 300, "bbox": [62, 57, 378, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: This schematic view shows the combined isodis- tances with two focal nodes (blue) for different values of p. The value of p controls to what extent nodes between two or more focal nodes will be preferred over nodes near a single focal node. High values of p will induce independent neigh- bourhoods; lower values of p will be more likely to cause neighbourhoods to merge. ", "caption_bbox": [59, 265, 360, 369]}, {"image_id": 2, "file_name": "519_02.png", "page": 6, "dpi": 300, "bbox": [390, 607, 693, 833], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The signpost directs the user to off-screen regions which can be reached via the adjacent node. Groups of nodes can be selected interactively in order to create user-defined regions. ", "caption_bbox": [391, 843, 692, 902]}, {"image_id": 3, "file_name": "519_03.png", "page": 6, "dpi": 300, "bbox": [58, 56, 378, 552], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The selection of nodes for the focus is executed in two steps. In the first step (a), the neighbourhoods around the focal nodes (1,2 and 3) are grown. Neighbourhoods may merge during the process (1 and 2, left). The growth always prefers nodes with a higher DOI. The process stops when a predefined number of nodes is reached. In the second step (b) the connectivity of the visible graph is ensured by cre- ating bridges. The smallest disconnected neighbourhood (3, right) is chosen and grown, until a another neighbourhood is reached. The bridge (B) is created along the shortest path. ", "caption_bbox": [59, 563, 360, 713]}, {"image_id": 4, "file_name": "519_04.png", "page": 8, "dpi": 300, "bbox": [58, 56, 378, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: This figure shows the focus surrounded by a num- ber of invisible regions. The distance to all regions needs to be calculated whenever the focus changes. To speed up the process, we only recalculate the distance to near re- gions (R1 , R2 , R3 , R4 ). To calculate the distance to far re- gions (R5 , R6 ) we add the precalculated distance between regions. ", "caption_bbox": [59, 311, 360, 415]}, {"image_id": 5, "file_name": "519_05.png", "page": 9, "dpi": 300, "bbox": [58, 451, 362, 651], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The results of the experiment: lower mean and lower standard deviation in completion time, focus change count and selection count for the visualization with sign- posts. ", "caption_bbox": [59, 661, 360, 720]}], "520": [{"image_id": 0, "file_name": "520_00.png", "page": 3, "dpi": 300, "bbox": [93, 56, 693, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An overview of our algorithm. The numbers between brackets indicate the paper sections which describe the corresponding portion. While the full majorization algorithm for the 16000-node graph (ncvxqp9) shown above took around forty minutes, the approximate layout we show below took about four minutes and a half. The two results are visually very close. ", "caption_bbox": [58, 314, 693, 357]}, {"image_id": 1, "file_name": "520_01.png", "page": 4, "dpi": 300, "bbox": [58, 56, 637, 428], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Comparing the speed of decay of singular values of the Laplacian L\u03c9 , and that of the off diagonal matrix O\u03c9 , for the 100 smallest symmetric matrices from the University of Florida Sparse Matrix Collection [DH11]. The largest matrix in this experiment has about 4875 elements. The first row assumes a unit edge weight, while the second row takes the absolute value of the matrix entries as the edge length. Colors encode the size of the matrices \u2013 blue for small matrices and orange for larger matrices. Each dot shows the position of the 100th singular value, and the approximation error that would be incurred if that matrix was approximated by a rank-100 matrix. Note that the singular values for O\u03c9 decay much faster; in addition, the larger the matrix, the faster the decay in general, and the better the top 100 singular values cover the whole spectrum. ", "caption_bbox": [57, 447, 691, 553]}, {"image_id": 2, "file_name": "520_02.png", "page": 5, "dpi": 300, "bbox": [58, 57, 378, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Algorithm to compute L\u0303\u03c9 , the approximation to L\u03c9 . In the final line, we do not explicitly carry out matrix operations. The matrix L\u0303\u03c9 is returned as an abstract linear operator. ", "caption_bbox": [58, 227, 359, 287]}, {"image_id": 3, "file_name": "520_03.png", "page": 6, "dpi": 300, "bbox": [58, 222, 344, 363], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Our algorithm for determining graph layouts using approximate stress majorization. ", "caption_bbox": [58, 374, 359, 402]}, {"image_id": 4, "file_name": "520_04.png", "page": 6, "dpi": 300, "bbox": [375, 57, 657, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Running times for neato, sfdp and our algorithm (\u201cMARS\u201d) on complete binary trees of the specified size. Graphs larger than shown are not practical for full stress majorization: at |V| = 216 , simply storing Lw in its entirety would take 16GB of memory. \u201cMARS-50\u201d, \u201cMARS-25\u201d and ", "caption_bbox": [389, 295, 693, 369]}, {"image_id": 5, "file_name": "520_05.png", "page": 7, "dpi": 300, "bbox": [89, 56, 693, 368], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A visual analysis of the approximation errors in our algorithm, computing different layouts of a complete binary tree of 2047 nodes. The top row shows the algorithm when using an exact SVD. The bottom row shows the column-sampling scheme approximate SVD we describe in the text. From left to right, we use 10, 20, 40 and 80 anchors, respectively. ", "caption_bbox": [58, 371, 691, 414]}, {"image_id": 6, "file_name": "520_06.png", "page": 8, "dpi": 300, "bbox": [58, 56, 662, 602], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The resulting layouts of MARS, compared to those of HDE, PivotMDS and sfdp. In all our examples, we set k = 100. HDE and PivotMDS run in negligible time for these examples. Going from top to bottom, sfdp takes 1.4, 323, 194, and 865 seconds. MARS takes 3.9, 588, 1915 and 1478 seconds. ", "caption_bbox": [57, 607, 693, 650]}, {"image_id": 7, "file_name": "520_07.png", "page": 9, "dpi": 300, "bbox": [57, 57, 378, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Some more layouts of MARS. Top left, lux- embourg_osm (|V | = 114599, 543s); top right, fi- nance256 (|V | = 37376, 151.9s); bottom left, ncvxbqp1 (largest connected component: |V | = 40000, 203s); bottom right, ncvxqp9 (|V | = 16554, 66.7s). k = 100. ", "caption_bbox": [57, 356, 361, 430]}], "521": [{"image_id": 0, "file_name": "521_00.png", "page": 3, "dpi": 300, "bbox": [375, 56, 693, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) MS complex for a simple height function. (b) Canceling a pair of critical points, qi , pi+1 , of index i, i + 1 that are connected by a single arc. (c) Combinatorial realization: connect all index i critical points (N pi i+1 ) that are connected to pi+1 except qi , to index i + 1 critical points (Nqi+1     i        ) that are connected to qi except pi+1 . (d) Geometric realization: compute the union of the descending manifold of pi+1 with the descending manifolds of all index i + 1 critical points connected to qi . Compute the union of the ascending manifold of qi with the ascending manifolds of all index i critical points connected to pi+1 . ", "caption_bbox": [391, 359, 692, 526]}, {"image_id": 1, "file_name": "521_01.png", "page": 5, "dpi": 300, "bbox": [375, 56, 694, 171], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (left) The \u03b5-lower-star and the lower link of a ver- tex with the height function defined. (center) Algorithm 1 declares the green edge and the red triangle as critical be- cause the edge is not the highest facet of any of its cofacets. (right) Algorithm 2 pairs these cells because the edge is the second highest facet of the unpaired triangle. ", "caption_bbox": [391, 179, 692, 272]}, {"image_id": 2, "file_name": "521_02.png", "page": 6, "dpi": 300, "bbox": [375, 57, 664, 162], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) \u03b1 is the second highest facet of \u03b2 and \u03b3 is the second highest facet of \u03b1. Respective maximal facets are shown (\u03b10 , \u03b30 ). Solid lines represent maximal facet relation. Dotted lines represent incidence relation. (b) The regularity of K implies the existence of faces \u03b100 and \u03b300 . ", "caption_bbox": [391, 173, 692, 252]}, {"image_id": 3, "file_name": "521_03.png", "page": 6, "dpi": 300, "bbox": [435, 266, 649, 367], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (left) The (1,2) sub-structure of a possible gradi- ent field between a the red 2-saddle and the green 1-saddle. (right) The gradient field interpreted as a directed acyclic graph. The nodes are 2-saddles, (1,2) pairs and 1-saddles. Dashed curves show directed edges from 2-saddles or from the 2-cells of (1,2) gradient pairs to incident 1-cells of dis- tinct (1,2) pairs or to 1-saddles. The gradient paths from the 2-saddle split and merge twice before they reach the 1-saddle resulting in four possible paths between them. Repetition of this configuration causes an exponential growth in the num- ber of paths connecting the 2-saddle to the 1-saddle. ", "caption_bbox": [391, 379, 692, 544]}, {"image_id": 4, "file_name": "521_04.png", "page": 9, "dpi": 300, "bbox": [58, 57, 378, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Timings for datasets available from volvis.org com- pared with timings to compute the MS complex as reported in (a) [GRWH11] and (b) [GBPH08] . ", "caption_bbox": [58, 584, 359, 628]}], "522": [{"image_id": 0, "file_name": "522_00.png", "page": 2, "dpi": 300, "bbox": [58, 56, 693, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Comparison of traditional topology (left) and flux topology (right). Dipoles are represented as a two-colored rectan- gles with a red north pole and a blue south pole. With flux topology, magnetic rings 1 or chains 2 are easier to identify. ", "caption_bbox": [59, 252, 692, 280]}, {"image_id": 1, "file_name": "522_01.png", "page": 4, "dpi": 300, "bbox": [58, 56, 378, 137], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Centers (left) are converted to sources or sinks (depending on their orientation) under the action of P, since every vector is rotated by \u2212 \u03c02 . Saddles (right) are rotated by \u2212 \u03c04 under the action of P. ", "caption_bbox": [58, 148, 359, 207]}, {"image_id": 2, "file_name": "522_02.png", "page": 4, "dpi": 300, "bbox": [375, 57, 654, 185], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: In such a configuration, there is no magnetic field line that connects the two dipoles. All magnetic field lines are separated by the separatrices (green). ", "caption_bbox": [391, 207, 692, 250]}, {"image_id": 3, "file_name": "522_03.png", "page": 5, "dpi": 300, "bbox": [78, 56, 693, 180], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Left: two dipoles are oriented in the same direction, which results in magnetic flux between both dipoles heading from left to right. Middle: the two centers of a dipole, which are infinitly close together, are shifted apart for illustration purposes only. Right: the two centers of a dipole within B are replaced by a source and a sink in the corresponding \u2207A field according to the dual topology rules. ", "caption_bbox": [59, 191, 692, 250]}, {"image_id": 4, "file_name": "522_04.png", "page": 5, "dpi": 300, "bbox": [88, 767, 332, 882], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Dipoles are oriented into the same direction. We call the region delineated by the separatrices (green) a dipole flux connection region. ", "caption_bbox": [59, 893, 360, 936]}, {"image_id": 5, "file_name": "522_05.png", "page": 5, "dpi": 300, "bbox": [398, 647, 694, 865], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: a) A Morse-Smale cell (green) can be found in the \u2207A field between connected dipoles. b) Returning to the B field, a respective connection region (yellow) is found be- tween the two dipoles. ", "caption_bbox": [391, 878, 692, 937]}, {"image_id": 6, "file_name": "522_06.png", "page": 6, "dpi": 300, "bbox": [58, 56, 378, 211], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Boundary flux indicators at the bottom visualize flux affecting dipoles from the outside. Two boundary switch points and a separatrix of B form border segments #1 and #2, which in turn give rise to semi-connectrices a and b . The \u201cvirtual\u201d separatrix 1 is started at the left boundary switch point and closes the connection region represented by connectrix 2 . ", "caption_bbox": [59, 222, 360, 326]}, {"image_id": 7, "file_name": "522_07.png", "page": 7, "dpi": 300, "bbox": [375, 56, 693, 211], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Constructing a connectrix: field line tracing is performed along \u2207A into the same direction as the halfway vector h at 1 until aavg is found in A at 2 . Tracing for- wards and backwards in B constructs the connectrix for this connection region. ", "caption_bbox": [391, 221, 692, 295]}, {"image_id": 8, "file_name": "522_08.png", "page": 7, "dpi": 300, "bbox": [73, 57, 378, 211], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Identifying connection regions: start with neigh- boring separatrices 1a and 1b of the left dipole along with saddles at 2a and 2b . To identify the second dipole, follow a field line fB in B starting at the left dipole. ", "caption_bbox": [58, 221, 359, 280]}, {"image_id": 9, "file_name": "522_09.png", "page": 8, "dpi": 300, "bbox": [375, 57, 694, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Monolayer data set. Ring and chain structures can be readily identified in our flux topology visualization. Computing the flux topology takes 14.74 seconds. ", "caption_bbox": [391, 395, 692, 438]}, {"image_id": 10, "file_name": "522_10.png", "page": 9, "dpi": 300, "bbox": [390, 572, 694, 876], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: This view corresponds to the black rectangle in the lower right image of Fig. 11. Flux is scaled down by one order of magnitude to reduce visual clutter. ", "caption_bbox": [391, 886, 692, 929]}, {"image_id": 11, "file_name": "522_11.png", "page": 9, "dpi": 300, "bbox": [59, 56, 693, 494], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: From left to right: time steps 1, 500, and 900 of a ferrogel simulation. Upper row: whole data set; lower row: zoomed-in views of the regions denoted by black rectangles. For all images, the same scaling for the flux magnitude was used. Non-magnetic particles are shown as black dots. Computing the flux topology takes 256, 270, and 264 seconds, respectively. ", "caption_bbox": [59, 504, 692, 547]}], "523": [{"image_id": 0, "file_name": "523_00.png", "page": 2, "dpi": 300, "bbox": [58, 56, 674, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Oceanic currents of the North Atlantic. We show a 600 \u00d7 600 tile from the larger simulation (center). Each image on the side is a zoomed view visualizing the topology for the tile. (Left) Black lines are separatrices grown from all saddles (blue balls), and green curves show detected closed orbits. (Right) Different colored regions are unstable manifolds grown from all the sources (green balls). ", "caption_bbox": [58, 239, 691, 279]}, {"image_id": 1, "file_name": "523_01.png", "page": 3, "dpi": 300, "bbox": [375, 56, 693, 172], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Quantized streamlines using \u03be+ indicated by the solid and \u03be\u2212 by the dashed arrows. \u03be+ and determine the quantized source\u2013destination pairs. (a) The red streamline (using \u03be+ ) inter- sects the green streamline (using \u03be\u2212 ). (b) Adjusted \u03be\u00b1 pairing picks the rightmost source/destination wrt the tracing direction. The for- ward and backward streamlines share a bin but do not intersect. ", "caption_bbox": [391, 178, 692, 260]}, {"image_id": 2, "file_name": "523_02.png", "page": 4, "dpi": 300, "bbox": [58, 56, 378, 176], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) Edge map of a spiraling source. Transition points (white squares) and their images (black dots) form the colored in- tervals. (b) An interior orbit touching an edge creates an ITP whose boundary flow (c) appears as an ETP. ", "caption_bbox": [58, 183, 359, 235]}, {"image_id": 3, "file_name": "523_03.png", "page": 4, "dpi": 300, "bbox": [375, 57, 677, 158], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The map of a triangle (CCW orientation) is stored as a linked list of intervals. Each interval stores a k-bit value (k = 3 here) for the beginning bin of the interval and a two byte descriptor. ", "caption_bbox": [391, 163, 692, 202]}, {"image_id": 4, "file_name": "523_04.png", "page": 5, "dpi": 300, "bbox": [60, 57, 378, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Map refinement at maximal error (wrt the edge length) of (a) 0.18%; and (b) 0.023%. The initial refinement causes a large change in the unstable region to the west of Florida (top-left of dataset). (c) Total mapping error as a function of average number of links shows well-behaved convergence as more links are used. ", "caption_bbox": [59, 195, 360, 261]}, {"image_id": 5, "file_name": "523_05.png", "page": 6, "dpi": 300, "bbox": [375, 57, 687, 165], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Classifications of forward stable closed orbit shown as grey bins. Forward maps/streamlines are indicated by solid, and backward by dashed arrows. (a) On the right of the closed orbit streamlines can only converge leading to attracting behavior. (b) If no forward streamlines approach from the left, the closed orbit is re- pelling from the left. (c) If a single forward streamline merges with the closed orbit it is attracting; all backward lines only touch it. ", "caption_bbox": [391, 172, 692, 265]}, {"image_id": 6, "file_name": "523_06.png", "page": 7, "dpi": 300, "bbox": [375, 56, 693, 163], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The classification of closed orbits. Flow is mostly domi- nated by both-side attracting (red) and both-side repelling (green) closed orbits. Blue closed orbits are neutral on both sides and hence are both forward and backward-stable. Other closed orbit types ex- ist but are too small to be seen. ", "caption_bbox": [391, 167, 692, 233]}, {"image_id": 7, "file_name": "523_07.png", "page": 7, "dpi": 300, "bbox": [71, 57, 378, 189], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Exact closed orbit detection. The bin level connectivity (a) defines the initial link graph (b). Extracting MSCCs removes the faded links, and the bin level pruning removes the circled bins. ", "caption_bbox": [58, 196, 359, 235]}, {"image_id": 8, "file_name": "523_08.png", "page": 8, "dpi": 300, "bbox": [402, 252, 680, 405], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: (a) Stable and unstable manifolds for an ocean wind dataset, where a separatrix converges to a closed orbit. (b) Separa- trices and closed orbits on the nearly divergence free dataset. ", "caption_bbox": [391, 413, 692, 452]}, {"image_id": 9, "file_name": "523_09.png", "page": 8, "dpi": 300, "bbox": [58, 56, 675, 196], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparison of closed orbit detection with Morse sets (left, Chen et al. [CDS\u2217 12]) and refined PC Morse sets (middle, Szymczak and Zhang [SZ12]). Both Morse techniques compute cyclic regions in the blue boxed region, but our approach (right) identifies none, as the bottom left inset indicates a streamline spans the region. ", "caption_bbox": [58, 199, 691, 240]}, {"image_id": 10, "file_name": "523_10.png", "page": 8, "dpi": 300, "bbox": [63, 252, 354, 347], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Graph-splitting progressively convergence to closed or- bits. Left-to-right: a gradual reduction in the size of regions. ", "caption_bbox": [59, 352, 360, 377]}], "524": [{"image_id": 0, "file_name": "524_00.png", "page": 2, "dpi": 300, "bbox": [58, 56, 688, 429], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: High-resolution screenshot of the World\u2019s Languages Explorer showing the main components. The example shows for 27 Indo-European languages 19 language features that were automatically extracted from parallel Bible texts. ", "caption_bbox": [59, 439, 692, 467]}, {"image_id": 1, "file_name": "524_01.png", "page": 7, "dpi": 300, "bbox": [393, 397, 695, 636], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Detailed look into two quantitative features for the Germanic languages. ", "caption_bbox": [391, 644, 692, 672]}, {"image_id": 2, "file_name": "524_02.png", "page": 7, "dpi": 300, "bbox": [61, 56, 696, 336], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: User Interaction with the Sunburst and feature rings", "caption_bbox": [218, 346, 533, 359]}, {"image_id": 3, "file_name": "524_03.png", "page": 9, "dpi": 300, "bbox": [61, 56, 693, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: High-resolution screenshot showing automatically extracted features for languages from Papua New Guinea.", "caption_bbox": [76, 438, 673, 451]}], "525": [{"image_id": 0, "file_name": "525_00.png", "page": 1, "dpi": 300, "bbox": [58, 530, 693, 735], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Vienna metro map. (a) Geographical layout. (b) Conventional MIP layout. (c) Customized layout using our approach.", "caption_bbox": [58, 509, 691, 522]}, {"image_id": 1, "file_name": "525_01.png", "page": 2, "dpi": 300, "bbox": [58, 56, 378, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A route-aware map of Tsukuba Express (courtesy of Metropolitan Intercity Railway Company, Japan). ", "caption_bbox": [58, 261, 359, 289]}, {"image_id": 2, "file_name": "525_02.png", "page": 3, "dpi": 300, "bbox": [442, 80, 638, 178], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Aligning metro lines with octilinear directions. (a) Octilinear directions emanating from the node u, and (b) the corresponding fan-shaped sectors with respect to u. ", "caption_bbox": [391, 185, 692, 229]}, {"image_id": 3, "file_name": "525_03.png", "page": 4, "dpi": 300, "bbox": [59, 89, 691, 196], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An example scenario for designing a travel-route-centered map layout. (a) Selecting a specific route. (b) Rotating the entire map by referring to the route. (c) Route-centered octilinear layout. (d) Rotating the entire metro map again. (e) Rearranging a local set of edge orientations. ", "caption_bbox": [58, 211, 691, 255]}, {"image_id": 4, "file_name": "525_04.png", "page": 4, "dpi": 300, "bbox": [86, 291, 330, 374], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Adjusting edge orientations. (a) Original layout of four stations and (b) its updated layout after the changes in edge orientation are propagated. ", "caption_bbox": [58, 382, 359, 426]}, {"image_id": 5, "file_name": "525_05.png", "page": 6, "dpi": 300, "bbox": [65, 318, 684, 454], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Effect of edge weights on leader shapes: (a) Only with square root of the difference along the horizontal axis as the edge weight. (b) Penalty weights are assigned to unwanted intersections between leaders and metro lines. (c) A pair of leaders having mutual intersection is swapped. (d) Endpoint-interpolating B-splines are employed for smoothing the leader shapes. ", "caption_bbox": [58, 462, 691, 506]}, {"image_id": 6, "file_name": "525_06.png", "page": 6, "dpi": 300, "bbox": [58, 56, 694, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Designing leader shapes using flow networks. (a) Network construction in the map domain. (b) Topologically rear- ranged structure of the network. (c) Each intermediate node consists of two virtual nodes and an implicit edge with weight 1.0 in between. (d) Final flow paths for laying out leaders between stations and external labels. ", "caption_bbox": [58, 267, 691, 311]}, {"image_id": 7, "file_name": "525_07.png", "page": 8, "dpi": 300, "bbox": [68, 483, 674, 732], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Interactive design of the Vienna metro map. (a) Original layout. (b) Improved layout through interactive design.", "caption_bbox": [66, 740, 683, 753]}, {"image_id": 8, "file_name": "525_08.png", "page": 8, "dpi": 300, "bbox": [98, 281, 674, 455], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Munich metro map. (a) Geographical layout. (b) Conventional MIP layout. (c) Customized layout using our approach.", "caption_bbox": [58, 463, 691, 476]}, {"image_id": 9, "file_name": "525_09.png", "page": 8, "dpi": 300, "bbox": [58, 56, 682, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Taipei metro map. (a) Geographical layout. (b) Conventional MIP layout. (c) Customized layout using our approach.", "caption_bbox": [58, 261, 691, 274]}, {"image_id": 10, "file_name": "525_10.png", "page": 9, "dpi": 300, "bbox": [96, 437, 309, 537], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Failure cases. (a) The MIP problem with con- straints on the route cannot be solved. (b) The route cannot be fully extended to be straight on the map. ", "caption_bbox": [58, 544, 359, 588]}, {"image_id": 11, "file_name": "525_11.png", "page": 9, "dpi": 300, "bbox": [59, 258, 366, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Eye-gaze distribution for maps with different leader types. (a) Straight leaders. (b) Orthogonal leaders. (c) Curved leaders (q = 50 in Eq. (1)). ", "caption_bbox": [58, 374, 359, 418]}, {"image_id": 12, "file_name": "525_12.png", "page": 9, "dpi": 300, "bbox": [59, 79, 366, 181], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Eye-gaze distribution for different metro map layouts. (a) Geographical layout. (b) Conventional MIP lay- out. (c) Customized layout using our approach. ", "caption_bbox": [58, 195, 359, 239]}], "526": [{"image_id": 0, "file_name": "526_00.png", "page": 3, "dpi": 300, "bbox": [393, 128, 681, 227], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Pipeline showing the overall flow of activities and iterative process from interactive visualization via parame- ter settings to automatic algorithm of encounter detection. ", "caption_bbox": [391, 239, 692, 282]}, {"image_id": 1, "file_name": "526_01.png", "page": 4, "dpi": 300, "bbox": [390, 720, 685, 839], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Interpolation example in 1D. (a) The original in- stances. (b) An interpolated instance is added in the middle. (c) Two more interpolated instances are added, and there is no need in more interpolation steps. ", "caption_bbox": [391, 849, 692, 908]}, {"image_id": 2, "file_name": "526_02.png", "page": 4, "dpi": 300, "bbox": [58, 56, 378, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Examples for higher level encounter patterns emerging from single encounters, showing trajectories as discrete instances and their direction of move. Encounters are represented by connecting lines between instances of movement. ", "caption_bbox": [59, 327, 360, 401]}, {"image_id": 3, "file_name": "526_03.png", "page": 7, "dpi": 300, "bbox": [58, 56, 693, 621], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Trajectories of public transportation routes in Helsinki, showing one day of traffic data. The labeled locations refer to the discussed encounter patterns found during exploration. Color of the trajectories is mapped to route direction. ", "caption_bbox": [59, 631, 692, 659]}, {"image_id": 4, "file_name": "526_04.png", "page": 8, "dpi": 300, "bbox": [58, 56, 688, 525], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Examples of encounter patterns found during exploration: (A) junction, (B) head-front , (C) parallel driving, (D) following, (E) high density area, (F) high- vs. low-density area, and (G) interleaving encounter pattern. Color on trajectories is mapped to their direction, and on encounters to the hour of the day of their ocurance. ", "caption_bbox": [59, 537, 692, 580]}, {"image_id": 5, "file_name": "526_05.png", "page": 9, "dpi": 300, "bbox": [61, 56, 693, 269], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Computation time as a function of (a) the spatial window size, (b) the temporal window size and (c) the data size.", "caption_bbox": [66, 283, 684, 296]}], "527": [{"image_id": 0, "file_name": "527_00.png", "page": 2, "dpi": 300, "bbox": [375, 57, 692, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Illustration using clipping to reveal the macro- molecular structures inside a Mycoplasma mycoides cell, by David S. Goodsell [goo12], the Scripps Research Institute. ", "caption_bbox": [391, 319, 692, 363]}, {"image_id": 1, "file_name": "527_01.png", "page": 3, "dpi": 300, "bbox": [95, 56, 693, 483], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Elementary building blocks of the illustrative clipping pipeline and the two use-case scenarios. Data samples from a specific level are mapped to forces using a potential field transfer function. The forces constitutes a potential field, which interact with a flexible membrane. The deformed membrane is then applied in volume visualization. ", "caption_bbox": [59, 494, 692, 538]}, {"image_id": 2, "file_name": "527_02.png", "page": 4, "dpi": 300, "bbox": [58, 56, 624, 316], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Rendering of a medical CT dataset. Compared to the regular slice view (3a), adding local DVR provides interesting structures out of the plane (3b). Figure 3c shows a tilted view of the same plane and the grid in Figrue 3d shows the deformed membrane. ", "caption_bbox": [59, 330, 692, 374]}, {"image_id": 3, "file_name": "527_03.png", "page": 5, "dpi": 300, "bbox": [90, 56, 693, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Two different methods for repositioning the membrane: Passive repositioning creates a new membrane at the position of the rigid frame. Active repositioning moves the frame and pulls the membrane through the potential field. We provide a means for interacting locally with the potential field by creating a force kernel with a desired radius to encapsulate interesting structures. In addition, the user can pin the membrane at the current position to prevent the membrane from moving through interesting features. ", "caption_bbox": [59, 264, 692, 338]}, {"image_id": 4, "file_name": "527_04.png", "page": 6, "dpi": 300, "bbox": [58, 56, 661, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Traditional explorative tools compared to illustrative clipping applied to a synthetic dataset.", "caption_bbox": [122, 309, 628, 322]}, {"image_id": 5, "file_name": "527_05.png", "page": 7, "dpi": 300, "bbox": [81, 763, 339, 860], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The hippocampus in a mouse brain imaged using ultramicroscopy [DLS\u2217 07]. Moving the slice plane through, the membrane is held back by the nerve cells (red), preserv- ing it in the final image. ", "caption_bbox": [58, 872, 359, 931]}, {"image_id": 6, "file_name": "527_06.png", "page": 7, "dpi": 300, "bbox": [65, 56, 693, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A mouse imaged using ultramicroscopy [DLS\u2217 07]. Adjusting the transparency according to the distance to the original slice. The figures show the effect of adjusting the relative maximum distance for contributing to the image. ", "caption_bbox": [58, 230, 691, 262]}, {"image_id": 7, "file_name": "527_07.png", "page": 8, "dpi": 300, "bbox": [67, 258, 352, 429], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Certain structures are completely lost using basic slice viewing of 3D ultrasound (9a). Using the illustrative slicing technique, elongated structures such as the blood ves- sels are kept in the image (9b). ", "caption_bbox": [59, 444, 360, 503]}, {"image_id": 8, "file_name": "527_08.png", "page": 8, "dpi": 300, "bbox": [58, 56, 694, 189], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Revealing the structure of a seismic horizon in seismic amplitude data. Flat clipping compared to illustrative clipping.", "caption_bbox": [59, 201, 692, 214]}, {"image_id": 9, "file_name": "527_09.png", "page": 9, "dpi": 300, "bbox": [390, 289, 694, 405], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Using a higher traversal depth in 10a for the data hierarchy results in a less close fit compared to 10b. ", "caption_bbox": [391, 420, 692, 448]}], "528": [{"image_id": 0, "file_name": "528_00.png", "page": 3, "dpi": 300, "bbox": [58, 56, 694, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview of our method. All steps are performed on a 2.5D screen space representation of the surface.", "caption_bbox": [94, 251, 656, 264]}, {"image_id": 1, "file_name": "528_01.png", "page": 4, "dpi": 300, "bbox": [58, 56, 378, 232], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The illustration buffer. (a) A cross section of a sur- face with three layers. (b) The corresponding buffer layout. ", "caption_bbox": [59, 244, 360, 272]}, {"image_id": 2, "file_name": "528_02.png", "page": 5, "dpi": 300, "bbox": [58, 57, 377, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Simplex noise for x \u2208 [\u22121, 1]2 . (a) Noise for s = 5. (b) Noise for s = 10. (c) The average of the two above images. (d) The average with applied contrast correction. ", "caption_bbox": [59, 315, 360, 362]}, {"image_id": 3, "file_name": "528_03.png", "page": 6, "dpi": 300, "bbox": [58, 56, 378, 134], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Discretizations of the gradient. (a) Full 3x3 sten- cil. (b) Forward and backward differences. (c) Central dif- ferences. ", "caption_bbox": [59, 145, 360, 189]}, {"image_id": 4, "file_name": "528_04.png", "page": 6, "dpi": 300, "bbox": [375, 57, 694, 182], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Boundary conditions. (a) Estimating the boundary normal. (b) 2000 diffusion iterations with a complex surface boundary. (c) Checkerboard pattern near boundaries. ", "caption_bbox": [391, 193, 692, 237]}, {"image_id": 5, "file_name": "528_05.png", "page": 6, "dpi": 300, "bbox": [390, 254, 694, 307], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Number of iterations on a 512 \u00d7 256 pixel image. (a) 20 iterations. (b) 100 iterations. (c) 1000 iterations. ", "caption_bbox": [391, 318, 692, 347]}, {"image_id": 6, "file_name": "528_06.png", "page": 8, "dpi": 300, "bbox": [390, 380, 694, 557], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: LCS based visualization of the simulation of a re- volving door with air curtain using cutaways. The air curtain is modeled by an air outlet, as shown in green. On both sides of the air curtain, air intakes are placed to compensate for air blown in by the air outlet. ", "caption_bbox": [391, 569, 692, 643]}, {"image_id": 7, "file_name": "528_07.png", "page": 8, "dpi": 300, "bbox": [375, 57, 656, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Two-layered dense visualization of the atmosphere of a tidally-locked exoplanet. The streaks are colored using the temperature. 800\u00d7600 pixels, 500 iterations. ", "caption_bbox": [391, 321, 692, 365]}, {"image_id": 8, "file_name": "528_08.png", "page": 9, "dpi": 300, "bbox": [59, 57, 377, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: LCS based visualization of the simulation of a revolving door with an air curtain using our method. Even without cutaways, the general structure of the LCS is much more easily understood. 800\u00d7600 pixels, 250 iterations. ", "caption_bbox": [59, 289, 360, 348]}, {"image_id": 9, "file_name": "528_09.png", "page": 9, "dpi": 300, "bbox": [375, 56, 694, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Visualization of the flow along a stream surface. (a) Base result. (b) Cool-warm shading and silhouette en- hancement. (c) Adaptively reduced noise density. (d) Auto- matic surface coloring. 1024\u00d71024 pixels, 1200 iterations. ", "caption_bbox": [391, 371, 692, 430]}], "529": [{"image_id": 0, "file_name": "529_00.png", "page": 1, "dpi": 300, "bbox": [58, 586, 693, 842], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Exemplary result of the visualization system that enables the seamless transition between abstract graphics (A) and a photorealistic version (B) view-dependently. The sequence below shows single frames of this transition. ", "caption_bbox": [58, 541, 691, 569]}, {"image_id": 1, "file_name": "529_01.png", "page": 2, "dpi": 300, "bbox": [58, 56, 690, 432], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of the present system\u2019s approach of LoA transitions for virtual 3D city models. (A) Feature classification using semantic information, (B/C) blend value computation based on saliency metrics (multipass), (D) global transformation of landmarks, (E) cartographic shading (multipass), (F) order-independent image blending and compositing. The transition configurations are used by components B-F. ", "caption_bbox": [58, 438, 691, 497]}, {"image_id": 2, "file_name": "529_02.png", "page": 4, "dpi": 300, "bbox": [375, 57, 692, 176], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Continuous LoA for textured green spaces: near distance (A), mid-range distance (B), far distance (C). ", "caption_bbox": [390, 183, 691, 211]}, {"image_id": 3, "file_name": "529_03.png", "page": 4, "dpi": 300, "bbox": [58, 56, 378, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Geospatial data processed by the system: multires- olution models (A), semantic information (B), landmarks with interest values wi and best-views (C), stylized textures (D). ", "caption_bbox": [58, 258, 361, 301]}, {"image_id": 4, "file_name": "529_04.png", "page": 5, "dpi": 300, "bbox": [61, 56, 693, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Exemplary saliency metrics defined by the system: view distance (A), view angle (B) and region interest (C). The debug outputs show areas of a 3D scene to be visualized with high detail (black) and low detail (white), respectively. ", "caption_bbox": [58, 345, 691, 373]}, {"image_id": 5, "file_name": "529_05.png", "page": 5, "dpi": 300, "bbox": [390, 388, 693, 547], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Examplary transition states for tree models.", "caption_bbox": [404, 553, 676, 566]}, {"image_id": 6, "file_name": "529_06.png", "page": 6, "dpi": 300, "bbox": [58, 56, 645, 185], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Transformation of landmarks: scaling (A), rotation to best-view (B), flattening (C), billboard transformation (D).", "caption_bbox": [67, 192, 683, 205]}, {"image_id": 7, "file_name": "529_07.png", "page": 7, "dpi": 300, "bbox": [58, 56, 693, 163], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Stylization techniques for water surfaces (A), green spaces (B), tree models (C) and digital terrain models (D).", "caption_bbox": [72, 170, 677, 183]}, {"image_id": 8, "file_name": "529_08.png", "page": 8, "dpi": 300, "bbox": [58, 56, 691, 269], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Performance evaluation measured in frames-per- second for three virtual environments and screen resolutions. The evaluation was performed on two platforms (Section 4). ", "caption_bbox": [57, 826, 361, 869]}, {"image_id": 9, "file_name": "529_09.png", "page": 9, "dpi": 300, "bbox": [57, 56, 693, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Examples showing a circular RoI and a highlighted route within the city of Chemnitz, compared to a detailed version. The bottom row shows the respective saliency maps using the algorithm of graph-based visual saliency [HKP07]. ", "caption_bbox": [57, 377, 693, 405]}], "530": [{"image_id": 0, "file_name": "530_00.png", "page": 1, "dpi": 300, "bbox": [59, 291, 694, 432], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Kelp Diagrams applied to a metabolic network (left) and cities on a map (right).", "caption_bbox": [148, 442, 602, 455]}, {"image_id": 1, "file_name": "530_01.png", "page": 2, "dpi": 300, "bbox": [58, 56, 378, 174], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The three phases of generating Kelp Diagrams.", "caption_bbox": [64, 186, 353, 199]}, {"image_id": 2, "file_name": "530_02.png", "page": 3, "dpi": 300, "bbox": [375, 56, 693, 151], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The added benefit of linking: (a) Elements are as- sociated solely by the colored shapes that contain them; (b) Elements are associated both by color and a common shape; (c) Spatial patterns are emphasized. ", "caption_bbox": [391, 159, 692, 218]}, {"image_id": 3, "file_name": "530_03.png", "page": 3, "dpi": 300, "bbox": [421, 772, 663, 834], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The distorting effect of shapes on element depic- tion: (a) An element contained in a shape attracts more at- tention; (b) The expected position of the element lies at the center of the circle, which conflicts with its actual position; (c) Both sets of elements have the same number of elements, but the difference in size of the shapes suggests otherwise. ", "caption_bbox": [391, 843, 692, 932]}, {"image_id": 4, "file_name": "530_04.png", "page": 4, "dpi": 300, "bbox": [375, 57, 691, 189], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Allocation of space for three elements: (a) Over- lapping circles, centered over elements; (b) The Voronoi faces of the elements\u2019 positions; (c) Intersection of circles and Voronoi faces. ", "caption_bbox": [391, 198, 692, 257]}, {"image_id": 5, "file_name": "530_05.png", "page": 4, "dpi": 300, "bbox": [393, 733, 690, 841], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Area division between elements: (a) Our method allocates an unequal share of space; (b) Possible outcome of a force-based relocation of the circles; (c) Instance where allocation of equal space for element e is not possible with- out a more complex shape. ", "caption_bbox": [391, 849, 692, 923]}, {"image_id": 6, "file_name": "530_06.png", "page": 5, "dpi": 300, "bbox": [375, 56, 696, 181], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Benefit of placing a link between p, q \u2208 S, S \u2208 S is dependent on already placed links: (a) The benefit of placing la is low because already placed l1 has low cost; (b) The benefit of placing lb is high because already placed chain of links l1 , l2 , ..., lr has high cost. ", "caption_bbox": [391, 189, 692, 266]}, {"image_id": 7, "file_name": "530_07.png", "page": 5, "dpi": 300, "bbox": [60, 805, 363, 880], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Examples of the additional edges in ET (in red): (a) Tangent edges between A(p) and A(q), p, q \u2208 E; (b) Edges from p to q and A(q); (c) Edges from v \u2208 VI . ", "caption_bbox": [58, 888, 359, 933]}, {"image_id": 8, "file_name": "530_08.png", "page": 5, "dpi": 300, "bbox": [60, 482, 364, 561], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Two possible paths of a link l between p, q \u2208 E (in red): (a) l with unnecessarily high cost; (b) l with identical topology but minimized cost. ", "caption_bbox": [58, 569, 359, 613]}, {"image_id": 9, "file_name": "530_09.png", "page": 6, "dpi": 300, "bbox": [390, 562, 699, 893], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Kelp Diagram of eleven elements and three sets. Top: Nested style. Bottom: Striped style. ", "caption_bbox": [391, 904, 692, 932]}, {"image_id": 10, "file_name": "530_10.png", "page": 6, "dpi": 300, "bbox": [58, 56, 378, 170], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Link radius: (a) Increase of element space allo- cation by rl ; (b) Link with allocated space of radius rl and its contours c1 and c2 ; (c) Two links routed beside each other. ", "caption_bbox": [58, 179, 359, 224]}, {"image_id": 11, "file_name": "530_11.png", "page": 7, "dpi": 300, "bbox": [60, 56, 693, 500], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Kelp applied to the capital cities of the European Union, where the eurozone is blue, the EU founding members (European Coal and Steel Community) are pink, and members with good, average, and bad credit rating are green, orange, and red respectively (Standard & Poor\u2019s, October 2011). The diagrams have various configurations: (a) Nested style without links; (b) Nested style with links; (c) Striped style; (d) Nested style with large element radius re and small link radius rl ; (e) Nested style with large intersection penalty cI ; (f) Nested style with low link addition threshold bt . ", "caption_bbox": [58, 509, 691, 584]}, {"image_id": 12, "file_name": "530_12.png", "page": 8, "dpi": 300, "bbox": [58, 56, 692, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Restaurants of three categories in Seattle: (a) Bubble Sets approach, generated with a public software library [KC]; (b) LineSets approach, image taken from [ARRC11]; (c) Nested Kelp Diagram. ", "caption_bbox": [58, 316, 691, 344]}, {"image_id": 13, "file_name": "530_13.png", "page": 9, "dpi": 300, "bbox": [60, 56, 693, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Disjoint sets of locations in Manhattan, with hotels (orange), subway stations (brown), and medical clinics (purple): (a) Bubble Sets, image taken from [CPC09]; (b) LineSets, image courtesy B. Alper and N. Riche; (c) Nested Kelp Diagram. ", "caption_bbox": [58, 358, 691, 386]}], "531": [{"image_id": 0, "file_name": "531_00.png", "page": 3, "dpi": 300, "bbox": [58, 57, 378, 372], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Evolution of density map and corresponding bundling for the US migrations graph. ", "caption_bbox": [59, 386, 360, 414]}, {"image_id": 1, "file_name": "531_01.png", "page": 3, "dpi": 300, "bbox": [375, 56, 711, 174], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Density map (left) and corresponding bundling for non-normalized advection (compare to Fig. 1) ", "caption_bbox": [391, 191, 692, 219]}, {"image_id": 2, "file_name": "531_02.png", "page": 5, "dpi": 300, "bbox": [80, 56, 693, 800], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Bundling examples. Radial graph (a,b); Poker graph (c,d); France airlines (e,f); US migrations, clustered (g,h); US migrations, unclustered (i,j,k,l); Colors mark different edge clusters. More examples at www.cs.rug.nl/svcg/Shapes/KDEEB ", "caption_bbox": [59, 804, 692, 832]}, {"image_id": 3, "file_name": "531_03.png", "page": 6, "dpi": 300, "bbox": [58, 56, 679, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Bundling examples. US airlines (FDEB (a), SBEB (b), MINGLE (c), KDEEB (d)).", "caption_bbox": [143, 348, 605, 361]}, {"image_id": 4, "file_name": "531_04.png", "page": 6, "dpi": 300, "bbox": [104, 372, 644, 723], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Obstacle-constrained bundling without endpoint displacement (a,c) and with endpoint displacement (b,d).", "caption_bbox": [82, 730, 664, 743]}, {"image_id": 5, "file_name": "531_05.png", "page": 7, "dpi": 300, "bbox": [58, 218, 377, 572], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: a) Obstacle-constrained bundling refinement; b) Bundle splitting singularity. The background shows the shape\u2019s distance transform for illustration (Sec. 5.1). ", "caption_bbox": [59, 589, 360, 632]}, {"image_id": 6, "file_name": "531_06.png", "page": 8, "dpi": 300, "bbox": [58, 56, 660, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Bundling quality visualized by shading. Shaded colorful structures indicate dense bundles. Outlier edges are white. Radial graph (a), France airlines (b) ", "caption_bbox": [59, 366, 692, 394]}, {"image_id": 7, "file_name": "531_07.png", "page": 9, "dpi": 300, "bbox": [137, 56, 693, 476], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Graph statistics for datasets used in this paper.", "caption_bbox": [68, 743, 350, 756]}], "532": [{"image_id": 0, "file_name": "532_00.png", "page": 1, "dpi": 300, "bbox": [404, 311, 694, 663], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": " Fig. 11 of [BD05]", "caption_bbox": [406, 666, 488, 678]}, {"image_id": 1, "file_name": "532_01.png", "page": 2, "dpi": 300, "bbox": [58, 56, 378, 200], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A hierarchical partition with uniform leaf values (top) and recursive construction of a Voronoi treemap (a\u2013c). Dots correspond to the sites which generate the cells. ", "caption_bbox": [59, 209, 360, 252]}, {"image_id": 2, "file_name": "532_02.png", "page": 5, "dpi": 300, "bbox": [182, 56, 693, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Example of two weighted power diagrams and conflicts when updating the sites and their weights. Circles represent                            \u221a the weight and have thus w p as radius for a site p \u2208 S. (a) Site s (with red circle) is moved to the centroid of its Voronoi cell, which could cause in combination with other site  \u221a \u2217movements the site v to have an empty cell (dotted blue circle contains v). Conflict is solved by reducing the radius of s to ws (blue circle) if necessary (line 5 of Algorithm 2). (b) Site s is not a neighbor of v in the weighted Voronoi diagram (black lines), but is one in the ordinary Voronoi diagram. Increasing the weight (dotted black circle) of v has thus to be limited by its neighbors in the ordinary Voronoi diagram or by its nearest neighbor (line 14 of Algorithm 2). ", "caption_bbox": [59, 293, 692, 397]}, {"image_id": 3, "file_name": "532_03.png", "page": 6, "dpi": 300, "bbox": [390, 184, 693, 364], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Computation of a power diagram: (a) sites s,t are transformed to the planes \u03a0(s) and \u03a0(t) in 3D. The bisector between s and t is a vertical mapping of the intersection of \u03a0(s) and \u03a0(t) back to the two-dimensional plane h0 . (b) The intersection of the projected half-planes creates a lower convex hull in 3D (gray facets) which is a dual solution to the power diagram. ", "caption_bbox": [391, 371, 692, 475]}, {"image_id": 4, "file_name": "532_04.png", "page": 8, "dpi": 300, "bbox": [58, 56, 555, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Timings for a single iteration (sites vs. time in ms). Blue dots are timings reported in [SFL10] for the GPU-accelerated approach at different resolutions, with quadratic curves fitted to extrapolate to larger instances. Red dots are our timings for our CPU-only approach, taken on a comparable machine. ", "caption_bbox": [59, 364, 692, 407]}, {"image_id": 5, "file_name": "532_05.png", "page": 9, "dpi": 300, "bbox": [375, 56, 693, 296], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Boxplots showing area misrepresentation after each iteration of our adaptation of Lloyd\u2019s method with (red) and without (black) the speedup heuristic. For 100 sample instances, initial sites have been distributed uniformly in a rectangle with aspect ratio 2, and target areas drawn from a power-law distribution with f (x) = x14 . ", "caption_bbox": [391, 313, 692, 402]}, {"image_id": 6, "file_name": "532_06.png", "page": 9, "dpi": 300, "bbox": [139, 57, 378, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The large growing cell of a site t needs to push surrounding sites s away. To reduce the number of iterations, we determine displacements ds depending on the distance from t directly rather than alternating between weights and centroid updates for the same effect. ", "caption_bbox": [59, 233, 360, 307]}], "533": [{"image_id": 0, "file_name": "533_00.png", "page": 2, "dpi": 300, "bbox": [58, 57, 378, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a1-a3): The first iteration of subdivision to con- struct a geodesic grid. (a1) shows the initial icosahedron with 12 vertices, 30 edges, and 20 equal spherical triangles. (a2) shows that each triangle is subdivided through bisec- tion. (a3) shows the new vertices are popped out onto the sphere. (b) shows the duality of Voronoi polygon and Delau- nay triangulation. (c) shows the structure of a 3D spherical geodesic grid. ", "caption_bbox": [59, 332, 360, 452]}, {"image_id": 1, "file_name": "533_01.png", "page": 4, "dpi": 300, "bbox": [58, 57, 378, 372], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a): The cell_corner, corner_edge, corner_cell, and edge_corner tables used to represent a 2D Voronoi polygonal grid of climate simulations. (b): The representa- tion of dual triangular mesh of (a). We note that the names of tables and table entries are modified for an illustration purpose in (b), and they are not changed in the real imple- mentation. Thus, from (a) to (b), the content of the four tables keeps intact, which implies that no explicit grid transforma- tion is required. ", "caption_bbox": [58, 380, 359, 515]}, {"image_id": 2, "file_name": "533_02.png", "page": 4, "dpi": 300, "bbox": [375, 57, 677, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Grid traversal. (a) Side View. The yellow, green, and red frusta are constructed on the fly with marching the ray through the grid. The intersection of the ray and a tem- porary frustum is used to identify the next neighboring tri- angle on the spherical surface. (b) Perspective View. The red dashed curve is the projection of the ray on the spherical surface. The triangles 4i and 4 j are identified based on the surface connectivity information, and are used to construct the corresponding frustum at the different layers. ", "caption_bbox": [391, 260, 692, 395]}, {"image_id": 3, "file_name": "533_03.png", "page": 6, "dpi": 300, "bbox": [58, 57, 378, 189], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Barycentric interpolation of the scalar value within a triangular frustum. We first interpolate the scalar values at the points r1 and r2 on the top and bottom trian- gles, respectively, and then use linear interpolation to com- pute the scalar value at the point s on the line segment r1 r2 . ", "caption_bbox": [59, 190, 360, 264]}, {"image_id": 4, "file_name": "533_04.png", "page": 6, "dpi": 300, "bbox": [69, 283, 351, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The plot of a reconstructed scalar value using our analytic function. (a) The analytic function is shown in blue, and has one local minimum. The cell along a ray is split into two intervals colored in light orange and green. The analytic function is monotonic within each interval, and its piecewise linear approximation is shown in black. (b) A transfer func- tion is shown in red, and introduces an additional local ex- tremum point. The cell is further split into three monotonic intervals accordingly. ", "caption_bbox": [59, 387, 360, 522]}, {"image_id": 5, "file_name": "533_05.png", "page": 7, "dpi": 300, "bbox": [394, 323, 689, 456], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Ray-casting with lighting effects using our ana- lytic ray integration and gradient estimation on the high res- olution data set. The left images shows the vorticity variable and the close-up view of a selected region. The right image shows the combination of grid illustration, volume render- ing of vorticity (yellow tubes) and temperature (north cap). Our approach can succinctly reveal great details from large data with enhanced depth and shape cues. ", "caption_bbox": [391, 468, 692, 588]}, {"image_id": 6, "file_name": "533_06.png", "page": 7, "dpi": 300, "bbox": [375, 57, 693, 219], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Ray-casting of a synthetic spherical scalar field defined on a real geodesic grid with 10242 cells and 61 lay- ers. (a) shows the result using our analytic approach with lighting enabled, and (b) shows the ground truth image. The image difference between (a) and (b) is negligible. ", "caption_bbox": [391, 227, 692, 301]}, {"image_id": 7, "file_name": "533_07.png", "page": 8, "dpi": 300, "bbox": [394, 404, 691, 528], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Performance measures and comparison with the conventional tetrahedron based method and the mean value interpolation method. The performance data is obtained by rendering images of Figure 8 with different sampling rate that is defined as the ratio of sample step size to the globe radius. Our approach outperforms both methods. ", "caption_bbox": [391, 538, 692, 627]}, {"image_id": 8, "file_name": "533_08.png", "page": 8, "dpi": 300, "bbox": [58, 57, 662, 237], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Rendering quality comparison of our approach (left) with the conventional tetrahedron based method (center) and the mean value interpolation method (right) in a close-up views. We render the vorticity variable in the high resolution grid. The ratio of sample step size to the globe radius is set as 10\u22124 to make sure there are enough sampling points within each cell. The boundary artifacts at the high frequency regions are perceivable from the rendering of tetrahedral mesh due to less vertex information for interpolation. Meanwhile, even if the rendering quality of mean value interpolation method is slightly better than the tetrahedron method, certain jaggy effect can still be perceived. This is due to the fact that mean value interpolation has proved to be smooth in the interior of a cell except at the vertices [HF06]. Therefore, in terms of image quality, our approach outperforms both methods. ", "caption_bbox": [58, 248, 691, 368]}, {"image_id": 9, "file_name": "533_09.png", "page": 9, "dpi": 300, "bbox": [87, 57, 693, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The left most two images show the volume rendering of the whole global atmospheric vorticity variable using dif- ferent visualization parameters. The top two rows of images incrementally show the close-up views of a particular region of interest. From left to right, we show the mesh grid, the surface rendering, the volume rendering with different transfer func- tions, and the images with lighting disabled and enabled. The bottom row shows a close-up view from a different geolocation, superimposed with geophysical information. ", "caption_bbox": [59, 349, 692, 423]}], "534": [{"image_id": 0, "file_name": "534_00.png", "page": 1, "dpi": 300, "bbox": [93, 319, 660, 463], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Results from our synthetic Brainbow technique and a true Brainbow image. A: Cells in the eye of a zebrafish embryo. B: Neurons in a Drosophila brain. C: Eye of a Drosophila. D: The cerebral cortex of a mouse (Confocal image by Tamily Weissman. Mouse by Jean Livet and Ryan Draft. Image source: http://www.conncoll.edu/ccacad/zimmer/GFP-ww/cooluses0.html). A, B, C are single-channel confocal scans processed with our synthetic Brainbow technique, in comparison with the true Brainbow image in D. ", "caption_bbox": [59, 476, 692, 551]}, {"image_id": 1, "file_name": "534_01.png", "page": 4, "dpi": 300, "bbox": [58, 57, 378, 243], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Comparison of synchronous and asynchronous updates of a 1D cellular automaton. The illustration shows only the first iteration in detailed steps. In the synchronous case, the original buffer is in red and the extra buffer for intermediate results is in green. Values are updated according to the maxima within the moving window (in blue), indicated by the yellow arrows. In the asynchronous cases, there is no extra buffer, so updates are immediate. The updated values in each step when the window moves are in dark red. We can repeat the iteration for the first two cases until all cells are updated to the maximum ID. Their results look exactly the same. The last case has already converged after the first iteration. ", "caption_bbox": [59, 255, 360, 452]}, {"image_id": 2, "file_name": "534_02.png", "page": 4, "dpi": 300, "bbox": [375, 57, 688, 307], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Test results of occurrence of asynchronous updates for four graphics cards: nVidia GeForce GTX 460, GTX 680, AMD FirePro M8900 and Radeon HD 7970. The horizontal axes of all plots are texture sizes tested. The vertical axes are the occurrence of asynchronous updates in percentage. ", "caption_bbox": [391, 321, 692, 396]}, {"image_id": 3, "file_name": "534_03.png", "page": 5, "dpi": 300, "bbox": [375, 57, 693, 186], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A 512\u00d7512 binary image of a spiral is used as a mask for Algorithm 1. After 512 iterations, different ID or- derings exhibit different patterns when IDs are color-mapped. A: IDs are in ascending order. B: IDs are in descending or- der. C: IDs are shuffled with Algorithm 3. The numbers of remaining sub-regions are shown below the images. Yellow arrowheads point to regions where high amount of un-merged sub-regions are present, due to the largely synchronous be- havior of the graphics card. With shuffled IDs, the algorithm is able to generate fewer sub-regions with the same number of iterations. The tests are done on an AMD Radeon HD 7970 graphics card, which exhibits the least asynchronous behavior in Figure 3. There are fewer remaining sub-regions when a more asynchronous graphics card is used, e.g. nVidia cards. However, the difference between ordered and shuffled ID orderings is still quite large. ", "caption_bbox": [391, 197, 692, 440]}, {"image_id": 4, "file_name": "534_04.png", "page": 6, "dpi": 300, "bbox": [58, 57, 378, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: ID shuffling for an 8-cell 1D grid. The binary code of each cell index is reversed and then subtracted from the total cell number. The IDs are placed in the order of visiting the binary tree shown below, with depth-first traversal. In the tree, larger IDs are on nodes of higher levels. ", "caption_bbox": [59, 273, 360, 348]}, {"image_id": 5, "file_name": "534_05.png", "page": 6, "dpi": 300, "bbox": [392, 427, 692, 577], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Colorization of a confocal scan of a Drosophila brain (512\u00d7512\u00d785\u00d78bit). A: The volume rendering of the original dataset. B: The volume rendering of the colorized dataset. Dotted outlines indicate large and homogeneous structures. It took 200 iterations to generate the result. Gen- erating the result took around 1 second on an AMD Radeon HD 7970. ", "caption_bbox": [391, 590, 692, 696]}, {"image_id": 6, "file_name": "534_06.png", "page": 7, "dpi": 300, "bbox": [60, 510, 360, 609], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: An illustrated example of two idealized touching biological cells. A: The original data. Cells have high inten- sity and low gradient magnitude at their centers and low intensity but high gradient magnitude at borders. B: Algo- rithm 4 is used with the measure in Equation 1. When the \u03c3 value in Equation 1 is low, the centers of the cells are colored differently. However, they are surrounded by a cloud of vari- ous colors (IDs), which obscures the content inside. C: When we increase the \u03c3 value, the two cells are fused together. D: When we introduce a size constraint, the two cells can be colored as desired. ", "caption_bbox": [59, 621, 360, 787]}, {"image_id": 7, "file_name": "534_07.png", "page": 8, "dpi": 300, "bbox": [375, 57, 693, 185], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Synthesized Brainbow of a confocal scan of a Drosophila brain (512\u00d7512\u00d7115\u00d78bit). A: The volume rendering of the original dataset. This is a noisy dataset. B: The volume rendering of the colorized result. The col- ored volume is rendered with maximum intensity projection (MIP) [WMLK89] plus a shading overlay, as described by Wan et al. [WOCH12], in order to see the colored structures clearly. C: A close-up of the cells. The colorization took two passes. In the first pass, iteration number is set to 200, and \u03c3 is set to 0.35. In the second pass, iteration number is set to 10, \u03c3 to 1.0, and size constraint is set to 50. This 10-iteration process is then repeated five times in the second pass. This is because the dataset is noisy and we need to look at the result and decide if more iterations are necessary. The colorization process took 1.98 seconds on an AMD Radeon HD 7970, excluding the time for manual parameter adjustment. ", "caption_bbox": [391, 196, 692, 439]}, {"image_id": 8, "file_name": "534_08.png", "page": 8, "dpi": 300, "bbox": [60, 386, 361, 538], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Synthesized Brainbow of a confocal scan of an eye of a zebrafish embryo (512\u00d7512\u00d733\u00d78bit). A: The volume rendering of the original dataset. B: The volume rendering of the colorized result. In the original scan, many structures are fused together, which are better discriminated in the colorized result. The colorization took two passes. In the first pass, iteration number is set to 50, and \u03c3 is set to 0.35. In the second pass, iteration number is set to 300, \u03c3 to 1.0, and size constraint is set to 250. The colorization process took 1.34 seconds on an AMD Radeon HD 7970. ", "caption_bbox": [59, 550, 360, 701]}, {"image_id": 9, "file_name": "534_09.png", "page": 8, "dpi": 300, "bbox": [58, 57, 378, 185], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Synthesized Brainbow of the same confocal scan of a Drosophila brain (512\u00d7512\u00d785\u00d78bit) in Figure 6. A: The volume rendering of the original dataset. B: Rendering of the colorized result generated with size constraint. C: A close-up of the fibers. Individual fibers are connected and different fibers are colored differently. In the first pass of ID merging, iteration number is set to 200, and \u03c3 is set to 0.5. In the second pass of ID merging, iteration number is set to 200, \u03c3 to 1.0, and size constraint is set to 100 voxels. The colorization process took 2.81 seconds on an AMD Radeon HD 7970. ", "caption_bbox": [59, 196, 360, 362]}, {"image_id": 10, "file_name": "534_10.png", "page": 9, "dpi": 300, "bbox": [60, 207, 360, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Results from the first part of our survey. The collective answers to the likelihood of each image being gen- erated with the Brainbow technique are plotted in one bar plot. The length of a bar represents the frequency of each choice being selected (5 - most likely, 1 - most unlikely). Here the images are grouped according to techniques used. In the survey, they were shown to the participants in random order. Above the plots are the combined percentages of the partic- ipants who answered 5 or 4. The answers to most of our images are similar to those of the true Brainbows. ", "caption_bbox": [59, 342, 360, 493]}], "535": [{"image_id": 0, "file_name": "535_00.png", "page": 1, "dpi": 300, "bbox": [58, 578, 693, 746], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example of the correction for a synthetic dataset (top row) and a liver segmentation dataset (bottom row) using our new approach: (a) features for the correction are circled, (b) iso-surfaces of the skeleton distance field are shown, (c) each color band represents a certain influence zone, (d) user interaction is shown together with the correction results. ", "caption_bbox": [59, 527, 692, 570]}, {"image_id": 1, "file_name": "535_01.png", "page": 2, "dpi": 300, "bbox": [58, 57, 693, 459], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Manipulation on the skeleton and the structural features for the correction: (a) a region with over-segmentation, (b) manipulation on (a), (c) correction of (a) by result of (b), (d) a region with under-segmentation, (e) manipulation on (d), (f) correction of (d) by result of (e), (g) a region with boundary artifacts, (h) manipulation on (g), (i) correction of (g) by result of (h). (a-c, g-i) depict the skeletons of the objects, (d-f) depict the skeletons of the compliments of the objects in the volumes. ", "caption_bbox": [59, 470, 692, 529]}, {"image_id": 2, "file_name": "535_02.png", "page": 4, "dpi": 300, "bbox": [58, 57, 377, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparison of (a, c) the Euclidean and (b, d) the skeleton distance fields for the influence zones calculation. (a, b) The features are selected by the same set of skeleton voxels in both cases. Note the \"leak\" of the selection if the Euclidean distance is used. (c, d) Iso-surfaces of the same values are shown in both cases. The left close-up views show a region with only one object structure. No strong difference appears. The right close-up views show a region with two ob- ject structures. Their delineation based on the skeleton lines in the skeleton distance field causes strong difference. ", "caption_bbox": [59, 316, 360, 466]}, {"image_id": 3, "file_name": "535_03.png", "page": 5, "dpi": 300, "bbox": [59, 57, 693, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The selection tools and the operations available during user interaction. Previews of changes are shown.", "caption_bbox": [84, 226, 663, 239]}, {"image_id": 4, "file_name": "535_04.png", "page": 7, "dpi": 300, "bbox": [58, 230, 361, 367], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison of (a) the initial segmentation and (b) the corrected segmentation of the object. The object is a liver, affected by Non-Alcoholic Fatty Liver Disease. The initial segmentation has severe over-segmentation towards the heart. The blue dotted line shows the desired delineation of the organs. ", "caption_bbox": [59, 378, 360, 467]}, {"image_id": 5, "file_name": "535_05.png", "page": 9, "dpi": 300, "bbox": [58, 57, 376, 385], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Selection of a partially occluded structural fea- ture (vessel aneurysm in MRA): (a) skeleton cluttering and self-occlusion, (b) direct interaction with the lasso tool fails to select the feature without the occluder, (c) a link between the 3D rendering and the slice views exploited, (d) the lasso tool with the slice views link allows to select the feature. ", "caption_bbox": [59, 397, 360, 486]}], "536": [{"image_id": 0, "file_name": "536_00.png", "page": 2, "dpi": 300, "bbox": [58, 57, 694, 391], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The TrajectoryLenses application to analyse the electric scooter data: a) map: interactive map with trajectories meeting the lens filter critera, b) result panel: details of the final filter result set (union of all groups), c) group panel: create, select, and delete groups, group details, d) time line: hierarchical time slider and range selection. ", "caption_bbox": [59, 401, 692, 444]}, {"image_id": 1, "file_name": "536_01.png", "page": 4, "dpi": 300, "bbox": [58, 57, 682, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Types of lenses with different filter criteria.", "caption_bbox": [241, 323, 509, 336]}, {"image_id": 2, "file_name": "536_02.png", "page": 5, "dpi": 300, "bbox": [58, 263, 362, 415], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The origin lens with context information. Trajec- tory origins are visualized as small yellow dots. The ones within the lens area are enlarged and their corresponding destinations are shown (cyan dots). ", "caption_bbox": [59, 425, 360, 484]}, {"image_id": 3, "file_name": "536_03.png", "page": 5, "dpi": 300, "bbox": [391, 645, 694, 807], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Two filter groups (coloured blue and green) filter- ing trajectories with a certain origin and destination area, traversing different waypoints. ", "caption_bbox": [391, 820, 692, 863]}, {"image_id": 4, "file_name": "536_04.png", "page": 6, "dpi": 300, "bbox": [390, 632, 694, 745], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Using only three layers (months, days, hours) saves screen space but greatly reduces the visual impression of a distorted, continuous display. ", "caption_bbox": [391, 755, 692, 798]}, {"image_id": 5, "file_name": "536_05.png", "page": 6, "dpi": 300, "bbox": [58, 354, 362, 592], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Lenses can be added and removed from ac- tive groups via the \u2018+\u2019 and \u2018-\u2019 buttons, which appear on a dropped lens while hovering over the lens area. ", "caption_bbox": [59, 602, 360, 645]}, {"image_id": 6, "file_name": "536_06.png", "page": 6, "dpi": 300, "bbox": [375, 57, 694, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A close-up view of the time line showing layers at various scales and aggregation levels. ", "caption_bbox": [391, 284, 692, 312]}, {"image_id": 7, "file_name": "536_07.png", "page": 8, "dpi": 300, "bbox": [390, 419, 694, 619], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Analysis of battery drainage: Using three lens groups we investigate the battery drainage behaviour based on three alternative routes from Obert\u00fcrkheim to Vaihingen. Darker map areas show hilly terrain. ", "caption_bbox": [391, 630, 692, 689]}, {"image_id": 8, "file_name": "536_08.png", "page": 8, "dpi": 300, "bbox": [58, 57, 694, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Analysis of daily usage behaviour: First, a cluster on the parking area of the company is selected (destination lens). Second, the origin lens is used to examine individual participants. Third, the temporal histogram is used to understand the increase and decrease in usage behaviours. (Please note that the map has been hidden in this case in order to protect the privacy of the involved project participants.) ", "caption_bbox": [59, 324, 692, 383]}], "537": [{"image_id": 0, "file_name": "537_00.png", "page": 1, "dpi": 300, "bbox": [58, 327, 694, 589], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An instance of visual exploration using the ExPlatesJS system. After performing an initial exploration, the user is annotating different exploration states using the freehand annotation feature supported by the system. ", "caption_bbox": [59, 600, 692, 628]}, {"image_id": 1, "file_name": "537_01.png", "page": 4, "dpi": 300, "bbox": [390, 548, 694, 734], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of different ExPlates components.", "caption_bbox": [401, 745, 681, 758]}, {"image_id": 2, "file_name": "537_02.png", "page": 6, "dpi": 300, "bbox": [58, 57, 691, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The E X P LATES JS visual exploration system used to explore the world life expectancy at birth database and the world income equality Gini index database. The system allows for building visualization workflows using components such as datasets (green panels), inner joins (yellow), intersections (purple), and filters (cyan), interspersed with visualization panels. ", "caption_bbox": [58, 306, 691, 349]}], "538": [{"image_id": 0, "file_name": "538_00.png", "page": 1, "dpi": 300, "bbox": [58, 565, 693, 763], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Schematic depiction of the construction of Julia sets to provide a visual explanation for their complexity. In a number of steps (top row), complexity builds up; a smooth animation (bottom row) shows how the shape is distorted per step. ", "caption_bbox": [58, 515, 691, 544]}, {"image_id": 1, "file_name": "538_01.png", "page": 4, "dpi": 300, "bbox": [58, 57, 644, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Mapping f (z) = zn + c. Forward and inverse mapping are shown, as well as the notation used in the animated model.", "caption_bbox": [58, 277, 690, 295]}, {"image_id": 2, "file_name": "538_02.png", "page": 5, "dpi": 300, "bbox": [58, 57, 693, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Overview of animation types. Each row shows an animation type (from top to bottom Corkscrew, Fan, Riemann surface, and Disks), from left to right frames from two complete cycles are shown. ", "caption_bbox": [58, 441, 691, 470]}, {"image_id": 3, "file_name": "538_03.png", "page": 6, "dpi": 300, "bbox": [58, 57, 378, 429], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: When the branches are shown as separate disks, here for n = 3, their rotation can be reduced by adding offsets 2\u03c0mk , here 2\u03c0 for the pink disk and \u22122\u03c0 for the blue disk. The purple, orange, and green lines represent the two sides of the three branch cuts. ", "caption_bbox": [58, 441, 359, 516]}, {"image_id": 4, "file_name": "538_04.png", "page": 6, "dpi": 300, "bbox": [375, 57, 695, 346], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The main window of JuliaInMotion.", "caption_bbox": [425, 357, 656, 371]}, {"image_id": 5, "file_name": "538_05.png", "page": 7, "dpi": 300, "bbox": [58, 330, 362, 444], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Alternative color \ufb01ll, which shows that equipoten- tial lines remain perpendicular to \ufb01eld lines. ", "caption_bbox": [58, 455, 359, 484]}, {"image_id": 6, "file_name": "538_06.png", "page": 7, "dpi": 300, "bbox": [375, 57, 694, 355], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Coloring attractor and basins of attraction.", "caption_bbox": [410, 366, 671, 380]}, {"image_id": 7, "file_name": "538_07.png", "page": 7, "dpi": 300, "bbox": [58, 57, 378, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Results for a sequence of iterations. The blue and green rings vanish quickly here. ", "caption_bbox": [58, 286, 359, 315]}, {"image_id": 8, "file_name": "538_08.png", "page": 8, "dpi": 300, "bbox": [375, 57, 694, 316], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Visual annotation to aid in understanding the math behind Julia sets. ", "caption_bbox": [390, 327, 691, 356]}, {"image_id": 9, "file_name": "538_09.png", "page": 8, "dpi": 300, "bbox": [58, 57, 378, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Animation timing styles. Per style the variation of three parameters between 0 and 1 over time is shown. ", "caption_bbox": [58, 267, 359, 296]}, {"image_id": 10, "file_name": "538_10.png", "page": 9, "dpi": 300, "bbox": [58, 57, 693, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Sequential (top) and parallel (bottom) animation timing styles, shown for one iteration of a cubic Julia set.", "caption_bbox": [82, 292, 667, 306]}], "539": [{"image_id": 0, "file_name": "539_00.png", "page": 3, "dpi": 300, "bbox": [73, 57, 693, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A symbol map (a) and heatmap (b) visualizing a dataset of Brightkite user checkins. The symbol map visualizes a sample of the data, and the heatmap shows the density of checkins by aggregation. Compared to the heatmap, sampling misses important structures such as inter-state highway travel and Hurricane Ike, while dense regions still suffer from over-plotting. ", "caption_bbox": [59, 326, 692, 369]}, {"image_id": 1, "file_name": "539_01.png", "page": 4, "dpi": 300, "bbox": [375, 57, 675, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Scatter plots with 100,000 data points: (a) tradi- tional, (b) hexagonal bins, (c) rectangular bins and (d) rect- angular bins with perceptual (cube root) color adjustment. ", "caption_bbox": [391, 382, 692, 425]}, {"image_id": 2, "file_name": "539_02.png", "page": 5, "dpi": 300, "bbox": [61, 57, 378, 164], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Panning and zooming in a binned plot: initial view (left), zooming in (middle), panning to the lower-left (right). ", "caption_bbox": [59, 177, 360, 205]}, {"image_id": 3, "file_name": "539_03.png", "page": 5, "dpi": 300, "bbox": [375, 57, 693, 248], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Multiple coordinated views of Brightkite user checkins in North America. Cyan lines in the heatmap in- dicate data tile boundaries. Each visualization region is an- notated by its backing data dimensions and indices. ", "caption_bbox": [391, 260, 692, 319]}, {"image_id": 4, "file_name": "539_04.png", "page": 6, "dpi": 300, "bbox": [395, 575, 690, 703], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Sparse and dense representations of a data tile.", "caption_bbox": [396, 714, 686, 727]}, {"image_id": 5, "file_name": "539_05.png", "page": 6, "dpi": 300, "bbox": [392, 324, 691, 499], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Brushing & linking from the geographic heatmap to the Day histogram. We aggregate four data tiles along the X and Y dimensions and sum up the projections. ", "caption_bbox": [391, 510, 692, 553]}, {"image_id": 6, "file_name": "539_06.png", "page": 6, "dpi": 300, "bbox": [58, 57, 677, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) A 5-dimensional data cube of Brightkite check-ins; (b) Decomposing a full cube into sub-cubes and data tiles.", "caption_bbox": [64, 283, 683, 296]}, {"image_id": 7, "file_name": "539_07.png", "page": 8, "dpi": 300, "bbox": [375, 57, 692, 414], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Benchmark results for three data sets.", "caption_bbox": [423, 615, 659, 628]}, {"image_id": 8, "file_name": "539_08.png", "page": 8, "dpi": 300, "bbox": [58, 57, 378, 170], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Average time (ms) for imMens (blue) and Profiler (orange) to update frames during brushing & linking. ", "caption_bbox": [391, 426, 692, 454]}], "540": [{"image_id": 0, "file_name": "540_00.png", "page": 4, "dpi": 300, "bbox": [375, 57, 681, 181], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Joint histogram computation.", "caption_bbox": [441, 197, 641, 210]}, {"image_id": 1, "file_name": "540_01.png", "page": 6, "dpi": 300, "bbox": [58, 57, 661, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Six views of the CT-carp with the corresponding mutual information values.", "caption_bbox": [160, 269, 591, 282]}, {"image_id": 2, "file_name": "540_02.png", "page": 7, "dpi": 300, "bbox": [106, 57, 693, 221], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Four views of the CT-engine embedded in the sphere of viewpoints which has been colored using the thermal scale.", "caption_bbox": [62, 244, 688, 257]}, {"image_id": 3, "file_name": "540_03.png", "page": 7, "dpi": 300, "bbox": [97, 295, 334, 459], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Mutual information for the CT-body using three manually defined transfer functions. ", "caption_bbox": [59, 466, 360, 494]}, {"image_id": 4, "file_name": "540_04.png", "page": 7, "dpi": 300, "bbox": [403, 295, 682, 538], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: CT-carp visualization applying (a) the ramp trans- fer function and the transfer functions automatically ob- tained with (b) one view and 54 iterations, and (c) six views and 75 iterations. For each image, the mutual information value is shown. ", "caption_bbox": [391, 546, 692, 620]}, {"image_id": 5, "file_name": "540_05.png", "page": 8, "dpi": 300, "bbox": [77, 191, 345, 331], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: CT-head visualization using (a) only the head- light, (b) the headlight and the best scene light, and (c) the headlight and the best two scene lights, where the red and blue arrows are the first and second scene lights, respec- tively. ", "caption_bbox": [59, 339, 360, 413]}, {"image_id": 6, "file_name": "540_06.png", "page": 9, "dpi": 300, "bbox": [73, 57, 378, 437], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Scatterplots that relate the standardized individ- ual score and mutual information values for the experiments that analyze (a) the viewpoint and (b) the transfer function, respectively. ", "caption_bbox": [59, 445, 360, 504]}], "541": [{"image_id": 0, "file_name": "541_00.png", "page": 2, "dpi": 300, "bbox": [58, 57, 687, 184], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Bar charts depicting fictional fruit sales. The charts use color assignments from an expert (left), our algorithm (center), and a standard palette (right). The first two charts use semantically-resonant colors to represent data values. ", "caption_bbox": [59, 197, 692, 225]}, {"image_id": 1, "file_name": "541_01.png", "page": 3, "dpi": 300, "bbox": [80, 468, 339, 518], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The Tableau 20 color palette.", "caption_bbox": [109, 529, 309, 542]}, {"image_id": 2, "file_name": "541_02.png", "page": 5, "dpi": 300, "bbox": [375, 57, 694, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Example categorical value sets and the counts of colors chosen by Turkers. Numbers in brackets are the mean colorability ratings. The first is an example of a more col- orable set (mean rating: 3.9) while the second is less col- orable (mean rating: 2.7) ", "caption_bbox": [391, 373, 692, 447]}, {"image_id": 3, "file_name": "541_03.png", "page": 5, "dpi": 300, "bbox": [395, 473, 685, 699], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Category sets ordered by mean colorability rating. Ratings are shown in parentheses. Column A contains colors selected by our algorithm; Column T contains the Turker- chosen colors with highest overlap. ", "caption_bbox": [391, 718, 692, 777]}, {"image_id": 4, "file_name": "541_04.png", "page": 6, "dpi": 300, "bbox": [58, 57, 378, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Independent variables in Experiment 1.", "caption_bbox": [419, 425, 664, 438]}, {"image_id": 5, "file_name": "541_05.png", "page": 7, "dpi": 300, "bbox": [63, 393, 347, 644], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Experiment trial for an A+B vs. C+D question.", "caption_bbox": [64, 652, 353, 665]}, {"image_id": 6, "file_name": "541_06.png", "page": 7, "dpi": 300, "bbox": [375, 57, 693, 201], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Experiment 1 results. Points depict means of log response times, by condition. Error bars show 50% (thick) and 95% (thin) confidence intervals. ", "caption_bbox": [391, 207, 692, 250]}, {"image_id": 7, "file_name": "541_07.png", "page": 7, "dpi": 300, "bbox": [68, 57, 378, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Color assignments for categorical values in Ex- periment 1. (A = Algorithm, E = Expert) ", "caption_bbox": [59, 346, 360, 374]}, {"image_id": 8, "file_name": "541_08.png", "page": 8, "dpi": 300, "bbox": [393, 236, 690, 412], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Experiment 2 results. Points depict means of log response times for each category, organized by colorability. Error bars show 50% confidence intervals. ", "caption_bbox": [391, 426, 692, 469]}, {"image_id": 9, "file_name": "541_09.png", "page": 8, "dpi": 300, "bbox": [375, 57, 685, 154], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Experiment 2 results. Points depict means of log response times. Error bars show 50% (thick) and 95% (thin) confidence intervals. ", "caption_bbox": [391, 168, 692, 211]}], "542": [{"image_id": 0, "file_name": "542_00.png", "page": 3, "dpi": 300, "bbox": [105, 57, 693, 398], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization of NSF awards, accompanied by a Q2Q interface (frontmost window on the right).", "caption_bbox": [109, 408, 641, 421]}, {"image_id": 1, "file_name": "542_01.png", "page": 5, "dpi": 300, "bbox": [375, 57, 694, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visualization of movies in the Internet Movie Database. Three tables list genres, movies, and people. ", "caption_bbox": [391, 251, 692, 279]}], "543": [{"image_id": 0, "file_name": "543_00.png", "page": 4, "dpi": 300, "bbox": [375, 57, 691, 210], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The division of the visual representation of a poem into 2 main domains (phonetic and semantic) and 5 regions. ", "caption_bbox": [391, 226, 692, 254]}, {"image_id": 1, "file_name": "543_01.png", "page": 5, "dpi": 300, "bbox": [58, 57, 378, 160], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) A representation of the position of the tongue for a close front rounded vowel. (b) The glyph design in our system for a close rounded vowel. (c) A representation of the tongue moving from a close front to a close back. (d) The glyph shows the transition of the vowel positions where a light shade represents the previous position and a darker shade indicates the current position. ", "caption_bbox": [59, 171, 360, 275]}, {"image_id": 2, "file_name": "543_02.png", "page": 5, "dpi": 300, "bbox": [375, 57, 693, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A snapshot of the final interface showing some of the variables with their visual mappings and legend. ", "caption_bbox": [391, 269, 692, 297]}, {"image_id": 3, "file_name": "543_03.png", "page": 6, "dpi": 300, "bbox": [58, 57, 378, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A sonnet showing its phonetic and rhyming con- nections, such as its internal rhymes, end rhymes and fre- quency of the IPA characters. ", "caption_bbox": [59, 379, 360, 422]}, {"image_id": 4, "file_name": "543_04.png", "page": 7, "dpi": 300, "bbox": [66, 57, 693, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualization of poems and texts with a focus on vowel positions. The top three are poems: a free-verse poem, a sonnet and a nursery rhyme. The last three are prose texts: a novel [BNC07], a political manifesto [BNC07] and a Nature paper. The gray vertical bars indicate line breaks in poems or sentence breaks in other texts. ", "caption_bbox": [59, 420, 692, 463]}, {"image_id": 5, "file_name": "543_05.png", "page": 8, "dpi": 300, "bbox": [59, 57, 694, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Three different latitudinal layouts of a poem.", "caption_bbox": [237, 351, 513, 364]}, {"image_id": 6, "file_name": "543_06.png", "page": 9, "dpi": 300, "bbox": [58, 500, 362, 632], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A user can interact with the visualization to view the location of a word in the structured layout. The texture under each word represents a grammatical \u201cpart of speech\u201d. ", "caption_bbox": [59, 644, 360, 687]}, {"image_id": 7, "file_name": "543_07.png", "page": 9, "dpi": 300, "bbox": [77, 57, 693, 446], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A structurally laid out poem with its phonetic and semantic connections.", "caption_bbox": [168, 468, 582, 481]}], "544": [{"image_id": 0, "file_name": "544_00.png", "page": 4, "dpi": 300, "bbox": [59, 57, 679, 296], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Motivation of the design of the fingerprint glyphs. (a) Fingerprint in which sentences that mention the name Harry are highlighted. (b) Fingerprint in which mentions of the name Hagrid are highlighted. (c) Mentions of Harry and/or Hagrid are shown in the same plot (green = both in same sentence). (d) Co-occurrence lines instead of single mentions (see also Figure 2) (e) Co-occurrence lines with coloring as a redundant encoding of the position. (f) Colored co-occurrence lines for which the inherent block structure was boosted. (g) The colormap that is used to encode the position of a co-occurrence line. ", "caption_bbox": [59, 309, 692, 383]}, {"image_id": 1, "file_name": "544_01.png", "page": 5, "dpi": 300, "bbox": [375, 57, 693, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of co-occurrence threshold and boost- ing. (a) Sentences marked with A,B mention the names of (one of) the two characters in focus. The numbered arrows show the distance, i.e. number of sentences, to the closest mention of the other character. (b) Given a co-occurrence threshold of 3, the highlighted sections would be colored. (c) Given a boosting threshold of 5, the two sections would be linked with semi-transparent coloring (transparency in- creases with the distance from the colored snippets). ", "caption_bbox": [391, 234, 692, 369]}, {"image_id": 2, "file_name": "544_02.png", "page": 7, "dpi": 300, "bbox": [124, 57, 693, 910], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Fingerprint matrix for the novel Harry Potter and the Philosopher\u2019s Stone by Joanne K. Rowling. The matrix was generated with a co-occurrence threshold of 6 and a boosting threshold of 50. ", "caption_bbox": [59, 920, 692, 948]}, {"image_id": 3, "file_name": "544_03.png", "page": 8, "dpi": 300, "bbox": [58, 57, 694, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Excerpt of the fingerprint matrix for the Swedish novel Drottningens juvelsmycke showing the co-occurrences of the main character Tintomara. The figure was generated with a co-occurrence threshold of 6 and a boosting threshold of 50. ", "caption_bbox": [59, 260, 692, 288]}, {"image_id": 4, "file_name": "544_04.png", "page": 9, "dpi": 300, "bbox": [64, 57, 378, 572], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Excerpt of the fingerprint matrix for the novel Drottningens juvelsmycke \u2019The Queen\u2019s Tiara\u2019 showing the co-occurrences of the four lovers of the main character Azouras Lazuli Tintomara. The figure was generated with a co-occurrence threshold of 6 and a boosting threshold of 50. ", "caption_bbox": [59, 582, 360, 656]}], "545": [{"image_id": 0, "file_name": "545_00.png", "page": 1, "dpi": 300, "bbox": [58, 612, 693, 802], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview our scheme for tetrahedral meshes (illustrated in 2D). (a) We interpret the Morse complex of a simplicial mesh in terms of the primal mesh \u03a3 (solid lines) and its dual \u03a3d (dashed lines). (b) Encoding the Discrete Morse gradient field entirely with the tetrahedra enables the use of compact topological data structures for morphological extraction. We associate the descending Morse complexes with the cells of \u03a3 (c-d), the ascending Morse complexes with the cells of \u03a3d (e-f) and the Morse-Smale complex with the dually subdivided tetrahedral mesh \u03a3S (g), whose hexahedral cells are defined by a tetrahedron and one of its vertices. All relations are encoded strictly in terms of the vertices and tetrahedra of \u03a3. ", "caption_bbox": [58, 515, 691, 605]}, {"image_id": 1, "file_name": "545_01.png", "page": 4, "dpi": 300, "bbox": [375, 57, 653, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A dually-subdivided tetrahedron \u03c4 (a) is decom- posed into four hexahedra (b), each defined by a vertex of \u03c4 (black) and interior points from each incident face within \u03c4. ", "caption_bbox": [389, 241, 693, 285]}, {"image_id": 2, "file_name": "545_02.png", "page": 4, "dpi": 300, "bbox": [59, 57, 378, 192], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The primal/dual relationships in a tetrahedral mesh. Each dual cell id (gray) is an i-polytope contained within the star (blue) of its corresponding primal k-simplex k p (green), where i + k = 3. ", "caption_bbox": [58, 199, 359, 259]}, {"image_id": 3, "file_name": "545_03.png", "page": 5, "dpi": 300, "bbox": [71, 57, 378, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Geometrical representation of a Morse-Smale com- plex computed on a synthetic dataset. (a) Filtered view of the (macro) MS complex 3-cells (unique colors) composed of a set of micro-hexahedra. (b) The MS 2-cells bounded by the MS 1-skeleton. Each 2-cell is composed of a set of micro- quads and is bounded by 1-cells (saddle connectors). ", "caption_bbox": [57, 243, 361, 332]}, {"image_id": 4, "file_name": "545_04.png", "page": 9, "dpi": 300, "bbox": [114, 57, 693, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Example of features extracted from the B UCKY dataset. (a) The Morse-Smale 1-manifolds: maxima\u20132-saddle connectors (red), 2-saddle\u20131-saddle connectors (green) and 1-saddle\u2013minima connectors (blue). (b) The Morse-Smale 3-cells, thresholded by region sizes to highlight the larger 3-cells decomposing the inner spheres. (c) The intersection of 3-cells from the ascending (blue) and descending (red) Morse complexes, filtered to highlight 3-cells decomposing the inner spheres. (d) The graph representing the combinatorial structure of the MS complex. ", "caption_bbox": [58, 259, 693, 333]}], "546": [{"image_id": 0, "file_name": "546_00.png", "page": 5, "dpi": 300, "bbox": [58, 57, 694, 225], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The barrier landscape of an example optimization problem. The landscape profile is shown with (a) linear scaling of the basin sizes and (b) logarithmic scaling. (c) evolves from (b) by drawing the complete slope right of the child basins to get the \u201cprecipice\u201d form. ", "caption_bbox": [59, 240, 692, 284]}, {"image_id": 1, "file_name": "546_01.png", "page": 6, "dpi": 300, "bbox": [58, 57, 378, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Depending on the measure, different color map- pings, supposed maximal values, and aggregation methods should be used. ", "caption_bbox": [391, 239, 692, 283]}, {"image_id": 2, "file_name": "546_02.png", "page": 7, "dpi": 300, "bbox": [98, 57, 378, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Multiple configurations (1, 2, and 3) and multiple time-steps are located within the same pixel (dashed square). The colors of the corresponding grid cells need to be aggre- gated to determine the color of the pixel. ", "caption_bbox": [59, 267, 360, 326]}, {"image_id": 3, "file_name": "546_03.png", "page": 9, "dpi": 300, "bbox": [58, 57, 694, 676], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualization of different variants of HelixPSO with dPSO-Vis for different RNAs with 10 particles over 100 time steps. Images a) to c) show the last visitor age, d) and e) show the search space covering, f) to i) and k) show the current visitor count, and j) shows the accumulated visitor count with a detailed view of two time steps. ", "caption_bbox": [59, 690, 692, 734]}], "547": [{"image_id": 0, "file_name": "547_00.png", "page": 2, "dpi": 300, "bbox": [402, 678, 682, 822], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Pareto sets for two 1D functions. \u03b1 and \u03b2 are marked as local Pareto maxima, because there is no point in their vincinity that has a higher value in both functions. Because f1 decreases and f2 increases when moving to the right between \u03b1 and \u03b2, that part of the domain is a local Pareto-optimal region. ", "caption_bbox": [391, 832, 692, 925]}, {"image_id": 1, "file_name": "547_01.png", "page": 3, "dpi": 300, "bbox": [61, 57, 693, 228], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Ascending and descending sets in simplices.", "caption_bbox": [238, 240, 512, 254]}, {"image_id": 2, "file_name": "547_02.png", "page": 4, "dpi": 300, "bbox": [62, 804, 357, 870], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Sucessive clipping of a triangle by half-planes originating from three gradients at the barycenter to deter- mine H\u03c3+ (x) (green region) ", "caption_bbox": [59, 880, 360, 927]}, {"image_id": 3, "file_name": "547_03.png", "page": 4, "dpi": 300, "bbox": [480, 684, 604, 835], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The union of the ascending set with re- spect to the triangle for the convex set of A and B is equivalent to the ascending set of a hypothet- ical point C outside the triangle with function value (min{ f1 (A), f1 (B)}, min{ f2 (A), f2 (B)}). ", "caption_bbox": [391, 849, 692, 925]}, {"image_id": 4, "file_name": "547_04.png", "page": 5, "dpi": 300, "bbox": [59, 57, 693, 259], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Analytical examples.", "caption_bbox": [296, 271, 453, 285]}, {"image_id": 5, "file_name": "547_05.png", "page": 6, "dpi": 300, "bbox": [59, 57, 688, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Pareto-extremal regions in a 2D slice of a 3D plate \ufb02ow.", "caption_bbox": [208, 301, 542, 315]}, {"image_id": 6, "file_name": "547_06.png", "page": 7, "dpi": 300, "bbox": [69, 358, 670, 569], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Ensemble of three \u03bb2 computations for different boundary conditions and parameters.", "caption_bbox": [134, 579, 615, 597]}, {"image_id": 7, "file_name": "547_07.png", "page": 7, "dpi": 300, "bbox": [92, 57, 693, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Pareto optima in a can \ufb02ow simulation.", "caption_bbox": [250, 285, 500, 299]}, {"image_id": 8, "file_name": "547_08.png", "page": 8, "dpi": 300, "bbox": [63, 722, 356, 883], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Jacobi sets in gray overlaid with Pareto extrema for the can dataset in Section 5.2. ", "caption_bbox": [59, 895, 360, 924]}], "548": [{"image_id": 0, "file_name": "548_00.png", "page": 1, "dpi": 300, "bbox": [58, 339, 694, 478], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The linked views of our application showing a protein (Candida antarctica lipase A) with a single highlighted feature. Left: line plot showing surface area per feature over time, middle: semi-transparent 3D visualization of the molecular surface (selected surface feature colored green), right: relation graph detailing the surface feature splits and merges over time. ", "caption_bbox": [58, 484, 691, 527]}, {"image_id": 1, "file_name": "548_01.png", "page": 2, "dpi": 300, "bbox": [480, 80, 604, 186], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A porin from the protein data bank [BWF\u2217 00] (2POR). This protein forms a transmembrane channel (or- ange) which was extracted by our method. ", "caption_bbox": [391, 193, 692, 240]}, {"image_id": 2, "file_name": "548_02.png", "page": 4, "dpi": 300, "bbox": [460, 80, 624, 243], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A coupling protein (1GKI) from the protein data bank [BWF\u2217 00]. Our method highlights the central channel though the protein (yellow) as well as the pockets (red and green) formed by the clefts in the outer surface (light blue). ", "caption_bbox": [391, 253, 692, 312]}, {"image_id": 3, "file_name": "548_03.png", "page": 5, "dpi": 300, "bbox": [77, 57, 375, 222], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Bar chart depicting the proportional size of each feature per time step (discretized time on x axis). ", "caption_bbox": [59, 234, 360, 262]}, {"image_id": 4, "file_name": "548_04.png", "page": 5, "dpi": 300, "bbox": [375, 57, 693, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Relation graph showing splits and merges of fea- tures over the whole simulation time. The horizontal lines denote features over time, the splines are splits and merges. ", "caption_bbox": [391, 262, 692, 305]}, {"image_id": 5, "file_name": "548_05.png", "page": 6, "dpi": 300, "bbox": [426, 80, 658, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Line plot depicting the absolute size of each fea- ture per frame (simulation time on x axis). The dashed verti- cal guide marks the current time in the 3D visualization. ", "caption_bbox": [391, 234, 692, 277]}, {"image_id": 6, "file_name": "548_06.png", "page": 6, "dpi": 300, "bbox": [128, 80, 292, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A protein (CALA) in cartoon representation (blue) showing three different pockets (red, grey, green). ", "caption_bbox": [59, 234, 360, 262]}, {"image_id": 7, "file_name": "548_07.png", "page": 7, "dpi": 300, "bbox": [375, 57, 693, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Cavity of a reductase (1RA8) extracted using 3D-S URFER [LERV\u2217 09] (left) and our method (right). Our method colors only the surface feature (blue circle). 3D- S URFER extracts the same cavity, but colors all atoms of all amino acids touching the cavity, which leads to a larger highlighted region because some parts of the amino acids may not lie inside the cavity (orange arrows). ", "caption_bbox": [391, 210, 692, 314]}, {"image_id": 8, "file_name": "548_08.png", "page": 8, "dpi": 300, "bbox": [459, 80, 625, 204], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A frame of the CALB simulation. The red surface segment marks the binding pocket containing the active site. ", "caption_bbox": [391, 214, 692, 242]}], "549": [{"image_id": 0, "file_name": "549_00.png", "page": 2, "dpi": 300, "bbox": [375, 57, 686, 598], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: ConFIS applied to two sample models: (a) cow and (b) the portal vein with three liver segments ", "caption_bbox": [391, 617, 692, 645]}, {"image_id": 1, "file_name": "549_01.png", "page": 4, "dpi": 300, "bbox": [59, 57, 378, 257], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Every point p in the triangle can be represented by the basis (u, v) with coefficients (\u03b1, \u03b2), \u03b1, \u03b2 \u2265 0 and \u03b1 + \u03b2 \u2264 1. The corresponding resulting vector e(p) can be obtained with the point p = (\u03b1, \u03b2) by: e(p) = (e2 \u2212 e1 e3 \u2212 e1 ) \u00b7 p + e1 . ", "caption_bbox": [59, 269, 360, 329]}, {"image_id": 2, "file_name": "549_02.png", "page": 5, "dpi": 300, "bbox": [120, 57, 693, 203], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The scheme of ConFIS which is divided in two parts: the preprocessing and the rendering part.", "caption_bbox": [111, 213, 638, 226]}, {"image_id": 3, "file_name": "549_03.png", "page": 6, "dpi": 300, "bbox": [59, 57, 691, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The ConFIS method with two anatomical surface models.", "caption_bbox": [203, 370, 546, 383]}, {"image_id": 4, "file_name": "549_04.png", "page": 7, "dpi": 300, "bbox": [63, 57, 693, 450], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Different surface models displayed with suggestive contour (SC), apparent ridges (AR), photic extremum lines (PEL), high quality hatching (HQ), and ConFIS. The models are from top to bottom: hyperthing, aneurysm 1, and endoscopic view of a trachea ", "caption_bbox": [59, 465, 692, 508]}, {"image_id": 5, "file_name": "549_05.png", "page": 8, "dpi": 300, "bbox": [59, 57, 665, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Performance test of ConFIS for all shown models.", "caption_bbox": [392, 397, 689, 410]}, {"image_id": 6, "file_name": "549_06.png", "page": 9, "dpi": 300, "bbox": [71, 57, 378, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Fresnel alternative with white streamlines (aneurysm 2). ", "caption_bbox": [59, 266, 360, 294]}], "550": [{"image_id": 0, "file_name": "550_00.png", "page": 2, "dpi": 300, "bbox": [375, 57, 694, 209], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A covariance matrix with annotated clustering and corresponding molecule. ", "caption_bbox": [391, 220, 692, 248]}, {"image_id": 1, "file_name": "550_01.png", "page": 4, "dpi": 300, "bbox": [59, 57, 378, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (left) Importance view of the Hepatitis protein us- ing the Cartoon drawing method in VMD. The red residues are in the important set. \u03b1 = 5, \u03b2 = 0.12. (right) The white residue has been selected. The color scale matches that of the matrix in Figure 1. ", "caption_bbox": [59, 267, 360, 341]}, {"image_id": 2, "file_name": "550_02.png", "page": 5, "dpi": 300, "bbox": [103, 57, 378, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An example of a protein model colored using the ray casting technique. ", "caption_bbox": [59, 252, 360, 280]}, {"image_id": 3, "file_name": "550_03.png", "page": 5, "dpi": 300, "bbox": [95, 301, 326, 411], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Example residue sphere with covariance cones with cut-off values. The numbers are the covariance matrix values. ", "caption_bbox": [59, 421, 360, 464]}, {"image_id": 4, "file_name": "550_04.png", "page": 5, "dpi": 300, "bbox": [375, 57, 693, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (left) An example of the correlation clustering vi- sualization applied to the average structure generated from free NS5B simulations performed in [DT13]. The clustering was performed using a correlation cut-off of 0.8. The ex- tensive connections between different parts of the free en- zyme are due to the wide-spread and extensive correlated motions that occur when the inhibitor is not bound. (right) The correlation clustering visualization applied to the aver- age structure generated from the NS5B simulations contain- ing a bound inhibitor [DT13]. The same cut-off parameter was used. There are significantly fewer connections appar- ent than in the left, which demonstrates how the presence of the inhibitor reduces the overall dynamics of the enzyme and decreases the protein\u2019s intrinsic correlations. ", "caption_bbox": [391, 236, 692, 447]}, {"image_id": 5, "file_name": "550_05.png", "page": 6, "dpi": 300, "bbox": [59, 57, 378, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An example residue and its most anti-correlated partners. ", "caption_bbox": [59, 311, 360, 339]}, {"image_id": 6, "file_name": "550_06.png", "page": 6, "dpi": 300, "bbox": [375, 57, 664, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: An allosteric path.", "caption_bbox": [467, 303, 613, 316]}, {"image_id": 7, "file_name": "550_07.png", "page": 7, "dpi": 300, "bbox": [375, 57, 693, 336], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Performance of the Covariance Clustering Visual- ization with different c values (top) and molecule sizes (with c = 0.5 (bottom) . ", "caption_bbox": [391, 348, 692, 392]}, {"image_id": 8, "file_name": "550_08.png", "page": 8, "dpi": 300, "bbox": [375, 57, 648, 447], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Cartoon representation of NS5B enzyme showing location of residues making up the GTP binding site (green space-filling representation). Key regulatory regions the \u03b2- loop and the \u22061-loop are shown in red and orange respec- tively. The free enzyme is shown in the top panel and the ligand bound enzyme in the lower panel. In each case a cor- relation path (straight pink lines) has been drawn from lig- and binding site residue Methionine 423 (grey sphere) using the allosteric path visualization. For the free enzyme, this path extends downward to the palm domain and continues throughout most of the enzyme, ultimately reaching the \u22061- loop. In contrast, the lower panel shows that the correla- tion path from Methionine 423 in the ligand bound enzyme extends upward towards the \u03b2-loop and GTP binding site, showing how the effects of a ligand binding event are propa- gated to these two important regions of the enzyme. The cor- relation paths were drawn using a search radius of 5.5 and a correlation cutoff of 0.5. The change in the pathway illus- trates how correlations that are likely to be functionally im- portant are altered as a consequence of ligand binding. This figure also demonstrates how the allosteric path visualiza- tion can be combined with standard visualization methods available in VMD to gain more insight into the functional significance of allosteric pathways. ", "caption_bbox": [391, 459, 692, 822]}], "551": [{"image_id": 0, "file_name": "551_00.png", "page": 1, "dpi": 300, "bbox": [58, 511, 693, 785], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Continuous representation of projected 5D attribute space of Smoothed Particle Hydrodynamics simulation data (a disrupting white dwarf). Projection matrices according to (a) and (c) result in continuous representations of projected attribute spaces (b) and (d), correspondingly. Manipulation of projection matrix by means of star-coordinates widget allows the user to visually separate two clusters of particles representing the star\u2019s core and the tail. These clusters are interactively selected in (d) and the locations of the particles in physical domain are shown (e). The color map used in (b) and (d) is presented in (f). ", "caption_bbox": [58, 434, 691, 510]}, {"image_id": 1, "file_name": "551_01.png", "page": 3, "dpi": 300, "bbox": [375, 56, 693, 190], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Physical space X is mapped by \u03c4 to the attribute space Q, which is then projected to the visual domain U by linear operator P. A spatial density si is defined in a spherical neighborhood of sample xi , which has an elliptical footprint in U. Scalar function \u03c3i stands for density on the footprint. ", "caption_bbox": [391, 200, 692, 277]}, {"image_id": 2, "file_name": "551_02.png", "page": 4, "dpi": 300, "bbox": [59, 56, 646, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Discrete scatterplot (a) may correspond to different spatial configurations, e.g., the ones shown in (b), (c), (d). Con- tinuous scatterplot (e) exhibits smooth transitions between spatially adjacent clusters , i.e., it can only correspond to (d). ", "caption_bbox": [58, 208, 691, 238]}, {"image_id": 3, "file_name": "551_03.png", "page": 7, "dpi": 300, "bbox": [375, 56, 693, 162], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparison of footprints in linear (left) and loga- rithmic (center and right) plots. All footprints parameters are the same except for the position of center ui . Several level curves of density function \u03c3 are shown. ", "caption_bbox": [391, 173, 692, 234]}, {"image_id": 4, "file_name": "551_04.png", "page": 8, "dpi": 300, "bbox": [59, 56, 378, 214], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Computation times for construction of CoRPAS.", "caption_bbox": [398, 869, 685, 884]}, {"image_id": 5, "file_name": "551_05.png", "page": 9, "dpi": 300, "bbox": [396, 538, 688, 857], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Logarithmic scaling of continuous scatterplot (smoothing length against internal energy, dataset as in Fig- ure 6) allows for the detection of four groups, which is not possible in the linearly scaled equivalent. ", "caption_bbox": [391, 869, 692, 930]}, {"image_id": 6, "file_name": "551_06.png", "page": 9, "dpi": 300, "bbox": [66, 56, 378, 793], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Projections of two white dwarfs dataset. Orienta- tion of splats in CoRPAS reflect the actual evolution of par- ticles on their way between two stars. It also allows to visu- ally separate particles corresponding to the cores of different stars (green and orange groups in (g)). Different weighting helps to analyze the properties of particles in each group. Note that the volume-weighted CoRPAS (c) is not helpful for the analysis since it is strongly affected by outliers. ", "caption_bbox": [58, 805, 359, 927]}], "552": [{"image_id": 0, "file_name": "552_00.png", "page": 3, "dpi": 300, "bbox": [63, 57, 378, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The proposed method comprises four main steps: representative samples selection and projection, user-driven layout manipulation, back projection of representative sam- ples, and feature space deformation. ", "caption_bbox": [59, 271, 360, 330]}, {"image_id": 1, "file_name": "552_01.png", "page": 5, "dpi": 300, "bbox": [375, 57, 693, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Silhouette values increase considerably after 10 interaction cycles. ", "caption_bbox": [391, 270, 692, 298]}, {"image_id": 2, "file_name": "552_02.png", "page": 6, "dpi": 300, "bbox": [61, 267, 361, 427], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Accuracy of SVM classification increases as the sample size to create the transformation increases. ", "caption_bbox": [59, 453, 360, 481]}, {"image_id": 3, "file_name": "552_03.png", "page": 6, "dpi": 300, "bbox": [375, 57, 693, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Clustering using k-means, rand index values in- crease considerably after 10 interaction cycles. ", "caption_bbox": [391, 277, 692, 305]}, {"image_id": 4, "file_name": "552_04.png", "page": 7, "dpi": 300, "bbox": [65, 57, 693, 432], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Overview of the image retrieval system. Initially the user defines the target images (highlighted with a red border). After that, a projection is created containing those images and a small sample drawn from the collection. The user can then reorganize the layout to create groups of similar images, which is used to transform the feature space. Finally, the most similar images to the target ones are retrieved. ", "caption_bbox": [59, 464, 692, 523]}, {"image_id": 5, "file_name": "552_05.png", "page": 8, "dpi": 300, "bbox": [73, 464, 342, 613], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Precision versus recall plot considering the origi- nal and transformed space. ", "caption_bbox": [59, 625, 360, 653]}, {"image_id": 6, "file_name": "552_06.png", "page": 8, "dpi": 300, "bbox": [58, 57, 378, 386], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Images retrieved using the original feature space. The precision worsen considerably if compared with the transformed space. ", "caption_bbox": [59, 397, 360, 440]}], "553": [{"image_id": 0, "file_name": "553_00.png", "page": 1, "dpi": 300, "bbox": [72, 300, 679, 420], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualizing time-varying frequencies of eye gaze fixations and transitions with AOI Rivers.", "caption_bbox": [124, 445, 627, 458]}, {"image_id": 1, "file_name": "553_01.png", "page": 5, "dpi": 300, "bbox": [120, 57, 693, 427], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visual encoding of time-varying eye gaze frequencies as AOI Rivers.", "caption_bbox": [178, 438, 572, 451]}, {"image_id": 2, "file_name": "553_02.png", "page": 6, "dpi": 300, "bbox": [375, 57, 686, 255], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: AOI Rivers for a small example dataset: (a) All in- fluents, effluents, and AOI transitions are displayed. (b) Fil- tered representation for illustrating the order of influents and effluents in the AOI Rivers (the same data as in (a)). ", "caption_bbox": [391, 270, 692, 329]}, {"image_id": 3, "file_name": "553_03.png", "page": 7, "dpi": 300, "bbox": [375, 57, 693, 180], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visualization techniques integrated into eye track- ing systems: (a) Time- and participant-aggregated heatmap. (b) Line-based gaze plot affected by visual clutter. ", "caption_bbox": [391, 195, 692, 238]}, {"image_id": 4, "file_name": "553_04.png", "page": 8, "dpi": 300, "bbox": [58, 57, 664, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: AOI Rivers for the eye gaze trajectory data from the stimulus shown in Figure 4.", "caption_bbox": [149, 431, 601, 444]}, {"image_id": 5, "file_name": "553_05.png", "page": 9, "dpi": 300, "bbox": [64, 329, 353, 534], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: AOI A3\u22125 is visited frequently in a short time in- terval and then split into several other rivers. ", "caption_bbox": [58, 539, 359, 567]}, {"image_id": 6, "file_name": "553_06.png", "page": 9, "dpi": 300, "bbox": [375, 57, 693, 283], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: AOI A1\u22124 contains the correct solution node. In the end, it is the most frequently visited AOI, but many par- ticipants look away and then back again. ", "caption_bbox": [391, 288, 692, 331]}, {"image_id": 7, "file_name": "553_07.png", "page": 9, "dpi": 300, "bbox": [65, 57, 378, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Exploration of AOI transitions in the beginning phase for AOIs A2\u22126 and A4\u22123 . ", "caption_bbox": [59, 278, 360, 306]}], "554": [{"image_id": 0, "file_name": "554_00.png", "page": 3, "dpi": 300, "bbox": [410, 396, 671, 528], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The interchange information (ten trajectories) at this junction can be summarized as a 5-by-5 matrix. ", "caption_bbox": [391, 532, 692, 561]}, {"image_id": 1, "file_name": "554_01.png", "page": 3, "dpi": 300, "bbox": [69, 57, 693, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: System workflow: from (a) a set of raw trajectory paths, to (b) traffic networks of different spatial scales, (c) inter- change statistics, (d) interchange circos diagrams per junction node, and (e) our interchange visualization with user interaction. ", "caption_bbox": [59, 243, 692, 271]}, {"image_id": 2, "file_name": "554_02.png", "page": 4, "dpi": 300, "bbox": [375, 57, 681, 215], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An initial design of interchange circos diagram.", "caption_bbox": [395, 219, 687, 232]}, {"image_id": 3, "file_name": "554_03.png", "page": 4, "dpi": 300, "bbox": [68, 779, 349, 918], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Example circos figures.", "caption_bbox": [124, 917, 294, 930]}, {"image_id": 4, "file_name": "554_04.png", "page": 5, "dpi": 300, "bbox": [61, 57, 693, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Developing the interchange circos diagram from the original circos figure: (a) the initial design in Figure 4; (b) use a grey-colored flyover ring (like a source/sink) for the junction itself; (c) bundle pairs of bi-directional ribbons to reduce the visual cluttering; and (d) draw white and black curved statistics boxes to present the total outgoing and incoming flow volumes. ", "caption_bbox": [59, 242, 692, 285]}, {"image_id": 5, "file_name": "554_05.png", "page": 6, "dpi": 300, "bbox": [391, 709, 690, 900], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Interchange Circos Diagrams in different scales: (a) city scale; (b) regional scale; and (c) road network scale. ", "caption_bbox": [391, 902, 692, 930]}, {"image_id": 6, "file_name": "554_06.png", "page": 6, "dpi": 300, "bbox": [401, 155, 680, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Comparing interchange circos diagrams with ex- isting visualization approach. (a) Two sets of raw trajecto- ries; (b) Existing approach aggregates flows between pairs of locations and draws arrows to indicate the aggregated flow volume; (c) Our interchange circos diagrams are able to reveal the detail on the interchange patterns. ", "caption_bbox": [391, 348, 692, 437]}, {"image_id": 7, "file_name": "554_07.png", "page": 7, "dpi": 300, "bbox": [391, 634, 689, 865], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Interchange patterns at four different train sta- tions (a-d) in a given area of the Singapore Metro system (note that station positions moved to random locations due to data privacy requirement). ", "caption_bbox": [391, 872, 692, 931]}, {"image_id": 8, "file_name": "554_08.png", "page": 8, "dpi": 300, "bbox": [58, 57, 686, 437], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Exploring the temporal changes (over a day) in the interchange patterns at four different train stations (a-d) in the Singapore Metro system. ", "caption_bbox": [59, 442, 692, 470]}, {"image_id": 9, "file_name": "554_09.png", "page": 9, "dpi": 300, "bbox": [88, 461, 329, 615], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Comparison of lower (left) and higher (right) ICU ratings at a road junction during different time periods. (a) The traffic flow from yellow to violet dominates the junc- tion utilization; moreover, both the orange and yellow con- necting links are highly unbalanced. (b) Traffic flows from different links in the junction are fairly balanced and the incoming/outgoing flows for each connecting links are also fairly balanced. ", "caption_bbox": [59, 617, 360, 737]}], "555": [{"image_id": 0, "file_name": "555_00.png", "page": 1, "dpi": 300, "bbox": [58, 555, 693, 784], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Wheelchair accessible stations in Prague metro. (a) Octilinear and (b) orthogonal annotated maps.", "caption_bbox": [100, 535, 649, 548]}, {"image_id": 1, "file_name": "555_01.png", "page": 2, "dpi": 300, "bbox": [58, 56, 682, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) The reference schematic Taipei MRT map. Hand-drawn illustrated maps designed in (b) 2011 and (c) 2012 for \u201cTaipei MRT map handkerchief\u201d (courtesy of Milu Design Co., LTD, Taiwan). Metro line segments circled in gray are elongated after the opening of new lines. ", "caption_bbox": [58, 311, 691, 355]}, {"image_id": 2, "file_name": "555_02.png", "page": 4, "dpi": 300, "bbox": [58, 56, 680, 198], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Overview of our algorithm for generating an annotated metro map. (a) An initial layout of the metro network with annotation labels. (b) An enlarged layout by a scale factor of 4. (c) Initial placement of annotation labels having mutual overlaps. (d) Overlap-free placement of annotation labels. (e) Final annotated map after minimal contraction has been applied. ", "caption_bbox": [58, 205, 691, 249]}, {"image_id": 3, "file_name": "555_03.png", "page": 4, "dpi": 300, "bbox": [408, 265, 673, 364], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Aligning metro lines with octilinear directions. (a) Octilinear coordinate system around the vertex u, where z1 (u) = (x(u) + y(u))/2 and z2 (u) = (x(u) \u2212 y(u))/2. (b) The corresponding fan-shaped sectors with respect to u. (c) Three sectors to which the optimized version of uv belongs. ", "caption_bbox": [391, 371, 692, 445]}, {"image_id": 4, "file_name": "555_04.png", "page": 6, "dpi": 300, "bbox": [58, 56, 684, 189], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Aesthetic constraints for spatially-efficient map design. (a) Twelve leader styles. (b) Aligning a leader line to make a maximal angle with adjacent metro lines. Checking overlap between (c) two labels, (d) a label and a metro line segment, (e) a label and a leader line segment, (f) leader and metro line segments, and (g) two leader line segments. ", "caption_bbox": [58, 197, 691, 241]}, {"image_id": 5, "file_name": "555_05.png", "page": 6, "dpi": 300, "bbox": [408, 261, 673, 370], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Distributing annotation labels to incident regions. (a) Labels are kicked out of a small closed region. (b) Labels are placed alternately to incident regions along a metro line. ", "caption_bbox": [391, 377, 692, 421]}, {"image_id": 6, "file_name": "555_06.png", "page": 8, "dpi": 300, "bbox": [72, 683, 685, 886], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Berlin annotated metro maps. (a) Light blue line annotated in an octilinear layout. (b) All the stations annotated in an orthogonal layout. ", "caption_bbox": [58, 894, 691, 922]}, {"image_id": 7, "file_name": "555_07.png", "page": 8, "dpi": 300, "bbox": [77, 349, 678, 639], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Taipei gourmet metro maps. (a) Octilinear layout. (b) Orthogonal layout.", "caption_bbox": [164, 647, 583, 660]}, {"image_id": 8, "file_name": "555_08.png", "page": 8, "dpi": 300, "bbox": [58, 56, 681, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Lisbon annotated metro maps. (a) Octilinear, (b) orthogonal, and (c) wheelchair accessible stations annotated only.", "caption_bbox": [58, 307, 688, 320]}], "556": [{"image_id": 0, "file_name": "556_00.png", "page": 3, "dpi": 300, "bbox": [74, 57, 378, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Mock-up of the AmniVis-Explorer layout: The 2D representations of the streamline bundles provide an overview. Their vertical arrangement left and right of the 3D focus represents the classification. ", "caption_bbox": [59, 281, 360, 340]}, {"image_id": 1, "file_name": "556_01.png", "page": 4, "dpi": 300, "bbox": [58, 57, 691, 211], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The selection of the ROIs based on shape index and curvedness. A shape index threshold (> 0.9 - cap shape) leads to connected components. Circular seeding region are created from an importance-dependent subset. ", "caption_bbox": [59, 223, 692, 251]}, {"image_id": 2, "file_name": "556_02.png", "page": 5, "dpi": 300, "bbox": [375, 57, 694, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The distortions in the 2D representation get stronger (dark brown), if the streamlines bend into the aneurysm. Sections close to the CSR plane (yellow) are rep- resented less distorted. ", "caption_bbox": [391, 243, 692, 302]}, {"image_id": 3, "file_name": "556_03.png", "page": 6, "dpi": 300, "bbox": [58, 57, 691, 501], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Example workflow: At the initial state, all widgets are aligned at the left side (a). Also the timeline for the first flow pattern was enabled. Long streamlines can be included as spatial context (b). In (c), the user employed automatic camera positioning to center the 3D view and highlighted a single pattern. In (d) the user employed the overview widgets for binary classification. ", "caption_bbox": [59, 514, 692, 573]}, {"image_id": 4, "file_name": "556_04.png", "page": 7, "dpi": 300, "bbox": [62, 57, 378, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Widget overview: The unrolled streamlines (A) are the central element. The button interface (B) provides functionality for (left-to-right): classification, viewpoint se- lection, manual and automatic time step selection, and time- line view activation. The mouse-over highlighting can be switched to permanent mode (C). To support comparison and identification, the widget provides the CSR ID, an ar- row glyph of the mean flow direction (D) and has the same color as the streamline bundle in the 3D focus (E). ", "caption_bbox": [59, 281, 360, 416]}, {"image_id": 5, "file_name": "556_05.png", "page": 8, "dpi": 300, "bbox": [58, 57, 691, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Animation: In Phase 1 (c) the view is centered. In Phase 2 (d) the camera moves above the CSR plane and is then rolled with respect to dmean (Phase 3 - (e)). ", "caption_bbox": [59, 264, 692, 293]}, {"image_id": 6, "file_name": "556_06.png", "page": 9, "dpi": 300, "bbox": [61, 57, 693, 236], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Example datasets: laminar flow in a smaller of multiple aneurysms (a), an expert classification of an unruptured aneurysm (b) and a ruptured aneurysm with view on the site of rupture (c). ", "caption_bbox": [59, 249, 692, 277]}], "557": [{"image_id": 0, "file_name": "557_00.png", "page": 3, "dpi": 300, "bbox": [405, 440, 679, 667], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Carotid Cuff: The surgically implanted cuff mod- ifies the shear stress along the right carotid artery (on the left, following medical convention). The left side is used for control. ", "caption_bbox": [391, 679, 692, 738]}, {"image_id": 1, "file_name": "557_01.png", "page": 3, "dpi": 300, "bbox": [80, 57, 693, 334], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview: Our Application consists of a number of linked views, arranged in a symmetric layout (right screen half is control). The top half of the screen is dedicated to display the unprocessed data using orthogonal slices (outside) and CPR (inside) while the bottom half shows our proposed visualization techniques, the normalized circular projection (outside) and vessel wall analysis (inside). ", "caption_bbox": [59, 345, 692, 404]}, {"image_id": 2, "file_name": "557_02.png", "page": 5, "dpi": 300, "bbox": [375, 57, 693, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Normalization: In comparison to other reforma- tion techniques (see Section 2) our approach does not only straighten the vessel (1-2) but also extrudes the vessel wall to a cylinder (3). We then switch modalities from CT to PET and sample in concentric circles (4). ", "caption_bbox": [391, 227, 692, 301]}, {"image_id": 3, "file_name": "557_03.png", "page": 6, "dpi": 300, "bbox": [390, 80, 694, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Normalized Circular Projection: We visualize the tracer uptake (red highlights) near a vessel segment (1) in a standardized fashion: From the centerline (green) we cast rays in an orthogonal plane (2) to detect the inner vessel wall (red). We then sample the PET signal further along each ray (3). Samples of the same color have the same distance to the vessel wall, regardless of the vessel diameter and shape (compare top-bottom of 2,3). Applying a maximum intensity projection (MIP) of all equidistant PET samples to one pixel (4) we generate the final image, which facilitates comparison to control. ", "caption_bbox": [391, 261, 692, 426]}, {"image_id": 4, "file_name": "557_04.png", "page": 7, "dpi": 300, "bbox": [58, 320, 362, 479], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Vessel Wall Analysis: The maximal and minimal PET activity inside a user-defined area (blue) around the in- ner vessel wall is plotted for each orthogonal slice along the centerline. Maximum activity is highlighted in solid yel- low, while the area between maximum and minimum is ren- dered semi-transparent. For comparison, the activity along the centerline is also displayed (green). The average radius provides a context for the user. ", "caption_bbox": [59, 489, 360, 609]}, {"image_id": 5, "file_name": "557_05.png", "page": 7, "dpi": 300, "bbox": [80, 57, 378, 225], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Extent of PET analysis: Plaques can remodel the vessel wall (light red, not visible in actual CT scan) in- ward (1) or outward (2). By analyzing a region of about four times the width of the vessel wall, starting at the lumen (light gray), our application can handle both types. ", "caption_bbox": [59, 235, 360, 309]}, {"image_id": 6, "file_name": "557_06.png", "page": 8, "dpi": 300, "bbox": [98, 87, 322, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: PET Activity inside the vessel wall is indicated by maxima inside the analysis region (blue line). By clicking on a position to be examined in any of the views the orthog- onal slice view (right) is set and shows the analysis region between red (inner vessel wall) and blue line, the centerline position (green dot) and the position of the maximum (yellow dot). ", "caption_bbox": [59, 224, 360, 328]}, {"image_id": 7, "file_name": "557_07.png", "page": 8, "dpi": 300, "bbox": [420, 80, 664, 222], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Activity increase along the cuff: Confirming the hypothesis of medical researchers, the PET uptake has in- creased along the cuff. The plot of the lumen shape shows that diameter shrinks steadily upstream and does not imme- diately increase downstream from the cuff. This finding fits well with the way shear stress is modified by the cuff (com- pare with Figure 2) and was confirmed by histology. ", "caption_bbox": [391, 232, 692, 336]}, {"image_id": 8, "file_name": "557_08.png", "page": 8, "dpi": 300, "bbox": [58, 345, 362, 475], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Spill-In on the control side: The wide spread of intensites in the activity plot (left) hints at a possible spill-in. The NCP (center-left) confirms this indication by visualizing position of the intensity distribution in one image. Note how the situation is not visualized by the CPR (center-right) due to an unsuitable vector of interest and would therefore re- quire rotation by the user. ", "caption_bbox": [59, 487, 360, 591]}, {"image_id": 9, "file_name": "557_09.png", "page": 9, "dpi": 300, "bbox": [60, 57, 378, 500], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Comparison Using a Software Phantom First Row: CPR plus orthogonal slices (left) and our proposed techniques (right). Second Row: Helical CPR using constant angle (left) and constant arc-length (right). Third Row: Flat- tening using a cylindrical MIP with shorter (left) and longer (right) rays. ", "caption_bbox": [59, 510, 360, 599]}], "558": [{"image_id": 0, "file_name": "558_00.png", "page": 2, "dpi": 300, "bbox": [58, 57, 378, 156], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Unifying aspects of Curvicircular Feature Aggre- gation (CFA) with respect to MIP and CPR. ", "caption_bbox": [59, 167, 360, 195]}, {"image_id": 1, "file_name": "558_01.png", "page": 3, "dpi": 300, "bbox": [375, 57, 693, 473], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Workflow of CFA.", "caption_bbox": [467, 485, 611, 498]}, {"image_id": 2, "file_name": "558_02.png", "page": 4, "dpi": 300, "bbox": [58, 57, 693, 355], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration of the sampling and aggregation around the centerline of a vessel. (a) displays a centerline with three cross-sectional planes. (b) demonstrates two sampling strategies, either with constant angle \u03c9 or with constant arc-length \u03b4 . (c) shows the circular ray profiles of the second cross-section with their maxima as squares and minima as dots. (d) presents the final image, where every cross-section is a row and every concentric circle a column. The maxima are displayed on the left side of the centerline and the minima on the right side. ", "caption_bbox": [59, 366, 692, 440]}, {"image_id": 3, "file_name": "558_03.png", "page": 5, "dpi": 300, "bbox": [59, 57, 378, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Example of CFA along a human abdominal aorta. The thin black centerline separates the image into two parts. MIP (left) shows how close calcifications approach the cen- terline and MINIP (right) displays the soft plaque. ", "caption_bbox": [59, 316, 360, 375]}, {"image_id": 4, "file_name": "558_04.png", "page": 5, "dpi": 300, "bbox": [375, 57, 693, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Example of a context visualization outside the CFA and a stability overlay (from red to blue). The context rendering uses the same method as for the CFA. ", "caption_bbox": [391, 316, 692, 359]}, {"image_id": 5, "file_name": "558_05.png", "page": 6, "dpi": 300, "bbox": [58, 57, 692, 364], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Anatomical layout of the human lower extremity vasculature with a cross-over bypass. (a) shows a 3D visualization together with the vessel tree. (b) presents the anatomical layout with the abdominal aorta (image with green border) in the middle and its branches placed to the left and right. The rightmost zoom-in uses a sampling plane orthogonal to the centerline to properly create the CFA of the bypass. It shows the transition margin, the slice line and the rulers inside the image borders. ", "caption_bbox": [59, 376, 692, 435]}, {"image_id": 6, "file_name": "558_06.png", "page": 7, "dpi": 300, "bbox": [59, 57, 693, 351], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A tubular phantom data set. (a) shows a 3D visualization of all relevant pathological features. (b) presents a MIP of the whole data set with the centerline in orange. (c) displays the CPR images and (d) the CFA with MIP on the left and MINIP on the right showing all the features within one image. A high variance (red) close to the centerline indicates that it is not properly centered. ", "caption_bbox": [59, 362, 692, 421]}, {"image_id": 7, "file_name": "558_07.png", "page": 8, "dpi": 300, "bbox": [79, 483, 673, 899], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A human pelvic CTA data set with a vessel occlusion pointed out by the orange arrows and the bracket.", "caption_bbox": [88, 910, 659, 923]}, {"image_id": 8, "file_name": "558_08.png", "page": 8, "dpi": 300, "bbox": [58, 57, 673, 443], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A CTA data set of the human pelvis with a vessel stenosis pointed out by the orange arrows.", "caption_bbox": [117, 455, 630, 468]}, {"image_id": 9, "file_name": "558_09.png", "page": 9, "dpi": 300, "bbox": [59, 57, 693, 196], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Evaluation of CFA. (a) shows the overall evaluation concerning five categories. (b) presents the clinical relevance of three categories. The y-axes show the ratings in percent (%) given by the participants. ", "caption_bbox": [59, 207, 692, 235]}], "559": [{"image_id": 0, "file_name": "559_00.png", "page": 1, "dpi": 300, "bbox": [66, 345, 686, 538], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Robustness assignment for critical point trajectories for a 2D time-varying vector field from a combustion simulation. The trajectories are mapped to colors based on their (dynamic) robustness values. The zoomed-in versions show robustness pairings among the trajectories: same color segments are paired to each other. (a) and (c) involve fold and blue-sky bifurcations. (b) and (d) are part of a long trajectory with high robustness values but different partners. ", "caption_bbox": [59, 541, 692, 600]}, {"image_id": 1, "file_name": "559_01.png", "page": 3, "dpi": 300, "bbox": [391, 367, 690, 576], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Example (a) and (b): from left to right, vec- tor fields f , relations among components of Fr , augmented merge trees and well diagrams. ", "caption_bbox": [391, 575, 692, 618]}, {"image_id": 2, "file_name": "559_02.png", "page": 7, "dpi": 300, "bbox": [84, 81, 697, 216], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Static and dynamic robustness of critical points for a stationary vector field. Left: (a) static robustness where critical points are colored based on partners who share unique robustness values; (b) merge tree and well diagram; (c) dynamic robustness partners. Right: critical points (from left to right) whose static (S) and dynamic (D) robustness may differ. r10 = 0.542685, r20 = 0.550826, r30 = 0.5549. The range of robustness is [0.0867794, 0.5549]. ", "caption_bbox": [58, 217, 691, 279]}, {"image_id": 3, "file_name": "559_03.png", "page": 7, "dpi": 300, "bbox": [72, 606, 345, 740], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A critical point trajectory highlighting the switch in static robustness pairing near birth-death points. ", "caption_bbox": [59, 739, 360, 767]}, {"image_id": 4, "file_name": "559_04.png", "page": 7, "dpi": 300, "bbox": [404, 407, 676, 600], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Combustion. Dynamic robustness of components in the sublevel sets. ", "caption_bbox": [391, 602, 692, 630]}, {"image_id": 5, "file_name": "559_05.png", "page": 8, "dpi": 300, "bbox": [72, 593, 345, 750], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: CentralAtlantic. Regions (a) and (d) are in cor- respondence with Figure 8 top (a) and (d). From (1) to (4), time slices 29, 42, 51 and 74. ", "caption_bbox": [59, 752, 360, 796]}, {"image_id": 6, "file_name": "559_06.png", "page": 8, "dpi": 300, "bbox": [120, 77, 628, 420], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Combustion. Top: robustness assignment along critical paths, for static (left) and dynamic (right) robustness. Bottom: robustness partners colored by unique values showcasing partner switches, for static (left) and dynamic (right) robustness. ", "caption_bbox": [59, 423, 692, 451]}, {"image_id": 7, "file_name": "559_07.png", "page": 9, "dpi": 300, "bbox": [114, 83, 635, 459], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Top: CentralAtlantic. Bottom: SouthAtlantic. Left: static robustness assignment along critical paths. Local features are highlighted. Right: chosen individual features. ", "caption_bbox": [59, 466, 692, 494]}], "560": [{"image_id": 0, "file_name": "560_00.png", "page": 3, "dpi": 300, "bbox": [137, 57, 693, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Interactive simulation of brown-out conditions, encountered by a helicopter in forward flight close to the ground.", "caption_bbox": [67, 244, 683, 257]}, {"image_id": 1, "file_name": "560_01.png", "page": 5, "dpi": 300, "bbox": [67, 734, 682, 898], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustrations of the integral lines in mass-space-time.", "caption_bbox": [217, 911, 533, 924]}, {"image_id": 2, "file_name": "560_02.png", "page": 6, "dpi": 300, "bbox": [375, 57, 690, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Integral lines in the Beads flow, depicted in space- time. Gravity is set to zero. ", "caption_bbox": [391, 380, 692, 408]}, {"image_id": 3, "file_name": "560_03.png", "page": 7, "dpi": 300, "bbox": [61, 375, 365, 868], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Depictions of path lines with different mass in the helicopter data set. Larger particles do not lift as high, due to gravity. ", "caption_bbox": [59, 881, 360, 924]}, {"image_id": 4, "file_name": "560_04.png", "page": 7, "dpi": 300, "bbox": [393, 375, 697, 868], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Depictions of streak lines with different mass in the helicopter data set. A higher uplift threshold and gravity keep larger particles closer to the ground. ", "caption_bbox": [391, 881, 692, 924]}, {"image_id": 5, "file_name": "560_05.png", "page": 8, "dpi": 300, "bbox": [88, 599, 690, 868], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Hydrocyclones are used to separate particles in liquid suspensions based on density variations. As visible in Fig. 9(a), an increase of mass (and thereby inertia) causes particles to drift off the vortex core and to exit at different times. Mass lines in Fig. 9(b) expand and swirl around the bottleneck, which shows that lighter particles reside longer in the bottleneck. ", "caption_bbox": [59, 881, 692, 924]}, {"image_id": 6, "file_name": "560_06.png", "page": 8, "dpi": 300, "bbox": [375, 57, 692, 209], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Depiction of mass lines with a varying diameter d p = 10\u00b5m..100\u00b5m, color-coded from brown (\u2022) to teal (\u2022). ", "caption_bbox": [391, 219, 692, 248]}, {"image_id": 7, "file_name": "560_07.png", "page": 8, "dpi": 300, "bbox": [58, 57, 378, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Time lines seeded below the rotor disk reveal that lighter particles are more subject to turbulence. ", "caption_bbox": [59, 353, 360, 381]}], "561": [{"image_id": 0, "file_name": "561_00.png", "page": 2, "dpi": 300, "bbox": [57, 57, 692, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The GeoLife Trajectories dataset clustered using vector field k-means. The original trajectories were cropped to a 10 block area in downtown Beijing. The orientation of each trajectory is represented by linearly interpolating from blue (start) to orange (end). This color scheme is used throughout the paper. We partition the data into four clusters (k = 4), and then subdivide each cluster resulting in 16 subclusters. Images (a) and (b) show two clusters from the first-level subdivision, and images (c) and (d) show two clusters from the second level. The first two vector fields show trajectories in patterns of faster vehicular traffic, while the latter appears to show pedestrian traffic moving to and from a lunch spot near the Microsoft Research Asia campus. ", "caption_bbox": [57, 310, 693, 399]}, {"image_id": 1, "file_name": "561_01.png", "page": 3, "dpi": 300, "bbox": [57, 57, 378, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An illustration of vector field k-means as it par- titions 2000 synthetic trajectories into two clusters. The al- gorithm alternates between fitting the best possible vector fields from the current assignment (\u201coptimize\u201d) and matching trajectories to the vector field which fits them best (\u201cassign\u201d). Although no trajectories form a complete circle, vector field k-means still recovers the two separate circular patterns. ", "caption_bbox": [57, 237, 361, 341]}, {"image_id": 2, "file_name": "561_02.png", "page": 4, "dpi": 300, "bbox": [58, 57, 378, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration of the trajectory tessellation and Lapla- cian matrix computation. The trajectories are tessellated so each segment is contained on a face of the grid. Each segment s j determines a constraint in the form of a matrix Cs j . The Laplacian matrix enforces our smoothness penalty. ", "caption_bbox": [57, 298, 360, 372]}, {"image_id": 3, "file_name": "561_03.png", "page": 5, "dpi": 300, "bbox": [390, 786, 690, 860], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Experimental results: For each dataset, we report the number of trajectories, the grid resolution, the number of clusters (k), and the total running times (in seconds) for the vector field fitting (optimize) and trajectory assignments. ", "caption_bbox": [390, 865, 691, 924]}, {"image_id": 4, "file_name": "561_04.png", "page": 6, "dpi": 300, "bbox": [57, 57, 693, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Left: 1415 Atlantic tropical storms (from the HURDAT dataset) used as input. Right: four trajectory clusters and their corresponding vector fields showing relative speed. Clusters (b) and (c) contain the Cape Verde-type cyclones, and separate them according to whether they dissipate in North America (b) or turn back to the Atlantic Ocean (c). Clusters (a) and (d) show storms developing in the Gulf of Mexico. We observed faster-moving storms to be in cluster (a), and slower-moving ones in (d). ", "caption_bbox": [58, 340, 691, 399]}, {"image_id": 5, "file_name": "561_05.png", "page": 7, "dpi": 300, "bbox": [57, 57, 693, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Large-scale movement patterns around Beijing, from the GeoLife Trajectories dataset. Clusters (a), (b) and (d) appear to depict travel in and out of the city through the surrounding highways. Cluster (c) has much slower speeds and its trajectories are tightly packed around a small region. Upon inspection, we found this to area to contain the Microsoft Research Asia campus. ", "caption_bbox": [58, 372, 693, 415]}, {"image_id": 6, "file_name": "561_06.png", "page": 8, "dpi": 300, "bbox": [375, 57, 693, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: TraClus computed nine clusters for the HURDAT dataset. Cluster representative trajectories are in black. No- tice that because TraClus starts by subdividing trajectories, no cluster from TraClus captures the pattern of trajectories found by vector field k-means in Figure 4 (c). ", "caption_bbox": [390, 307, 693, 381]}, {"image_id": 7, "file_name": "561_07.png", "page": 8, "dpi": 300, "bbox": [58, 57, 378, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: TraClus experiments using the synthetic dataset. In (a) 268 clusters are found with \u03b5 = 0.03 and MinLns = 2. In (b), with \u03b5 = 0.23 and MinLns = 140 TraClus detects two clusters (drawn here separated for clarity), but clearly merges portions of the two circular patterns. Slight variations on the parameters (\u03b5 = 0.25 and MinLns = 160) causes TraClus to merge the two cluster into one as seen in (c). These results were obtained in 0.8, 1.6, and 6.5 seconds respectively. ", "caption_bbox": [58, 230, 361, 350]}, {"image_id": 8, "file_name": "561_08.png", "page": 9, "dpi": 300, "bbox": [375, 57, 693, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Despite the noisy trajectories, we recovered clear movement patterns related to highway (bold black lines) traf- fic. The two vector fields correspond to the clusters in Fig. 9. ", "caption_bbox": [390, 385, 693, 428]}, {"image_id": 9, "file_name": "561_09.png", "page": 9, "dpi": 300, "bbox": [57, 57, 378, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The anonymized call detail records for over 370,000 cell phone calls produced noisy trajectories around a suburban city. Two of the four clusters computed are shown. ", "caption_bbox": [57, 384, 361, 427]}], "562": [{"image_id": 0, "file_name": "562_00.png", "page": 1, "dpi": 300, "bbox": [58, 341, 696, 484], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Novel visual data exploration method using Small Multiples. Users alternate between Large Singles and Small Multiples for comparison and guidance during exploration using a filmstrip metaphor. ", "caption_bbox": [58, 494, 691, 522]}, {"image_id": 1, "file_name": "562_01.png", "page": 6, "dpi": 300, "bbox": [58, 55, 693, 477], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Graphical user interface: The menu (B) on top of the large single (A) shows different parameters that can be selected to produce small multiples. Hovering over the menu items provides information on the current value such as what attribute is mapped to color, or what is shown on the x-axis for example. (C) Items are highlighted across all visualizations, identical to standard brushing and linking mechanisms in multiple coordinated view systems. A user-adjustable radius around the mouse cursor determines what items are highlighted. The number of highlighted items in the current visualization is shown in the upper right corner, along with total number of items in the visualization and total number of items in the data-set. (D) Information on parameter that is split on. Also, multiples can be sorted based on parameter value or number of items contained in each small multiple. (E-G) Navigation mechanism to explore visual history trail. (H) Undo, redo and reset exploration options. (I) Legend with color and size information of small multiple visualization currently hovered. ", "caption_bbox": [58, 488, 691, 623]}, {"image_id": 2, "file_name": "562_02.png", "page": 7, "dpi": 300, "bbox": [62, 55, 378, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Four different tested interaction methods involving combinations of Small Multiples and Visual History. ", "caption_bbox": [58, 313, 359, 341]}, {"image_id": 3, "file_name": "562_03.png", "page": 9, "dpi": 300, "bbox": [375, 55, 693, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Interaction method user preference.", "caption_bbox": [423, 215, 655, 228]}], "563": [{"image_id": 0, "file_name": "563_00.png", "page": 1, "dpi": 300, "bbox": [58, 562, 693, 776], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Different bar charts for visualizing data with large value range. Half lives of different plutonium isotopes (see Sect. 6.1) are visualized with: (a) classic linear bar chart, (b) linear bar chart with cut-off bars, (c) linear bar chart with scale break, (d) logarithmic bar chart, and (e) our novel scale-stack bar chart. ", "caption_bbox": [59, 498, 692, 541]}, {"image_id": 1, "file_name": "563_01.png", "page": 3, "dpi": 300, "bbox": [77, 57, 693, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of our concept. (a) Every row (delimited by bold lines) covers a complete scale; the bars always start at 0 in every row. Inside each scale, a linear mapping is used. (b) Because of this mapping, our method can be used to display stacked bars. (c) For negative values, the chart is extended downward as it is also a common approach with classic bar charts. ", "caption_bbox": [59, 273, 692, 316]}, {"image_id": 2, "file_name": "563_02.png", "page": 4, "dpi": 300, "bbox": [60, 57, 676, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Variations of our method. (a) Nearby values may be mapped to different scales (e.g., B and C). This makes their comparison difficult. (b) Displaying the values on multiple scales avoids this problem. The values of B and C can now be compared on the second scale. In this case, the values are shown on all scales that cover the full value range. (c) Dashed lines can be used as placeholders to show that a value exceeds the range of the respective scale. ", "caption_bbox": [59, 274, 692, 333]}, {"image_id": 3, "file_name": "563_03.png", "page": 5, "dpi": 300, "bbox": [64, 399, 685, 551], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Results of the user study. Boxplots show the distribution of the measured answer times with linear (\"Lin.\"), logarith- mic (\"Log.\"), and scale-stack (\"Sca.\") bar charts for all tasks ((a)\u2013(c)), and the error rate distribution for tasks 1 and 2 ((d), (e)). Red dots represent average values. If they are not visible, the average values exceed the scale. For the discrete results (correct or incorrect) of task 3, the percentage of wrong answers is shown in a bar chart (f). In all charts, lower values are better. ", "caption_bbox": [59, 564, 692, 623]}, {"image_id": 4, "file_name": "563_04.png", "page": 6, "dpi": 300, "bbox": [60, 57, 670, 444], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualization of different growth behavior. (a) Our approach showing linear growth with three different slopes: y = 22x (blue), y = 831x (red), y = 2546x (green). (b) Our approach showing polynomial growth with three different degrees: y = x2 (blue), y = x4 (red), y = x8 (green). (c) Our approach showing exponential growth with three different bases: y = 2x (blue), y = 4x (red), y = 10x (green). The respective logarithmic plots are shown in (d)\u2013(f). The envelopes (illustrated by dashed lines) of the logarithmic charts for polynomial and exponential growth can be approximated in our scale-stack charts by connecting the last element of each row. The envelope for the blue bars in (e) is not shown due to the small number of sample points in (b). ", "caption_bbox": [58, 457, 691, 546]}, {"image_id": 5, "file_name": "563_05.png", "page": 8, "dpi": 300, "bbox": [375, 57, 694, 832], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Age structure of selected countries. The popula- tions are divided into three age groups (see legend). Stacked bar charts with absolute values are used to show not only the distribution but also the absolute size of the groups. The data is visualized with (a) linear, (b) logarithmic, and (c) scale-stack bar charts. ", "caption_bbox": [391, 845, 692, 934]}, {"image_id": 6, "file_name": "563_06.png", "page": 8, "dpi": 300, "bbox": [60, 57, 378, 832], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The half life of different isotopes released to the environment during the Chernobyl disaster visualized with (a) linear, (b) logarithmic, and (c) scale-stack bar charts. In all charts, the isotopes are ordered on the x-axis according to the activity released during the accident. The respective activity values are shown in (d) with scale-stack bars. The bars are colored to be better distinguishable. ", "caption_bbox": [58, 846, 359, 950]}, {"image_id": 7, "file_name": "563_07.png", "page": 9, "dpi": 300, "bbox": [375, 57, 694, 839], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Profits of AMD and Apple Inc. for the period from the first quarter of 2009 to the third of 2012, visualized with (a) linear, (b) logarithmic, and (c) scale-stack bar charts. ", "caption_bbox": [391, 852, 692, 895]}], "564": [{"image_id": 0, "file_name": "564_00.png", "page": 2, "dpi": 300, "bbox": [408, 362, 669, 520], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Seven basic gestalt laws of perception. For exam- ple, the law of continuity suggests that we tend to perceive two crossing rather than two touching            lines. ", "caption_bbox": [391, 535, 692, 581]}, {"image_id": 1, "file_name": "564_01.png", "page": 2, "dpi": 300, "bbox": [375, 57, 689, 248], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Ranking of perception accuracy (top-to-bottom) as a guideline for graphical mapping. Boxes indicate vari- ables irrelevant for the corresponding type of data. Redrawn from [Mac86]. ", "caption_bbox": [391, 278, 692, 337]}, {"image_id": 2, "file_name": "564_02.png", "page": 4, "dpi": 300, "bbox": [60, 57, 685, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Scatterplots of geyser eruption patterns showing waiting times (x-axis) versus subsequent eruption duration (y-axis) with colors indicating membership in cluster models (a),(b) and estimation error in regression model (c). The gestaltlines below show the actual sequence of eruptions using the same colors. ", "caption_bbox": [59, 264, 692, 307]}, {"image_id": 3, "file_name": "564_03.png", "page": 5, "dpi": 300, "bbox": [375, 57, 693, 255], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Net flow of people entering and leaving a build- ing [IHS06, FA10]. Each row represents a day, each column a 30 minute interval. The area of a dot is proportional to the maximum of the number of people entering and leaving the building within the corresponding half hour, whereas the color indicates the ratio of in- and out-flow on a color scale from red (in) via yellow (balanced) to blue (out). Horizontal background lines indicate known exceptional events taking place in the building. ", "caption_bbox": [391, 267, 692, 402]}, {"image_id": 4, "file_name": "564_04.png", "page": 6, "dpi": 300, "bbox": [399, 145, 685, 201], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualization and interpretation of participant decisions relative to a rational baseline. ", "caption_bbox": [391, 216, 692, 244]}, {"image_id": 5, "file_name": "564_05.png", "page": 7, "dpi": 300, "bbox": [375, 57, 693, 197], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Results for introductory question of user study (Section 4.4); Q1 \u201cPlease mark for each row the appropriate fields\u201d. Unexpected answers highlighted in red. ", "caption_bbox": [391, 202, 692, 245]}, {"image_id": 6, "file_name": "564_06.png", "page": 8, "dpi": 300, "bbox": [72, 131, 378, 937], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "C1  7.0 C2 11.7 C3 11.7 C4 14.1 C5 15.8 C6 16.9 C7 17.3 C8 18.3 C9 18.3 Ca 18.4 Cb 19.4 Cc 20.9 Figure 6: ", "caption_bbox": [103, 81, 294, 132]}, {"image_id": 7, "file_name": "564_07.png", "page": 9, "dpi": 300, "bbox": [110, 57, 693, 184], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Results for Q11 \u201cPlease divide the sequence into sub-sequences and label them with a brief description\u201d (irrational, rational, outliers, passive, active). Answers split into irrational vs. rational (left) and passive vs. active (right) with outliers highlighted. Top two rows indicate our predictions, others the actual answers (one row per subject). ", "caption_bbox": [59, 194, 692, 237]}], "565": [{"image_id": 0, "file_name": "565_00.png", "page": 3, "dpi": 300, "bbox": [73, 56, 378, 515], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: NVIDIA Visual Pro\ufb01ler for matrix transpose iden- ti\ufb01es existence of errors (marked in red) but not the source. ", "caption_bbox": [58, 519, 361, 547]}, {"image_id": 1, "file_name": "565_01.png", "page": 4, "dpi": 300, "bbox": [65, 666, 352, 860], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Breakdown of grid and block visualizations where: A is an indicator light highlighting difference; B represents indicator lights for block-to-block comparison; and C repre- sents indicator lights for warp-to-warp comparison. ", "caption_bbox": [57, 865, 361, 924]}, {"image_id": 2, "file_name": "565_02.png", "page": 5, "dpi": 300, "bbox": [77, 56, 693, 400], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Left: Warp visualizations for 3 version of matrix transpose. Right: The 4 associated operation visualizations show a mix of good quality global (d) and shared (g) transactions, as well as poor quality global (e) and shared (f) transactions. ", "caption_bbox": [58, 408, 691, 436]}, {"image_id": 3, "file_name": "565_03.png", "page": 5, "dpi": 300, "bbox": [72, 728, 347, 906], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The 4 metaphors used in the warp visualization.", "caption_bbox": [62, 910, 355, 923]}, {"image_id": 4, "file_name": "565_04.png", "page": 6, "dpi": 300, "bbox": [64, 657, 352, 860], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Breakdown of operation visualization where: A represents a discontinuity of address space; B shows a single coalesced transaction; C shows a underutilized transaction; and D shows a single bank transaction. ", "caption_bbox": [58, 865, 361, 924]}, {"image_id": 5, "file_name": "565_05.png", "page": 7, "dpi": 300, "bbox": [398, 702, 683, 844], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Diagram of banks used in shared memory matrix transpose. Left: The 16x16 matrix sub-blocks allow writing of data (blue) to be con\ufb02ict-free, while reading data produces con\ufb02icts (orange). Right: Padding each row with an unused element results in con\ufb02ict-free reads and writes. ", "caption_bbox": [390, 849, 691, 923]}, {"image_id": 6, "file_name": "565_06.png", "page": 8, "dpi": 300, "bbox": [60, 56, 674, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparative analysis shows little difference at the grid-level (a) but large difference at the block-level (b). Investigation of two warps (c) shows that the difference is that one warp remains active (top) while the other becomes inactive (bottom). ", "caption_bbox": [58, 385, 691, 413]}, {"image_id": 7, "file_name": "565_07.png", "page": 9, "dpi": 300, "bbox": [90, 461, 658, 760], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A comparison of a shared memory access on different architectures shows that some instructions ((c) and (e)) improve as expected while others do not ((d) and (f)). ", "caption_bbox": [58, 764, 691, 792]}, {"image_id": 8, "file_name": "565_08.png", "page": 9, "dpi": 300, "bbox": [87, 56, 693, 409], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A comparison of global memory access on different architectures shows that while the majority of memory transactions are similarly coalesced, some transactions will perform signi\ufb01cantly better on CUDA 1.2 (d) than on CUDA 1.0 (b). ", "caption_bbox": [58, 422, 691, 450]}], "566": [{"image_id": 0, "file_name": "566_00.png", "page": 2, "dpi": 300, "bbox": [456, 665, 627, 779], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Factor matrix properties: (1.1) spatial selectivity and (1.2) subsampling in the spatial dimension, (2) feature scale reduction along the rank dimension. ", "caption_bbox": [391, 786, 692, 833]}, {"image_id": 1, "file_name": "566_01.png", "page": 3, "dpi": 300, "bbox": [375, 57, 693, 197], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Factor-matrix subsampling by pair-wise row aver- aging generates a mipmapped factor matrix hierarchy. ", "caption_bbox": [391, 196, 692, 228]}, {"image_id": 2, "file_name": "566_02.png", "page": 3, "dpi": 300, "bbox": [65, 422, 361, 549], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration of spatial selectivity: A range of se- lected submatrix rows reconstructs a well defined subvolume (in brown) of the original whole dataset. ", "caption_bbox": [59, 550, 360, 597]}, {"image_id": 3, "file_name": "566_03.png", "page": 3, "dpi": 300, "bbox": [397, 793, 690, 871], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Illustration of a rank truncated reconstruction: Truncated factor matrices with corresponding fewer core tensor entries reconstruct at the full spatial resolution, but at a lower approximation, i.e., at a lower feature scale. ", "caption_bbox": [391, 873, 692, 936]}, {"image_id": 4, "file_name": "566_04.png", "page": 4, "dpi": 300, "bbox": [151, 217, 601, 504], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Factor matrix subsampling (bottom) compared to direct TA (center) derived from original subsampled datasets (top).", "caption_bbox": [59, 503, 690, 520]}, {"image_id": 5, "file_name": "566_05.png", "page": 4, "dpi": 300, "bbox": [60, 57, 586, 198], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Spatial selectivity: Selected bricks reconstructed by the corresponding selection of row-index factor matrix subranges.", "caption_bbox": [59, 197, 692, 214]}, {"image_id": 6, "file_name": "566_06.png", "page": 4, "dpi": 300, "bbox": [136, 524, 617, 682], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Progressive rank truncations (bottom row) compared to fixed rank-(R, R, R) TAs (top row).", "caption_bbox": [125, 681, 625, 698]}, {"image_id": 7, "file_name": "566_07.png", "page": 5, "dpi": 300, "bbox": [66, 252, 351, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Octree based on the mipmapped factor matrices.", "caption_bbox": [63, 425, 354, 442]}, {"image_id": 8, "file_name": "566_08.png", "page": 5, "dpi": 300, "bbox": [133, 665, 286, 771], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Processing the mipmapped initial global factor matrices in order to obtain orthogonal localized row-block submatrices and thus all-orthogonal per-brick core tensors. ", "caption_bbox": [59, 770, 360, 817]}, {"image_id": 9, "file_name": "566_09.png", "page": 7, "dpi": 300, "bbox": [87, 498, 330, 682], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Multiresolution and multiscale octree front (bold): The multiresolution front (dotted) is adjusted de- pending on (1) the minimum error octree front (prevent re- finement), and (2) the maximum error octree front (enforce refinement). ", "caption_bbox": [59, 685, 360, 763]}, {"image_id": 10, "file_name": "566_10.png", "page": 8, "dpi": 300, "bbox": [60, 57, 682, 197], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Different spatial resolution levels reconstructed from the mipmapped TA bases: (a-d) flower, (e-h) wood branch.", "caption_bbox": [68, 199, 683, 216]}, {"image_id": 11, "file_name": "566_11.png", "page": 8, "dpi": 300, "bbox": [62, 229, 357, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Visualization of an initial factor matrix U(1) of the hazelnut and its full resolution row-block SVD replacement   (1)                          (1) U\u21930 . Subsampled matrices U\u2193k are stretched to fit and value coded: brown (negative), white (zero), green (positive). ", "caption_bbox": [58, 313, 359, 379]}, {"image_id": 12, "file_name": "566_12.png", "page": 8, "dpi": 300, "bbox": [63, 475, 357, 570], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: A slice through the reconstructed flower dataset once without (a) and once with additional brick borders (b). ", "caption_bbox": [59, 572, 360, 604]}, {"image_id": 13, "file_name": "566_13.png", "page": 8, "dpi": 300, "bbox": [429, 409, 657, 572], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Mean normalized brick RMSEs for all octree lev- els of the hazelnut. The standard deviation of the errors is additionally indicated. ", "caption_bbox": [391, 572, 692, 619]}, {"image_id": 14, "file_name": "566_14.png", "page": 9, "dpi": 300, "bbox": [61, 57, 378, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Coupling of multiresolution and multiscalability by a feature scale metric (rank-based). The rank is color en- coded (red\u2013blue\u2013green bricks correspond to few-more-many ranks). The size of each brick indicates its spatial resolution. ", "caption_bbox": [59, 292, 360, 355]}, {"image_id": 15, "file_name": "566_15.png", "page": 9, "dpi": 300, "bbox": [375, 57, 693, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 17: Performance measurements of the flower render- ing. Time in ms per frame (top) as well as number of loaded and rendered blocks per frame (bottom). ", "caption_bbox": [391, 391, 692, 438]}], "567": [{"image_id": 0, "file_name": "567_00.png", "page": 4, "dpi": 300, "bbox": [58, 737, 362, 855], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A snapshot of the animation window. The particles are events in execution at a selected point in time. Processes 8-16 are mostly executing calls to MPI_Bcast, while the rest of the processes are waiting on long MPI_Recv operations. ", "caption_bbox": [59, 865, 360, 924]}, {"image_id": 1, "file_name": "567_01.png", "page": 4, "dpi": 300, "bbox": [106, 354, 314, 422], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Color mapping of the MPI function calls found in the traces. Some traces only contain a subset of these. ", "caption_bbox": [59, 436, 360, 464]}, {"image_id": 2, "file_name": "567_02.png", "page": 5, "dpi": 300, "bbox": [119, 606, 302, 792], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A section of the animation window showing both running and ended events. The transparency of a fading par- ticle indicates the time passed since the end of the event. ", "caption_bbox": [59, 803, 360, 846]}, {"image_id": 3, "file_name": "567_03.png", "page": 5, "dpi": 300, "bbox": [390, 403, 694, 525], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The history background image at the end of the matrix invert operation. The striations are due to the float precision limitation present in the traces. There are notice- able differences in the duration patterns of MPI Broadcast function calls across the processes. ", "caption_bbox": [391, 536, 692, 610]}, {"image_id": 4, "file_name": "567_04.png", "page": 6, "dpi": 300, "bbox": [427, 722, 656, 777], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Time line for the Cholesky Decomposition opera- tion on Franklin. Total duration is approximately 0.24 sec- onds. After the initialization stage, which is dominated by a spike in the number of calls to MPI_Bcast, communication activity drops to a relatively low level and remains constant for the duration of the execution. The slight increase in activ- ity in the middle indicates that this is a two-stage operation. ", "caption_bbox": [391, 787, 692, 891]}, {"image_id": 5, "file_name": "567_05.png", "page": 6, "dpi": 300, "bbox": [60, 57, 634, 184], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Common patterns revealed by our visualization. The four bottom segments labeled PGx encode four process groups. These patterns may occur both during the animation and in the background image. ", "caption_bbox": [59, 196, 692, 224]}, {"image_id": 6, "file_name": "567_06.png", "page": 6, "dpi": 300, "bbox": [401, 242, 684, 463], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The shifting \u201cgroup of 8\u201d pattern. In 6(a), the first 8 processes are performing short MPI_Bcast and MPI_Recv operations, while the other processes appear to be idle. In 6(b), the pattern shifts, with the next 8 processes working and the first waiting on long MPI_Recv operations. ", "caption_bbox": [391, 476, 692, 550]}, {"image_id": 7, "file_name": "567_07.png", "page": 7, "dpi": 300, "bbox": [390, 482, 694, 609], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The end of the Eigenproblem solving opera- tion on Franklin, with the pattern of very long MPI_Bcast calls visible. The background history image shows slightly noisy patterns in event durations across the processes. Most notable are the synchronization operations (calls to MPI_Waitall), which appear to have occurred at each stage within the 8-process groups. ", "caption_bbox": [391, 619, 692, 723]}, {"image_id": 8, "file_name": "567_08.png", "page": 7, "dpi": 300, "bbox": [467, 80, 619, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The first \u201cgroup of 8\u201d in the Eigenproblem solv- ing operation. Only currently running or recently ended (fading) events are shown here. The background history was cleared prior to taking this snapshot. ", "caption_bbox": [391, 239, 692, 298]}, {"image_id": 9, "file_name": "567_09.png", "page": 7, "dpi": 300, "bbox": [95, 653, 325, 705], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Time line of the ScalaPACK parallel Eigenprob- lem solving operation running on the Franklin system. ", "caption_bbox": [59, 715, 360, 743]}, {"image_id": 10, "file_name": "567_10.png", "page": 7, "dpi": 300, "bbox": [104, 330, 317, 464], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Linear delay patterns present in the Cholesky De- composion trace. Similar patterns can be observed in the Matrix Inversion operation, in Figure 2. ", "caption_bbox": [59, 475, 360, 518]}, {"image_id": 11, "file_name": "567_11.png", "page": 8, "dpi": 300, "bbox": [424, 300, 663, 486], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Time lines of the matrix multiplication operation. The communication spikes are where the computation starts. ", "caption_bbox": [391, 499, 692, 527]}, {"image_id": 12, "file_name": "567_12.png", "page": 8, "dpi": 300, "bbox": [60, 57, 378, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Both functions execute in five stages, with a log- arithmic decrease in the number of MPI calls during each phase. This logarithmic falloff indicates that, as processes finish their computation for a particular stage, they send their data to the next processes and no longer communicate until the next phase starts. Each phase is shorter than the previous one because there is less data to perform computa- tions on, as is the nature of divide and conquer algorithms. syevd also appears to have a large temporal gap between the end of computation and communication and the final clean- up and conclusion of the run. Because Kraken is a system available for use, this is likely caused by other running ap- plications interfering with inter-node communication. ", "caption_bbox": [59, 265, 360, 461]}, {"image_id": 13, "file_name": "567_13.png", "page": 9, "dpi": 300, "bbox": [153, 596, 598, 775], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: For the 16,384 process trace, we reduced the size of the particles to minimize the over-plotting of active events. Large-scale logarithmic trends in particle positions are present, indicating delays in event start time across processes. ", "caption_bbox": [59, 785, 692, 813]}, {"image_id": 14, "file_name": "567_14.png", "page": 9, "dpi": 300, "bbox": [154, 339, 598, 518], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: The same trace as Figure 14 during a communication spike. The log curve of MPI_Recv operations continues to shift toward the right until the end of the execution. Unlike the smaller runs where events of the same types had roughly the same durations, event durations are more spread out and irregular here. This could be due to load imbalances or, to a lack of sufficient data for the number of processes used, or to the increased communication overhead present at these larger scales. ", "caption_bbox": [59, 528, 692, 587]}, {"image_id": 15, "file_name": "567_15.png", "page": 9, "dpi": 300, "bbox": [154, 81, 597, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Matrix multiplication on 4,096 processes, at the end of the communication groups\u2019 setup phase. There is an inter- esting pattern visible here: processes appear to take turns executing MPI_Send, MPI_Recv and MPI_Reduce operations. In particular, the MPI_Recv operations take longer to execute the higher the process ID. Globally, the operation appears to have been initiated by process #0 and each process had to wait for the previous one to receive its data. ", "caption_bbox": [59, 271, 692, 330]}], "568": [{"image_id": 0, "file_name": "568_00.png", "page": 4, "dpi": 300, "bbox": [60, 57, 659, 494], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A toy example of a discretized scalar field with just 2 grid points and an ensemble consisting of L = 50 realizations. Depicted are joint distributions of the random variables Y1 ,Y2 . The subfigures (a-e) visualize nonparametric distributions, while subfigure (f) shows a parametric Gaussian distribution for comparison: (a) empirical distribution, depicted by linear interpolants (each line shows a sample); (b) empirical distribution, depicted as scatterplot; eigenvectors of the covariance matrix displayed in light blue; (c) 2D histogram; (d) KDE using a Gaussian kernel; (e) KDE using a Gaussian kernel and principal components transformation. Note that the PDF in (e) represents the correlation of the data better than that in (d). ", "caption_bbox": [58, 502, 691, 591]}, {"image_id": 1, "file_name": "568_01.png", "page": 6, "dpi": 300, "bbox": [60, 57, 656, 421], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) A single member of the scalar field ensemble displayed as a heightmap with an isoline. Color mapped level cross- ing probabilities computed from (b) the empirical distributions, (c) histograms, (d) kernel density estimates with untransformed data and (e) kernel density estimates working with PC transformation. The isoline of the mean field is shown in black. (f) For comparison: Level crossing probabilities computed using a parametric Gaussian model. ", "caption_bbox": [59, 435, 692, 494]}, {"image_id": 2, "file_name": "568_02.png", "page": 6, "dpi": 300, "bbox": [92, 511, 328, 662], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: 1D marginal distributions, red: empirical distri- bution, blue: histogram, yellow: normal distribution (para- metric model), violet: kernel density estimate ", "caption_bbox": [59, 671, 360, 714]}, {"image_id": 3, "file_name": "568_03.png", "page": 7, "dpi": 300, "bbox": [56, 57, 695, 468], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Level crossing probabilities (\u03d1 = 24\u25e6 C) in the 2 meter temperature field from a climate simulation of the DEMETER project [Pal04] are mapped to color. The results were computed using (a) empirical distributions, (c) KDE and (d) a paramet- ric Gaussian model. The results of vertex-wise Shapiro-Wilk tests (p-values) are visualized in (b). The regions with the most significant differences between (c) and (d) are highlighted by white boxes. ", "caption_bbox": [59, 473, 692, 536]}, {"image_id": 4, "file_name": "568_04.png", "page": 8, "dpi": 300, "bbox": [60, 57, 683, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Probabilities for the existence of critical points in the wall shear stress field on the vessel and aneurysm wall employing (a) empirical distributions, (b) KDE and (c) parametric Gaussian models. The mean vector field is shown using LIC. ", "caption_bbox": [59, 320, 692, 348]}, {"image_id": 5, "file_name": "568_05.png", "page": 8, "dpi": 300, "bbox": [58, 357, 694, 727], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Probabilities for the existence of vortex cores in the blood flow velocity field are displayed using nested isosurfaces (top row). 2D slices through the probability fields in the dome region are shown in the second row. The probabilities were computed using (a) empirical distributions, (b) KDE and (c) a parametric Gaussian model. ", "caption_bbox": [59, 740, 692, 783]}, {"image_id": 6, "file_name": "568_06.png", "page": 9, "dpi": 300, "bbox": [392, 257, 692, 404], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Schematic diagram for the model selection task for ensemble data. ", "caption_bbox": [391, 410, 692, 438]}, {"image_id": 7, "file_name": "568_07.png", "page": 9, "dpi": 300, "bbox": [61, 57, 696, 198], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Level crossing probabilities for the pressure field on the vessel and aneurysm wall are mapped to color. The proba- bilities were computed using (a) empirical distributions, (b) KDE and (c) a parametric Gaussian model. ", "caption_bbox": [59, 212, 692, 240]}], "569": [{"image_id": 0, "file_name": "569_00.png", "page": 1, "dpi": 300, "bbox": [58, 484, 693, 758], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Four quite different fiber probability distributions (a) lead to the same cones of uncertainty (b), a current standard visualization of variability in fiber directions. We propose a novel glyph that highlights the differences between them (c). ", "caption_bbox": [59, 448, 692, 476]}, {"image_id": 1, "file_name": "569_01.png", "page": 5, "dpi": 300, "bbox": [61, 57, 378, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: While high diffusion tensor linearity cl predicts high precision of the principal eigenvector, precision be- comes much more variable when cl < 0.2. (a) and (b) show cases with similar cl , but quite different precision (from left to right: diffusion tensor, density estimate, HiFiVE glyph). ", "caption_bbox": [59, 231, 360, 305]}, {"image_id": 2, "file_name": "569_02.png", "page": 5, "dpi": 300, "bbox": [377, 57, 693, 170], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The fiber PDF (a) is better approximated with sharper cosine kernels (m = {2, 3, 4} in (d)\u2013(f)) than with a simple square-of-cosine (c) or a cone of uncertainty (b). ", "caption_bbox": [391, 176, 692, 219]}, {"image_id": 3, "file_name": "569_03.png", "page": 6, "dpi": 300, "bbox": [60, 57, 378, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: While the HiFiVE glyph still depends on the ran- dom seed for N = 100, it has stabilized at N = 1000. A plot of relative differences confirms convergence. ", "caption_bbox": [59, 316, 360, 359]}, {"image_id": 4, "file_name": "569_04.png", "page": 6, "dpi": 300, "bbox": [378, 57, 673, 152], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Our HiFiVE glyph combines double-ended cones that indicate the main direction with a spherical plot of the residual (a). Cylinders would either make poor use of screen space, or occlude too much of the residual (b). ", "caption_bbox": [391, 158, 692, 217]}, {"image_id": 5, "file_name": "569_05.png", "page": 7, "dpi": 300, "bbox": [72, 57, 693, 491], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Using HiFiVE glyphs to visualize the probability distributions estimated by different bootstrapping techniques con- firms that they produce very similar PDF shapes and thus contributes to their validation. ", "caption_bbox": [59, 496, 692, 524]}, {"image_id": 6, "file_name": "569_06.png", "page": 8, "dpi": 300, "bbox": [378, 57, 692, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Optimizing the gradient directions to achieve lower echo time (TE) slightly improves precision, at the cost of making variance dependent on the fiber direction. ", "caption_bbox": [391, 299, 692, 342]}, {"image_id": 7, "file_name": "569_07.png", "page": 8, "dpi": 300, "bbox": [60, 57, 378, 227], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: All bootstrapping methods estimate a large num- ber of voxels in which eigenvectors have high precision. Adding Rician noise leads to a less peaked distribution. ", "caption_bbox": [59, 243, 360, 286]}, {"image_id": 8, "file_name": "569_08.png", "page": 9, "dpi": 300, "bbox": [69, 57, 693, 429], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Even though multi-tensor models and constrained deconvolution produce similar results overall, HiFiVE glyphs highlight regions in which one model performs better than the other. ", "caption_bbox": [59, 435, 692, 463]}], "570": [{"image_id": 0, "file_name": "570_00.png", "page": 2, "dpi": 300, "bbox": [60, 57, 681, 216], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualizing the performance of an algorithm against different input sizes using conventional line graphs, including (a) runtime, (b) memory usage and (c) energy measurements. (d) Shows a design sketch of a complexity plot with complexity classes as the x-axis, and input size n as the y-axis. ", "caption_bbox": [59, 230, 692, 274]}, {"image_id": 1, "file_name": "570_01.png", "page": 2, "dpi": 300, "bbox": [394, 285, 696, 429], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A set of algorithmic measures are shown in a linear line graph (a) and a logarithmic plot (b). The complexity of the 9th algorithm is unknown (black dotted line) and is difficult to estimate in either (a) or (b). As the O(n2 ) (pink line) has a very large constant component, it is not shown in (a), and its complexity cannot be observed in (b) easily. ", "caption_bbox": [391, 443, 692, 532]}, {"image_id": 2, "file_name": "570_02.png", "page": 4, "dpi": 300, "bbox": [60, 57, 680, 205], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The convergence rate of four main estimators on four different algorithms. The x-axis shows the problem (input) size, and the y-axis shows the output values returned by different estimators. ", "caption_bbox": [59, 219, 692, 247]}, {"image_id": 3, "file_name": "570_03.png", "page": 5, "dpi": 300, "bbox": [375, 57, 698, 219], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The convergence patterns of two estimators, E1 and E4, when they are applied to the Knapsack algorithm and an O(n2 ) algorithm respectively. We show the variation with four different windows sizes \u03b7 = 10, 20, 50, max, where max is the special maximum window size. ", "caption_bbox": [391, 233, 692, 307]}, {"image_id": 4, "file_name": "570_04.png", "page": 6, "dpi": 300, "bbox": [60, 57, 700, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Elements of the complexity plot visual design. (a) Comparison of three algorithms\u2019 complexities. (b) Comparing the convergence of two estimators for an algorithm. (c) Conveying uncertainty in the visualization through opacity. (d) Comparing an algorithm plotted using estimations of varying window sizes. ", "caption_bbox": [59, 316, 692, 360]}, {"image_id": 5, "file_name": "570_05.png", "page": 6, "dpi": 300, "bbox": [398, 390, 683, 593], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Our final visual design, showing three algorithms (green, orange, purple) analyzed by two estimators each. ", "caption_bbox": [391, 605, 692, 633]}, {"image_id": 6, "file_name": "570_06.png", "page": 7, "dpi": 300, "bbox": [424, 332, 657, 746], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparing (a) varying quality settings for an ffm- peg encode; (b) a set of lossless file compression algorithms. ", "caption_bbox": [391, 760, 692, 788]}, {"image_id": 7, "file_name": "570_07.png", "page": 7, "dpi": 300, "bbox": [66, 57, 693, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Complexity plots for a variety of algorithms. (a) A number of sorting algorithms with different runtime complexities. (b) Complexity of insertion sort with different data ordering. (c) Complexity of the brute-force Knapsack algorithm. ", "caption_bbox": [58, 275, 691, 303]}, {"image_id": 8, "file_name": "570_08.png", "page": 8, "dpi": 300, "bbox": [60, 57, 669, 581], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Different complexities compared for various cases. (a) Combined visualization of storage, runtime and energy com- plexities. (b) Comparison of runtime and energy complexities for MMIJK and MMIKJ versions. (c) Different complexities of MMIJK compared across two different hardware platforms. (d) Comparing runtime/energy complexities of IKJ against a highly-optimized vendor library (IMKL). ", "caption_bbox": [59, 595, 692, 654]}], "571": [{"image_id": 0, "file_name": "571_00.png", "page": 2, "dpi": 300, "bbox": [59, 57, 378, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The mass spectrum of an aerosol represents a pat- tern (coordinates) that quanti\ufb01es the abundance of inher- ent fragment ions (peak labels) per mass (dimensions). Data factorization provides lower-dimensional representations of aerosols in terms of latent components of these patterns. ", "caption_bbox": [59, 245, 360, 320]}, {"image_id": 1, "file_name": "571_01.png", "page": 3, "dpi": 300, "bbox": [58, 57, 378, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Previous work visualizes the errors produced by SPMS data factorization in high detail. Due to data com- plexity and dimensionality, this representation is prone to vi- sual clutter and fails to provide an overview to analysts who are faced with the problem of identifying, classifying, and analyzing error features. ", "caption_bbox": [59, 245, 360, 335]}, {"image_id": 2, "file_name": "571_02.png", "page": 5, "dpi": 300, "bbox": [395, 789, 690, 850], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: By utilizing a measure of error regularity (left: regular \u2192 0, right: irregular \u2192 1), the presence of dominant features in errors can be quanti\ufb01ed, allowing for a visual assessment of noise level. ", "caption_bbox": [391, 865, 692, 925]}, {"image_id": 3, "file_name": "571_03.png", "page": 6, "dpi": 300, "bbox": [60, 57, 672, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An overview of factorization errors is achieved by projecting errors based on magnitude (vertical axis) and irregu- larity (horizontal axis). Further classi\ufb01cation of error types is provided by color (similarity) and density contours (abundance). ", "caption_bbox": [59, 311, 692, 340]}, {"image_id": 4, "file_name": "571_04.png", "page": 8, "dpi": 300, "bbox": [375, 57, 691, 209], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The numerical gain in introducing basis candi- dates minimizing speci\ufb01c errors is depicted in relation to the previous basis con\ufb01guration (red = decrease). Sub-optimal parts of the factorization exhibit a smaller gain than the ana- lysts candidate ((a) and (c)). The analyst can add the candi- date to the basis, delete existing parts, or continue analysis. ", "caption_bbox": [391, 221, 692, 311]}, {"image_id": 5, "file_name": "571_05.png", "page": 8, "dpi": 300, "bbox": [78, 581, 342, 778], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Errors of the factorization of Pittsburgh source sampling data, June-July, 2002. Selecting errors by color and/or region in the projection (center, also shown in Figure 4(c)) effectively \ufb01lters high-level views and, thereby, makes possible a detailed data analysis by uncovering errors of high (right) or low (left) irregularity, magnitude, maxima of abundance (bottom right), and provides further classi\ufb01ca- tions by color. Red (bottom left), green (top left), and blue (top right) error clusters are selected. ", "caption_bbox": [59, 789, 360, 925]}, {"image_id": 6, "file_name": "571_06.png", "page": 9, "dpi": 300, "bbox": [66, 57, 378, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) Controlled re\ufb01nement of the factorization pro- duced a decrease of the overall error by 21.5% in relation to the initial solution. (b) Further decrease was achieved by increasing the basis dimensionality, here accounting for an overall error of 14.8% in relation to the original data. ", "caption_bbox": [59, 261, 360, 336]}], "572": [{"image_id": 0, "file_name": "572_00.png", "page": 4, "dpi": 300, "bbox": [58, 57, 694, 456], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Interface: (a) Workspace Pane, (b) Method Pane, (c) Heat Map Pane, (d) Plot Pane, (e) Favourites Pane.", "caption_bbox": [92, 468, 658, 481]}, {"image_id": 1, "file_name": "572_01.png", "page": 5, "dpi": 300, "bbox": [82, 580, 339, 625], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Profile plot views: (a) mean +/- standard devia- tion, (b) continuous box plot, (c) mean and signal scatter, (d) mean and peak scatter, and (e) summary plot. ", "caption_bbox": [59, 637, 360, 681]}, {"image_id": 2, "file_name": "572_02.png", "page": 5, "dpi": 300, "bbox": [375, 57, 693, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Method Panes: (a) Signal Query (b) Cluster (c) Comparison. ", "caption_bbox": [391, 400, 692, 428]}, {"image_id": 3, "file_name": "572_03.png", "page": 7, "dpi": 300, "bbox": [375, 57, 693, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Analysis 1: Comparison Pane is used to exclude regions in which only one mark out of four showed a signal. ", "caption_bbox": [391, 383, 692, 411]}, {"image_id": 4, "file_name": "572_04.png", "page": 8, "dpi": 300, "bbox": [59, 498, 361, 647], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: k-means clustering of the set shown in Figure 5. The unimodal distribution of H3K4me1_C1 and H4ac_C1 is highlighted with a border. ", "caption_bbox": [59, 659, 360, 703]}, {"image_id": 5, "file_name": "572_05.png", "page": 8, "dpi": 300, "bbox": [59, 140, 361, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Signal Query Pane used in Case Study 1. Numbers correspond to the observations in Analysis 2. ", "caption_bbox": [59, 294, 360, 322]}, {"image_id": 6, "file_name": "572_06.png", "page": 8, "dpi": 300, "bbox": [394, 345, 684, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Heat map sorted by CpG. This figure is a direct PDF export from the tool. ", "caption_bbox": [391, 551, 692, 579]}, {"image_id": 7, "file_name": "572_07.png", "page": 9, "dpi": 300, "bbox": [59, 57, 378, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Clustering by H3K4me3 and 5-hmC into four clus- ters. A cluster with a high level of H3K4me3 and 5-hmC, but low level of 5-mC is highlighted with a border (top cluster). ", "caption_bbox": [59, 272, 360, 316]}, {"image_id": 8, "file_name": "572_08.png", "page": 9, "dpi": 300, "bbox": [59, 479, 361, 605], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: k-means clustering by H3K4me3 and H3K27me3 into three clusters. A cluster with low levels of both 5-mC and 5-hmC is highlighted with a border (top cluster). ", "caption_bbox": [59, 617, 360, 661]}], "573": [{"image_id": 0, "file_name": "573_00.png", "page": 4, "dpi": 300, "bbox": [68, 470, 351, 622], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Alert Monitor of the Crew Tracking Enterprise software by Jeppesen Systems AB. A linked view of prob- lem list and time line with pictographs allows brushing and linking. (Image courtesy of Jeppesen Systems AB) ", "caption_bbox": [58, 632, 359, 691]}, {"image_id": 1, "file_name": "573_01.png", "page": 4, "dpi": 300, "bbox": [59, 57, 378, 364], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Problem Desk of the NetLine Crew software by Lufthansa Systems AG [GST05, H\u00f6s09]. All current prob- lems are listed in a tabular view which enables sorting and filtering for different dimensions like problem ID or problem time. (Image courtesy of Lufthansa Systems AG) ", "caption_bbox": [58, 375, 359, 449]}, {"image_id": 2, "file_name": "573_02.png", "page": 4, "dpi": 300, "bbox": [399, 375, 685, 661], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Three-dimensional Problem Desk developed by H\u00f6sel [H\u00f6s09]. All airports are circularly arranged in seg- ments. Time is running perpendicular to this disk. The prob- lems at one airport are represented by \u201cneedles\u201d above the airport\u2019s segment. The size of a segment is determined by the number of problems at the respective airport. Hierarchi- cal connections between the problems are indicated by lines connecting the respective problems. ", "caption_bbox": [391, 671, 692, 791]}, {"image_id": 3, "file_name": "573_03.png", "page": 5, "dpi": 300, "bbox": [401, 375, 683, 428], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visualization of problems as boxes. (a) The box of a problem consists of three rows. Problem ID, airport code, and problem time are indicated in the first row. The prob- lem type description is shown in the second row. (b) Severity of each problem is color-coded in a small bar at the bot- tom of the box using five discrete colors from white over yel- low to red. (c) Similar problems with equal problem time are grouped into one box. A grey marker on the right side indi- cates the number of problems. ", "caption_bbox": [391, 436, 692, 571]}, {"image_id": 4, "file_name": "573_04.png", "page": 6, "dpi": 300, "bbox": [59, 57, 684, 352], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Annotated screen shot of VisRuption showing a serious problem situation with 1,000 problems. The visible time span is set to seven hours and hierarchies are sorted with respect to airport. ", "caption_bbox": [58, 363, 691, 391]}, {"image_id": 5, "file_name": "573_05.png", "page": 6, "dpi": 300, "bbox": [398, 534, 685, 583], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Problem boxes for the same problem but with dif- ferent relative points in time: (a) problem time in the lower third of the desk, (b) problem time in the middle third, (c) problem time even further away. ", "caption_bbox": [391, 591, 692, 650]}], "574": [{"image_id": 0, "file_name": "574_00.png", "page": 2, "dpi": 300, "bbox": [58, 57, 691, 325], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The maximum entropy 56-node summary tree of the math genealogy tree rooted at Carl Friedrich Gauss, which has 43,527 equal-weighted nodes (where the original advisor-student graph was forced to be a tree by choosing the primary advisor for each student who had multiple advisors). Node colors are determined by their depth-1 ancestor, and node areas are proportional to their weights in the summary tree. This tree is best viewed on a computer screen. ", "caption_bbox": [59, 354, 692, 413]}, {"image_id": 1, "file_name": "574_01.png", "page": 4, "dpi": 300, "bbox": [375, 57, 687, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: In the upper panel, a 9-node tree (with node weights in parentheses), and below it, two different 6-node summary trees of the original 9-node tree, with their en- tropies (to be defined in Section 5) included. ", "caption_bbox": [391, 340, 692, 399]}, {"image_id": 2, "file_name": "574_02.png", "page": 6, "dpi": 300, "bbox": [58, 57, 378, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The subtree, Tv , for which we illustrate the defini- tion of gv (l, k, w), for l = 4, k = 5, w = 36 (and d = 6). Node weights are listed in parentheses. The upper figure is Tv , and the lower figure shows the maximum entropy summary forest for Tv1 \u222a \u00b7 \u00b7 \u00b7 \u222a Tv4 for k = 5 with an \u201cother\" child of v of size w = 36 within the dashed box (where we chose the \u201cother\" child Sv = {1, 3}). ", "caption_bbox": [58, 270, 359, 375]}, {"image_id": 3, "file_name": "574_03.png", "page": 7, "dpi": 300, "bbox": [62, 57, 693, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The maximum entropy 60-node summary tree of a company organizational chart that has 43,134 equal-weighted nodes. Nodes are labeled 1 through n = 43, 134, node colors are determined by their depth-1 ancestor, and node areas are proportional to their weights in the summary tree, which are labeled in parentheses, except summary tree nodes with weight 1, where the node is drawn transparently with a dotted outline. ", "caption_bbox": [59, 294, 692, 353]}, {"image_id": 4, "file_name": "574_04.png", "page": 8, "dpi": 300, "bbox": [375, 57, 693, 438], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Three summary trees of the 19,335-node web traf- fic tree. The upper figure is a naive aggregation to depth 2, where the node weights are heavily skewed. The middle fig- ure is the maximum entropy 32-node summary tree, which displays much more information given the same number of nodes. The bottom figure is the maximum entropy 60-node summary tree, which provides an even finer-grained view of the structure of clicks across the taxonomy of the web portal. We color the nodes according to their depth-2 ancestor, and we draw their sizes proportional to their weights. ", "caption_bbox": [391, 450, 692, 600]}, {"image_id": 5, "file_name": "574_05.png", "page": 9, "dpi": 300, "bbox": [59, 618, 361, 762], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Entropy profiles for k = 1, ..., 100 for all 5 data sets. For the web traffic and hard drive data sets, the (ap- proximate) maximum entropy summary trees have nearly as high entropy as the original trees using many fewer nodes. ", "caption_bbox": [59, 779, 360, 838]}], "575": [{"image_id": 0, "file_name": "575_00.png", "page": 3, "dpi": 300, "bbox": [390, 303, 692, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An overview of the framework for analyzing set relations. Left: glyphs integrated with a node-link diagram. Right: set visualization over item clusters. The example of publication dataset is used for illustration. Three nodes are selected on the left, and the items in the sets are depicted by visual links on the left. ", "caption_bbox": [390, 436, 691, 525]}, {"image_id": 1, "file_name": "575_01.png", "page": 4, "dpi": 300, "bbox": [72, 670, 346, 771], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Design choices for glyphs encoding set relations and social distances for each node to all the other nodes in the social graph. (a)scatterplot; (b) grayscale stacked his- togram; (c) stacked graph. ", "caption_bbox": [58, 783, 359, 842]}, {"image_id": 2, "file_name": "575_02.png", "page": 5, "dpi": 300, "bbox": [375, 57, 693, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Formation and simplification of a backbone span- ning tree: (a) hierarchical agglomerative clustering of the items based on their euclidean distances in the initial MDS layout; (b) the nodes are grouped based on a cut on the hierarchy, the spanning tree are simplified (by reducing branches) based on the grouping, where the dashed lines are new edges; (c) the resulting branches on the spanning tree are straightened by moving the items, where the dashed lines indicate an approximate shape of the backbone span- ning tree. ", "caption_bbox": [390, 405, 691, 555]}, {"image_id": 3, "file_name": "575_03.png", "page": 6, "dpi": 300, "bbox": [72, 574, 345, 687], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The simplified and smoothed spanning tree are divided into segments (where there are no branches). In each segment, continuous lines are used to connect the items in the same sets. ", "caption_bbox": [58, 698, 359, 757]}, {"image_id": 4, "file_name": "575_04.png", "page": 6, "dpi": 300, "bbox": [375, 57, 678, 181], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The intermediate and the final results of the layout algorithm: (a) the initial spanning tree connecting all the items and the backbone spanning tree after the first phase of the algorithm is performed; (b) the visual links for individual sets drawn based on the backbone spanning tree. ", "caption_bbox": [390, 193, 691, 267]}, {"image_id": 5, "file_name": "575_05.png", "page": 6, "dpi": 300, "bbox": [404, 350, 678, 580], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Subgraphs from the last.fm social network with glyphs. There are two observations: 1) in general, a larger distance in the social network implies less overlap in inter- ests; and 2) two groups of persons marked by the rectangles exhibit different properties on the amount of interest over- laps. The effect of homophily is more noticeable in group B. ", "caption_bbox": [390, 590, 691, 679]}, {"image_id": 6, "file_name": "575_06.png", "page": 7, "dpi": 300, "bbox": [89, 57, 693, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Interest overlap of close neighbors in the last.fm social network. The three persons are mutually connected to each other. However, one person has drastic difference in his interest from the other two. The others have a lot of interest overlaps in several clusters of similar music artists. ", "caption_bbox": [58, 372, 691, 415]}, {"image_id": 7, "file_name": "575_07.png", "page": 8, "dpi": 300, "bbox": [58, 57, 378, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Interest overlap on the academic collaboration network. Two observations are: 1) there are strongly con- nected communities with a higher level of locality of keyword distribution and 2) there are some outlier nodes having many keyword overlaps even with distant nodes. ", "caption_bbox": [58, 349, 359, 423]}, {"image_id": 8, "file_name": "575_08.png", "page": 9, "dpi": 300, "bbox": [94, 57, 693, 853], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Interest overlap of three authors in an academic collaboration network. Three authors (i.e., Peter Pirolli, George W. Furnas and Marti Hearst) are selected from the social network. They are at different social distances from each other. (a) and (b) show the results with two different MDS layouts respectively. ", "caption_bbox": [58, 866, 691, 909]}], "576": [{"image_id": 0, "file_name": "576_00.png", "page": 3, "dpi": 300, "bbox": [64, 57, 693, 599], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: All attention-guiding video visualizations applied to the i-LIDS dataset for AVSS 2007 [AVS07] (street with cars) and to the i-LIDS multi-camera tracking scenario [i-L10] (area with people). ", "caption_bbox": [59, 610, 692, 638]}, {"image_id": 1, "file_name": "576_01.png", "page": 4, "dpi": 300, "bbox": [375, 57, 657, 156], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The top-down map is generated by two steps: (i) application of a perspective transformation to the video background and (ii) manual modifications of the trans- formed image. ", "caption_bbox": [391, 167, 692, 226]}, {"image_id": 2, "file_name": "576_02.png", "page": 4, "dpi": 300, "bbox": [58, 57, 378, 163], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: In the force-directed visualization, overlapping bounding spheres repel each other along the line between their bottom-center points to avoid overlapping. ", "caption_bbox": [59, 174, 360, 217]}, {"image_id": 3, "file_name": "576_03.png", "page": 5, "dpi": 300, "bbox": [375, 57, 693, 197], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The cartoon figure appears several times in a video for a few seconds on existing people or cars. The par- ticipants have to find it and hit a buzzer to confirm. ", "caption_bbox": [391, 208, 692, 251]}, {"image_id": 4, "file_name": "576_04.png", "page": 7, "dpi": 300, "bbox": [71, 57, 378, 237], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: F1 -score: measured effectiveness for detection of changes (whiskers represent the lowest / highest values within one and a half times interquartile range to the me- dian, the mean is represented by red diamonds). ", "caption_bbox": [59, 248, 360, 307]}, {"image_id": 5, "file_name": "576_05.png", "page": 8, "dpi": 300, "bbox": [58, 57, 691, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Boxplots of the results of the questionnaire; bottom right: ranking of the participants for long-time observation (values represent Borda scores). ", "caption_bbox": [59, 398, 692, 426]}], "577": [{"image_id": 0, "file_name": "577_00.png", "page": 3, "dpi": 300, "bbox": [397, 696, 700, 854], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: High-level structure of evaluation library. The EvaluationManager controls the evaluation. The abstract EvaluationDelegate needs to be implemented to connect the library to the visualization artifact. ", "caption_bbox": [391, 872, 692, 931]}, {"image_id": 1, "file_name": "577_01.png", "page": 4, "dpi": 300, "bbox": [115, 705, 307, 870], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Data model for quantitative experiments. Con- creteQuestions need to host and process different data types according to the question type (e.g., multiple choice). ", "caption_bbox": [58, 887, 359, 931]}, {"image_id": 2, "file_name": "577_02.png", "page": 4, "dpi": 300, "bbox": [378, 57, 679, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Evaluation process. Simplified state machine that is run by the EvaluationManager during an evaluation. ", "caption_bbox": [391, 255, 692, 284]}, {"image_id": 3, "file_name": "577_03.png", "page": 5, "dpi": 300, "bbox": [107, 737, 314, 870], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: ViewFactory. Creates a view for a given task, whereas the QuestionStrategies provide a subview, set the answers, and check for sufficient input for each question. ", "caption_bbox": [58, 887, 359, 931]}, {"image_id": 4, "file_name": "577_04.png", "page": 5, "dpi": 300, "bbox": [430, 806, 655, 885], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: JournalFactory. Enables the configuration of var- ious journal implementations. ", "caption_bbox": [391, 902, 692, 930]}, {"image_id": 5, "file_name": "577_05.png", "page": 6, "dpi": 300, "bbox": [391, 502, 694, 875], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Task Definition in XML. Illustrative example with one task comprised of a multiple-choice question and a yes/no question. ", "caption_bbox": [391, 887, 692, 931]}, {"image_id": 6, "file_name": "577_06.png", "page": 6, "dpi": 300, "bbox": [58, 613, 355, 890], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Implementation of EvaluationDelegate. Frag- mentary example of an evaluation system. ", "caption_bbox": [58, 902, 359, 931]}, {"image_id": 7, "file_name": "577_07.png", "page": 7, "dpi": 300, "bbox": [61, 307, 359, 412], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Gallery of Question-answering Controls Pro- vided by EvalBench. ", "caption_bbox": [59, 425, 360, 453]}, {"image_id": 8, "file_name": "577_08.png", "page": 8, "dpi": 300, "bbox": [58, 57, 694, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: User Interface for Comparative Evaluation in [ARH12]. The visualization technique takes the larger part of the screen with the task view on the right (blue rectangle). The screenshot demonstrates an interval selection question, which the participants answer by brushing a time interval in the visualization (blue oval). ", "caption_bbox": [58, 301, 691, 345]}], "578": [{"image_id": 0, "file_name": "578_00.png", "page": 2, "dpi": 300, "bbox": [59, 57, 675, 527], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: EvoGraphDice prototype showing an exploration session of a synthetic dataset. New extensions to the GraphDice system are indicated by coloured label arrows. Widgets: (a) an overview scatterplot matrix showing the original data set of 5 dimensions (x0..x4) and the new dimensions (1..5) as suggested by the evolutionary algorithm. (b) main plot view. (c) tool bar for main plot view. (d) a tool bar with (top to bottom)\u201cfavorite\u201d toggle button, \u201cevolve\u201d button , a slider to evaluate cells and a restart (PCA) button. (e) the selection history tool. (f) the favorite cells window. (g) the selection query window. (h) IEA main control window. (i) window to limit the search space. (j) dimension editor. ", "caption_bbox": [59, 539, 692, 628]}, {"image_id": 1, "file_name": "578_01.png", "page": 3, "dpi": 300, "bbox": [375, 57, 694, 248], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Nine scagnostics measures from [WW08].", "caption_bbox": [408, 261, 674, 274]}, {"image_id": 2, "file_name": "578_02.png", "page": 5, "dpi": 300, "bbox": [393, 243, 693, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Two different solutions (screenshots of plots) for the training game problem (left) that involve a simple dimen- sion combination (middle) and a complex formula (right). ", "caption_bbox": [391, 367, 692, 410]}, {"image_id": 3, "file_name": "578_03.png", "page": 6, "dpi": 300, "bbox": [61, 379, 360, 503], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Confirmed findings (left and centre) and new in- sight found by the expert (right): a linear combination of four parameters that approximates customer consumption. ", "caption_bbox": [59, 511, 360, 554]}, {"image_id": 4, "file_name": "578_04.png", "page": 7, "dpi": 300, "bbox": [77, 627, 341, 758], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Selections of over-fit (red), best-fit (green) and under-fit (blue) parameter values (left), and (right) a finding by the expert showing a separation between the two groups of interest in relation to a new parameter. ", "caption_bbox": [59, 766, 360, 825]}, {"image_id": 5, "file_name": "578_05.png", "page": 7, "dpi": 300, "bbox": [408, 455, 676, 576], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An interesting combined dimension from the pa- rameter space and its impact on two objective dimensions. ", "caption_bbox": [391, 583, 692, 611]}, {"image_id": 6, "file_name": "578_06.png", "page": 8, "dpi": 300, "bbox": [62, 630, 354, 733], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Two interesting combined dimensions (centre and right) found by the system and their impact on one objective dimension (aireha). Brushing and linking to an original view (left) shows interesting profiles. ", "caption_bbox": [59, 741, 360, 800]}], "579": [{"image_id": 0, "file_name": "579_00.png", "page": 2, "dpi": 300, "bbox": [58, 57, 689, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization of response surfaces for all pairs of parameters of a multivariate scalar function. Incremental update and visualization of the surfaces is performed at less than 5 ms. ", "caption_bbox": [59, 347, 692, 375]}, {"image_id": 1, "file_name": "579_01.png", "page": 6, "dpi": 300, "bbox": [398, 351, 686, 481], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Utilizing parallel coordinates to adjust the center point (indicated by circles) in HyperSlice. Parallel coordi- nates are color coded to show the sample density on each parameter axis. ", "caption_bbox": [391, 499, 692, 558]}, {"image_id": 2, "file_name": "579_02.png", "page": 7, "dpi": 300, "bbox": [63, 133, 355, 403], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: HyperSlice is used to display the fuel efficiency (mpg) according to origin and model year for three differ- ent tupels of horsepower and weight: (a) (50, 1900), (b) (80, 2500), (c) (150, 3600). Note that there is virtually no impact of origin. (d) All samples are projected to the selected subspace and smoothly interpolated. Now one can see that cars from one origin tend to have low fuel efficiency, mean- ing that they generally differ in other attributes like horse- power or weight. ", "caption_bbox": [58, 419, 359, 554]}, {"image_id": 3, "file_name": "579_03.png", "page": 8, "dpi": 300, "bbox": [58, 57, 690, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Simulation setting, including arrow glyphs indicating the simulated forces. (b) Response surfaces for different force magnitudes depending on force direction. ", "caption_bbox": [59, 244, 692, 272]}, {"image_id": 4, "file_name": "579_04.png", "page": 9, "dpi": 300, "bbox": [61, 399, 358, 605], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: GPU/CPU Computation times for kriging inter- polation at different resolutions and for different numbers of samples. ", "caption_bbox": [59, 619, 360, 662]}, {"image_id": 5, "file_name": "579_05.png", "page": 9, "dpi": 300, "bbox": [61, 57, 378, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Computation times in ms for inverting the covari- ance matrix when samples are added incrementally. Times for different numbers of dimensions d are considered and compared with a direct non-incremental approach as refer- ence. ", "caption_bbox": [59, 302, 360, 376]}], "580": [{"image_id": 0, "file_name": "580_00.png", "page": 1, "dpi": 300, "bbox": [59, 545, 694, 713], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Isosurfaces from the weld dataset with \u2018sharp \u2019 mesh edges (large dihedral angles) marked in red. 1a), 1b) Polymender generates disconnected sharp mesh edges representing a sharp edge of the object. It also generates mesh edges with large dihedral angle in smooth regions of the surface. 1c), 1d) MergeSharp correctly generates a connected curve of sharp mesh edges to represent a sharp edge of the object. It does not generate mesh edges with large dihedral angles in the smooth region of the surface. ", "caption_bbox": [59, 470, 692, 544]}, {"image_id": 1, "file_name": "580_01.png", "page": 5, "dpi": 300, "bbox": [375, 57, 693, 201], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: 2D illustration of cube stack (blue, magenta, red) which are close enough together to form a triangle yet far enough apart so that no 3\u00d73\u00d73 cube region covers the other two cubes. Sharp edge is represented by the green curve. Each cube generates a vertex location (with the same color as the cube) on the sharp edge. The triangle formed by the three vertices is almost degenerate. ", "caption_bbox": [391, 212, 692, 317]}, {"image_id": 2, "file_name": "580_02.png", "page": 6, "dpi": 300, "bbox": [375, 59, 682, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Elements from our evaluation datasets. The cube stacks and flanges are rotated at various angles to test the robustness of the algorithms. Note that each data set contains only one cube stack or flange, not two or three as shown here. ", "caption_bbox": [391, 247, 692, 306]}, {"image_id": 3, "file_name": "580_03.png", "page": 7, "dpi": 300, "bbox": [375, 57, 693, 551], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Close-up isosurfaces on the rotor dataset. Edges with large dihedral angle are shown in red. (a) Yellow rect- angles indicate some problematic regions in Polymender iso- surface. ", "caption_bbox": [391, 565, 692, 624]}, {"image_id": 4, "file_name": "580_04.png", "page": 8, "dpi": 300, "bbox": [398, 249, 687, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 4: Effect of adding uniform noise to the gradients (300 test cases). Gradients were perturbed uniformly within the given angular bound. ", "caption_bbox": [391, 577, 692, 621]}, {"image_id": 5, "file_name": "580_05.png", "page": 8, "dpi": 300, "bbox": [84, 249, 337, 461], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Comparing different thresholds for the singular value. Singular values below the threshold are set to 0 in computing vertex locations. ", "caption_bbox": [59, 616, 360, 660]}, {"image_id": 6, "file_name": "580_06.png", "page": 9, "dpi": 300, "bbox": [82, 349, 333, 488], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: MergeSharp on flange datasets of various sizes. Graphs of time to position the isosurface using hermite data, time to position the isosurface using gradient data, time to merge grid cubes and time to extract isosurface triangles. ", "caption_bbox": [59, 509, 360, 568]}], "581": [{"image_id": 0, "file_name": "581_00.png", "page": 2, "dpi": 300, "bbox": [375, 56, 685, 176], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Distribution-based shape comparison for isosur- faces. (a): A test scalar field where the isosurfaces form a layered structure of cubes. (b): The distribution of scalar values on a cube. (c): The distribution of scalar values on a sphere. ", "caption_bbox": [391, 188, 692, 264]}, {"image_id": 1, "file_name": "581_01.png", "page": 4, "dpi": 300, "bbox": [58, 56, 378, 128], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Level-set evolution example. 6 morphed surfaces are shown when morphing from the isosurface 1 to isosur- face 100 of the data set HydrogenAtom. ", "caption_bbox": [59, 137, 360, 183]}, {"image_id": 2, "file_name": "581_02.png", "page": 4, "dpi": 300, "bbox": [375, 56, 672, 201], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The evolution of the level set surface using the test data set Plume.(a): Triangle count for the surface at each level-set step. (b): The distances from the morphed surfaces to the initial isosurface (blue) and the target isosurface (red) ", "caption_bbox": [391, 213, 692, 274]}, {"image_id": 3, "file_name": "581_03.png", "page": 6, "dpi": 300, "bbox": [58, 56, 378, 403], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Result of data set HydrogenAtom. The top row shows the initial isosurfaces Sinit (isovalue 1) and Starget (iso- value 100). The columns below from left to right represent the result for the first three selected isosurfaces. (1-a)-(1-c): Isosurface information maps. (2-a) - (2-c): The correspond- ing normalized specific conditional entropy. (3-a)-(3-c): The selected isosurfaces. ", "caption_bbox": [59, 415, 360, 521]}, {"image_id": 4, "file_name": "581_04.png", "page": 7, "dpi": 300, "bbox": [591, 519, 688, 702], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The iso- surface information map (a) and the normalized condi- tional entropy (b) for Tooth. ", "caption_bbox": [585, 712, 692, 803]}, {"image_id": 5, "file_name": "581_05.png", "page": 7, "dpi": 300, "bbox": [59, 371, 361, 466], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Regular sampling of 8 isosurfaces from the value interval [0.1, 20.0] of Plume. ", "caption_bbox": [59, 480, 360, 510]}, {"image_id": 6, "file_name": "581_06.png", "page": 7, "dpi": 300, "bbox": [397, 265, 687, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Regular sampling of 4 isosurfaces between isoval- ues 600 and 1100 of Tooth. ", "caption_bbox": [391, 346, 692, 376]}, {"image_id": 7, "file_name": "581_07.png", "page": 7, "dpi": 300, "bbox": [58, 56, 378, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The selected isosurfaces for Plume from the inter- val [0.1, 20.0]. Each white bar represent a value interval and the normalized conditional entropy H \u2032 . Below each bar, in addition to the divided subinterval, the selected isosurface is also shown. ", "caption_bbox": [59, 275, 360, 351]}, {"image_id": 8, "file_name": "581_08.png", "page": 7, "dpi": 300, "bbox": [375, 56, 694, 202], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The selected isosurfaces for Tooth from the inter- val [600, 1100]. ", "caption_bbox": [391, 216, 692, 246]}, {"image_id": 9, "file_name": "581_09.png", "page": 8, "dpi": 300, "bbox": [375, 56, 677, 175], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: An example isosurface information map with dif- ferent CFL number \u03b1 of level-set evolution for Plume. ", "caption_bbox": [391, 189, 692, 219]}, {"image_id": 10, "file_name": "581_10.png", "page": 9, "dpi": 300, "bbox": [375, 56, 693, 222], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Isosurface similarites computed based on Bruck- ner and M\u00f6ller\u2019s method [BM10]. (a): The isosurface sim- ilarity [BM10] between 20 sampled isovalues and Sinit . (b) and (c): The joint distributions between the distance fields of Sinit and spheres of radiuses 6 and 30, respectively. (d): The normalized mutual information between the 20 samples and Sinit . (e) and (f): The isosurface information maps for spheres of radiuses 6 and 30, respectively. ", "caption_bbox": [391, 234, 692, 356]}], "582": [{"image_id": 0, "file_name": "582_00.png", "page": 2, "dpi": 300, "bbox": [58, 75, 656, 336], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Using our semantic zoom interface users can explore distances between matrices (a) (here: 100 matrices; ordered by time stamp; cf. Section 6.1). Starting from an overview distance meta-matrix (b) showing the pairwise distances between matrices, users can identify patterns (e.g. strong groups or outliers). Having found such patterns, users can investigate the impact of matrix size variations on the distance calculation (c) and steer it using a simple set of interactions (d) and (e). ", "caption_bbox": [59, 354, 692, 413]}, {"image_id": 1, "file_name": "582_01.png", "page": 3, "dpi": 300, "bbox": [92, 100, 661, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Processing pipeline for our projection-based matrix comparison technique: A set of matrices of potentially different size is input (left). Their columns and/or rows are interpreted as high-dimensional vectors and projected to the plane (middle). Solving a bipartite graph-matching problem on the resultant point clouds leads to a set of allocation edges. Aggregating the euclidean lengths of the edges results in a similarity score for each pair of matrices (right). ", "caption_bbox": [59, 293, 692, 352]}, {"image_id": 2, "file_name": "582_02.png", "page": 4, "dpi": 300, "bbox": [58, 75, 625, 316], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A visual interpretation of the distance calculation is possible from two perspectives. Clicking on a cell of the distance meta-matrix (see Figure 1 (b)) shows the compared matrices (left). Additionally, a transparency factor for columns indicates their impact on the overall distance score. The matrices\u2019 columns are visually connected by edges to represent the bipartite graph matching decisions (middle). These connections are also shown in the projection view (right), which lets the user explore patterns in the projection of columns, i.e. projection points which are close together represent columns which are similar. ", "caption_bbox": [59, 334, 692, 408]}, {"image_id": 3, "file_name": "582_03.png", "page": 5, "dpi": 300, "bbox": [390, 605, 694, 758], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Changing the penalty function has a large im- pact on the appearance of the distance meta-matrix show- ing all pairwise matrix comparisons. From left to right, the ZeroPenalty and MaxDistSquare penalty functions are rendered in the upper diagonal part of the matrix. The lower part shows the MaxDist, for reference purposes. ", "caption_bbox": [391, 776, 692, 865]}, {"image_id": 4, "file_name": "582_04.png", "page": 6, "dpi": 300, "bbox": [58, 75, 694, 485], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Matrix Projection Explorer is used to visualize matrices and their projections. The overview (2) shows a distance meta-matrix of all pairwise matrix distances for the VAST Challenge 2013 dataset with 120 matrices. Patterns, like closely related (dark groups) and outlying (light rows) matrices, stand out. The projection view (3) lets the user explore the selected matrices\u2019 structural similarities expressed in the projection space. ", "caption_bbox": [59, 502, 692, 561]}, {"image_id": 5, "file_name": "582_05.png", "page": 8, "dpi": 300, "bbox": [58, 75, 637, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Excluding vertices from the calculation helps to filter out aspects of low importance. In this soccer analysis task it makes sense to exclude goal-keepers to find semantically similar game situations, where goal-keepers have a low impact. ", "caption_bbox": [59, 294, 692, 322]}, {"image_id": 6, "file_name": "582_06.png", "page": 9, "dpi": 300, "bbox": [63, 106, 686, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The experimental evaluation shows the technique\u2019s insensitivity to noise in the input data, scaling factors and the projection technique used, as long as it is deterministic. ", "caption_bbox": [59, 258, 692, 286]}], "583": [{"image_id": 0, "file_name": "583_00.png", "page": 2, "dpi": 300, "bbox": [55, 75, 693, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A screenshot of the entire system. The similarity view on the left side shows all daily patterns of all sensors. Similar patterns are assigned to the same group and color. The change of patterns over time for a selected sensor is indicated by the black spline. The network view on the right side gives an overview of the network topology. The small calendar in the node glyph shows changes over time and a fingerprint view underneath shows the sensor patterns in the global context. ", "caption_bbox": [58, 372, 691, 431]}, {"image_id": 1, "file_name": "583_01.png", "page": 4, "dpi": 300, "bbox": [58, 288, 361, 464], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A part of the sensor network, displayed as a octi- linear topological map. At the cost of uniform edge lengths, geographical directions are preserved, if possible [NW06]. ", "caption_bbox": [58, 474, 359, 517]}, {"image_id": 2, "file_name": "583_02.png", "page": 5, "dpi": 300, "bbox": [390, 368, 693, 529], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The projected pattern similarities, clustered and colored using a 2D colormap. Some of the patterns show negative energy consupmtion during daytime (purpelish red patterns at the top). This could indicate that connected solar plants produced significant amounts of energy on that days. ", "caption_bbox": [390, 539, 691, 613]}, {"image_id": 3, "file_name": "583_03.png", "page": 5, "dpi": 300, "bbox": [57, 525, 361, 749], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The sensor at Newham, plotted based on the sim- ilarity of daily patterns for the month May. ", "caption_bbox": [58, 759, 359, 787]}, {"image_id": 4, "file_name": "583_04.png", "page": 6, "dpi": 300, "bbox": [117, 237, 302, 348], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A 2D colormap created by interpolation of four perceptually distant colors. It defines the color of the simi- larity clusters. ", "caption_bbox": [58, 358, 359, 401]}, {"image_id": 5, "file_name": "583_05.png", "page": 6, "dpi": 300, "bbox": [391, 482, 693, 619], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The network view at the second level of detail. Both calendar and cluster fingerprint view appear. ", "caption_bbox": [390, 629, 691, 657]}, {"image_id": 6, "file_name": "583_06.png", "page": 7, "dpi": 300, "bbox": [58, 394, 361, 460], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Calendar view of a partly selected sensor. The cal- endar maps colored patterns to a cluster. A selection is ac- tive which causes unselected elements (mostly in summer) to become smaller. ", "caption_bbox": [58, 471, 359, 530]}, {"image_id": 7, "file_name": "583_07.png", "page": 7, "dpi": 300, "bbox": [394, 175, 691, 389], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A sensor shown at the highest level of detail. The calendar maps time to a cluster of patterns. The fingerprint view below illustrates which patterns this sensor recorded compared to the other sensors. Low and even negative con- sumption patterns are recorded from March to October. ", "caption_bbox": [390, 401, 691, 475]}, {"image_id": 8, "file_name": "583_08.png", "page": 8, "dpi": 300, "bbox": [60, 615, 358, 861], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Partly selected sensor at Hartham. Mostly week- ends are affected by the selection. Filtered patterns are dis- played only as small rectangles. The months August and September do not contain any data. ", "caption_bbox": [58, 874, 359, 933]}, {"image_id": 9, "file_name": "583_09.png", "page": 8, "dpi": 300, "bbox": [58, 173, 361, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Selected patterns distributed to their related sen- sors in the network. Sensors that are at least partly selected are accordingly marked with bluish selection bars on bright background. ", "caption_bbox": [58, 359, 359, 418]}], "584": [{"image_id": 0, "file_name": "584_00.png", "page": 1, "dpi": 300, "bbox": [158, 333, 595, 549], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The visualization of Android application permissions with Papilio", "caption_bbox": [183, 559, 564, 572]}, {"image_id": 1, "file_name": "584_01.png", "page": 5, "dpi": 300, "bbox": [58, 75, 378, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Applying force-directed layout on our dataset. Inset A: the force-directed layout on the entire dataset. B: the layout of one-third of applications in our dataset (reducing the applications gives a better view of the layout). ", "caption_bbox": [59, 310, 360, 369]}, {"image_id": 2, "file_name": "584_02.png", "page": 5, "dpi": 300, "bbox": [390, 732, 694, 887], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The representation of e-classes and their relations in our dataset using the \u201cdot\u201d program. Many link crossings and long links has led to an unreadable representation. ", "caption_bbox": [391, 898, 692, 941]}, {"image_id": 3, "file_name": "584_03.png", "page": 6, "dpi": 300, "bbox": [58, 75, 694, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Papilio is a two-sided visualization showing ordered application e-classes through the center, with the parent-child relations among e-classes on the right side and the requested permissions of e-classes on the left side. ", "caption_bbox": [59, 452, 692, 480]}, {"image_id": 4, "file_name": "584_04.png", "page": 7, "dpi": 300, "bbox": [393, 705, 694, 888], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Parents and children of a selected e-class. Two off-screen children and two off-screen parents are repre- sented using Halos. ", "caption_bbox": [391, 898, 692, 941]}, {"image_id": 5, "file_name": "584_05.png", "page": 7, "dpi": 300, "bbox": [60, 75, 378, 323], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: CA is a parent e-class for CB , CC and CD . Also CB and CC are siblings which are recognizable based on their positions. ", "caption_bbox": [59, 334, 360, 377]}, {"image_id": 6, "file_name": "584_06.png", "page": 8, "dpi": 300, "bbox": [390, 787, 694, 888], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Game applications grouped in CA and CB . The application in CC is an outlier, potentially interesting for a security analyst. ", "caption_bbox": [391, 898, 692, 941]}, {"image_id": 7, "file_name": "584_07.png", "page": 8, "dpi": 300, "bbox": [58, 75, 378, 158], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: An application requested INSTALL_PACKAGES permission which is not intended to be used by third-party applications. ", "caption_bbox": [59, 170, 360, 213]}, {"image_id": 8, "file_name": "584_08.png", "page": 9, "dpi": 300, "bbox": [375, 75, 694, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: 15 out of 30 applications towards the bottom of the hierarchy belong to the Communication category (black colored applications). ", "caption_bbox": [391, 350, 692, 393]}, {"image_id": 9, "file_name": "584_09.png", "page": 9, "dpi": 300, "bbox": [58, 75, 378, 344], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Out of 130 permissions, just a small set of them are frequently requested by applications and the rest are ei- ther never requested or requested infrequently. ", "caption_bbox": [59, 354, 360, 397]}], "585": [{"image_id": 0, "file_name": "585_00.png", "page": 4, "dpi": 300, "bbox": [376, 75, 693, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Schematic depiction of insert, update, and deletion with the EditLens. The node being edited is highlighted in orange, regular nodes are shown in green. Nodes that are not considered for the editing operation are dimmed. ", "caption_bbox": [391, 297, 692, 356]}, {"image_id": 1, "file_name": "585_01.png", "page": 5, "dpi": 300, "bbox": [58, 75, 378, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Empty space rectangles (green) under the Ed- itLens (dark frame) with the node being edited (yellow). Dif- ferent shades of green indicate where rectangles overlap. ", "caption_bbox": [59, 332, 360, 375]}, {"image_id": 2, "file_name": "585_02.png", "page": 6, "dpi": 300, "bbox": [58, 75, 689, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Three placement strategies determine a node\u2019s position based on prioritizing different layout criteria, including favoring much free space around nodes, shortening edges to neighbors, and reducing the number of edge bends. The inserted node is shown in red, its neighbors are yellow, unaffected elements are dimmed. ", "caption_bbox": [59, 279, 692, 322]}, {"image_id": 3, "file_name": "585_03.png", "page": 7, "dpi": 300, "bbox": [66, 75, 378, 136], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Touch gestures used in the EditLens prototype.", "caption_bbox": [66, 148, 351, 161]}, {"image_id": 4, "file_name": "585_04.png", "page": 8, "dpi": 300, "bbox": [376, 75, 691, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The improved PluriNetWork as visualized by our prototype. Node size and color visualize node degree. Labels were placed using a dedicated labeling algorithm. ", "caption_bbox": [391, 369, 692, 412]}, {"image_id": 5, "file_name": "585_05.png", "page": 8, "dpi": 300, "bbox": [58, 75, 378, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The PluriNetWork. Marked are the three seman- tic regions (blue, green, and orange). The detail view (gray) indicates how cumbersome manual editing must be. ", "caption_bbox": [59, 369, 360, 412]}], "586": [{"image_id": 0, "file_name": "586_00.png", "page": 3, "dpi": 300, "bbox": [426, 325, 675, 644], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: ValueChart using vertical layout (VC-V).", "caption_bbox": [394, 647, 643, 662]}, {"image_id": 1, "file_name": "586_01.png", "page": 3, "dpi": 300, "bbox": [54, 92, 690, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: ValueChart using horizontal layout (VC-H), in the sample domain of hotel selection.", "caption_bbox": [54, 301, 508, 316]}, {"image_id": 2, "file_name": "586_02.png", "page": 5, "dpi": 300, "bbox": [405, 467, 692, 611], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: VC Interface actions for each low-level task", "caption_bbox": [405, 615, 668, 630]}, {"image_id": 3, "file_name": "586_03.png", "page": 5, "dpi": 300, "bbox": [401, 773, 694, 876], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Experimental Procedure.", "caption_bbox": [394, 884, 566, 899]}, {"image_id": 4, "file_name": "586_04.png", "page": 7, "dpi": 300, "bbox": [399, 471, 692, 629], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Interaction with verbal WM & task type for time.", "caption_bbox": [394, 633, 678, 648]}, {"image_id": 5, "file_name": "586_05.png", "page": 8, "dpi": 300, "bbox": [396, 288, 706, 398], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Time spent for high-level tasks split by reported frequency of visualization use for making preferential choices. ", "caption_bbox": [394, 401, 695, 430]}, {"image_id": 6, "file_name": "586_06.png", "page": 8, "dpi": 300, "bbox": [59, 479, 352, 576], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Interaction effects of Visual WM with Vis Layout for completion time (left), and task accuracy (right). ", "caption_bbox": [53, 580, 354, 611]}, {"image_id": 7, "file_name": "586_07.png", "page": 8, "dpi": 300, "bbox": [56, 98, 355, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Interaction between PS and task type on time.", "caption_bbox": [53, 243, 323, 258]}], "587": [{"image_id": 0, "file_name": "587_00.png", "page": 3, "dpi": 300, "bbox": [375, 75, 693, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Subscenes and scene templates. (a) With scene templates, each scene inherits the same annotations from a template; the annotations are removed when transitioning between scenes. (b) With subscenes, annotations are not re- moved when moving between sibling subscenes. ", "caption_bbox": [391, 359, 692, 433]}, {"image_id": 1, "file_name": "587_01.png", "page": 4, "dpi": 300, "bbox": [375, 75, 663, 868], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Budget Forecasts by the New York Times, decon- structed into scenes and scene transitions (purple), parame- ter changes (yellow), and annotations (green). ", "caption_bbox": [391, 879, 692, 922]}, {"image_id": 2, "file_name": "587_02.png", "page": 5, "dpi": 300, "bbox": [68, 628, 312, 749], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Wrapping an existing visualization within Ellipsis to expose its data and states. ", "caption_bbox": [59, 765, 360, 793]}, {"image_id": 3, "file_name": "587_03.png", "page": 5, "dpi": 300, "bbox": [68, 802, 305, 921], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Defining a scene that coordinates two visualiza- tions: budgetForecast and dowJones ", "caption_bbox": [59, 928, 360, 956]}, {"image_id": 4, "file_name": "587_04.png", "page": 6, "dpi": 300, "bbox": [58, 75, 654, 593], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The Ellipsis interface. (a) Ellipsis creates a stage element for each visualization. (b) The GUI inspects visualization parameters and creates controls for them. (c) Creating a new scene prompts the storyteller for a scene name; scenes can be built by changing visualization parameters or drawing annotations. (d) The sidebar lists reorderable scenes and members. (e) Triggers and scene transitions are defined using an \u201cif this, then that\u201d syntax. (f) Annotation properties and data binding can be modified, triggering real-time updates. (g) Standard form widgets can be instantiated and bound to visualization parameters. ", "caption_bbox": [59, 600, 692, 674]}, {"image_id": 5, "file_name": "587_05.png", "page": 7, "dpi": 300, "bbox": [375, 75, 694, 869], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A \u201cdrill-down\u201d narrative with scenes and scene transitions (purple), parameter changes (yellow) and anno- tations (green). A representative story is shown for Los An- geles. Selecting a U.S. county triggers a single-scene story that cycles through all years. ", "caption_bbox": [391, 871, 692, 945]}, {"image_id": 6, "file_name": "587_06.png", "page": 8, "dpi": 300, "bbox": [375, 75, 692, 600], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A \u201cpartitioned poster\u201d narrative visualization im- plemented using Ellipsis. Scenes and scene transitions (pur- ple); parameter changes (yellow); annotations (green). ", "caption_bbox": [391, 610, 692, 653]}], "588": [{"image_id": 0, "file_name": "588_00.png", "page": 1, "dpi": 300, "bbox": [88, 222, 661, 495], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The Lyra visualization design environment, here used to recreate William Playfair\u2019s classic chart comparing the price of wheat and wages in England. Lyra enables the design of custom visualizations without writing code. ", "caption_bbox": [59, 499, 692, 527]}, {"image_id": 1, "file_name": "588_01.png", "page": 2, "dpi": 300, "bbox": [58, 75, 689, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: U.S. Gun Deaths in 2013, a visualization by Periscopic (left). The use of arcs and color reflects the emotional weight of its subject: the devastating effect of gun violence. A static version of the visualization recreated in Lyra (right). ", "caption_bbox": [59, 298, 692, 326]}, {"image_id": 2, "file_name": "588_02.png", "page": 4, "dpi": 300, "bbox": [375, 75, 664, 446], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Lyra\u2019s side-panels for data pipelines (left), and visual properties (right). (a) Data table showing the cur- rent output of the pipeline; (b) Scale transforms defined over fields in the pipeline. (c) A property inspector for a symbol mark type; two properties have been mapped to data fields. ", "caption_bbox": [391, 449, 692, 523]}, {"image_id": 3, "file_name": "588_03.png", "page": 7, "dpi": 300, "bbox": [65, 75, 694, 958], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Example visualizations demonstrating Lyra\u2019s expressivity.", "caption_bbox": [204, 970, 546, 983]}, {"image_id": 4, "file_name": "588_04.png", "page": 8, "dpi": 300, "bbox": [58, 75, 378, 634], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Using Lyra to recreate the New York Times\u2019 Dis- secting a Trailer. (a) Drag a line mark onto the canvas. (b) Drag a field from a pipeline\u2019s data table to a drop zone to map it to a mark property. (c) Add a \u201cgroup by\u201d data transform to create a hierarchy. (d) Edit a scale definition to reverse the range. (e) Use a connector to anchor text marks to the rectangles. ", "caption_bbox": [59, 646, 360, 750]}, {"image_id": 5, "file_name": "588_05.png", "page": 8, "dpi": 300, "bbox": [390, 739, 694, 913], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Users were asked to recreate a version of the bar- ley yields Trellis display by Becker et al. [BCS96] ", "caption_bbox": [391, 913, 692, 941]}, {"image_id": 6, "file_name": "588_06.png", "page": 9, "dpi": 300, "bbox": [111, 75, 694, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A user approximately recreates a D3 visualization (left, requiring 4-6 hours) in Lyra (right, requiring 10 minutes).", "caption_bbox": [64, 312, 686, 325]}], "589": [{"image_id": 0, "file_name": "589_00.png", "page": 2, "dpi": 300, "bbox": [375, 61, 675, 374], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Similarity computation. Illustration of spatial and temporal correlations are computed between models M1 and M2 after aggregating the temporal information. The spa- tial granularity is preserved at the cost of temporal informa- tion, and vice versa. ", "caption_bbox": [390, 375, 691, 449]}, {"image_id": 1, "file_name": "589_01.png", "page": 2, "dpi": 300, "bbox": [58, 61, 378, 323], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualizing the complexity of multifaceted cli- mate data in terms of models, regions, time and variables. ", "caption_bbox": [58, 322, 359, 351]}, {"image_id": 2, "file_name": "589_02.png", "page": 5, "dpi": 300, "bbox": [109, 61, 693, 427], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: SimilarityExplorer is composed of a set of filters (a), similarity views (b, c, d) and data views (e, f). The similarity views are b) a matrix view for showing pairwise similarity, c) a projection view for showing multi-way similarity, and d) a small multiples view for showing region-wise spatiotemporal similarity. The data views are: e) a parallel coordinates view for showing multi-model distribution of each variable, and f) a time series for showing temporal distribution of any pair of models. ", "caption_bbox": [58, 426, 691, 485]}, {"image_id": 3, "file_name": "589_03.png", "page": 6, "dpi": 300, "bbox": [58, 61, 642, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Preserving the mental model and symmetry about spatial and temporal similarity through use of maps for representing space and use of area graphs for representing time, and by reflecting the change in granularity on both sides. ", "caption_bbox": [58, 245, 691, 274]}, {"image_id": 4, "file_name": "589_04.png", "page": 7, "dpi": 300, "bbox": [109, 61, 694, 248], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Data View: Parallel Coordinates. The ability to examine the region-wise range and distribution of variables enables climate scientists to relate the meta views to the patterns in the data view, i.e., parallel coordinates, and additionally, find clusters and outliers. For NPP, we can see a cluster of polylines for the regions South American Tropical and Tropical Asia for all models, indicating multi-model similarity for those regions. ", "caption_bbox": [58, 250, 691, 309]}, {"image_id": 5, "file_name": "589_05.png", "page": 8, "dpi": 300, "bbox": [58, 61, 378, 400], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Comparing multiple output variables for differ- ent months and analyzing their distribution (Q2, Q4). ", "caption_bbox": [58, 403, 359, 432]}, {"image_id": 6, "file_name": "589_06.png", "page": 9, "dpi": 300, "bbox": [109, 61, 694, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparing model similarity for GPP and analyzing spatiotemporal anomalies for winter and summer (Q1, Q3). Using the projection view, scientists were able to select similar models; using the matrix view they could compare spatial and temporal correlation (indicated by the numbers); and identify anomalies using the small multiples view. ", "caption_bbox": [58, 320, 691, 364]}], "590": [{"image_id": 0, "file_name": "590_00.png", "page": 2, "dpi": 300, "bbox": [375, 75, 690, 211], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The plots represent the linear relationship be- tween two variables can be different when considering dif- ferent partitions of data points. From a domain expert point of view, both high return and low return companies have rel- atively high risk; intermediate return (fluctuate around 0) companies tend to follow a trend that the risk is reversely proportional to the return. ", "caption_bbox": [391, 227, 692, 331]}, {"image_id": 1, "file_name": "590_01.png", "page": 2, "dpi": 300, "bbox": [58, 75, 378, 231], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The two plots show that the two models oppose each other in terms of bias. Model1 has the tendency to un- derestimate and Model2 tends to overestimate when the total asset grows. The y-axis shows the goodness of fit (residuals). The x-axis is the value of total assets (one of the indepen- dent variables). DLTT: Total long-term debt; LEV: Lever- age; MKVALT: Market value ", "caption_bbox": [58, 249, 359, 353]}, {"image_id": 2, "file_name": "590_02.png", "page": 3, "dpi": 300, "bbox": [74, 75, 693, 440], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Model spaces for visualization", "caption_bbox": [441, 666, 641, 679]}, {"image_id": 3, "file_name": "590_03.png", "page": 5, "dpi": 300, "bbox": [88, 75, 378, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A candidate model LEV complement the TBR model DEBTTA (in the yellow box). The y-axis represents the error spread of two models. Positive (Negative) values sug- gest bias towards underestimate (overestimate). The x-axis represents local partitions where the errors are estimated. The theme river design [HHN00] represents the residuals of the TBR model; and the red vertical lines represent the resid- uals of a candidate model (usually a uni-variate model). ", "caption_bbox": [59, 311, 360, 431]}, {"image_id": 4, "file_name": "590_04.png", "page": 6, "dpi": 300, "bbox": [58, 75, 665, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The x-y position of any cell in the grid view (a) is determined by the lower (x) and upper (y) percentile threshold of a data partition. The relationship between x-y position and the partition boundary is shown in (b) and is indexed as in (c,d). Each cell is colored by the fitness of a local model in it. The diagonal and the orthogonal direction in (c) indicates two ways a data partition may change to another: expanding (add more data points) and shifting (add data points at one end and remove at the other). An alternative display of (a) (Figure 6) is transformed from (a) by the sequence in (d) where the main diagonal is walked from top left first followed by the second diagonal above it. The walk continues till the right top corner. ", "caption_bbox": [59, 264, 692, 353]}, {"image_id": 5, "file_name": "590_05.png", "page": 7, "dpi": 300, "bbox": [415, 502, 672, 666], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visualize the coefficient vector (red horizontal bars in the icicle plot) of the linear trend in the highlighted data partition (left). The red text shows the value of the co- efficients and the name of variables. ", "caption_bbox": [391, 676, 692, 735]}, {"image_id": 6, "file_name": "590_06.png", "page": 7, "dpi": 300, "bbox": [417, 281, 672, 424], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visualizing the coverage (cells with red outline on the left) of a selected cluster of data partitions (selected node marked with red rectangle on the right). ", "caption_bbox": [391, 435, 692, 478]}, {"image_id": 7, "file_name": "590_07.png", "page": 7, "dpi": 300, "bbox": [74, 75, 694, 204], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Plot represents degree of diversities. It shows that the local models isolated by partitioning on DLTT (a,b) have more diversity over the local models isolated by partitioning on ARChange (c,d). ARChange: Account Receivable Change ", "caption_bbox": [59, 215, 692, 243]}, {"image_id": 8, "file_name": "590_08.png", "page": 8, "dpi": 300, "bbox": [58, 75, 694, 510], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A case study for modeling risk. a) A ranking list of independent variables. b) Scatterplot of a selected independent variable and the dependent variable. c) A list of built models. d,e) Complementarity analysis. f,g,h,i) Local model diversity analysis. j,k,l,m) Model representivity analysis. Detailed analysis is in Section 4.1. ", "caption_bbox": [59, 520, 692, 563]}], "591": [{"image_id": 0, "file_name": "591_00.png", "page": 3, "dpi": 300, "bbox": [60, 75, 378, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Cross section scheme of flame surface with seeded points p: profiles sampled from profile lines p(t) at different locations on the flame surface. The minimum, inflection, and maximum of the sigmoidal shape are indicated by the blue, green and red dots. If the sampled line enters or leaves the burning region multiple times, multiple sigmoidal shapes can occur (bottom right box). Seeding density is dependent on the surface curvature (see green vs. red circle). ", "caption_bbox": [58, 313, 360, 433]}, {"image_id": 1, "file_name": "591_01.png", "page": 4, "dpi": 300, "bbox": [394, 98, 691, 343], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Sigmoidal model (top) and Gaussian model (bot- tom) with examples of models fitted to a profile. ", "caption_bbox": [390, 351, 693, 379]}, {"image_id": 2, "file_name": "591_02.png", "page": 5, "dpi": 300, "bbox": [375, 75, 694, 255], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Mean RMS fitting error for all variables. Note that not all data sets contain the same variables. ", "caption_bbox": [390, 259, 691, 287]}, {"image_id": 3, "file_name": "591_03.png", "page": 5, "dpi": 300, "bbox": [393, 307, 684, 875], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Error vs. reduction ratio for selected variables. Top: S YNGAS I, middle: S YNGAS II, bottom: S YNGAS III. The plots corresponding to each variable are shifted by a constant increment. The horizontal lines signify the zero-levels of the respective plots. ", "caption_bbox": [390, 879, 693, 953]}, {"image_id": 4, "file_name": "591_04.png", "page": 6, "dpi": 300, "bbox": [57, 98, 361, 514], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Top: S YNGAS II: Comparison of reconstruction results for H with q = 36 (ca. 2500 profile lines, c = 321). Bottom: S YNGAS I: Reconstruction results of linear interpo- lation for different sample densities for O2 . ", "caption_bbox": [58, 525, 361, 584]}, {"image_id": 5, "file_name": "591_05.png", "page": 6, "dpi": 300, "bbox": [391, 101, 691, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Reduction ratio and computation time for different seeding densities q. Plot shows mean (solid) and standard de- viation (dashed) over eight time steps of data set H YDROGEN and values for the synthetic data set (dash-dotted). ", "caption_bbox": [390, 243, 693, 302]}, {"image_id": 6, "file_name": "591_06.png", "page": 7, "dpi": 300, "bbox": [375, 75, 694, 323], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Construction of feature points and feature mesh. Left: Feature points are constructed by shifting the anchor points pi on the flame surface S along their direction vectors ri by amount t f taken from the model parameters (here, xm of a gaussian model). The resulting points pi (t f ,i ) are located on feature surface S f . Right: Directions and model parameters for mesh points m j are obtained from points pi by diffusion (grey arrows and dots). Feature mesh M f is then constructed from flame surface mesh M by shifting all vertices along their corresponding directions by their corresponding values of t f . ", "caption_bbox": [390, 326, 693, 476]}, {"image_id": 7, "file_name": "591_07.png", "page": 8, "dpi": 300, "bbox": [58, 98, 362, 845], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Prototype of visual analysis tool for feature meshes showing dataset H YDROGEN. Top: Graphical user interface. Upper middle: Effect of varying color scale parameter u1 . Lower middle: Morphing between the different surfaces by adjusting u2 . Bottom: Sliding through time to observe the development of the feature meshes (circles). ", "caption_bbox": [58, 848, 361, 937]}, {"image_id": 8, "file_name": "591_08.png", "page": 9, "dpi": 300, "bbox": [61, 75, 378, 312], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Diffusion error (median, max and min) for selected variables of data set H YDROGEN. Images show qualitative results of visualization for different seeding densities q. The plots corresponding to each variable are shifted by a constant increment. ", "caption_bbox": [58, 316, 359, 390]}], "592": [{"image_id": 0, "file_name": "592_00.png", "page": 1, "dpi": 300, "bbox": [83, 284, 682, 529], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The interface of the survey analysis tool allowing navigation through 8,434 collected responses (49,285 answers) with use of glyphs, linked views and interaction. Available at photoassessment.org/results, demo video at vimeo.com/90299533. ", "caption_bbox": [59, 541, 692, 569]}, {"image_id": 1, "file_name": "592_01.png", "page": 2, "dpi": 300, "bbox": [399, 700, 689, 768], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The concept of a survey response glyph. Rows cor- respond to survey questions and columns contain categories. ", "caption_bbox": [391, 788, 692, 816]}, {"image_id": 2, "file_name": "592_02.png", "page": 3, "dpi": 300, "bbox": [47, 425, 370, 822], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Photo content assessment survey: UI & questions.", "caption_bbox": [59, 838, 358, 851]}, {"image_id": 3, "file_name": "592_03.png", "page": 4, "dpi": 300, "bbox": [390, 305, 691, 534], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Glyphs representing responses grouped by pho- tographs (samples) and users (participants). Opacity of a sin- gle line is 15%. Vivid patterns in groups denote a high level of agreement among responses. ", "caption_bbox": [391, 547, 692, 606]}, {"image_id": 4, "file_name": "592_04.png", "page": 5, "dpi": 300, "bbox": [375, 75, 693, 224], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Glyph interactions with mouse (Photo 489).", "caption_bbox": [407, 238, 676, 251]}, {"image_id": 5, "file_name": "592_05.png", "page": 5, "dpi": 300, "bbox": [59, 782, 356, 916], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Time scaling of the response glyphs.", "caption_bbox": [93, 935, 326, 948]}, {"image_id": 6, "file_name": "592_06.png", "page": 6, "dpi": 300, "bbox": [375, 75, 685, 207], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Cross-highlighting relationships between groups.", "caption_bbox": [393, 219, 688, 232]}, {"image_id": 7, "file_name": "592_07.png", "page": 6, "dpi": 300, "bbox": [57, 811, 354, 920], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Multilevel sorting of the entity lists.", "caption_bbox": [94, 935, 323, 948]}, {"image_id": 8, "file_name": "592_08.png", "page": 7, "dpi": 300, "bbox": [57, 75, 696, 733], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The list of subjects with different representations and orderings applied. Not all elements are shown for compactness.", "caption_bbox": [59, 754, 692, 767]}, {"image_id": 9, "file_name": "592_09.png", "page": 8, "dpi": 300, "bbox": [54, 75, 378, 398], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The list of survey participants ordered by the number of completed responses. ", "caption_bbox": [59, 412, 360, 440]}, {"image_id": 10, "file_name": "592_10.png", "page": 8, "dpi": 300, "bbox": [390, 582, 706, 855], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Most participants found the test image in query f190234 irrelevant as expected. This also applies to the last photograph. Three other images are believed to be relevant, which is confirmed by the previews. Hovering over test im- age \u00d7 fairly relevant reveals an insincere participant. ", "caption_bbox": [391, 866, 692, 940]}, {"image_id": 11, "file_name": "592_11.png", "page": 9, "dpi": 300, "bbox": [65, 75, 378, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Examples of glyphs representing rankings of Wikipedia articles. ", "caption_bbox": [59, 292, 360, 320]}], "593": [{"image_id": 0, "file_name": "593_00.png", "page": 1, "dpi": 300, "bbox": [74, 244, 671, 484], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Glyph SPLOM uses color-coded, areal glyphs to summarize a scatterplot matrix.", "caption_bbox": [145, 494, 602, 507]}, {"image_id": 1, "file_name": "593_01.png", "page": 2, "dpi": 300, "bbox": [88, 710, 332, 793], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An example of different logical implication classes with the same dependency strength. PCC: Pearson\u2019s correlation coefficient. ", "caption_bbox": [59, 807, 360, 850]}, {"image_id": 2, "file_name": "593_02.png", "page": 4, "dpi": 300, "bbox": [406, 604, 663, 806], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Workflow for Logical Implication Classification.", "caption_bbox": [392, 811, 689, 824]}, {"image_id": 3, "file_name": "593_03.png", "page": 6, "dpi": 300, "bbox": [398, 438, 686, 638], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: WHO Per Class Examples. Life Span in Years (from birth) versus other measures per country; one example per signed logical implication class. ", "caption_bbox": [391, 651, 692, 694]}, {"image_id": 4, "file_name": "593_04.png", "page": 6, "dpi": 300, "bbox": [82, 591, 337, 846], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The complete Glyph SPLOM for the WHO data.", "caption_bbox": [59, 857, 355, 870]}, {"image_id": 5, "file_name": "593_05.png", "page": 7, "dpi": 300, "bbox": [390, 658, 695, 933], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A Glyph SPLOM for all 655 C. elegans TFs.", "caption_bbox": [401, 944, 679, 957]}, {"image_id": 6, "file_name": "593_06.png", "page": 7, "dpi": 300, "bbox": [68, 678, 353, 944], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A Glyph SPLOM for the C. elegans PAL-1 genes.", "caption_bbox": [59, 950, 360, 963]}, {"image_id": 7, "file_name": "593_07.png", "page": 7, "dpi": 300, "bbox": [58, 75, 378, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: WHO Non-linear Dependency Example; Life Span in Years (from birth) versus Health spending as % GDP. ", "caption_bbox": [59, 356, 360, 399]}, {"image_id": 8, "file_name": "593_08.png", "page": 7, "dpi": 300, "bbox": [375, 75, 694, 204], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: C. elegans heatmaps for PAL-1 genes.", "caption_bbox": [418, 215, 664, 228]}, {"image_id": 9, "file_name": "593_09.png", "page": 8, "dpi": 300, "bbox": [76, 522, 347, 747], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: NecNet Vs Gold Standard", "caption_bbox": [121, 938, 297, 951]}], "594": [{"image_id": 0, "file_name": "594_00.png", "page": 2, "dpi": 300, "bbox": [58, 75, 693, 283], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The Titanic data set as a proof of concept. Left: Attribute View with ranked attributes and all bin relations above the interestingness filter. Center: the Bin View aligns related bins close to each other. Right: the Cluster List View provides compact representations of clustered subspaces. The blue cluster relates to the Birkenhead Drill: \u2018women and children first!\u2019. ", "caption_bbox": [59, 294, 692, 337]}, {"image_id": 1, "file_name": "594_01.png", "page": 5, "dpi": 300, "bbox": [58, 75, 378, 155], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Glyph layout of bins and attributes. Left, center: levels of detail. Right: cluster color indication. ", "caption_bbox": [59, 169, 360, 197]}, {"image_id": 2, "file_name": "594_02.png", "page": 5, "dpi": 300, "bbox": [375, 75, 694, 142], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Question in a formative user study: \u2018I am a multi- colored object\u2019. The shown variants of the bin glyph reflect the design process of the multi-cluster color assignment. ", "caption_bbox": [391, 154, 692, 197]}, {"image_id": 3, "file_name": "594_03.png", "page": 6, "dpi": 300, "bbox": [58, 75, 378, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Bin clustering of the titanic data set. The target bins \u2018Class=3\u2019 (red) and \u2018Survived=true\u2019 (blue) reveal sep- arated clusters, except of the children\u2018s bin \u2018AGE [0-20.5]\u2019. ", "caption_bbox": [59, 228, 360, 271]}, {"image_id": 4, "file_name": "594_04.png", "page": 6, "dpi": 300, "bbox": [375, 75, 694, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Some multivariate bin relations are less interest- ing. We remove two subspaces with jointly occurring missing values of genetical (red) and clinical attributes (purple). ", "caption_bbox": [391, 228, 692, 271]}, {"image_id": 5, "file_name": "594_05.png", "page": 7, "dpi": 300, "bbox": [375, 75, 694, 367], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Cluster List View. Matrices show internal clus- ter relations. Depending on the cluster mode, not every cell needs to have a relation above the interestingness value. Two weather phenomena in Antarctica are shown. ", "caption_bbox": [391, 380, 692, 439]}, {"image_id": 6, "file_name": "594_06.png", "page": 7, "dpi": 300, "bbox": [59, 75, 378, 366], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Matrix View showing 7 weather-related attributes in Antarctica. Different non-linear correlations can be seen. Horizontal Width and Cloud Height are selected, revealed subspace clusters are highlighted with color-coding. ", "caption_bbox": [59, 377, 360, 436]}, {"image_id": 7, "file_name": "594_07.png", "page": 8, "dpi": 300, "bbox": [58, 75, 693, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Exploration of undiscovered relations. The bin Fog=Yes occurs in winter (green) and in summer (orange). While in the winter period katabatic winds are observed, foggy weather in summer is not significantly influenced by maritime winds. ", "caption_bbox": [59, 276, 692, 304]}, {"image_id": 8, "file_name": "594_08.png", "page": 9, "dpi": 300, "bbox": [58, 75, 694, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Attribute clustering of the prostate cancer data set. We discovered an association of the genomic \u2018deletion\u2019 ERG_IHC attribute to bins of the OP_AGE attibute. The finding will be published in the prostate cancer research community soon. ", "caption_bbox": [59, 341, 692, 369]}], "595": [{"image_id": 0, "file_name": "595_00.png", "page": 1, "dpi": 300, "bbox": [58, 314, 694, 442], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Making many plans for multiple \ufb02ood scenarios. (Left) Overtopping incident. (Middle) Scenarios are modelled as multidimensional, time-varying simulation ensembles, managed by Continuous World Lines. A zoom lens displays details about an optimized water barrier which protects a prioritized area. (Right) Visualization of plan logistics and construction. ", "caption_bbox": [59, 452, 692, 496]}, {"image_id": 1, "file_name": "595_01.png", "page": 2, "dpi": 300, "bbox": [375, 75, 694, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Area of interest protected by mobile walls. If over- topping happens, vital infrastructure should be kept water- free. The importance of objects is outlined by user sketches, coloring buildings and areas according to user-de\ufb01ned pri- orities between 0 and 1. ", "caption_bbox": [391, 282, 692, 357]}, {"image_id": 2, "file_name": "595_02.png", "page": 3, "dpi": 300, "bbox": [375, 75, 694, 544], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visual ensemble management. (a) 1D-ensemble of four water levels created by branching. The chosen scenario is highlighted in blue. (b) Scalability issues as soon as an- other dimension (overtopping duration) is added. (c) Contin- uous WL display a 2D-ensemble consisting of 150 members. A zoom lens simpli\ufb01es the selection of members. ", "caption_bbox": [391, 555, 692, 645]}, {"image_id": 3, "file_name": "595_03.png", "page": 4, "dpi": 300, "bbox": [58, 75, 694, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Combinatorial ensembles. (a) Based on multiple user sketches, the system (b) generates an ensemble of barrier positions containing all possible combinations, indicated in zoom lenses. (c) Added dimension for barrier types. (d) Depending on the selected position combination, a different number of type variations is possible and displayed. ", "caption_bbox": [59, 292, 692, 336]}, {"image_id": 4, "file_name": "595_04.png", "page": 5, "dpi": 300, "bbox": [375, 75, 693, 182], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Progress visualization in an ensemble with dimen- sions D1, D2, and time steps t0, t1. The green arrows denote the incoming progress for a \ufb01nished simulation step, identi- \ufb01ed by the member m and a time step t. ", "caption_bbox": [391, 193, 692, 253]}, {"image_id": 5, "file_name": "595_05.png", "page": 5, "dpi": 300, "bbox": [58, 75, 378, 451], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: 5D-ensemble from the case study showing the two protection dimensions and the three incident dimensions. The time-navigation cursor is equipped with a slider for each dimension to enable interactive browsing through en- semble members. ", "caption_bbox": [59, 461, 360, 536]}, {"image_id": 6, "file_name": "595_06.png", "page": 6, "dpi": 300, "bbox": [58, 75, 378, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Attributes of barrier types: Number of units per cargo; Assembly time per unit per person (s); Cost per unit (e). AquaBarrier may include two material types. ", "caption_bbox": [391, 187, 692, 231]}, {"image_id": 7, "file_name": "595_07.png", "page": 7, "dpi": 300, "bbox": [375, 75, 694, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Important infrastructure protected from \ufb02ooding using the chosen plan from Figure 8. (a) AquaBarrier and (b) sandbags at the subway stations. (c) AquaBarrier sup- plemented with pallets protects the hospital. ", "caption_bbox": [391, 367, 692, 427]}, {"image_id": 8, "file_name": "595_08.png", "page": 7, "dpi": 300, "bbox": [58, 75, 378, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Logistics visualization. (a) Labels display the truck positions and delivery destinations. Colored lines indi- cate the current route for each truck. (b) Overlapping routes are stacked. Progress bars in labels show the status with re- spect to (b) truck loads or (c) construction status. ", "caption_bbox": [59, 367, 360, 442]}, {"image_id": 9, "file_name": "595_09.png", "page": 8, "dpi": 300, "bbox": [375, 75, 694, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Embedded visualization in CWL ensemble di- mensions. The position dimension shows the possible pro- tection levels for the selected incident. The type dimension displays construction times for the selected position sample. ", "caption_bbox": [391, 239, 692, 299]}, {"image_id": 10, "file_name": "595_10.png", "page": 8, "dpi": 300, "bbox": [58, 75, 378, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Visual ranking of plans according to their perfor- mance in the chosen incident scenario. The rank is computed as a weighted sum of the qualities with respect to protection, costs and construction time. The user has selected the plan (blue) which is visualized in Figures 8 and 9 ", "caption_bbox": [59, 257, 360, 332]}], "596": [{"image_id": 0, "file_name": "596_00.png", "page": 1, "dpi": 300, "bbox": [58, 577, 693, 820], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: This figure shows our maps for Lisbon with different zoom levels.", "caption_bbox": [184, 562, 567, 575]}, {"image_id": 1, "file_name": "596_01.png", "page": 2, "dpi": 300, "bbox": [58, 75, 678, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Two separate maps are commonly used for planning. (a) is a screenshot of panoramio.com Swapping between these two different maps can cause a mental gap for city tour planning. ", "caption_bbox": [58, 323, 691, 351]}, {"image_id": 2, "file_name": "596_02.png", "page": 3, "dpi": 300, "bbox": [78, 75, 693, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: This figure shows our maps for the Vienna city with different zoom levels.", "caption_bbox": [165, 363, 585, 376]}, {"image_id": 3, "file_name": "596_03.png", "page": 4, "dpi": 300, "bbox": [375, 77, 703, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: This figure shows the overall structure of our sys- tem. ", "caption_bbox": [391, 342, 692, 370]}, {"image_id": 4, "file_name": "596_04.png", "page": 4, "dpi": 300, "bbox": [390, 385, 695, 614], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: This figure shows a heat map of Lisbon resulting from our kernel density estimation with POIs (shown in red dots). ", "caption_bbox": [391, 626, 692, 670]}, {"image_id": 5, "file_name": "596_05.png", "page": 5, "dpi": 300, "bbox": [375, 75, 693, 884], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (b) and (c) show computed octilinear layouts of the Lisbon metro network (a) constructed with uniform or vari- able edge lengths. POIs, shown in red dots, are also trans- formed according to the computed octilinear layout. ", "caption_bbox": [391, 898, 692, 957]}, {"image_id": 6, "file_name": "596_06.png", "page": 7, "dpi": 300, "bbox": [398, 413, 689, 629], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: This figure shows our clustering result at an inter- mediate level. ", "caption_bbox": [391, 651, 692, 679]}, {"image_id": 7, "file_name": "596_07.png", "page": 7, "dpi": 300, "bbox": [75, 75, 694, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: This figure shows our maps for Prague with different zoom levels.", "caption_bbox": [185, 364, 565, 377]}, {"image_id": 8, "file_name": "596_08.png", "page": 8, "dpi": 300, "bbox": [375, 75, 693, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Design factors study results.", "caption_bbox": [445, 328, 636, 341]}, {"image_id": 9, "file_name": "596_09.png", "page": 9, "dpi": 300, "bbox": [61, 75, 378, 255], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Average user satisfaction rating with 99% confi- dence intervals. ", "caption_bbox": [59, 267, 360, 295]}], "597": [{"image_id": 0, "file_name": "597_00.png", "page": 3, "dpi": 300, "bbox": [375, 75, 693, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Design space of a Tangram Diagram.", "caption_bbox": [421, 323, 662, 336]}, {"image_id": 1, "file_name": "597_01.png", "page": 4, "dpi": 300, "bbox": [58, 75, 378, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visual encoding of the ratio between inner and outer triangles - area, side, and their average (60% for all). ", "caption_bbox": [59, 248, 360, 276]}, {"image_id": 2, "file_name": "597_02.png", "page": 5, "dpi": 300, "bbox": [95, 75, 378, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Tangram Diagram showing visiting engagement with schematic patterns. ", "caption_bbox": [59, 314, 360, 342]}, {"image_id": 3, "file_name": "597_03.png", "page": 6, "dpi": 300, "bbox": [95, 700, 322, 900], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Tangram Diagram showing visiting circulation with schematic patterns. ", "caption_bbox": [59, 913, 360, 941]}, {"image_id": 4, "file_name": "597_04.png", "page": 6, "dpi": 300, "bbox": [58, 75, 688, 427], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Engagement at different locations is shown on a Tangram Diagram. Engagement is expressed by the holding power (low-intensity triangles) and the relative value of attracting power (high-intensity triangles). Hue is mapped on the usage of guides (using is blue, and not using is orange). ", "caption_bbox": [59, 438, 692, 481]}, {"image_id": 5, "file_name": "597_05.png", "page": 7, "dpi": 300, "bbox": [375, 75, 694, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Tangram Diagram for temporal analysis and schematic patterns. (b) two consecutive exhibits with same durations with low guide usage ", "caption_bbox": [391, 330, 692, 373]}, {"image_id": 6, "file_name": "597_06.png", "page": 7, "dpi": 300, "bbox": [58, 209, 357, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visitor circulation between rooms are shown using Tangram Diagrams. Differences between first time visitors and directional differences are clearly shown by the different glyphs. ", "caption_bbox": [59, 372, 360, 431]}, {"image_id": 7, "file_name": "597_07.png", "page": 8, "dpi": 300, "bbox": [81, 219, 336, 740], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Individual and Group Temporal Analysis using Tangram Diagrams. Patterns of dynamic behavior at differ- ent exhibits are shown by the glyphs and temporal flow. Col- ors encode different areas in the museum. ", "caption_bbox": [59, 750, 360, 809]}], "598": [{"image_id": 0, "file_name": "598_00.png", "page": 3, "dpi": 300, "bbox": [92, 665, 327, 817], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Gaze correction in our system. The blue circle rep- resents the corrected gaze while the red one matches the raw gaze sample. The magnitude of vectors in the offset map is displayed as a red heatmap. ", "caption_bbox": [58, 827, 359, 886]}, {"image_id": 1, "file_name": "598_01.png", "page": 3, "dpi": 300, "bbox": [77, 308, 341, 536], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Gaze correction: fixations f1..3 do not perfectly overlap the nearest vertices v1..3 but their relative position- ing matches that of the vertices. We conclude that f1..3 were fixations on v1..3 . We compute displacement offsets between  f and v and incorporate them into a grid of displacement vectors that we apply to all gaze samples. ", "caption_bbox": [58, 550, 359, 639]}, {"image_id": 2, "file_name": "598_02.png", "page": 4, "dpi": 300, "bbox": [58, 75, 378, 245], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Edges running through users\u2019 fovea but with both endpoints far away from its center are filtered out. ", "caption_bbox": [58, 257, 359, 285]}, {"image_id": 3, "file_name": "598_03.png", "page": 4, "dpi": 300, "bbox": [375, 75, 657, 114], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Viewing histograms along edges are computing by dividing the edge in segments and monitoring gaze-count in each segment. ", "caption_bbox": [391, 131, 692, 174]}, {"image_id": 4, "file_name": "598_04.png", "page": 5, "dpi": 300, "bbox": [82, 75, 378, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Viewed edge highlighting. An edge visually traced by the user is highlighted (red). ", "caption_bbox": [58, 299, 359, 327]}, {"image_id": 5, "file_name": "598_05.png", "page": 5, "dpi": 300, "bbox": [70, 355, 350, 480], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Highlighting a sub-network of interest. Recently viewed nodes and edges between them become slightly high- lighted. The effect is also diffused to their immediate neigh- borhoods. ", "caption_bbox": [58, 491, 359, 550]}, {"image_id": 6, "file_name": "598_06.png", "page": 8, "dpi": 300, "bbox": [58, 75, 675, 407], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Our quantitative results show that subjects using eye-tracking more accurately determined if two nodes are connected (left, p = 0.02) but showed no improvement finding shortest edges between nodes (middle). Our gaze-correction algorithm (section 3.1) increases the ability of eye-tracking users to fixate nodes (right, p = 0.01). ", "caption_bbox": [58, 421, 691, 465]}, {"image_id": 7, "file_name": "598_07.png", "page": 8, "dpi": 300, "bbox": [125, 506, 593, 639], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Our evaluation questionnaire showed that subjects preferred eye-tracking interaction to the control condition, thought eye-tracking was helpful, and liked it. ", "caption_bbox": [58, 647, 691, 675]}], "599": [{"image_id": 0, "file_name": "599_00.png", "page": 3, "dpi": 300, "bbox": [78, 75, 693, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: This illustration shows a multivariate data object X associated with a location p in a visualization. The visual encoder maps the data values of X to different visual signals that may be partitioned spatially and temporally and may use different amounts of spatial or temporal bandwidth. The visual decoder attempts to recover information about X, for example, by estimating its data values and determining its relationships with data conveyed by other signals. The mux and demux are part of the vis-encoder and vis-decoder respectively. Similar to the terminology in communication, the connection between the mux and demux is referred to as vis-link that consists of multiple visual channels (cf. [CJ10]). ", "caption_bbox": [59, 259, 692, 348]}, {"image_id": 1, "file_name": "599_01.png", "page": 4, "dpi": 300, "bbox": [58, 75, 693, 596], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Different types of visual multiplexing. While multiplexing may occur in several places in each illustration, we focus on a specific point p indicated by arrows on the bounding box. For Type J (model-based), three sets of illustrations are shown. ", "caption_bbox": [59, 610, 692, 638]}, {"image_id": 2, "file_name": "599_02.png", "page": 6, "dpi": 300, "bbox": [58, 75, 692, 847], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Examples of multiplexing in visualization. IEEE, Wiley-Blackwell and SAGE granted the permission to reprint the images in this figure, and the corresponding authors were informed. The image in (b) was provided by Dr. T. Isenberg, INRIA. ", "caption_bbox": [58, 861, 691, 889]}, {"image_id": 3, "file_name": "599_03.png", "page": 8, "dpi": 300, "bbox": [58, 75, 689, 243], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Uniplexed and multiplexed dot plots for time series visualization. Plots (a), (b), (c), (d), and (e) show 1, 2, 4, 8, 16 time series respectively, each of which is an instance of an independent data space Xi , i = 1, 2, . . . , 16. Although the original data was obtained from DataMarket.com, it is not intended here to visualize that dataset. In order to illustrate the calculation of information theoretic measures, the data has been mapped to the integer value range [0, 63]. ", "caption_bbox": [58, 251, 691, 310]}], "600": [{"image_id": 0, "file_name": "600_00.png", "page": 1, "dpi": 300, "bbox": [375, 327, 693, 707], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Pixel-cell based visualization for time series data. The highlighted values share the same data value of 0.6. Due to the surrounding regions in the visualization, contrast effects let us perceive the data points differently. ", "caption_bbox": [389, 722, 693, 781]}, {"image_id": 1, "file_name": "600_01.png", "page": 2, "dpi": 300, "bbox": [58, 75, 608, 364], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Standard examples of simultaneous contrast. (Top) Original images. The gray patches share the same gray values but are perceived differently (a) or as a gradient (c). The cats (e) share the same gradient from less saturated blue to yellow. (Bottom) Compensated images. The patches and cats are almost perceived equal. (b) Our method reduces the contrast effect on the patches to faithfully represent the gray value (3). (d) The method reduces the perceptually induced gradient (6). (f) Our method improves the global gradient and average color of the cats (7). ", "caption_bbox": [57, 377, 693, 451]}, {"image_id": 2, "file_name": "600_02.png", "page": 3, "dpi": 300, "bbox": [65, 446, 348, 550], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Schematic approach. The method iteratively re- duces the difference between perceived and original image. ", "caption_bbox": [58, 562, 361, 590]}, {"image_id": 3, "file_name": "600_03.png", "page": 6, "dpi": 300, "bbox": [112, 221, 306, 372], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Task of experiment 1. Participants had to draw a line (shown in yellow) that estimates the value at each point in the time series shown above and below the drawing field. The colormap was given for reference. ", "caption_bbox": [57, 382, 361, 441]}, {"image_id": 4, "file_name": "600_04.png", "page": 7, "dpi": 300, "bbox": [120, 75, 694, 236], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Results of experiment 1. (a) Pairwise distance measure for participant-participant and participant-model comparison. (b) Error of participants in the metric task using standard mapping and our compensation method. ", "caption_bbox": [57, 247, 693, 275]}, {"image_id": 5, "file_name": "600_05.png", "page": 7, "dpi": 300, "bbox": [444, 553, 639, 735], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Results of experiment 2. (Top) The percentage of correct data value assignments increases if our method is applied on perceptual linear colormaps. (Bottom) The percentage of correct data value comparisons does increase with our method. ", "caption_bbox": [390, 746, 691, 820]}, {"image_id": 6, "file_name": "600_06.png", "page": 9, "dpi": 300, "bbox": [58, 491, 693, 585], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Detail of a news visualization in [WRM\u2217 09] using colored triangles with low alpha value for representing single news items in time. The images show the original a) and compensated b) visualizations. The normalized difference between a) and b) is shown in c). Depending on the color, single news items in a) appear as bright as dense episodes of news. Our compensation in b) compensates the contrast effects and the corrects the impression of single news. ", "caption_bbox": [58, 592, 692, 655]}, {"image_id": 7, "file_name": "600_07.png", "page": 9, "dpi": 300, "bbox": [94, 75, 694, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Detail of Vanderbei\u2019s Purple America map of the 2012 presidential election in the US [Van12]. The images show the original a) and compensated b) visualizations. The normalized difference between a) and b) is shown in c). The labels in c) mark the districts or counties Baine/ID (A), Teton/WY (B), and Big Horn/MT (C). The colors in a) appear crisp and saturated due to color contrast effects. Our compensation removes color contrasts and the resulting image b) appears less saturated with dull colors but represents the data faithfully. In b) the share of blue increases from (B) to (A) and (C), which accords to the data. ", "caption_bbox": [58, 395, 691, 469]}], "601": [{"image_id": 0, "file_name": "601_00.png", "page": 6, "dpi": 300, "bbox": [58, 75, 676, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A snapshot of ConVis for exploring blog conversation: The Thread Overview visually represents the whole conversa- tion encoding the thread structure and how the sentiment is expressed for each comment(middle); The Facet Overview presents topics and authors circularly around the Thread Overview; and the Conversation View presents the actual conversation in a scrollable list (right). Here, topics and authors are connected to their related comments via curved links. ", "caption_bbox": [58, 396, 691, 455]}, {"image_id": 1, "file_name": "601_01.png", "page": 7, "dpi": 300, "bbox": [59, 75, 378, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Hovering the mouse over a topic element (\u2018ma- jor army security\u2019) causes highlighting the connecting vi- sual links, brushing the related authors, and providing visual prominence to the related comments in the Thread Overview. ", "caption_bbox": [58, 251, 359, 310]}, {"image_id": 2, "file_name": "601_02.png", "page": 7, "dpi": 300, "bbox": [375, 75, 694, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Clicking on a topic results in drawing a thick ver- tical outline next to each of the related comments. ", "caption_bbox": [391, 251, 692, 279]}, {"image_id": 3, "file_name": "601_03.png", "page": 7, "dpi": 300, "bbox": [417, 287, 667, 456], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An example showing: (a) The user clicked on a comment (the one with horizontal outlines) in the Thread Overview. (b) As a result, the system automatic scrolled to the actual comment in the Conversation View. ", "caption_bbox": [391, 469, 692, 528]}, {"image_id": 4, "file_name": "601_04.png", "page": 8, "dpi": 300, "bbox": [58, 75, 378, 210], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison of uses patterns between two partic- ipants using the two different strategies on the conversation titled \u201cMusic Streaming to Overtake Downloads\u201d. ", "caption_bbox": [58, 222, 359, 265]}], "602": [{"image_id": 0, "file_name": "602_00.png", "page": 2, "dpi": 300, "bbox": [58, 75, 378, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Narrative structure created with Networks of Names: The CDU donations scandal (1999), see     http://en.wikipedia.org/wiki/CDU_ donations_scandal. ", "caption_bbox": [59, 292, 360, 350]}, {"image_id": 1, "file_name": "602_01.png", "page": 3, "dpi": 300, "bbox": [377, 75, 693, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Networks of Names: The preprocessor extracts a network from the corpus (1). Users search (2a) for an in- teresting subgraph that contains the query and expand on demand (2b). Search and expansion is handled by the server (3). Users tag source sentences (2c). User-created tags are used for classifier training and application (4). ", "caption_bbox": [391, 355, 692, 444]}, {"image_id": 2, "file_name": "602_02.png", "page": 4, "dpi": 300, "bbox": [378, 75, 692, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visual aid for graph exploration: Hovering a node highlights incident edges and adjacent nodes. ", "caption_bbox": [391, 292, 692, 320]}, {"image_id": 3, "file_name": "602_03.png", "page": 5, "dpi": 300, "bbox": [377, 75, 693, 691], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Search and expand using a DOI measure based on node frequency. Two very different searches, Angela Merkel (the chancellor of Germany) and Stefan Raab (an enter- tainer and TV host) have very similar results due to a strong bias towards high-frequency nodes. ", "caption_bbox": [391, 704, 692, 778]}, {"image_id": 4, "file_name": "602_04.png", "page": 6, "dpi": 300, "bbox": [58, 75, 378, 336], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Search for Stefan Raab using our edge-based DOI measure. The result shows a neighbourhood containing ver- tices that are closely related to the focal node (instead of ex- panding globally interesting nodes such as political parties and politicians, as seen in Figure 4 (b)). ", "caption_bbox": [59, 346, 360, 420]}, {"image_id": 5, "file_name": "602_05.png", "page": 6, "dpi": 300, "bbox": [378, 75, 692, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The sources view shows source sentences for a re- lationship. Sentences appear grouped by similarity and can be tagged by users. Tag labels appear on the corresponding graph edge. User-created tags are utilized to train an auto- matic relationship classifier. ", "caption_bbox": [391, 399, 692, 473]}], "603": [{"image_id": 0, "file_name": "603_00.png", "page": 2, "dpi": 300, "bbox": [58, 75, 693, 515], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Comparison of 495 papers of InfoVis, SciVis, and Siggraph (discrimination threshold = 6, number of topics = 30)", "caption_bbox": [67, 528, 683, 541]}, {"image_id": 1, "file_name": "603_01.png", "page": 7, "dpi": 300, "bbox": [375, 75, 694, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Topic coins arranged line-by-line and sorted ac- cording to their class membership. ", "caption_bbox": [391, 279, 692, 307]}, {"image_id": 2, "file_name": "603_02.png", "page": 9, "dpi": 300, "bbox": [81, 75, 694, 573], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Presidential Debates of 2012 (discrimination threshold = 2, number of topics = 80)", "caption_bbox": [144, 586, 607, 599]}], "604": [{"image_id": 0, "file_name": "604_00.png", "page": 1, "dpi": 300, "bbox": [58, 615, 693, 828], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Electrostatic potential (bottom row) and comparative visualization (top row) of six C. antarctica Lipase B (CALB) simulation results with increasing methanol (MeOH) activity. The top row shows a comparison of conformer one (a) with respect to all other conformers (b-f). The gradual change in the electrostatic potential complies with the change in MeOH activity. The conformer shown in (a) differs most from the one in (f), which is shown in our rendering by a more saturated patch (arrow). ", "caption_bbox": [59, 554, 692, 613]}, {"image_id": 1, "file_name": "604_01.png", "page": 5, "dpi": 300, "bbox": [72, 75, 378, 193], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Comparison of the original GVF [XP98] and our modified GVF. In the regions marked by the blue arrows, the original GVF causes the source surface S (dashed line) to be pulled towards the wrong side of the target surface T (solid line). This would lead to self-intersection in the deformation process. This issue is resolved when using our modified GVF. ", "caption_bbox": [59, 207, 360, 296]}, {"image_id": 2, "file_name": "604_02.png", "page": 6, "dpi": 300, "bbox": [59, 75, 378, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A discrete plot of the external forces computed with our GVF approach. (a) shows the initial external forces obtained from the gradients in the border regions of both the source surface S (blue) and the target surface T (ochre). (b) shows streamlines following the final external forces. ", "caption_bbox": [59, 256, 360, 330]}, {"image_id": 3, "file_name": "604_03.png", "page": 6, "dpi": 300, "bbox": [375, 75, 672, 194], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) illustrates how the deformation can lead to oversized triangles. (b) shows our subdivision approach with subsequent backtracking for consistent sampling. ", "caption_bbox": [391, 209, 692, 252]}, {"image_id": 4, "file_name": "604_04.png", "page": 8, "dpi": 300, "bbox": [393, 653, 688, 738], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: 2D plot of the global descriptors D\u03c6 , Dsign , and G computed with our method, as well as the RMSD. The same subset of variants is shown as in Figure 1. The gradual change in D\u03c6 and Dsign suggests a correlation to the chang- ing solvent mixture that is not present in the purely geometric RMSD and G. ", "caption_bbox": [391, 753, 692, 842]}, {"image_id": 5, "file_name": "604_05.png", "page": 8, "dpi": 300, "bbox": [405, 373, 679, 551], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A matrix plot for 152 conformers of CALB, show- ing the mean absolute potential difference D\u03c6 . The upper half of the matrix is omitted if symmetry is given (using a tolerance value, which is defined as a percentage of to the difference range). ", "caption_bbox": [391, 563, 692, 637]}, {"image_id": 6, "file_name": "604_06.png", "page": 8, "dpi": 300, "bbox": [58, 373, 362, 443], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Mapping of surface parts with different genus. The source mesh is pulled into the sides of the target meshes\u2019 tunnel, leading to two patches of unmapped triangles (or- ange parts, middle), which become transparent in the final rendering (right). ", "caption_bbox": [59, 454, 360, 528]}, {"image_id": 7, "file_name": "604_07.png", "page": 8, "dpi": 300, "bbox": [59, 75, 652, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A comparative surface rendering of two variants of P450. On the left are the target surface (a) and the source one (b) colored by electrostatic potential. The circle in (c) highlights a region where both the local geometry and the potential are similar. An area of high potential differences is near the arrow. (d) and (e) show areas of high local geometrical differences, which we render with increased transparency. ", "caption_bbox": [59, 285, 692, 344]}, {"image_id": 8, "file_name": "604_08.png", "page": 9, "dpi": 300, "bbox": [375, 75, 694, 176], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: In some situations, the GVF creates saddles that prevent morphing of a newly created vertex (arrow) inside the cavity. ", "caption_bbox": [391, 188, 692, 231]}, {"image_id": 9, "file_name": "604_09.png", "page": 9, "dpi": 300, "bbox": [72, 75, 378, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Comparison of 2YPI-A with 25 other proteins us- ing our descriptor G, the Zernike-based descriptor presented in [SLL\u2217 08] (denoted by Z), and the RMSD. ", "caption_bbox": [59, 267, 360, 310]}], "605": [{"image_id": 0, "file_name": "605_00.png", "page": 2, "dpi": 300, "bbox": [375, 75, 645, 612], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Our method applied to two molecular surfaces: (a) illustration of the surface structure of an isomerase pro- tein and (b) focus-and-context visualization for an ATPase. The 2D LUT shown in (b) was used for both renderings. ", "caption_bbox": [391, 625, 692, 684]}, {"image_id": 1, "file_name": "605_01.png", "page": 4, "dpi": 300, "bbox": [59, 75, 689, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A lipase model with different feature lines methods. We have ridge and valleys (RV), suggestive contours (SC), apparent ridges (AR), photic extremum line (PEL), and our approach. Note that our method marks salient region whereas feature lines depict salient details using lines. ", "caption_bbox": [58, 248, 691, 291]}, {"image_id": 2, "file_name": "605_02.png", "page": 5, "dpi": 300, "bbox": [99, 75, 378, 221], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration of the Isomerase I data set. Every ver- tex i is assigned to (\u03c4i , 1 \u2212 \u03b1 \u00b7 |\u03d5i |). The values correspond to the x- and y-component of the texture (right). ", "caption_bbox": [59, 233, 360, 276]}, {"image_id": 3, "file_name": "605_03.png", "page": 5, "dpi": 300, "bbox": [58, 308, 359, 347], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The first eight textures of a noise texture pyramid. The first texture has size 1 \u00d7 1. ", "caption_bbox": [59, 359, 360, 388]}, {"image_id": 4, "file_name": "605_04.png", "page": 5, "dpi": 300, "bbox": [375, 75, 693, 219], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An example of the lipase model with high-quality hatching (HQ), ConFIS, and our approach. ", "caption_bbox": [391, 232, 692, 261]}, {"image_id": 5, "file_name": "605_05.png", "page": 6, "dpi": 300, "bbox": [59, 75, 693, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: From a given mesh, the screen-based ambient occlusion (SSAO) term and the illumination gradient (IG) is determined. These values correspond to the RGB-values of the texture. The assigned color values are combined with the shading and the noise. Finally, LIC is applied to obtain the result. ", "caption_bbox": [59, 366, 692, 409]}, {"image_id": 6, "file_name": "605_06.png", "page": 7, "dpi": 300, "bbox": [61, 412, 689, 598], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The DNA model with 65.634 ((a) \u2013 (c)) and 3.280 ((d) \u2013 (f)) triangles. Our method shows robust result regarding the tessellation compared with the ConFIS method. We used the texture in Figure 1(b). ", "caption_bbox": [59, 611, 692, 639]}, {"image_id": 7, "file_name": "605_07.png", "page": 7, "dpi": 300, "bbox": [61, 75, 694, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Different molecules illustrated with our approach: (a) shows a small peptide as VDW surface; (b) is a focus-and- context rendering of a porin, where a smooth molecular surface and a secondary structure (cartoon) representation are com- bined; (c) illustrates the solvent excluded surface of a potassium channel. The LUT shown in Figure 3 was used for all images. ", "caption_bbox": [59, 339, 692, 382]}, {"image_id": 8, "file_name": "605_08.png", "page": 8, "dpi": 300, "bbox": [390, 397, 683, 570], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: (a) Qualitative exploration of the hemodynamics (aneurysm); (b) Focus-and-context visualization with the left ventricle and their interior infarction scar. ", "caption_bbox": [391, 583, 692, 626]}, {"image_id": 9, "file_name": "605_09.png", "page": 9, "dpi": 300, "bbox": [58, 75, 694, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The Isomerase II (upper row) and hydrogel model in different animation steps with the LUT in 1(b). The upper row shows a gradual change of the surface parameter. The lower row shows different time steps from a simulation trajectory. ", "caption_bbox": [59, 376, 692, 404]}], "606": [{"image_id": 0, "file_name": "606_00.png", "page": 2, "dpi": 300, "bbox": [59, 75, 686, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization of a validation experiment for a DNA-binding surface classifier. The corpus overview (left) is configured to display each molecule as a quilted glyph and orders these glyphs by classifier performance to show how performance varies over the molecules. Selected molecules (left, yellow box) are visualized as heatmaps in a subset view (middle) and ordered by molecule size to help localize the positions of errors relative to correct answers. The detail view (right) shows a selected molecule to confirm that most errors (blue, red) are close to the correctly found binding site (green). ", "caption_bbox": [59, 348, 692, 422]}, {"image_id": 1, "file_name": "606_01.png", "page": 5, "dpi": 300, "bbox": [60, 75, 693, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Different glyph encodings for overviews afford different observations about the data.", "caption_bbox": [139, 276, 612, 289]}, {"image_id": 2, "file_name": "606_02.png", "page": 6, "dpi": 300, "bbox": [59, 75, 378, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Clustering similar values creates discrete regions that can be identified visually and by interaction. ", "caption_bbox": [59, 330, 360, 358]}, {"image_id": 3, "file_name": "606_03.png", "page": 6, "dpi": 300, "bbox": [375, 75, 686, 431], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A multivariate encoding for a scalar field (shown as the purple-to-green color field) overlayed on classification values shown as procedural textures (checkerboard, grid, Perlin noise). Note how TP (checkerboard) and FP (grid) generally correlate with positive charge (green), suggesting a correlation between charge and positive predictions. ", "caption_bbox": [391, 442, 692, 531]}, {"image_id": 4, "file_name": "606_04.png", "page": 7, "dpi": 300, "bbox": [74, 75, 694, 401], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Our approach applied to the validation of a DNA-binding classifier. The overview window (left) displays the corpus rendered as quilted blocks (\u00a73.2), giving an idea of aggregate performance across the corpus. The detail window (right) shows the clustered classifications (\u00a74.1) for PDB: 1PVR_A, highlighted in yellow in the overview window. These clusters are itemized (lower right), allowing for highlighting regions of interest and automatic navigation to view a selected region. ", "caption_bbox": [59, 414, 692, 473]}, {"image_id": 5, "file_name": "606_05.png", "page": 8, "dpi": 300, "bbox": [59, 75, 378, 899], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Analyzing the spatial clustering of a DNA-binding classifier reveals high-level trends of classification. ", "caption_bbox": [59, 913, 360, 941]}], "607": [{"image_id": 0, "file_name": "607_00.png", "page": 3, "dpi": 300, "bbox": [434, 189, 650, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A prescription can be seen as a hyperedge con- necting a physician, a patient, and a medicine. ", "caption_bbox": [391, 317, 692, 345]}, {"image_id": 1, "file_name": "607_01.png", "page": 3, "dpi": 300, "bbox": [95, 649, 325, 770], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A prescription can be seen as the dose as a func- tion of the time. We can derive several metrics: the initial dose (dinit ), the maximum dose (dmax ), and the time it takes to reach the maximum dose (tstm ). ", "caption_bbox": [59, 780, 360, 841]}, {"image_id": 2, "file_name": "607_02.png", "page": 4, "dpi": 300, "bbox": [107, 349, 313, 556], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A comparison between (a) the 3-partite graph and (b) Jigsaw\u2019s List View, visualizing the same sample data. In the List View, physician 1, patient 1, medicine 1, and medicine 2 are selected simultaneously. ", "caption_bbox": [59, 567, 360, 626]}, {"image_id": 3, "file_name": "607_03.png", "page": 4, "dpi": 300, "bbox": [406, 300, 678, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The same tables as in Figure 3b, but the relations are denoted with RRGs. Selected rows are highlighted in the table\u2019s color (blue, green, and orange), and the RRGs are shown in corresponding colors. (d1 ) A physician who pre- scribed both selected medicines to the selected patient, indi- cated by the green and orange boxes in front; (p1 ) A patient who received m1 and m2 from d1 ; (m1 , m2 ) Medicines that d1 prescribed to p1 ; (d2 ) A physician who prescribed only one of the selected medicines, indicated by a small orange box; (p2 ) A patient who received m1 and m2 , but not both from d1 , indicated by a missing thick border around the two boxes. ", "caption_bbox": [391, 395, 692, 575]}, {"image_id": 4, "file_name": "607_04.png", "page": 5, "dpi": 300, "bbox": [58, 75, 694, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Screenshot of the 3TV showing its tables with physicians, patients, and medicines: (a) A selected physician is high- lighted with a blue color; (b) Additional columns show distribution characteristics such as the number of patients treated by a physician; (c) A legend explains in natural language how the RRGs have to be interpreted, and shows between brackets how many of these exist in the corresponding table; (d) Row extensions can be used to obtain detailed information about a specific item, in this case the patient\u2019s medication history; (e) The selection on the timeline indicates the interval from which the data is taken; (f) Grayed out rows show physicians, patient, or medicines that have no prescriptions in the selected time window. ", "caption_bbox": [59, 364, 692, 453]}, {"image_id": 5, "file_name": "607_05.png", "page": 6, "dpi": 300, "bbox": [58, 75, 694, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Screenshot of the 3TV with a different configuration compared to Figure 5: (a) Patients are grouped by the column that indicates whether they have a symptomatic localization-related syndrome (classified as ILAE 12), this results in two groups; (b) By sorting on the RRG column, we find out that Carbamazepine is the most commonly prescribed medicine for patients with this syndrome; (c) Sparklines give a global indication of how the number of prescriptions associated with each row develops over time; (d) An extension showing a medicine\u2019s prevalence (the number of patients using it) over time, the green graph represents the selected patients. In case of Vigabatrin we spot a sudden decrease of patients just before the year 2000, due to a discovery that this medicine can cause blindness. Other views on medicines can be selected by pressing the buttons in the top right corner of the extension. ", "caption_bbox": [59, 365, 692, 485]}, {"image_id": 6, "file_name": "607_06.png", "page": 7, "dpi": 300, "bbox": [58, 75, 694, 470], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Screenshot of two tabs of the Prescription View, comparing Physician 9 with his colleagues. The left tab shows the dose distribution for Carbamazepine, while the right tab shows how other medicines are combined with Lamotrigine. (a) The size of the primary and secondary selection; (b) Metrics are grouped by tabs; (c) Histogram showing that Physician 9 starts with relatively low doses (either because of a different patient population, or a real difference in individual behavior); (d) A legend indicates the queries for both selections; (e) Histogram showing that Pipamperon is usually not combined with Lamotrigine, but Physician 9 does this for 30% of the prescriptions. (f) Radio buttons to select whether the primary and/or secondary selection is currently adjusted by the 3TV. ", "caption_bbox": [59, 481, 692, 585]}], "608": [{"image_id": 0, "file_name": "608_00.png", "page": 1, "dpi": 300, "bbox": [68, 352, 683, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The workflow of our proposed method which comprises four stages: attribute inspection, guided uncertainty-aware lasso for defining features, feature extraction through automated transfer function tuning and finally spatial fine tuning and visualization. Shown in this figure is the example of extracting the tumor core in a multimodal MR brain scan data. ", "caption_bbox": [58, 549, 691, 592]}, {"image_id": 1, "file_name": "608_01.png", "page": 3, "dpi": 300, "bbox": [375, 74, 693, 249], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: On an MR brain scan dataset, the inspection window with attribute, T1C, is shown over a tumor region with the FLAIR attribute as background. The boundary con- fidence derived from T1C, is rendered overlaying the data slice with a color map shown to the right. ", "caption_bbox": [391, 259, 692, 333]}, {"image_id": 2, "file_name": "608_02.png", "page": 5, "dpi": 300, "bbox": [124, 74, 378, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Left, shows the lasso image Is where the red indi- cates the lasso region. The transfer function classified image I f is seen in the center where the blue and green regions are classified by the transfer function. Right, sees the connected component image Ic where blue is the dominant connected component. ", "caption_bbox": [58, 206, 359, 295]}, {"image_id": 3, "file_name": "608_03.png", "page": 6, "dpi": 300, "bbox": [86, 442, 334, 680], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: On the top, shows the steps involved in transfer function modification by bin dropping. In the bottom left is the initial transfer function classified result (green) using the queried values from the lasso (white) on the MR brain scan HG11. To the right, the optimized transfer function classifi- cation result. ", "caption_bbox": [58, 690, 359, 779]}, {"image_id": 4, "file_name": "608_04.png", "page": 7, "dpi": 300, "bbox": [134, 74, 693, 449], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The first row shows the upper channel in the New Zealand seismic data. Shown in subfigure (a) is the lasso which extracts the feature, (b) is the result using GuideME, and (c) is the result generated by a domain expert using [ZH13]. The salt dome is shown to the bottom. In subfigure (d) shows the lasso region drawn for feature extraction, in (e), shows the result using GuideME, and in (f), the result extracted by the domain expert. ", "caption_bbox": [58, 459, 691, 518]}, {"image_id": 5, "file_name": "608_05.png", "page": 8, "dpi": 300, "bbox": [58, 74, 620, 421], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Quantitative comparisons and timing results for the features extracted in the example datasets. For the tim- ings, the first numbers in the parenthesis are the automated transfer function tuning time while the second numbers are the 3D connected component finding time. ", "caption_bbox": [58, 692, 359, 766]}], "609": [{"image_id": 0, "file_name": "609_00.png", "page": 1, "dpi": 300, "bbox": [91, 361, 661, 530], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Demonstration of our system capabilities from three different zooming levels (left to right). We showcase a scene containing 106 diffusing and reacting molecules in real-time at 30 FPS. ", "caption_bbox": [59, 542, 692, 571]}, {"image_id": 1, "file_name": "609_01.png", "page": 4, "dpi": 300, "bbox": [59, 75, 643, 282], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of our system: A biological process is represented by a metabolic network model, which is numerically simulated. The Omniscient Intelligence module routinely reads the results from the quantitative simulation, and dispatches reaction events to the agents. The final stage of the pipeline represents elements with their structural models and renders the entire scene at interactive framerates. ", "caption_bbox": [59, 295, 692, 354]}, {"image_id": 2, "file_name": "609_02.png", "page": 4, "dpi": 300, "bbox": [399, 392, 682, 538], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparison between a fully stochastic system (a) and our system (b). In a fully stochastic system we can ob- serve reaction happening in the scene at random locations, and without any follow-up according to the pathway. On the other hand, in our system it is possible to visualize reaction immediately and to build reactions sequences. ", "caption_bbox": [391, 550, 692, 639]}, {"image_id": 3, "file_name": "609_03.png", "page": 5, "dpi": 300, "bbox": [95, 75, 378, 182], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Description of the reaction motion, we blend a random walk motion (left), with linear interpolation (mid- dle) in order to get a consistent attraction motion (right). ", "caption_bbox": [59, 197, 360, 240]}, {"image_id": 4, "file_name": "609_04.png", "page": 6, "dpi": 300, "bbox": [59, 75, 378, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Representation of the Array-of-Structure allo- cated on the GPU memory, each index value corresponds to one molecule and can be used to access the properties form the different buffer. On the CPU a book-keeping is constantly maintained in order to access elements of a given type, when the buffers are all sorted according to the molecule type ", "caption_bbox": [59, 225, 360, 314]}, {"image_id": 5, "file_name": "609_05.png", "page": 7, "dpi": 300, "bbox": [406, 727, 678, 859], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: An example of LOD application. The same scene is rendered without (left, 43 948 997 atoms) and with LOD (right, 7 227 817 atoms). Notice that for the molecules that are further in the back (the closeups), only negligible differ- ences are visible. ", "caption_bbox": [391, 870, 692, 944]}, {"image_id": 6, "file_name": "609_06.png", "page": 7, "dpi": 300, "bbox": [73, 448, 346, 547], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An example of our molecular Level-of-Detail. With increasing distance to the camera, more atoms are skipped. The radii of the remaining atoms are scaled accordingly. ", "caption_bbox": [59, 559, 360, 602]}, {"image_id": 7, "file_name": "609_07.png", "page": 8, "dpi": 300, "bbox": [59, 75, 662, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Snapshots from the NAD pathway. The examples show four extracted frames from four reactions involved in NAD pathway. We see four enzymes (yellow \u2014 NAMPT_ATP, blue \u2014 NMNAT1_NMN, green \u2014 NNMT, red \u2014 PARP1) that catalyze these reactions. The camera follows metabolites that take part in reactions (small molecules). The navigation is done fully automatically, where in a case that there are two reaction products a user can interactively select which one to follow. ", "caption_bbox": [59, 244, 692, 303]}], "610": [{"image_id": 0, "file_name": "610_00.png", "page": 2, "dpi": 300, "bbox": [59, 75, 693, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An overview of the data analysis pipeline. On the left-hand side, the simulation inputs are depicted. Patient-specific morphology is obtained by segmentation of computed tomography (CT) imaging data. Together with this geometry, inflow conditions and different stent configurations are used to model the blood flow behavior. The blood flow simulations, shown in the middle, provide for each stent configuration a time-varying volumetric velocity field, as well as vessel wall characteristics. Visual analysis of this abundance of information is tedious and time-consuming. Therefore, we present a comprehensive comparative visualization that supports the decision-making process for stent placement, as depicted on the right-hand side. ", "caption_bbox": [59, 320, 692, 409]}, {"image_id": 1, "file_name": "610_01.png", "page": 3, "dpi": 300, "bbox": [70, 75, 693, 399], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An overview of the two cerebral aneurysm datasets and their stent configurations. The top row depicts the VISC 2010 data set configurations, comprising from left to right two Neuroform and two SILK type stents, each in different positions. The bottom row depicts a dataset with a known rupture location, visible as a small bulge on the aneurysm sac. For this dataset only the SILK type stent was used. The configuration legend, shown in the top right, consistently encodes the color for the individual configurations of each dataset, where configuration 1 represents the non-stented aneurysm. ", "caption_bbox": [59, 407, 692, 481]}, {"image_id": 2, "file_name": "610_02.png", "page": 5, "dpi": 300, "bbox": [64, 75, 378, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The proposed glyph set enables details-on- demand using zoom levels. The levels have a coherent tran- sition and provide progressively rich information. The first level shows a disk glyph that conveys the overall maximum WSS. By zooming in, the flower glyphs shows the maximum WSS over time for each stent configuration. The web glyph furthermore conveys the WSS variations in time, first as a subsampling (3a) and finally with time variation strips (3b). ", "caption_bbox": [59, 303, 360, 423]}, {"image_id": 3, "file_name": "610_03.png", "page": 6, "dpi": 300, "bbox": [59, 75, 690, 538], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The proposed workflow for exploration (dataset 1). (1a) Assess the overview using disk glyphs combined with the endovascular flow, depicted by the inflow jets (arrow glyphs) and impingement zones (contours). (1b) Hovering the mouse over the configuration legend shows the stent geometry. (2) Zooming in reveals the flower glyphs, enabling comparison of the maximum WSS between configurations. (3a) Closing in further, the web glyphs show the temporal WSS variation using five subsamples. (3b) Configuration four is omitted. (4) Time ribbons give more details on the temporal WSS variation. ", "caption_bbox": [59, 552, 692, 626]}, {"image_id": 4, "file_name": "610_04.png", "page": 8, "dpi": 300, "bbox": [59, 75, 685, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: An informal evaluation was conducted with domain experts. They were presented with the established juxtaposed grid visualization (left) to compare the hemodynamic information of different stent configurations, and were asked to compare this to our comparative visualization approach (right). Besides the WSS values on the vessel wall, our approach furthermore superimposes endovascular blood flow information, e.g., the inflow jets (dataset 1). ", "caption_bbox": [59, 324, 692, 383]}, {"image_id": 5, "file_name": "610_05.png", "page": 9, "dpi": 300, "bbox": [62, 75, 378, 296], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Stent configuration assessment visualization for dataset 2: the ruptured case. Configurations 5 appears most suitable, since it results in a low WSS on the aneurysm and exhibits a large impingement zone. ", "caption_bbox": [59, 307, 360, 366]}], "611": [{"image_id": 0, "file_name": "611_00.png", "page": 2, "dpi": 300, "bbox": [375, 75, 694, 216], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example of a 4D PC-MRI blood-flow dataset. Three slices depict the velocity components at 200ms. ", "caption_bbox": [391, 220, 692, 248]}, {"image_id": 1, "file_name": "611_01.png", "page": 3, "dpi": 300, "bbox": [124, 75, 693, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of the measurement-simulation coupling. The 4D PC-MRI data is represented by cubes with an arrow. We propose a coupled approach between the full measured data and hybrid fluid simulation, represented by grids and particles. For each time point of the cardiac cycle at which MRI data exists, the simulation is coupled with the measurements. In-between measurements, the simulation provides physics-based interpolated velocity fields, e.g., on the positions of the red dots. ", "caption_bbox": [59, 266, 692, 325]}, {"image_id": 2, "file_name": "611_02.png", "page": 5, "dpi": 300, "bbox": [375, 75, 693, 449], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparison of the coupling with other simulation approaches using synthetic data. The field average of the per voxel speed and angle dissimilarity are presented. used as ground truth. Notice that linear interpolation in time will give a perfect result for this simple data set. ", "caption_bbox": [391, 455, 692, 529]}, {"image_id": 3, "file_name": "611_03.png", "page": 6, "dpi": 300, "bbox": [59, 75, 670, 331], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparison of the robustness to noise of the coupling method (solid lines) with the standard interpolation (dashed lines) using synthetic data. The average over the field of the per voxel speed and angle dissimilarity values for different SNR levels compared to the noiseless results are shown. ", "caption_bbox": [59, 343, 692, 386]}, {"image_id": 4, "file_name": "611_04.png", "page": 7, "dpi": 300, "bbox": [71, 75, 378, 368], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Results of the dissimilarity measures between the measured and coupled simulation velocities in an oblique slice. The slice is captured at peak systole for a healthy vol- unteer data set. ", "caption_bbox": [59, 375, 360, 434]}, {"image_id": 5, "file_name": "611_05.png", "page": 7, "dpi": 300, "bbox": [375, 75, 694, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Measurement vectors are shown as gray arrows, and the coupled simulation vectors as arrows color-coded according to the angle between the vectors. Angles > 90\u25e6 are depicted. The vectors are located close to the boundary at peak systole for an aortic dissection case. ", "caption_bbox": [391, 375, 692, 449]}, {"image_id": 6, "file_name": "611_06.png", "page": 8, "dpi": 300, "bbox": [375, 75, 687, 374], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparative visualization of pathlines traced in the original measurements, depicted in gray, and the super- sampled velocity field obtained by our coupled simulation. The simulation pathlines are color-coded according to the Hausdorff distance. Pathlines with the 50% largest distances are depicted for a healthy volunteer data set at peak systole. ", "caption_bbox": [391, 390, 692, 479]}, {"image_id": 7, "file_name": "611_07.png", "page": 9, "dpi": 300, "bbox": [89, 75, 378, 374], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparative visualization between inviscid (gray pathlines) and viscid (pathlines color-coded by the Haus- dorff distance) simulation velocities. In both cases, our measurement-simulation coupling scheme was used. Only the pathlines with the 50% largest distances are shown. ", "caption_bbox": [59, 390, 360, 464]}], "612": [{"image_id": 0, "file_name": "612_00.png", "page": 2, "dpi": 300, "bbox": [375, 74, 649, 422], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The sensing and recovery pipeline. The CS frame- work allows us to sense the data without prior information of specific feature domains during the data reduction stage. Domain experts can refine the definition of features without having to repeat the simulation process. In the data recovery stage, the compressively sensed data can be reused to recon- struct the original data within different feature domains. ", "caption_bbox": [391, 433, 692, 538]}, {"image_id": 1, "file_name": "612_01.png", "page": 6, "dpi": 300, "bbox": [59, 74, 378, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Sparse approximation accuracy (red) and timing (blue) of the Aneurysm dataset. ", "caption_bbox": [58, 276, 359, 304]}, {"image_id": 2, "file_name": "612_02.png", "page": 6, "dpi": 300, "bbox": [375, 74, 667, 362], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Reconstruction of Aneurysm dataset. (a) Ground truth, the RLE of ground truth dataset yields a sampling rate of \u03c1 = 2.41%. (b) CS reconstruction from the sampling rate of \u03c1 = 2.41%. Downsampling (\u03c1 = 12.5%) with (c) linear and (d) cubic filters. The dotted boxes highlight some miss- ing vessels. ", "caption_bbox": [391, 370, 692, 459]}, {"image_id": 3, "file_name": "612_03.png", "page": 7, "dpi": 300, "bbox": [83, 74, 378, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Sparse approximation of the Hydrogen in the wavelet domain (red), the curvelet domain (blue) and the surfacelet domain (green). ", "caption_bbox": [58, 290, 359, 334]}, {"image_id": 4, "file_name": "612_04.png", "page": 7, "dpi": 300, "bbox": [375, 74, 694, 493], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Sparse approximation and interpolation of the Hy- drogen dataset with \u03c1 = 12.5%. ", "caption_bbox": [391, 501, 692, 530]}, {"image_id": 5, "file_name": "612_05.png", "page": 9, "dpi": 300, "bbox": [90, 74, 378, 362], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Sparse approximation vs cubic interpolation of the Head Aneurysm dataset of size 512 \u00d7 512 \u00d7 512 (\u03c1 = 12.5%). Close-up images are shown. ", "caption_bbox": [58, 370, 359, 414]}, {"image_id": 6, "file_name": "612_06.png", "page": 9, "dpi": 300, "bbox": [375, 74, 703, 259], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Sparse approximation using surfacelets and cubic interpolation of the Supernova dataset of size 432 \u00d7 432 \u00d7 432 (\u03c1 = 12.5%, time step 1345). ", "caption_bbox": [391, 273, 692, 317]}], "613": [{"image_id": 0, "file_name": "613_00.png", "page": 5, "dpi": 300, "bbox": [390, 640, 698, 829], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A system overview showing two views and one control panel. (a) Embedding view. (b) Parallel coordinates view. (c) Data panel. ", "caption_bbox": [391, 831, 692, 874]}, {"image_id": 1, "file_name": "613_01.png", "page": 6, "dpi": 300, "bbox": [59, 75, 685, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A typical interactive data exploration pipeline. We could apply different DR for an additional round of analysis, as well as different distortions inside each analysis cycle. (a) DR; (b) Distortion-guided selection of region of interest; (c)-(d) Hierarchical clustering of the data and distortion-guided clustering selection. (e) Data manipulations with on-the-fly update of distortion measures reveal structural insights of the data. (f) Parameter differentiations across different clusters for additional structural insights. ", "caption_bbox": [59, 311, 692, 385]}, {"image_id": 2, "file_name": "613_02.png", "page": 7, "dpi": 300, "bbox": [58, 568, 378, 732], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Parabola. (a) 3D embedding colored by z- coordinate. (b) 2D embedding colored by KDE distortion. (b)-(d) Distortion-guided clustering selection. On-the-fly up- date of distortion measures for data movement (e)-(f), and data deletion (g)-(h). Distortion measures adopt spectral colormap. ", "caption_bbox": [59, 734, 360, 823]}, {"image_id": 3, "file_name": "613_03.png", "page": 7, "dpi": 300, "bbox": [390, 303, 698, 444], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Combustion. (a) Points colored by temperature. (b)-(f) All five distortion measures (local cost, local stress, robust distance distortion, KDE distortion and co-rank dis- tortion) indicate an interesting region with high distor- tion around a temperature minima. Temperature image uses spectral colormap and distortion measure images adapt hot colormap. ", "caption_bbox": [391, 446, 692, 550]}, {"image_id": 4, "file_name": "613_04.png", "page": 8, "dpi": 300, "bbox": [375, 75, 697, 594], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Combustion. (a)-(b) Distortion-guided cluster se- lection. (c)-(e) On-the-fly updates of point-wise distortion measure (local stress) reflect structural relations between different parts of the data. (f) Validation of two overlapped temperature minima based on topological clustering. Distor- tion is colored by spectral colormap. The parameter boxes in (g) contain summary statistics of parameters in the clusters. ", "caption_bbox": [391, 596, 692, 700]}, {"image_id": 5, "file_name": "613_05.png", "page": 9, "dpi": 300, "bbox": [404, 165, 693, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Nuclear. (a) Interactive deletion of failure cases; (b)-(c) re-apply DR and visualize by local cost (b) and KDE distortion (c). Both visualizations reveal a point (indicate by white arrow) with high distortion that corresponds to a boundary scenario for the success cases. (d) Success sce- narios in parallel coordinate plots. Embedding views are rescaled in the paper due to space constraints. ", "caption_bbox": [391, 314, 692, 418]}, {"image_id": 6, "file_name": "613_06.png", "page": 9, "dpi": 300, "bbox": [62, 75, 378, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Nuclear. (a) Local stress; (b) Robust distance dis- tortion; (c) Distortion-guided cluster selection; (d) Points colored by their labels: system failure (yellow) and system success (purple); (e) Plot of 609 time-varying core tempera- ture profiles in the parallel coordinate plots where x-axis is time, y-axis is temperature. (f)-(g) On-the-fly update of local stress before (f) and after (g) movement of points belonging to the bottom cluster. The embedding views are re-scaled in the paper due to space constraints. ", "caption_bbox": [59, 375, 360, 510]}], "614": [{"image_id": 0, "file_name": "614_00.png", "page": 2, "dpi": 300, "bbox": [376, 75, 686, 525], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Workflow and features of the InSpectr tool.", "caption_bbox": [408, 536, 675, 549]}, {"image_id": 1, "file_name": "614_01.png", "page": 4, "dpi": 300, "bbox": [58, 75, 691, 368], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Schematic of InSpectr\u2019s interface and the interactions between the available views", "caption_bbox": [143, 379, 607, 392]}, {"image_id": 2, "file_name": "614_02.png", "page": 5, "dpi": 300, "bbox": [58, 75, 377, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Aggregated spectrum view using the maximum values of voxel spectra. In 1-3, individual voxel spectra probed on a 2D slice are shown. The image at the bottom shows the spectrum at point 4 together with the aggregated spectrum in gray. ", "caption_bbox": [59, 344, 360, 418]}, {"image_id": 3, "file_name": "614_03.png", "page": 5, "dpi": 300, "bbox": [375, 75, 695, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Semi-transparent spectra lines (a) and spectra his- tograms (b). The aggregated spectrum is shown in gray in the background. ", "caption_bbox": [391, 360, 692, 403]}, {"image_id": 4, "file_name": "614_04.png", "page": 6, "dpi": 300, "bbox": [390, 321, 695, 415], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The XCT data and the corresponding spectral color image (a). Spectral magic lenses: centered (b), with offset (c), and side-by-side (d). ", "caption_bbox": [391, 425, 692, 468]}, {"image_id": 5, "file_name": "614_05.png", "page": 6, "dpi": 300, "bbox": [58, 75, 378, 245], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Selection specified in the spectral view (a) and the selection results on the 2D slice (b) and in the 3D view (c). ", "caption_bbox": [59, 256, 360, 284]}, {"image_id": 6, "file_name": "614_06.png", "page": 6, "dpi": 300, "bbox": [376, 75, 695, 245], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Color transfer function defined in the spectral view (a), XCT slice (b), and resulting spectral color image (c). ", "caption_bbox": [391, 256, 692, 299]}, {"image_id": 7, "file_name": "614_07.png", "page": 7, "dpi": 300, "bbox": [375, 75, 695, 181], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Elemental composition at selected voxel, visual- ized in the pie-chart view (a) and in the periodic table view (b) ", "caption_bbox": [391, 192, 692, 235]}, {"image_id": 8, "file_name": "614_08.png", "page": 7, "dpi": 300, "bbox": [59, 75, 377, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Linked 3DXCT volume rendering (a) and individ- ual 3D element maps (b). Composite 3D element map for the TP09 specimen showing copper and zinc concentrations. ", "caption_bbox": [59, 246, 360, 289]}, {"image_id": 9, "file_name": "614_09.png", "page": 8, "dpi": 300, "bbox": [58, 75, 378, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Pie-chart glyphs", "caption_bbox": [138, 348, 280, 361]}, {"image_id": 10, "file_name": "614_10.png", "page": 9, "dpi": 300, "bbox": [59, 75, 377, 381], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Evaluation results: subjective usefulness and task solving ability are analyzed for the presented tech- niques. ", "caption_bbox": [59, 397, 360, 440]}], "615": [{"image_id": 0, "file_name": "615_00.png", "page": 3, "dpi": 300, "bbox": [400, 561, 680, 661], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Dual lattices in the frequency domain correspond- ing to equivalent CC, FCC, and BCC sampling lattices. (a): Dual CC lattice of a CC sampling lattice. (b): Dual BCC lattice of an FCC sampling lattice. (c): Dual FCC lattice of a BCC sampling lattice. ", "caption_bbox": [391, 669, 692, 743]}, {"image_id": 1, "file_name": "615_01.png", "page": 4, "dpi": 300, "bbox": [73, 115, 346, 603], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Packing of disc-shaped aliasing spectra in the fre- quency domain on dual CC, BCC, and FCC lattices that cor- respond to CC, FCC, and BCC sampling lattices of the same density, respectively. The green and red circles represent the primary spectrum and the MS aliasing spectra, respectively. ", "caption_bbox": [58, 612, 359, 686]}, {"image_id": 2, "file_name": "615_02.png", "page": 7, "dpi": 300, "bbox": [77, 75, 694, 545], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Reconstruction of the ML signal from 40 \u00d7 40 \u00d7 40 CC samples (a), 32 \u00d7 32 \u00d7 32 \u00d7 2 BCC samples (b), and 25 \u00d7 25 \u00d7 25 \u00d7 4 FCC samples (c). ", "caption_bbox": [58, 552, 691, 581]}, {"image_id": 3, "file_name": "615_03.png", "page": 7, "dpi": 300, "bbox": [126, 617, 628, 902], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Reconstruction of the ML signal from 40 \u00d7 40 \u00d7 40 CC samples (a) and from 25 \u00d7 25 \u00d7 25 \u00d7 4 FCC samples (b). The sampling lattices are rotated such that the prealiasing is increased on the FCC lattice but decreased on the CC lattice. ", "caption_bbox": [58, 909, 691, 938]}, {"image_id": 4, "file_name": "615_04.png", "page": 9, "dpi": 300, "bbox": [105, 524, 647, 898], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Portion of the primary spectrum that is not corrupted by the aliasing spectra depending on the sampling frequency.", "caption_bbox": [60, 908, 687, 921]}, {"image_id": 5, "file_name": "615_05.png", "page": 9, "dpi": 300, "bbox": [77, 75, 694, 476], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Estimated total prealiasing effect produced by CC, FCC, and BCC lattices depending on the sampling frequency.", "caption_bbox": [65, 486, 681, 499]}], "616": [{"image_id": 0, "file_name": "616_00.png", "page": 2, "dpi": 300, "bbox": [58, 75, 691, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "                                                                                                           TM Figure 1: 5 million atom molecular dynamics glass (SiO2 ) fracture data, rendered on a Intel R Xeon Phi SE10P in Stampede. Top: RBF volume rendering using two transfer functions to classify silicon and oxygen atoms as separate fields (11.7 fps at 2560 \u00d7 512, \u03ba = 4, dt = .5, \u03c3 = 2). Bottom: From left to right: close-up of the the top view (4.7 fps at 1024 \u00d7 1024); the same view reconstructed with narrower RBFs (3.1 fps, \u03ba = 1, dt = .125, \u03c3 = 2.835); trilinear interpolation of two-field structured data (2.1 fps, dt = .125), and tricubic B-spline interpolation of structured data (0.221 fps, dt = .125). The two-field structured data (1 voxel per \u00c5ngstr\u00f6m, 32-bit float) occupies 800 MB on disk and took 80 seconds to precompute on a 16-core CPU. RBF volume rendering incurs less memory overhead and exhibits better performance and quality for rendering atomistic data. ", "caption_bbox": [58, 377, 691, 485]}, {"image_id": 1, "file_name": "616_01.png", "page": 4, "dpi": 300, "bbox": [58, 75, 378, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Options for RBF field reconstruction. (1) Direct method: the field is evaluated directly at each sample along the ray, which can prove expensive. (2) Proxy method: the field is resampled into a grid, and then inexpensively recon- structed from the proxy, at the cost of memory and/or quality. ", "caption_bbox": [59, 280, 360, 354]}, {"image_id": 2, "file_name": "616_02.png", "page": 5, "dpi": 300, "bbox": [120, 75, 693, 259], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Coherent RBF algorithm. (a) Iterate through samples along a packet, depositing into a fixed-size buffer. (b) Each BVH leaf node (particle with support \u03c3 ) adds its value to all samples it overlaps in the buffer. (c) When this buffer has finished traversal, it is integrated front-to back using Equation 3, and we proceed to the next set of samples. In this manner, particles can be added to the buffer in any order, allowing for traversal of each particle once per packet and improving memory access. but maintaining only a small buffer of samples with little          4. Traverse the BVH, with nodes extended by \u03c3 , summing overhead, yielding the exact same quality as the direct ray            \u03c6 for every leaf at every sample (Equation 1) and storing casting method. This concept is illustrated in Figure 3.               that in Phi_buf; ", "caption_bbox": [59, 259, 692, 367]}, {"image_id": 3, "file_name": "616_03.png", "page": 6, "dpi": 300, "bbox": [59, 794, 354, 890], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Multi-material classification of RBF contribu- tions of separate atoms as separate volumetric fields. From left to right: silicon atoms only, oxygen atoms only, and both silicon and oxygen in a zeolite structure. ", "caption_bbox": [59, 889, 360, 948]}, {"image_id": 4, "file_name": "616_04.png", "page": 7, "dpi": 300, "bbox": [83, 75, 694, 765], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Data set statistics. (*)Single CPU thread (Xeon E5-2680). (**) 16 CPU threads. 32-bit float data, 1 voxel/\u00c5ngstr\u00f6m.", "caption_bbox": [59, 911, 691, 924]}, {"image_id": 5, "file_name": "616_05.png", "page": 8, "dpi": 300, "bbox": [395, 815, 687, 926], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: \u03c3 controls RBF truncation width, impacting per- formance and reconstruction quality. ", "caption_bbox": [391, 925, 692, 953]}, {"image_id": 6, "file_name": "616_06.png", "page": 8, "dpi": 300, "bbox": [395, 689, 687, 800], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Varying \u03ba increases both RBF value and width.", "caption_bbox": [393, 799, 685, 813]}, {"image_id": 7, "file_name": "616_07.png", "page": 8, "dpi": 300, "bbox": [375, 75, 688, 192], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Plots from Fig. 6. Left: Performance vs. number of particles. Right: Impact of early termination. ", "caption_bbox": [391, 191, 692, 219]}, {"image_id": 8, "file_name": "616_08.png", "page": 8, "dpi": 300, "bbox": [58, 75, 378, 194], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Performance with respect to data size, using sub- sets of the 82 million particle CubeP3M astrophysics data rendered with dt = 1 and varying \u03c3 . The table shows per- formance with both fixed and varying \u03c3 , see Figure 7(left). ", "caption_bbox": [59, 193, 360, 252]}, {"image_id": 9, "file_name": "616_09.png", "page": 9, "dpi": 300, "bbox": [58, 791, 361, 908], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Reference scenes from [KWN\u2217 13], rendered with a fixed dt of 0.5, using a standard 1D heatmap transfer func- tion, lighting enabled. Refer to frame rates in Table 2. ", "caption_bbox": [59, 907, 360, 954]}], "617": [{"image_id": 0, "file_name": "617_00.png", "page": 1, "dpi": 300, "bbox": [58, 546, 693, 706], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Three volumes with enlarged areas rendered with Irradiance Caching (left half) and normal Monte Carlo Volume Rendering (right half) after the same time. The extracted areas show a significant reduction in noise with our approach. ", "caption_bbox": [59, 510, 692, 538]}, {"image_id": 1, "file_name": "617_01.png", "page": 4, "dpi": 300, "bbox": [60, 180, 362, 282], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The overview over our system. Three procedures run in parallel on a single GPU. The scheduler distributes time slots for each of them based on the cache hit rate. The rendering procedure is also prioritized based on screen- space convergence information. ", "caption_bbox": [59, 293, 360, 367]}, {"image_id": 2, "file_name": "617_02.png", "page": 4, "dpi": 300, "bbox": [377, 75, 667, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Our approach consists of worker-blocks, contin- uously drawing tasks from queues. We keep one queue per procedure, which is essential for a divergence free execution of tasks with different granularities. ", "caption_bbox": [391, 287, 692, 346]}, {"image_id": 3, "file_name": "617_03.png", "page": 5, "dpi": 300, "bbox": [58, 75, 378, 189], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (Left) We compute the tentative extinction coeffi- cients \u03c3\u0303 as well as radii R for six directions (\u00b1i, \u00b1j, \u00b1k). (Right) When interpolating local extinction coefficients, the ellipsoidal shape may be inconsistent with the actual valid- ity radius if the ratio of irradiances at different axes is very high (inner graph). Therefore, to avoid visual artefacts, we discard the influence of a cache entry in areas beyond the in- terpolated validity radius (red hatching). However, for lower ratios (outer graph), the ellipsoidal shape is a good estimate for the actual validity radius. ", "caption_bbox": [59, 201, 360, 351]}, {"image_id": 4, "file_name": "617_04.png", "page": 5, "dpi": 300, "bbox": [58, 651, 362, 722], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Influence of the entry shape on the cache den- sity. The white lines denote the radii corresponding to the local coordinate frame of an entry. If the entry is represented as a union of elliptical sections, (middle) less cache entries are required compared to the spherical ones (left). Orienting these shapes along the opacity gradient (right) reduces the cache density even more because in many cases, the largest irradiance gradient coincides with the opacity gradient. Ori- enting the entries allows for larger validity zones, since the radius has to be small only along one axis. ", "caption_bbox": [59, 732, 360, 882]}, {"image_id": 5, "file_name": "617_05.png", "page": 6, "dpi": 300, "bbox": [377, 75, 664, 185], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Neighboring rays may issue cache entry creation requests at very similar positions. We avoid redundant cache entries by allowing only one cache entry to be created per octree node. Once a cache entry C is created, creation re- quests within the influence of C will be ignored. ", "caption_bbox": [391, 195, 692, 269]}, {"image_id": 6, "file_name": "617_06.png", "page": 6, "dpi": 300, "bbox": [91, 245, 329, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Reduction of radii in the local coordinate frame of the cache entry to exclude point p0 from the validity area in the corresponding octant of the cache entry. The radii are reduced proportionally to the coordinates of point p0 in the local coordinate frame. In this case, |p0i |/\u2206R(+i) = |p0j |/\u2206R(+j) . ", "caption_bbox": [58, 322, 359, 413]}, {"image_id": 7, "file_name": "617_07.png", "page": 6, "dpi": 300, "bbox": [58, 75, 378, 164], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (left) Visible artefacts can be produced if extrapo- lated irradiance does not capture the actual irradiance field. (right) The update procedure removes such artefacts. ", "caption_bbox": [59, 174, 360, 217]}, {"image_id": 8, "file_name": "617_08.png", "page": 7, "dpi": 300, "bbox": [88, 75, 378, 194], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: As the octree nodes are small in the areas of high cache density, more cache entries can be created in these areas in parallel. This does not lead to the creation of re- dundant cache entries, because the new entries are likely to have small radii as a high cache density suggests high frequency of irradiance change in this area. In this illustra- tion, the simultaneous creation of two entries, shown in red, will be allowed, while it will be forbidden for the two yellow ones, even though the distance between them is the same. ", "caption_bbox": [59, 204, 360, 339]}, {"image_id": 9, "file_name": "617_09.png", "page": 8, "dpi": 300, "bbox": [377, 75, 673, 178], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The ratio of average relative error of extrap- olated radiance values computed using the approach pre- sented in [JDZJ08] (|\u2206LJ |) to the ones computed with our method (|\u2206LO |) for scene with a single light source (blue) and with additional background illumination (orange). The red line shows the value of 1 which means no difference in average errors of two methods. The horizontal axis shows the global density factor D which is used to convert trans- fer function values in range [0, 1] to the density of partici- pating medium. Our method is significantly more accurate for higher gradient magnitudes, which are caused by larger global volume density factor D or by the light setup. Lower estimation errors for our method lead to the lower number of cache entries required to represent the irradiance field. ", "caption_bbox": [391, 190, 692, 401]}], "618": [{"image_id": 0, "file_name": "618_00.png", "page": 3, "dpi": 300, "bbox": [70, 75, 693, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: In a 1D function (a), the dissipation elements are the line segments in the domain corresponding to monotonic regions. In 2D, dissipation elements are deformed quadrilaterals (red square). A subset of dissipation elements are shown for a 3D example (c), each one a deformed crystal-like object. The boundary of a crystal in the Morse-Smale complex consists of lower-dimensional cells: quads, arcs, and nodes. Every crystal has a unique origin and destination node, the minimum and maximum, respectively, which are end points of integral lines lying within. ", "caption_bbox": [58, 234, 691, 308]}, {"image_id": 1, "file_name": "618_01.png", "page": 4, "dpi": 300, "bbox": [375, 75, 691, 186], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Dissipation elements are computed numerically (left), and the segmentation is displayed along with red lines between the minimum-maximum pairs. The MS complex is computed using discrete Morse theory for the same data, producing a similar segmentation (middle), displayed with corresponding colors. The boundaries of topological dissi- pation elements are shown over the numerically computed ones (right) as a comparison of the segmentation. ", "caption_bbox": [391, 196, 692, 316]}, {"image_id": 2, "file_name": "618_02.png", "page": 5, "dpi": 300, "bbox": [76, 75, 693, 460], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A two-dimensional image (a) is whirled (e) to simulate the effects of turbulence. The corresponding decompositions into dissipation elements are shown in (b) and (f). The persistence plots of the two functions (c) are nearly identical for persistent critical points. (d) shows the negative correlation between dissipation element length scale (in voxel units) and size for the whirled image. Modeling dissipation elements as rhombi gives an idea of their aspect ratios (g). The correlation between function change and length scale is lost in the whirled image (h), corresponding to the stretching and compression of gradients. ", "caption_bbox": [59, 462, 692, 536]}, {"image_id": 3, "file_name": "618_03.png", "page": 5, "dpi": 300, "bbox": [71, 548, 678, 692], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The original image (a) is perturbed with low amplitude noise (b). This noise is simplified (c) to recover the features of the original image. While length-scale statistics (d,e) of the simplified and original images match, the noise hides these characteristics for the perturbed image. ", "caption_bbox": [59, 695, 692, 738]}, {"image_id": 4, "file_name": "618_04.png", "page": 5, "dpi": 300, "bbox": [58, 748, 709, 892], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A slice (a) of the temperature field in a homogeneous charge compression ignition simulation is decomposed into dissipation elements (b). A 1% persistence filter (c) affects dissipation element count, mean size, mean difference in function value between minimum and maximum, and mean length scales (d). Each dissipation element is plotted as a point (e), red being dissipation elements in the original, green in the simplified images. The mean of function difference conditioned on length are shown with a blue line for the original and purple for simplified dissipation elements. ", "caption_bbox": [58, 896, 691, 970]}, {"image_id": 5, "file_name": "618_05.png", "page": 6, "dpi": 300, "bbox": [404, 338, 685, 479], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The count and volume contained in regions iden- tified as turbulence zone is plotted for varying persistence simplification threshold values (red). The volume of numer- ically computed dissipation elements is shown with the blue line. ", "caption_bbox": [391, 491, 692, 565]}, {"image_id": 6, "file_name": "618_06.png", "page": 6, "dpi": 300, "bbox": [375, 75, 634, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Volume rendering of mixture fraction in a tem- poral jet. The transparent regions on the top and bottom of the flame correspond to regions with mixture fraction below 0.01. ", "caption_bbox": [391, 250, 692, 309]}, {"image_id": 7, "file_name": "618_07.png", "page": 7, "dpi": 300, "bbox": [399, 457, 691, 745], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Dissipation elements are computed for multiple persistences, and each dissipation element is plotted as a point in (a) with coordinates given by the length of the dissi- pation element and the difference in function value between its extrema. The mean of the difference is conditioned on length (b), and shows a lower scaling value for the simpli- fied dissipation elements. Cumulative density plots (CDF) of function difference (c), length (d), and volume (e) show fur- ther differences due to level of simplification. ", "caption_bbox": [391, 758, 692, 893]}, {"image_id": 8, "file_name": "618_08.png", "page": 7, "dpi": 300, "bbox": [98, 75, 694, 352], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The unsimplified local minima and maxima inside the turbulence region are show in (a). These generate dissipation elements (b). A cross section of this segmentation is shown in (c), where blue are dissipation elements whose minima are in the top layer of oxidizer, green are dissipation elements from the bottom layer, and red are dissipation elements from the turbulence layer. The same sequence is shown (d-f) for the function simplified to 1.0% of its maximum persistence, representing a small-scale perturbation of the function. ", "caption_bbox": [58, 360, 691, 434]}, {"image_id": 9, "file_name": "618_09.png", "page": 8, "dpi": 300, "bbox": [66, 382, 691, 521], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Key attributes of dissipation elements of the temperature field are computed and plotted for varying simplification thresholds. The darkest line of each color represents dissipation elements computed for 1% persistence simplification, and the lighter lines show 0.5%, 0.75%, 1.25% and 1.5%. Each plot divides the dissipation elements into two categories, one where each maximum is above 1500 degrees, and the other where the maxima are below this threshold. This corresponds to the regions illustrated in Fig. 10. The count of dissipation elements with volume greater than 1000 voxels is shown in (a). The total volume (b), mean length (c), mean function difference (d), and mean volume (e) of dissipation elements in these two categories are also illustrated. ", "caption_bbox": [59, 529, 692, 633]}, {"image_id": 10, "file_name": "618_10.png", "page": 8, "dpi": 300, "bbox": [58, 75, 648, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The SACI experiment is visualized for key time steps. The dissipation elements with maxima above 1500 degrees are also shown. The experiment begins with a spark, from which a ball of flame grows and is distorted by background turbulence. As the temperature and pressure increase over time, autoignition takes over. ", "caption_bbox": [58, 317, 691, 360]}, {"image_id": 11, "file_name": "618_11.png", "page": 9, "dpi": 300, "bbox": [58, 75, 378, 178], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: A scalar function f with a low-gradient region (left) can be perturbed to produce an arbitrary number and configuration of dissipation elements (middle and right). The leftmost function is a topologically simplified representation of the others. A threshold used in zonal analysis is shown with the green line. The dissipation elements in the turbu- lence zone (purple bracket) disappear under perturbation. ", "caption_bbox": [59, 188, 360, 292]}], "619": [{"image_id": 0, "file_name": "619_00.png", "page": 2, "dpi": 300, "bbox": [375, 75, 689, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Contours of a scalar field may appear, join, split, and disappear with changing isovalues. The contour tree represents that behavior. It can be created by merging the join and split tree. ", "caption_bbox": [390, 200, 693, 259]}, {"image_id": 1, "file_name": "619_01.png", "page": 3, "dpi": 300, "bbox": [375, 75, 693, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The upper row shows a simple scalar field with two maxima as well as its corresponding join tree and branch decomposition tree. The lower row shows a version with added noise. Note how difficult it is to relate the two join trees, whereas the branch decomposition trees show a remarkable similarity. ", "caption_bbox": [390, 329, 693, 418]}, {"image_id": 2, "file_name": "619_02.png", "page": 3, "dpi": 300, "bbox": [57, 75, 378, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A join tree can be segmented into a collection of branches according to the weight of the edges. This is a hierarchical segmentation. It is represented as the branch decomposition tree, where each node corresponds to a branch of the join tree. ", "caption_bbox": [58, 263, 359, 337]}, {"image_id": 3, "file_name": "619_03.png", "page": 4, "dpi": 300, "bbox": [57, 75, 378, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A forest of all subtrees (top-row) of the join tree shown in Figure 2, along with their branches (middle-row) and the branch decomposition trees (bottom row). ", "caption_bbox": [58, 277, 360, 320]}, {"image_id": 4, "file_name": "619_04.png", "page": 5, "dpi": 300, "bbox": [65, 275, 361, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: eBDG table for the contour tree in Figure 2.", "caption_bbox": [74, 440, 342, 453]}, {"image_id": 5, "file_name": "619_05.png", "page": 6, "dpi": 300, "bbox": [375, 75, 559, 129], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Illustration of the dynamic program- ming concept behind matching child nodes. ", "caption_bbox": [563, 128, 693, 187]}, {"image_id": 6, "file_name": "619_06.png", "page": 7, "dpi": 300, "bbox": [57, 75, 439, 221], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Vertical instability of a branch decomposition. The extrema B and C fight for the dominance, since the corresponding edge weights are very similar, i.e., small perturbations may favor one over the other. ", "caption_bbox": [58, 231, 426, 274]}, {"image_id": 7, "file_name": "619_07.png", "page": 7, "dpi": 300, "bbox": [425, 75, 694, 221], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Horizontal instability of a branch decom- position. Swapping the close saddles E and G leads to a different horizontal ordering in the BDT. ", "caption_bbox": [438, 231, 693, 274]}, {"image_id": 8, "file_name": "619_08.png", "page": 7, "dpi": 300, "bbox": [59, 313, 361, 420], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Perturbation analysis of the data set from Figure 7 (left) and the Neghip data set (right, cf. Figure 12). Shown is the comparison score of the unperturbed data against increasingly noisier versions. The score is normalized by the total weight of the unperturbed BDT. At every noise level, 50 differently perturbed samples are shown. They show different patterns depending on the choice of edge weights for the merge tree. ", "caption_bbox": [57, 434, 359, 554]}, {"image_id": 9, "file_name": "619_09.png", "page": 8, "dpi": 300, "bbox": [58, 75, 687, 248], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Self-Similarity pertaining to different regions in the electrostatic field of the Benzene molecule.", "caption_bbox": [109, 260, 639, 273]}, {"image_id": 10, "file_name": "619_10.png", "page": 8, "dpi": 300, "bbox": [59, 297, 692, 432], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Interactive expansion of search regions in the Neghip data set. A small ROI is expanded to the next higher level in the join tree and the corresponding matches are instantly updated. Notice that complicated self-similar structures are found. ", "caption_bbox": [58, 444, 691, 472]}, {"image_id": 11, "file_name": "619_11.png", "page": 8, "dpi": 300, "bbox": [70, 514, 339, 629], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Automatic super-seed selection from one super- seed for the method in [TN13]. EMDB-1706 data set. ", "caption_bbox": [58, 641, 361, 669]}, {"image_id": 12, "file_name": "619_12.png", "page": 9, "dpi": 300, "bbox": [64, 282, 358, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Self-similarity in a slice of EMDB-1603.", "caption_bbox": [78, 407, 339, 420]}, {"image_id": 13, "file_name": "619_13.png", "page": 9, "dpi": 300, "bbox": [66, 75, 378, 221], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: The EMDB-1603 data set has \u224839k edges in the join tree. We simplified it to \u2248900 edges. ", "caption_bbox": [58, 233, 359, 262]}, {"image_id": 14, "file_name": "619_14.png", "page": 9, "dpi": 300, "bbox": [375, 75, 694, 282], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Periodicity analysis in the 2D time-dependent flow behind a cylinder. The scores are obtained by comparing the full join trees of every time step against each other: for 1000 time slices, a 1000 \u00d7 1000 symmetric matrix is obtained. ", "caption_bbox": [390, 296, 691, 355]}], "620": [{"image_id": 0, "file_name": "620_00.png", "page": 1, "dpi": 300, "bbox": [58, 578, 693, 852], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Mandatory critical points of the velocity magnitude of the uncertain K\u00e1rm\u00e1n vortex street. a) Each vertex v is assigned with a histogram hv estimating its probability density function. The shades of red show the point-wise probability for the isovalue 0.85. b) The support of hv is visualized by the lower (light blue) and upper (dark blue) bound fields. c) depicts the mandatory critical points (blue: minimum, green: join saddle, yellow: split saddle, red: maximum), d) illustrates the spatial uncertainty within the components. e) shows the mandatory join/split tree, and f) and g) the simplified visualization. ", "caption_bbox": [58, 496, 691, 570]}, {"image_id": 1, "file_name": "620_01.png", "page": 3, "dpi": 300, "bbox": [375, 75, 694, 198], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Sub-level sets (blue) of a realization g with iso- values i0 < i1 < i2 . Connected components are born at i0 a) and i1 b) (minima m1 and m2 (green)), and merge at i2 c) (join saddle s (green)). The other vertices of Lg (blue) are mapped to valence-2 vertices in the join tree (blue, insets). ", "caption_bbox": [391, 208, 692, 282]}, {"image_id": 2, "file_name": "620_02.png", "page": 4, "dpi": 300, "bbox": [58, 75, 378, 348], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Sub-level sets of f (blue) and f + (green) at three different isovalues i < f + (m1 ) < f + (m2 ) with m1 and m2 being minima of f + . The sub-level sets of two realizations ga and gb are illustrated as gray regions. ", "caption_bbox": [58, 355, 359, 418]}, {"image_id": 3, "file_name": "620_03.png", "page": 4, "dpi": 300, "bbox": [375, 75, 698, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Minima mk of T ( f + ) are traversed by increasing value of f + (m1 , m2 , m3 ). For each mk , the critical compo- nent Ck corresponds to the sub-tree of T ( f ) containing mk and rooted at the isovalue f + (mk ). The component is valid if it contains no previously processed minimum of T ( f + ). ", "caption_bbox": [391, 240, 692, 317]}, {"image_id": 4, "file_name": "620_04.png", "page": 5, "dpi": 300, "bbox": [58, 75, 378, 343], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "                                             + Figure 5: Sub-level sets of f (blue) and f (green), and of two realizations ga and gb (gray regions, a)-f)) for the isoval- ues \u03be < f (s ) < f + (s+ ). The set of vertices R is enclosed by the dashed lines c)-f). Two components of a realization can merge from the isovalue f (s ) c),d) but must merge by the isovalue f + (s+ ) e),f). ", "caption_bbox": [58, 350, 359, 443]}, {"image_id": 5, "file_name": "620_05.png", "page": 5, "dpi": 300, "bbox": [375, 75, 694, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Left: Bipartite graph G between the saddles S of T ( f ) (left) and S+ of T ( f + ) (right). Each connected com- ponent of G yields a unique mandatory n-join saddle (top to bottom: n = 2, 1, 1). Right: For each Sk , the list Mk of its mandatory minima and its critical interval Ik is maintained. ", "caption_bbox": [391, 252, 692, 326]}, {"image_id": 6, "file_name": "620_06.png", "page": 6, "dpi": 300, "bbox": [375, 75, 694, 137], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Mandatory join tree construction (left to right). Saddles are progressively added to the tree (top to bottom, left). A union-find data-structure tracks the added edges, en- abling to identify the non-visited nodes to which a saddle node must be linked, given its minima list. At each step, vis- ited nodes are depicted in light blue. ", "caption_bbox": [391, 148, 692, 237]}, {"image_id": 7, "file_name": "620_07.png", "page": 6, "dpi": 300, "bbox": [58, 75, 378, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Mandatory join saddle extraction. Left: Given a pair of mandatory minima (M1 , M2 ), the common ancestor of their mandatory vertices m1,2 are extracted in T ( f ) and T ( f + ). Right: B is given by the sub-tree of T ( f ) rooted at the vertex obtained by walking up from s to f + (s+ ). ", "caption_bbox": [58, 260, 359, 334]}, {"image_id": 8, "file_name": "620_08.png", "page": 8, "dpi": 300, "bbox": [58, 75, 686, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Illustration of mandatory critical points and mandatory join/split trees: a) A synthetic scalar field with global error bounds (20% (top), 0.5% (bottom)). The critical points of the synthetic field (ground truth) are shown with colored spheres. Red circles indicate extrema of the synthetic field which are not extracted as mandatory features. b) User-selected critical points in a Martian elevation map using the mandatory join tree. Zoom-ins illustrate their geometrical structure and spatial uncertainty. c) Magnitude of velocity fields caused by a heated cylinder. The most dominant mandatory maximum is depicted with a black line (1-3). The shades of red illustrate the spatial uncertainty within this region (4). The PDF of a v \u2208 S is estimated by a histogram. ", "caption_bbox": [59, 275, 692, 364]}, {"image_id": 9, "file_name": "620_09.png", "page": 9, "dpi": 300, "bbox": [58, 75, 694, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Mandatory critical points on the Sea Surface Height data set. Our simplification scheme allows the user to dis- tinguish more dominant features in the data (top left), marked with bold boundaries. This drives the selection of regions of interest (a, b, c) that can be further inspected with zoom-ins. Each of these reveal the local structure of a major sea stream. The visualization of the mandatory saddles (d, e) helps understanding the relation between the extrema (arrows) found in the data. ", "caption_bbox": [59, 369, 692, 428]}], "621": [{"image_id": 0, "file_name": "621_00.png", "page": 1, "dpi": 300, "bbox": [58, 572, 693, 835], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Analyzing unsteady flows remains challenging as many techniques designed for steady flows do not yield meaningful features for such cases. This paper introduces the notion of an internal reference frame which allows utilizing standard instanta- neous techniques, e.g., topological, for analyzing unsteady flows. The analysis in the internal frame can capture spatio-temporal dynamics of pathlines (in the center) by analyzing the flow one time-step at a time. Left and right show topological analysis that successfully captures the start and end of these pathlines, useful for, e.g., identifying vortices. In contrast, the contours of Q-criteria, shown in black (Q = 0) and red (Q = 0.1), creates false-positives and false-negatives. ", "caption_bbox": [58, 475, 691, 564]}, {"image_id": 1, "file_name": "621_01.png", "page": 6, "dpi": 300, "bbox": [375, 75, 667, 186], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of the expected von K\u00e1rm\u00e1n vortex street [DL02]. Notice the backward flow between counter- rotating vortices that induces drag on the cylinder. ", "caption_bbox": [391, 188, 692, 231]}, {"image_id": 2, "file_name": "621_02.png", "page": 6, "dpi": 300, "bbox": [400, 239, 680, 431], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": " uring steady swimming, and more than one-third      and the encounter phase of the foil with respect to the    Figure 3: Topological decomposition of the flow behind a e total lateral force during turning, underlines its upstream vortices. For two adjacent foils shedding a e role in propulsion. The partitioning of swim-      thrust wake, as in a swimming fish, annihilation or    cylinder is trivial in the original frame (top), while the same  force among multiple fins is likely a widespread    reinforcement of vorticity will also depend on encoun- ", "caption_bbox": [385, 434, 714, 465]}, {"image_id": 3, "file_name": "621_03.png", "page": 7, "dpi": 300, "bbox": [392, 747, 689, 868], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The traces of vortices show the presence of stable rotational structures in the ilfted ethylene flame. ", "caption_bbox": [391, 875, 692, 903]}, {"image_id": 4, "file_name": "621_04.png", "page": 7, "dpi": 300, "bbox": [67, 75, 694, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Vortex traces in the flow behind the cylinder. From top-left to bottom-right, with increasing Re, the speed of vortices increases as expected. To reduce clutter, only those vortex traces are shown that exist for the entire time range. ", "caption_bbox": [59, 325, 692, 353]}, {"image_id": 5, "file_name": "621_05.png", "page": 7, "dpi": 300, "bbox": [397, 369, 684, 614], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Comparison of the topological decomposition of the lifted ethylene jet flame in the simulation\u2019s (left) and the internal (right) reference frames. The natural harmonic flow (middle) describes the motion of the internal frame. Only 8 critical points are identified in the original frame, while 62 critical points describe the complex dynamics of this simu- lated flow in the internal frame. The internal frame for this [800 \u00d7 2025] data took \u2248 186 sec. to compute. ", "caption_bbox": [391, 619, 692, 739]}, {"image_id": 6, "file_name": "621_06.png", "page": 8, "dpi": 300, "bbox": [58, 75, 378, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Illustration [FR94] of the four types of vortical structures associated with this flow: jet shear-layer vortices at the perimeter of the bending jet, the developing counter- rotating vortex pair, horseshoe vortices on the wall, and wake vortices extending from the wall to the jet. The orthog- onal axes assumed for analysis are shown, and the dimen- sions of the dataset are [1408 \u00d7 1080 \u00d7 1100]. ", "caption_bbox": [59, 264, 360, 369]}, {"image_id": 7, "file_name": "621_07.png", "page": 9, "dpi": 300, "bbox": [97, 635, 656, 789], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Localized analysis on a 3D subset of the flow. (a) The natural harmonic flow. (b) and (c) Flow in the internal frame highlighting features near the jet orifice (b) and the formation of counter-rotating vortex pairs (c). ", "caption_bbox": [59, 802, 692, 830]}, {"image_id": 8, "file_name": "621_08.png", "page": 9, "dpi": 300, "bbox": [84, 332, 669, 582], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Topological decomposition of the flow in the internal frame for the yx slices shows the interior of the jet near its orifice, and the evolution of jet with height. Observed wake vortices are marked with arrows. ", "caption_bbox": [59, 592, 692, 620]}, {"image_id": 9, "file_name": "621_09.png", "page": 9, "dpi": 300, "bbox": [65, 75, 694, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Topological decomposition of the jet in a cross-flow (b bottom, a) shows little structure as the interesting intrinsic phenomena are overshadowed by the background flow. The same topological analysis to the flow in the internal frame (b top, c) reveals the expected shear-layer vortices on the front of the flame as well as a wealth of other features. ", "caption_bbox": [58, 281, 691, 324]}], "622": [{"image_id": 0, "file_name": "622_00.png", "page": 1, "dpi": 300, "bbox": [59, 304, 691, 435], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Stream surfaces in a S QUARE CYLINDER flow, inside a STATIC MIXER and in a R AYLEIGH -B \u00c9NARD convection (left to right). Our method fades out unimportant surfaces to clear the view on interesting structures, e.g., vortex cores. The visualizations are view-dependent, frame-coherent, at interactive rates (13\u201350 fps), and with 3\u201315 opacity updates per second. ", "caption_bbox": [58, 445, 691, 488]}, {"image_id": 1, "file_name": "622_01.png", "page": 3, "dpi": 300, "bbox": [394, 382, 690, 491], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Overview: Starting with an initial set (a), we parti- tion all surfaces into n patches (b), compute optimal opacity, which is interpolated on the surface (c). Here, n = 100. ", "caption_bbox": [391, 496, 692, 540]}, {"image_id": 2, "file_name": "622_02.png", "page": 3, "dpi": 300, "bbox": [58, 828, 362, 905], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Even for rather simple surfaces, silhouettes may be distracting if the object of interest is hidden. Opacity op- timization: off (left) / on (right). ", "caption_bbox": [59, 908, 360, 951]}, {"image_id": 3, "file_name": "622_03.png", "page": 4, "dpi": 300, "bbox": [391, 818, 693, 924], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Mean curvature is estimated per vertex, then av- eraged per patch and interpolated for n patches. ", "caption_bbox": [391, 923, 692, 951]}, {"image_id": 4, "file_name": "622_04.png", "page": 5, "dpi": 300, "bbox": [96, 75, 378, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Occlusion degrees hi j are obtained by rasteriza- tion: The contribution of centers (\u2022) to the rasterized frag- ment\u2019s ( ) opacity is reconstructed. For each vertex (\u2022) of the rasterized triangle the k = 3 closest centers are consid- ered. (For illustration, their distances are shortened.) The center-to-fragment contribution is the product of interpola- tion weight (\u2014) and barycentric weight (\u2014). ", "caption_bbox": [58, 194, 359, 298]}, {"image_id": 5, "file_name": "622_05.png", "page": 6, "dpi": 300, "bbox": [58, 75, 690, 378], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Study of the parameters inherited from opacity optimization [GRT13]", "caption_bbox": [175, 382, 575, 395]}, {"image_id": 6, "file_name": "622_06.png", "page": 6, "dpi": 300, "bbox": [58, 631, 359, 903], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Solve rates for varying number of patches n. Using a higher number of patches preserves details, though n = 400 already proved useful. ", "caption_bbox": [58, 908, 359, 952]}, {"image_id": 7, "file_name": "622_07.png", "page": 7, "dpi": 300, "bbox": [94, 779, 319, 875], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Black silhouette gradients (J\u2013) and white halo gradients (\u2013I) are injected at the occluder fragment ( ) and next ( ) to the occluded fragment ( ), see [CFM\u2217 13] for details. We modulate their intensity (which is then diffused) by the opacity of the occluder fragment ( ). ", "caption_bbox": [58, 877, 359, 951]}, {"image_id": 8, "file_name": "622_08.png", "page": 7, "dpi": 300, "bbox": [58, 75, 378, 176], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Silhouette edges depend on the surface opacity, and can be longer conserved by an \u03b7-exponent. Left to right: \u03b7 = 1 (neutral), \u03b7 = 10 (recommended), \u03b7 = 50. ", "caption_bbox": [59, 179, 360, 223]}, {"image_id": 9, "file_name": "622_09.png", "page": 8, "dpi": 300, "bbox": [59, 75, 710, 908], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Comparison with standard techniques, from left to right: constant transparency, angle-based [HGH\u2217 10], normal variation [HGH\u2217 10], smart transparency [CFM\u2217 13], and our novel surface opacity optimization. ", "caption_bbox": [58, 910, 691, 942]}, {"image_id": 10, "file_name": "622_10.png", "page": 9, "dpi": 300, "bbox": [80, 794, 337, 890], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The performance of the silhouette rendering has great impact on the frames and solves per second. Left: en- hanced silhouettes [CFM\u2217 13] (12.8 fps, 3.8 sol/s), right: sil- houettes by depth discontinuity (25.8 fps, 7.5 sol/s). ", "caption_bbox": [59, 892, 360, 951]}], "623": [{"image_id": 0, "file_name": "623_00.png", "page": 3, "dpi": 300, "bbox": [57, 97, 361, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Algorithm Overview. We extend the single stream surface optimization method [MSRT13a] (left) to the selec- tion of multiple surfaces (right) by employing the selection algorithm on an updated weighted domain graph (\u2022 cutaway regions). Edge cost updates are based on restriction of ribbon integration times by inter-surface distance enforcement. Our selected set of stream surfaces for this B \u00c9NARD compartment \ufb02ow example is shown in Figure 7. ", "caption_bbox": [57, 246, 360, 366]}, {"image_id": 1, "file_name": "623_01.png", "page": 4, "dpi": 300, "bbox": [56, 74, 378, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Inter-Surface Distance Field. For the globally optimal stream surface initially selected by [MSRT13a] in the T ORNADO \ufb02ow (left) we compute a distance \ufb01eld using Euclidean Distance Transform (\u2022 volume rendering, dmin = 8l/100) (center). It is used to restrict the search space for further selected stream surfaces (right). The distance \ufb01eld is updated for each selected surface. ", "caption_bbox": [59, 207, 363, 312]}, {"image_id": 2, "file_name": "623_02.png", "page": 4, "dpi": 300, "bbox": [375, 74, 695, 221], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Quality Measure Segmentation. Stream surfaces s are partitioned into equidistant segments [\u03c4i , \u03c4i+1 ] along inte- gration time for ef\ufb01cient measure evaluation (top). Our piece- wise linear approximation of surface-integrated quality mea- sures on this segmentation (thin \u2022) is close to the exact inte- gration (\u2022), as shown in the graphs (bottom) for the measures E\u0304a (\u03c4) \u2261 E\u0304a (\u03c40 , \u03c4), K\u0304n (\u03c4) \u2261 K\u0304n (\u03c40 , \u03c4), and A\u0304(\u03c4) \u2261 A\u0304(\u03c40 , \u03c4) on the benchmark surface s. ", "caption_bbox": [391, 228, 694, 348]}, {"image_id": 3, "file_name": "623_03.png", "page": 5, "dpi": 300, "bbox": [87, 75, 377, 209], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Estimation of Integration Times. For each graph edge a set of streamlines (\u2022) is integrated that evaluate the dis- tance \ufb01eld (\u2022 isocontour d(x) = dmin = l/10) for the restricted integration time range [\u03c40 , \u03c41 ] of the stream ribbon (\u2022). \u03c41 is the maximal integration time for which all streamlines at least dmin -distant to any other surface (\u2022). ", "caption_bbox": [57, 220, 360, 309]}, {"image_id": 4, "file_name": "623_04.png", "page": 5, "dpi": 300, "bbox": [376, 75, 692, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Iterative Edge Costs Update. Left: the domain graph with per-edge graph costs (low \u2022, high \u2022) at different iterations k combined with the currently selected surfaces. Right: the \ufb01nal set of stream surfaces S12 . In each iteration, edge costs are updated by the evaluation of quality measures on integration time-restricted stream ribbons. ", "caption_bbox": [389, 242, 693, 331]}, {"image_id": 5, "file_name": "623_05.png", "page": 6, "dpi": 300, "bbox": [56, 74, 378, 191], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Surface Density Variation. Increasing the minimal inter-surface distance dmin yields stream surface sets of lower density. Note that the \ufb01rst selected stream surface (\u2022) is al- ways equal, whereas the seed curves and integration times of subsequent surfaces vary for different dmin values. ", "caption_bbox": [59, 198, 362, 272]}, {"image_id": 6, "file_name": "623_06.png", "page": 7, "dpi": 300, "bbox": [56, 97, 710, 525], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Selection Results for Analytical and Simulated Vector Fields. Left: analytical \ufb01elds are suitable to illustrate properties of our method: selected sets of stream surface respect the minimal distance bound and represent the major \ufb02ow features. Surface color encodes selection order (bottom left), seed curves are colored (\u2022). All examples maximize the squared mean normal curvature Kn and we also show its minimization for the S PIRAL \ufb02ow. Right: for simulated \ufb01elds of varying characteristics we show the selected stream surface sets Sk . Two time steps of a magnetic \ufb02ux decay simulation are shown for the T REFOIL \ufb02ow. Simulated Vector Fields. More complex simulated \ufb02ows                Fig. 15]) [WSE05, GRT13]. Again, a single globally selected usually contain multiple \ufb02ow features or can be segmented           stream surface can only partially represent the data set (see into multiple disjoint compartment regions. Therefore, these        Figure 1). Using only four stream surfaces our method de \ufb02ows are likely to require multiple stream surfaces for the         tects a symmetric result in which two outmost vortical \ufb02ow uniform representation of the whole \ufb02ow domain. We present          compartments are connected symmetrically by two center automatically selected stream surface sets in this type of          \ufb02ow regions. \ufb02ows in Figure 7 (right). Based on the well-known \ufb02ow                  The simulation of the outlet area of a hydroelectric turbine behind a cubic C YLINDER (cf. Edmunds et al. [ELM\u2217 12:              that comprises a \ufb02ow bifurcation is analyzed in the T URBINE Fig. 14], also shown in Figure 6 for an earlier time step,          data set [SGRT12, MSRT13a, MSRT13b]. The initial stream see also [CSBI05, BFTW09, ELM\u2217 12, EML\u2217 12, SGRT12,                 surface captures both dominant features: the bifurcation and MSRT13a]) the C YLINDER S UB L AMINAR data set is ob-               the only vortical \ufb02ow structure near the split region \u2014 in this tained by removing the laminar \ufb02ow component. This \ufb02ow is           case further surfaces provide a visualization of the remaining used to study the extraction and tracking of multiple vortex        laminar \ufb02ow context. core lines [SWH05, TSW\u2217 05]. Our method selects a set of                                                                        The ef\ufb01ciency of a radial \ufb02uid mixing device with two stream surfaces that contains both surfaces that are close to                                                                     inlets and one outlet at the bottom is studied in the M IXER these core lines and surfaces that represent the vortical \ufb02ow                                                                     \ufb02ow. Only after the selection of three surfaces all openings context. A single stream surface is not suf\ufb01cient to visualize                                                                     and the main vortical structure in the center are captured by all features of the data set and our method captures more                                                                     the set of stream surfaces. features with uniformly distributed stream surfaces. ", "caption_bbox": [64, 527, 697, 896]}], "624": [{"image_id": 0, "file_name": "624_00.png", "page": 4, "dpi": 300, "bbox": [103, 142, 720, 284], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Examples of five visualization method evaluated in our user study. (a) Hedgehogs Plot (b) Image-Guided Streamlin (c) Illustrative Streamline (d) Line Integral Convolution (e) is a frame of the animating result generated by Unsteady Flow LIC. ", "caption_bbox": [96, 285, 729, 313]}, {"image_id": 1, "file_name": "624_01.png", "page": 5, "dpi": 300, "bbox": [435, 669, 713, 772], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An example of NSS score estimation. (a) a partic- ipant\u2019s eye fixations and scanpath. (b) is a scalar field ob- tained by computing the directional difference of the flow field, where large values are shown in red color. The orange dots represent eye gazes. (c) is a histogram of (b) normalized by z-score, the blue line shows the weighted mean of entire scanpath. ", "caption_bbox": [428, 785, 729, 889]}, {"image_id": 2, "file_name": "624_02.png", "page": 6, "dpi": 300, "bbox": [461, 142, 696, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) An example of directional difference map. Red color represents larger directional differences. (b) The NSS scores of directional difference map, F(4,659)= 12.67, p < 1e-4. ", "caption_bbox": [428, 288, 729, 347]}, {"image_id": 3, "file_name": "624_03.png", "page": 6, "dpi": 300, "bbox": [121, 134, 372, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: NSS scores in Exp 1. (a) F(4,659) = 18.52, p < 1e-4. (b) F(4,659) = 11.55, p < 1e-4. The error bars show the standard errors. ", "caption_bbox": [96, 284, 397, 327]}, {"image_id": 4, "file_name": "624_04.png", "page": 6, "dpi": 300, "bbox": [434, 361, 725, 471], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Exp 2: Advection prediction results. (a) F(2.6,338.2) = 12.2, p < 1e-4. (b) F(2,265) = 2, p = 0.15. (c) F(2.7,346.1) = 29.03, p < 1e-4 ", "caption_bbox": [428, 483, 729, 526]}, {"image_id": 5, "file_name": "624_05.png", "page": 7, "dpi": 300, "bbox": [116, 112, 415, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Definition of prediction error. (a) An example of flow images used in Exp 2. (b) Suppose the green dot is a par- ticipant\u2019s predicted position of flow advected from the center. The blue curve is a pathline starting from the center and its intersection with the circle is the real advected position. The central angle between the predicted and advected positions is defined as the prediction error. ", "caption_bbox": [96, 285, 397, 389]}, {"image_id": 6, "file_name": "624_06.png", "page": 8, "dpi": 300, "bbox": [122, 372, 374, 660], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Results of Exp 3. (a) F(3.4,360.5) = 5.80, p = 0.0004. (b) F(2.6046,273.48) = 10.964, p < 1e-4. (c) F(3.2,339.7) = 66.66, p < 1e-4. (d) F(3.3,347.8) = 12.71, p < 1e-4. ", "caption_bbox": [96, 672, 397, 731]}, {"image_id": 7, "file_name": "624_07.png", "page": 8, "dpi": 300, "bbox": [434, 372, 725, 482], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Results of Exp 4. (a) F(2.5,1090.1) = 60.94, p < 1e-4. (b) Percentage of the first critical point (CP) visit that is correct. F(3,1689) = 1.005, p = 0.3896. (c) Green: first- notice visits, F(2.9,1216.9) = 4.76, p = 0.0029; Red: total visits, F(2.8,1184.6) = 17.59, p < 1e-4. ", "caption_bbox": [428, 494, 729, 568]}, {"image_id": 8, "file_name": "624_08.png", "page": 8, "dpi": 300, "bbox": [99, 143, 728, 284], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Five eye scanpathes and their trajectory difference with the pathline in Exp 2. (a) Eye gaze moved with the pathline. (b) Eye gaze kept scanning on the pathline repeatedly. (c) Participant\u2019s eye gaze moved to a distant location. (d)(e) Participant focused on arrows first and traced the pathline later. Please see also the supplemental materials for enlarged images. ", "caption_bbox": [96, 285, 729, 328]}], "625": [{"image_id": 0, "file_name": "625_00.png", "page": 4, "dpi": 300, "bbox": [95, 112, 731, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a): The radiance transfer function To (x, \u03c9 \u2192 y, \u03bd) yields the radiance reflected at point y in direction \u03bd per radiance passing through the differential cone (dA(x), d\u03c9) located at point x with direction \u03c9. It respects all possible light paths. (b): Visibility separatrix, (c): light separatrices and (d): indirect light separatrices, marked in purple. Area lights are marked orange. Influence is marked in the color of the corresponding point of interest. Case (d) depicts indirect light separatrices caused by a mirroring ground plane. The reflection lobe illustrates the effect of a glossy ground instead of a mirror. ", "caption_bbox": [96, 282, 729, 357]}, {"image_id": 1, "file_name": "625_01.png", "page": 5, "dpi": 300, "bbox": [100, 112, 731, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Computation of the pairwise path deviation \u2206 from two paths x\u0304, y\u0304 deflected by a mirror (a) and a diffuse surface (b)", "caption_bbox": [99, 305, 726, 318]}, {"image_id": 2, "file_name": "625_02.png", "page": 6, "dpi": 300, "bbox": [95, 112, 731, 379], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: FTPD (a),(b),(c) and FTPD gradient (d),(e),(f) for three scenes. (a),(d): A diffuse \u2018stair wall\u2019 (gray) illuminated by an area light (white). (b),(e): An area light (white) that indirectly illuminates two diffuse objects (gray) through a two-piece system of mirrors (green). (c),(f): An area-lit mirroring sphere (green) that illuminates a diffuse cube (gray). ", "caption_bbox": [96, 389, 729, 432]}, {"image_id": 3, "file_name": "625_03.png", "page": 7, "dpi": 300, "bbox": [95, 112, 731, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: FTPD (a) and FTPD gradient (b) fields for two glossy surfaces lit by a small area light, showing band-limited (fuzzy) separatrices caused by Phong-exponents 200 (right) and 2000 (left). FTPD (c) and FTPD gradient (d) fields for point-lit surface patches with different glossiness (green, descending from moderately glossy to a perfect mirror). The borders on either side of the glossy surfaces are diffuse. ", "caption_bbox": [96, 264, 729, 323]}, {"image_id": 4, "file_name": "625_04.png", "page": 7, "dpi": 300, "bbox": [95, 336, 731, 458], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Omni-directionally integrated radiance (a), FTPD (b) and FTPD gradient (c) fields for a refracting glass sphere lit by a small area light. Light paths used for radiance integration and radiance weighting were limited to a length of 6 segments. ", "caption_bbox": [96, 469, 729, 497]}, {"image_id": 5, "file_name": "625_05.png", "page": 8, "dpi": 300, "bbox": [95, 112, 731, 379], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: FTPD (a),(b),(c),(f) and FTPD gradient (d),(e) fields for more scenes, including 3D examples. (a),(b): U-shaped room lit by an area light. (b),(d): Slice through the 3D \u2018Metropolis Light Transport [Vea98] Door Scene\u2019 lit by a point light. The walls reflect the actual radiance. (c): FTPD for a slice of a 3D canal lit by a point light, unblocked (left) and blocked by an obstacle (right). (f): 3D scene [Lla10] where the slice does not contain the point light above the pot plant in front of the column. ", "caption_bbox": [96, 389, 729, 448]}, {"image_id": 6, "file_name": "625_06.png", "page": 9, "dpi": 300, "bbox": [95, 112, 731, 257], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: FTPD (a) and FTPD gradient (b) fields computed without any directional weighting by radiance/light sources. (c): Visualization of a 3D scene [Lla10] with \u2018Importance-weighted\u2019 FTPD, traced along primary rays. ", "caption_bbox": [96, 268, 729, 296]}], "626": [{"image_id": 0, "file_name": "626_00.png", "page": 1, "dpi": 300, "bbox": [97, 353, 730, 573], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A drop of green dye is dripped into water. Before impact, only advection plays a role (left). Directly after impact, the drop\u2019s velocity, i.e. advection, still dominates concentration transport (middle), but diffusion increasingly becomes the main mode of transport (right). Red and blue indicate advection and diffusion dominated flow, respectively. ", "caption_bbox": [96, 580, 729, 627]}, {"image_id": 1, "file_name": "626_01.png", "page": 4, "dpi": 300, "bbox": [167, 752, 328, 884], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Diffusion follows the random movement of molecules, here depicted as the black molecule trajectories. The high concentration left of the blue plane leads to a net flux to the right. However, there is no net flux through the gray plane as the concentration on either side is the same. ", "caption_bbox": [96, 894, 397, 972]}, {"image_id": 2, "file_name": "626_02.png", "page": 5, "dpi": 300, "bbox": [466, 144, 691, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Construction of the direction of unified maximum velocity flux. If cd 6= ca , the directions of unified mean veloc- ity flux ~ja + ~jd and maximum velocity ~va +~vd are different. ", "caption_bbox": [428, 248, 729, 297]}, {"image_id": 3, "file_name": "626_03.png", "page": 5, "dpi": 300, "bbox": [472, 584, 682, 670], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Stream feathers are able to capture different flux components in an intuitive combined view. The barbs of the feathers point in the direction of fluxes strongly deviating from the flux visualized as stream tube. ", "caption_bbox": [428, 683, 729, 746]}, {"image_id": 4, "file_name": "626_04.png", "page": 7, "dpi": 300, "bbox": [96, 454, 730, 671], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Advective, diffusive and unified mean velocity fluxes at impact of a solvent drop in a tank of dye. Advection and diffusion work in opposite direction. ", "caption_bbox": [96, 680, 729, 712]}, {"image_id": 5, "file_name": "626_05.png", "page": 7, "dpi": 300, "bbox": [96, 142, 730, 370], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Advective, unified mean velocity and diffusive fluxes after impact of dye in solvent (see Fig. 1). Diffusion radially transports concentration away from the site of impact and dominates the flow farther away from the impact site. Advection due to bouncing water dominates the flow near the impact site. ", "caption_bbox": [96, 380, 729, 427]}, {"image_id": 6, "file_name": "626_06.png", "page": 8, "dpi": 300, "bbox": [95, 112, 415, 781], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Advective, diffusive and unified fluxes of the flow in a t-sensor. Note how advective and diffusive fluxes transport concentration in nearly perpendicular directions. ", "caption_bbox": [96, 791, 397, 838]}, {"image_id": 7, "file_name": "626_07.png", "page": 9, "dpi": 300, "bbox": [96, 142, 730, 372], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Unified mean velocity flux of the checker board scene over three time steps. The quad of solute dye (Fig. 9(a)) moves downward and hits the surface of the tank (Fig. 9(b)) causing a superposition of the initially separated advective and diffusive fluxes. The impact causes a wave to form (Fig. 9(c)) that travels to the right causing a strong advective flux. ", "caption_bbox": [96, 382, 729, 429]}], "627": [{"image_id": 0, "file_name": "627_00.png", "page": 1, "dpi": 300, "bbox": [95, 600, 730, 844], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Mass separation of inertial particles in the D OUBLE G YRE. Left image: Mass (color-coded) that separates strongest during integration over time \u03c4 = 17. Center image: inertial particles of different mass are released at the cross in the left image. In space-time their trajectories assemble a surface, with the purple line being its frontline\u2014a so-called massline. The green line is the particle trajectory with strongest separation (here, with diameter d p = 99 \u00b5m). Right image: plot of difference to reference particle, here the smallest inertial particle (diameter d p = 20 \u00b5m), which makes the temporal evolution of the separation apparent. ", "caption_bbox": [95, 509, 731, 584]}, {"image_id": 1, "file_name": "627_01.png", "page": 4, "dpi": 300, "bbox": [95, 112, 415, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Finite-Time Mass Separation (FTMS) of the D OU - BLE G YRE for inertial particles with diameter d p = 99 \u00b5m at t = 0 and \u03c4 = 9.95. ", "caption_bbox": [95, 285, 399, 329]}, {"image_id": 2, "file_name": "627_02.png", "page": 4, "dpi": 300, "bbox": [412, 112, 714, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Maximal Finite-Time Mass Separation (maxFTMS) in the D OUBLE G YRE at t = 0 after duration \u03c4 = 9.95. ", "caption_bbox": [427, 293, 729, 322]}, {"image_id": 3, "file_name": "627_03.png", "page": 5, "dpi": 300, "bbox": [129, 329, 359, 446], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Space-time domain of the D OUBLE G YRE in which inertial particle trajectories form a mass-path surface. The purple line is a massline, the green line depicts the trajectory of the most separating inertial particle, here with d p = 99 \u00b5m, \u03c4 = 9.95 and seed point (x, t) = (0.45417, 0.5675, 0). ", "caption_bbox": [95, 454, 398, 528]}, {"image_id": 4, "file_name": "627_04.png", "page": 5, "dpi": 300, "bbox": [97, 112, 731, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Distance plots over time in the D OUBLE G YRE, showing the temporal evolution of the difference to the smallest inertial particle (r = 20 \u00b5m). As in Fig. 4, with selected diameter d p = 99 \u00b5m, \u03c4 = 9.95 and the seed point (x, t) = (0.45417, 0.5675, 0). ", "caption_bbox": [95, 291, 728, 320]}, {"image_id": 5, "file_name": "627_05.png", "page": 6, "dpi": 300, "bbox": [97, 340, 727, 460], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: F ORCED D UFFING data set at integration duration \u03c4 = 10.45. The seed point is at (x, t) = (1.294, \u22120.22133, 0).", "caption_bbox": [106, 311, 717, 325]}, {"image_id": 6, "file_name": "627_06.png", "page": 7, "dpi": 300, "bbox": [96, 112, 415, 540], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: S QUARE C YLINDER data set at integration duration \u03c4 = 64 and seed point at (x, t) = (7.664, 3.77067, 40). ", "caption_bbox": [95, 553, 396, 582]}, {"image_id": 7, "file_name": "627_07.png", "page": 7, "dpi": 300, "bbox": [412, 112, 731, 387], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparison between inertial FTLE (IFTLE) and FTMS for diameter d p = 99 \u00b5m at t = 0 and \u03c4 = 9.95. A corresponding point is selected, showing that ridges in IFTLE and FTMS frequently correlate. However, notice the absence of the white valley lines in IFTLE that even cross ridges. ", "caption_bbox": [427, 393, 728, 467]}, {"image_id": 8, "file_name": "627_08.png", "page": 8, "dpi": 300, "bbox": [95, 112, 729, 630], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Comparison of different masses that cause small and strong separation, released from the same seed point in the F ORCED D UFFING data set at integration duration \u03c4 = 10.45. The seed point is at (x, t) = (1.00496, 0.43565, 0). ", "caption_bbox": [95, 639, 728, 668]}, {"image_id": 9, "file_name": "627_09.png", "page": 9, "dpi": 300, "bbox": [102, 112, 415, 524], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Space-time resolution of the maxFTMS grid X \u00d7 Y \u00d7 T , number of sampled masses M and the computation time of maxFTMS in minutes. ", "caption_bbox": [94, 678, 396, 722]}, {"image_id": 10, "file_name": "627_10.png", "page": 9, "dpi": 300, "bbox": [412, 112, 731, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Multiple masses exhibit a similarly strong separa- tion after integration duration \u03c4 = 30 in the D OUBLE G YRE. ", "caption_bbox": [427, 289, 730, 318]}], "628": [{"image_id": 0, "file_name": "628_00.png", "page": 2, "dpi": 300, "bbox": [427, 392, 731, 606], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A page of the print version of Dana Diminescu\u2019s e-Diasporas project [Dim12b]. The page is organized as a matrix of e-diaspora graphs. ", "caption_bbox": [428, 618, 729, 662]}, {"image_id": 1, "file_name": "628_01.png", "page": 2, "dpi": 300, "bbox": [412, 112, 716, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Close-up of an e-diaspora graph, as seen on the print version of Dana Diminescu\u2019s e-Diasporas project [Dim12b]. ", "caption_bbox": [428, 336, 729, 380]}, {"image_id": 2, "file_name": "628_02.png", "page": 4, "dpi": 300, "bbox": [125, 770, 369, 946], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Teresa Elms\u2019 visualization of the lexical distance between the languages of Europe [Elm08]. ", "caption_bbox": [96, 957, 397, 985]}, {"image_id": 3, "file_name": "628_03.png", "page": 5, "dpi": 300, "bbox": [412, 112, 731, 453], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Reproducing the lexi-graph with GraphCoiffure.", "caption_bbox": [432, 467, 724, 480]}, {"image_id": 4, "file_name": "628_04.png", "page": 6, "dpi": 300, "bbox": [95, 112, 415, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Node group deformations of nodes representing Germanic languages. ", "caption_bbox": [96, 291, 397, 319]}, {"image_id": 5, "file_name": "628_05.png", "page": 7, "dpi": 300, "bbox": [102, 328, 725, 536], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Using page layout schemas.", "caption_bbox": [317, 549, 506, 562]}, {"image_id": 6, "file_name": "628_06.png", "page": 7, "dpi": 300, "bbox": [95, 136, 734, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Manipulating lexi-graph\u2019s layout", "caption_bbox": [305, 300, 519, 313]}], "629": [{"image_id": 0, "file_name": "629_00.png", "page": 3, "dpi": 300, "bbox": [414, 112, 731, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An example of a task file", "caption_bbox": [490, 317, 665, 330]}, {"image_id": 1, "file_name": "629_01.png", "page": 3, "dpi": 300, "bbox": [94, 112, 415, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Architecture of GraphUnit", "caption_bbox": [153, 290, 338, 303]}, {"image_id": 2, "file_name": "629_02.png", "page": 3, "dpi": 300, "bbox": [432, 356, 731, 528], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Options of quantitative tasks that can be used for the evaluation ", "caption_bbox": [428, 538, 729, 566]}, {"image_id": 3, "file_name": "629_03.png", "page": 4, "dpi": 300, "bbox": [412, 112, 722, 682], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An interface for configuring a user study", "caption_bbox": [450, 683, 706, 696]}, {"image_id": 4, "file_name": "629_04.png", "page": 5, "dpi": 300, "bbox": [96, 112, 415, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: An example of a study specification file", "caption_bbox": [122, 393, 370, 406]}, {"image_id": 5, "file_name": "629_05.png", "page": 6, "dpi": 300, "bbox": [95, 112, 714, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An example of a user study, showing three stages: instruction about task, training, and study", "caption_bbox": [155, 393, 668, 406]}, {"image_id": 6, "file_name": "629_06.png", "page": 7, "dpi": 300, "bbox": [89, 276, 381, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Accuracy and time result for Study I (node-link vs. matrix). Error bars are standard errors. ", "caption_bbox": [96, 329, 397, 357]}, {"image_id": 7, "file_name": "629_07.png", "page": 8, "dpi": 300, "bbox": [87, 112, 717, 224], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Accuracy and time result for Study II (arrow vs. circular vs. tapered). Error bars are standard errors.", "caption_bbox": [133, 230, 691, 243]}], "630": [{"image_id": 0, "file_name": "630_00.png", "page": 1, "dpi": 300, "bbox": [96, 335, 731, 502], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: We investigate the memorability of relational data represented with node-link (left-side) and map-based (right-side) visualizations; shown are a node-link and a map-based visualization with 200 nodes and 500 links from the LastFM dataset. ", "caption_bbox": [95, 512, 729, 540]}, {"image_id": 1, "file_name": "630_01.png", "page": 2, "dpi": 300, "bbox": [95, 112, 415, 204], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Our study has three phases. In phases 1 and 2 the participants are involved in reading of the visualizations. In phase 3, they are required to recall the visualization contents. ", "caption_bbox": [95, 209, 398, 253]}, {"image_id": 2, "file_name": "630_02.png", "page": 8, "dpi": 300, "bbox": [104, 551, 406, 660], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Per-task breakdown of outcomes. Note that the gap in performance for Task 7 seems larger than other tasks in the study. ", "caption_bbox": [95, 678, 396, 721]}, {"image_id": 3, "file_name": "630_03.png", "page": 8, "dpi": 300, "bbox": [95, 112, 723, 417], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A summary of the data analysis results. The left column shows the results for accuracy, while the right column shows the results for time to completion. All tests are Bonferroni-corrected Welch 2-sample t-tests. The plots show a jittered dotplot of the mean accuracy, and the orange bar indicates the range of the 95% confidence interval of the true means. The confidence intervals of the true mean differences (computed from the t-tests) are shown in the row below. Factors highlighted by an asterisk indicate statistically significant rejections of the null. ", "caption_bbox": [95, 429, 728, 503]}], "631": [{"image_id": 0, "file_name": "631_00.png", "page": 2, "dpi": 300, "bbox": [95, 112, 415, 429], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Interactive visualization with linking+brushing: Linked views of physical domain and parameter space en- able users to inspect data in different reference frames. ", "caption_bbox": [96, 440, 397, 483]}, {"image_id": 1, "file_name": "631_01.png", "page": 3, "dpi": 300, "bbox": [95, 112, 415, 387], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Persistent homology of 1D data: The persistence diagram (top right) summarizes the connectivity changes of a real-valued function (top left). The highlighted point cor- responds to the connected component that lives in the range y \u2208 [c, d]. Bottom: Matching between the function shown at the top and a noisy version of the same function. The four large-scale features are present in both versions (and mapped onto each other), while noise can be ignored easily. ", "caption_bbox": [96, 397, 397, 517]}, {"image_id": 2, "file_name": "631_02.png", "page": 5, "dpi": 300, "bbox": [414, 112, 731, 398], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Global quality of the Swiss Hole dataset: The orig- inal data in 3D (top left) is located on a curled-up plane with a hole. The central quality chart relates the global quality ratings for the five depicted embeddings. ", "caption_bbox": [428, 409, 729, 468]}, {"image_id": 3, "file_name": "631_03.png", "page": 6, "dpi": 300, "bbox": [412, 112, 731, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The limits of analysing quality estimators on data sets: At first glance, both PCA and Isomap seem to approxi- mate the original data set (the Swiss Roll) rather well. Our analysis, however, shows that the PCA contains severe over- plotting. ", "caption_bbox": [428, 245, 729, 319]}, {"image_id": 4, "file_name": "631_04.png", "page": 6, "dpi": 300, "bbox": [95, 112, 415, 585], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Quality and stability analysis of the Swiss Roll data: The upper section contains three selected embeddings. The middle section shows their local quality values. The lower section indicates the stability of the global quality val- ues under perturbations. ", "caption_bbox": [96, 596, 397, 670]}, {"image_id": 5, "file_name": "631_05.png", "page": 7, "dpi": 300, "bbox": [414, 112, 731, 519], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Quality for the compressive strength data: MDS and t-SNE have very small global errors. RP keeps linear structures in the data intact (such that it resembles the MDS embedding), but tends to distort the function values. SPE, on the other hand, is unable to extract meaningful structures from the data. ", "caption_bbox": [428, 529, 729, 618]}, {"image_id": 6, "file_name": "631_06.png", "page": 7, "dpi": 300, "bbox": [95, 112, 415, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Errors of density estimates.", "caption_bbox": [150, 256, 340, 269]}, {"image_id": 7, "file_name": "631_07.png", "page": 8, "dpi": 300, "bbox": [412, 112, 731, 498], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: DR for climate data: SPE and PCA retain density similarly well. RP performs slightly worse, while t-SNE is unable to preserve density. ", "caption_bbox": [428, 508, 729, 551]}, {"image_id": 8, "file_name": "631_08.png", "page": 9, "dpi": 300, "bbox": [95, 112, 731, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Analysis of the \u201cIsomap faces\u201d data set: The model on the left shows the structure of the data. We compare MDS, and t-SNE, which we found to perform best, to Isomap with varying neighbourhood parameter k. ", "caption_bbox": [96, 323, 729, 351]}], "632": [{"image_id": 0, "file_name": "632_00.png", "page": 4, "dpi": 300, "bbox": [95, 112, 415, 352], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Feature extraction via density maps. Entities (white marks) and groups (circles) superimposed on a density map (top) and extracted regions (bottom) with high (red) and low (green) density and overlaps with groups (orange). ", "caption_bbox": [96, 365, 397, 424]}, {"image_id": 1, "file_name": "632_01.png", "page": 5, "dpi": 300, "bbox": [95, 112, 731, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Analytically extracted high-level features are visualized via interactive overview and detail representations.", "caption_bbox": [120, 348, 704, 361]}, {"image_id": 2, "file_name": "632_02.png", "page": 5, "dpi": 300, "bbox": [434, 392, 725, 550], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Overviews sorted row-wise by parameter configu- rations (left) and according to feature behavior (right). ", "caption_bbox": [428, 562, 729, 590]}, {"image_id": 3, "file_name": "632_03.png", "page": 6, "dpi": 300, "bbox": [412, 112, 731, 502], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The overview of parameters and features (center) in conjunction with the chart view (top), the trajectory view (bottom), and a legend (right) facilitate spatio-temporal data exploration. ", "caption_bbox": [428, 514, 729, 573]}, {"image_id": 4, "file_name": "632_04.png", "page": 7, "dpi": 300, "bbox": [118, 734, 377, 946], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The visualization shows that average group size depends on the size of lipid rafts and the fluidity rho. ", "caption_bbox": [96, 957, 397, 985]}, {"image_id": 5, "file_name": "632_05.png", "page": 7, "dpi": 300, "bbox": [450, 734, 709, 946], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualizing average group retention confirms the influence of parameters rho and raft size. ", "caption_bbox": [428, 957, 729, 985]}, {"image_id": 6, "file_name": "632_06.png", "page": 8, "dpi": 300, "bbox": [95, 112, 731, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visualizing the average distance of non-member proteins to the nearest lipid raft feature in conjunction with the detail line chart and a selected 2D density map helps in studying the sweeping effect. ", "caption_bbox": [96, 350, 729, 378]}], "633": [{"image_id": 0, "file_name": "633_00.png", "page": 3, "dpi": 300, "bbox": [125, 112, 731, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Computation and basic plot of the windowed cross-correlation between two time series. The time series are divided into windows of equal length (a) and the cross-correlation between the time series for corresponding intervals is calculated (b). The resulting matrix of correlations can be visualized by mapping correlation to color (c). The matrix plot shows that one time series exhibits a time-varying phase difference, visible by the change of the lagged correlation over time (d). ", "caption_bbox": [96, 396, 729, 455]}, {"image_id": 1, "file_name": "633_01.png", "page": 4, "dpi": 300, "bbox": [95, 112, 697, 366], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Our visual analytics concept. It comprises computation and statistical analysis of windowed cross-correlations (WCC) between two time series ensembles (module M I) and interactive visual exploration of the resulting time-varying corre- lations and their uncertainty (module M II). ", "caption_bbox": [96, 378, 729, 421]}, {"image_id": 2, "file_name": "633_02.png", "page": 5, "dpi": 300, "bbox": [96, 622, 399, 818], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Correlations view (top) and color legend with integrated scatter plot (bottom) of component M II.1. The color of the squares encode the mean or median correla- tions of each combination of time window (x-axis) and lag (y-axis). The size inversely depicts the uncertainty of the un- derlying distribution. Thus, small squares represent high un- certainty. When users select a window-lag combination it is highlighted in the correlations view (yellow square) and in the scatter plot (labeled cross). ", "caption_bbox": [96, 844, 397, 979]}, {"image_id": 3, "file_name": "633_03.png", "page": 6, "dpi": 300, "bbox": [427, 716, 731, 879], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Line chart showing both ensembles (component M II.2). Line density is mapped to opacity to depict the un- certainty in the ensembles. Dense regions in each ensemble are mapped to high opacity, sparse regions are more trans- parent to indicate less agreement among ensemble members. ", "caption_bbox": [428, 905, 729, 979]}, {"image_id": 4, "file_name": "633_04.png", "page": 6, "dpi": 300, "bbox": [412, 112, 731, 218], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: On-demand histogram of correlation values for a combination of time window and lag. The gray areas in the background mark statistically significant correlations. ", "caption_bbox": [428, 245, 729, 288]}, {"image_id": 5, "file_name": "633_05.png", "page": 6, "dpi": 300, "bbox": [95, 112, 415, 307], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Glyph encoding the results of aggregating the dis- tributions of correlations from multiple window-lag combi- nations (top) and a zoomed-out version of the correlations view using the glyph (bottom). \u2018Uncertainty\u2019 denotes either standard deviation or interquartile range of correlation val- ues. Small squares signal high uncertainty and vice versa. ", "caption_bbox": [96, 333, 397, 422]}, {"image_id": 6, "file_name": "633_06.png", "page": 7, "dpi": 300, "bbox": [412, 112, 731, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Electroencephalogram (EEG) ensembles of two subjects (a) and (b). The red lines represent the average of the respective trial. After a visual stimulus at time t = 0 ms, an evoked electrophysiological activity around 170 ms (marked by the blue shading) can be clearly observed for subject (b), but only suspected for subject (a). ", "caption_bbox": [428, 394, 729, 483]}, {"image_id": 7, "file_name": "633_07.png", "page": 8, "dpi": 300, "bbox": [412, 112, 731, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The windowed cross-correlation between two en- sembles of paleoclimate time series. In accordance with domain-specific conventions, the most recent observations are plotted on the left and the oldest on the right. ", "caption_bbox": [428, 390, 729, 449]}, {"image_id": 8, "file_name": "633_08.png", "page": 8, "dpi": 300, "bbox": [95, 112, 415, 346], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Correlations between EEG ensembles of two sub- jects. In both subjects, the presented facial stimulus causes the same electrophysiological activity between 120 and 170 ms (a). This is revealed by the strong correlations within this time interval. The histogram shows that the majority of the trials is significantly correlated (b). ", "caption_bbox": [96, 372, 397, 461]}, {"image_id": 9, "file_name": "633_09.png", "page": 9, "dpi": 300, "bbox": [96, 112, 415, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: (a) Fractions of significant positive correlations between two ensembles of paleoclimate time series. The dashed line indicates the derived correction function for re- ducing the dating uncertainties. (b\u2013d) Looking at the distri- butions of correlation values for different lags at the epoch around 7700 years BP (dashed rectangle) allows for identi- fying the most suitable lag for the correction function. Since (b) exhibits the largest portion of high correlations, its re- spective lag was chosen. ", "caption_bbox": [96, 324, 397, 459]}], "634": [{"image_id": 0, "file_name": "634_00.png", "page": 2, "dpi": 300, "bbox": [95, 112, 731, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) A 2D illustration of the underlying physics of the photoelectric current generation process. (b) A 2D illustration of the bottleneck computation steps (for the donor part). The figure illustrates the computation steps over one sample cross- sectional area (S). We only refer to the donor in the current paper, since the acceptor bottlenecks can be analogously extracted. ", "caption_bbox": [96, 339, 729, 382]}, {"image_id": 1, "file_name": "634_01.png", "page": 3, "dpi": 300, "bbox": [96, 112, 731, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An overview of our framework comprising preprocessing, storage, and interactive visual exploration. The workflow illustrates the dependency among different system modules as well as typical steps performed by users for visual exploration. ", "caption_bbox": [96, 315, 729, 343]}, {"image_id": 2, "file_name": "634_02.png", "page": 4, "dpi": 300, "bbox": [95, 112, 730, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A 2D illustration of the invidivual steps of extracting the structural features that are used for computing the bottleneck indicators and exciton diffusion probabilities. Note that in our framework these steps are performed entirely in 3D. ", "caption_bbox": [96, 311, 729, 339]}, {"image_id": 3, "file_name": "634_03.png", "page": 5, "dpi": 300, "bbox": [177, 112, 731, 269], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A 2D illustration of the cross-sectional area extraction guided by the 3D segmentation and the backbone. The cross- sectional area at a backbone point is the intersection between the plane perpendicular to the tangent at this point and the current segment of the 3D segmentation. (a) illustrates how the plane of the cross-sectional area is determined. (b) illustrates different examples of cross-sectional areas after intersection with 3D segments. Note that we perform these computations entirely in 3D. ", "caption_bbox": [96, 278, 729, 337]}, {"image_id": 4, "file_name": "634_04.png", "page": 6, "dpi": 300, "bbox": [95, 112, 729, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: An illustration of spatial exploration of the backbone: The backbone is color-coded via a user-defined transfer function that highlights values of interest for the user (K(S) = 20 in this example). The user can then move a point probe to regions with a high bottleneck value (here: yellow regions), and explore the surrounding area to ascertain its shape and size. This information can guide experts in enhancing the morphology, e.g, by increasing the sizes of cross-sectional areas. ", "caption_bbox": [96, 339, 729, 398]}, {"image_id": 5, "file_name": "634_05.png", "page": 7, "dpi": 300, "bbox": [98, 112, 731, 427], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: The data sets used in our evaluation. We have used two 3D morphologies, each of which consists of several time steps (one volume each) computed via thermal annealing. ", "caption_bbox": [428, 944, 729, 987]}, {"image_id": 6, "file_name": "634_06.png", "page": 8, "dpi": 300, "bbox": [95, 112, 727, 407], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Charge path exploration for a sample morphology: Time step 21 of Morphology A. Typically, visualizing all charge paths results in too cluttered visualizations. Hence, the user needs to navigate to a region of interest for which the paths are then displayed. In the right column, the backbone of the data set as well as a big subset of the charge paths are shown to provide a feeling for their cluttered nature. In the middle, a user-selected region in a scatter plot filters the back bone down to only a few points. Then, the user selects a region of interest (10 by 10 voxels), whose center is a point interactively probed in the filtered volume, using the GUI shown in the center. Finally, the final selected paths are color-coded according to tortuosity. ", "caption_bbox": [96, 410, 729, 499]}, {"image_id": 7, "file_name": "634_07.png", "page": 9, "dpi": 300, "bbox": [95, 112, 731, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Running times for all steps of our framework.", "caption_bbox": [109, 972, 383, 985]}], "635": [{"image_id": 0, "file_name": "635_00.png", "page": 1, "dpi": 300, "bbox": [95, 357, 731, 477], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: We present Shotviewer, software that supports visual analysis of spatial and nonspatial ballistic simulation data for vulnerability analysis. It consists of three linked views: a) the Shotline View displays an abstract representation of shots\u2019 paths through a vehicle; b) the Geometry View shows shots\u2019 3D spatial context; and c) the System View visualizes the propagation of damage through a vehicle\u2019s systems. In this example, the green shot damages the vehicle\u2019s radio which impacts the vehicle\u2019s mobility and firepower capabilities. ", "caption_bbox": [96, 487, 729, 561]}, {"image_id": 1, "file_name": "635_01.png", "page": 2, "dpi": 300, "bbox": [412, 113, 731, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The timeline of our design study. After conduct- ing initial understand and ideate activities, we decided on a multiple linked view system. We designed each of these views in parallel and ultimately combined them into a full system. ", "caption_bbox": [428, 257, 729, 316]}, {"image_id": 2, "file_name": "635_02.png", "page": 3, "dpi": 300, "bbox": [95, 113, 415, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A cell plot output from ballistic simulations. Cell color encodes the quantitative damage that each shot inflicts on this vehicle\u2019s mobility or firepower capabilities. Analysts understand cell plots by comparing cells to their neighbors of different colors, such as the highlighted cells marked here. ", "caption_bbox": [96, 280, 397, 354]}, {"image_id": 3, "file_name": "635_03.png", "page": 4, "dpi": 300, "bbox": [95, 112, 698, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An overview of ballistic vulnerability analysis data: a) vehicles consist of various 3D meshes called components; b) a subset of these components appear in a dependency graph which describes the vehicle\u2019s capabilities; and c) the simulations trace shots through the vehicle and aggregate per-shot damage using the dependency graph. ", "caption_bbox": [96, 243, 729, 286]}, {"image_id": 4, "file_name": "635_04.png", "page": 5, "dpi": 300, "bbox": [95, 112, 731, 454], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The Shotline View consists of three subviews. The Table View (top) provides human-readable details about the shot. The Compare View (center) uses a 2D projection of shotlines to enable visual comparison through juxtaposition [GAW\u2217 11]. The two Line Plots Views (bottom) show trends in shot degradation. ", "caption_bbox": [96, 465, 729, 508]}, {"image_id": 5, "file_name": "635_05.png", "page": 5, "dpi": 300, "bbox": [95, 519, 399, 660], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: We propose that cell plots serve as an interactive legend for Shotviewer. Here, the user selected four shotlines which have been assigned categorical colors that are used within Shotviewer. ", "caption_bbox": [96, 670, 397, 729]}, {"image_id": 6, "file_name": "635_06.png", "page": 6, "dpi": 300, "bbox": [412, 113, 731, 307], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The Geometry View renders 3D representations of the shotlines along with user-defined landmark geometry to provide spatial context while avoiding clutter and occlusion. Here, the crew and wheels serve as landmark geometry. ", "caption_bbox": [428, 317, 729, 376]}, {"image_id": 7, "file_name": "635_07.png", "page": 7, "dpi": 300, "bbox": [97, 112, 731, 316], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The System View uses a node-link diagram to show the systemic impact of damaged components. The full dependency graph is filtered to only show damaged components (leaves) and their parents (systems and capabilities). The vertical bars on the right of each node encode damage, and color identifies the shots causing the damage. Using this view analysts can filter the damaged capabilities to focus on one of interest. Here, highlighting enables the user to trace the valve_assembly damage up to the vehicle\u2019s mobility. ", "caption_bbox": [96, 328, 729, 402]}], "636": [{"image_id": 0, "file_name": "636_00.png", "page": 4, "dpi": 300, "bbox": [431, 271, 728, 459], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Screenshot of our Visual Interactive Dashboard (VIDa). ", "caption_bbox": [428, 470, 729, 498]}, {"image_id": 1, "file_name": "636_01.png", "page": 4, "dpi": 300, "bbox": [148, 572, 375, 786], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Task workflow: the new visualization pipeline is integrated in our collaborators\u2019 workflow at tasks WT3 and WT4. GDAS provides observational data for the workflow. ", "caption_bbox": [96, 799, 397, 842]}, {"image_id": 2, "file_name": "636_02.png", "page": 5, "dpi": 300, "bbox": [97, 541, 394, 746], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Minimap timeline overview. It shows a crossed view of multiple forecast runs and predictions, depicting the temporal behavior of a given variable. It also shows the \u201cdi- agnostic\u201d which is a reference forecast created with obser- vational data. ", "caption_bbox": [96, 777, 397, 851]}, {"image_id": 3, "file_name": "636_03.png", "page": 6, "dpi": 300, "bbox": [95, 112, 635, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Curve-pattern analysis process: (a) The selected forecasts that predict 2D scalar-fields for a given date and time. (b) The curve drawing allows the user to sketch the desired patterns. (c) The selectable list of possible patterns shows the curve matches. (d) The selected color scheme. (e) The selected curves show the curve-patterns chosen by the user and its associated colors. (f) Pattern matching process for each pixel of the selected minimaps. (g) Visualization of the curve-pattern classification. ", "caption_bbox": [96, 369, 729, 428]}, {"image_id": 4, "file_name": "636_04.png", "page": 7, "dpi": 300, "bbox": [437, 635, 722, 892], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Trend analysis: the largest temperature drops, just after the passage of the cold front, are indicated in cyan tones. Orange tones in the south of the map indicate increas- ing temperature. Results are presented using two different delta values: 6 \u25e6 and 8 \u25e6 Celsius. ", "caption_bbox": [428, 908, 729, 982]}, {"image_id": 5, "file_name": "636_05.png", "page": 8, "dpi": 300, "bbox": [433, 781, 728, 915], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Forecast uncertainty analysis. The standard devia- tion shows the dispersion of the forecasts in different regions of the map. ", "caption_bbox": [428, 928, 729, 971]}, {"image_id": 6, "file_name": "636_06.png", "page": 8, "dpi": 300, "bbox": [439, 185, 725, 445], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Forecast verification using multiple runs. It shows the passage of a cold front. This is observed as errors in the forecasted temperature shown in oranges tones. ", "caption_bbox": [428, 461, 729, 504]}], "637": [{"image_id": 0, "file_name": "637_00.png", "page": 3, "dpi": 300, "bbox": [176, 112, 731, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Cox et al.\u2019s ensemble display vs. the uncertainty cone, NHC advisory 10 AM CDT, August 27, 2005.", "caption_bbox": [149, 321, 675, 334]}, {"image_id": 1, "file_name": "637_01.png", "page": 4, "dpi": 300, "bbox": [95, 112, 651, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Path ensembles sampled at two different times, NHC advisory 10 AM CDT, August 27, 2005.", "caption_bbox": [167, 321, 658, 334]}, {"image_id": 2, "file_name": "637_02.png", "page": 6, "dpi": 300, "bbox": [95, 112, 714, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Simplicial depth visualization. NHC advisory 10 AM CDT, August 27, 2005.", "caption_bbox": [208, 321, 617, 334]}, {"image_id": 3, "file_name": "637_03.png", "page": 6, "dpi": 300, "bbox": [199, 348, 624, 530], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: RBF interpolation with dynamically adjustable kernel radius. NHC Advisory: Hurricane Isaac, 1 pm CDT, Aug. 27, 2012.", "caption_bbox": [99, 533, 725, 546]}, {"image_id": 4, "file_name": "637_04.png", "page": 7, "dpi": 300, "bbox": [106, 112, 731, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Minimum enclosing ellipses of depth intervals. NHC Advisory: Hurricane Isaac, 1 pm CDT, Aug. 27, 2012.", "caption_bbox": [134, 325, 690, 338]}, {"image_id": 5, "file_name": "637_05.png", "page": 8, "dpi": 300, "bbox": [95, 112, 415, 276], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Rotation angles as a function of frame number.", "caption_bbox": [104, 289, 388, 302]}, {"image_id": 6, "file_name": "637_06.png", "page": 9, "dpi": 300, "bbox": [105, 112, 731, 899], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Time-specific visualizations of risk regions for four different hurricane advisories.", "caption_bbox": [183, 926, 642, 939]}], "638": [{"image_id": 0, "file_name": "638_00.png", "page": 1, "dpi": 300, "bbox": [98, 355, 731, 474], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: US election 2012, electorial college votes. Diffusion cartogram by Mark Newman (University of Michigan), square mosaic cartogram from Wikipedia, square and hexagonal mosaic cartograms computed by our algorithm. ", "caption_bbox": [96, 482, 729, 514]}, {"image_id": 1, "file_name": "638_01.png", "page": 3, "dpi": 300, "bbox": [96, 136, 731, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Constructing simple mosaic drawings for square and hexagonal grids via an orderly spanning tree (adapted from [CLL05]). ", "caption_bbox": [96, 380, 729, 412]}, {"image_id": 2, "file_name": "638_02.png", "page": 3, "dpi": 300, "bbox": [153, 880, 342, 960], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A simple mosaic drawing on a hexagonal tiling.", "caption_bbox": [102, 970, 391, 987]}, {"image_id": 3, "file_name": "638_03.png", "page": 4, "dpi": 300, "bbox": [96, 734, 399, 929], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: US: mosaic drawing based on Chiang et al. [CLL05] (left) and on Schnyder labeling (top right), area cartogram with 1 square \u2248 5000 km2 . ", "caption_bbox": [96, 939, 397, 986]}, {"image_id": 4, "file_name": "638_04.png", "page": 4, "dpi": 300, "bbox": [427, 851, 731, 961], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Guiding shapes for Italy with 20, 28 and 40 tiles.", "caption_bbox": [431, 970, 725, 987]}, {"image_id": 5, "file_name": "638_05.png", "page": 5, "dpi": 300, "bbox": [428, 819, 731, 946], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Tile t mapped to two points in the input map M and the corresponding direction of the repulsion forces. ", "caption_bbox": [428, 954, 729, 986]}, {"image_id": 6, "file_name": "638_06.png", "page": 5, "dpi": 300, "bbox": [95, 136, 399, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The move and reshape algorithm executed on an instance containing Portugal, Spain and France. ", "caption_bbox": [96, 310, 397, 342]}, {"image_id": 7, "file_name": "638_07.png", "page": 6, "dpi": 300, "bbox": [412, 112, 709, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A mosaic drawing, guiding shapes as overlay, and the associated MCFP instance. The feasibility node is omit- ted for simplicity. Boundary nodes are represented by circles and supply nodes by squares. Sea nodes are white. The sup- plies are bred = bgreen = 0, bblue = \u22121 and bnsea = 1. ", "caption_bbox": [428, 358, 729, 437]}, {"image_id": 8, "file_name": "638_08.png", "page": 7, "dpi": 300, "bbox": [442, 136, 716, 412], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: US area. 1 hexagon \u2248 Rhode Island \u2248 4001 km2 , 1928 hexagons (top), standard federal regions I\u2013IV removed, 2 resp. 1 hexagons \u2248 Indiana \u2248 94326 km2 , 130 and 67 hexagons (bottom). Cut line indicated in top figure. ", "caption_bbox": [428, 420, 729, 485]}, {"image_id": 9, "file_name": "638_09.png", "page": 7, "dpi": 300, "bbox": [105, 796, 718, 946], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Europe population in 2010: 1 hexagon per 2 million, 413 hexagons (left), 1 hexagon per 500.000, 1629 hexagons (middle), 1 hexagon per 125.000, 6517 hexagons (right). ", "caption_bbox": [96, 954, 729, 986]}, {"image_id": 10, "file_name": "638_10.png", "page": 9, "dpi": 300, "bbox": [95, 571, 399, 946], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: US Starbucks locations in 2009. The mosaic map uses 1 hexagon per location. ", "caption_bbox": [96, 954, 397, 986]}, {"image_id": 11, "file_name": "638_11.png", "page": 9, "dpi": 300, "bbox": [95, 136, 731, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Businesses without paid employees in the US: rectilinear [dBMS10], rectangular [BSV12], contiguous area [GN04], and mosaic cartogram. The mosaic cartogram uses 1 square per 10.000 businesses. See Table 1 for statistics. ", "caption_bbox": [96, 269, 729, 301]}], "639": [{"image_id": 0, "file_name": "639_00.png", "page": 1, "dpi": 300, "bbox": [95, 495, 731, 701], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: 2004 US Presidential elections: (a) geographically accurate map, (b) diffusion cartogram, (c) rectangular cartogram.", "caption_bbox": [124, 474, 700, 487]}, {"image_id": 1, "file_name": "639_01.png", "page": 2, "dpi": 300, "bbox": [95, 112, 415, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Three cartograms for a map with an area assignment for four states (A, B, C, D with desired areas 1, 2, 1, 2, respectively), containing (a) cartographic error, (b) topology error and (c) shape error. There is no cartogram with no cartographic error, topology error and shape error. ", "caption_bbox": [96, 219, 397, 287]}, {"image_id": 2, "file_name": "639_02.png", "page": 4, "dpi": 300, "bbox": [412, 113, 730, 197], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Cartograms with no cartographic error realizing areas (100, 100 and 1 units) (left), with symmetric errors (97,97,7 units) (center), and with asymmetric errors (199,1,1 units) (right). Intu- itively, the center map is more accurate than the right map as it still has one small and two large regions. This intuition is supported by symmetric normalization (0.3 for center, 0.495 for right), while the asymmetric one (2.02 for center, 0.66 for right) reverses the order. ", "caption_bbox": [428, 210, 729, 306]}, {"image_id": 3, "file_name": "639_03.png", "page": 4, "dpi": 300, "bbox": [95, 112, 415, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Normalized cartographic errors with different ob- tained areas o(v) for a country v with desired area w(v) = 1 unit. Red, blue and green curves give the distributions when w(v), o(v) + w(v), and max{o(v), w(v)} are the normalization factors. ", "caption_bbox": [96, 308, 382, 362]}, {"image_id": 4, "file_name": "639_04.png", "page": 5, "dpi": 300, "bbox": [412, 112, 731, 219], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A polygonal region of a map and four of its schematiza- tions in decreasing order by turning angle distortion \u03a8M (top) and by Hamming distance \u03b4 (bottom). Intuitively, the bottom order is more accurate as it seems to capture the original shape better than the top. \u03a8 and the modified variant \u03a8M give the same ranking (top). ", "caption_bbox": [428, 229, 729, 298]}, {"image_id": 5, "file_name": "639_05.png", "page": 7, "dpi": 300, "bbox": [118, 112, 731, 511], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Properties of the input data.", "caption_bbox": [492, 811, 665, 824]}, {"image_id": 6, "file_name": "639_06.png", "page": 8, "dpi": 300, "bbox": [95, 112, 691, 777], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Average normalized cartographic error \u03b5, maximum normalized cartographic error \u03be, angular orientation error \u03b8, Hamming distance \u03b4, average aspect ratio \u03b1 and running time for all algorithms (the iterative algorithm RECT-E was stopped after 50 seconds). ", "caption_bbox": [96, 789, 729, 816]}], "640": [{"image_id": 0, "file_name": "640_00.png", "page": 3, "dpi": 300, "bbox": [101, 113, 747, 450], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: For designing VIMTEX we use different histograms for quantifying visual properties, common to scatter plots and parallel coordinates. As shown, each cell represents a pixel bin. Numbers within each cell in the first row represents the pixel coordinate of the bin and the numbers within each cell in the other rows represent the frequency of the bin. ", "caption_bbox": [79, 453, 745, 496]}, {"image_id": 1, "file_name": "640_01.png", "page": 4, "dpi": 300, "bbox": [79, 137, 745, 445], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The different components of VIMTEX are: A) Data view, which is a multivariate, time-varying view of the data and re- orderable, B) Density view, which shows univariate temporal distribution with the selected axis pair being highlighted, and C) Matrix view which shows the bivariate correlations as time-series. ", "caption_bbox": [79, 452, 745, 496]}, {"image_id": 2, "file_name": "640_02.png", "page": 6, "dpi": 300, "bbox": [438, 146, 728, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3:      Illustrating the data density metrics: Three different con- figurations of the axis pair (kinetic iron and sorbed kinetic iron) on in- teraction with the density view. Each blue box represents the density median plot for sorbed kinetic iron and the red box represents the same for kinetic iron. Low IQR clearly leads to more recognizable patterns due to low clutter. ", "caption_bbox": [428, 318, 745, 400]}, {"image_id": 3, "file_name": "640_03.png", "page": 7, "dpi": 300, "bbox": [412, 113, 748, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5:       Different degrees of clumping exhibited between uranium carbonate and uraninite at subsequent time steps. The clumping met- ric (C f ) returns a higher value when there are more clumped regions with higher density as in the rightmost image. ", "caption_bbox": [428, 275, 745, 329]}, {"image_id": 4, "file_name": "640_04.png", "page": 7, "dpi": 300, "bbox": [101, 113, 415, 379], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Illustration of the parallelism metric, for two different axis pairs. In a) parallelism reflects aggregation, while in b) parallelism reflects positive linear correlation. ", "caption_bbox": [79, 385, 396, 428]}, {"image_id": 5, "file_name": "640_05.png", "page": 8, "dpi": 300, "bbox": [148, 142, 331, 257], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Clumping pattern among Iron sillicate, Iron hydrox- ide and Iron sulphide that was an unexpected phenomena ac- cording to the scientists\u2019 initial hypothesis. ", "caption_bbox": [79, 257, 396, 300]}], "641": [{"image_id": 0, "file_name": "641_00.png", "page": 1, "dpi": 300, "bbox": [97, 362, 731, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Understanding the uncertain vulnerability of a selected building to a multitude of \ufb02ood scenarios. (Left) Vulnerability to \ufb02oodwall overtopping events, displayed on a water gauge. (Middle) Vulnerability to \ufb02oodwall breaches, shown along the protection wall. (Right) Adverse impact on the selected building, including cellar \ufb02ooding. The probability of water reaching a particular level varies around the building and is mapped onto the facades. ", "caption_bbox": [96, 543, 729, 603]}, {"image_id": 1, "file_name": "641_01.png", "page": 3, "dpi": 300, "bbox": [97, 112, 415, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Impact visualization with facade area plots. The color indicates the probability of that particular part of the facade to be exposed to the water. ", "caption_bbox": [96, 337, 397, 381]}, {"image_id": 2, "file_name": "641_02.png", "page": 4, "dpi": 300, "bbox": [95, 112, 415, 423], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Internal and external \ufb02ooding impact. (a) Esti- mated cellar \ufb02ooding through user-sketched windows. Water levels are visualized with a facade area plot. (b) Facade line plot showing the water level probabilities for the external \ufb02ooding. ", "caption_bbox": [96, 434, 397, 509]}, {"image_id": 3, "file_name": "641_03.png", "page": 5, "dpi": 300, "bbox": [96, 112, 415, 405], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Pattern for the uncertainty-aware visualization of vulnerability. For non-experts, only one of the three choices (at least, expected, worst case) is shown at a time. For ex- perts, this uncertainty information is combined. (a) 100% vulnerable in all cases. (b) Vulnerable up to 100% in some cases, at least 50%, average 75%. (c) Safe in some cases, but in some other cases up to 60% vulnerable. Average vul- nerability is 50%. (d) Always safe. ", "caption_bbox": [96, 415, 397, 535]}, {"image_id": 4, "file_name": "641_04.png", "page": 5, "dpi": 300, "bbox": [412, 112, 731, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Interactive 2D chart for the vulnerability to \ufb02ood- wall overtoppings. The gauge shows the water levels and the corresponding uncertain vulnerability values for experts. Each cell in the chart shows the vulnerability for the corre- sponding scenario (water level + duration). ", "caption_bbox": [428, 381, 729, 456]}, {"image_id": 5, "file_name": "641_05.png", "page": 6, "dpi": 300, "bbox": [95, 112, 731, 427], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Vulnerability to sewer over\ufb02ows, presented for experts. (a) Sewer locations potentially dangerous for the selected building. (b) For another building, different locations are dangerous. (c) On mouse-over, a context legend is displayed, showing the 0% and 100% bounds. The building contours preserve the spatial context. (d) Vulnerability with respect to the hospital accessibility. (e) One sewer location is picked, the shades of blue show the expected water depths associated with an over\ufb02ow at that location. A satellite image is used as a texture. (f) A different perspective is chosen, and a different building is selected. ", "caption_bbox": [96, 437, 729, 512]}, {"image_id": 6, "file_name": "641_06.png", "page": 7, "dpi": 300, "bbox": [98, 112, 731, 411], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Vulnerability to \ufb02oodwall breaches. (a) For the selected building, dangerous breach positions are indicated by the plot. (b) Another building has a different vulnerability pro\ufb01le. (c) A close-up view of (b) with the context legend displayed. The vulnerability per width is shown for each position in centered bar plots. (d) Vulnerability with respect to the hospital accessibil- ity. A scenario is picked by clicking on a width bar, showing the aggregated water depths on the terrain. (e) Vulnerability with respect to the damage of the building from (a), non-expert view. ", "caption_bbox": [96, 421, 729, 496]}, {"image_id": 7, "file_name": "641_07.png", "page": 8, "dpi": 300, "bbox": [95, 112, 415, 558], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Building accessibility. (a) Expert view showing the accessibility of hospitals, schools, and pharmacies with respect to sewer over\ufb02ows. (b) Non-expert view showing the worst-case accessibility with respect to heavy rains. ", "caption_bbox": [96, 568, 397, 628]}, {"image_id": 8, "file_name": "641_08.png", "page": 9, "dpi": 300, "bbox": [95, 112, 415, 557], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Routes accessibility with respect to the shown buildings. (a) Expert view showing the hospital accessibil- ity with respect to heavy rain incidents. (b) Non-expert view showing the expected accessibility of pharmacies with re- spect to sewer over\ufb02ow scenarios. ", "caption_bbox": [96, 567, 397, 642]}], "642": [{"image_id": 0, "file_name": "642_00.png", "page": 3, "dpi": 300, "bbox": [95, 112, 731, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Data abstractions. (a) Original data. (b) Monoplex substrate network. (c) Multiplex network. (d) Substrates and catalysts. (e) Catalyst network. (f) Bipartite network. (g) Projected bipartite network contains incorrect links. ", "caption_bbox": [96, 340, 729, 368]}, {"image_id": 1, "file_name": "642_01.png", "page": 4, "dpi": 300, "bbox": [110, 782, 384, 917], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Weighted projections also lose information; these two multiplex networks have identical projected substrate networks but very different catalyst network topologies. ", "caption_bbox": [96, 920, 397, 964]}, {"image_id": 2, "file_name": "642_02.png", "page": 5, "dpi": 300, "bbox": [133, 112, 731, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Pivoting from substrates to catalysts. The user selects nodes in the substrate view. Detangler retrieves the correspond- ing multiplex nodes and creates the induced subgraph of edges that connect them in the multiplex network. It computes the two group entanglement measures of homogeneity and intensity for this subgraph, and along the way finds the corresponding subgraph in the catalyst network. It also computes new individual entanglement index measures for each catalyst node with respect to this subgraph. ", "caption_bbox": [96, 250, 729, 324]}, {"image_id": 3, "file_name": "642_03.png", "page": 5, "dpi": 300, "bbox": [127, 369, 361, 447], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The two modes of pivoting from catalysts. The more restrictive AND operator yields only the substrate nodes connected through all of the designed catalysts; the more expansive OR mode yields the substrates nodes con- nected through any of the catalyst links. ", "caption_bbox": [96, 452, 397, 526]}, {"image_id": 4, "file_name": "642_04.png", "page": 5, "dpi": 300, "bbox": [114, 599, 381, 720], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Leapfrogging between substrates and catalysts through back-to-back pivots. ", "caption_bbox": [96, 723, 397, 751]}, {"image_id": 5, "file_name": "642_05.png", "page": 6, "dpi": 300, "bbox": [95, 112, 674, 351], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The Detangler interface. (a) The four views are annotated in orange and labelled. The current source is the substrate view on the left with a rectangular lasso showing the user\u2019s selection, and the target is the catalyst view on the right showing corresponding highlighting. The two secondary views are on the left: the entanglement measure detail view and the menu panel. (b) Sequential-segmented color ramp. The bottom segment is white; the main sequence has three hues with monotonically decreasing luminance; the top segment is bright purple, with discrete change of hue and luminance for maximal contrast. ", "caption_bbox": [96, 357, 729, 431]}, {"image_id": 6, "file_name": "642_06.png", "page": 7, "dpi": 300, "bbox": [128, 112, 731, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Harmonized layout illustration. (a) Lay out the catalyst network. (b) Remove edges. Assign substrates to catalysts based on their entanglement. (c) Lay out the substrates without moving the catalysts, prior to separating catalysts and substrates. ", "caption_bbox": [96, 262, 729, 290]}, {"image_id": 7, "file_name": "642_07.png", "page": 7, "dpi": 300, "bbox": [97, 322, 398, 560], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Leapfrog sequence showing visual encoding changes between pivot steps, with Detangler screenshots rather than the schematic diagram in Figure 5. ", "caption_bbox": [96, 564, 397, 608]}, {"image_id": 8, "file_name": "642_08.png", "page": 8, "dpi": 300, "bbox": [136, 345, 691, 532], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: American independence movement dataset. The right catalyst view shows terrorist cells, and the left substrate view shows terrorists such as Paul Revere. (a) Lassoing Paul Revere and then leapfrogging with the AND operators shows that he can reach every other terrorist in the network, as he did in his famous ride. (b) In contrast, leapfrogging with the OR operator shows that he is the only person with connections to all others, and is thus the only person who could have done that ride. ", "caption_bbox": [96, 540, 729, 599]}, {"image_id": 9, "file_name": "642_09.png", "page": 8, "dpi": 300, "bbox": [95, 112, 700, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: INA dataset of documents concerning speed and road safety. The right catalyst view shows two clusters of topics connected by the bridge nodes accident prevention and speed. The user has lassoed the cluster on the left as source nodes; the blue interior color shows high entanglement values, indicating that the group is cohesive. The left substrate view shows four documents highlighted as target nodes. The harmonized layout provides spatial stability between these two views. ", "caption_bbox": [96, 270, 729, 329]}, {"image_id": 10, "file_name": "642_10.png", "page": 9, "dpi": 300, "bbox": [110, 856, 384, 970], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Subjective ratings and overall confidence.", "caption_bbox": [126, 973, 367, 986]}], "643": [{"image_id": 0, "file_name": "643_00.png", "page": 1, "dpi": 300, "bbox": [97, 375, 730, 564], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Dual adjacency matrix (left), node-link-contour diagram (middle), and highlighted group nodes (right) that depict a trade network of countries (nodes) with substantial changes in volume traded (links) over a fifty year period. One group of links is selected in the top-left matrix, which covers countries such as Japan (ASI_JPN) and the USA (AME_USA). ", "caption_bbox": [96, 574, 729, 618]}, {"image_id": 1, "file_name": "643_01.png", "page": 2, "dpi": 300, "bbox": [95, 112, 730, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Example of a network and derived community structures: (a) Plain social network, people are nodes (dots) and their interactions are links (connecting lines); (b) Densely interconnected nodes of (a) have been grouped into communities, in which Dalia is part of a single community in spite of her widespread interactions; (c) Densely interconnected links of (a) have been grouped into communities, in which Dalia is part of multiple communities. ", "caption_bbox": [96, 260, 729, 319]}, {"image_id": 2, "file_name": "643_02.png", "page": 4, "dpi": 300, "bbox": [413, 112, 721, 690], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Overview of network aggregations, applied to the network of Fig. 2: (a) Bipartite network that bridges the node and link duality of (b) and (c), in which the node-to-node (solid dots) and link-to-link (hollow dots) con- nections correspond to node-link-node and link-node-link paths respectively; (b) Node-link diagram in which nodes (solid dots) are colored by group; (c) Node-link diagram of the dual of (b) in which links (hollow dots) are col- ored by group; (d) and (e) Node-link diagrams in which the respective groups of (b) and (c) are aggregated into single nodes; (f),(g),(h), and (i) Adjacency matrices of the (b),(c),(d), and (e) networks respectively. ", "caption_bbox": [428, 702, 729, 883]}, {"image_id": 3, "file_name": "643_03.png", "page": 5, "dpi": 300, "bbox": [112, 112, 412, 499], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Providing a node group interpretation of link groups with a dual adjacency matrix: (a) Network of Fig. 4(a), but with links colored to emphasize their groups; (b) Euler diagram of the set system that is induced by the link groups of (a), in which every set contains those nodes covered by its corresponding link group; (c) Set membership table (or matrix) of the set system of (b) that depicts all link group overlaps as the composition of node groups; (d) Node adjacency matrix of the node groups of (c); (e) Combination of (c), (d), and Fig. 4(i) that forms a dual adjacency matrix. ", "caption_bbox": [96, 512, 397, 662]}, {"image_id": 4, "file_name": "643_04.png", "page": 6, "dpi": 300, "bbox": [95, 112, 413, 378], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Node-link diagrams that incorporate link groups: (a) Detailed, full node-link diagram with color coding of nodes and links via interaction; (b) Aggregated node-link di- agram with links between node group pairs, color coded like (a); (c) Link group contours derived (and color coded) from the links of (b); (d) Addition of links between group pairs to (c) for improved depiction of topology. ", "caption_bbox": [96, 386, 397, 491]}, {"image_id": 5, "file_name": "643_05.png", "page": 7, "dpi": 300, "bbox": [96, 112, 731, 355], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Elucidation of link groups in a trade network, in which time series of highlighted groups are shown as trend plots that show trade volume on a log scale: (a) Comparison of the time series of a large link group (red) that has a mostly steady growth of trade volume, and a smaller link group (blue) with a significant trade slump in the 90\u2019s; (b) Overlap of all available trade relations of Iraq (red) with the relations of the smaller link group of (a) (blue), showing that many 90\u2019s volume slumps involve trade with Iraq (overlap colored black); (c) The blue link group of (a) is split into three subgroups of which one subgroup is a single link (red, covering ARA_IRQ and EUR_GFR) that is compared to the single link of a smaller top group (blue, covering ARA_IRQ and AME_USA). ", "caption_bbox": [96, 362, 729, 467]}, {"image_id": 6, "file_name": "643_06.png", "page": 9, "dpi": 300, "bbox": [96, 112, 731, 493], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Exploration of 20 brain regions connected by 183 links that encode (sliding window) fMRI signal correlations along 200 time points. The brain is divided into three zones (DAN, FPTC, and DMN) and links are grouped accordingly: three intra- zone link groups that are subgrouped [MG14], and three inter-zone link groups: (a) The top-left matrix shows no overlap between the three intra-zone link groups, but that they do overlap with the inter-zone link groups. The bottom-right matrix has three node groups that match the zones. The intra-zone link group DMN (red) has mixed signals, while DAN (blue) and FPTC have positive signals. (b) Both the FPTC link group (red) and the link group between FPTC and DAN (blue) have positive signals. (c) Splitting DMN because of its mixed signals reveals its overlapping link subgroups. Two link subgroups have strong overlap, where one group (red) is strongly correlated and tightly positioned in the brain, and the other group (blue) is less correlated and more spread across the brain. (d) The bottom-right adjacency matrix shows a missing link between spatial opposites Rlattemp and Llattemp. Hovering the empty spot compares all neighboring links of Rlattemp and Llattemp, where their signals show a consensus. (e) One node group (red) acts as a hub to DMN link groups. Hovering this node group and the DMN link groups shows that the node group has many anti-correlations within the DMN zone. However, hovering the inter-zone link groups (blue) shows that this node group has mostly positive correlations with the \u2018remainder\u2019 of the network. ", "caption_bbox": [96, 500, 729, 696]}], "644": [{"image_id": 0, "file_name": "644_00.png", "page": 1, "dpi": 300, "bbox": [99, 414, 727, 576], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Refinery allows exploration of large, heterogeneous networks by visualizing subgraphs of items relevant to user queries. Here, querying for a paper in a publication network has led this user to a conference session of possible interest. ", "caption_bbox": [96, 589, 729, 617]}, {"image_id": 1, "file_name": "644_01.png", "page": 4, "dpi": 300, "bbox": [95, 112, 665, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Free-text search allows users to identify items matching their interest and add them to the query. (b) Items which have been \u201cupvoted\u201d or \u201cdownvoted\u201d into the query are grouped together in the Query Panel for easy reference. ", "caption_bbox": [96, 306, 729, 334]}, {"image_id": 2, "file_name": "644_02.png", "page": 5, "dpi": 300, "bbox": [100, 112, 414, 307], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Refinery\u2019s Graph View clearly displays items most relevant to the query along with their relationships. ", "caption_bbox": [96, 319, 397, 347]}, {"image_id": 3, "file_name": "644_03.png", "page": 5, "dpi": 300, "bbox": [413, 112, 731, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Refinery\u2019s List View ranks items by overall rele- vance. Users can easily hide or show particular types using toggles in the Sidebar in order to focus their view. ", "caption_bbox": [428, 319, 729, 362]}, {"image_id": 4, "file_name": "644_04.png", "page": 9, "dpi": 300, "bbox": [108, 112, 731, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) SF Bay Area startup company data in Crunchbase: looking for content relevant to Big Data and Data Visual- ization, the user has identified an interesting company and explores further. (b) National flags: viewing content associated with the UK and Australia, the user highlights a node representing \u201csun or star imagery\u201d revealing that this graphical element is shared by several Commonwealth nations. ", "caption_bbox": [96, 297, 729, 356]}], "645": [{"image_id": 0, "file_name": "645_00.png", "page": 2, "dpi": 300, "bbox": [430, 454, 734, 542], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Some simple and intuitive visual guidance rules.", "caption_bbox": [431, 541, 726, 554]}, {"image_id": 1, "file_name": "645_01.png", "page": 3, "dpi": 300, "bbox": [95, 112, 415, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Data properties considered for the design of visual interpretation rules: distribution properties (a-c), and (mul- tivariate) linear correlations (e-f). In (d), a two-dimensional overlay of distribution is illustrated. ", "caption_bbox": [96, 334, 397, 393]}, {"image_id": 2, "file_name": "645_02.png", "page": 3, "dpi": 300, "bbox": [412, 112, 736, 410], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Our considered projection techniques.", "caption_bbox": [456, 414, 700, 427]}, {"image_id": 3, "file_name": "645_03.png", "page": 3, "dpi": 300, "bbox": [428, 433, 735, 680], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Schema for modeling the test data", "caption_bbox": [467, 684, 690, 697]}, {"image_id": 4, "file_name": "645_04.png", "page": 5, "dpi": 300, "bbox": [110, 112, 731, 997], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visual guidance pictograms for the distribution analysis", "caption_bbox": [213, 1007, 546, 1020]}, {"image_id": 5, "file_name": "645_05.png", "page": 6, "dpi": 300, "bbox": [95, 112, 699, 1002], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visual guidance pictograms for the correlation analysis", "caption_bbox": [214, 1013, 545, 1026]}, {"image_id": 6, "file_name": "645_06.png", "page": 8, "dpi": 300, "bbox": [95, 112, 691, 670], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Composing of a Visual Task: illustrated for RadVis and a number of dimensions n = 4.", "caption_bbox": [168, 680, 652, 693]}, {"image_id": 7, "file_name": "645_07.png", "page": 9, "dpi": 300, "bbox": [412, 112, 731, 529], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Visual guidance pictograms compared with se- lected data projections for distribution properties (top) and correlation properties (bottom). ", "caption_bbox": [428, 529, 729, 572]}, {"image_id": 8, "file_name": "645_08.png", "page": 9, "dpi": 300, "bbox": [95, 475, 409, 680], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Results of the user experiment.", "caption_bbox": [141, 684, 348, 697]}, {"image_id": 9, "file_name": "645_09.png", "page": 9, "dpi": 300, "bbox": [95, 112, 415, 441], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Examples of visual tasks of the user experiment.", "caption_bbox": [98, 452, 391, 465]}], "646": [{"image_id": 0, "file_name": "646_00.png", "page": 3, "dpi": 300, "bbox": [158, 112, 731, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Method pipeline.", "caption_bbox": [343, 212, 481, 225]}, {"image_id": 1, "file_name": "646_01.png", "page": 4, "dpi": 300, "bbox": [95, 112, 731, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Identification of three groups and their most relevant attributes by our method for the US counties data set.", "caption_bbox": [119, 339, 706, 352]}, {"image_id": 2, "file_name": "646_02.png", "page": 6, "dpi": 300, "bbox": [95, 112, 731, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Frequency histogram x Coefficient of variation (CV). Ad-10 data set (left) has uniform classes with low CV, US Counties (middle) has non-uniform classes with low CV, and US Counties-ad has non-uniform classes with high CV. ", "caption_bbox": [96, 319, 729, 347]}, {"image_id": 3, "file_name": "646_03.png", "page": 6, "dpi": 300, "bbox": [116, 364, 375, 499], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Percentage of the times each sampling scheme was able to get at least one sample per class in a thousand trials. ", "caption_bbox": [96, 503, 397, 531]}, {"image_id": 4, "file_name": "646_04.png", "page": 7, "dpi": 300, "bbox": [95, 436, 731, 608], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Identification of clusters in non-trivial data set: (a) original data classification; (b) applying the Column Selection Method (CSM); (c) applying the Expectation Maximization (EM) method; and (d) by the Make Density Based Cluster (MDBC). The bottom graphs illustrate the confusion matrix in each method and the accuracy (ACC). Notice that CSM is more accurate than the other methods. ", "caption_bbox": [96, 616, 729, 675]}, {"image_id": 5, "file_name": "646_05.png", "page": 7, "dpi": 300, "bbox": [95, 112, 731, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Silhouette coefficient. Our method (CSM) in dark blue outperforms the methods Expectation Maximization (EM) in red, Farthest First (FF) in green, Make Density Based Cluster (MDBC) in purple, Simple K-Means (SKM) in cyan, and X-Means (XM) in orange. ", "caption_bbox": [96, 372, 729, 415]}, {"image_id": 6, "file_name": "646_06.png", "page": 8, "dpi": 300, "bbox": [428, 615, 731, 735], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Analyzing the preference for products according to the customer types. ", "caption_bbox": [428, 745, 729, 773]}, {"image_id": 7, "file_name": "646_07.png", "page": 8, "dpi": 300, "bbox": [95, 112, 731, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Running time in seconds for representative instance identification and attribute selection. ", "caption_bbox": [96, 610, 397, 638]}], "647": [{"image_id": 0, "file_name": "647_00.png", "page": 3, "dpi": 300, "bbox": [125, 701, 374, 794], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An intuitive explanation of the subspace clustering. Left: The PCA view shows the projection from the side of the two 2D planes. By subspace clustering, we obtain two 2D subspaces (middle and right) that correspond to the two planes, respectively. 3.1.1    Subspace Clustering ", "caption_bbox": [96, 794, 397, 863]}, {"image_id": 1, "file_name": "647_01.png", "page": 4, "dpi": 300, "bbox": [95, 112, 714, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An overview of our workflow.", "caption_bbox": [323, 304, 501, 316]}, {"image_id": 2, "file_name": "647_02.png", "page": 4, "dpi": 300, "bbox": [101, 495, 390, 686], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: For the subspace corresponding to each class, we show the average accuracy of samples in finding neighbors sharing their class label, using different subspace analysis strategies. We also show the subspace dimension in each case. ", "caption_bbox": [96, 686, 397, 739]}, {"image_id": 3, "file_name": "647_03.png", "page": 5, "dpi": 300, "bbox": [412, 112, 734, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: kNN graphs with varying k. (a) k = 1. (b) k = 2. (c) k = 3. From all of the graphs (a)-(c), we can infer two groups of subspaces with strong intra-cluster relationships: the orange and black sub- spaces; and the PCA, brown, purple, and cyan subspaces. ", "caption_bbox": [428, 263, 729, 317]}, {"image_id": 4, "file_name": "647_04.png", "page": 5, "dpi": 300, "bbox": [96, 474, 395, 622], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The views navigation graph. (a) The square glyph indexed by subspace ID corresponds to the representative view of a given subspace. The circle glyph corresponds to a non-representative view or the PCA projection. For each subspace with dimension three or higher, we can dynamically expand its representative into multiple 2D views generated from its basis (e.g., (b) & (c)). ", "caption_bbox": [96, 629, 397, 710]}, {"image_id": 5, "file_name": "647_05.png", "page": 5, "dpi": 300, "bbox": [436, 611, 719, 769], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The software architecture.", "caption_bbox": [498, 774, 659, 786]}, {"image_id": 6, "file_name": "647_06.png", "page": 6, "dpi": 300, "bbox": [469, 659, 680, 839], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Combustion dataset. (a) PCA view colored by point-wise distortion measure. (b) Yellow subspace view colored by point-wise distortion measure. (c) Yellow subspace view colored by tempera- ture. (d) Yellow subspace view colored by HO2 concentration. ", "caption_bbox": [428, 839, 729, 894]}, {"image_id": 7, "file_name": "647_07.png", "page": 6, "dpi": 300, "bbox": [97, 383, 398, 569], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: User interface. (A) The dynamic projection panel. (B) The subspace view navigation panel. ", "caption_bbox": [96, 573, 397, 599]}, {"image_id": 8, "file_name": "647_08.png", "page": 7, "dpi": 300, "bbox": [104, 683, 387, 840], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Yale face dataset. (a) View navigation graph. (b) illus- trates the correlation between the points distribution and the lighting directions in the PCA view. ", "caption_bbox": [96, 839, 397, 879]}, {"image_id": 9, "file_name": "647_09.png", "page": 7, "dpi": 300, "bbox": [482, 608, 673, 765], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Yale face dataset. (a) The cyan subspace view. (b) The brown subspace view. ", "caption_bbox": [428, 764, 729, 790]}, {"image_id": 10, "file_name": "647_10.png", "page": 7, "dpi": 300, "bbox": [99, 112, 731, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Combustion dataset. (a) View navigation graph. (b) From left to right, top to bottom: we transition from the PCA view, to the cyan, purple, and brown subspace views; then to the orange, and finally to the black subspace view. Two snapshots of the dynamic transition between the orange and the black subspace views connected by black arrows are included. ", "caption_bbox": [96, 332, 729, 372]}, {"image_id": 11, "file_name": "647_11.png", "page": 8, "dpi": 300, "bbox": [95, 864, 409, 956], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: GGobi results using the grand tour and projection pursuit holes index; example frames for the combustion (a)-(b) and face datasets (c)-(d). ", "caption_bbox": [96, 960, 397, 1000]}, {"image_id": 12, "file_name": "647_12.png", "page": 8, "dpi": 300, "bbox": [95, 112, 731, 420], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Yale face dataset. (a)-(b) Dynamic transition from the PCA to the orange subspace view; two snapshots of the animations are included. (b) Shows the three stratified sets and highlights the image variation (the amount of shadow) along their dominant directions. (c) highlights the mis-classification (circled area) caused by poor lighting conditions. (d)-(e) Dynamic transition from the PCA to the red subspace view; two snapshots of the animation are included. (f) Shows the red points in the red space view where their corresponding images vary along the cluster\u2019s dominating direction according to the differences in lighting direction. ", "caption_bbox": [96, 422, 729, 489]}], "648": [{"image_id": 0, "file_name": "648_00.png", "page": 3, "dpi": 300, "bbox": [166, 112, 731, 941], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Screenshots of three example stimuli for a value retrieval task at the easy level in terms of task difficulty.", "caption_bbox": [126, 949, 698, 962]}, {"image_id": 1, "file_name": "648_01.png", "page": 5, "dpi": 300, "bbox": [96, 112, 746, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Example stimuli for three different visualization tasks: clustering (left), outlier detection (middle), and change detec- tion (right). All stimuli are at the easy level in terms of task difficulty. ", "caption_bbox": [96, 434, 729, 462]}, {"image_id": 2, "file_name": "648_02.png", "page": 6, "dpi": 300, "bbox": [95, 112, 741, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Sample stimuli for the change detection task at the medium and hard levels of task difficulty.", "caption_bbox": [156, 353, 668, 366]}, {"image_id": 3, "file_name": "648_03.png", "page": 8, "dpi": 300, "bbox": [412, 112, 727, 709], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Summary of the performance results of each data representation in conjunction with each visualization task. ", "caption_bbox": [428, 717, 729, 745]}, {"image_id": 4, "file_name": "648_04.png", "page": 9, "dpi": 300, "bbox": [437, 563, 719, 927], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Performance of the change detection task at dif- ferent levels of task difficulty. ", "caption_bbox": [428, 935, 729, 963]}, {"image_id": 5, "file_name": "648_05.png", "page": 9, "dpi": 300, "bbox": [104, 564, 388, 927], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Performance of the clustering task at different lev- els of task difficulty. ", "caption_bbox": [96, 935, 397, 963]}, {"image_id": 6, "file_name": "648_06.png", "page": 9, "dpi": 300, "bbox": [412, 112, 731, 504], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Performance of the outlier detection task at differ- ent level of task difficulty. ", "caption_bbox": [428, 511, 729, 539]}, {"image_id": 7, "file_name": "648_07.png", "page": 9, "dpi": 300, "bbox": [105, 112, 415, 504], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Performance of the value retrieval task at different levels of task difficulty. ", "caption_bbox": [96, 511, 397, 539]}], "649": [{"image_id": 0, "file_name": "649_00.png", "page": 3, "dpi": 300, "bbox": [95, 112, 415, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: CLaMS trajectories seeded at volcanic ash detec- tions from 0 S to 90 S: Top: Point cloud filtered by time be- tween June 12 at 13:00 and June 15 at 16:00. Bottom: Path- lines further filtered by StreamProbe technique [ESGG\u2217 14] around the eruption location with trajectory seeds marked by yellow X\u2019s. ", "caption_bbox": [95, 369, 396, 458]}, {"image_id": 1, "file_name": "649_01.png", "page": 4, "dpi": 300, "bbox": [95, 112, 711, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Sample 12 hour AIRS coverage on June 10th 2011. Morning measurements are displayed on the left while afternoon readings are on the right. Shades of brown encode time while the ash plume is shown in blue. ", "caption_bbox": [95, 375, 728, 403]}, {"image_id": 2, "file_name": "649_02.png", "page": 4, "dpi": 300, "bbox": [440, 440, 718, 647], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Data visualization framework.", "caption_bbox": [474, 658, 679, 671]}, {"image_id": 3, "file_name": "649_03.png", "page": 5, "dpi": 300, "bbox": [412, 112, 731, 404], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Data processing: CPU-based spatio-temporal in- terpolation technique. ", "caption_bbox": [427, 419, 728, 447]}, {"image_id": 4, "file_name": "649_04.png", "page": 7, "dpi": 300, "bbox": [98, 186, 395, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Two sample IR images at 20110606114500 UTC after re-projection in the World Geodetic System 1984 (WGS1984) common geographic coordinate system. ", "caption_bbox": [95, 350, 396, 393]}, {"image_id": 5, "file_name": "649_05.png", "page": 7, "dpi": 300, "bbox": [412, 112, 731, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Cross correlation over 3 consecutive days between geostationary satellites\u2019 delineated plumes and four recon- structed plumes: the simulated model plume (red), CPU- corrected AIRS data using CLaMS for interpolation (black), and GPU-corrected AIRS data using plume for interpolation at neighborhood sizes of 4 (green) and 16 (violet). ", "caption_bbox": [427, 311, 728, 400]}, {"image_id": 6, "file_name": "649_06.png", "page": 8, "dpi": 300, "bbox": [95, 598, 399, 740], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Generated plume (yellow) shown with raw AIRS data (red) from midnight to noon on June 8th, 2011. ", "caption_bbox": [95, 751, 396, 779]}, {"image_id": 7, "file_name": "649_07.png", "page": 9, "dpi": 300, "bbox": [139, 575, 685, 911], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparison at 20110608054500 UTC between METEOSAT-7 IR image, raw AIRS data, and three types of AIRS corrected plumes. (a) raw AIRS (no correction), (b) CPU corrected plume, (c) GPU plume calculated from 4 NN (nearest neighbors), and (d) GPU plume calculated from 16 NN. ", "caption_bbox": [95, 935, 728, 978]}, {"image_id": 8, "file_name": "649_08.png", "page": 9, "dpi": 300, "bbox": [143, 112, 731, 473], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison at 20110606174500 UTC between GOES-12 IR image, raw AIRS data, and three types of AIRS corrected plumes. (a) raw AIRS (no correction), (b) CPU corrected plume, (c) GPU plume calculated from 4 NN (nearest neighbors) , and (d) GPU plume calculated from 16 NN. ", "caption_bbox": [95, 497, 728, 540]}], "650": [{"image_id": 0, "file_name": "650_00.png", "page": 1, "dpi": 300, "bbox": [95, 397, 731, 607], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Fiber Surfaces of electron density and reduced gradient in an ethane-diol molecule: (a) While an isosurface of electron density identifies regions of influence of atoms (grey), it does not distinguish atomic type. An isosurface of reduced gradient identifies bonding interaction sites (blue) but does not distinguish non-covalent (top) from covalent bonds (others). (b) Continuous scatter plot (log scale) of electron density and reduced gradient. Isosurfaces and fiber surfaces are shown as dashed lines and polygons respectively. (c) Fiber surfaces distinguish atom types (oxygen in red, carbons in grey) as well as bond types (non-covalent in green, covalent in blue). ", "caption_bbox": [96, 633, 729, 722]}, {"image_id": 1, "file_name": "650_01.png", "page": 2, "dpi": 300, "bbox": [101, 279, 390, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Fiber Construction. Left: isosurface of f1 . Centre: fiber defined by intersecting isosurfaces. Right: isosurface of  f2 . Both isosurfaces show the fiber for reference. ", "caption_bbox": [96, 393, 397, 436]}, {"image_id": 2, "file_name": "650_02.png", "page": 3, "dpi": 300, "bbox": [437, 636, 722, 748], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Fiber Surface of a Polygon. Left: the polygon in the range with the projection of a single tetrahedra. Right: the tetrahedron in the range with the fibers corresponding to edges uv, vw. Each fiber is a point in the range but a line in the domain. Each line in the range corresponds to a plane in the tetrahedron. ", "caption_bbox": [428, 759, 729, 848]}, {"image_id": 3, "file_name": "650_03.png", "page": 5, "dpi": 300, "bbox": [125, 112, 731, 396], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Fiber surfaces obtained by increasing the range distance to the initial fiber surface control polygon, from (a) to (d).", "caption_bbox": [96, 406, 728, 419]}, {"image_id": 4, "file_name": "650_04.png", "page": 6, "dpi": 300, "bbox": [95, 112, 731, 442], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Fiber Surfaces of a cosmological simulation of universe expansion: (a, b) Isosurfaces of matter (white) and dark matter (orange) concentrations for different pairs of isovalues (a: low, b: high). (c) Discrete scatter plot superimposed on the continuous one (matter vs. dark matter distribution). (d) Distribution by surface area of fiber surface components. (e)-(g) Zoom- in views for dark matter, matter and fiber surface respectively. (h) Composite zoom-in views for the 3 surfaces emphasizing their nesting relation. (i) Fiber surface for the polygon shown in (c). (j)-(k) Progressive simplification of the fiber surface components by surface area (dashed lines in (d)). (l) Composite view of dark matter (orange), matter (white) and fiber surface (blue). (m) Fiber surface contraction through smoothing passes to enhance the visual display of bubbles and filaments. ", "caption_bbox": [96, 467, 729, 571]}, {"image_id": 5, "file_name": "650_05.png", "page": 7, "dpi": 300, "bbox": [412, 112, 731, 378], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Fiber surfaces for material boundaries in a tooth CT-scan: (a) User selected isosurfaces. (b) Continuous scat- ter plot of isovalue vs. gradient magnitude with user selected isovalues (dashed lines) and polygons. (c) Fiber surfaces of the selected polygons. (d) Fiber surfaces after connected component filtering. (e) Cut-away view of the fiber surfaces. ", "caption_bbox": [428, 404, 729, 493]}, {"image_id": 6, "file_name": "650_06.png", "page": 7, "dpi": 300, "bbox": [95, 112, 415, 405], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Extracting the core of a burning flame: (a) Isotherm thresholded (opaque triangles) on temperature gradient magnitude (color map). (b) Extracting the same feature with fiber surfaces guarantees closed 2-manifolds. ", "caption_bbox": [96, 431, 397, 490]}, {"image_id": 7, "file_name": "650_07.png", "page": 9, "dpi": 300, "bbox": [103, 112, 731, 636], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Fiber surfaces compared with direct volume rendering. Top: cosmology (enzo) simulation. Bottom: chemistry (ethane-diol) simulation. Direct volume rendering was optimized with peak finding [KKS\u2217 12] to identify the fiber surface boundaries (this gives a roughly 2\u20134x performance improvement over naive volume rendering). Fiber surfacing exhibits better contrast, enables geometric analyses and better rendering performance via rasterization. ", "caption_bbox": [96, 647, 729, 706]}], "651": [{"image_id": 0, "file_name": "651_00.png", "page": 4, "dpi": 300, "bbox": [432, 411, 729, 504], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Parts of a dot plot and two matrices collected dur- ing the study. ", "caption_bbox": [428, 515, 729, 543]}, {"image_id": 1, "file_name": "651_01.png", "page": 4, "dpi": 300, "bbox": [95, 112, 731, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Sample representations along a continuum of numeracy to abstractness. Tokens indicate how many representations of each type were collected. An extended version of this figure is available online: http://bit.ly/datasketching. ", "caption_bbox": [96, 262, 729, 289]}, {"image_id": 2, "file_name": "651_02.png", "page": 5, "dpi": 300, "bbox": [97, 112, 415, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Graph-like representations that place appropriate behaviours in orbits around a situation and link behaviours across situations. ", "caption_bbox": [96, 240, 397, 283]}, {"image_id": 3, "file_name": "651_03.png", "page": 5, "dpi": 300, "bbox": [117, 304, 373, 469], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A data sketch of a \u201cdecision helper\u201d tool", "caption_bbox": [115, 480, 373, 493]}, {"image_id": 4, "file_name": "651_04.png", "page": 6, "dpi": 300, "bbox": [95, 112, 730, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The spectrum of data report statements.", "caption_bbox": [286, 261, 538, 274]}, {"image_id": 5, "file_name": "651_05.png", "page": 7, "dpi": 300, "bbox": [100, 112, 415, 509], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Summary of artifacts collected for each partici- pant. Columns show (L-R): Statements on the data report spectrum (A-F), corresponding to Fig. 5; Participant\u2019s most abstract sketch along the representation continuum (Max); Classification of submitted representations \u2013 letters corre- spond to those in Fig. 1; Presence of process comments (P); Presence of full-sentence annotation on data sketches, in yel- low (A); Self-reported experience in visualization (X) \u2013 dark- est denotes most experience. Rows are ordered by Max, from most abstract to most numeric. The abstract representations tend to correspond to data reports in columns E3 and F. ", "caption_bbox": [96, 522, 397, 687]}, {"image_id": 6, "file_name": "651_06.png", "page": 7, "dpi": 300, "bbox": [412, 112, 731, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Relation of data report spectrum to the levels of data description that a representation can convey about a two-dimensional dataset: (1) value level, (2) dimension level, (3) global level, and (4) external information. ", "caption_bbox": [428, 318, 729, 377]}], "652": [{"image_id": 0, "file_name": "652_00.png", "page": 1, "dpi": 300, "bbox": [95, 563, 731, 708], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Two examples of embellished charts and abstracted versions of the embellishments.", "caption_bbox": [179, 549, 646, 562]}, {"image_id": 1, "file_name": "652_01.png", "page": 2, "dpi": 300, "bbox": [95, 112, 718, 737], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A sampling of charts used in infographics, taken from examples found on Visual.ly [Vis14b].", "caption_bbox": [155, 750, 669, 763]}, {"image_id": 2, "file_name": "652_02.png", "page": 5, "dpi": 300, "bbox": [159, 112, 731, 862], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Embellished bar charts simplified for use in the study.", "caption_bbox": [253, 876, 571, 889]}, {"image_id": 3, "file_name": "652_03.png", "page": 6, "dpi": 300, "bbox": [436, 336, 729, 725], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An example of what a survey participant saw when answering questions. This screen uses the absolute value question and the baseline bar chart. The participant has en- tered \u201c20\u201d into the text entry. ", "caption_bbox": [428, 756, 729, 815]}, {"image_id": 4, "file_name": "652_04.png", "page": 7, "dpi": 300, "bbox": [412, 112, 731, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Absolute judgements: summary statistics and Mann-Whitney-Wilcoxon Tests Results comparing embel- lishment types to the baseline. Significant values denoted by * with \u03b1 = 0.0083. ", "caption_bbox": [428, 398, 729, 457]}, {"image_id": 5, "file_name": "652_05.png", "page": 7, "dpi": 300, "bbox": [190, 112, 415, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Log error for the absolute value task by embellish- ment type. ", "caption_bbox": [428, 351, 729, 379]}, {"image_id": 6, "file_name": "652_06.png", "page": 8, "dpi": 300, "bbox": [95, 112, 413, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Relative judgements: summary statistics and Mann- Whitney-Wilcoxon Tests Results comparing embellishment types to the baseline. Significant values are denoted by * with \u03b1 = 0.0083. ", "caption_bbox": [96, 404, 397, 463]}, {"image_id": 7, "file_name": "652_07.png", "page": 8, "dpi": 300, "bbox": [412, 112, 646, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The possible mental operation viewers use to tell the value of an individual bar depends heavily on the shape of the top of the bar and the axis. ", "caption_bbox": [428, 302, 729, 346]}], "653": [{"image_id": 0, "file_name": "653_00.png", "page": 1, "dpi": 300, "bbox": [412, 366, 730, 808], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Examples of contrast effects. (a) The ends of the gray bar and also the cats (b) are perceived differently, but are equal. (c) and (d) show compensated results of [MSK14]. ", "caption_bbox": [427, 822, 730, 865]}, {"image_id": 1, "file_name": "653_01.png", "page": 2, "dpi": 300, "bbox": [95, 112, 674, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of a smart grid [MWE\u2217 15]. Transformer stations (rectangles) are connected via power lines and linked to the communication infrastructure (triangles). While gray indicates normal operation mode, yellow elements on the screen reveal a severe situation (violet stations are destroyed due to a debris avalanche in the eastern area). Due to contrast effects, the elements in (a) seem to be more critical than they actually are, causing that operators unnecessarily try to reconfigure the system, which increases operational costs. In (b), contrast effects are compensated showing (accurately) a less severe situation. ", "caption_bbox": [95, 399, 730, 477]}, {"image_id": 2, "file_name": "653_02.png", "page": 3, "dpi": 300, "bbox": [110, 112, 415, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The algorithm computes the perception model PM, the bias with cost function f , and iteratively reduces the bias in an optimization process. Our algorithm parallelizes PM and f and also introduces a convergence threshold t. ", "caption_bbox": [95, 251, 398, 310]}, {"image_id": 3, "file_name": "653_03.png", "page": 4, "dpi": 300, "bbox": [412, 112, 716, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Original image. (b) shows the compen- sated image without sampling in comparison to recon- struction with (c) our method and (d) the Lanczos filter method [Tur90] (both with 7px sampling interval). ", "caption_bbox": [427, 244, 730, 303]}, {"image_id": 4, "file_name": "653_04.png", "page": 5, "dpi": 300, "bbox": [132, 112, 731, 373], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Contrast compensation with surrogate models. The method applies contrast compensation on the sampled image and \u201clearns\u201d how to compensate for contrast effects. The method determines the contrast effects for each original pixel, finds an equivalent sampled pixel in the (sampled) proximity, and applies the compensation. The algorithm adjusts the parameters automatically to provide an accurate solution without artifacts. ", "caption_bbox": [95, 385, 728, 444]}, {"image_id": 5, "file_name": "653_05.png", "page": 6, "dpi": 300, "bbox": [95, 112, 699, 343], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) The effectiveness of the algorithm with different sampling intervals and t = 1\u2206E being the quality threshold (zero line due to logarithmic scaling). At a sampling interval of 7px, the algorithm is still able to find a \u201cgood\u201d solution for the security visualization (green). (b) The computation time decreases significantly with increasing sampling interval. With 7px sampling interval the security visualization can be rendered in 360ms. ", "caption_bbox": [95, 361, 728, 420]}, {"image_id": 6, "file_name": "653_06.png", "page": 7, "dpi": 300, "bbox": [464, 583, 693, 667], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The subjects had to assign the highlighted values to the value range in the color legend (here 4). ", "caption_bbox": [427, 678, 728, 706]}, {"image_id": 7, "file_name": "653_07.png", "page": 7, "dpi": 300, "bbox": [95, 112, 731, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Left: (a) The user is shown samples of contrast effect for each type of cones in the human eye. The colors of the left, right, and middle patch in each sample are equal. The sliders parametrize the perception model. The user is asked to match the colors of the patches with the center and thus, personalizes the method. (b) No compensation with \u03b5C0 = 0 and \u03b5C1 = 0. (c) Compensation with \u03b5C0 = 0.8 and \u03b5C1 = 1.0. Right: Staircase method for personalization: The user selects the patch (a), (b), or (c) that appears most similar to the reference (d). The parameter is adapted and iteratively refined. ", "caption_bbox": [94, 274, 730, 348]}, {"image_id": 8, "file_name": "653_08.png", "page": 8, "dpi": 300, "bbox": [95, 112, 415, 200], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Experiment results. (a) Cone contrast exponents \u03b50 and \u03b51 of all subjects. (b) Error of subjects comparing color encoded values with different parameters for the perception model in contrast effect compensation. ", "caption_bbox": [95, 210, 396, 269]}], "654": [{"image_id": 0, "file_name": "654_00.png", "page": 2, "dpi": 300, "bbox": [95, 112, 415, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Examples of two scatterplots, each showing syn- thetic data with three different classes, color-coded in the plots. Scatterplot (a) visually separates the classes nicely as can be seen by a human; an effective visual separation mea- sure should score high. In scatterplot (b) the classes are not visually separable; the measure should score low. ", "caption_bbox": [96, 311, 397, 400]}, {"image_id": 1, "file_name": "654_01.png", "page": 3, "dpi": 300, "bbox": [96, 112, 731, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of our data-driven framework for quality measure evaluation. The overall process is broken down into three major steps. The gray boxes show the generic steps of our framework, while the white boxes within them describe how we instantiated the framework for testing class separation measures in color-coded scatterplots. ", "caption_bbox": [96, 312, 729, 355]}, {"image_id": 2, "file_name": "654_02.png", "page": 5, "dpi": 300, "bbox": [95, 112, 415, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (left) The horizontal axis represents a continuum of all possible values a separation measure (m) can take. Onto this axis, one can now draw all measure values as a probability density function. Measure values associated with separable classes in the human ground truth data are drawn in green. The ones associated with non-separable classes in red. A classifier is now defined by a decision threshold (blue dot) acting on this axis. Any data located over the de- cision threshold is assigned to the positive class (P, that is, it would predict separable), else to the negative class (N, pre- dicting non-separable). By moving the threshold along the axis the tradeoff between false positives (FP) and false neg- atives (FN) changes drastically, as indicated by the three dif- ferent threshold positions A, B, and C. (right) The Receiver Operating Characterictic (ROC) curve results from varying the decision threshold value from the lowest available sep- aration measure value to the highest one. The Area Under the ROC Curve (AUC) quantifies the quality of the classifier over all possible decision threshold values. ", "caption_bbox": [96, 315, 397, 602]}, {"image_id": 3, "file_name": "654_03.png", "page": 7, "dpi": 300, "bbox": [412, 112, 731, 434], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Results of real and synthetic datasets separately. Each separation measure is represented as a point with coordinates encoding the AUC bootstrap average on real datasets (x-axis) and synthetic datasets (y-axis). Observa- tions: (1) Points fall in the upper left part, that is, measures score better on synthetic than on real datasets. (2) Points of parametric measures are colored and connected in sequence (by parameter value). AUC scores vary greatly, and the pa- rameter dependence is stronger for synthetic datasets. ", "caption_bbox": [428, 445, 729, 580]}, {"image_id": 4, "file_name": "654_04.png", "page": 7, "dpi": 300, "bbox": [97, 112, 415, 435], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Results of our study. Each row represents a sep- aration measure with a box plot encoding the AUC boot- strap distribution: median (red center line); interquartile range (IQR), i.e., from 25 to 75 percentile (box); 25/75 percentile +/- 1.5 times the IQR, including 99.3% of the data (whiskers); and outliers (red points). The measures are ranked in decreasing order of the AUC bootstrap average. A score of 0.5 denotes a random guess, while 1 would indicate perfect separation prediction on unseen (but similar) data. ", "caption_bbox": [96, 445, 397, 580]}], "655": [{"image_id": 0, "file_name": "655_00.png", "page": 1, "dpi": 300, "bbox": [95, 622, 731, 835], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A rationale visualization of a maritime use case in which an alarm has risen due to possible Reckless behavior. By hovering the mouse over the name attribute, the operator is investigating the possible names of the vessel and the effect on the reasoning. All hypotheses that depend on the name attribute are highlighted in green. ", "caption_bbox": [96, 570, 729, 614]}, {"image_id": 1, "file_name": "655_01.png", "page": 2, "dpi": 300, "bbox": [96, 112, 715, 228], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Evidence is reasoned upon by an automated reasoner, a monolithic black box based on a domain model, which sup- plies a conclusion with a certain probability. This is, however, not sufficient for a decision-maker to take decisions confidently. We therefore propose to extract an abstraction of the reasoning engine, and visualize this such that the decision-maker can understand the reasoning process. Our contribution is highlighted in blue. ", "caption_bbox": [96, 238, 729, 297]}, {"image_id": 2, "file_name": "655_02.png", "page": 4, "dpi": 300, "bbox": [412, 112, 707, 248], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A schematic representation of the reasoning ab- straction of our toy problem. The main hypothesis, h0 : Crim- inal Activity, states that the person crossing a border at a customs office is involved in criminal activity. This is based on whether the individual is trying to hide their identity (h1 ), has past criminal activity (h2 ), and is an adult (h3 ). ", "caption_bbox": [428, 259, 729, 348]}, {"image_id": 3, "file_name": "655_03.png", "page": 5, "dpi": 300, "bbox": [113, 112, 731, 225], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) A rationale visualization of a scenario in which there is a rise in probability that the OOI is involved in criminal activity. Because edge (1) is thick and red, we can see this is mainly due to a history of criminal activity. (b) There is a lowered probability of criminal activity. Because edge (2) is thick and blue, we can see this is mainly because the OOI is not an adult. In our toy model, we have made the assumption that a child is less likely to be involved in criminal activity. (c) We show a close-up of a hypothesis node, with below it, some of the alternatives we considered for the probability indicator. ", "caption_bbox": [96, 237, 729, 311]}, {"image_id": 4, "file_name": "655_04.png", "page": 6, "dpi": 300, "bbox": [96, 112, 415, 346], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) The evidence matrix where attribute values are colored-coded to show contradiction or agreement between observations. (b) A user can investigate the evidence by hov- ering the mouse over the matrix. ", "caption_bbox": [96, 374, 397, 433]}, {"image_id": 5, "file_name": "655_05.png", "page": 7, "dpi": 300, "bbox": [96, 112, 415, 312], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: We have a slightly risen probability that the OOI is involved in criminal activity. This appears to be mainly due to past criminal activity, and an eye witness report with the OOI\u2019s descriptions. In the time line, however, the tip appears to be old, and even predates the criminal record. This is re- flected by the lowered relevance of the eye witness report, and the only slight rise in probability of Criminal Activity. ", "caption_bbox": [96, 339, 397, 444]}, {"image_id": 6, "file_name": "655_06.png", "page": 8, "dpi": 300, "bbox": [95, 112, 728, 516], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A set of maritime use cases using real data. In (a) we see a vessel with a risen probability that it poses an environment hazard. We can see this is because the vessel is trying to hide its identity by spoofing its AIS ID, and because it already has polluted in the past. It can be immediately seen through the evidence matrix that the vessel is likely trying to hide its identity, because the information broadcasted by its AIS cannot be confirmed by other sources. In (b) we see a slight rise in probability that the vessel is smuggling. This appears to be because the vessel is trying to hide its identity by spoofing its AIS ID, which in turn is supported by the varying colors in the evidence matrix, and because the vessel is inside a forbidden area. ", "caption_bbox": [96, 547, 729, 636]}], "656": [{"image_id": 0, "file_name": "656_00.png", "page": 1, "dpi": 300, "bbox": [473, 707, 675, 877], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Air traffic routes for arrivals (red) and departures (blue) to Zurich airport and average distributions of flights amongst them. Note the Swiss-German border to the north. ", "caption_bbox": [426, 894, 728, 937]}, {"image_id": 1, "file_name": "656_01.png", "page": 4, "dpi": 300, "bbox": [95, 112, 731, 461], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The Exploration View. Part A denotes the management area, whereas part B contains a map view depicting all selected data and showing details on a flight violating a rule in a textbox-overlay. Black tracks denote flights that violate rules. ", "caption_bbox": [95, 487, 728, 515]}, {"image_id": 2, "file_name": "656_02.png", "page": 4, "dpi": 300, "bbox": [95, 536, 396, 794], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Management interface with visualization options and behavior filter in part A, date and time selection in part B, weather display in Part C and the overview visualization in the right part. ", "caption_bbox": [95, 804, 396, 863]}, {"image_id": 3, "file_name": "656_03.png", "page": 5, "dpi": 300, "bbox": [427, 136, 731, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Per-cell averaged flight direction visualization with the average direction of arrivals in red and of departures in blue. Selected trajectories appear in yellow. ", "caption_bbox": [427, 311, 728, 354]}, {"image_id": 4, "file_name": "656_04.png", "page": 5, "dpi": 300, "bbox": [427, 821, 731, 956], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Prediction view, with input feature selection con- trols and density representation. ", "caption_bbox": [427, 966, 730, 994]}, {"image_id": 5, "file_name": "656_05.png", "page": 6, "dpi": 300, "bbox": [427, 331, 731, 633], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: View on aggregated real-world (A) and predicted density values (B) of the same day. Comparison visualization thereof in (C) and (D) with noise visualization for predictor error. ", "caption_bbox": [427, 643, 728, 702]}, {"image_id": 6, "file_name": "656_06.png", "page": 6, "dpi": 300, "bbox": [412, 112, 693, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Example of a cell containing two different density values for comparison (left) and examples for cells with all possible difference combinations and noise-based uncertainty visualization in detail (right). ", "caption_bbox": [427, 262, 728, 321]}, {"image_id": 7, "file_name": "656_07.png", "page": 7, "dpi": 300, "bbox": [95, 136, 398, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Noise applied to a solid, dark gray image and a map excerpt showing Zurich. With increasing noise, the incremental loss of information can be observed, while the main features of the map excerpt stay visible. ", "caption_bbox": [95, 276, 396, 335]}, {"image_id": 8, "file_name": "656_08.png", "page": 8, "dpi": 300, "bbox": [427, 397, 731, 588], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Two density predictions, showing differences between (1) and (2). (3) shows the comparison visualization with two opposing weather situations. ", "caption_bbox": [427, 599, 728, 642]}, {"image_id": 9, "file_name": "656_09.png", "page": 8, "dpi": 300, "bbox": [96, 112, 683, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Exploration with aggregated overview (1), flights violating regulations (2) and a day with no northern approaches (3).", "caption_bbox": [95, 287, 730, 300]}], "657": [{"image_id": 0, "file_name": "657_00.png", "page": 3, "dpi": 300, "bbox": [431, 139, 729, 224], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Fundamental diagrams are used to depict rela- tions of speed-occupancy, speed-flow, and flow-occupancy. ", "caption_bbox": [428, 239, 729, 267]}, {"image_id": 1, "file_name": "657_01.png", "page": 4, "dpi": 300, "bbox": [412, 112, 731, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Our system draws color-coded charts of a re- gion within a time span to convey traffic situations. The ver- tical and horizontal axes represent VD\u2019s mileage and data time, respectively. The color-coded charts with the data in- terpolated are rendered with half-transparency. The black arrow indicates the vehicle moving direction. The color bar depicts the speed-color mapping. Notice that our system pro- vides both focus (left) and context (bottom right) views for experts to maintain the overall image when they zoom-in to a small area of the data. The red rectangle in the context view indicates the region detailed in the focus view. (b) By a simple click, our system plots the locations of the visualized VDs on the map to reveal the geography and helps experts make sense of traffic situations. ", "caption_bbox": [428, 298, 729, 509]}, {"image_id": 2, "file_name": "657_02.png", "page": 5, "dpi": 300, "bbox": [98, 112, 414, 228], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Our system provides semantic zoom for users to explore traffic events at different scales. From left to right are the color-coded charts at local, meso, and global scales. ", "caption_bbox": [96, 238, 397, 281]}, {"image_id": 3, "file_name": "657_03.png", "page": 5, "dpi": 300, "bbox": [412, 112, 731, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (Left) Our system allows users to specify the range of VD data that span sy kilometers and sx days during visu- alization. (Right) It then projects the data onto a screen with a resolution of w \u00d7 h using pixel based rendering to achieve interactive performance. ", "caption_bbox": [428, 282, 729, 356]}, {"image_id": 4, "file_name": "657_04.png", "page": 6, "dpi": 300, "bbox": [96, 112, 721, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (Left) The visualization of speed bottlenecks. To investigate the moving bottlenecks, we zoom into the region of interest (highlighted using a white rectangle) and show the color-coded charts that represent speed (middle) and flow (right). ", "caption_bbox": [96, 344, 729, 372]}, {"image_id": 5, "file_name": "657_05.png", "page": 6, "dpi": 300, "bbox": [431, 410, 730, 606], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: We retrieve traffic patterns similar to the refer- ence patch three times. The patches from the most similar to the fifth similar are listed from left to right. The retrieved patterns are generally the same, except their starting time spans and mileages are a little bit different. ", "caption_bbox": [428, 618, 729, 692]}, {"image_id": 6, "file_name": "657_06.png", "page": 7, "dpi": 300, "bbox": [430, 139, 729, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Left and right images show the flow and speed of VD data from Ilan to Taipei. The visual patterns have dif- ferent appearances at weekdays and weekends because of different travel purposes. ", "caption_bbox": [428, 290, 729, 349]}, {"image_id": 7, "file_name": "657_07.png", "page": 8, "dpi": 300, "bbox": [95, 427, 398, 690], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: We visualize the vehicle speed of consecutive Sun- days in Hsuehshan tunnel. The visual patterns show that speed was slow in the tunnel. One possible reason for this phenomenon was defensive driving style in the tunnel. An- other reason could be vehicles entering the freeway from the interchange highlighted using a blue arrow. ", "caption_bbox": [96, 703, 397, 792]}, {"image_id": 8, "file_name": "657_08.png", "page": 8, "dpi": 300, "bbox": [96, 112, 730, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (Left) The path of a hurricane in June. (Middle) The traffic flows heading north. Because the class and work suspen- sion were not issued by the government at north at June 20, the traffic flows at north remain the same compared to those at weekdays, as highlighted by blue rectangles. However, most citizens in the middle and southern parts of Taiwan stayed at home during the hurricane strike so that traffic flows became much lighter, as highlighted in white rectangles. (Right) We retrieved traffic patterns similar to that of Jun 20 and found that hurricanes struck the island at all these dates. ", "caption_bbox": [96, 316, 729, 390]}], "658": [{"image_id": 0, "file_name": "658_00.png", "page": 3, "dpi": 300, "bbox": [412, 112, 731, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Particle advection techniques. (a) Stationary vec- tor field. The red streamline is computed starting from the blue seed point. (b) Time-varying vector field. The three black lines correspond to pathlines starting at different time steps. The red streakline is the locus of a stream of particles injected into the vector field. ", "caption_bbox": [428, 306, 729, 395]}, {"image_id": 1, "file_name": "658_01.png", "page": 5, "dpi": 300, "bbox": [95, 286, 399, 484], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The closest path than paths T3 and T4 . model chooses the k-closest Therefore, the weights w1 paths for every trip. This ex- and w2 are greater than the ample uses k = 4.              weights w3 and w4 . Also ", "caption_bbox": [96, 484, 397, 543]}, {"image_id": 2, "file_name": "658_02.png", "page": 5, "dpi": 300, "bbox": [412, 112, 731, 255], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Histogram of the KL divergence measures ob- tained when comparing the closest path and shortest path models with the distributions computed using data from EZ pass tag readers. Note that values of Dclosest from more time periods are closer to zero than the values of Dshortest indi- cating that the closest path model better approximates the observed traffic speeds. ", "caption_bbox": [428, 265, 729, 369]}, {"image_id": 3, "file_name": "658_03.png", "page": 6, "dpi": 300, "bbox": [412, 112, 729, 344], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The traffic function of Manhattan is displayed us- ing glyphs (a). Given the multiple directions a particle can take at a node of the graph, we propose different direction choices for computing flow lines depending on the aspect of the traffic the user wants to visualize (b,c,d,e). ", "caption_bbox": [428, 344, 729, 418]}, {"image_id": 4, "file_name": "658_04.png", "page": 7, "dpi": 300, "bbox": [412, 112, 731, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Pathlines at different time periods showing the most probable flow of taxis. Note that the pathlines tend to cross into Upper Manhattan only in the latter part of the day. The direction is color encoded from yellow to red. ", "caption_bbox": [428, 269, 729, 328]}, {"image_id": 5, "file_name": "658_05.png", "page": 7, "dpi": 300, "bbox": [95, 112, 415, 243], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Orbits found at different times of the day. Note that a few orbits like the ones around a school and the parking lot occur only at certain times, while the ones near Holland tunnel and Washington Square occur more frequently. ", "caption_bbox": [96, 245, 397, 304]}, {"image_id": 6, "file_name": "658_06.png", "page": 8, "dpi": 300, "bbox": [412, 112, 730, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Short 1 minute pathlines are used to identify di- rection of high speed traffic flow. Red pathlines indicate northward direction, while blue pathlines indicate south- ward movement. Note that the direction of high speed is up- ward during the day, and reverses at 5 pm. ", "caption_bbox": [428, 295, 729, 369]}, {"image_id": 7, "file_name": "658_07.png", "page": 8, "dpi": 300, "bbox": [95, 112, 415, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Traffic trends in Manhattan. This sequence of maps shows the visualization of the mean speed (in MPH) of traffic on all Fridays from 8 am until midnight. Note the change in traffic trends during different times of the day. ", "caption_bbox": [96, 363, 397, 422]}, {"image_id": 8, "file_name": "658_08.png", "page": 9, "dpi": 300, "bbox": [98, 112, 415, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Simulating traffic flow during road blocks. The streamlines are computed from the set of blue seed points. The direction of highest speed was used for computing the path taken. The changes in the streamlines indicates that the speeds of the roads in the blockage region initially increases during the unblocking period, before stabilizing to normal flow. The direction is color encoded from yellow to red. ", "caption_bbox": [96, 361, 397, 465]}], "659": [{"image_id": 0, "file_name": "659_00.png", "page": 3, "dpi": 300, "bbox": [95, 112, 415, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Notation of our illumination model. Left: surface reflection and volume illumination of particle i. Right: am- bient occlusion and illumination at first hit x 0 . ", "caption_bbox": [96, 237, 397, 280]}, {"image_id": 1, "file_name": "659_01.png", "page": 4, "dpi": 300, "bbox": [95, 112, 731, 245], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The different parts of our illumination model.", "caption_bbox": [271, 254, 551, 267]}, {"image_id": 2, "file_name": "659_02.png", "page": 5, "dpi": 300, "bbox": [95, 112, 415, 231], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Different settings of our volumetric model. a) nai- ve opacity, b) with a constant density function, c) L22 norm density function, d) constant density with 10% border ", "caption_bbox": [96, 239, 397, 283]}, {"image_id": 3, "file_name": "659_03.png", "page": 7, "dpi": 300, "bbox": [412, 112, 731, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison of ambient occlusion methods with a close-up of a small portion of dataset D5. Left: our method, center: ambient occlusion from [GKSE12], right: ambient occlusion from QuteMol [TCM06]. ", "caption_bbox": [428, 275, 729, 334]}, {"image_id": 4, "file_name": "659_04.png", "page": 8, "dpi": 300, "bbox": [96, 112, 725, 431], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Performance of different steps in milliseconds. upload is the vertex data particle upload, sort. is the particle sorting step, voxel. is the voxelization step, render is the whole fragment shader for the final image generation, and other denotes additional overhead. The right sub-table details parts of the render stage: basic is the fundamental particle ray casting, transp. is the evaluation of our volume model, and amb.occl. is the computation of the ambient occlusion values. ", "caption_bbox": [96, 465, 729, 524]}], "660": [{"image_id": 0, "file_name": "660_00.png", "page": 1, "dpi": 300, "bbox": [96, 630, 731, 843], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Brake Lever dataset. Tensor field lines (a) are continuous but not quantitative. Superquadric glyphs (b) are quan- titative but discrete. Von Mises stress rendering (c) is continuous but not showing orientation. Our virtual photoelasticity (d), which corresponds to experimental stress analysis with polariscopes, is continuous, quantitative, and conveys orientation. ", "caption_bbox": [96, 579, 729, 623]}, {"image_id": 1, "file_name": "660_01.png", "page": 3, "dpi": 300, "bbox": [102, 111, 731, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Circular polariscope, from right to left. Incident light (gray) is linearly polarized (green), and transformed to circular polarization (yellow) while passing a \u03bb/4-plate (magenta, fast direction by red arrow, slow by blue). It then enters the material under investigation (blue), which, in general, renders it elliptically polarized (orange). Subsequently, it passes another \u03bb/4- plate with opposite orientation, and from that, a single linear polarization is selected by the analyzer (red). This results in two waves with retardation \u0394, leading to the observed images due to interference. ", "caption_bbox": [96, 223, 729, 297]}, {"image_id": 2, "file_name": "660_02.png", "page": 6, "dpi": 300, "bbox": [96, 111, 415, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration of ray traversal. Raycasting in direc- tion from camera (a) to light source (e), but with reverse reflection/refraction, i.e., light direction is from (e) to (a). ", "caption_bbox": [96, 256, 397, 300]}, {"image_id": 3, "file_name": "660_03.png", "page": 7, "dpi": 300, "bbox": [95, 111, 731, 631], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Simple Model dataset. Polarizer orientation by blue arrows, analyzer orientation by red arrows. No refrac- tion/reflection (a)\u2013(d), refraction/reflection (e)\u2013(l), and monochromatic analysis (i)\u2013(l) at 575 nm. Plane polariscope analy- sis (a), (b), (e), (f), (i), (j), and circular polariscope analysis (c), (d), (g), (h), (k), (l), with open (i.e., parallel) analyzer (left respective images) and closed (i.e., perpendicular) analyzer (right respective images). ", "caption_bbox": [96, 634, 729, 693]}, {"image_id": 4, "file_name": "660_04.png", "page": 8, "dpi": 300, "bbox": [412, 111, 731, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Experimental circular polariscope result (a) from [FM49], and our virtual circular polariscope result (b) for a corresponding stress simulation denoted Simple Model. ", "caption_bbox": [428, 245, 729, 289]}, {"image_id": 5, "file_name": "660_05.png", "page": 8, "dpi": 300, "bbox": [95, 111, 415, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Two-Point Load dataset. (a) Circular photoelas- ticity raycasting without refraction. (b) Planar photoelastic- ity raycasting without refraction. (c) Planar photoelasticity raycasting with refraction (refractive index of 1.5). ", "caption_bbox": [96, 258, 397, 317]}, {"image_id": 6, "file_name": "660_06.png", "page": 9, "dpi": 300, "bbox": [103, 111, 731, 520], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Brake Lever dataset for varying stress-optic coefficient C and refractive index n, circular and plane polariscope.", "caption_bbox": [104, 525, 717, 538]}, {"image_id": 7, "file_name": "660_07.png", "page": 9, "dpi": 300, "bbox": [113, 583, 396, 727], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Selected time steps of Femur dataset, visualized with circular polariscope, C = 37, refractive index n = 1.3. ", "caption_bbox": [96, 733, 397, 762]}], "661": [{"image_id": 0, "file_name": "661_00.png", "page": 3, "dpi": 300, "bbox": [114, 112, 731, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A denoising example of the L0 volume gradient minimization method. (a) The noisy volume, corrupted by synthetic noise. (b) The smoothed volume after our method. (c) The profile plot is a 1D scanline plot of the scalar values taken from a slice as indicated by the white line in the 2D images. The black curve is a plot of the noisy scalar values, while the red one is the plot of the smoothed scalar values. Our method smoothes noise while preserving the most significant sharp edges. ", "caption_bbox": [96, 305, 729, 364]}, {"image_id": 1, "file_name": "661_01.png", "page": 4, "dpi": 300, "bbox": [96, 112, 725, 323], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The impact of the smoothing parameter \u03bb of the L0 volume gradient minimization method. The slices from the corresponding volumes are displayed at the top row. (a) The original sphere volume with severe artificial noise. (b-g) The smoothed results by the L0 volume gradient minimization method with the increasing values of \u03bb . Our method obtains the best smoothing result in (d) when \u03bb = 0.002, since a small \u03bb dose not filter noise sufficiently and large \u03bb destroys the salient spheres. ", "caption_bbox": [96, 329, 729, 393]}, {"image_id": 2, "file_name": "661_02.png", "page": 5, "dpi": 300, "bbox": [109, 112, 415, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Number of voxels with a non-zero gradient on the sphere volume in Figure 2 under different \u03bb values. With the increasing of the parameter, more voxels with a non-zero gradient are smoothed. The red circles on the curve indicate the corresponding parameters in Figure 2(b-f), respectively. ", "caption_bbox": [96, 285, 397, 359]}, {"image_id": 3, "file_name": "661_03.png", "page": 6, "dpi": 300, "bbox": [96, 112, 415, 224], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Boundary smoothing using the blurring- sharpening strategy. (a) To mimic the effect of the band- limited property of capturing instruments, a Gaussian filter is applied to the original 1D sharp signal and this obtains the purple curve with a blurred edge. The red curve is the smoothed result of the L0 gradient minimization. (b) The captured signal (the purple curve) is further destroyed by noise. The red curve is the recovered signal by the blurring- sharpening strategy. ", "caption_bbox": [96, 237, 397, 372]}, {"image_id": 4, "file_name": "661_04.png", "page": 6, "dpi": 300, "bbox": [412, 112, 726, 355], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The impact of the Gaussian filtering in the blurring-sharpening strategy. (a) The original sphere vol- ume with severe noise. (b) The under-smoothed result of the Gaussian filter with \u03c3 = 0.5. (c) The over-smoothed result of the Gaussian filter with \u03c3 = 2.0. (d-f) are smoothed results of (a-c) using the L0 volume gradient minimization. ", "caption_bbox": [428, 367, 729, 458]}, {"image_id": 5, "file_name": "661_05.png", "page": 7, "dpi": 300, "bbox": [106, 112, 731, 577], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The denoising capability of the blurring-sharpening strategy based on the tooth volume. (a-d) are obtained by adding one particular type of noise, as indicated by the corresponding captions. SNR (in dB) of the noisy and the smoothed volumes are shown in each figure. ", "caption_bbox": [96, 590, 729, 634]}, {"image_id": 6, "file_name": "661_06.png", "page": 8, "dpi": 300, "bbox": [110, 402, 721, 597], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison of three smoothing methods on a 3D CT flower volume. (a) The original volume data. (b) The smoothed volume with the bilateral filter, \u03c3s = 5, \u03c3r = 120. (c) The smoothed volume with edge aware anisotropic diffusion, \u03c3 = 10 and 15 iterations. (d) Our L0 smoothing result, \u03bb = 0.005. Compared with other methods, our method suppresses low gradient amplitude block-like noises, while retaining the salient boundaries. (e) Close-ups (as shown the yellow box in (a)) of pistils and stamens in the results. (f) Close-ups (as shown the red box in (a)) of the results with increasing smoothing strength gradually from top to bottom. The methods from left to right are the bilateral filter, edge aware anisotropic diffusion and the L0 volume gradient minimization method. ", "caption_bbox": [96, 610, 729, 715]}, {"image_id": 7, "file_name": "661_07.png", "page": 8, "dpi": 300, "bbox": [96, 112, 729, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparison of three smoothing methods on a 3D MRI tomato volume. (a) The original volume data. (b) The smoothed volume with the bilateral filter, \u03c3s = 2, \u03c3r = 40. (c) The smoothed volume with edge aware anisotropic diffusion, \u03c3 = 2 and 10 iterations. (d) Our smoothed result, \u03bb = 0.00023. Our method suppresses low gradient amplitude details and globally retains salient edges, clearly shown in the boundaries of seeds and placenta. ", "caption_bbox": [96, 322, 729, 381]}, {"image_id": 8, "file_name": "661_08.png", "page": 9, "dpi": 300, "bbox": [105, 112, 415, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Performance evaluation of different smoothing methods: Bilateral filter (BLF), edge aware anisotropic d- iffusion (AD), and our method on Tomato volume (Figure 7) and Flower volume (Figure 8). The lower value of MSE is better, while the higher value of SSIM and QILV is better. ", "caption_bbox": [96, 854, 397, 928]}], "662": [{"image_id": 0, "file_name": "662_00.png", "page": 4, "dpi": 300, "bbox": [96, 112, 725, 372], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Framework of the proposed method.", "caption_bbox": [293, 385, 527, 398]}, {"image_id": 1, "file_name": "662_01.png", "page": 5, "dpi": 300, "bbox": [97, 738, 397, 850], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Refine rule-evaluation result by connected compo- nent analysis. (a) A slice taken from the Visible Male Head dataset; (b) Original rule-evaluation result on the slice; (c) result after thresholding; (d) result after 2-D connected com- ponent analysis; (e) result after 3-D connected component analysis. ", "caption_bbox": [95, 864, 398, 953]}, {"image_id": 2, "file_name": "662_02.png", "page": 6, "dpi": 300, "bbox": [413, 112, 726, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visualization of the Visible Male Head dataset.", "caption_bbox": [434, 398, 721, 411]}, {"image_id": 3, "file_name": "662_03.png", "page": 6, "dpi": 300, "bbox": [427, 606, 727, 801], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visualization of the Aneurysm dataset.", "caption_bbox": [455, 817, 700, 830]}, {"image_id": 4, "file_name": "662_04.png", "page": 7, "dpi": 300, "bbox": [427, 429, 726, 654], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visualization of the CT Head dataset. The rules used to enhance the visualization of the brain are those that are learned from the Visible Male Head dataset. ", "caption_bbox": [427, 675, 728, 718]}, {"image_id": 5, "file_name": "662_05.png", "page": 7, "dpi": 300, "bbox": [95, 201, 396, 453], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualization of the MRI Woman Head dataset.", "caption_bbox": [102, 477, 389, 490]}, {"image_id": 6, "file_name": "662_06.png", "page": 7, "dpi": 300, "bbox": [412, 112, 731, 370], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualization of the Brain Tumor dataset.", "caption_bbox": [448, 387, 707, 400]}, {"image_id": 7, "file_name": "662_07.png", "page": 8, "dpi": 300, "bbox": [433, 569, 730, 817], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The maximum fitness value of each generation v.s. number of generations plot for: (a) Visible Male Head dataset; (b) Aneurysm dataset; (c) MRI Woman Head dataset; (d) Brain Tumor dataset. ", "caption_bbox": [426, 829, 730, 888]}], "663": [{"image_id": 0, "file_name": "663_00.png", "page": 1, "dpi": 300, "bbox": [95, 563, 731, 807], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Different supervised classification techniques result in very different probabilistic transfer functions when applied to the same scribbles in the volumetric domain. We provide a comprehensive comparison and guidelines for use. ", "caption_bbox": [96, 527, 729, 555]}, {"image_id": 1, "file_name": "663_01.png", "page": 5, "dpi": 300, "bbox": [97, 112, 415, 228], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Increasing the minimum number of samples per leaf in random forests avoids visual discontinuities. ", "caption_bbox": [96, 234, 397, 262]}, {"image_id": 2, "file_name": "663_02.png", "page": 6, "dpi": 300, "bbox": [96, 112, 717, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Classification accuracy as a function of the number k of nearest neighbors (a); regularization parameter C (b) and bandwidth parameter \u03b3 (c) of a support vector machine; the number of hidden nodes in a single layer perceptron (d); and the number of trees (e) and features per node (f) in a random forest. ", "caption_bbox": [96, 444, 729, 487]}, {"image_id": 3, "file_name": "663_03.png", "page": 6, "dpi": 300, "bbox": [103, 510, 727, 649], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Time needed for training and classification as a function of the number k of nearest neighbors (a); the number of hidden nodes in a single layer perceptron (b); and the number of trees in a random forest (c). ", "caption_bbox": [96, 659, 729, 687]}, {"image_id": 4, "file_name": "663_04.png", "page": 7, "dpi": 300, "bbox": [427, 408, 731, 539], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Different rendering styles can be used to either ex- plore the uncertainty in a probabilistic classifier, or to gen- erate a clean picture of objects in the scene. ", "caption_bbox": [428, 551, 729, 594]}, {"image_id": 5, "file_name": "663_05.png", "page": 8, "dpi": 300, "bbox": [427, 372, 731, 517], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: On the brain, k Nearest Neighbors (a) and Ran- dom Forests (c) both present a good depiction of the white matter surface. The sharp creases in the SVM result (b) indi- cate that the outermost parts of the white matter are missing. ", "caption_bbox": [428, 523, 729, 582]}, {"image_id": 6, "file_name": "663_06.png", "page": 8, "dpi": 300, "bbox": [95, 112, 731, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Slice images (b)\u2013(d) illustrate the artifacts that result from imperfect training data (a) when using different classifiers. In the slices as well as the volume renderings (e)\u2013(g), SVM appears least robust. Smaller artifacts in the k Nearest Neighbors (e) are highlighted by blue arrows. ", "caption_bbox": [96, 293, 729, 336]}, {"image_id": 7, "file_name": "663_07.png", "page": 9, "dpi": 300, "bbox": [95, 112, 415, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Low-dose chest CT takes purely transfer function based visualization to its limit. In comparison to k-NN and SVM, random forests still provide the cleanest result. ", "caption_bbox": [96, 259, 397, 302]}], "664": [{"image_id": 0, "file_name": "664_00.png", "page": 1, "dpi": 300, "bbox": [127, 356, 699, 569], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Compressive Volume Rendering exploits image smoothness to recover images from a small number of rendered pixels. We present two non-adaptive methods that can achieve high quality recovery with as few as 20% of the pixels. ", "caption_bbox": [96, 581, 729, 609]}, {"image_id": 1, "file_name": "664_01.png", "page": 4, "dpi": 300, "bbox": [412, 112, 730, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Histogram of the absolute values of the DFT coef- ficients of the engine image (left) and its derivatives (right). The image and the derivatives were normalized to lie in the range [0, 1] before applying the FFT. ", "caption_bbox": [428, 288, 729, 347]}, {"image_id": 2, "file_name": "664_02.png", "page": 4, "dpi": 300, "bbox": [96, 112, 415, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Coherence results for different sensing matrices (N = 642 ). The numbers indicate the standard deviation of the Gaussian blurring filter in the Fourier domain, lower values indicate greater blurring. The other abbreviations are: ld - low discrepancy, ran - random, and par - partial Fourier. ", "caption_bbox": [96, 354, 397, 443]}, {"image_id": 3, "file_name": "664_03.png", "page": 6, "dpi": 300, "bbox": [412, 112, 690, 237], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Masks with 50% missing pixels; left: random, and right: LD via pixel shuffle. ", "caption_bbox": [428, 249, 729, 277]}, {"image_id": 4, "file_name": "664_04.png", "page": 6, "dpi": 300, "bbox": [444, 286, 713, 482], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Random vs. LD distributions.", "caption_bbox": [478, 497, 678, 510]}, {"image_id": 5, "file_name": "664_05.png", "page": 7, "dpi": 300, "bbox": [97, 112, 731, 581], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Recovery results for all methods with LD distribution (50% missing pixels). The grayscale images indicate the magnitude of the error computed in the CIELUV space; the error range range [0, 20] is linearly mapped to a grayscale colormap. ", "caption_bbox": [96, 593, 729, 622]}, {"image_id": 6, "file_name": "664_06.png", "page": 8, "dpi": 300, "bbox": [95, 384, 399, 499], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Rendering timing for different resolutions.", "caption_bbox": [117, 605, 375, 618]}, {"image_id": 7, "file_name": "664_07.png", "page": 8, "dpi": 300, "bbox": [448, 384, 710, 532], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Timing results for head data via different recovery methods (1200 \u00d7 1200 images). ", "caption_bbox": [428, 546, 729, 584]}, {"image_id": 8, "file_name": "664_08.png", "page": 8, "dpi": 300, "bbox": [96, 112, 699, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Recovery results for foot and aneurysm data via TV and SS                                                                Timing results                                             200 ", "caption_bbox": [238, 361, 611, 383]}, {"image_id": 9, "file_name": "664_09.png", "page": 9, "dpi": 300, "bbox": [135, 470, 359, 711], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Upscaling results via TV and SS", "caption_bbox": [136, 721, 356, 734]}, {"image_id": 10, "file_name": "664_10.png", "page": 9, "dpi": 300, "bbox": [127, 112, 731, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Performance summary of TV and SS for different types of images.", "caption_bbox": [225, 452, 599, 465]}], "665": [{"image_id": 0, "file_name": "665_00.png", "page": 1, "dpi": 300, "bbox": [95, 541, 730, 769], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: We propose a novel guided volume editing approach for improving the quality of segmented medical data (Jaccard coefficient in percents). (a) Two suggestions to rectify over-estimation defects, with an initial quality of 88%, (b) after applying the suggestions, 91%, (c) after applying four more suggestions, 92%. (d) Two suggestions to fix under-estimation defects, with an initial quality of 80%, (e) after applying the suggestions, 85%, (f) after applying six more suggestions, 94%. ", "caption_bbox": [95, 474, 728, 533]}, {"image_id": 1, "file_name": "665_01.png", "page": 2, "dpi": 300, "bbox": [412, 112, 731, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Our main contribution is the integration of the suggestion generation and the visual mapping into the work- flow of volume editing. ", "caption_bbox": [428, 321, 729, 364]}, {"image_id": 2, "file_name": "665_02.png", "page": 3, "dpi": 300, "bbox": [412, 112, 731, 399], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Two phantom datasets with common segmenta- tion defects: (a) object (dark gray), (b) segmentation (green) of the object from a) with OP , OL over-estimation defects, (c) object (dark gray), (d) segmentation (green) of the object from c) with UP ,UL under-estimation defects. ", "caption_bbox": [428, 410, 729, 484]}, {"image_id": 3, "file_name": "665_03.png", "page": 4, "dpi": 300, "bbox": [95, 112, 415, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Structure-aligned data collection using the skele- ton and the influence zones. The histogram H1 (pi ) collects data values in a whole influence zone IZ(pi ) (to identify OP defects). The histogram H2 (q, j) collects data values at a skeleton distance DS = j in an influence zone IZ(q) (to iden- tify OL defects). The histograms are normalized for illustra- tion purposes. The bin size is 4 HU. Colors differentiate the influence zones and the skeleton-distance iso-surfaces. ", "caption_bbox": [95, 313, 396, 433]}, {"image_id": 4, "file_name": "665_04.png", "page": 5, "dpi": 300, "bbox": [98, 112, 731, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Smart volume editing in the synthetic datasets of Figure 3: (a) the initial segmentation of object #1 with two defects, (b) skeleton view: the dissimilarity values \u03b41 (green to red transition for [0; 1]), the basins of the watershed transformation, and a level of the basins hierarchy, used in c), (c) the suggestion for the OP defect, (d) skeleton view: the dissimilarity values \u03b42 (green to red transition for [0; 1]), the basins of the watershed transformation, and a level of the basins hierarchy, used in e), (e-g) the suggestions for the OL defect, (h) the correct segmentation of object #1, (i) the initial segmentation of object #2 with two defects, (j) the suggestion for the UP defect, (k) the suggestion for the UL defect, (l) the correct segmentation of object #2. ", "caption_bbox": [95, 282, 728, 371]}, {"image_id": 5, "file_name": "665_05.png", "page": 6, "dpi": 300, "bbox": [95, 112, 724, 215], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) The dissimilarity values \u03b41 (green to red transition for [0; 1]), (b) A coarse level of the basins hierarchy, (c) A finer level of the basins hierarchy with the basin, which corresponds to the defect. The user interaction with our proposed technique: (d) the initial coarse level of detail, (e) the user selects correction scenario in the coarse level, (f) the user explores the finer level of detail and selects the finer correction scenario, which fixes the defect, (g) after applying the selected correction scenario, (h) example of defect, which is not properly captured by the skeleton. Each correction scenario is depicted by a single glyph. ", "caption_bbox": [95, 225, 728, 299]}, {"image_id": 6, "file_name": "665_06.png", "page": 7, "dpi": 300, "bbox": [412, 112, 731, 440], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Guided volume editing in industrial XCT data: (a) the dataset, (b) the initial segmentation of the two metal rods, (c-f) the first four of seven correction operations, (g) the correct segmentation of the metal rods, (h) the initial segmentation of the plastic box, (i) the correct segmentation of the box, after only nine operations. ", "caption_bbox": [428, 450, 729, 539]}, {"image_id": 7, "file_name": "665_07.png", "page": 7, "dpi": 300, "bbox": [95, 112, 415, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Guided volume editing in CT-A data: (a) the au- tomatic vessel segmentation exhibiting defects (vessels and bones are touching), (b-e) the first four correction opera- tions, (f) the corrected vessel segmentation after only twelve operations, (g) correctly detected vascular occlusion. ", "caption_bbox": [95, 376, 396, 450]}, {"image_id": 8, "file_name": "665_08.png", "page": 8, "dpi": 300, "bbox": [95, 112, 415, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Guided volume editing in electron microscopy data: (a) the neuron, segmented automatically, (b-d) three correction steps, (e) the segmentation of the neuron, cor- rected without slice editing, (f) the segmentation of the neu- ron, created manually by the domain expert. ", "caption_bbox": [95, 324, 396, 398]}, {"image_id": 9, "file_name": "665_09.png", "page": 9, "dpi": 300, "bbox": [95, 112, 731, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: (a) Evaluation of our technique. (b) Comparative evaluation. Grades for a) and b) range from 1 (worst) to 5 (best).", "caption_bbox": [95, 230, 728, 243]}], "666": [], "667": [{"image_id": 0, "file_name": "667_00.png", "page": 1, "dpi": 300, "bbox": [156, 266, 666, 499], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Perfopticon visualizing a recorded query execution that estimates species abundance in an oceanography dataset. The left panel displays the optimized query execution plan. The right panel includes (top) a divided bar chart showing the runtime contribution of individual query operators, and (bottom) a focus+context view of detailed per-worker execution traces. ", "caption_bbox": [95, 508, 728, 552]}, {"image_id": 1, "file_name": "667_01.png", "page": 3, "dpi": 300, "bbox": [412, 113, 731, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of the Myria architecture. A query is sent through the front-end to the master; the optimizer translates it to a physical query execution plan. The query execution plan consists of parts that can be executed locally on each machine (fragments) with communication steps in between. ", "caption_bbox": [427, 380, 728, 454]}, {"image_id": 2, "file_name": "667_02.png", "page": 4, "dpi": 300, "bbox": [412, 113, 731, 397], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Query plan view for a query with a two-way join and an aggregate. The user collapsed Fragment 0 and selected Fragment 1 to view details in the right side view. The edges going into Fragment 1 are wider than the outgoing edge, indicating that the number of tuples is decreasing. ", "caption_bbox": [427, 399, 729, 473]}, {"image_id": 3, "file_name": "667_03.png", "page": 5, "dpi": 300, "bbox": [412, 113, 731, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The fraction of workers executing operators in a fragment (top), and the same data summarized as the fraction of workers executing any operator in the fragment (bottom). ", "caption_bbox": [427, 277, 728, 321]}, {"image_id": 4, "file_name": "667_04.png", "page": 5, "dpi": 300, "bbox": [100, 113, 415, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Overview showing small multiples of utilization over time, grouped by fragment. Utilization is measured as the fraction of workers executing each fragment. The long tail in the utilization chart for Fragment 1 shows that a few workers take significantly longer, indicating skew. ", "caption_bbox": [95, 325, 397, 399]}, {"image_id": 5, "file_name": "667_05.png", "page": 6, "dpi": 300, "bbox": [95, 113, 413, 460], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Communication matrix for a join query on a Twitter follower graph, running over a 72-worker cluster. Source workers are on the y-axis and target workers on the x-axis. The matrix shows that all source workers send the same number of tuples, but that the amount of data sent to target workers is skewed due to large differences in follower count among Twitter users. ", "caption_bbox": [95, 468, 399, 572]}, {"image_id": 6, "file_name": "667_06.png", "page": 7, "dpi": 300, "bbox": [96, 215, 398, 316], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: An early design for execution traces. Each operator occupies a separate lane. Colors indicate states: \u2018active\u2019 ( ), ", "caption_bbox": [95, 324, 397, 352]}, {"image_id": 7, "file_name": "667_07.png", "page": 8, "dpi": 300, "bbox": [412, 113, 727, 312], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Communication for a redundant shuffle before (left) and after (right) implementing deterministic shuffling. ", "caption_bbox": [427, 319, 728, 347]}], "668": [{"image_id": 0, "file_name": "668_00.png", "page": 2, "dpi": 300, "bbox": [95, 112, 731, 502], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Our visual tool for assessing cases of plagiarism displays the types of plagiarism found on the bottom (c), a list of difflines (b) (glyph-based visualization of the finding spots (d)) in the center, and an overview on the left (a). Copy-and- pasted passages are marked in red (e). A finding spot can be opened for a side-by-side comparison of suspicious and original text fragments. The overview reveals the distribution of finding spots across the document (g) and their relationship to the sources (h). The overview supports brushing and selection to define a subset of finding spots to be displayed in the diffline view. ", "caption_bbox": [96, 512, 729, 586]}, {"image_id": 1, "file_name": "668_01.png", "page": 5, "dpi": 300, "bbox": [412, 112, 732, 376], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The visual representation of a finding spot shows the essential information on the top left (a) (position and length of the suspicious fragment where length is indicated as a thin horizontal line directly below (b)), plagiarism cate- gory (also shown on the left as a vertical line with the color of the category), and the name of the potential original doc- ument. The diffline visualization is shown at the top (c). The finding spot is opened and the suspicious text fragment (d), as well as the potential original (e), are shown directly be- low. The textual view is based upon a particular wrapping intended for easier recognition of the differences and com- monalities of both texts. Hovering above a glyph or a text element will highlight both (f) to simplify the mental match. ", "caption_bbox": [428, 386, 729, 582]}, {"image_id": 2, "file_name": "668_02.png", "page": 6, "dpi": 300, "bbox": [95, 515, 402, 601], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The classic approach for text comparison uses striking out or underlining to reveal removed and inserted words, respectively. The sample text was taken and adapted from [Mis14c]. ", "caption_bbox": [96, 611, 397, 670]}, {"image_id": 3, "file_name": "668_03.png", "page": 6, "dpi": 300, "bbox": [412, 112, 735, 382], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The diff blending morphs between the two texts by adjusting the transparency values of the respective markups of the changed text. (a) The focus is on the source. (b) The focus is on the suspicious text. Although gaps are created by focusing on the source (a) or on the finding spot (b), the text can be read surprisingly well. Moving the slider from one stop to the other creates an animation-like behavior that draws attention to the changes, especially when using our alternative color scheme. ", "caption_bbox": [428, 395, 729, 530]}, {"image_id": 4, "file_name": "668_04.png", "page": 8, "dpi": 300, "bbox": [95, 112, 726, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The various difflines composed of different glyph alphabets. All of them represent the same information. The top area represents the original document. The lower part represents the suspicious fragment. ", "caption_bbox": [96, 288, 729, 316]}, {"image_id": 5, "file_name": "668_05.png", "page": 9, "dpi": 300, "bbox": [103, 112, 731, 418], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Different methods of plagiarism. Each case differs in length, number of finding spots and sources, categories, and distribution of finding spots. (a) The very few crossings indicate that this suspect worked in a linear way, integrating source by source after another. (b) Only few sources suffice if they can be exploited extensively. (c) This short document employed surprisingly many sources. (d) The suspicious document utilizes a main source across all pages (selected), which indicates that the overall structure of the original work was employed and filled in with other sources (not selected). ", "caption_bbox": [96, 430, 729, 504]}], "669": [{"image_id": 0, "file_name": "669_00.png", "page": 2, "dpi": 300, "bbox": [413, 112, 727, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Techniques for visualizing overlapping proximal events. (a) Listing or adjoining events in parallel vertically (b) Partially overlaying horizontal bars (c) Fully overlay- ing semi-transparent horizontal bars (d) Partially overlay- ing vertical bars ", "caption_bbox": [428, 279, 729, 353]}, {"image_id": 1, "file_name": "669_01.png", "page": 3, "dpi": 300, "bbox": [412, 112, 731, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: TipoVis Visualization Technique. Events from the two behaviors (variables) have different colors and bar heights. ", "caption_bbox": [428, 244, 729, 287]}, {"image_id": 2, "file_name": "669_02.png", "page": 4, "dpi": 300, "bbox": [95, 112, 415, 249], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Highlight and left-align overlapping pattern. (a) Normal view (b) Highlight overlapping pattern: colors of the bars fade, and the overlapping pattern highlighted in red. (c) Left-align overlapping pattern: the highlighted red overlap- ping bars moved to the left. ", "caption_bbox": [96, 262, 397, 336]}, {"image_id": 3, "file_name": "669_03.png", "page": 4, "dpi": 300, "bbox": [413, 112, 728, 228], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Extending the overlapping time window by the or- ange variable to find overlapping patterns. (a) Normal view with highlighted overlapping patterns (b) Redefine overlap- ping time window by extending events of the orange variable in the end to find new overlapping patterns. The green bars are the extended part of the overlapping time window. We can see that a new overlapping pattern emerged and the ex- isting overlapping pattern, shown as the red bar in (a), is extended in (b). ", "caption_bbox": [428, 241, 729, 376]}, {"image_id": 4, "file_name": "669_04.png", "page": 5, "dpi": 300, "bbox": [99, 112, 414, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Compare event sequences. (a) Original view (b) Event sequences grouped by age (c) Event sequences sorted by some criterion ", "caption_bbox": [96, 239, 397, 282]}, {"image_id": 5, "file_name": "669_05.png", "page": 6, "dpi": 300, "bbox": [95, 112, 731, 493], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Finding the relationship between Child Non-conventional Use (of toy) and the Mother Conventional Use (of toy) in extended overlapping time windows. (a) Highlighted overlapping pattern (b) Left-aligned overlapping pattern (c) Extended overlapping time window to find Mother Conventional Use (of toy) after Child Non-conventional Use (of toy) ", "caption_bbox": [96, 507, 729, 550]}, {"image_id": 6, "file_name": "669_06.png", "page": 7, "dpi": 300, "bbox": [96, 112, 414, 434], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Examining the overlap between child taking a toy and mother holding it out. Sessions are grouped and sorted by age. Older children (b) seem to take the toy sooner than younger children (a). ", "caption_bbox": [96, 446, 397, 505]}, {"image_id": 7, "file_name": "669_07.png", "page": 8, "dpi": 300, "bbox": [413, 112, 731, 512], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Children who failed a parent-reported assessment (highlighted yellow) do not seem to form a similar amount of gaze shift patterns. Notice the gaze shift distribution of high- lighted sessions along the y-axis that indicates this behav- ioral pattern did not separate this subgroup of children from the rest of the group. (a) Selected behaviors (b) Highlighted overlap (c) Extended overlapping time window by about 0.5 seconds to find gaze shift from object to examiner\u2019s face (d) Sessions sorted with data in entire event sequence (e) Ses- sions ungrouped (f) Sorted by overlap frequency (red) (g) Five gaze shift occasions (red) ", "caption_bbox": [428, 523, 729, 688]}, {"image_id": 8, "file_name": "669_08.png", "page": 9, "dpi": 300, "bbox": [97, 112, 414, 513], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Sessions with children who did not fail the parent- reported assessments but showed similar atypicalities over multiple behavioral patterns when compared to the rest of the group. See the yellow-highlighted sessions mostly clus- tering at the bottom of the session lists. ", "caption_bbox": [96, 526, 397, 600]}], "670": [{"image_id": 0, "file_name": "670_00.png", "page": 4, "dpi": 300, "bbox": [102, 248, 391, 396], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: System overview. At run-time, users navigate inside the 3D scene, while adaptively receiving unobtrusive guidance towards interesting viewpoints and history- and location-dependent sugges- tions on important information, which is adaptively presented using 2D overlays displayed over the 3D scene. ", "caption_bbox": [95, 396, 398, 463]}, {"image_id": 1, "file_name": "670_01.png", "page": 5, "dpi": 300, "bbox": [434, 649, 726, 746], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: State Machine. State machine of the recommendation system. ", "caption_bbox": [427, 754, 728, 780]}, {"image_id": 2, "file_name": "670_02.png", "page": 5, "dpi": 300, "bbox": [428, 316, 729, 431], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overlaid information. Left: Drawing showing a possible reconstruction of the missing parts of the object; Right: Textual information is presented without cluttering the region of interest. ", "caption_bbox": [427, 431, 728, 470]}, {"image_id": 3, "file_name": "670_03.png", "page": 7, "dpi": 300, "bbox": [102, 112, 415, 397], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Suggestions and overlays. Top: Suggestions are presented in a small inset, using animations to relate them to the spatial context. These suggestions appear only when the attraction forces do not drive the user close enough to the current view. Bottom: when moving close to the currently selected view or accepting a suggestion, annotations are overlaid to 3D view. ", "caption_bbox": [94, 398, 397, 479]}], "671": [{"image_id": 0, "file_name": "671_00.png", "page": 1, "dpi": 300, "bbox": [412, 411, 710, 741], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Piling as hybrid between small multiples and ag- gregation + flipbook. ", "caption_bbox": [425, 745, 708, 776]}, {"image_id": 1, "file_name": "671_01.png", "page": 2, "dpi": 300, "bbox": [112, 135, 389, 224], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Fuzzy states in brain activity. [RHVA08]", "caption_bbox": [132, 231, 375, 248]}, {"image_id": 2, "file_name": "671_02.png", "page": 4, "dpi": 300, "bbox": [115, 140, 707, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Eight piles indicating topological states in brain connectivity. The piles have been created by our temporal clustering heuristic. Users can adapt the piling slider (right) to define the number of piles they want to obtain. ", "caption_bbox": [112, 246, 708, 277]}, {"image_id": 3, "file_name": "671_03.png", "page": 4, "dpi": 300, "bbox": [112, 288, 398, 530], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: MultiPiles user interface: a) Main menu, b) Piling slider, c) Timeline, d) Piles plot showing adjacency matrices. ", "caption_bbox": [112, 537, 395, 568]}, {"image_id": 4, "file_name": "671_04.png", "page": 5, "dpi": 300, "bbox": [439, 136, 696, 323], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Hierarchically aggregating matrices into piles. Each horizontal layers show the piles and matrices shown at the same moment. Moving the piling up results in fewer piles, moving the slider down, results in more piles/matrices. ", "caption_bbox": [425, 329, 708, 388]}, {"image_id": 5, "file_name": "671_05.png", "page": 5, "dpi": 300, "bbox": [112, 135, 398, 474], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Timeline with different automatic pilings based on the similarity between matrices. White vertical lines sepa- rate piles. ", "caption_bbox": [112, 482, 395, 527]}, {"image_id": 6, "file_name": "671_06.png", "page": 5, "dpi": 300, "bbox": [112, 550, 397, 589], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Node degree encoding on the timeline.", "caption_bbox": [139, 595, 369, 612]}, {"image_id": 7, "file_name": "671_07.png", "page": 6, "dpi": 300, "bbox": [119, 471, 391, 565], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Examples of visualizing aggregated information in cover matrices, for the same pile. (a) Mean value, (b) Trend (red=increase, blue=decrease), (c) variation, (d) bar charts. ", "caption_bbox": [112, 574, 395, 619]}, {"image_id": 8, "file_name": "671_08.png", "page": 6, "dpi": 300, "bbox": [115, 141, 389, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Flip through pile by hovering matrix previews above the cover matrix. From lef to right: cover matrix show- ing mean values, hover matrices 59, 60, and 61. ", "caption_bbox": [112, 231, 395, 276]}, {"image_id": 9, "file_name": "671_09.png", "page": 7, "dpi": 300, "bbox": [119, 134, 708, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Operations on piles including formation, exploration, aggregation, filtering.", "caption_bbox": [204, 375, 616, 392]}, {"image_id": 10, "file_name": "671_10.png", "page": 7, "dpi": 300, "bbox": [112, 412, 398, 610], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Hovering over a node on the left side of the time- line shows only this node\u2019s connections (large node label). Top and bottom timelines show two different nodes exhibit- ing (a) asynchronous, (b) inverse or (c) synchronous activity. ", "caption_bbox": [112, 619, 395, 678]}, {"image_id": 11, "file_name": "671_11.png", "page": 8, "dpi": 300, "bbox": [116, 366, 392, 457], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Local ordering in pile 4 and 8 from Figure 3. (a) global ordering for pile 4, (b) optimal (local) ordering for pile 4, (c) optimal (local) ordering for pile 8, and (d) optimal ordering from pile 4, applied to pile 8. ", "caption_bbox": [112, 466, 395, 525]}, {"image_id": 12, "file_name": "671_12.png", "page": 8, "dpi": 300, "bbox": [114, 135, 391, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Zooming into the matrices, showing only 8 re- gions and their connections. Cover matrices show standard deviation a) and alternating trends in red and blue b). ", "caption_bbox": [112, 305, 395, 350]}, {"image_id": 13, "file_name": "671_13.png", "page": 9, "dpi": 300, "bbox": [427, 134, 713, 677], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: 2 Representative scans from each group: patients (a) and controls (b). We observe the occurence of the black framed pattern across individuals. ", "caption_bbox": [425, 686, 708, 731]}], "672": [{"image_id": 0, "file_name": "672_00.png", "page": 2, "dpi": 300, "bbox": [95, 112, 415, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A cell lineage captures how (a) a progenitor cell proliferates into (b) a progeny, or population of offspring. It describes key cellular events such as (c) cell division and (d) cell death. (e) Additional data are often associated with cells. (f) Every level corresponds to a generation of cells and (g) non-death leaves correspond to the end of an experiment. ", "caption_bbox": [96, 282, 397, 371]}, {"image_id": 1, "file_name": "672_01.png", "page": 4, "dpi": 300, "bbox": [95, 112, 415, 352], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Grouping by metadata values. Lineages A, B, and C are grouped according to the different values they take for metadata fields M1, M2, and M3. (b) Spatial summaries of groups of lineages. The field of view is divided into dis- crete regions (3 \u00d7 3 in this example), and the average num- ber of events per region is visualised as a heat map. (c) Tem- poral summaries of groups of lineages. The average number of events per generation is visualised as a bar chart. ", "caption_bbox": [96, 363, 397, 483]}, {"image_id": 2, "file_name": "672_02.png", "page": 5, "dpi": 300, "bbox": [98, 112, 731, 432], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) Design alternatives for spatial summaries of grouped lineages. (a.1) The smallest convex polygon containing all key events gives no indication of different levels of activity. (a.2) Division into rectangular sub-regions with the average number of events shown as a heatmap. (a.3) For more precise analysis, the average number of events is redundantly encoded with the height of a bar in each region and standard deviation is shown with vertical error bars. The average number of cell deaths, an event type of great interest, is shown with the height of red bars. (b) Alternatives for temporal summaries of grouped lineages. (b.1) A bar chart where for every generation, the average number of key events and the standard deviation are shown. Cell deaths are in red. (b.2) To allow comparison of per-generation behaviour to an ideal scenario, the number of cell divisions for a lineage where every cell divides into two daughter cells, is shown in the background. (c) An alternative for visualising selected lineages as a scrolling list (compare to Figure 4(d)). The area of intersection of their \u201cfootprints\u201d with a user-specified lineage is computed and they are sorted in descending order of this area (dark grey). (d) Alternatives for visualising cell lineage detail. (d.1) Lineage laid out by elapsed time. (d.2) To emphasise the presence or absence of symmetry, a lineage can be laid out as it would be for a complete binary tree, but screen space is used very inefficiently. A more suitable approach is (d.3.1) to position the subtree with the smallest total inter mitotic time over all its descendants nearer the top at every branching point, and (d.3.2) centre parent nodes between direct child nodes and not between all descendants. (d.4) To highlight synchrony, the layout can be interactively changed to align nodes per generation. Average inter mitotic time \u00b1 standard deviation are shown as vertical lines behind every generation. When multiple lineages are displayed, they share a temporal timescale on the x-axis. ", "caption_bbox": [96, 443, 729, 684]}, {"image_id": 3, "file_name": "672_03.png", "page": 7, "dpi": 300, "bbox": [98, 112, 731, 766], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Cell lineage visualisation. (a) For every selected metadata field, a group is created for each unique value it can take. Every lineage is allocated to one group for each field, corresponding to the value that it takes for that field (see Figure 2(a)). (b) Groups are shown in a faceted display where every group is visualised as an icon that summarises the spatial and temporal behaviour of its member lineages. Users specify scenarios of interest by selecting groups that correspond to different metadata values. (c) Deselected groups can be filtered out. (d) Individual lineages contained in selected groups are sorted by a similarity measure and displayed in a pagination fashion, using the same spatiotemporal icons. (e) Users pick individual lineages to view their detailed structure with the option of mapping associated data onto the visualisation. (f) A more detailed spatial representation is also provided. (g) Spatiotemporal summary of osteocarcoma cell lineages under control conditions (untreated) versus treatment with the anticancer drug topotecan (10\u00b5M). Untreated lineages exhibit more activity (darker green, taller bars) while cell death (red) is more prominent in treated lineages (compared to other behaviour). (h)\u2013(i) Detail of osteocarcoma cell lineages (cellular events are colour-coded). (h) Under the control condition, there is a great degree of cell proliferation with few cell deaths (red). However, (h.1) polyploid events (light blue) and (h.2) refusion events (green) do occur. (i) Under treatment, cell death is prominent and three behaviour patterns occur: (i.1) primary cytotoxicity, (i.2) symmetric cytotoxicity, and (i.3) asymmetric cytotoxicity. Importantly, the latter is a \u201cstrategy\u201d for subsets of tumour cells to escape drug action. ", "caption_bbox": [96, 777, 729, 988]}], "673": [{"image_id": 0, "file_name": "673_00.png", "page": 4, "dpi": 300, "bbox": [85, 785, 407, 989], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visualizations used for the identi\ufb01cation and ex- ploration of distinct intra-tumor regions with similar tissue characteristics (T1). ", "caption_bbox": [96, 991, 397, 1035]}, {"image_id": 1, "file_name": "673_01.png", "page": 4, "dpi": 300, "bbox": [96, 112, 727, 257], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: General pro\ufb01le of the proposed visual tool. The core of the tool (pink) consists of three linked components (grey).", "caption_bbox": [101, 259, 720, 273]}, {"image_id": 2, "file_name": "673_02.png", "page": 4, "dpi": 300, "bbox": [436, 754, 720, 986], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visualizations used to analyze the underlying structure of the features of the each intra-tumor region (T2). ", "caption_bbox": [428, 986, 729, 1015]}, {"image_id": 3, "file_name": "673_03.png", "page": 5, "dpi": 300, "bbox": [82, 761, 410, 965], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Cluster analysis view for comparison and assess- ment of two distinct intra-tumor regions (T2). ", "caption_bbox": [96, 964, 397, 993]}, {"image_id": 4, "file_name": "673_04.png", "page": 6, "dpi": 300, "bbox": [118, 765, 373, 990], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Linking the anatomical/clinical reference to the feature space (T3). The reverse linking is shown in Figure 2. ", "caption_bbox": [96, 989, 397, 1018]}, {"image_id": 5, "file_name": "673_05.png", "page": 6, "dpi": 300, "bbox": [420, 832, 734, 990], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualizations for the easy exploration of the ef- fect of variability and inaccuracy (T4). ", "caption_bbox": [428, 989, 729, 1018]}, {"image_id": 6, "file_name": "673_06.png", "page": 7, "dpi": 300, "bbox": [81, 112, 743, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Case study of a prostate tumor patient.", "caption_bbox": [286, 311, 536, 325]}, {"image_id": 7, "file_name": "673_07.png", "page": 8, "dpi": 300, "bbox": [96, 112, 711, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Case study of a cervical tumor patient.", "caption_bbox": [286, 330, 536, 344]}, {"image_id": 8, "file_name": "673_08.png", "page": 9, "dpi": 300, "bbox": [94, 275, 729, 400], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Schematic representation of the evaluation results of Table 5.1, for each one of the tasks of Section 2.", "caption_bbox": [131, 403, 690, 417]}], "674": [{"image_id": 0, "file_name": "674_00.png", "page": 3, "dpi": 300, "bbox": [129, 113, 415, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Different types of tunnel surface representations. (a) set of intersecting spheres, (b) asymmetric tunnel repre- sentation. The hydrophobicity is mapped onto the surfaces of both representations (hydrobphobic = red, hydrophylic = blue, neutral = violet). ", "caption_bbox": [96, 280, 397, 354]}, {"image_id": 1, "file_name": "674_01.png", "page": 4, "dpi": 300, "bbox": [412, 113, 716, 453], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration of the biochemist\u2019s workflow along with our proposed methods enhancing this process. ", "caption_bbox": [428, 464, 729, 492]}, {"image_id": 2, "file_name": "674_02.png", "page": 5, "dpi": 300, "bbox": [103, 113, 415, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: ATH (All Tunnels Heat Map) representation of all tunnels in a molecular dynamics. Each column corresponds to one tunnel, the vertical axis represents time. White spaces denote that a given tunnel is closed at the corresponding timestep. ", "caption_bbox": [96, 345, 397, 419]}, {"image_id": 3, "file_name": "674_03.png", "page": 6, "dpi": 300, "bbox": [95, 113, 713, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Three STH representing one tunnel over time, with different settings of the bottleneck size (0.9 \u00c5 in (a), 1.4 \u00c5 in (b), 1.8 \u00c5 in (c)). One row of the STH represents one tunnel at a specific timestep. The STH in (c) does not contain enough timesteps with open tunnels for a ligand of size 1.8 \u00c5. ", "caption_bbox": [96, 302, 729, 346]}, {"image_id": 4, "file_name": "674_04.png", "page": 7, "dpi": 300, "bbox": [114, 113, 415, 366], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Collar of the bottleneck shape from molecular dy- namics. ", "caption_bbox": [96, 379, 397, 407]}, {"image_id": 5, "file_name": "674_05.png", "page": 8, "dpi": 300, "bbox": [95, 113, 415, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) 2D collar representation and (b) its mapping onto the 3D visualization of the clipped tunnel. The 3D rep- resentation of the amino acids is supported as well. ", "caption_bbox": [96, 305, 397, 349]}, {"image_id": 6, "file_name": "674_06.png", "page": 9, "dpi": 300, "bbox": [142, 113, 731, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Difference in the bottleneck shape between the wild type of (a) DhaA haloalkane dehalogenase and its (b) DhaA80 and (c) DhaA106 mutations. The changes of the stability of the contour shape over time and the area of the void space correspond to the conclusions made by the biochemists. ", "caption_bbox": [96, 347, 729, 391]}], "675": [{"image_id": 0, "file_name": "675_00.png", "page": 1, "dpi": 300, "bbox": [69, 326, 757, 682], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Screenshot of CLUE applied to the StratomeX technique (a) in authoring mode. An annotation (b) highlights relevant aspects. The provenance graph view (c) and story view (d) show the history of the analysis and a Vistory being created. ", "caption_bbox": [63, 694, 762, 722]}, {"image_id": 1, "file_name": "675_01.png", "page": 2, "dpi": 300, "bbox": [62, 265, 399, 428], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Traditional workflow and information flow for visual data exploration and presentation of discoveries. Dashed edges indicate information flow, solid edges show transitions between stages. The information flow is sequential and different tools are used in each stage. ", "caption_bbox": [63, 441, 397, 515]}, {"image_id": 2, "file_name": "675_02.png", "page": 2, "dpi": 300, "bbox": [427, 296, 765, 475], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Information flow and stage transitions using the CLUE model. The provenance graph of an exploratory session and Visto- ries (interactive visual stories) are in the center. Solid edges indi- cate possible stage transitions, dashed lines indicate information flow. In the exploration stage, provenance data is generated; in the authoring stage a Vistory is created by curating provenance data, which is then used in the presentation stage. Note that consumers of a Vistory can also switch to any other stage. ", "caption_bbox": [428, 487, 762, 607]}, {"image_id": 3, "file_name": "675_03.png", "page": 4, "dpi": 300, "bbox": [412, 93, 761, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Three examples of transitions within the CLUE model, highlighting different entry points. Numbers indicate the order in which the stages are visited by the user. ", "caption_bbox": [428, 232, 762, 275]}, {"image_id": 4, "file_name": "675_04.png", "page": 5, "dpi": 300, "bbox": [62, 576, 399, 667], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The provenance graph data model consists of four differ- ent node types that are connected with each other by one or more edges. ", "caption_bbox": [63, 679, 397, 722]}, {"image_id": 5, "file_name": "675_05.png", "page": 6, "dpi": 300, "bbox": [62, 92, 415, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Close-ups of the provenance and story views. Based on the DoI, exploration states are represented at different levels of de- tail in the provenance view. The structure of the Vistory, shown on the right, corresponds to a path through the provenance graph, which is shown as a thick black line in the provenance visualiza- tion. Both the active slide in the story view and the associated ex- ploration state in the provenance graph are highlighted in orange. ", "caption_bbox": [63, 382, 397, 486]}, {"image_id": 6, "file_name": "675_06.png", "page": 7, "dpi": 300, "bbox": [62, 116, 764, 477], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Screenshot of a Gapminder-inspired application illustrating a Vistory in presentation mode. African countries are highlighted using annotations. Vistory: http://vistories.org/v/gapminder. ", "caption_bbox": [63, 488, 762, 516]}], "676": [{"image_id": 0, "file_name": "676_00.png", "page": 1, "dpi": 300, "bbox": [62, 785, 764, 1095], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The provenance graph (a) is aggregated and filtered based on the selected analysis execution time and the weighted degree-of- interest (DoI) components (b). In the top center of the graph, two horizontally aligned workflows show a compound layer node, where the top node represents the layer itself, while two workflows are extracted because their specific DoI values exceeded a predefined threshold. The toolbar (c) allows users to switch between node-type-specific views (layer, analysis, analysis input group, workflow instance) and to change the attribute mapping onto nodes. ", "caption_bbox": [63, 697, 762, 771]}, {"image_id": 1, "file_name": "676_01.png", "page": 3, "dpi": 300, "bbox": [62, 93, 764, 459], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A workflow provenance graph consists of multiple workflow executions over time. (a) Each execution requires one or more input files and applies a workflow template, containing a sequence of tools and files. (b) The provenance graph can be visualized at multiple aggre- gation levels (AL) exploiting the hierarchical structure of the graph. AL0 shows the connected workflow instances that are first aggregated to analysis input groups at AL1 and further aggregated to analyses at AL2. The aggregation methods are explained in Section 5.1. ", "caption_bbox": [63, 470, 762, 529]}, {"image_id": 2, "file_name": "676_02.png", "page": 5, "dpi": 300, "bbox": [65, 93, 415, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: AL2 corresponds to AL2 in Figure 2(b). The additional aggregation level AL3 groups similar analyses into layers using motif-based aggregation. ", "caption_bbox": [63, 287, 397, 330]}, {"image_id": 3, "file_name": "676_03.png", "page": 5, "dpi": 300, "bbox": [412, 93, 764, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The DoI value for each node incorporates the user-driven weight w and value v for all DoI components. Based on this value, the aggregation level of the node is selected, which determines the compression or expansion of the node. ", "caption_bbox": [428, 345, 762, 404]}, {"image_id": 4, "file_name": "676_04.png", "page": 7, "dpi": 300, "bbox": [412, 93, 764, 895], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Overview of the data provenance graph of the analy- sis. Colors represent workflow instances QC (orange), Mapping (green), MACS2 (red), SPP (purple), and Pileup (brown). (a) Fully expanded graph showing tool and file nodes. (b) Graph aggregated to level AL3. ", "caption_bbox": [428, 908, 762, 982]}, {"image_id": 5, "file_name": "676_05.png", "page": 8, "dpi": 300, "bbox": [108, 426, 717, 562], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The filtered subgraph from Figure 6(c) is expanded to the workflow instance level (AL0) with the tissue attribute mapped to the output nodes (\u201ckidney\u201d). ", "caption_bbox": [63, 581, 762, 609]}, {"image_id": 6, "file_name": "676_06.png", "page": 8, "dpi": 300, "bbox": [61, 93, 717, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Attribute mapping and time-based filtering. Darker nodes were created more recently. (a) Data provenance graph aggregated to level AL3 with node color representing time. No filtering applied. (b) Time filter applied in blend mode. (c) Time filter applied in hide mode. ", "caption_bbox": [63, 376, 762, 404]}], "677": [{"image_id": 0, "file_name": "677_00.png", "page": 3, "dpi": 300, "bbox": [427, 122, 764, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Prototype software that implements the design.", "caption_bbox": [451, 334, 738, 347]}, {"image_id": 1, "file_name": "677_01.png", "page": 4, "dpi": 300, "bbox": [427, 370, 764, 567], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Timeline modes: (a) original points as time (x-axis) against speed (y-axis); (b) density as time against speed, showing the time at which birds spent at different speeds over time (note the possible distinction between flying and non-flying speed); (c) den- sity as time against altitude (y-axis), with birds spending more time at higher altitudes on certain days (e.g. 21st June). ", "caption_bbox": [428, 577, 762, 666]}, {"image_id": 2, "file_name": "677_02.png", "page": 4, "dpi": 300, "bbox": [412, 93, 763, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Oystercatcher data on the mudflats: (a) Occluded point view, coloured by individual; (b) tile map showing the relative time of each individual in each grid square. ", "caption_bbox": [428, 306, 762, 349]}, {"image_id": 3, "file_name": "677_03.png", "page": 4, "dpi": 300, "bbox": [62, 92, 415, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Five mapping modes: (a) original points; (b) lines; (c) density estimation; (d) relative tile maps; (e) absolute tile maps, where b-e are coloured by duration spent there and (d-e) show rel- ative duration of time spent by each individual. ", "caption_bbox": [63, 244, 397, 303]}, {"image_id": 4, "file_name": "677_04.png", "page": 5, "dpi": 300, "bbox": [427, 116, 764, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Gulls\u2019 use of locations; the statistical legend on the right indicates the time spent in the current map view. ", "caption_bbox": [428, 306, 762, 334]}, {"image_id": 5, "file_name": "677_05.png", "page": 5, "dpi": 300, "bbox": [62, 116, 399, 348], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The timeline is time plotted against individual (one per row). There is little variation in density, because data are time- normalised. The area highlighted the map is only visited by one individual shown in a red on the timeline. Zooming in on 24th June reveals that the individual visited the area twice on that day, once at 03:00 and once at 19:00. ", "caption_bbox": [62, 358, 396, 447]}, {"image_id": 6, "file_name": "677_06.png", "page": 5, "dpi": 300, "bbox": [427, 359, 764, 598], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Highlighted journeys on the map and timeline, with five of these journeys are shown (top) as distance from start on the (x- axis) against altitude (y-axis) with 1 hour isochrones (grey vertical lines). ", "caption_bbox": [428, 609, 762, 668]}, {"image_id": 7, "file_name": "677_07.png", "page": 5, "dpi": 300, "bbox": [428, 692, 764, 883], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Left: Oystercatchers tend to only be in the in brushed area in August, with #367 spending the highest proportion of time there than other birds. Middle: Only #367 shown, verifying it was indeed only there in August. Right: #367 was further North and on land earlier in the year. ", "caption_bbox": [428, 893, 762, 967]}, {"image_id": 8, "file_name": "677_08.png", "page": 6, "dpi": 300, "bbox": [62, 92, 415, 200], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Moving the mouse pointer over the density plot provides a tooltip whenever over an original data point (same dyke as in Fig. 7). If multiple data points are at that location, left/right click- ing with cycle forward/backwards through these and any associated journey if one exists. ", "caption_bbox": [63, 211, 397, 285]}, {"image_id": 9, "file_name": "677_09.png", "page": 6, "dpi": 300, "bbox": [412, 93, 764, 236], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Density plot scale computed according to zoom level. (Left) Zoomed to full extent \u2013 individuals spend most time around the nest; (middle) density at a large spatial scale, showing a loop structure; (right) Aerial imagery context helps to interpret the loop structure. ", "caption_bbox": [428, 247, 762, 321]}, {"image_id": 10, "file_name": "677_10.png", "page": 6, "dpi": 300, "bbox": [427, 339, 764, 525], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Brushing an area on the map indicates the duration time of individuals\u2019 spent there as a proportion of the time they spent in the visible map area. ", "caption_bbox": [428, 535, 762, 578]}, {"image_id": 11, "file_name": "677_11.png", "page": 7, "dpi": 300, "bbox": [427, 387, 764, 483], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Intriguing \u2018hooks\u2019 of floating birds being moved by the tide [SBBCB11]. ", "caption_bbox": [428, 494, 762, 522]}, {"image_id": 12, "file_name": "677_12.png", "page": 7, "dpi": 300, "bbox": [62, 116, 764, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Brushing modes. Left: Brushing early morning (03:00) on the cyclic timeline (right) to see the spatial distribution. Middle: Brush- ing the cyclic timeline (18:00) shows a different spatial pattern. Notice the repeated red highlighting on the timeline. Right: Brushing only high speeds of travel in attribute mode shows that travel along the coast is mainly at high travel speeds. The highlighted areas on the stacked barchart indicate that all these brushed subsets affect all individuals by a similar proportion of time to each other in the current field of view. ", "caption_bbox": [63, 292, 762, 351]}, {"image_id": 13, "file_name": "677_13.png", "page": 7, "dpi": 300, "bbox": [427, 555, 764, 685], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: A lesser black-backed gull\u2019s day trip to Amsterdam ex- hibiting soaring and gliding behaviour. ", "caption_bbox": [428, 696, 762, 724]}, {"image_id": 14, "file_name": "677_14.png", "page": 8, "dpi": 300, "bbox": [412, 93, 764, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Foraging ranges of male gulls (left) and females (mid- dle) with proportions of time for each shown as a tile map (right). ", "caption_bbox": [428, 253, 762, 281]}, {"image_id": 15, "file_name": "677_15.png", "page": 8, "dpi": 300, "bbox": [62, 92, 415, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Brushed area visited at 03:00 in Fig. 12 (left) is visited in the morning and evening, mainly by three gulls. ", "caption_bbox": [63, 245, 397, 273]}, {"image_id": 16, "file_name": "677_16.png", "page": 9, "dpi": 300, "bbox": [66, 116, 760, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 17: Ten homing pigeons [FAN\u2217 13]. Group behaviour can be explored by colouring the dots by individual and brushing the timeline (top row). Brushed dots are highlighted in the darker colour and zooming in (bottom left) can help identify the structure of the group. The map-based spineplots (bottom right) summarises which pigeons took which routes. ", "caption_bbox": [63, 297, 762, 344]}], "678": [{"image_id": 0, "file_name": "678_00.png", "page": 1, "dpi": 300, "bbox": [63, 336, 764, 475], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Quantitative visualization of material movement for several flow components at once. (Left) Different materials in a logistics delivery process. (Middle) Uncertainty in water transportation for a storm water simulation (\u201cat least\u201d, \u201cexpected\u201d, \u201cworst case\u201d). (Right) Flow map for crowd movement in an evacuation scenario, colored by the time of stay. ", "caption_bbox": [63, 485, 762, 528]}, {"image_id": 1, "file_name": "678_01.png", "page": 3, "dpi": 300, "bbox": [62, 92, 764, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Flow map generation pipeline for 1D (top row) and 2D (bottom row) flow data. (a) Semantic-based zonation. (b) Bidirectional border flows between example zones (red, green) are derived from simulation data. (c) Abstract, directed acyclic zone graph. (d) Resulting flow map visualization. ", "caption_bbox": [63, 360, 762, 403]}, {"image_id": 2, "file_name": "678_02.png", "page": 5, "dpi": 300, "bbox": [63, 92, 764, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Overview of spatial embedding. (a) Input zone graph with two flow components (red, grey). (b) Input zone representations. (c) Connection of relevant zone representations. (d) Resampling of lines and creation of geospatial graph. (e) Iterative vertex merging. (f) Layout of individual flow lines. (g) Removal of some connection circles. (h) Visual styles and rendering. ", "caption_bbox": [63, 349, 762, 392]}, {"image_id": 3, "file_name": "678_03.png", "page": 7, "dpi": 300, "bbox": [412, 92, 764, 501], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Zoom-dependent level of detail (LoD). (a) Low. (b) Medium. (c) High. ", "caption_bbox": [428, 511, 762, 539]}, {"image_id": 4, "file_name": "678_04.png", "page": 7, "dpi": 300, "bbox": [62, 93, 415, 646], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Flow map composition according to different material origins. (a) Depots. (b) User-defined rooms (yellow) combined with all other rooms (blue). (c) Interactive decomposition according to rooms. ", "caption_bbox": [63, 657, 397, 716]}, {"image_id": 5, "file_name": "678_05.png", "page": 8, "dpi": 300, "bbox": [412, 93, 764, 696], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Overlay visualization of important information. (a) Mon- itored traffic conditions aggregated over a time span. (b) Road in- accessibility due to water level. (c) Wave arrival times for a flood wall breach [hh:mm]. ", "caption_bbox": [428, 706, 762, 765]}, {"image_id": 6, "file_name": "678_06.png", "page": 8, "dpi": 300, "bbox": [62, 92, 415, 695], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Flow maps for storm water. (a) Overview. Circles in- dicate the sewer effects (red=outflow, green=inflow). (b) Glyphs show details about the sewer-surface coupling. (c) Increased local LoD nearby important buildings. ", "caption_bbox": [63, 705, 397, 764]}], "679": [{"image_id": 0, "file_name": "679_00.png", "page": 4, "dpi": 300, "bbox": [293, 93, 765, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustrations for Lemmas 1\u20133", "caption_bbox": [313, 377, 511, 390]}, {"image_id": 1, "file_name": "679_01.png", "page": 6, "dpi": 300, "bbox": [62, 92, 415, 719], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Using direct line segments between cell roots is not topo- logically safe. Even if there are no intersections in the output, it may still be the case that the embedding changes as illustrated in this example: the children of the fat vertex are numbered in clock- wise order. ", "caption_bbox": [63, 731, 397, 805]}, {"image_id": 2, "file_name": "679_02.png", "page": 7, "dpi": 300, "bbox": [65, 123, 761, 376], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: W\u00fcrzburg with \u03b1 = 0.8, with the vertex s indicated in figure (a). The simplified drawing contains only two internal branches: Figure 3 is a crop of this map showing the extra vertices (located near the bottom right of this figure). ", "caption_bbox": [63, 387, 762, 416]}, {"image_id": 3, "file_name": "679_03.png", "page": 8, "dpi": 300, "bbox": [62, 92, 761, 659], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: W\u00fcrzburg with cross connections, for various values of \u03b1, and with either detailed of direct drawing style. All drawings use the same vertex s, which is indicated in figure (a). Note that figures (b) and (e) are the detailed and the direct drawing of the same underlying partition; this also holds for (c) and (f). ", "caption_bbox": [63, 673, 762, 716]}, {"image_id": 4, "file_name": "679_04.png", "page": 9, "dpi": 300, "bbox": [65, 123, 761, 401], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The city of Dallas, Texas. In Figure (b), the black lines indicate a detailed drawing of the tree summary and the gray lines indicate cross connections. The focus map (c) was computed with the method of Van Dijk et al. [vDvGH\u2217 13], using a scale factor of 3 for a region around the selected center. ", "caption_bbox": [63, 413, 762, 456]}], "680": [{"image_id": 0, "file_name": "680_00.png", "page": 2, "dpi": 300, "bbox": [62, 92, 747, 415], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An snapshot of our visual analytics system. (a) Control Panel; (b) Time-Series View; (c) Category Tree; (d) Message Table; (e) Map View. Hovering over a petal glyph (e) highlights the related keywords and connects to the corresponding keywords using threads. ", "caption_bbox": [63, 430, 762, 458]}, {"image_id": 1, "file_name": "680_01.png", "page": 5, "dpi": 300, "bbox": [97, 118, 363, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Coupling spatial lens with petal glyphs.", "caption_bbox": [101, 300, 356, 313]}, {"image_id": 2, "file_name": "680_02.png", "page": 6, "dpi": 300, "bbox": [62, 92, 415, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Conventional transition: Zooming in (a). The animated transition: Zooming in (b), Zooming out (c). ", "caption_bbox": [63, 298, 397, 326]}, {"image_id": 3, "file_name": "680_03.png", "page": 6, "dpi": 300, "bbox": [79, 347, 380, 454], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a): The design of the petal glyph. Two design alterna- tives are presented in (b) and (c). ", "caption_bbox": [63, 467, 397, 495]}, {"image_id": 4, "file_name": "680_04.png", "page": 7, "dpi": 300, "bbox": [82, 269, 746, 488], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Demonstration of our system using the Boston Marathon bombings incident. Screenshots of our system after 30 minutes (A), 1 hour (B), and 2 hours (C) of the bombings are shown. ", "caption_bbox": [63, 500, 762, 528]}, {"image_id": 5, "file_name": "680_05.png", "page": 7, "dpi": 300, "bbox": [82, 92, 764, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: An example of the animated transition in a zooming-in scenario. The transition states correspond to the timestamps in Figure 3b.", "caption_bbox": [63, 252, 762, 265]}, {"image_id": 6, "file_name": "680_06.png", "page": 8, "dpi": 300, "bbox": [445, 119, 746, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The evaluation results of different petal designs.", "caption_bbox": [447, 283, 743, 296]}, {"image_id": 7, "file_name": "680_07.png", "page": 9, "dpi": 300, "bbox": [66, 119, 394, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Evaluation results: Conventional zooming vs. animated transition. ", "caption_bbox": [63, 285, 397, 313]}], "681": [{"image_id": 0, "file_name": "681_00.png", "page": 2, "dpi": 300, "bbox": [62, 92, 729, 406], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Frame from the animation of the Utterance-Sedimentation View of the complete Stuttgart 21 arbitration.", "caption_bbox": [127, 419, 697, 432]}, {"image_id": 1, "file_name": "681_01.png", "page": 5, "dpi": 300, "bbox": [73, 530, 379, 686], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Speaker-Trails [V1] showing the movement of Barack Obama in the Topic-Space created for the Obama vs. Romney Pres- idential Debates. ", "caption_bbox": [63, 699, 397, 743]}, {"image_id": 2, "file_name": "681_02.png", "page": 5, "dpi": 300, "bbox": [434, 560, 753, 720], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Topic Glyph overlays on top of the Speaker-Trail view [V2] showing the position of the last spoken utterance for the time- frame of the animation. ", "caption_bbox": [428, 741, 762, 785]}, {"image_id": 3, "file_name": "681_03.png", "page": 6, "dpi": 300, "bbox": [64, 360, 393, 524], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Utterance-Sedimentation view [V3] for the presidential debate of Obama vs. Romney. ", "caption_bbox": [63, 536, 397, 564]}, {"image_id": 4, "file_name": "681_04.png", "page": 7, "dpi": 300, "bbox": [88, 122, 739, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Speaker-Path view [V4] for different speakers of the Stuttgart 21 arbitration.", "caption_bbox": [197, 258, 628, 271]}, {"image_id": 5, "file_name": "681_05.png", "page": 7, "dpi": 300, "bbox": [427, 294, 761, 486], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Glyph-based representation for three participants over the course of the debate. Each glyph represents one utterance. For the glyph in the rectangle, a detailed view is provided in Figure 7. ", "caption_bbox": [428, 500, 762, 544]}, {"image_id": 6, "file_name": "681_06.png", "page": 8, "dpi": 300, "bbox": [62, 92, 414, 431], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Panel providing a detailed view on the glyph dimensions and its content. The top chart illustrates the complete conversation and indicates the position of the glyph in the discourse. The left panel presents the content of the utterance; on the right, the glyph and its dimensions are given. ", "caption_bbox": [63, 445, 397, 519]}], "682": [{"image_id": 0, "file_name": "682_00.png", "page": 1, "dpi": 300, "bbox": [132, 350, 695, 631], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: TextDNA allows people to compare word usage patterns across large text corpora. Here, configurable colorfields provide an overview of the 5,000 most commonly used words per decade over the last 350 years (one decade per row). Ordering words according to the sets of decades in which they are common (left are common in all, right in one) and coloring by a word\u2019s commonality within each decade reveals temporal correspondences between decades (c.f. \u00a76.1.2) ", "caption_bbox": [63, 641, 762, 700]}, {"image_id": 1, "file_name": "682_01.png", "page": 3, "dpi": 300, "bbox": [65, 116, 401, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The first ten words of our two data models applied to A Midsummer Night\u2019s Dream. The text sequence model emphasizes word location whereas the ranked count model orders words ac- cording to frequency patterns. TextDNA\u2019s configurable colorfield approach allows researchers to explore text data using these mod- els to address a breadth of analyses. ", "caption_bbox": [63, 199, 397, 288]}, {"image_id": 2, "file_name": "682_02.png", "page": 6, "dpi": 300, "bbox": [412, 93, 767, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The top 5,000 words per decade from Google Books or- dered by their commonality in each decade (most common on the left) and colored by their commonality in the 2000s (purple are common in the 2000s, orange are not). The orange words form a nearly linear boundary in the upper right, suggesting that language evolves steadily over time. ", "caption_bbox": [428, 296, 762, 385]}, {"image_id": 3, "file_name": "682_03.png", "page": 8, "dpi": 300, "bbox": [62, 92, 415, 640], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Ordering words by Word Rank (most common on the left, 1,800th most common on the right) and using qualitative filtering allowed users to identify correlations between word usage and his- torical events. ", "caption_bbox": [63, 652, 397, 711]}, {"image_id": 4, "file_name": "682_04.png", "page": 8, "dpi": 300, "bbox": [412, 93, 760, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The raw text of She: A History of Adventure with one chapter per sequence. Red areas contain predominantly words in less than half of the chapters, whereas blue are common terms. As the novel progresses, the language shifts to contain larger numbers of blue terms, characteristic of a growing familiarity of the protag- onist with the \u201clost world.\u201d ", "caption_bbox": [428, 314, 762, 403]}], "683": [{"image_id": 0, "file_name": "683_00.png", "page": 3, "dpi": 300, "bbox": [79, 116, 747, 381], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Retailoring a box spline to a square lattice. Note that, using the traditional nearest-neighbor kernel, the diagonal projections are overrepresented. In contrast, using retailoring, the sampling rates for the projected lattice points and the approximation orders of the projected kernels compensate each other. ", "caption_bbox": [63, 391, 762, 434]}, {"image_id": 1, "file_name": "683_01.png", "page": 4, "dpi": 300, "bbox": [444, 176, 748, 395], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The Fourier error kernels corresponding to the axis- aligned (Enn| (\u03c9)) and diagonal (Enn/ (\u03c9)) projections of the 2D nearest-neighbor kernel. ", "caption_bbox": [428, 405, 762, 448]}, {"image_id": 2, "file_name": "683_02.png", "page": 5, "dpi": 300, "bbox": [79, 425, 382, 644], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The Fourier error kernels corresponding to the axis- aligned (Erb| (\u03c9)) and diagonal (Erb/ (\u03c9)) projections of the 2D rotated box kernel. ", "caption_bbox": [62, 654, 396, 697]}, {"image_id": 3, "file_name": "683_03.png", "page": 5, "dpi": 300, "bbox": [79, 92, 764, 307], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Tomographic reconstruction of an analytically defined test signal using a nearest-neighbor kernel, a rotated box kernel, and an upscaled box kernel. Note that the rotated box kernel nicely compensates the anisotropic effect of the square lattice yielding an isotropic signal representation. In contrast, the nearest-neighbor kernel and the square lattice amplify the anisotropic effects of each other. A similarly anisotropic signal representation is obtained if an upscaled box kernel is used on the square lattice that covers four times more lattice points than the nearest-neighbor kernel, but still provides the same approximation order. ", "caption_bbox": [63, 314, 762, 388]}, {"image_id": 4, "file_name": "683_04.png", "page": 5, "dpi": 300, "bbox": [448, 460, 744, 629], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Error of a 2D tomographic reconstruction depending on the number of iterations. Note that the residual error is much lower in case of retailoring, that is, using the rotated box kernel instead of the nearest-neighbor kernel or the upscaled box kernel. ", "caption_bbox": [428, 675, 762, 734]}, {"image_id": 5, "file_name": "683_05.png", "page": 8, "dpi": 300, "bbox": [62, 92, 650, 847], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Error of 3D tomographic reconstructions depending on the number of iterations. Note that the residual error is much lower in case of retailoring box splines to lattices. ", "caption_bbox": [63, 856, 762, 884]}, {"image_id": 6, "file_name": "683_06.png", "page": 9, "dpi": 300, "bbox": [107, 116, 720, 976], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Tomographic reconstruction of vascular structures using box splines tailored and retailored to CC, BCC, and FCC lattices. Note that retailoring (the lower three rows of images) yields much more isotropic volume representations. ", "caption_bbox": [63, 983, 762, 1011]}], "684": [{"image_id": 0, "file_name": "684_00.png", "page": 1, "dpi": 300, "bbox": [62, 646, 764, 875], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Real-time rendering results of volume datasets with heterogeneous lighting and shading parameters.", "caption_bbox": [135, 625, 689, 638]}, {"image_id": 1, "file_name": "684_01.png", "page": 2, "dpi": 300, "bbox": [99, 118, 727, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The diagram of our rendering pipeline. Rectangular nodes are data objects and ellipsoidal nodes are operations.", "caption_bbox": [104, 264, 721, 277]}, {"image_id": 2, "file_name": "684_02.png", "page": 5, "dpi": 300, "bbox": [468, 508, 725, 672], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration of irradiance estimation and volume scatter- ing. The radiance at the red point consists of both single scattering from the light sources directly and multiple scattering from other points such as the green and blue points. The irradiance is sparsely estimated through secondary ray-integration toward light sources and the scattering is approximated using volume-space diffusion. The pre-integrated irradiance is then used for radiance sampling at a higher frequency along the primary rays. ", "caption_bbox": [428, 689, 762, 809]}, {"image_id": 3, "file_name": "684_03.png", "page": 5, "dpi": 300, "bbox": [430, 823, 763, 925], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Illustration of using different light sources and the multi- ple scattering effect on the green sphere. All the examples run at 49 FPS. The performance does not depend on the type of light source because it is memory bandwidth limited, not math limited. ", "caption_bbox": [428, 937, 762, 996]}, {"image_id": 4, "file_name": "684_04.png", "page": 7, "dpi": 300, "bbox": [66, 429, 396, 688], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison between previous volume rendering meth- ods including local ambient occlusion (AO), ambient volume scat- tering (AVS) and our multi-material method using the Christmas tree dataset and the keratinocyte cell dataset. It is shown that pre- vious methods are limited to homogeneous materials. By using our method, the Christmas tree leaves and decorations, the cell or- ganelle and cytosol can have their own materials and present dif- ferent looks. ", "caption_bbox": [63, 701, 397, 821]}, {"image_id": 5, "file_name": "684_05.png", "page": 8, "dpi": 300, "bbox": [429, 115, 763, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) Rendering of the present box dataset in a cutaway view. In addition to a directional light source, a spot light is also added to highlight the interior objects. (b) Rendering of a high res- olution scanned sea spider in a cutaway view. ", "caption_bbox": [428, 312, 762, 371]}, {"image_id": 6, "file_name": "684_06.png", "page": 8, "dpi": 300, "bbox": [66, 805, 396, 933], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Rendering of the keratinocyte cell dataset. Different clip- ping planes are used to reveal the interior of the cell. Different ma- terials are used to illustrate the organelles of the cell. ", "caption_bbox": [63, 945, 397, 989]}, {"image_id": 7, "file_name": "684_07.png", "page": 8, "dpi": 300, "bbox": [64, 115, 397, 216], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Rendering of the Christmas tree dataset using different irradiance volume resolutions. Using a high resolution irradiance volume can capture high-frequency shadow while using a low res- olution irradiance volume leads to softer shadow. ", "caption_bbox": [63, 229, 397, 288]}, {"image_id": 8, "file_name": "684_08.png", "page": 9, "dpi": 300, "bbox": [72, 307, 755, 496], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Quality and performance evaluation with different integration steps. \u2206x is the voxel size. The reference image is generated using per-sample irradiance estimation and 0.125\u2206x. Other images are generated using our decoupled lighting and material shading technique. ", "caption_bbox": [63, 508, 762, 537]}], "685": [{"image_id": 0, "file_name": "685_00.png", "page": 3, "dpi": 300, "bbox": [84, 119, 746, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Pipeline of the image-based viewpoint selection model. 3D visualizations are organized and stored in the voter database. The voter dataset with similar features in the input volume is chosen from the voter database, and each image casts votes to its most similar candidate viewpoints by similarity voting. A voting sphere records the votes of each viewpoint, and the optimal viewpoint is the one with the most votes. ", "caption_bbox": [63, 338, 762, 381]}, {"image_id": 1, "file_name": "685_01.png", "page": 4, "dpi": 300, "bbox": [412, 93, 756, 236], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A pyramid representation of the image and its PHOG vector. ", "caption_bbox": [428, 248, 762, 276]}, {"image_id": 2, "file_name": "685_02.png", "page": 5, "dpi": 300, "bbox": [99, 116, 718, 423], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Three images\u2019 HOG vectors of the tooth dataset. The histogram representations from levels l = 0 (K = 20) to l = 3 (20\u00d743 = 1280) for each image is shown from left to right, respectively. The histograms between (a) and (b) are more similar than the ones between (a) and (c), that is, the image in (b) shares more similar shape information with the voter image. ", "caption_bbox": [63, 436, 762, 483]}, {"image_id": 3, "file_name": "685_03.png", "page": 7, "dpi": 300, "bbox": [95, 116, 744, 216], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a)\u2013(c) Three representative viewpoints of the carp dataset based on our method. (d) Three voter images with similar viewpoints from the voter dataset. ", "caption_bbox": [63, 229, 762, 257]}, {"image_id": 4, "file_name": "685_04.png", "page": 7, "dpi": 300, "bbox": [97, 294, 379, 611], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The image similarity measure in viewpoint selection of the NCAT phantom. Two voter images of 40 selected viewpoints are shown in (a) and (c), respectively. The voting sphere is shown in (b) and (d). 40 viewpoints are displayed in black or red points, and the viewpoints of (a) and (c) are marked in red in (b) and (d), respectively. ", "caption_bbox": [63, 624, 397, 713]}, {"image_id": 5, "file_name": "685_05.png", "page": 8, "dpi": 300, "bbox": [72, 340, 393, 438], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The top and bottom views of the voting spheres of the foot (a) and the engine (b). The voted viewpoints are relatively focused in small regions for the foot, and the optimal viewpoint is indicated by the red point in Fig. 6(b). The voted viewpoints are quite diverse around the voting sphere for the engine, and the optimal viewpoint is indicated by the red point in Fig. 6(d). ", "caption_bbox": [63, 451, 397, 540]}, {"image_id": 6, "file_name": "685_06.png", "page": 8, "dpi": 300, "bbox": [437, 340, 754, 464], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The optimal viewpoints of the Chapel Hill CT head under different transfer functions, which highlight both the bone and skin (a), the bone only (b), and the skin only (c). The optimal viewpoints are slightly different under these transfer functions. ", "caption_bbox": [428, 478, 762, 537]}, {"image_id": 7, "file_name": "685_07.png", "page": 8, "dpi": 300, "bbox": [87, 117, 741, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The image-based viewpoint selection results of the simulated electron density distribution in a hydrogen atom, the foot, the tooth, the engine, and the head of the visual male from (a) to (e), respectively. ", "caption_bbox": [63, 276, 762, 304]}, {"image_id": 8, "file_name": "685_08.png", "page": 9, "dpi": 300, "bbox": [73, 122, 392, 530], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparison of the optimal viewpoints for the head of the visual male, the bonsai tree, and the aneurism datasets obtained by three different methods: our method (left), the opacity entropy (middle), and structure-aware viewpoint selection (right). ", "caption_bbox": [63, 543, 397, 602]}], "686": [{"image_id": 0, "file_name": "686_00.png", "page": 1, "dpi": 300, "bbox": [62, 628, 763, 872], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: High-quality FTLE visualization of a European Centre for Medium-Range Weather Forecasts (E CMWF) reanalysis simulation of the wind velocity field of the northern hemisphere at April, 10th in 2010. The three-dimensional FTLE field emphasizes the spatial turbulence structure in the wind field and illustrates differences above land masses of North America (left and detail region), the North Atlantic region (center) and Europe (right). Integration duration (GPU): \u03c4 = 10, majorant extinction \u03c3\u0304t = 1, FTLE range R = [0.35, 0.61], \u03c3\u0304t grid: 100 \u00d7 50 \u00d7 10, left: 1600 \u00d7 600, right: 1400 \u00d7 800 pixels. ", "caption_bbox": [62, 537, 763, 611]}, {"image_id": 1, "file_name": "686_01.png", "page": 3, "dpi": 300, "bbox": [479, 119, 712, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of single-scattering light transport. A direc- tional light emits radiance Le in direction ~\u03c9L , which enters the domain D at xL . The transmittance Tr (xs \u2194 xL ) accounts for the attenuation on the way toward xs , where it scatters with coefficient \u03c3s . The amount of light that is scattered toward the viewer in direc- tion ~\u03c9 is determined by f p (xs , ~\u03c9L \u2192 ~\u03c9). Finally, the transmittance Tr (x \u2194 xs ) attenuates toward the entry point x of the view ray. ", "caption_bbox": [427, 302, 763, 407]}, {"image_id": 2, "file_name": "686_02.png", "page": 3, "dpi": 300, "bbox": [427, 416, 762, 602], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: D OUBLE G YRE flow on the GPU without \u03c3\u0304t grid (Sec- tion 4) at 4000\u00d72000 pixels. Integration time: T = [0, 40], \u03c3\u0304t = 100, FTLE range R = [0.05, 0.235]. ", "caption_bbox": [427, 613, 763, 657]}, {"image_id": 3, "file_name": "686_03.png", "page": 6, "dpi": 300, "bbox": [62, 92, 754, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Convergence series of a close-up in the D OUBLE G YRE at 300 \u00d7 300 pixels, using the GPU (without \u03c3\u0304t grid). The majority of the noise vanishes in a few minutes. Integration time: T = [0, 40], \u03c3\u0304t = 100, FTLE range R = [0.05, 0.235]. ", "caption_bbox": [62, 325, 761, 355]}, {"image_id": 4, "file_name": "686_04.png", "page": 6, "dpi": 300, "bbox": [66, 368, 395, 702], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: ABC flow on the GPU without \u03c3\u0304t grid at 1500 \u00d7 1500 pixels, showing several sharp ridges. Integration time: T = [5, 15], \u03c3\u0304t = 35, FTLE range R = [0.38, 0.92]. ", "caption_bbox": [62, 717, 398, 762]}, {"image_id": 5, "file_name": "686_05.png", "page": 6, "dpi": 300, "bbox": [427, 368, 759, 571], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: R ABINOVICH -FABRIKANT flow on the GPU with \u03c3\u0304t grid of 50 \u00d7 20 \u00d7 5 at 1200 \u00d7 750 pixels. Integration duration \u03c4 = 20, \u03c3\u0304t = 5, FTLE range R = [0, 0.47]. ", "caption_bbox": [427, 584, 763, 628]}, {"image_id": 6, "file_name": "686_06.png", "page": 7, "dpi": 300, "bbox": [74, 415, 398, 695], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: B OUSSINESQ flow on the GPU with \u03c3\u0304t grid of 5 \u00d7 10 \u00d7 5 at 600 \u00d7 1600 pixels. We set \u03c3\u0304t = 60 and FTLE range R = [0.02, 1]. The flow is shown at different start times (front slice), left: t0 = 1, right: t0 = 5, both with \u03c4 = 10. ", "caption_bbox": [61, 711, 398, 772]}, {"image_id": 7, "file_name": "686_07.png", "page": 7, "dpi": 300, "bbox": [62, 117, 764, 363], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: C LOUD - TOPPED B OUNDARY L AYER flow on the GPU with 40 \u00d7 20 \u00d7 20 \u03c3\u0304t grid. Integration duration: \u03c4 = 30, majorant extinction \u03c3\u0304t = 2, FTLE range R = [0.09, 0.21], left: 1200 \u00d7 640, right: 800 \u00d7 800 pixels. ", "caption_bbox": [62, 374, 761, 404]}, {"image_id": 8, "file_name": "686_08.png", "page": 8, "dpi": 300, "bbox": [431, 631, 760, 726], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Plotting the RMSE over time in log-log scale shows the linear convergence expected from MC methods. ", "caption_bbox": [427, 734, 761, 762]}], "687": [{"image_id": 0, "file_name": "687_00.png", "page": 1, "dpi": 300, "bbox": [67, 335, 752, 518], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization of the initial positions (blue curves) of inertial particle trajectories (green curves) that lead to the same location (small white sphere). At this location, a glyph is placed that depicts the velocities (orange curves), with which the inertial particles arrive. We solve the source inversion problem for left: T REFOIL and right: WALL - MOUNTED C YLINDER. ", "caption_bbox": [61, 522, 761, 566]}, {"image_id": 1, "file_name": "687_01.png", "page": 4, "dpi": 300, "bbox": [412, 93, 762, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Given an observation x, the influence curve (blue) is the union of all locations that lead an inertial pathline (green) to the observation x. The velocity of arriving particles (orange) is shown in a glyph at x. The glyph design is described later in Section 3.3. ", "caption_bbox": [427, 261, 761, 320]}, {"image_id": 2, "file_name": "687_02.png", "page": 4, "dpi": 300, "bbox": [427, 762, 764, 947], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Inertial particles in a center flow, showing influence curves (blue), inertial pathlines (green, seeded from selected curve), as well as velocity glyphs (see Section 3.3). ", "caption_bbox": [427, 953, 762, 997]}, {"image_id": 3, "file_name": "687_03.png", "page": 5, "dpi": 300, "bbox": [412, 92, 764, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Influence curve vector field h(x, y,t) in the D OUBLE G YRE. Left: Space-time visualization of the influence curve vector field, containing several pathlines (i.e., influence curves). Right: Selected LIC slices, showing areas where h is undefined, since particles left the domain (black) and where the magnitude is high (red). ", "caption_bbox": [427, 296, 763, 370]}, {"image_id": 4, "file_name": "687_04.png", "page": 6, "dpi": 300, "bbox": [427, 424, 764, 605], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A dense sampling of a 3D domain, such as in the T RE - FOIL flow, might lead to cluttered influence curves. Left: only one influence curve is shown, right: all are shown. ", "caption_bbox": [427, 609, 763, 653]}, {"image_id": 5, "file_name": "687_05.png", "page": 6, "dpi": 300, "bbox": [62, 92, 764, 379], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualization of all locations (blue curves) that reach the observation points (centers of gray circles). Here, we show the impact of particle size d p in the T REFOIL 2D data set, together with inertial pathlines (green curves) for a selected glyph. ", "caption_bbox": [62, 384, 761, 413]}, {"image_id": 6, "file_name": "687_06.png", "page": 6, "dpi": 300, "bbox": [61, 424, 395, 524], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Typically, the observed velocities (orange) are distributed in a characteristic drop shape inside the glyphs. The orange line is parameterized by \u03c4 as well. The end of the line is thicker and represents the terminal velocity to which inertial particles converge. ", "caption_bbox": [62, 533, 396, 592]}, {"image_id": 7, "file_name": "687_07.png", "page": 7, "dpi": 300, "bbox": [61, 675, 398, 866], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Influence curves in a steady T ORNADO flow.", "caption_bbox": [89, 870, 368, 883]}, {"image_id": 8, "file_name": "687_08.png", "page": 7, "dpi": 300, "bbox": [61, 455, 764, 631], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Influence curves for different initial velocities in the D OUBLE G YRE. Left: v0 = (0, 0)T , right: v0 = (0, 0.15)T . When inertial particles are not released from rest (right image), orange curves (observed velocities) no longer start at the glyph center. ", "caption_bbox": [62, 632, 761, 664]}, {"image_id": 9, "file_name": "687_09.png", "page": 7, "dpi": 300, "bbox": [65, 92, 764, 379], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Influence curves in the phase space of the F ORCED -DAMPED D UFFING oscillator for different particle sizes d p and gravity g. The larger the particles, the slower their response to changes in the underlying flow. Thus, they take longer to accelerate and as shown by the orange curves (observed velocity), they enter the observation points with less speed than the smaller particles. With increased gravity (downward), influence curves bend upward to accommodate the downward motion of inertial particles. ", "caption_bbox": [62, 384, 763, 443]}, {"image_id": 10, "file_name": "687_10.png", "page": 7, "dpi": 300, "bbox": [427, 675, 764, 817], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Influence curves in a symmetric R AYLEIGH -B \u00c9NARD convection are separated into convection cells. ", "caption_bbox": [427, 820, 761, 848]}, {"image_id": 11, "file_name": "687_11.png", "page": 8, "dpi": 300, "bbox": [412, 93, 764, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Unsteady flow around WALL - MOUNTED C YLINDER. Behind the obstacle, the flow is slow and turbulent. ", "caption_bbox": [427, 290, 763, 318]}, {"image_id": 12, "file_name": "687_12.png", "page": 8, "dpi": 300, "bbox": [62, 92, 415, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Influence curves (blue) in the unsteady wake of the 3D S QUARE C YLINDER sequence. ", "caption_bbox": [62, 281, 396, 309]}], "688": [{"image_id": 0, "file_name": "688_00.png", "page": 3, "dpi": 300, "bbox": [135, 92, 764, 225], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview over our method including intermediate steps and relevant structures. Most important results are marked with thick outlines. Starting with the dataset, our method extracts critical points, their probability, and even relations. ", "caption_bbox": [63, 238, 762, 266]}, {"image_id": 1, "file_name": "688_01.png", "page": 4, "dpi": 300, "bbox": [62, 92, 723, 259], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Different spaces used to define singular patches based on a 2-dimensional realization space. A grid point x and all of its neighbors, e.g. y, are represented as hyperplanes in the extended realization space (b). Here Uz (x) and Uz (y) may have an intersection denoting all realizations with equal value at x and y. Projecting this intersection and all the ones for x\u2019s other neighbors into the space spanned by zi \u2019s (the realization space) it decomposes this space (c) into sets of realizations with x having the same neighbor configuration. We call these regions patches. Classifying patches based on the configuration leads to singular patches representing maxima (red), saddles (yellow) and minima (not present in this example). Combining the regions in realization space (realization sets) with the point\u2019s plane, one can also think of patches as regions on hyperplanes in the extended realization space (d). ", "caption_bbox": [62, 263, 761, 367]}, {"image_id": 2, "file_name": "688_02.png", "page": 6, "dpi": 300, "bbox": [62, 92, 415, 236], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Different situations of patches in the extended realization space with them either being adjacent (a,b,c) or not (d,e,f). We dif- ferentiate between horizontal (a), vertical (b), and higher order (c) adjacency. ", "caption_bbox": [63, 237, 397, 296]}, {"image_id": 3, "file_name": "688_03.png", "page": 6, "dpi": 300, "bbox": [412, 93, 758, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Exemplary horizontal (a) and vertical (b) folds in a 2- dimensional realization space (bottom right). In extended realiza- tion space (left) two patches overlap forming two other patches. Folds appear in the patch graph as special patterns (top right). Maximum patches are colored red while saddle patches are yellow. The edges of the graph indicate vertical (green), horizontal (blue), and order 2 (gray) adjacency. ", "caption_bbox": [428, 219, 762, 323]}, {"image_id": 4, "file_name": "688_04.png", "page": 7, "dpi": 300, "bbox": [78, 93, 415, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Edge coloring (a) and node glyph (b) used for visualizing the patch graph. In (c), some regions indicating critical points with spatial uncertainty can be seen. The texture indicates the probabil- ity of the points being at a specific location within the region. ", "caption_bbox": [63, 202, 397, 261]}, {"image_id": 5, "file_name": "688_05.png", "page": 7, "dpi": 300, "bbox": [412, 92, 764, 224], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Dataset containing a maximum with spatial uncertainty (a). Merging the patch graph (a) allows for identifying the varying maximum as an important critical point (b). ", "caption_bbox": [428, 227, 762, 270]}, {"image_id": 6, "file_name": "688_06.png", "page": 8, "dpi": 300, "bbox": [412, 93, 714, 249], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The patch graph (a) of an uncertain temperature fore- cast with 2 eigenvalues chosen. Zooming to a connected component (b) allows for investigating patch adjacency and even higher level structures like folds (red). ", "caption_bbox": [428, 249, 762, 308]}, {"image_id": 7, "file_name": "688_07.png", "page": 8, "dpi": 300, "bbox": [65, 206, 399, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: An estimate on the relative sampling error by averaging the deviation at different sample counts. ", "caption_bbox": [63, 305, 397, 333]}, {"image_id": 8, "file_name": "688_08.png", "page": 9, "dpi": 300, "bbox": [121, 92, 765, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Regions of merged critical points in a Gaussian-distributed scalar field of temperature data. In (a), an overview over all critical points is given. In (b), only points which are present in at least 50% of all realizations with a color mapped mean field in the background are shown. Zooming in gives a clearer look at the probability distributions inside the merged regions (c). Here, e.g., the critical points A and C have a higher spatial uncertainty than B as the texture is spread out more. ", "caption_bbox": [63, 250, 762, 309]}], "689": [{"image_id": 0, "file_name": "689_00.png", "page": 2, "dpi": 300, "bbox": [452, 714, 739, 954], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Structure of the human heart.", "caption_bbox": [493, 964, 696, 977]}, {"image_id": 1, "file_name": "689_01.png", "page": 2, "dpi": 300, "bbox": [62, 92, 415, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: AVOCLA is applied to a patient dataset with an aortic dilation. Starting from the path lines, two clusters are generated that are visualized by a 2D plot and a 3D glyph. ", "caption_bbox": [63, 363, 397, 406]}, {"image_id": 2, "file_name": "689_02.png", "page": 3, "dpi": 300, "bbox": [62, 92, 764, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The pipeline of AVOCLA. The imported data contains the surface mesh, the centerline and the vortex-representing path lines. The path lines and the centerline are sampled equidistantly and a dissimilarity matrix is calculated as input for the clustering. Each clustered vortex is classified and depicted by a 2D and 3D visualization. ", "caption_bbox": [63, 227, 762, 270]}, {"image_id": 3, "file_name": "689_03.png", "page": 4, "dpi": 300, "bbox": [62, 92, 764, 282], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Vortex classification criteria. The shape is divided into helix (a) and vortex (b). The flow curve (c) is used to determine the temporal behavior. For the spatial classification, four aortic sections (d) are distinguished. The size is divided into minor (e) and pronounced (f) flow and the RD is distinguished into right- (g) and left-handed (h). ", "caption_bbox": [63, 292, 762, 335]}, {"image_id": 4, "file_name": "689_04.png", "page": 5, "dpi": 300, "bbox": [412, 92, 764, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The curve shows the eigenvalues of a helix depending on the turn number to determine the vortex shape. The colored helices correspond to the colored curve points. ", "caption_bbox": [428, 361, 762, 404]}, {"image_id": 5, "file_name": "689_05.png", "page": 6, "dpi": 300, "bbox": [62, 92, 764, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: 3D glyph-based vortex visualization. The vortex-representing path lines (a) are clustered (b). For each cluster, a cubic spline (red) is calculated, and at each spline point an ellipse approximates the local vortex expansion (c). The ellipses are triangulated to a surface (d) on which the percentage size and RD are depicted using a color-coding and arrow glyphs (e). ", "caption_bbox": [63, 317, 762, 360]}, {"image_id": 6, "file_name": "689_06.png", "page": 7, "dpi": 300, "bbox": [412, 92, 764, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Classification results for six datasets according to: shape (SH), temporal occurrence (T), vessel section (V), size (SI) and ro- tation direction (RD). Each colored column represents a vortex. The marks show matches and mismatches between the ground truth and AVOCLA\u2019s results. ", "caption_bbox": [428, 244, 762, 318]}, {"image_id": 7, "file_name": "689_07.png", "page": 8, "dpi": 300, "bbox": [61, 92, 764, 414], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Clustering and visualization of the classification results for the six datasets from Fig. 7.", "caption_bbox": [168, 424, 657, 437]}], "690": [{"image_id": 0, "file_name": "690_00.png", "page": 3, "dpi": 300, "bbox": [436, 548, 756, 649], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Different baselines: (a) with 2-norm, distortions are present; (b) with 1-norm, all layers are smooth. ", "caption_bbox": [428, 656, 762, 684]}, {"image_id": 1, "file_name": "690_01.png", "page": 3, "dpi": 300, "bbox": [412, 92, 764, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Different baselines: (a) with weighted 2-norm minimiza- tion, notice the wiggle on all layers; (b) with 1-norm minimization: only the thick green layer has a wiggle. ", "caption_bbox": [428, 231, 762, 274]}, {"image_id": 2, "file_name": "690_02.png", "page": 4, "dpi": 300, "bbox": [62, 92, 415, 221], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The optimal baseline algorithm", "caption_bbox": [125, 234, 335, 247]}, {"image_id": 3, "file_name": "690_03.png", "page": 5, "dpi": 300, "bbox": [105, 347, 354, 423], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Two orderings of two layers on a flat baseline. Case (b) produces a distortion, case (a) is preferred. ", "caption_bbox": [63, 431, 397, 459]}, {"image_id": 4, "file_name": "690_04.png", "page": 5, "dpi": 300, "bbox": [60, 770, 406, 853], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Layer orderings produced by different algorithms: (a) on-set; (b) BestFirst; (c) TwoOpt. The first two have layer distor- tions. Labels identify layers and were positioned with the algorithm described in Section 5. ", "caption_bbox": [63, 860, 397, 919]}, {"image_id": 5, "file_name": "690_05.png", "page": 6, "dpi": 300, "bbox": [129, 760, 332, 845], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Lower and upper bounds for a label with width w = 4. Left: i = 2. Lower/upper bounds B2 = 1 and T2 = 2. Right: i = 7. Lower/upper bounds B7 = 1 and T7 = 3 ", "caption_bbox": [63, 858, 397, 902]}, {"image_id": 6, "file_name": "690_06.png", "page": 8, "dpi": 300, "bbox": [425, 548, 764, 638], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Number of calls on 50 topics to the NYC 311 for the days before and after hurricane Sandy hit New York City. Left: D3\u2019s implementation of Byron and Wattenberg [BW08]. Right: with TwoOpt ordering and the 1-norm baseline algorithm. ", "caption_bbox": [428, 649, 762, 708]}, {"image_id": 7, "file_name": "690_07.png", "page": 8, "dpi": 300, "bbox": [412, 93, 745, 448], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Marketcap data for the top 50 companies from 1995- 2015. Top: D3\u2019s implementation of Byron and Wattenberg [BW08]. Bottom: with TwoOpt ordering and a baseline algorithm that min- imizes weighted 1-norm wiggle. ", "caption_bbox": [428, 460, 762, 519]}], "691": [{"image_id": 0, "file_name": "691_00.png", "page": 3, "dpi": 300, "bbox": [69, 92, 764, 489], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: PhysioEx is a visual analysis tool for event stream analysis of multiple streams. Several Temporal Intensity Maps (left), in the coordinated dashboard reveal the duration, frequency, and intensity of physiologic data over time, alongside a selected raw data display (middle), and three visualizations (right, top to bottom): a sequence, linear, and stream graph. ", "caption_bbox": [63, 512, 762, 556]}, {"image_id": 1, "file_name": "691_01.png", "page": 4, "dpi": 300, "bbox": [62, 92, 751, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Temporal Intensity Maps, compact visualizations for gaining rapid situational awareness of low-level behaviours in data streams.", "caption_bbox": [66, 282, 758, 295]}, {"image_id": 2, "file_name": "691_02.png", "page": 4, "dpi": 300, "bbox": [67, 340, 395, 540], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The four-step method of constructing the Temporal Inten- sity Map beginning with identifying kernels. ", "caption_bbox": [63, 556, 397, 584]}, {"image_id": 3, "file_name": "691_03.png", "page": 5, "dpi": 300, "bbox": [63, 93, 415, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The Sequence Graph, illustrating a matrix of hours by days (truncated to 10 hours). Each bubble\u2019s radius encodes the to- tal duration of episodes within that hour, and smaller bubbles are drawn on top. ", "caption_bbox": [63, 352, 397, 411]}, {"image_id": 4, "file_name": "691_04.png", "page": 5, "dpi": 300, "bbox": [412, 92, 764, 334], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The Linear Graph shows a log-transformed duration of each event classification in a linear temporal view. Hue is used to indicate event classification, and event duration is double-encoded using size. ", "caption_bbox": [428, 352, 762, 411]}, {"image_id": 5, "file_name": "691_05.png", "page": 6, "dpi": 300, "bbox": [413, 93, 763, 435], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The Raw Data View displays sensor data using 3 line graphs. The highlighted region corresponds to a PE classification, and the white regions before and after the event are 30 second buffers for improved contextualization. ", "caption_bbox": [428, 449, 762, 508]}, {"image_id": 6, "file_name": "691_06.png", "page": 6, "dpi": 300, "bbox": [62, 92, 415, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The Stream Graph illustrates the flow of event classifica- tion frequency over the analysis duration. ", "caption_bbox": [63, 227, 397, 255]}, {"image_id": 7, "file_name": "691_07.png", "page": 7, "dpi": 300, "bbox": [412, 92, 765, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Stacked bar representation of cardiorespiratory behaviour prior to the suspicion of infection. ", "caption_bbox": [428, 282, 762, 310]}], "692": [{"image_id": 0, "file_name": "692_00.png", "page": 1, "dpi": 300, "bbox": [62, 350, 764, 634], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A pseudo-perspective view of two time-series plots is integrated between two adjacent axes of a parallel-coordinates display. An independent translucent parallel-coordinates panel connects the two time-series plots and allows the analysis of trends in time as well as the exploration of changes in the relationship between the two time-dependent attributes. ", "caption_bbox": [63, 644, 762, 687]}, {"image_id": 1, "file_name": "692_01.png", "page": 2, "dpi": 300, "bbox": [412, 93, 764, 355], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The temporal and multivariate data cube consists of independent design parameters (red columns) and simulated re- sponses (blue columns). Each simulation run (one row/slice) con- sists of a set of input values and the generated time-dependent out- put values. ", "caption_bbox": [428, 369, 762, 443]}, {"image_id": 2, "file_name": "692_02.png", "page": 3, "dpi": 300, "bbox": [427, 647, 767, 907], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Multiple vanishing-point widgets for adjacent parame- ters in the same parallel-coordinates plot. The vanishing point of the right widget was moved to the right to focus on the left time- series plot. ", "caption_bbox": [428, 917, 762, 976]}, {"image_id": 3, "file_name": "692_03.png", "page": 4, "dpi": 300, "bbox": [412, 93, 767, 367], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Two vanishing-point widgets which show the same time- series plots. The relationship between the two clusters in the two times-series plots gets inverted between the two time steps. ", "caption_bbox": [428, 377, 762, 420]}, {"image_id": 4, "file_name": "692_04.png", "page": 4, "dpi": 300, "bbox": [427, 443, 767, 693], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The parallel-coordinates panel connects two different time steps of the two adjacent time-series plots to reveal delays between the time-dependent attributes. The orange and green clus- ters on the left side seem to form at about the same point in time but the relationship between the axes gets inverted over time. ", "caption_bbox": [428, 703, 762, 777]}, {"image_id": 5, "file_name": "692_05.png", "page": 5, "dpi": 300, "bbox": [62, 305, 402, 705], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Multiple adjacent vanishing-point widgets are opened and shown in a merged view. The axes of the vanishing-point widget display the same local time step (top), but can also be configured to show an individual time step at each axis (bottom). ", "caption_bbox": [63, 715, 397, 774]}, {"image_id": 6, "file_name": "692_06.png", "page": 6, "dpi": 300, "bbox": [45, 92, 787, 546], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A snapshot of our application showing a crash simulation data set. (a) The constraint set widget, containing the two predefined and one user-defined data subsets. (b) The parallel-coordinates canvas displays a subset of the attributes, whereas the activated overview shows them all. (c) The parameter repository displays mainly time-dependent parameter. (d) Multiple canvases showing different kinds of plots. ", "caption_bbox": [63, 556, 762, 615]}, {"image_id": 7, "file_name": "692_07.png", "page": 7, "dpi": 300, "bbox": [62, 116, 398, 538], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Selection and brushing in action. (a) A subset of the data records has been selected by the range sliders of the rightmost axis and thus showed in blue. Some outliers are being brushed in the right time-series plot, turned orange, and appeared as new subset in the list on the left. (c) By brushing on the parallel-coordinates panel of the vanishing-point plot, another subset is defined in green. ", "caption_bbox": [63, 549, 397, 638]}, {"image_id": 8, "file_name": "692_08.png", "page": 8, "dpi": 300, "bbox": [427, 287, 767, 427], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The vanishing-point plot shows an ideal dam displace- ment over time (see Displacement_0,_1,_2). The displacement at- tribute expresses the shift of the individual points in their respec- tive direction (0 \u2192 x, 1 \u2192 y, 2 \u2192 z). The sample points with the largest displacements at the end of the fill process are shown in orange. They are located in the upper center of the dam (see Posi- tion_x,_y,_z \u2013 x along the dam, x = 0 at the dam\u2019s horizontal center, z = 0 at the top of the dam , +y in direction towards the reservoir). ", "caption_bbox": [428, 437, 762, 557]}], "693": [{"image_id": 0, "file_name": "693_00.png", "page": 4, "dpi": 300, "bbox": [454, 561, 737, 734], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Alternative representations of \u2018before\u2019 and \u2018after\u2019 time series. ", "caption_bbox": [428, 748, 762, 776]}, {"image_id": 1, "file_name": "693_01.png", "page": 4, "dpi": 300, "bbox": [62, 92, 695, 505], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The overall design is illustrated.", "caption_bbox": [307, 517, 517, 530]}, {"image_id": 2, "file_name": "693_02.png", "page": 6, "dpi": 300, "bbox": [62, 92, 695, 480], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The design illustrated with dynamic arcs to show causal relationships between the species. Arc thickness reflects the magnitude of the causal effect. ", "caption_bbox": [63, 492, 762, 520]}, {"image_id": 3, "file_name": "693_03.png", "page": 8, "dpi": 300, "bbox": [62, 92, 415, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Mean grades for the higher-order explanations given by study participants under the four conditions. Means of both high and low quantitative participants are shown. ", "caption_bbox": [63, 340, 397, 384]}], "694": [{"image_id": 0, "file_name": "694_00.png", "page": 5, "dpi": 300, "bbox": [479, 341, 718, 539], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Adjacency matrix of a scale-free network (used in user study). ", "caption_bbox": [428, 559, 762, 587]}, {"image_id": 1, "file_name": "694_01.png", "page": 6, "dpi": 300, "bbox": [108, 331, 351, 453], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: 2D scatterplot showing the correlation between the topo- logical parameter of the degree of nodes and the detected dynami- cal parameter for activity. ", "caption_bbox": [63, 465, 397, 508]}, {"image_id": 2, "file_name": "694_02.png", "page": 6, "dpi": 300, "bbox": [62, 91, 755, 243], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Activity plot of dynamics on an excitable scale-free network which has adjacency matrix in Figure 1 with n = 300 nodes, k = 2, 500 time steps, and parameters f = 0.01 and p = 0.1. (b) Brushing left-most nodes of linear structure in activity plot after zooming in. (c) Highlighting the brushed nodes in degree map exhibits that the selection represents the hubs. ", "caption_bbox": [63, 251, 762, 294]}, {"image_id": 3, "file_name": "694_03.png", "page": 6, "dpi": 300, "bbox": [469, 331, 721, 499], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Mean-field prediction for the numerical results from Fig- ure 3 (p has same value, i.e., p \u2248 0.1). The qualitative agreement about the relationship derived in Figure 3 is clearly visible. ", "caption_bbox": [428, 511, 762, 554]}, {"image_id": 4, "file_name": "694_04.png", "page": 6, "dpi": 300, "bbox": [429, 587, 752, 736], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) A network with tree topology (root is a hub) and (b) respective co-activation plot with p = 0.1, f = 0.01. The co- activation plot with color-coded topological distances to the hub exhibits the pattern that each cluster consists of nodes of equal dis- tance to the hub. ", "caption_bbox": [428, 745, 762, 819]}, {"image_id": 5, "file_name": "694_05.png", "page": 7, "dpi": 300, "bbox": [70, 91, 764, 248], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) Selecting sequentially the four dominant hubs in degree map and (b-e) examining the co-activation plot (p = 0.1, f = 0.01) with color-coded topological distances to the selected hub reveals an interference pattern of propagation waves around the two largest hubs. ", "caption_bbox": [63, 257, 762, 285]}, {"image_id": 6, "file_name": "694_06.png", "page": 8, "dpi": 300, "bbox": [429, 579, 759, 724], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Co-activation patterns of the biggest hub (out-degree) in the cat cortical network. The merging part at the top in the co- activation plot includes nodes having distance 1 to the selected hub. ", "caption_bbox": [428, 734, 762, 778]}, {"image_id": 7, "file_name": "694_07.png", "page": 8, "dpi": 300, "bbox": [64, 348, 383, 647], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) Selecting first-level modules in the adjacency matrix (b) reveals matching clusters in the co-activation plot (p = 0.1, f = 0.01). Selecting one clusters and (d) re-computing the co-activation plot for that clusters reveals less obvious sub-clusters (c) that some- what match second-level modules. ", "caption_bbox": [62, 656, 396, 730]}, {"image_id": 8, "file_name": "694_08.png", "page": 8, "dpi": 300, "bbox": [429, 348, 736, 493], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Co-activation patters of two modules in the cat cortical network for p = 0.1, f = 0.005. In the co-activation plot, the two clusters are not clearly separated, as they seem to merge at the top. ", "caption_bbox": [428, 503, 762, 546]}, {"image_id": 9, "file_name": "694_09.png", "page": 8, "dpi": 300, "bbox": [62, 91, 690, 248], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) Selecting a cluster in the co-activition plot and (b,c) re-computing the co-activation plot for the selection reveals sub-clusters with interference pattern for Hubs 3 and 4 similar to that of original clusters. (d) Eigenvalue plot for MDS projection used to compute the co-activation plot for selected cluster. ", "caption_bbox": [63, 257, 762, 300]}], "695": [{"image_id": 0, "file_name": "695_00.png", "page": 1, "dpi": 300, "bbox": [167, 375, 660, 506], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The visualization of original (left) and anonymized (right) location-based social network (LBSN) data using GSUVis", "caption_bbox": [95, 516, 729, 529]}, {"image_id": 1, "file_name": "695_01.png", "page": 4, "dpi": 300, "bbox": [62, 92, 736, 396], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The list of analytic tasks are presented in rows. The column \u201cData\u201d shows whether the needed data dimension is available for performing the task. The columns P1 to P6 show the experts who mentioned the task. ", "caption_bbox": [63, 406, 762, 434]}, {"image_id": 2, "file_name": "695_02.png", "page": 5, "dpi": 300, "bbox": [115, 117, 710, 455], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The GSUVis system showing part of the Gowalla dataset before anonymization. It is composed of (a) Social Network Visualization (SocialArcs), and (b) Location Trajectory Visualization (TravelLines). ", "caption_bbox": [63, 466, 762, 494]}, {"image_id": 3, "file_name": "695_03.png", "page": 6, "dpi": 300, "bbox": [62, 92, 415, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Co-located and co-occurred locations for two selected check-in points (represented in green and red). ", "caption_bbox": [63, 249, 397, 277]}, {"image_id": 4, "file_name": "695_04.png", "page": 6, "dpi": 300, "bbox": [427, 778, 764, 910], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Anonymization detail on node degree and location trajec- tories. a) Increase in node degree, b) decrease in node degree, c) a star glyph with dense original points d) a star glyph with divergent rays. In star glyphs, direction and length of rays is based on the angle and Euclidean distance of original points to the anonymized point. ", "caption_bbox": [428, 921, 762, 1010]}, {"image_id": 5, "file_name": "695_05.png", "page": 7, "dpi": 300, "bbox": [115, 117, 712, 415], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The GSUVis system showing part of the Gowalla dataset after loading anonymized data. SocialArcs and TravelLines represent data before and after anonymization. Trajectory strands (T1, T2, and T3) are explained in \u00a76. ", "caption_bbox": [63, 427, 762, 455]}], "696": [{"image_id": 0, "file_name": "696_00.png", "page": 4, "dpi": 300, "bbox": [62, 92, 755, 440], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An overview of our design process. Four distinct channels played a role in BubbleNet\u2019s design, the first was previous work, and the second and fourth were various users in two distinct settings, both research and operational. The third channel involved a network analyst from a university. Each channel involved different sets of users and data, but the final BubbleNet design in c) and deployments all occurred due to the interaction of outcomes and user feedback across all of these channels. ", "caption_bbox": [63, 456, 762, 515]}, {"image_id": 1, "file_name": "696_01.png", "page": 5, "dpi": 300, "bbox": [67, 116, 764, 580], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The BubbleNet dashboard labeled by its corresponding encodings: a) location map based on a Dorling cartogram, b) temporal chart and heatmap, c) attribute bullet bar charts, d) record details table, and e) selection overview. ", "caption_bbox": [63, 590, 762, 618]}, {"image_id": 2, "file_name": "696_02.png", "page": 6, "dpi": 300, "bbox": [62, 92, 681, 436], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Most elements of the BubbleNet dashboard are interactive and update all other views accordingly. For example, selecting four different countries shows significantly different patterns in the hourly heatmap. ", "caption_bbox": [63, 441, 762, 469]}, {"image_id": 3, "file_name": "696_03.png", "page": 8, "dpi": 300, "bbox": [62, 92, 677, 366], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Final results of a system usability survey of nine different users, both network analysts and managers. The average score of the dashboard is 75, above the average usability score of 68 [Sau11]. ", "caption_bbox": [63, 380, 762, 408]}], "697": [{"image_id": 0, "file_name": "697_00.png", "page": 1, "dpi": 300, "bbox": [62, 588, 764, 786], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visual debugging techniques enable inspection of program state and interaction logic for a reactive data visualization in Vega. Designers author (a) a declarative specification to produce (b) an interactive visualization. (c) Tooltips on the visualization provide intro- spection into visual encodings while viewing a past state via (d) replay. Recorded interactions are shown in (e) an overview and (f) a timeline. (g) A time series shows the variability of data attributes in (h) the backing datasets. ", "caption_bbox": [63, 519, 762, 578]}, {"image_id": 1, "file_name": "697_01.png", "page": 3, "dpi": 300, "bbox": [78, 118, 744, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) An excerpt of the Vega JSON specification and (b) a corresponding design schematic for (c) an interactive index chart. Event streams capture mousemove events that are passed through an inverted scale transform and stored in a signal. The signal parameterizes data transforms to select an index point and normalize stock price time-series data. ", "caption_bbox": [63, 344, 762, 387]}, {"image_id": 2, "file_name": "697_02.png", "page": 5, "dpi": 300, "bbox": [63, 117, 751, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The overview, timeline, and signal annotations after performing interactions. (a) The overview provides insight into different interaction patterns. (b) Stepping within a pulse allows users to see intermediate states of an interaction. The second scatterplot shows a brush representing the new brush_start and old brush_end. (c) Dependencies are shown as red outlines on hover. (d) Signal annotations overlay the visualization, with fill color encoding temporality: from darkest (past), through red (current), to lightest (future). ", "caption_bbox": [63, 370, 762, 429]}, {"image_id": 3, "file_name": "697_03.png", "page": 6, "dpi": 300, "bbox": [62, 92, 737, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) An index chart interactively normalizes stock price time-series, (b) but a data transformation error zeros out the indexed price, flatlining the chart. (c) An excerpt of the specification shows the distribution of lines identified by participants as the source of the error. ", "caption_bbox": [63, 327, 762, 355]}, {"image_id": 4, "file_name": "697_04.png", "page": 7, "dpi": 300, "bbox": [87, 92, 764, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) As the user pans the visualization, the axes stretch and distort the plot. This occurs due to an interdependency in the definition of the signals responsible for setting the range of the scale. (b) The min signal uses the old values of both min and max to compute its new value, whereas (c) the max signal uses the new min value and the old max value, thus causing the difference to drift. (d) An excerpt of the specification indicates the problematic lines and shows the distribution of lines identified by participants as the source of the error. ", "caption_bbox": [63, 408, 762, 467]}, {"image_id": 5, "file_name": "697_05.png", "page": 8, "dpi": 300, "bbox": [62, 92, 737, 401], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Scale definitions are extracted from the scatterplot signal for the color encoding. The signal is initialized as an empty object, causing (a) the brush to display but leaving the points grey. When a point is clicked, (b) scatterplot is defined and (c) the brush works correctly for all future interactions. (d) An excerpt of the specification displays the distribution of lines identified as the source of the error. ", "caption_bbox": [63, 406, 762, 449]}, {"image_id": 6, "file_name": "697_06.png", "page": 9, "dpi": 300, "bbox": [64, 116, 397, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Average ratings for each debugging technique, by task (shape) and overall (lines), with one standard deviation (gray). ", "caption_bbox": [63, 262, 397, 290]}], "698": [{"image_id": 0, "file_name": "698_00.png", "page": 4, "dpi": 300, "bbox": [62, 92, 713, 542], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The MCV system interface. The panels are placed beyond the screen and can be brought in with a gesture.", "caption_bbox": [122, 553, 702, 566]}, {"image_id": 1, "file_name": "698_01.png", "page": 5, "dpi": 300, "bbox": [481, 117, 729, 831], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The evolution of the edit-selection feature. a) The selec- tion rectangle with circular handles that can be dragged to edit the edges. b) Each finger in a pinch gesture control the movement of an edge of the selection rectangle. Here, movement of the fingers in x controls the edges. c) The entire space adjacent to an edge outside the rectangle controls the edge. Here, the finger translation increases the selection size. d) The arrow that replaces the handles on selection rectangles. e) The count label depicts the number of se- lected items. \u201cFilters On\" label signifies that at least one dynamic query filter is active in the tools menu. ", "caption_bbox": [428, 846, 762, 996]}], "699": [{"image_id": 0, "file_name": "699_00.png", "page": 4, "dpi": 300, "bbox": [62, 92, 764, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview of the extensions for structured brushing. A: A scatterplot with a regular 4 \u00d7 4 grid (value-based). The constrained brush (a) is moved vertically across 4 predefined intervals. The initial position and all consequent positions (dashed brushes) are shown. B: A scatterplot with a percentile 4 \u00d7 4 grid (rank-based). C: Parallel coordinates with a one-dimensional \u201cquartile grid\u201d enabled for both axes. The brush (c) is placed over the first strip of the grid (compare (c) with the brush (b)). D: A scatterplot with three percentile brushes with respect to the horizontal dimension. E: The two percentile brushes are combined using a logical AND operation. The user can grab the intersection and move both brushes. ", "caption_bbox": [62, 280, 761, 370]}, {"image_id": 1, "file_name": "699_01.png", "page": 4, "dpi": 300, "bbox": [62, 389, 764, 540], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of the extensions for structured brushing. A: A scatterplot with the three circular percentile brushes. B: Mahalanobis brushes (l, m, and n) select the same number of data points like the brushes (i), (j), and (k) in A, respectively. Note that usually a Mahalanobis brush changes its shape when moved. C: Outliers from the distribution are not selected by the Mahalanobis brush. D: An animated brush is defined, and the animation is started (changes are observed in the linked views, for example, in Figures 3 and 6). More examples are provided in the accompanying video. ", "caption_bbox": [62, 550, 761, 624]}, {"image_id": 2, "file_name": "699_02.png", "page": 5, "dpi": 300, "bbox": [427, 116, 762, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Path of the brush (r), which was moved in Figure 2 (D), is analyzed in a linked scatterplot. Left: The Trace View re- veals differences between the values of the three center points. One point (red rectangle) is selected for additional inspection. Right: The cross-hair is placed at the position selected in the Trace View. It shows the one standard deviation spread from the mean in both directions. The values show the difference to the bounding box of the brushed data; the high difference (1.5) towards the top is the reason for the skewness in the midrange path at this position. ", "caption_bbox": [428, 336, 762, 471]}, {"image_id": 3, "file_name": "699_03.png", "page": 6, "dpi": 300, "bbox": [62, 92, 415, 343], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The mean value for the brushed data is shown in parallel coordinates. The table below the view shows additional statistics. ", "caption_bbox": [63, 354, 397, 382]}, {"image_id": 4, "file_name": "699_04.png", "page": 6, "dpi": 300, "bbox": [412, 93, 764, 343], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The cross-hair shows the one standard deviation spread. It moved form the last position (dashed cross-hair). The animation helps in perceiving the transition. ", "caption_bbox": [428, 354, 762, 397]}, {"image_id": 5, "file_name": "699_05.png", "page": 7, "dpi": 300, "bbox": [427, 116, 762, 364], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Brushed view (green border): The view shows a scat- terplot with a percentile 1x10 grid, and the current brush position. Linked view: The spread for the y-dimension is 1.5829 as shown in the statistical table. ", "caption_bbox": [428, 375, 762, 434]}, {"image_id": 6, "file_name": "699_06.png", "page": 7, "dpi": 300, "bbox": [62, 116, 399, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Left: The actual midrange path in brown and the ref- erence path in black. Right: The relative difference plot shows the relative difference between actual (red) and reference (black) cen- ter and spread. The relative difference plot is shown for several selected animation frames. ", "caption_bbox": [63, 319, 397, 393]}, {"image_id": 7, "file_name": "699_07.png", "page": 8, "dpi": 300, "bbox": [427, 353, 762, 656], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Using the Mahalanobis brush to highlight structured data. Note how this would be impossible/highly inconvenient with a conventional, screen space techniques. ", "caption_bbox": [428, 669, 762, 712]}, {"image_id": 8, "file_name": "699_08.png", "page": 8, "dpi": 300, "bbox": [62, 92, 764, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A screenshot from the analysis of the main shafts, torques and stiffness parameters.", "caption_bbox": [177, 298, 648, 311]}, {"image_id": 9, "file_name": "699_09.png", "page": 9, "dpi": 300, "bbox": [84, 116, 382, 372], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Three different views of the same parallel coordinates plot, each showing the 10% percentile brush placed at different positions of the differential split ratio. ", "caption_bbox": [63, 382, 397, 425]}], "700": [{"image_id": 0, "file_name": "700_00.png", "page": 1, "dpi": 300, "bbox": [61, 718, 763, 1054], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Small multiples summarising spatial (red), temporal (blue) and descriptive (green) signatures of several collections of reported road incident data from London. The three perspectives \u2013 space, time and description \u2013 are superimposed on one another to form space-filling single graphic composites. They indicate, for example, that incidents involving pedal cycles are highly spatially concentrated around central London, although reasonably evenly so, and typically happen during the daytime and mid-week. This is distinct from incidents involving taxis, which have a similar spatial concentration, but typically happen towards the end of the week and in the evening. ", "caption_bbox": [62, 636, 761, 710]}, {"image_id": 1, "file_name": "700_01.png", "page": 3, "dpi": 300, "bbox": [113, 93, 764, 414], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Left. Designs for each level of abstraction: high abstraction, measures of central tendency; medium abstraction, aggregation into bins; low abstraction, maximum detail necessary. Right. Possible abstraction-combinations: occlusion and interference between views is probable where all perspectives are displayed at low abstraction. Where all perspectives are at high abstraction, the graphics are perhaps most obviously \u2018single\u2019 composites. ", "caption_bbox": [62, 432, 761, 491]}, {"image_id": 2, "file_name": "700_02.png", "page": 6, "dpi": 300, "bbox": [62, 93, 760, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Test screens showing juxtaposed (left) and superimposed (right) design equivalents. Group membership is assigned by selecting a button that temporarily appears when graphics are hovered. Once assigned to a group, the graphic\u2019s outline changes from grey to the green (group 1), purple (group 2) or blue (group 3). A timer and information on the total number of graphics assigned to groups appears top right. The timer counts down from 180 seconds, after this it continues with a negative sign and in red (right). Notice that the juxtaposed views are necessarily smaller, but graphics are equal in absolute area. ", "caption_bbox": [62, 318, 761, 392]}, {"image_id": 3, "file_name": "700_03.png", "page": 8, "dpi": 300, "bbox": [118, 93, 709, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Multiple variable model output. Outcome: binary success rate. Predictors: s vs. j, abstraction-combination, perspective-change and completion time. Odds-Ratios (exp(b)) and associated 95% CIs are presented. \u20180\u2019 odds represents no effect, thus where the CIs cross \u20180\u2019, there is very little confidence in the estimated coefficient (b). ", "caption_bbox": [62, 353, 761, 396]}], "701": [{"image_id": 0, "file_name": "701_00.png", "page": 2, "dpi": 300, "bbox": [90, 728, 404, 950], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An example of the resulting TCP curves for a given dose, with three different RT treatment strategies. ", "caption_bbox": [63, 962, 397, 990]}, {"image_id": 1, "file_name": "701_01.png", "page": 3, "dpi": 300, "bbox": [93, 92, 764, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The proposed Visual Analytics approach for the Prediction of RT Treatment Response in TCP Modeling. With colors, we denote the four requirements (T1-T4) described in Section 2, which are our contributions to the workflow employed in clinical research. ", "caption_bbox": [63, 296, 762, 324]}, {"image_id": 2, "file_name": "701_02.png", "page": 4, "dpi": 300, "bbox": [454, 647, 770, 904], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Dataset extracted from the experiment of Gibbs et al. (blue points), and linear relation between ADC and CD (red line) [GPT07], without uncertainty. Incorporating ADC uncer- tainty results in a set of linear fits (shown with grayscale: dark denotes higher probability). ", "caption_bbox": [428, 916, 762, 990]}, {"image_id": 3, "file_name": "701_03.png", "page": 5, "dpi": 300, "bbox": [99, 92, 764, 395], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Quantification and interactive exploration of the ADC-induced uncertainty and its effect on TCP modeling (T1).", "caption_bbox": [99, 407, 722, 420]}, {"image_id": 4, "file_name": "701_04.png", "page": 5, "dpi": 300, "bbox": [452, 810, 768, 948], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Exploration of the parameter-induced TCP model sen- sitivity (T2), for three different approaches ( 1 - 3 ). ", "caption_bbox": [428, 962, 762, 990]}, {"image_id": 5, "file_name": "701_05.png", "page": 6, "dpi": 300, "bbox": [62, 92, 415, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Probing the model curve at a specific TCP value, to inspect the required dose per-voxel (heated-body colormap) and the respective variability (circular glyphs) (T2). ", "caption_bbox": [63, 287, 397, 330]}, {"image_id": 6, "file_name": "701_06.png", "page": 6, "dpi": 300, "bbox": [412, 93, 767, 747], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Partitioning a patient cohort based on TCP treatment re- sponse (T3). The cluster analysis view adapted from [RvdHD\u2217 15] is used for the visual optimization of clustering. ", "caption_bbox": [428, 762, 762, 805]}, {"image_id": 7, "file_name": "701_07.png", "page": 7, "dpi": 300, "bbox": [95, 92, 764, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Reversing the workflow in TCP modeling (T4).", "caption_bbox": [262, 249, 560, 262]}, {"image_id": 8, "file_name": "701_08.png", "page": 8, "dpi": 300, "bbox": [94, 348, 758, 670], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Results from the case study.", "caption_bbox": [310, 683, 510, 696]}, {"image_id": 9, "file_name": "701_09.png", "page": 8, "dpi": 300, "bbox": [62, 92, 756, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Schematic representation of the evaluation results, for each one of the tasks of Section 2.", "caption_bbox": [162, 312, 660, 325]}], "702": [{"image_id": 0, "file_name": "702_00.png", "page": 1, "dpi": 300, "bbox": [63, 361, 763, 526], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: From a set of iso-contours (inlay), our method computes an abstract visualization of the uncertainty that is carried by this set (left). The visualization is further refined by showing correlations, i.e. probabilities for the joint occurrence of iso-contours in a selected region (black circle) and other locations along the main trends (color coded in the right image). ", "caption_bbox": [63, 538, 762, 581]}, {"image_id": 1, "file_name": "702_01.png", "page": 3, "dpi": 300, "bbox": [62, 92, 764, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of our method: (a) Input set of iso-contours. (b) Statistical model of the corresponding signed distance functions in the principal component basis, represented by confidence ellipses and geometric cluster medians. (c) Contour variability plot, obtained by transforming ellipses and medians back to domain space (with cluster strengths indicated by a bar plot). (d) Visualization of global correlations in the orange cluster by picking a circular region (black) and color coding the conditional probability of contours going through other regions, given that they go through this picked region. ", "caption_bbox": [63, 311, 762, 385]}, {"image_id": 2, "file_name": "702_02.png", "page": 4, "dpi": 300, "bbox": [62, 92, 415, 373], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Standard deviation of distance functions: Four different ensembles of equally spaced iso-contours (black lines) and corre- sponding confidence bands (colored green) are shown. Bands in- dicate the regions within one standard deviation from the mean contour. Below each image is a corresponding 1D plot of equally spaced points and an error bar showing mean and standard devia- tion. ", "caption_bbox": [63, 384, 397, 488]}, {"image_id": 3, "file_name": "702_03.png", "page": 5, "dpi": 300, "bbox": [66, 119, 342, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Illustration of L(D) (Eq. (2)). For a set of 1D SDF- like functions D = {d1 , ..., d5 } (gray lines), the \u201cband\u201d covered by their zero-contours (thick, black lines) is the region where L(D) = cmin{\u2212 cmini di , cmaxi di } \u2265 0. ", "caption_bbox": [62, 276, 396, 335]}, {"image_id": 4, "file_name": "702_04.png", "page": 5, "dpi": 300, "bbox": [430, 116, 761, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Domain and SDF space: Each contour in an ensem- ble (orange lines) corresponds to a point in SDF-space (orange points). A band of standard deviation corresponds to an axis- aligned rectangular region in SDF-space (orange regions), which is determined by the confidence ellipse that is fitted to the points in SDF-space (purple line). The contours going through the black and blue circle, respectively, form slabs in SDF-space. From their intersection, a joint occurrence in the two circles can be computed. ", "caption_bbox": [428, 284, 762, 404]}, {"image_id": 5, "file_name": "702_05.png", "page": 6, "dpi": 300, "bbox": [412, 93, 765, 343], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Color coding of conditional probabilities. (a) Spaghetti plots comprised of shifted circles of the same size, and (c) the same circles cut off and mirrored at the center vertical axis. (b+d) The bands corresponding to one standard deviation \u03b1 = 1 (bounded by green lines). Only when coloring the bands according to f (z) in a region around point y with radius t (black circle), the contours\u2019 structures can be revealed. ", "caption_bbox": [428, 354, 762, 458]}, {"image_id": 6, "file_name": "702_06.png", "page": 6, "dpi": 300, "bbox": [62, 92, 415, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Coloring of bands for the contour cluster in Fig. 5. Top: A unicolored variability plot with band and median. Middle: Color coding of the probability function f (z) at every domain point, and at points in the band (bottom). ", "caption_bbox": [63, 403, 397, 462]}, {"image_id": 7, "file_name": "702_07.png", "page": 7, "dpi": 300, "bbox": [427, 113, 756, 573], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Spatial variability of an ensemble of 500 hPa geopo- tential height contour lines. The ECMWF ENS forecast from 00:00 UTC, 15 October 2012, valid at 00:00 UTC, 20 October 2012, is shown. (a) Geopotential height contours (m) of the en- semble control forecast (5600 m highlighted in red). Note the dis- tinct trough over Spain (blue axis). (b) Spaghetti plot of the 5600 m contour lines of all 51 ensemble members, colored by cluster membership. (c) Contour variability plot. ", "caption_bbox": [428, 583, 762, 703]}, {"image_id": 8, "file_name": "702_08.png", "page": 8, "dpi": 300, "bbox": [62, 92, 763, 347], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Contour variability plot for an ensemble of 3D wind speed contours representing the jet stream. 50 ms\u22121 iso-surfaces of the ECMWF ENS forecast from 00:00 UTC, 15 October 2012, valid at 18:00 UTC, 19 October 2012 are shown. For comparison, the same scene as in Fig. 6 in [RKSW15] has been chosen. The images show (a) a \u201c3D spaghetti\u201d plot of all 51 iso-surfaces (colored by cluster membership), (b) the median contours of six clusters identified by the algorithm, and (c-h) the median contour (opaque) and the outer boundary of the \u201cband\u201d (transparent) for the six clusters. Note that clusters 5 and 6 contain one outlier each. ", "caption_bbox": [63, 353, 762, 431]}, {"image_id": 9, "file_name": "702_09.png", "page": 9, "dpi": 300, "bbox": [84, 116, 742, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Spatial correlations. (a) Correlations in the purple cluster of Fig. 8c. (b) Correlations of a cluster of 680 m contour lines of geopotential height at 925 hPa show a behavior similar to the idealized case in Fig. 7b (forecast from 00:00 UTC, 17 October 2012, valid at 12:00 UTC, 21 October 2012). (c) Contour lines of 0 \u00b0C of the temperature field at 850 hPa are clustered into a single cluster and three outliers (same forecast as in Fig. 8). (d) Except for the westernmost part of the analyzed region, these lines are almost entirely uncorrelated. ", "caption_bbox": [63, 436, 762, 495]}], "703": [{"image_id": 0, "file_name": "703_00.png", "page": 3, "dpi": 300, "bbox": [462, 659, 730, 852], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Block-based hierarchies of software, hardware, and memory on GPUs, corresponding to each other along the horizontal direction. ", "caption_bbox": [428, 864, 762, 892]}, {"image_id": 1, "file_name": "703_01.png", "page": 4, "dpi": 300, "bbox": [62, 165, 398, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Mapping of algorithmic hierarchy onto GPU thread hierarchy.", "caption_bbox": [63, 369, 397, 382]}, {"image_id": 2, "file_name": "703_02.png", "page": 4, "dpi": 300, "bbox": [442, 236, 749, 395], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The data flowchart of the algorithm. Yellow boxes stand for the three CUDA kernels; pink ellipses stand for the data in the GPU global memory, and green arrows indicate the direction of data fetches or writes. ", "caption_bbox": [428, 409, 762, 452]}, {"image_id": 3, "file_name": "703_03.png", "page": 5, "dpi": 300, "bbox": [515, 662, 676, 766], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A 3D MC cell (with 8 corner voxels) and its three distinct edges.", "caption_bbox": [428, 777, 762, 790]}, {"image_id": 4, "file_name": "703_04.png", "page": 6, "dpi": 300, "bbox": [121, 181, 340, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: neighborMappingTable maps an edgeID (of one of the 12 edges of an MC cell) to a distinct edge of a neighbour cell indicated by the four integers stored in edgemap.xyzw. ", "caption_bbox": [428, 262, 762, 305]}, {"image_id": 5, "file_name": "703_05.png", "page": 7, "dpi": 300, "bbox": [79, 93, 415, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Performance comparison for dynamic isovalues among nvsdk, hpmc, and PMB using a variety of input volumes. n2 and f ail are as in Table 2. ", "caption_bbox": [428, 566, 762, 609]}, {"image_id": 6, "file_name": "703_06.png", "page": 8, "dpi": 300, "bbox": [62, 92, 415, 416], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Rendering results of PMB for a variety of datasets (from left to right and top to bottom): backpack, hazelnut, Xmastree, ncat, aneurism, tra- becula, macoessix, abdomen, manix, melanix, visFemale, stagBeetle, flower, rm, beechnut, and cayley. ", "caption_bbox": [63, 421, 397, 479]}, {"image_id": 7, "file_name": "703_07.png", "page": 9, "dpi": 300, "bbox": [495, 117, 697, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: 2D illustration of the limitation: vertex merging is only per- formed within each individual block separately, but not performed across the block boundaries (red). ", "caption_bbox": [428, 281, 762, 324]}], "704": [{"image_id": 0, "file_name": "704_00.png", "page": 2, "dpi": 300, "bbox": [62, 92, 415, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Four defect types on a 2D slice of a 3DCT volume com- ing from an interrupted in situ tensile test. ", "caption_bbox": [63, 300, 397, 328]}, {"image_id": 1, "file_name": "704_01.png", "page": 3, "dpi": 300, "bbox": [124, 116, 702, 276], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An overview of the workflow for 4DCT interrupted in situ tensile-test data-analysis.", "caption_bbox": [174, 287, 647, 300]}, {"image_id": 2, "file_name": "704_02.png", "page": 4, "dpi": 300, "bbox": [461, 116, 731, 461], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The pipeline for measurement and classification of indi- vidual defects. Defect types are assigned based on the combination of criteria C1-C7 that are evaluated: C1 - matrix fracture (a), C2, C3, C4 - fiber/matrix debonding (b), C5, C6 - fiber pull-out (c), and C7 - fiber fracture (d). ", "caption_bbox": [428, 473, 762, 547]}, {"image_id": 3, "file_name": "704_03.png", "page": 5, "dpi": 300, "bbox": [62, 117, 401, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Characteristics important for the defect classification: the original defect shape (a); object oriented bounding box (b); length, width, and depth (c); direction (d); endpoints (e). ", "caption_bbox": [63, 251, 397, 294]}, {"image_id": 4, "file_name": "704_04.png", "page": 5, "dpi": 300, "bbox": [447, 116, 745, 356], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The Defect Viewer shows the original image of Dataset 1 as context with highlighted fiber pull-outs, matrix fractures, and fiber fractures. ", "caption_bbox": [428, 367, 762, 410]}, {"image_id": 5, "file_name": "704_05.png", "page": 6, "dpi": 300, "bbox": [427, 652, 766, 903], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The Defect Density Map isosurface outlines the high- defect density region in 3D for Dataset 1 (a). A slice with defects highlighted in yellow is shown using the 3D Magic Lens (b). A zoom-in into the region of interest demonstrates that the isosurface efficiently separates regions containing high amount of defects (c). ", "caption_bbox": [428, 916, 762, 990]}, {"image_id": 6, "file_name": "704_06.png", "page": 6, "dpi": 300, "bbox": [62, 92, 731, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Four Defect Density Maps displaying distributions of fiber pull-outs (a), matrix fractures (b), fiber breakages (c), and fiber/matrix debondings (d) in Dataset 1. ", "caption_bbox": [63, 301, 762, 329]}, {"image_id": 7, "file_name": "704_07.png", "page": 7, "dpi": 300, "bbox": [436, 116, 757, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: To calculate the Final Fracture Surface rays are casted from top to bottom. An average position of defects is calculated for each ray (a). The resulting height-map is then smoothed and reconstructed into a 3D mesh (b). ", "caption_bbox": [428, 277, 762, 336]}, {"image_id": 8, "file_name": "704_08.png", "page": 7, "dpi": 300, "bbox": [62, 116, 401, 207], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The Final Fracture Surfaces show differences between the final fractures of Datasets 1 (a), 2 (b), and 3 (c). Dataset 2 has the fracture surface that is flatter than for Datasets 2 and 3. ", "caption_bbox": [63, 220, 397, 263]}, {"image_id": 9, "file_name": "704_09.png", "page": 8, "dpi": 300, "bbox": [62, 92, 734, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The usage scenarios of the 3D Magic Lens: (a) Comparing two stages (244 N and 260 N) of Dataset 2 in the side-by-side mode. Defects are highlighted for the 260 N stage. (b) Comparing a Defect Density Map of all defects to the Density Maps for matrix fractures (blue), fiber/matrix debondings (green), fiber pull-outs (yellow), and fiber fractures (red). The 440 N stage of Dataset 3 is used. (c) Exploring the Density Map isosurface with high density (red) together with the 2D slice of CT data in the context of isosurface with low density (blue). ", "caption_bbox": [63, 378, 762, 437]}, {"image_id": 10, "file_name": "704_10.png", "page": 9, "dpi": 300, "bbox": [62, 116, 768, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: A series of Defect Density Maps showing the defect development process from the first to the last stage for the Dataset 3. Direct volume rendering is used. A color transfer function is shown on the top. ", "caption_bbox": [63, 284, 762, 312]}], "705": [{"image_id": 0, "file_name": "705_00.png", "page": 3, "dpi": 300, "bbox": [65, 365, 394, 536], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview over input, preprocessing pipeline and the data explored by GEMSe. ", "caption_bbox": [63, 547, 397, 575]}, {"image_id": 1, "file_name": "705_01.png", "page": 4, "dpi": 300, "bbox": [63, 92, 756, 509], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Main interface of GEMSe: (a) cluster tree view, (b) detail view, (c) slice view, (d) cluster example view, (e) favorite bar, (f) scatterplot view, (g) histogram view, (h) magic lens showing original image ", "caption_bbox": [63, 519, 762, 547]}, {"image_id": 2, "file_name": "705_02.png", "page": 5, "dpi": 300, "bbox": [412, 92, 764, 435], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Datasets used in our case studies: Attenuation image (a1) and three K-Edge element maps (a2-a4) of the synthetic K- Edge dataset. Attenuation image (b1) and dark field image (b2) of the middle slice along x-y-axis of the rock crystal TLGI-XCT scan. Channels 26(c1), 46(c2), 125(c3) and 176(c4) from the SalinasA hyperspectral dataset. ", "caption_bbox": [428, 445, 762, 534]}, {"image_id": 3, "file_name": "705_03.png", "page": 7, "dpi": 300, "bbox": [70, 92, 764, 398], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: GEMSe with the rock crystal dataset loaded. Clusters (a1-7) show an overview of the result ensemble. For the selected cluster a1, the enlarged representative is shown in the detail view (b) along with exemplary label images (c) from that cluster. Histograms d1-d3 show the distribution of \u03b3svm for clusters (a2, a5, a6). Histograms d4-d6 show the distribution of the number of channels used in SVM for clusters (a2, a3, a4). The filter set in d6 affects the cluster tree view (e), also clusters rated suitable and unsuitable are highlighted here, and their parameter ranges are color-mapped accordingly in histograms d3 and d6. ", "caption_bbox": [63, 409, 762, 483]}, {"image_id": 4, "file_name": "705_04.png", "page": 9, "dpi": 300, "bbox": [65, 495, 394, 646], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) label image with best kappa value, the ground truth is shown in the magic lens for comparison. (b-d) objective measure histograms. ", "caption_bbox": [63, 658, 397, 701]}, {"image_id": 5, "file_name": "705_05.png", "page": 9, "dpi": 300, "bbox": [70, 92, 765, 405], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Cluster view (a) of the synthetic K-Edge dataset. Histogram b1 shows the \u03b3erw distribution of node a2, b2 that of a5, b3 demonstrates the filtered histogram, (c) the resulting cluster tree view. Histogram (d) shows the object count for node a1, the scatterplot (e) correlates \u03b3erw (x-axis) to the object count (y-axis). ", "caption_bbox": [63, 415, 762, 458]}, {"image_id": 6, "file_name": "705_06.png", "page": 9, "dpi": 300, "bbox": [65, 737, 395, 865], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparison of ranked parameter ranges for all case studies. ", "caption_bbox": [63, 876, 397, 904]}], "706": [{"image_id": 0, "file_name": "706_00.png", "page": 1, "dpi": 300, "bbox": [62, 761, 764, 1054], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: High (top) and low entropy (bottom) viewpoints of ribbon representations of 4 protein structural domains used as test structures in our evaluation. Every domain is a member of 1 of 4 classes in the top level of the CATH hierarchy (from left to right: alpha and beta, mainly beta, few secondary structures, and mainly alpha). ", "caption_bbox": [63, 717, 762, 761]}, {"image_id": 1, "file_name": "706_01.png", "page": 5, "dpi": 300, "bbox": [71, 127, 754, 415], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: The 4 domains used for evaluation in this work, sorted by increasing complexity (in terms of #SS, the number of distinct sec- ondary structure elements [#SS equals N f \u2212 1 to exclude the back- ground feature]). ", "caption_bbox": [62, 655, 396, 714]}, {"image_id": 2, "file_name": "706_02.png", "page": 6, "dpi": 300, "bbox": [441, 332, 755, 645], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The consistency at which participants picked a viewpoint was lowest for 1kobA02, indicating that participants were most indecisive for that structure. ", "caption_bbox": [428, 671, 762, 715]}, {"image_id": 3, "file_name": "706_03.png", "page": 7, "dpi": 300, "bbox": [77, 92, 764, 463], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The difference I(vi ) \u2212 I(v j ) in viewpoint entropy for viewpoints vi and v j (in units of standard deviation), plotted against the fraction of times vi was chosen over v j for the full model (left) and all individual test structures (right). In these plots, a point denotes a single viewpoint and the curves show the best-fit logistic regression. ", "caption_bbox": [63, 489, 762, 533]}, {"image_id": 4, "file_name": "706_04.png", "page": 8, "dpi": 300, "bbox": [63, 92, 759, 477], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The distribution of viewpoint entropies (top) and spatial locations on the viewing sphere (bottom), for all viewpoints chosen by experts. For every structure, an image of the lowest and highest entropy viewpoint chosen by experts was added to the plot. All of these viewpoints except for the low entropy viewpoint of 1aym400 are either close or antipodal (on the sphere of camera positions) to the highest (lowest) entropy viewpoints from Figure 1. ", "caption_bbox": [63, 499, 762, 558]}], "707": [{"image_id": 0, "file_name": "707_00.png", "page": 1, "dpi": 300, "bbox": [68, 411, 758, 614], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Cytosplore. Screenshot of our system with four widgets (adaptive settings, overview (a), embedding (b) and heatmap (c)), repre- senting the workflow. Views can be rearranged or additional views of these types added. ", "caption_bbox": [63, 633, 762, 662]}, {"image_id": 1, "file_name": "707_01.png", "page": 3, "dpi": 300, "bbox": [63, 92, 764, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Abstraction of the identified high-level tasks (a), consisting of grouping and naming points, as well as the detailed subtasks. b shows the major lineage delineation (high-level clustering) and c the phenotypical subset exploration and identification (low-level clustering). ", "caption_bbox": [63, 314, 762, 343]}, {"image_id": 2, "file_name": "707_02.png", "page": 5, "dpi": 300, "bbox": [66, 92, 764, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Phenotype Specification Workflow and its three major user-facing blocks; major-lineage delineation, subset exploration and identification. SPADE, A-tSNE, GMS and Tag-labeled blocks form the computational glue between user-driven parts. GMS requires a kernel- bandwidth definition, but is computed in real time, merging subset exploration and identification. ", "caption_bbox": [63, 323, 762, 367]}, {"image_id": 3, "file_name": "707_03.png", "page": 5, "dpi": 300, "bbox": [62, 806, 396, 957], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: SPADE Detail. Meta-clusters can be selected by brushing (left) and annotated (dialog-box and right). ", "caption_bbox": [63, 968, 397, 997]}, {"image_id": 4, "file_name": "707_04.png", "page": 6, "dpi": 300, "bbox": [63, 92, 415, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: tSNE Visualization of a single lineage, as scatterplot (a) and as density plot (b). Erroneous selections can be identified in the scatterplot (blue circles) due to the low expression in the discerning marker for this lineage. Visual clusters can easily be distinguished in the density plot. ", "caption_bbox": [62, 299, 396, 373]}, {"image_id": 5, "file_name": "707_05.png", "page": 6, "dpi": 300, "bbox": [412, 93, 762, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Detail of the Heatmap View showing marker expres- sions and variation. Variation is encoded in the amount of paint in each box. Columns are ordered by similarity as indicated by the dendrogram on top. ", "caption_bbox": [428, 299, 762, 358]}, {"image_id": 6, "file_name": "707_06.png", "page": 7, "dpi": 300, "bbox": [70, 793, 397, 881], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: GPU Mean-Shift Steps. a shows the density map, with increasing density from white to black. b shows the corresponding (absolute) gradients, using the m and c channels of the cmyk color space to indicate the x and y components of the gradient vectors, respectively. c shows the final segmentation using unique colors for each partition. d shows the clustered points using the same coloring as in c. ", "caption_bbox": [63, 892, 397, 997]}, {"image_id": 7, "file_name": "707_07.png", "page": 7, "dpi": 300, "bbox": [436, 745, 764, 941], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Performance of our Mean-Shift Clustering. The graph shows that the grid size has the biggest impact on performance, while the number of points and kernel size only contribute slightly. ", "caption_bbox": [428, 953, 762, 997]}, {"image_id": 8, "file_name": "707_08.png", "page": 9, "dpi": 300, "bbox": [64, 93, 415, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Subsets Created in the Evaluation by Participant A with the traditional workflow (a) and using Cytosplore (b). Note that a consists of only 54% of the cells assigned to the lineage, due to incomplete clustering using ACCENSE. ", "caption_bbox": [62, 233, 396, 292]}], "708": [{"image_id": 0, "file_name": "708_00.png", "page": 1, "dpi": 300, "bbox": [63, 692, 764, 905], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The workflow of our method for a model of HIV surrounded with blood plasma proteins. (a) The entire dataset is shown. The blood serum (shown in red) is occluding the virus. (b) Clipping objects are added to selectively clip molecules to reveal the HIV capsid. (c) The illustrator decides to show more of the matrix proteins (shown in blue), so their clipping is disabled. However, they are now occluding the view of the capsid. (d) The probabilistic clipping has been used to selectively remove those matrix proteins occluding the capsid, but some of them are left in the scene to indicate the presence of this type of protein on the virus membrane. The capsid has been clipped with view space clipping to reveal its internal structure. ", "caption_bbox": [63, 562, 762, 651]}, {"image_id": 1, "file_name": "708_01.png", "page": 2, "dpi": 300, "bbox": [412, 93, 759, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Various types of protein molecules and (b) their em- bedding into a mesoscale model. It is a demanding task to deter- mine which molecular types are visible and how many of their in- stances are shown. ", "caption_bbox": [428, 330, 762, 389]}, {"image_id": 2, "file_name": "708_02.png", "page": 4, "dpi": 300, "bbox": [63, 92, 763, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An illustration of the workflow with the visibility equalizer. (1) Clipping objects filter out elements in the data based on their type and location. (2) The clipping is applied in serial, i.e., the output of a clipping object constitute the input of the next one. The visibility information of the entire scene is routinely collected and updated in the visibility equalizer to keep the viewer informed about the current state of the data. (3) The clipping parameters of a given clipping object can later on be refined by interacting with the bar charts of the visibility equalizer to offer more control on the clipping, such as fuzziness. ", "caption_bbox": [63, 307, 762, 381]}, {"image_id": 3, "file_name": "708_03.png", "page": 5, "dpi": 300, "bbox": [68, 93, 415, 222], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Illustration of the visibility equalizers. Each molecular ingredient has its own stacked bar showing (a) instances visible from the current viewpoint, (b) occluded instances, (c) instances clipped away by the clipping objects. ", "caption_bbox": [63, 239, 397, 298]}, {"image_id": 4, "file_name": "708_04.png", "page": 5, "dpi": 300, "bbox": [412, 92, 764, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Illustration of the falloff function mechanism: (a) ele- ments located further than distance d from the clipping object are clipped, (b) elements between the clipping object and d are uni- formly clipped, (c) elements are removed gradually based on their distance to the clipping object to further customize its behaviour. ", "caption_bbox": [428, 265, 762, 339]}, {"image_id": 5, "file_name": "708_05.png", "page": 6, "dpi": 300, "bbox": [412, 93, 714, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Illustration of contextual anchoring with an HIV particle. Despite the cutaway, some of the glyco-proteins (in yellow) are dis- played and their surrounding lipid molecules (green) is preserved as contextual information. ", "caption_bbox": [428, 253, 762, 312]}, {"image_id": 6, "file_name": "708_06.png", "page": 6, "dpi": 300, "bbox": [63, 92, 415, 255], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: View-space clipping, (a) shows the full HIV Capsid, (b) shows the uniformly distributed clipping, (c) demonstrate the aper- ture effect and (d) shows the results of the 2D distance transform of the clipping mask. ", "caption_bbox": [63, 269, 397, 328]}, {"image_id": 7, "file_name": "708_07.png", "page": 7, "dpi": 300, "bbox": [79, 134, 382, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The principle of the depth-bias used for contextual an- choring. The dark bars represents the depth values of the mask from the side, in one dimension. Elements in grey correspond to poten- tial occluders, while elements in red and green correspond to oc- cludees. The red type is subject to contextual anchoring. (a) With- out contextual anchoring, the depth of occluders (grey) is overlap- ping the depth of the mask and will therefore be discarded. (b) With contextual anchoring, the depth of the occludees (red) is shifted so that context elements (purple) no longer overlap the focus and re- main unclipped. ", "caption_bbox": [63, 282, 397, 432]}, {"image_id": 8, "file_name": "708_08.png", "page": 8, "dpi": 300, "bbox": [63, 92, 761, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Advanced clipping options in real test systems. (a) A falloff function is used to gradually clip serum molecules (red) from bottom to top to reveal the HIV capsid, with ghosting to give cues about the overall concentration. (b) Selective clipping is used to reveal the location of ribosome (blue) in a model of Mycoplasma mycoides. (c) Internal structures of a immature HIV model are shown by several clipping objects. On the left, the visibility equalizer is shown. ", "caption_bbox": [63, 347, 762, 406]}, {"image_id": 9, "file_name": "708_09.png", "page": 8, "dpi": 300, "bbox": [67, 589, 399, 925], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: HIV clipped with a plane. Contextual anchoring is used to indicate the proximity of envelope proteins (dark blue) with the lipid membrane (grey) The dark spots represent shadows projected into interior proteins. ", "caption_bbox": [63, 938, 397, 997]}], "709": [{"image_id": 0, "file_name": "709_00.png", "page": 2, "dpi": 300, "bbox": [412, 93, 742, 390], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A visual abstraction of viral genomic data, where red boxes denote nucleotides that do not match the reference genome. Rows are individual reads from NGS, while columns are ge- nomic positions. Two positions (i, j) are checked for mutation co- occurrence. ", "caption_bbox": [428, 410, 762, 484]}, {"image_id": 1, "file_name": "709_01.png", "page": 5, "dpi": 300, "bbox": [74, 121, 388, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Our initial prototype to identify pairwise correlations between all positions i (x-axis) and j (y-axis). The matrix view (a) shows these co-occurences, and the overview (b) provides a hori- zontal overview of the space. The super-zoom window (c) highlights the coordinates and co-occurrence metric currently under the cur- sor, while the bar chart (d) presents the proportion of reads at a selected pair of positions. The legend (e) presents the 2D color key. ", "caption_bbox": [63, 345, 397, 449]}, {"image_id": 2, "file_name": "709_02.png", "page": 6, "dpi": 300, "bbox": [63, 92, 415, 370], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A close-up of a co-occurrence summary between two po- sitions (counts included for explanation). The positions being com- pared are mapped to rectangles, with both reference (green) and variant (red) nucleotide types. The links show the correlated pro- portion of reads between the two positions. The gray arcs represent the proportion of reads that overlap one position but not the other. ", "caption_bbox": [63, 394, 397, 483]}, {"image_id": 3, "file_name": "709_03.png", "page": 7, "dpi": 300, "bbox": [104, 92, 764, 667], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An overall view of SIV (\u00a77.2) loaded into CooccurViewer. Annotations (a) denote regions of the genome that have some biological context, and the overview (b) denotes positions of significant co-occurrence, summarizing the three metrics (\u00a75) using color. The correlation diagrams (c) provide a representation of correlation between pairs of positions, and some details (d) about metric values. The current position\u2019s summary of correlations (e) is given on the left, with small-multiple representations. The sliders (f) control the thresholds for the interest metrics and filters the co-occurrences shown in the visualization. ", "caption_bbox": [63, 679, 762, 753]}, {"image_id": 4, "file_name": "709_04.png", "page": 8, "dpi": 300, "bbox": [412, 93, 751, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: In this SIV sample, a cluster of correlated mutations ap- pears within the Nef protein (top-right, dark yellow bar), known to harbor viral escape. Variants at positions 9,645 and 9,651 are in- versely co-occurring with reference reads (mid-top), while reads at positions 9,646 and 9,651 are positively correlated (mid-bottom). ", "caption_bbox": [428, 406, 762, 480]}, {"image_id": 5, "file_name": "709_05.png", "page": 8, "dpi": 300, "bbox": [63, 92, 415, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: For this particular sample of an H5N1 viral population, a strong inverse correlation is identified between mutations at 738 to non-variant reads at 728, as well as a inverse correlation be- tween positions 728 and 788, validating the results presented by the reference study [WD\u2217 13]. ", "caption_bbox": [63, 406, 397, 480]}], "710": [{"image_id": 0, "file_name": "710_00.png", "page": 5, "dpi": 300, "bbox": [433, 892, 758, 968], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Symmetric tensors going down left (R = 0) edge of trian- gle, from (D, S) = (1, 0) (left) to (D, S) = (0, 1) (right). ", "caption_bbox": [428, 970, 762, 1003]}, {"image_id": 1, "file_name": "710_01.png", "page": 6, "dpi": 300, "bbox": [68, 887, 390, 962], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Traceless tensors going right along bottom (D = 0) edge, from (S, R) = (1, 0) (left) to (S, R) = (0, 1) (right). ", "caption_bbox": [62, 964, 396, 997]}, {"image_id": 2, "file_name": "710_02.png", "page": 6, "dpi": 300, "bbox": [435, 119, 758, 193], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Rotationally symmetry going up along right (S = 0) edge, from (R, D) = (1, 0) (left) to (R, D) = (0, 1) (right). ", "caption_bbox": [428, 196, 762, 229]}, {"image_id": 3, "file_name": "710_03.png", "page": 6, "dpi": 300, "bbox": [429, 232, 762, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: At D = 0.9, around |R| = S glyphs shrink to an area unrelated to their determinant when their geometry is strictly determined by the (pseudo)eigenvectors (top row). Using quasi- eigenvectors (bottom row) fixes this. ", "caption_bbox": [428, 306, 762, 369]}, {"image_id": 4, "file_name": "710_04.png", "page": 7, "dpi": 300, "bbox": [430, 520, 761, 620], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Negation legibility is demonstrated by negating D (to the right, where blue shows contraction) and R (to the left, which reverses the rotation direction). ", "caption_bbox": [428, 622, 762, 670]}, {"image_id": 5, "file_name": "710_05.png", "page": 7, "dpi": 300, "bbox": [426, 119, 763, 453], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Palette of our proposed tensor glyphs, shown over faint streamlines indicating the vector field created by (36). ", "caption_bbox": [428, 457, 762, 490]}, {"image_id": 6, "file_name": "710_06.png", "page": 8, "dpi": 300, "bbox": [62, 581, 399, 918], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Two superimposed Sullivan vortices, shown with white arrows near center. Yellow circles indicate critical points. Two glyphs with a determinant close to zero are indicated by a white outline. The visualization domain is from \u22121.125 to 1.125 in x and y. ", "caption_bbox": [63, 919, 397, 997]}, {"image_id": 7, "file_name": "710_07.png", "page": 9, "dpi": 300, "bbox": [62, 116, 764, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Flow (from left to right) past a square obstacle creating a train of vortices.", "caption_bbox": [199, 324, 625, 342]}], "711": [{"image_id": 0, "file_name": "711_00.png", "page": 2, "dpi": 300, "bbox": [63, 92, 414, 176], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The same sequence using value and size.", "caption_bbox": [101, 192, 357, 205]}, {"image_id": 1, "file_name": "711_01.png", "page": 3, "dpi": 300, "bbox": [72, 93, 413, 434], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The visual stimuli used in our experiments. Each 1D plot is mapped using the visual channels taken from semiology of graph- ics [Ber83]. ", "caption_bbox": [63, 447, 397, 490]}, {"image_id": 2, "file_name": "711_02.png", "page": 4, "dpi": 300, "bbox": [63, 92, 639, 374], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Interface for Experiment 1: How ordered is it? Shape is tested in this example.", "caption_bbox": [190, 384, 635, 397]}, {"image_id": 3, "file_name": "711_03.png", "page": 5, "dpi": 300, "bbox": [412, 92, 764, 440], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Correctness (top) and response time (bottom) of each visual channel in Experiment 1. Significant differences are listed above each bar, with (mean, median) values indicated below. Error bars show 95% confidence intervals. ", "caption_bbox": [428, 454, 762, 513]}, {"image_id": 4, "file_name": "711_04.png", "page": 7, "dpi": 300, "bbox": [95, 93, 413, 506], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Measured orderedness (correlation coefficient) versus perceived orderedness. Points are the perceived orderedness for each visual channel given its measured orderedness (power scale). Average plotted as dashed line. ", "caption_bbox": [63, 520, 397, 579]}, {"image_id": 5, "file_name": "711_05.png", "page": 8, "dpi": 300, "bbox": [428, 466, 764, 855], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Ranking of visual channels from worst (7th) to best (1st) for each experiment based on performance (top) and response time (bottom). These measurements are compared to the participants\u2019 perceived ranking. ", "caption_bbox": [428, 868, 762, 927]}, {"image_id": 6, "file_name": "711_06.png", "page": 8, "dpi": 300, "bbox": [62, 464, 397, 808], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparing the effects of visual channel against error rate (top) and response time (bottom) in Experiment 2. Significant differences are listed above each bar, with (mean,median) values indicated below. Error bars show 95% confidence intervals. ", "caption_bbox": [63, 822, 397, 881]}, {"image_id": 7, "file_name": "711_07.png", "page": 8, "dpi": 300, "bbox": [63, 92, 639, 401], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Interface for Experiment 2: Which is smallest? Which is largest?", "caption_bbox": [224, 412, 600, 425]}], "712": [{"image_id": 0, "file_name": "712_00.png", "page": 1, "dpi": 300, "bbox": [100, 365, 728, 519], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: 67% encoded using different visual cues: angle, arc length, and area; just arc length; just angle; and just area.", "caption_bbox": [114, 532, 711, 545]}, {"image_id": 1, "file_name": "712_01.png", "page": 2, "dpi": 300, "bbox": [412, 93, 691, 312], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The three different encodings representing data in a pie or donut chart: central angle, wedge area, and arc length. ", "caption_bbox": [428, 331, 762, 359]}, {"image_id": 2, "file_name": "712_02.png", "page": 3, "dpi": 300, "bbox": [75, 92, 764, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A sampling of pie and donut charts used in infographics, taken from examples found on Visual.ly [Vis15]. (a) exploded pie chart, (b) chart with varying segment radii, (c) pie chart constructed with an icon, and (d) nested donut chart. ", "caption_bbox": [63, 331, 762, 359]}, {"image_id": 3, "file_name": "712_03.png", "page": 3, "dpi": 300, "bbox": [63, 375, 764, 636], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A sampling of charts used in the study of pie and donut chart encodings. The top row all represent 67%, while the bottom row all represent 33%. ", "caption_bbox": [63, 649, 762, 677]}, {"image_id": 4, "file_name": "712_04.png", "page": 4, "dpi": 300, "bbox": [63, 92, 415, 423], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Screenshot of the survey showing a baseline pie chart.", "caption_bbox": [70, 451, 390, 464]}, {"image_id": 5, "file_name": "712_05.png", "page": 5, "dpi": 300, "bbox": [63, 92, 764, 363], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Means and confidence intervals for log error by chart type (ANOVA: F(5, 4650) = 121.955, p < 0.001). ", "caption_bbox": [428, 560, 762, 588]}, {"image_id": 6, "file_name": "712_06.png", "page": 6, "dpi": 300, "bbox": [63, 92, 761, 259], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The distribution of error segmented by the percentage amount shown in each chart. All charts except the angle charts show an increase in error as the percentage shown in the chart increases. ", "caption_bbox": [63, 273, 762, 301]}, {"image_id": 7, "file_name": "712_07.png", "page": 7, "dpi": 300, "bbox": [64, 379, 761, 581], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The distribution of error segmented by the second self-reported encoding preference for pie charts. People using angle did better in the angle-only condition than ones who reported using area or arc length. Black lines represent the means for each encoding preference per chart type, error bars show 95% confidence intervals. ", "caption_bbox": [63, 595, 762, 639]}, {"image_id": 8, "file_name": "712_08.png", "page": 7, "dpi": 300, "bbox": [68, 92, 764, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: At the beginning and end of the study, participants were asked about the encoding they primarily used to interpret pie and donut charts. These are compared with self-reported answers from an earlier study [Eel26]. ", "caption_bbox": [63, 335, 762, 363]}, {"image_id": 9, "file_name": "712_09.png", "page": 9, "dpi": 300, "bbox": [66, 92, 765, 320], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The distribution of amount of error per radius size. The error bars show 95% CI and the middle black lines represent the mean for each radius. ", "caption_bbox": [63, 335, 762, 363]}], "713": [{"image_id": 0, "file_name": "713_00.png", "page": 3, "dpi": 300, "bbox": [437, 653, 751, 842], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The two datasets for the authoring tasks.", "caption_bbox": [466, 856, 723, 869]}, {"image_id": 1, "file_name": "713_01.png", "page": 3, "dpi": 300, "bbox": [65, 270, 396, 458], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Tiles in different colors. Two boxes of these tiles were provided to participants. ", "caption_bbox": [63, 469, 397, 497]}, {"image_id": 2, "file_name": "713_02.png", "page": 3, "dpi": 300, "bbox": [82, 755, 383, 945], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Room setup: 1) computer screen; 2) box to cover canvas during tangible reading test; 3) boxes of tiles; 4) canvas for tiles authoring; 5) dataset; and 6) computer used for Excel. ", "caption_bbox": [63, 957, 397, 1000]}, {"image_id": 3, "file_name": "713_03.png", "page": 5, "dpi": 300, "bbox": [63, 116, 757, 457], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Bar charts authored by participants with the tangible tiles and Microsoft Excel. A larger version is available on our supplementary website at http://innovis.cpsc.ucalgary.ca/supplemental/Comparing-excel-tiles/. ", "caption_bbox": [63, 469, 762, 497]}, {"image_id": 4, "file_name": "713_04.png", "page": 6, "dpi": 300, "bbox": [62, 92, 768, 282], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Actions over time for each participant, using Excel and using tiles, for authoring and editing tasks: loading data ( ), visual mapping ( ), presentation mapping ( ), exploring the tool ( ), coloring the bar ( ) and verifying the visualization ( ). ", "caption_bbox": [63, 293, 762, 321]}, {"image_id": 5, "file_name": "713_05.png", "page": 7, "dpi": 300, "bbox": [62, 116, 402, 202], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Distribution of time spent in average by all participants by conditions. Vertical axis represents the time in milliseconds, hor- izontal axis the different participant\u2019s actions. Times were com- puted from analysis of the video codings. ", "caption_bbox": [63, 213, 397, 272]}, {"image_id": 6, "file_name": "713_06.png", "page": 8, "dpi": 300, "bbox": [62, 315, 402, 415], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Freedom of the visual variables [Mac86] by tool (Excel, Tiles, Programming). Filled circles represent a variable that can be modified by the tool operator, transparent circles are setup by default according the template chosen in Excel; the line illustrates dependancies between variables. ", "caption_bbox": [63, 425, 397, 499]}, {"image_id": 7, "file_name": "713_07.png", "page": 8, "dpi": 300, "bbox": [63, 92, 730, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Schema representing interrelations between operations along the first part of the InfoVis pipelinel [JD13]. The lock icon represents operations that cannot be separated; red lines represent linked operations with tiles, and blue lines linked operations within Excel. ", "caption_bbox": [63, 275, 762, 303]}], "714": [{"image_id": 0, "file_name": "714_00.png", "page": 3, "dpi": 300, "bbox": [62, 116, 764, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An example of the clustering exploration approaches provided in our framework. (A) Choropleth clustering map with the thumbnail plot displaying the clustering criteria. (B) Scatterplot in PCA projection mode with scope lens enabled. (C) PCP area profiler of the data values of the local highlighted counties. (D) PCP area profiler of the data values from all counties. (E) PCP area profiler showing the data values from counties of the blue cluster. (F) Rose plots of all five clusters. ", "caption_bbox": [63, 303, 762, 362]}, {"image_id": 1, "file_name": "714_01.png", "page": 4, "dpi": 300, "bbox": [62, 92, 764, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Here we demonstrate the coherent clustering color mapping when both maps have five clusters. By maintaining label consistency for generalized clustering comparison, users can quickly tell that the clustering results are similar while at the same time noting that there exists differences in the northern part of the US (the red circle). However, it is still difficult for users to figure out exactly how many differences there are. ", "caption_bbox": [63, 316, 762, 375]}, {"image_id": 2, "file_name": "714_02.png", "page": 5, "dpi": 300, "bbox": [427, 116, 764, 352], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An example of the Triple-D View (Drag and Drop clus- tering Difference View). The top three maps are three different clus- tering results using K-means but with different initial centroids re- spectively. The bottom two maps are the comparison results of the first two and last two respectively. When users click on a certain unit in the comparison result, indicator lines will be drawn on top of them to mark the corresponding units from the two compared clustering results. ", "caption_bbox": [428, 362, 762, 482]}, {"image_id": 3, "file_name": "714_03.png", "page": 5, "dpi": 300, "bbox": [62, 120, 399, 498], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparing two clustering results for the same group of 15 objects. In the top figure, the left part is a clustering result \u2126 with three clusters, and the right part is a clustering result \u21260 with four clusters. The bottom figure is the illustration of the comparison process. The value on the arrow indicates the proportion of the sub- cluster in that step. ", "caption_bbox": [62, 508, 396, 597]}, {"image_id": 4, "file_name": "714_04.png", "page": 6, "dpi": 300, "bbox": [62, 92, 764, 531], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: An example of exploration between clusterings in different geographical locations. The top and bottom row are results based on surroundings of King County and Harris County respectively. (A) Selections with the circle selection tool. (B) Local clustering results and its clustering statistics. (C) Rose plots for the local clusters, the variables from the top in a clock-wise manner are: percentage of other languages, percentage of education level above high school, mean time to work, and per capita income. ", "caption_bbox": [63, 551, 762, 610]}, {"image_id": 5, "file_name": "714_05.png", "page": 7, "dpi": 300, "bbox": [74, 116, 754, 563], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An example of partial clustering for units of different geographical feature. The left map shows the units with all positive population change and the right map shows the units with all negative population change in 2014. ", "caption_bbox": [63, 574, 762, 602]}, {"image_id": 6, "file_name": "714_06.png", "page": 8, "dpi": 300, "bbox": [62, 92, 764, 443], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: An example of scale effect on clustering around Cook County. (A) The Triple-D view of the clustering comparison regarding the scale change (B) The change of scales demonstrated in 4 colors (C) PCP area profiler for scale 1 and 2 (D) PCP area profiler for scale 1 and 3 (D) PCP area profiler for scale 1 and 4. ", "caption_bbox": [63, 462, 762, 505]}, {"image_id": 7, "file_name": "714_07.png", "page": 9, "dpi": 300, "bbox": [64, 116, 764, 468], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: An example of clustering results under different geographical resolution. (A) Clustering result, corresponding rose plot and PCA scatterplot in county level, (B) Clustering result, corresponding rose plot and PCA scatterplot under state level. Both use the same hierarchical clustering with 6 clusters. ", "caption_bbox": [63, 484, 762, 527]}], "715": [{"image_id": 0, "file_name": "715_00.png", "page": 3, "dpi": 300, "bbox": [62, 115, 766, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) Forward-time (T+ ) FTLE computation with ridge (red curve on orange sampling plane at t0 ), and reverse-time (T\u2212 ) FTLE with ridge (blue curve at t3 ). (b) A dense space-time stack of FTLE fields reveals space-time ridge surface (forward-time red, reverse-time blue). The intersection of forward and reverse space-time ridge surface yields the hyperbolic trajectory (space-time bifurcation line, green). (c) Repelling LCS / stable bifurcation manifold (red), and attracting LCS / unstable bifurcation manifold (blue) of bifurcation line (green). (d) Upper half: FTLE suffers from sampling issues (Buoyant Plumes dataset, cf. Section 5.3 and Figure 4(d)) and provides only an implicit determination of LCS. Lower half: Our streakline manifolds (black curves), in contrast, capture the LCS at high accuracy and are not subject to aliasing. (e) Close-up of region (black box) indicated in (d). ", "caption_bbox": [62, 280, 761, 385]}, {"image_id": 1, "file_name": "715_01.png", "page": 6, "dpi": 300, "bbox": [66, 116, 761, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Oscillating Gyre-Saddle dataset. (a) Our result by extracting the hyperbolic trajectory (green) as a space-time bifurcation line, with bifurcation manifolds (red, blue) representing the streak manifolds (LCS) of streak-based topology. FTLE slices (red: high, blue: low) from left to right: (t0 , T) = (4, 5), (6.5, \u22125), (9, \u22125), and (11.5, 5). Our hyperbolic trajectory extraction resides exactly at the intersection (arrow) of the attracting and repelling LCS, in contrast to integration-based extraction [SW10] (b), where errors tend to grow exponentially. There, the deviated white part of the extracted hyperbolic trajectory is located in a non-hyperbolic region, and, hence, it is not suitable there for extraction of streak manifolds. (c) The refinement approach for bifurcation line extraction (Section 3.2) causes a small deformation at both ends. However, this has typically, as in this case, no impact. Nevertheless, we extract longer bifurcation lines and trim them to the region of interest to avoid this. ", "caption_bbox": [62, 259, 761, 379]}, {"image_id": 2, "file_name": "715_02.png", "page": 7, "dpi": 300, "bbox": [75, 117, 749, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Buoyant Barrier Flow dataset. (a) Right FTLE slice: (t0 , T) = (10.7, 1), left slice: (t0 , T) = (11.5, \u22121). Hyperbolic trajectory by means of space-time bifurcation line (green) and repelling (red) and attracting (blue) LCS by space-time bifurcation manifolds fit well to LCS captured by FTLE ridges. (b) Corresponding visualization with right FTLE slice at t0 = 13.7 and left slice at t0 = 14.5. ", "caption_bbox": [62, 305, 761, 350]}, {"image_id": 3, "file_name": "715_03.png", "page": 8, "dpi": 300, "bbox": [149, 115, 674, 557], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Buoyant Plumes dataset in time range [2.5, 20.1], with two FTLE slices with (t0 , T) = (15, \u221215) and (20, \u221220). (a) HTs extracted as space-time bifurcation lines (green). (b) Early state of space-time bifurcation manifold integration for better insight into overall structure. (c) Final LCS representation by space-time bifurcation manifolds with transparency in the upper half to reveal internal structure. (d) Same as (c), but from the back for better comparison of FTLE slice and our streak manifolds (see also Figure 1(d) and (e)). ", "caption_bbox": [62, 564, 761, 624]}, {"image_id": 4, "file_name": "715_04.png", "page": 9, "dpi": 300, "bbox": [63, 742, 760, 888], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Comparison of techniques (Oscillating Gyre-Saddle dataset): (a) traditional dense computation (FTLE computation and ridge extraction), (b) our approach (Jacobian estimation, parallel vectors extraction, refinement, filtering, manifold integration), and (c) the ap- proach by Sadlo and Weiskopf (FTLE computation, ridge extraction, manifold integration) for different parameters with (d) respective error \u03b5 of the hyperbolic trajectories. Our approach is two orders of magnitude faster than the one based on dense FTLE, and faster than the one by Sadlo and Weiskopf without the issue of deviating HTs due to error growth. ", "caption_bbox": [62, 895, 761, 969]}, {"image_id": 5, "file_name": "715_05.png", "page": 9, "dpi": 300, "bbox": [95, 115, 727, 642], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Relation between streak manifolds (black) and FTLE ridges, by reverse-time pathlines (colors by FTLE), configuration from Figure 4. (a) Very strong spread (diverging red pathlines) with twist, captured by FTLE ridge and streak manifold at (i). (b) Two strong spreads (left and top), captured by FTLE ridge and streak manifold at (ii). (c) Slight divergence of pathlines but no separation, captured by FTLE ridge at (iii) but not by streak manifold. (d) Similar to (c) with stronger divergence, with FTLE ridge at (iv) but no streak manifold. FTLE ridges at (iii) and (iv) can be considered false positives, as indicated by our approach. ", "caption_bbox": [62, 650, 761, 724]}], "716": [{"image_id": 0, "file_name": "716_00.png", "page": 2, "dpi": 300, "bbox": [412, 93, 764, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Calculating persistent homology of a manifold M (left) with a height function f . The extended persistence diagram (right) serves as a fingerprint. ", "caption_bbox": [428, 308, 762, 351]}, {"image_id": 1, "file_name": "716_01.png", "page": 4, "dpi": 300, "bbox": [62, 92, 415, 438], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Different clusterings for several test data sets and the values of our global measure \u03c3Global . Higher values indicate that more geometrical-topological variation has been retained. ", "caption_bbox": [63, 449, 397, 492]}, {"image_id": 2, "file_name": "716_02.png", "page": 6, "dpi": 300, "bbox": [62, 92, 415, 775], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Clustering similarity graphs (top) and cluster maps for several \u201cIris\u201d data clusterings. ", "caption_bbox": [63, 787, 397, 815]}, {"image_id": 3, "file_name": "716_03.png", "page": 7, "dpi": 300, "bbox": [412, 92, 764, 965], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Clustering similarity graphs (top) and selected cluster maps for the \u201cOlive oils\u201d data. ", "caption_bbox": [428, 976, 762, 1004]}, {"image_id": 4, "file_name": "716_04.png", "page": 8, "dpi": 300, "bbox": [412, 93, 764, 546], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Selected clustering similarity graphs and cluster maps for the \u201cEl Ni\u00f1o\u201d data set. ", "caption_bbox": [428, 558, 762, 586]}], "717": [{"image_id": 0, "file_name": "717_00.png", "page": 1, "dpi": 300, "bbox": [62, 360, 764, 688], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Pathfinder visualizes multiple paths of a coauthor graph connecting Hanspeter Pfister and Ben Shneiderman. The paths are shown in a ranked list together with associated sets and attributes on the left (path list view). To its right, a node-link diagram shows the topology of the paths (path topology view). The path statistics view on the far right shows an overview of the properties of the paths. ", "caption_bbox": [63, 694, 762, 737]}, {"image_id": 1, "file_name": "717_01.png", "page": 3, "dpi": 300, "bbox": [412, 92, 764, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Four ways of visualizing paths in a graph, connecting the nodes A and D: (a) highlighting in a node-link diagram, (b) drawing only the subset of the graph connecting node A and D, (c) drawing a path list, (d) enumerating edges in a matrix. ", "caption_bbox": [428, 326, 762, 385]}, {"image_id": 2, "file_name": "717_02.png", "page": 5, "dpi": 300, "bbox": [62, 116, 398, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The advanced interface showing a query where the start node is either Hanspeter Pfister or Jarke van Wijk, the paths must not contain Jean-Daniel Fekete, and the last node is Ben Shneider- man or an author of the NodeTrix paper. ", "caption_bbox": [63, 205, 397, 264]}, {"image_id": 3, "file_name": "717_03.png", "page": 5, "dpi": 300, "bbox": [427, 724, 764, 884], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A path from the coauthor network connecting Jean- Daniel Fekete and Ben Shneiderman. The coauthored papers are treated as sets and visualized below the path. The CHI papers are aggregated\u2014only the strength of the connection can be estimated. We see that Catherine Plaisant is highly connected with Ben Shnei- derman. The TVCG papers show details: We can see who has coau- thored which papers. Below the sets, numerical attributes, such as the number of publications in each venue, are shown for each node. ", "caption_bbox": [428, 890, 762, 1010]}, {"image_id": 4, "file_name": "717_04.png", "page": 6, "dpi": 300, "bbox": [62, 92, 711, 399], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Path comparison and ranking. The second path (violet) is the reference path. Icons next to the nodes and sets in all paths indicate whether they are shared with the reference path. For example, the third path shares two CHI papers, one TVCG paper, and four authors. The rank columns show different scores by which the paths are ranked. Their order indicates score priority: First, paths are ranked by whether they contain Krzysztof Z. Gajos, second, by length, and third, by the average node degree. ", "caption_bbox": [63, 398, 762, 457]}, {"image_id": 5, "file_name": "717_05.png", "page": 7, "dpi": 300, "bbox": [427, 116, 764, 448], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The path topology view showing paths that connect Hanspeter Pfister and Ben Shneiderman. All neighbors of Tim Berners-Lee were added and are shown in white, indicating that they are not part of any path. Links to those nodes are stippled to distinguish them from links that occur in the path list. ", "caption_bbox": [428, 454, 762, 528]}, {"image_id": 6, "file_name": "717_06.png", "page": 7, "dpi": 300, "bbox": [62, 123, 393, 197], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Node-alignments that support path comparison. (a) All paths are aligned around a selected pivot node. (b) A layout that strives to put re-occurring nodes at the same horizontal position. ", "caption_bbox": [63, 201, 397, 244]}, {"image_id": 7, "file_name": "717_07.png", "page": 8, "dpi": 300, "bbox": [64, 500, 399, 866], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The query result in Pathfinder for paths connecting KRAS and MAPK3. The paths are ranked by set connection strength, which places the path KRAS-RAF1-MAP2K1-MAPK3 on top (no- tice the thick lines for the aggregated pathways). This path cor- responds to the ERK-MAPK signaling cascade. Associated copy number and mRNA expression data are shown as box plots. The expression dataset is expanded to investigate the expression across different tissue types in detail. The box plots show that the four genes are expressed in all displayed tissues, which emphasizes the importance of this path. ", "caption_bbox": [63, 871, 397, 1021]}], "718": [{"image_id": 0, "file_name": "718_00.png", "page": 2, "dpi": 300, "bbox": [62, 92, 739, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualizing collocated popular terms obtained from Wikinews in TimeArcs. Area graphs show how frequently the terms appear and are colored by term categorizations. Arcs highlight terms that appear together in the same articles. ", "caption_bbox": [63, 387, 762, 415]}, {"image_id": 1, "file_name": "718_01.png", "page": 4, "dpi": 300, "bbox": [429, 437, 759, 763], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Popular techniques to visualize entity evolutions: (a) stacked graph and (b) small multiples. Here, entities are terms ex- tracted from political blogs and color-coded by category: green for person, red for location, blue for organization, and yellow for mis- cellaneous data. The two above graphs are implemented in D3.js. ", "caption_bbox": [428, 774, 762, 848]}, {"image_id": 2, "file_name": "718_02.png", "page": 4, "dpi": 300, "bbox": [74, 717, 395, 913], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A schematic showing the main components of TimeArcs: computing the evolution of input entities, computing the relation- ships of ranked entities, selecting highly connected entities, and filtering entities. ", "caption_bbox": [63, 924, 397, 983]}, {"image_id": 3, "file_name": "718_03.png", "page": 5, "dpi": 300, "bbox": [427, 225, 752, 552], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The TimeArcs visualization applied to the IEEE VIS pub- lication co-authorship network of the top 50 researchers from 2010 to 2014 (i.e., the same data in Fig. 4). ", "caption_bbox": [428, 577, 762, 620]}, {"image_id": 4, "file_name": "718_04.png", "page": 6, "dpi": 300, "bbox": [427, 327, 762, 672], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Overview of political events in the past 10 years using TimeArcs. The top 100 terms were selected based on their sudden attention and degree centrality. Terms are color-coded by category: green for person, red for location, blue for organization, yellow for miscellaneous category. ", "caption_bbox": [428, 698, 762, 772]}, {"image_id": 5, "file_name": "718_05.png", "page": 6, "dpi": 300, "bbox": [62, 92, 772, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visualizing the IEEE VIS publication co-authorship network of the top 50 researchers between 2010 and 2014.", "caption_bbox": [108, 278, 717, 291]}, {"image_id": 6, "file_name": "718_06.png", "page": 6, "dpi": 300, "bbox": [62, 370, 399, 557], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualizing collaboration networks for \u201cMunzner, T.\u201d over the past 20 years (green for the InfoVis conference, red for VAST, and blue for SciVis). ", "caption_bbox": [62, 583, 396, 627]}, {"image_id": 7, "file_name": "718_07.png", "page": 7, "dpi": 300, "bbox": [427, 116, 771, 672], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visualizing the IMDB co-star network of the top actors from highly rated movies from 1980 to 2014. Boxes A, B, and C highlight actors appearing together in multiple seasons of a series. ", "caption_bbox": [428, 698, 762, 741]}, {"image_id": 8, "file_name": "718_08.png", "page": 8, "dpi": 300, "bbox": [67, 666, 391, 723], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: TimeArcs visualization for interactions around PCAF protein. (1), (2), and (3) in the figure are supporting evidences in literature of \u201cPCAF binds MAML\u201d. ", "caption_bbox": [63, 733, 397, 776]}, {"image_id": 9, "file_name": "718_09.png", "page": 8, "dpi": 300, "bbox": [412, 93, 756, 198], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: TimeArcs visualization for interactions around OPSD protein. (1) and (2) are conflicting evidences of OPSD and K+ in- teraction in 2003 and 2012 publications. ", "caption_bbox": [428, 208, 762, 251]}, {"image_id": 10, "file_name": "718_10.png", "page": 8, "dpi": 300, "bbox": [62, 92, 415, 574], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Visualizing the publication of new discoveries in protein interaction networks from 2002 to 2014. The colors encode differ- ent types of biochemical interactions. ", "caption_bbox": [63, 600, 397, 643]}], "719": [{"image_id": 0, "file_name": "719_00.png", "page": 1, "dpi": 300, "bbox": [65, 316, 758, 565], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Node-link diagram of an almost fully connected, bidirectional graph, originating from a NEST simulation based on a macaque\u2019s brain [GD07]. These images depict 32 vertices each of which represents a brain region. The edges are the regions\u2019 interconnectivity. Left: original graph; Right: the same graph after edge bundling; the edges are directed from purple to yellow. ", "caption_bbox": [63, 593, 762, 637]}, {"image_id": 1, "file_name": "719_01.png", "page": 3, "dpi": 300, "bbox": [62, 93, 414, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Edge bundling pipeline. The edges are clustered and then, per cluster task-parallel, bundled and drawn. ", "caption_bbox": [63, 274, 397, 302]}, {"image_id": 2, "file_name": "719_02.png", "page": 3, "dpi": 300, "bbox": [412, 92, 764, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Example of a DBSCAN cluster calculation [EKSX96], with minimal cluster size is 2. The dashed circles, each framing one data point, depict the destiny parameter eps. Whenever a data point falls within the radius of any existing point of the current cluster, it is added recursively. The result is a green and a purple cluster. The two black data points are marked as unclustered. ", "caption_bbox": [428, 308, 762, 397]}, {"image_id": 3, "file_name": "719_03.png", "page": 4, "dpi": 300, "bbox": [62, 92, 764, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Graph from Figure 1 shown with color-coded clusters consisting of similar edges; black edges are unclustered, i.e., not similar to any other. Left: Complete graph; Right: 6 example clusters, where the upper left depicts not a cluster, but all unclustered edges. ", "caption_bbox": [63, 336, 762, 364]}, {"image_id": 4, "file_name": "719_04.png", "page": 4, "dpi": 300, "bbox": [487, 382, 703, 504], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Segmented edges e1 and e2 . Example force calcula- tion for the 3rd segmentation point of e1 , assumed there is only                                 (3)        (3)        (3) one other relevant edge e2 : F(e1 ) = Fe (e1 ) + Fn (e1 ). All other points are static. Figure based on [HvW09b]. ", "caption_bbox": [428, 516, 762, 577]}, {"image_id": 5, "file_name": "719_05.png", "page": 5, "dpi": 300, "bbox": [432, 116, 751, 160], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Two bundles coming from the left become one bundle, with their widths stacked. (a) without an additional smoothing step. (b) with an additional smoothing. ", "caption_bbox": [428, 168, 762, 211]}, {"image_id": 6, "file_name": "719_06.png", "page": 6, "dpi": 300, "bbox": [62, 92, 666, 325], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A section of the graph shown in Figure 1 depicting different rendering styles: (a) edge rendering style, (b) bundle rendering style, line width represents the number of edges combined in this bundle, (c) bundle rendering style, line width represents the combined edge weight in this bundle. ", "caption_bbox": [63, 335, 762, 378]}, {"image_id": 7, "file_name": "719_07.png", "page": 7, "dpi": 300, "bbox": [427, 116, 762, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Dependency of the density parameter eps to runtime and number of clusters, within the useful range of eps values for this particular graph. This means from, \"there is first time a real clustering\" to, \"clusters start getting so small that there is no more bundling worth mentioning\". Additionally in the background the ratio of unclustered edges (dark) to clustered ones (bright) is de- picted. ", "caption_bbox": [428, 305, 762, 409]}], "720": [{"image_id": 0, "file_name": "720_00.png", "page": 1, "dpi": 300, "bbox": [104, 338, 719, 644], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An illustration of the experimental setting for comparing node-link and node-link-group visualizations from the perspective of participant enjoyment. In the first phase we studied the spontaneous interaction of participants with the posters installed in the back of the room. In this phase, experimenters are outside the room and participants are not aware this is part of the experiment. The second and third phases were conducted in the forefront area, where the laptop is located. ", "caption_bbox": [62, 652, 761, 711]}, {"image_id": 1, "file_name": "720_01.png", "page": 2, "dpi": 300, "bbox": [62, 92, 729, 491], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Examples of visualizations considered in this study. We investigate the enjoyability of relational data represented with node-link (left-side) and node-link-group (right-side) visualizations. ", "caption_bbox": [61, 502, 761, 530]}, {"image_id": 2, "file_name": "720_02.png", "page": 7, "dpi": 300, "bbox": [96, 332, 724, 548], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Summary plot of responses for phase 2. The orange vertical bars indicate the 95% confidence interval for the true overall enjoyment level of each response group. For questions 1, 4, and 6, the difference between the mean enjoyment level is statistically significant at p < 0.05; we highlight those significant distribution differences by drawing a red line segment between their means. ", "caption_bbox": [62, 566, 763, 609]}, {"image_id": 3, "file_name": "720_03.png", "page": 8, "dpi": 300, "bbox": [62, 92, 415, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: This figure shows the number of people who selected each specific reason to explain why they preferred one visualization over another. Each participant could select more than one option. ", "caption_bbox": [62, 311, 396, 354]}], "721": [{"image_id": 0, "file_name": "721_00.png", "page": 1, "dpi": 300, "bbox": [62, 551, 764, 734], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Exploration of high-dimensional data with IF , FI -Tables: based on selected items, the user can find similar items and relevant features; and based on selected features, the user can find similar features and relevant items. ", "caption_bbox": [63, 519, 762, 549]}, {"image_id": 1, "file_name": "721_01.png", "page": 2, "dpi": 300, "bbox": [455, 116, 737, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Multivariate data can be represented by a table where each row corresponds to an item, and each column to a feature. ", "caption_bbox": [428, 279, 762, 307]}, {"image_id": 2, "file_name": "721_02.png", "page": 4, "dpi": 300, "bbox": [62, 116, 764, 454], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Screenshot of the IF -Table (left) and FI -Table (right). Colored rows indicate selected items (blue) and features (green). The leftmost columns indicate how similar the rows are to the selection in the same table. The second leftmost columns indicate the relevance of the rows based on selections in the other table. The items and features columns show how many values are present for each row. The +/- column in the FI -Table shows if the selected items are within a standard deviation (o), above average (+), or under average (-). Selected rows are added as columns in the other table, together with a scented widget showing the distribution within the column. The search box on top of a table can be used to filter rows by their name. The tables visualize a United States community data set [Lic13] and show what is special about the communities with the highest employment rate. ", "caption_bbox": [62, 463, 761, 570]}, {"image_id": 3, "file_name": "721_03.png", "page": 7, "dpi": 300, "bbox": [65, 117, 762, 859], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparison of visualizations for multivariate data showing how similarity and relevance are visually encoded. The blue objects are selected items (X 0 ), the green objects are selected features (F 0 ), and the gray areas denote the bulk of the items. The cyan blob in (d) shows the new position of the items when using only the selected features for PCA. The similarities SX 0 (x) and SF 0 ( f ), and relevances RX 0 ( f ) and RF 0 (x) are displayed for the single item x and single feature f . ", "caption_bbox": [62, 875, 761, 937]}, {"image_id": 4, "file_name": "721_04.png", "page": 8, "dpi": 300, "bbox": [427, 116, 764, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Groningen compared to other cities based on three cri- teria. ", "caption_bbox": [428, 321, 762, 349]}, {"image_id": 5, "file_name": "721_05.png", "page": 8, "dpi": 300, "bbox": [62, 116, 399, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Features sorted by their relevance to the top 25 cities with high student density. ", "caption_bbox": [63, 321, 397, 349]}, {"image_id": 6, "file_name": "721_06.png", "page": 9, "dpi": 300, "bbox": [62, 116, 399, 219], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Features for which Groningen and Oxford both score high are found by using the histograms in the FI -Table. ", "caption_bbox": [63, 230, 397, 258]}], "722": [{"image_id": 0, "file_name": "722_00.png", "page": 2, "dpi": 300, "bbox": [62, 92, 415, 167], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Dimensionality reduction with landmarks. In non- linear embedding techniques the underlying manifold (a) is re- spected (b). In hybrid approaches, landmarks are placed without considering the underlying manifold (c) and data points are placed by interpolating the landmark positions (grey line in c). The layout quality thus relates to the used number of landmarks. ", "caption_bbox": [62, 178, 396, 267]}, {"image_id": 1, "file_name": "722_01.png", "page": 3, "dpi": 300, "bbox": [89, 93, 415, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of the hierarchy construction. A Finite Markov Chain (FMC) is built from the k-nearest neighbor graph. The FMC encodes the similarities between landmarks and it is used for selecting landmarks in the next scale. The FMC is also used to compute the area of influence of the selected landmarks on the landmarks in the lower scale. The overlap between the areas of in- fluence is used to build a new FMC that encodes similarities in the new scale. ", "caption_bbox": [62, 354, 396, 474]}, {"image_id": 2, "file_name": "722_02.png", "page": 4, "dpi": 300, "bbox": [62, 92, 415, 181], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Selection of landmarks and outliers using the equilib- rium distribution \u03c0 of the Finite Markov Chain (see Equation 2). Points are color coded from black to red according to their \u03c0-value. Selected landmarks are circled in green, while potential outliers are circled in blue. ", "caption_bbox": [62, 193, 396, 267]}, {"image_id": 3, "file_name": "722_03.png", "page": 4, "dpi": 300, "bbox": [412, 93, 781, 225], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The area of influence can be seen as flow converging in landmarks of the higher scale. The area of influence of the land- marks selected in Figure 3 is shown here. The overlap in the area of influence is used to compute similarities between landmarks (see Equation 5). ", "caption_bbox": [428, 237, 762, 311]}, {"image_id": 4, "file_name": "722_04.png", "page": 5, "dpi": 300, "bbox": [62, 93, 415, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Traditional vs Hierarchical analysis. (a) High- dimensional readings from sensors located on a map and prior knowledge on the phenomenon of interest are available to the user. In the traditional analysis (b) a single embedding is generated and analyzed. In our hierarchical analysis (c), an overview shows dom- inant structures in the dataset. Detailed embedding of the structures are created by filtering and drilling into the data. ", "caption_bbox": [63, 325, 397, 430]}, {"image_id": 5, "file_name": "722_05.png", "page": 6, "dpi": 300, "bbox": [62, 92, 754, 488], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Hierarchical analysis of hyperspectral images. Hyperspectral images of the Sun and the area surronding the city of Los Angeles are analyzed using HSNE. Dominant structures are revealed at different scales and can further inspected by creating detailed embeddings. ", "caption_bbox": [63, 511, 762, 540]}, {"image_id": 6, "file_name": "722_06.png", "page": 7, "dpi": 300, "bbox": [80, 92, 764, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Deep Learning models. Features are extracted from 100k images using a Deep Neural Network (DNN) [KSH12] and the hier- archical analysis is performed using HSNE. Starting from the overview, dominant structures at different levels are revealed. The user can inspect the embeddings and request detailed visualization. This is achieved through filtering of the landmarks and by drilling down in the hierarchy. A high-resolution version of the figure is provided in the supplemental materials. ", "caption_bbox": [63, 447, 762, 506]}, {"image_id": 7, "file_name": "722_07.png", "page": 8, "dpi": 300, "bbox": [62, 92, 763, 373], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Embeddings of the MNIST dataset created by non-linear dimensionality reduction techniques (tSNE and Landmark-SNE) and by hybrid techniques (LSP, P-LSP and LAMP). Differently from hybrid techniques, HSNE preserves the manifold in the landmark embedding, creating compact clusters in the complete embedding. ", "caption_bbox": [62, 384, 761, 428]}, {"image_id": 8, "file_name": "722_08.png", "page": 9, "dpi": 300, "bbox": [66, 93, 415, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Nearest Neighborhood Preservation (NNP) on the MNIST dataset. HSNE outperforms hybrid techniques and it is comparable to tSNE on a full scale analysis. When the user filters the data during the drill-in, HSNE outperforms tSNE. ", "caption_bbox": [63, 280, 397, 339]}], "723": [{"image_id": 0, "file_name": "723_00.png", "page": 1, "dpi": 300, "bbox": [63, 595, 764, 808], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Hurricane Isabel data set shown in different plots. Left: scatterplot of x\u00d7y using our blur method. Top row: zoomed-in views of the two marked regions. a) and c) use our method. b) and d) use transparent splats for comparison. Bottom row: histograms of three relevant dimensions and the selected focus coordinates marked with red vertical lines. (cf. Sec. 5.2) ", "caption_bbox": [63, 543, 762, 586]}, {"image_id": 1, "file_name": "723_01.png", "page": 4, "dpi": 300, "bbox": [62, 92, 415, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Applied selection bodies for synthetic data (left) and the \u201cpollen\u201d dataset (right). ", "caption_bbox": [63, 256, 397, 284]}, {"image_id": 2, "file_name": "723_02.png", "page": 4, "dpi": 300, "bbox": [412, 93, 765, 248], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Blurring with different kernels. a) whole data set; b) zoom-in with Gaussian blur; c) zoom-in with disc blur ", "caption_bbox": [428, 259, 762, 287]}, {"image_id": 3, "file_name": "723_03.png", "page": 5, "dpi": 300, "bbox": [412, 92, 764, 196], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The color map used in our visualizations (cf. Color- Brewer 5-class GnBu) ", "caption_bbox": [428, 207, 762, 235]}, {"image_id": 4, "file_name": "723_04.png", "page": 5, "dpi": 300, "bbox": [65, 93, 415, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Outline of the control flow during rendering", "caption_bbox": [92, 397, 365, 410]}, {"image_id": 5, "file_name": "723_05.png", "page": 6, "dpi": 300, "bbox": [63, 92, 764, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Separation task; a) the data set in x \u00d7 z; for x \u00d7 y: b) results of blur, c) results of color and depth sorting, d) results with added varying scale, e) used color table (cf. ColorBrewer diverging 5-class spectral) ", "caption_bbox": [63, 304, 762, 333]}, {"image_id": 6, "file_name": "723_06.png", "page": 6, "dpi": 300, "bbox": [64, 370, 401, 500], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Effects of ordered rendering for opaque glyphs; the color map shown in Fig. 6 is used. ", "caption_bbox": [63, 510, 397, 538]}, {"image_id": 7, "file_name": "723_07.png", "page": 7, "dpi": 300, "bbox": [430, 371, 766, 696], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Scatterplots of data set \u201cParticles in Fluid simulation\u201d; Upper row: classical scatterplots for dimensions y by either x, velo (linear velocity), and ang_velo (angular velocity). Correlation be- tween angular velocity and height is not clear. Lower row: in scat- terplots x\u00d7z particles with low angular velocity appear in the bulk material (e.g. red marked areas), while particles with high values appear at borders of holes (e.g. purple marked areas). ", "caption_bbox": [428, 707, 762, 811]}, {"image_id": 8, "file_name": "723_08.png", "page": 7, "dpi": 300, "bbox": [64, 371, 401, 648], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Scatterplots of data set \u201cHurricane Isabel\u201d: Top row: two scatterplots of the spatial dimensions. The focus selection is on the hurricane\u2019s structure for increased pressure, mid-high tem- peratures and increased wind speed at lower height. Bottom row: histograms of the involved dimensions showing the focal point. ", "caption_bbox": [63, 658, 397, 732]}, {"image_id": 9, "file_name": "723_09.png", "page": 7, "dpi": 300, "bbox": [64, 92, 767, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Shape perception task. a) sketch of the data set, b) results of blur, c) results of color and depth sorting, d) results with added varying scale, e) used color table (cf. ColorBrewer sequential 5-class YlOrBr) ", "caption_bbox": [63, 305, 762, 333]}], "724": [{"image_id": 0, "file_name": "724_00.png", "page": 3, "dpi": 300, "bbox": [62, 92, 764, 420], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: First row: the three steps (marked with different colors) for constructing the Grassmannian Atlas. Bottom row: examine the space of linear projections involving a 3D example. For illustration purposes, the left panel displays point cloud samples representing projections rather than subspaces as the Gassmannian has no intuitive embedding. ", "caption_bbox": [63, 431, 762, 475]}, {"image_id": 1, "file_name": "724_01.png", "page": 4, "dpi": 300, "bbox": [62, 92, 761, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Sampling experiments. Let m be the sample size, dann be the average nearest neighbor distance, and n be the data dimension. (a) For a fixed m = 1500, dann increases with an exponential increase of n (x-axis, log-scale). (b) For a fixed n (4 \u2264 n \u2264 7), dann (y-axis) decreases with an exponential increase of m (x-axis, log-scale). (c) To maintain a fixed density dann \u2248 0.3, m (y-axis, log-scale) scales exponentially with n (x-axis). ", "caption_bbox": [62, 370, 761, 429]}, {"image_id": 2, "file_name": "724_02.png", "page": 5, "dpi": 300, "bbox": [89, 93, 415, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Selecting projections based purely on the ranking of a quality measure, (a) fails to identify structurally distinct projections as those obtained via topological analysis (b). ", "caption_bbox": [63, 332, 397, 376]}, {"image_id": 3, "file_name": "724_03.png", "page": 5, "dpi": 300, "bbox": [64, 748, 403, 910], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Multiscale topological spine representations. The persis- tence plots are shown on the left: the x-axis corresponds to the per- sistence threshold, and the y-axis is the number of current cells in the simplification. The long plateau in the persistence plot (bottom) corresponds to a stable topological structure. ", "caption_bbox": [63, 923, 397, 997]}, {"image_id": 4, "file_name": "724_04.png", "page": 6, "dpi": 300, "bbox": [430, 239, 762, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Validating the stability of topological spines by varying the number of samples and the number of neighbors for the k-NN graph. ", "caption_bbox": [428, 442, 762, 486]}, {"image_id": 5, "file_name": "724_05.png", "page": 6, "dpi": 300, "bbox": [68, 599, 393, 761], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A histogram showing the distribution of pointwise nearest (blue) and farthest (orange) neighbor distances for Gr(2, 5) with 10K samples. ", "caption_bbox": [62, 773, 396, 817]}, {"image_id": 6, "file_name": "724_06.png", "page": 7, "dpi": 300, "bbox": [62, 350, 764, 596], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Quality measures comparison by evaluating their respective persistence plots, which provide concise summaries of the multireso- lution topological structure. Only four datasets are shown here due to space constrains. ", "caption_bbox": [63, 610, 762, 638]}, {"image_id": 7, "file_name": "724_07.png", "page": 7, "dpi": 300, "bbox": [90, 92, 764, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Validate the Grassmannian Atlas framework on a synthetic two-planes dataset. The dataset is sampled from the space illustrated in (a). In (b), the two maxima within the topological spine correspond to the projections where one or both planes are at the \u201cskinniest\u201d. In (c), the (global) stress measure captures one only interesting projection at its global maxima. In (d), the projection pursuit index central mass measure captures the two projections where one of the two planes becomes \u201cskinny\". ", "caption_bbox": [63, 277, 762, 336]}, {"image_id": 8, "file_name": "724_08.png", "page": 8, "dpi": 300, "bbox": [64, 649, 411, 805], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The different outliers captured by the Grassmannian At- las using the scagnostics outlying measure for the housing dataset. The outliers are highlighted by small solid circles. ", "caption_bbox": [63, 817, 397, 861]}, {"image_id": 9, "file_name": "724_09.png", "page": 8, "dpi": 300, "bbox": [62, 92, 412, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The complementary projections captured by Grassman- nian Atlas using the scagnostics clumpy measure for the E. coli dataset. ", "caption_bbox": [63, 292, 397, 336]}, {"image_id": 10, "file_name": "724_10.png", "page": 9, "dpi": 300, "bbox": [104, 92, 765, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Word2Vect dataset. The clumpy measure helps to identify the two projections that highlight clear separation between cities and countries from the rest of the data points. ", "caption_bbox": [63, 347, 762, 375]}], "725": [{"image_id": 0, "file_name": "725_00.png", "page": 1, "dpi": 300, "bbox": [412, 367, 763, 762], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An icicle plot [KL83] visualizing 10143 events in 300 clickstream sequences. Each sequence goes from top to bottom, where the events are represented as small rectangles. The color of the rectangles represents event category. ", "caption_bbox": [427, 775, 763, 834]}, {"image_id": 1, "file_name": "725_01.png", "page": 2, "dpi": 300, "bbox": [64, 349, 394, 578], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Eleven sequential patterns extracted from the input se- quences in Figure 2 with minimum support set to 30%. The hor- izontal position of the events represent the average time elapsed relative to the beginning of the sequences. For example, the second pattern shows that two sequences share the ordered events \u201cA\u201d, ", "caption_bbox": [62, 592, 398, 666]}, {"image_id": 2, "file_name": "725_02.png", "page": 2, "dpi": 300, "bbox": [62, 112, 415, 279], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Six event sequences with 12 unique events (A - L). The horizontal axis represents the timestamp (in seconds) for the events. ", "caption_bbox": [62, 290, 396, 318]}, {"image_id": 3, "file_name": "725_03.png", "page": 3, "dpi": 300, "bbox": [412, 112, 764, 979], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Step-by-step process to extract a branching pattern. The tables show top 5 events in the (sub)sequences with event name, number of sequences containing that event, and the average index of the event. ", "caption_bbox": [427, 985, 763, 1044]}, {"image_id": 4, "file_name": "725_04.png", "page": 4, "dpi": 300, "bbox": [62, 112, 415, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A visualization of the branching pattern extracted in Figure 4. The horizontal distance between adjacent nodes represent the average time taken to go from the parent node to the child node. The link width represents the number of sequences following the path, and we annotate the links with the raw sequence IDs. The branching pattern provides a succinct overview of the input sequences. Compared with visualization based on frequent pattern in Figure 3, the branching pattern provides a unified view connecting frequent events in continuous paths. ", "caption_bbox": [61, 304, 398, 439]}, {"image_id": 5, "file_name": "725_05.png", "page": 5, "dpi": 300, "bbox": [52, 112, 415, 987], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Three visualization designs implemented based on Core- Flow ", "caption_bbox": [61, 1001, 398, 1029]}, {"image_id": 6, "file_name": "725_06.png", "page": 5, "dpi": 300, "bbox": [412, 112, 764, 395], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Hovering over a branch displays the most frequent events in the branch ", "caption_bbox": [427, 406, 761, 434]}, {"image_id": 7, "file_name": "725_07.png", "page": 6, "dpi": 300, "bbox": [62, 112, 415, 486], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The analysts define a funnel consisting of two milestones: the plans page and a completed order. CoreFlowVis highlights this funnel in green, and displays it in the context of branching patterns. ", "caption_bbox": [62, 497, 398, 540]}, {"image_id": 8, "file_name": "725_08.png", "page": 6, "dpi": 300, "bbox": [412, 112, 778, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Drilling down on the link \u201clogin \u2212\u2192 account info\u201d. The link is highlighted with an orange outline (left). The new branching pattern for the subsequences in this link does not always fit within the original partition (right). ", "caption_bbox": [427, 251, 761, 310]}, {"image_id": 9, "file_name": "725_09.png", "page": 7, "dpi": 300, "bbox": [412, 112, 764, 407], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: CoreFlow scales better to larger datasets and consumes less computation time. Due to memory limitation, we could not compute patterns for Dataset3 using the FSPM approach. To better display the labels and avoid overlap, we use a log scale for the y axis representing computation time. ", "caption_bbox": [427, 411, 761, 485]}, {"image_id": 10, "file_name": "725_10.png", "page": 7, "dpi": 300, "bbox": [63, 112, 415, 320], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Three datasets with varying size and complexity used in our evaluation study ", "caption_bbox": [61, 505, 395, 533]}, {"image_id": 11, "file_name": "725_11.png", "page": 8, "dpi": 300, "bbox": [62, 112, 753, 575], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Comparison of patterns extracted by FSPM and CoreFlow. The vertical scale represents the average number of events.", "caption_bbox": [85, 589, 737, 602]}, {"image_id": 12, "file_name": "725_12.png", "page": 9, "dpi": 300, "bbox": [69, 112, 415, 500], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Patterns generated by FSPM and CoreFlow", "caption_bbox": [90, 514, 368, 527]}], "726": [{"image_id": 0, "file_name": "726_00.png", "page": 1, "dpi": 300, "bbox": [427, 784, 764, 976], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A remake of a complex slide in analysts\u2019 slide deck. The titles and labels were modified for anonymity. ", "caption_bbox": [428, 988, 741, 1016]}, {"image_id": 1, "file_name": "726_01.png", "page": 4, "dpi": 300, "bbox": [62, 112, 729, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An example of a staged transition: one element of the visualization appears at a time", "caption_bbox": [174, 251, 650, 264]}, {"image_id": 2, "file_name": "726_02.png", "page": 5, "dpi": 300, "bbox": [87, 112, 413, 368], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A divergent stacked bar chart of the superstore shipping timings. ", "caption_bbox": [63, 380, 397, 408]}, {"image_id": 3, "file_name": "726_03.png", "page": 5, "dpi": 300, "bbox": [412, 112, 764, 372], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A small multiple visualization about the electric power generation in 2004 and 2014. Source: U.S. Energy Information Ad- ministration ", "caption_bbox": [428, 386, 762, 429]}, {"image_id": 4, "file_name": "726_04.png", "page": 6, "dpi": 300, "bbox": [62, 112, 415, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Responses to the interview question \u201cWhich cue did you find most useful?\u201d Some participants chose multiple cues. ", "caption_bbox": [63, 324, 397, 352]}, {"image_id": 5, "file_name": "726_05.png", "page": 6, "dpi": 300, "bbox": [413, 112, 743, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The frequency distribution of cues in the slides by task.", "caption_bbox": [430, 332, 760, 345]}, {"image_id": 6, "file_name": "726_06.png", "page": 8, "dpi": 300, "bbox": [62, 112, 695, 718], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A selection of the slides made during the user study", "caption_bbox": [257, 732, 567, 745]}], "727": [{"image_id": 0, "file_name": "727_00.png", "page": 1, "dpi": 300, "bbox": [62, 358, 764, 513], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Mobile devices support graph visualization and interaction on wall-sized displays close to the display wall and further away (A). The G RA S P system provides a mobile toolbox with selections, alternative representations, lenses, and filtering close to the user (B). ", "caption_bbox": [63, 520, 762, 549]}, {"image_id": 1, "file_name": "727_01.png", "page": 5, "dpi": 300, "bbox": [62, 112, 764, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Selection Techniques & Details on Demand: Tapping a node opens associated details on the mobile (A). Encircling multiples nodes enables group selections (B). Remote pointing provides a focus view on the mobile (C), which can be used for remote selection using either tap or encircling (D). ", "caption_bbox": [63, 268, 762, 312]}, {"image_id": 2, "file_name": "727_02.png", "page": 6, "dpi": 300, "bbox": [412, 112, 764, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The Adjacency Matrix as an alternative representation can be extracted to the device and moved freely in space (A). It also provides remote edge manipulation (B). ", "caption_bbox": [428, 271, 762, 315]}, {"image_id": 3, "file_name": "727_03.png", "page": 7, "dpi": 300, "bbox": [62, 112, 415, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Tangible Graph Lenses: Bring Neighbors pulls in adja- cent nodes of nodes in focus (here: highlighted in pink) (A) and Attribute Filter enlarges nodes with specific attribute values (B). ", "caption_bbox": [62, 271, 396, 315]}, {"image_id": 4, "file_name": "727_04.png", "page": 7, "dpi": 300, "bbox": [412, 112, 764, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Body-relative attribute filtering: Left-right movement supports selection of individual attribute ranges (B), a down move- ment then brings the selected range into focus (C). ", "caption_bbox": [428, 271, 762, 315]}, {"image_id": 5, "file_name": "727_05.png", "page": 8, "dpi": 300, "bbox": [62, 112, 415, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Sieve Filter Tool: After configuring the filter criteria (A), nodes are spatially separated using physics (B). When rotated, they will fall to create a comparative view (C). ", "caption_bbox": [62, 271, 396, 315]}], "728": [{"image_id": 0, "file_name": "728_00.png", "page": 1, "dpi": 300, "bbox": [62, 590, 764, 773], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The InsightsFeed tool for progressive visual analytics of Twitter (left): (A) a list of tweets, (B) a sentiment chart, (C) user popularity chart, (D) a map from a 2D projection of tweets with important keywords highlighted in each region, and (E) feedback and controls over the progression and computations. (Right) The interface is progressively updated when more data is processed. ", "caption_bbox": [63, 546, 762, 589]}, {"image_id": 1, "file_name": "728_01.png", "page": 2, "dpi": 300, "bbox": [412, 112, 761, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Early stage in the progression of the tweet map. Three important keywords are found by the data journalist. ", "caption_bbox": [428, 270, 762, 298]}, {"image_id": 2, "file_name": "728_02.png", "page": 4, "dpi": 300, "bbox": [438, 301, 761, 402], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Dependency graph of the InsightsFeed views. KE is key- word extraction and SC is sentiment classification. ", "caption_bbox": [428, 413, 762, 441]}, {"image_id": 3, "file_name": "728_03.png", "page": 4, "dpi": 300, "bbox": [428, 457, 764, 588], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Two instances of the tweet list view, during progression, with keywords highlighted. New tweets are inserted based on the timestamp order and highlighted with a gray background. ", "caption_bbox": [428, 599, 762, 642]}, {"image_id": 4, "file_name": "728_04.png", "page": 5, "dpi": 300, "bbox": [412, 112, 764, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Three instances of the tweet map. Tweets are projected, aggregated into heatmap, clustered, and labelled. The labels are generated by extracting the top keywords in each cluster region. ", "caption_bbox": [428, 437, 762, 480]}, {"image_id": 5, "file_name": "728_05.png", "page": 6, "dpi": 300, "bbox": [61, 112, 415, 269], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Feedback and controls added to each visualization to track the progression and control the computations. ", "caption_bbox": [63, 286, 397, 314]}, {"image_id": 6, "file_name": "728_06.png", "page": 7, "dpi": 300, "bbox": [66, 112, 414, 201], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Interactions with the tweet map: hover on a cell to get the keywords, and select a region to update the interface. ", "caption_bbox": [63, 212, 397, 240]}, {"image_id": 7, "file_name": "728_07.png", "page": 9, "dpi": 300, "bbox": [63, 112, 414, 396], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Participant response counts for the Likert scales con- cerning the usability of the progressive (PVA) and instantaneous (IVA) interfaces, as well as the utility of the features. ", "caption_bbox": [63, 410, 397, 453]}], "729": [{"image_id": 0, "file_name": "729_00.png", "page": 4, "dpi": 300, "bbox": [428, 277, 762, 542], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visualizations of the uncertainty footprint values from cell segmentation using the EM clustering method. (A) We use the EM clustering algorithm to segment two fused cells in a confo- cal microscopy scan of zebrafish eye development. The first column shows the two fused cells selected and colored. The second column shows the parameter estimation for two Gaussian distributions as the initial condition for the EM. The third column shows the uncer- tainty footprint result mapped to a purple-green-red lookup table. The fourth column is the 2D histogram of the uncertainty footprint values. (B) The same cells in A are segmented using the same EM process. However, the initial condition is different. The two initial Gaussian distributions are set to overlap each other. (C) We use the EM algorithm to segment a single cell with a concave shape. Despite that certain isolated parts exhibit higher uncertainty than others, we are able to detect a possibly acceptable segmentation at the dent on the cell. (D) We use the EM algorithm to segment a single cell with a round shape. The result exhibits high uncertainty and slow convergence. For all examples, we truncate or pad the 2D histograms to show the results from 127 iterations. Actual iter- ation numbers vary for different cases depending on convergence criteria. However, the trends to reach convergence can be clearly observed in the 2D histograms. ", "caption_bbox": [428, 553, 762, 886]}, {"image_id": 1, "file_name": "729_01.png", "page": 4, "dpi": 300, "bbox": [61, 112, 415, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An illustration of a typical 2D histogram of the uncer- tainty footprint values in an iterative process. The 2D histogram is a concatenation of a sequence of 1D histograms at consecu- tive iteration numbers. Each 1D histogram shows the frequency for different uncertainty footprint values. Frequency values are color mapped. Several patterns are interesting to the analysis of a 2D histogram. Lines or curves represent local features having simi- lar convergence. Diagonal lines denote the aggregation of value changes. The steeper a diagonal line is, the faster the changes. Hor- izontal lines denote convergence. The locations of the horizontal lines determine the uncertainty at convergence. If a diagonal line does not turn to a horizontal line, it means oscillation. We can also find out when oscillation separates from convergence. ", "caption_bbox": [63, 379, 397, 575]}, {"image_id": 2, "file_name": "729_02.png", "page": 6, "dpi": 300, "bbox": [134, 474, 330, 622], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A summary of EM result classification using the 2D his- togram of uncertainty footprint. Two factors are examined. The hor- izontal axis of the graph represents the aggregation of local value changes. The vertical axis represents how much local uncertainty footprint value spreads. The more lines or curves are spread, the higher nonuniformity of local convergence. We place the four ex- amples in Figure 2 on the graph. An acceptable result should have both values low, not just convergence, indicated as the green region. ", "caption_bbox": [63, 636, 397, 756]}, {"image_id": 3, "file_name": "729_03.png", "page": 7, "dpi": 300, "bbox": [413, 112, 764, 417], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Uncertainty footprint result for tracking two time points of a scan of zebrafish eye development. The top panels show the volume renderings of the two time points. The volume data are segmented and colored using the Synthetic Brainbows. The bottom panels show two representations of the 2D histogram of the uncer- tainty footprint, a 2D color-mapped image and a 3D ribbon graph. The 3D ribbon graph shows two prominent ridges, representing rapidly converged results and uncertain results respectively. ", "caption_bbox": [428, 430, 762, 550]}, {"image_id": 4, "file_name": "729_04.png", "page": 7, "dpi": 300, "bbox": [429, 576, 762, 708], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Filtering the volume rendering results by selecting a range from the histogram of uncertainty footprint. Only cells within the selected range (red regions on histograms) are colored using the Synthetic Brainbows. (A) A result generated using a similarity threshold value of 0.2. (B) A result generated by adjusting the seg- mentation parameters so that fewer cases of over-segmentation are present. (C) A result generated from the same segmentation as in A, but using a similarity threshold value of 0.85. ", "caption_bbox": [428, 721, 762, 841]}, {"image_id": 5, "file_name": "729_05.png", "page": 8, "dpi": 300, "bbox": [61, 112, 415, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Examples of high uncertainties in cell tracking. (A) Two cells are tracked over time. In T1, one cell with varied colors is identified as noise because of low intensity values, which should be matched to the cyan cell in T2. Instead, the blue cell in T1 is matched to both cells in T2. (B) One cell is tracked over time. In T2, the cell is over-segmented to two parts because of its shape. The red cell in T1 is matched to both parts in T2. (C) Two cells are tracked over time. In T1, the two cells are under-segmented and fused into one green component. In T2, the two cells are correctly segmented. The green component in T1 is tracked to both cells in T2. (D) The yellow cell in T1 disappears in T2. The matching of the cyan cell in T1 to the orange cell in T2 is correct. ", "caption_bbox": [63, 324, 397, 504]}, {"image_id": 6, "file_name": "729_06.png", "page": 9, "dpi": 300, "bbox": [413, 112, 764, 321], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A comparison of the cell tracking results between Amat et al.\u2019s and ours. (A1) One time point from the tracking result using a sample data set provided by Amat et al. This time point contains several tracking issues. The inset magnifies one such issue that the green part is incorrectly tracked to the yellow cell due to an over- segmentation that separates the green from the orange. (A2) One time point from the tracking result using our workflow. The inset shows the correct tracking of the two cells. (B) Two time points of a magnified region from Amat et al.\u2019s tracking result. The orange cell in the first time point is tracked to the green part of the cell in the second time point. Since the track is consistent, the issue cannot be detected using Amat et al.\u2019s method without a detailed uncertainty analysis. (C) Two time points from the result by applying Amat et al.\u2019s method to the 4D scan of zebrafish eye development. The col- ored cells are those could be tracked, only a portion of which are correct. All data and results are included in the supplementary ma- terials and can be interactively viewed using FluoRender. ", "caption_bbox": [428, 333, 762, 589]}], "730": [{"image_id": 0, "file_name": "730_00.png", "page": 1, "dpi": 300, "bbox": [104, 397, 723, 703], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Bubble Column Data Set. a) Color coding of the velocity of the dispersed phase. b) Generated bubbles, color coded by the velocity of the dispersed phase. c) Photorealistic rendering of generated bubbles. d) Photograph of bubbles in the physical experiment. ", "caption_bbox": [63, 715, 762, 743]}, {"image_id": 1, "file_name": "730_01.png", "page": 4, "dpi": 300, "bbox": [61, 112, 415, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Left: Bubble shapes are determined based on pre-defined representatives which are arranged in the diagram of the E\u00f6tv\u00f6s number and the Reynolds number. Right: Intermediate shapes be- tween three arbitrary bubble representatives can be obtained using barycentic interpolation. ", "caption_bbox": [63, 388, 397, 462]}, {"image_id": 2, "file_name": "730_02.png", "page": 4, "dpi": 300, "bbox": [65, 487, 395, 557], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Left: The outline of each bubble is defined by a B-Spline curve in the xy plane. Right: The three-dimensional bubble is ob- tained by rotating the outline curve around the y-axis (red). ", "caption_bbox": [63, 568, 397, 611]}, {"image_id": 3, "file_name": "730_03.png", "page": 4, "dpi": 300, "bbox": [412, 112, 763, 469], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Rejection sampling, one-dimensional example. Top: sam- pling the initial distribution. A number of uniform samples are gen- erated in the range of x and assigned a random value in [0 . . . dmax ]. Samples that fall in the green area below the curve are kept; the rest are discarded. Bottom: Updating an existing bubble set to match a target density function. Left of the dotted line, uniform samples are generated and assigned a random value in [0 . . . dmax ]. Samples that fall into the green area are added, the rest are discarded. Right of the dotted line, each of the existing bubbles are assigned a random value between 0 and the current density. If a bubble falls into the red area, it is removed. ", "caption_bbox": [428, 481, 762, 646]}, {"image_id": 4, "file_name": "730_04.png", "page": 6, "dpi": 300, "bbox": [412, 112, 720, 532], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Advancing the bubbles through time. Left: Bubbles are moved according to the velocity field. Gray: old position, blue: new position. Center: Superfluous bubbles (red) are deleted. Right: New bubbles (green) are added. ", "caption_bbox": [428, 547, 762, 606]}, {"image_id": 5, "file_name": "730_05.png", "page": 7, "dpi": 300, "bbox": [64, 112, 764, 550], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A single time step of the bubble column dataset. From left to right: a) Two-dimensional slice of the volume fraction \u03b1disp . b) Two- dimensional slice of the volume-based bubble diameter d30 . c) Density field M0 . d) Velocity magnitude udisp of the dispersed phase. e) Bubble set generated with our visualization approach. Color represents velocity magnitude of the dispersed phase. ", "caption_bbox": [63, 566, 762, 609]}, {"image_id": 6, "file_name": "730_06.png", "page": 8, "dpi": 300, "bbox": [61, 112, 415, 530], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Left: Setup of the bubble column. Center: Photograph of the physical experiment. Right: Rendering of a simulation time step produced using our sampling approach. ", "caption_bbox": [63, 543, 397, 586]}], "731": [{"image_id": 0, "file_name": "731_00.png", "page": 1, "dpi": 300, "bbox": [76, 384, 748, 558], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Accurate rendering of a real scale model of the New Horizons spacecraft taking measurements on Pluto. The model of about 2 m size is shown in its correct location relative to Pluto, which is about 6 \u00b7 1012 m from the coordinate system origin with the stars of the constellation Ophiucus (about 1018 m) in their correct 3D positions. High precision is required for computing the correct location of images on the surface of Pluto as well as correctly rendering the shadow cylinders of both Pluto and its moon, Charon. ", "caption_bbox": [62, 568, 761, 627]}, {"image_id": 1, "file_name": "731_01.png", "page": 3, "dpi": 300, "bbox": [68, 112, 415, 248], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An illustration of the effects of limited coordinate preci- sion where the number of mantissa bits is limited to 5 when visual- izing a system analogous to a world coordinate system in a scene graph. Increasing distance leads to decreasing precision. ", "caption_bbox": [63, 277, 397, 336]}, {"image_id": 2, "file_name": "731_02.png", "page": 3, "dpi": 300, "bbox": [412, 112, 766, 279], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Floating point error at Pluto. Floating point quantiza- tion are visible at Pluto\u2019s distance of 5.1 billion km from the Sun using PSC. Our method achieves high fidelity renderings while still representing objects with single precision floating point numbers. ", "caption_bbox": [428, 304, 762, 363]}, {"image_id": 3, "file_name": "731_03.png", "page": 6, "dpi": 300, "bbox": [61, 112, 415, 575], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A potential scene graph consisting of two translation nodes for the solar system and the Earth system (1,3) and three rendering nodes for the Sun (2), Earth (4), and the Moon (5). Cameras (A, B) can be attached to different nodes, thus avoiding the introduction of large, error-prone translation values. (a) shows the nodes relative location, whereas (b) shows their organization in a graph. The arrows represent local upwards (red) and downwards (blue) transformations. ", "caption_bbox": [63, 605, 397, 725]}, {"image_id": 4, "file_name": "731_04.png", "page": 7, "dpi": 300, "bbox": [62, 112, 415, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: When the camera reattaches to a node, its coordinate system changes. While the old location A is expressed relative to N as v, the new location B is expressed relative to M as w \u2212 n instead. ", "caption_bbox": [62, 326, 396, 370]}, {"image_id": 5, "file_name": "731_05.png", "page": 8, "dpi": 300, "bbox": [62, 797, 400, 941], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A rendering of Pluto\u2019s surface with a height field recon- structed from New Horizons\u2019 images showing the Zheng He Montes and al-Idrisi Montes in front of Tombaugh Regio. ", "caption_bbox": [63, 966, 397, 1009]}, {"image_id": 6, "file_name": "731_06.png", "page": 8, "dpi": 300, "bbox": [61, 112, 761, 449], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A journey of 1.65 billion km as sequence of images of a flight started on Earth\u2019s surface (a), showing Earth from the view of geostationary satellites (b), entering the Saturnian system (c), entering Titan\u2019s sphere of influence (d), and approaching Titan (e). Figure (f) shows the accompanying scene graph structure and and which locations the individual images were taken. ", "caption_bbox": [63, 462, 762, 505]}, {"image_id": 7, "file_name": "731_07.png", "page": 9, "dpi": 300, "bbox": [62, 899, 400, 956], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A volumetric rendering of a three-channel simulation of the Milky Way with a bounding box size in the order of 1020 m. ", "caption_bbox": [63, 981, 397, 1010]}, {"image_id": 8, "file_name": "731_08.png", "page": 9, "dpi": 300, "bbox": [62, 112, 415, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Details of structures with up to 25 cm per pixel resolution in a rendering of the surface features in West Candor Chasma on Mars as captured from the HiRISE camera. ", "caption_bbox": [63, 305, 397, 348]}, {"image_id": 9, "file_name": "731_09.png", "page": 9, "dpi": 300, "bbox": [412, 112, 766, 228], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Our approach supports stereoscopic rendering (here, amber/blue anaglyph) exemplified with the Rosetta/Philae separa- tion for the landing on the comet 67P/Churyumov-Gerasimenko. ", "caption_bbox": [428, 253, 762, 296]}], "732": [{"image_id": 0, "file_name": "732_00.png", "page": 1, "dpi": 300, "bbox": [62, 341, 764, 632], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: This image shows the Gulf Stream eddies moving through the Northwest Atlantic Ocean basin in 2006 and 2007. Each eddy instance is illustrated by the depiction of its color-coded isosurface. Colors are used to differentiate cyclonic (green) and anticyclonic (purple) eddy and convey variations in ocean temperature (warm=light; cold=dark). Directional lines are used to highlight the motion of eddies. This is an illustrative visualization using actual data in a manner similar to hand drawing illustrations (e.g., Figure 2) ", "caption_bbox": [63, 643, 762, 702]}, {"image_id": 1, "file_name": "732_01.png", "page": 2, "dpi": 300, "bbox": [79, 707, 382, 956], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An artistic illustration of ocean eddies in the context of oceanic thermal structure. Image is courtesy of Japan Agency for Marine-Earth Science and Technology. [JAM] ", "caption_bbox": [63, 966, 397, 1009]}, {"image_id": 2, "file_name": "732_02.png", "page": 3, "dpi": 300, "bbox": [434, 730, 758, 969], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: ROMS domain and a representative model output of the daily averaged sea surface temperature. [KC13] ", "caption_bbox": [428, 981, 762, 1009]}, {"image_id": 3, "file_name": "732_03.png", "page": 4, "dpi": 300, "bbox": [61, 112, 763, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The proposed method has two phases: (1) Eddy feature computation includes three steps: eddy extraction, eddy path detection, and properties computation. All of these provide data that is used to construct the illustrative eddy visualization. (2) Illustrative eddy visualization. ", "caption_bbox": [63, 355, 762, 383]}, {"image_id": 4, "file_name": "732_04.png", "page": 5, "dpi": 300, "bbox": [62, 112, 415, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The Okubo-Weiss parameter is plotted on a data frame.", "caption_bbox": [65, 360, 395, 373]}, {"image_id": 5, "file_name": "732_05.png", "page": 5, "dpi": 300, "bbox": [427, 704, 764, 955], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Eddy path detection model. An eddy that lasts at least fifteen days will be detected. Each output eddy path includes eddy features\u2019 IDs and their corresponding state IDs in each time step. ", "caption_bbox": [428, 966, 762, 1009]}, {"image_id": 6, "file_name": "732_06.png", "page": 6, "dpi": 300, "bbox": [428, 718, 764, 910], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The GUI is showing an Skeletonized Eddy Path Map in 2006 and 2007. The eddy instances in the eddy paths lasting at least fifteen days are represented as simple glyphs (cylinders) and placed in a context of the ocean basin, Gulf Stream (orange line), and coastline. Color is used to differentiate cyclonic eddies (blue) and anticyclonic eddies (red). ", "caption_bbox": [428, 921, 762, 1010]}, {"image_id": 7, "file_name": "732_07.png", "page": 7, "dpi": 300, "bbox": [62, 112, 764, 618], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: This three-dimensional Eddy Path Map shows the eddy paths that last at least fifty days in 2006 and 2007. The physical and kinematic changes in an eddy over its life cycle are illustrated by the depiction of its three-dimensional color-coded isosurface in successive time steps. Directional lines above each eddy path highlight eddy motion. Colors convey variations in ocean temperature. Three typical scenarios are observed from the map: A. An eddy propagates onto the shelf, then bumps it before splitting. B. A cyclonic eddy propagates to the west. C. An anticyclonic eddy propagates to the east. ", "caption_bbox": [63, 632, 762, 706]}, {"image_id": 8, "file_name": "732_08.png", "page": 8, "dpi": 300, "bbox": [61, 112, 764, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Two cyclonic eddy paths (left) and two anticyclonic eddy paths (right) are presented as Isolated Eddy Path Visualization. Trans- parency and directional lines are used to give a sense of motion. Each eddy feature (instance) is plotted as isosurface color-coded by temperature variation on its surface. ", "caption_bbox": [63, 409, 762, 452]}, {"image_id": 9, "file_name": "732_09.png", "page": 9, "dpi": 300, "bbox": [412, 112, 764, 556], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Individual Eddy Visualization of horizontal velocity for an anticyclonic eddy (a, b) and salinity for a cyclonic eddy (c, d). ", "caption_bbox": [428, 566, 762, 594]}, {"image_id": 10, "file_name": "732_10.png", "page": 9, "dpi": 300, "bbox": [62, 112, 415, 556], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Individual Eddy Visualization of temperature for an an- ticyclonic eddy (a, b) and a cyclonic eddy (c, d). In (a) and (c), temperature variation on the surface are color coded in isosurface of the two eddies. In (b) and (d), eddies are first clipped by a cutting plane, then their internal structures are shown by volume rendering indicating the variation of temperature inside. ", "caption_bbox": [63, 566, 397, 655]}], "733": [{"image_id": 0, "file_name": "733_00.png", "page": 2, "dpi": 300, "bbox": [61, 112, 763, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Tile maps: (a) Bloomberg.com [TC15], (b) FiveThirtyEight.com [CM15], (c,d) NPR [DeB15].", "caption_bbox": [151, 289, 674, 302]}, {"image_id": 1, "file_name": "733_01.png", "page": 4, "dpi": 300, "bbox": [61, 112, 763, 211], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Unlabeled tile maps for US states. The first map is based on the original centroids; other maps are based on noisy centroids. Noise standard deviation: 0.1; other parameters fixed (fully transformed centroids, boundaries smoothed\u201330 basis functions, no grid shift). ", "caption_bbox": [63, 222, 762, 250]}, {"image_id": 2, "file_name": "733_02.png", "page": 4, "dpi": 300, "bbox": [79, 288, 382, 597], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: States of the USA. (a) Original centroids. (b) \u2018Fully transformed\u2019 centroids. ", "caption_bbox": [63, 608, 397, 636]}, {"image_id": 3, "file_name": "733_03.png", "page": 5, "dpi": 300, "bbox": [64, 112, 764, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: States of the USA. (a) Points are state centroids: gray\u2013original (no noise), green\u2013fully transformed. Lines: gray\u2013original boundary, green\u2013transformed boundary. (b) Creating variation by smoothing the boundary and shifting the grid origin. ", "caption_bbox": [63, 343, 762, 371]}, {"image_id": 4, "file_name": "733_04.png", "page": 7, "dpi": 300, "bbox": [121, 112, 764, 960], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: States of the USA; screenshots from browser-based prototype with default options (left side panel). Top-ranked map for: (a) default weights (all equal to 1); (b) relative orientation (angle) weight 1, other weights 0; (c) adjacency weight 1, other weights 0. ", "caption_bbox": [63, 971, 762, 999]}, {"image_id": 5, "file_name": "733_05.png", "page": 8, "dpi": 300, "bbox": [61, 112, 415, 479], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Local authorities of the UK. (a) Points are local authority centroids: gray\u2013original (no noise), green\u2013fully trans- formed. Lines: gray\u2013original boundary, green\u2013transformed bound- ary (smoothed, 30 basis functions). (b) Hexagonal tile map corre- sponding to (a) (grid shift: half step along x-axis). ", "caption_bbox": [63, 490, 397, 564]}, {"image_id": 6, "file_name": "733_06.png", "page": 8, "dpi": 300, "bbox": [412, 112, 763, 825], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: States of the USA; hexagonal and triangular tile maps.", "caption_bbox": [431, 836, 758, 849]}, {"image_id": 7, "file_name": "733_07.png", "page": 9, "dpi": 300, "bbox": [82, 112, 764, 989], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) Departments of France. (b) Counties of California (The bottom map shows the same tile assignments plotted as circles).", "caption_bbox": [78, 1001, 747, 1014]}, {"image_id": 8, "file_name": "733_08.png", "page": 10, "dpi": 300, "bbox": [61, 112, 761, 991], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: (a) Countries of continental Africa. (b) Boroughs of London.", "caption_bbox": [234, 1004, 589, 1017]}, {"image_id": 9, "file_name": "733_09.png", "page": 11, "dpi": 300, "bbox": [62, 112, 415, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: A poor tile map. States of the USA; no centroid noise, centroids (and hence boundary) not transformed, boundary smoothed (30 basis functions), no grid shift. ", "caption_bbox": [63, 298, 397, 341]}], "734": [{"image_id": 0, "file_name": "734_00.png", "page": 1, "dpi": 300, "bbox": [62, 622, 764, 865], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Layout results after overlap removal with two methods without (b) and two methods with (c) order preservation. Rectangles are colored by displacement with respect to their actual position (a). Both with and without order preservation RE A RRANGE results in a layout with smaller displacement and better shape preservation than PRISM. ", "caption_bbox": [63, 570, 762, 614]}, {"image_id": 1, "file_name": "734_01.png", "page": 4, "dpi": 300, "bbox": [412, 113, 757, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overlap computation for correct (a) and reversed (b) orthogonal order in the x-dimension ", "caption_bbox": [428, 284, 762, 312]}, {"image_id": 2, "file_name": "734_02.png", "page": 5, "dpi": 300, "bbox": [430, 717, 763, 974], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Examples of synthetic test data with varying label shapes (a-c) and density (d-f) ", "caption_bbox": [428, 981, 762, 1009]}, {"image_id": 3, "file_name": "734_03.png", "page": 6, "dpi": 300, "bbox": [440, 589, 755, 959], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparison of runtime in seconds, averaged over three runs for each algorithm. Both with and without order repair, RE A RRANGE is faster in the vast majority of the cases. ", "caption_bbox": [428, 966, 762, 1010]}, {"image_id": 4, "file_name": "734_04.png", "page": 7, "dpi": 300, "bbox": [83, 112, 764, 605], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Displacement (a), Procrustes correlation (b) and order violations (c) for PRISM versus RE A RRANGE and displacement (d) and Procrustes correlation (e) for PRISM with order repair versus RE A RRANGE with order repair. Each dot represents one test instance, the color indicates the number of nodes in this instance. Points below the diagonal represent instances where RE A RRANGE outperformed PRISM. ", "caption_bbox": [63, 614, 762, 658]}, {"image_id": 5, "file_name": "734_05.png", "page": 8, "dpi": 300, "bbox": [61, 112, 769, 744], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Layout results for four examples. The initial layout is shown in the middle, the results of the two methods without order repair on the left, and the results of both methods with order repair on the right. The rectangles are colored by their displacement. The lighter-colored rectangles in the RE A RRANGE layouts indicate that RE A RRANGE(+OR) results in a smaller displacement than PRISM(+OR). The numbers at the bottom indicate the average displacement (d), Procrustes correlation (p) and average number of violations (v). ", "caption_bbox": [63, 755, 762, 814]}, {"image_id": 6, "file_name": "734_06.png", "page": 9, "dpi": 300, "bbox": [412, 112, 764, 343], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Procrustes correlation (a) and order violations (b) for PRISM versus RE A RRANGE, showing the variation in results de- pending on density. Each dot represents one test instance, the color indicates the node size in this instance. Points below the diagonal represent instances where RE A RRANGE outperformed PRISM. ", "caption_bbox": [428, 352, 762, 426]}, {"image_id": 7, "file_name": "734_07.png", "page": 9, "dpi": 300, "bbox": [71, 113, 415, 522], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Variation in results depending on label shapes. The per- formance of RE A RRANGE remains similar for varying label shape distributions, PRISM clearly performs better with uniform labels than with a mix of tall and wide rectangles. ", "caption_bbox": [63, 530, 397, 589]}, {"image_id": 8, "file_name": "734_08.png", "page": 10, "dpi": 300, "bbox": [61, 112, 747, 975], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Layout result for real-world data: meta-data cards representing culture and heritage sites on the island of Saint Kitts. This order- preserving layout was computed using RE A RRANGE extended with order repair. A map of the island is projected in the background with the same distortion as the bounding box of the point set. The actual positions are shown in the lower left corner. ", "caption_bbox": [63, 986, 762, 1030]}], "735": [{"image_id": 0, "file_name": "735_00.png", "page": 1, "dpi": 300, "bbox": [89, 370, 737, 687], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A part of obesity influence map used in experiment 2; sequential (left) and non-sequential (right) graphs.", "caption_bbox": [124, 703, 700, 716]}, {"image_id": 1, "file_name": "735_01.png", "page": 4, "dpi": 300, "bbox": [412, 112, 759, 513], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The mapping from numerical values (from 5 to 95 in 19 levels) to the three levels (low, medium, and high). Mappings from (a) strength and (b) certainty values to low, medium, and high are not equally divided into three parts. Red trajectory lines show the divisions of the three levels. ", "caption_bbox": [428, 526, 762, 600]}, {"image_id": 2, "file_name": "735_02.png", "page": 4, "dpi": 300, "bbox": [61, 112, 415, 748], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Sequential and non-sequential stimuli in experiment 1.", "caption_bbox": [67, 761, 393, 774]}, {"image_id": 3, "file_name": "735_03.png", "page": 6, "dpi": 300, "bbox": [61, 112, 415, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Means of the first and second edges\u2019 strength-certainty on strength and certainty value mappings and strength and certainty distances. One level difference (=diff.) indicates means of H-M, M- H, M-L, and L-M. Two levels difference indicates means of H-L and L-H. ", "caption_bbox": [428, 335, 762, 409]}, {"image_id": 4, "file_name": "735_04.png", "page": 7, "dpi": 300, "bbox": [68, 112, 415, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Significant main effects on participants\u2019 strength mea- sures and difference from expected answers. (Ind. var. = Indepen- dent variable). ", "caption_bbox": [428, 962, 762, 1005]}, {"image_id": 5, "file_name": "735_05.png", "page": 9, "dpi": 300, "bbox": [129, 329, 697, 505], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The reasons why participants think it is a root cause (a) and a derived effect (b) ordered by the total number of selections.", "caption_bbox": [82, 517, 743, 530]}, {"image_id": 6, "file_name": "735_06.png", "page": 9, "dpi": 300, "bbox": [76, 112, 764, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The root causes (a) and derived effects (b) chosen by the participants ordered by the total number of selections.", "caption_bbox": [108, 301, 716, 314]}], "736": [{"image_id": 0, "file_name": "736_00.png", "page": 2, "dpi": 300, "bbox": [412, 112, 781, 370], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Cluster/Class Separation Properties", "caption_bbox": [478, 395, 712, 408]}, {"image_id": 1, "file_name": "736_01.png", "page": 3, "dpi": 300, "bbox": [429, 325, 762, 496], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: 3D data and a related Star Coordinates.", "caption_bbox": [468, 506, 722, 519]}, {"image_id": 2, "file_name": "736_02.png", "page": 5, "dpi": 300, "bbox": [63, 365, 395, 596], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Discriminative Star Coordinates for labeled data com- pared with traditional Star Coordinates for (top) a 3D synthetic data set with 2 classes and (bottom) the 4D Iris data set with 3 classes. ", "caption_bbox": [63, 606, 397, 664]}, {"image_id": 3, "file_name": "736_03.png", "page": 5, "dpi": 300, "bbox": [412, 112, 766, 374], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Discriminative Star Coordinates for unlabeled Pendigits data. ", "caption_bbox": [428, 406, 762, 434]}, {"image_id": 4, "file_name": "736_04.png", "page": 5, "dpi": 300, "bbox": [435, 456, 754, 662], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The interface for visual cluster exploration and feature selection: (a) the visualization command view; (b) the DSC view; (c) the cluster selection view; and (d) the bar view. In this example, the six selected classes are well separated in the DSC view, where the un-selected class is indicated by the gray icon in the cluster selection view. ", "caption_bbox": [428, 672, 762, 760]}, {"image_id": 5, "file_name": "736_05.png", "page": 6, "dpi": 300, "bbox": [61, 112, 754, 686], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: DSC visualizations for the BreastTissue data set, where the number of clusters is set to 4. (a,b) The default DSC view and the bar chart view; (c) The DSC view generated by transforming the 1st and 9th axes; (d,e) The DSC view and the bar chart view generated by removing the 3rd axis in (a); (f) The DSC view generated by removing the 6th axis in (d), where a blue point highlighted in a red box shows the difference in cluster separation between (d) and (f); (g,h) The DSC view and the bar chart view generated by zooming in the green and magenta clusters; (i) The DSC view generated by using the dimensions corresponding to the right-most 3 axes (8th , 4th and 1st ) in (g). ", "caption_bbox": [63, 697, 762, 770]}, {"image_id": 6, "file_name": "736_06.png", "page": 8, "dpi": 300, "bbox": [61, 112, 763, 510], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The star coordinates visualization for the unlabeled USDA data set. (a-d) show the star coordinates where the numbers of cluster are set to 3, 4, 5, 6, respectively; (e) the bar chart view of the DSC result in (c); (f,g) the DSC view and the bar chart view generated by removing first four axes whose length are noticeably shorter than the rest shown in (e); (h) The DSC view generated by manipulating the most important 4 axes, allowing the five clusters to be shown more clearly. ", "caption_bbox": [63, 525, 762, 583]}, {"image_id": 7, "file_name": "736_07.png", "page": 9, "dpi": 300, "bbox": [76, 112, 764, 376], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The star coordinates visualization for the labeled PENDIGITS data set, which contains 10 different clusters and each cluster corresponds to a digits. (a) The scatterplot visualization generated by projection pursuit; (b) The scatterplot visualization generated by the method [VLL11]; (c) The default DSC view; (d) The DSC view generated by zooming in the red and blue clusters (represent 0 and 6, respectively), where the outlier is highlighted with a black box; (e) The DSC view generated by zooming in the yellow, orange and light blue clusters (represent 4, 9, and 1, respectively), where the outlier is highlighted with a black box; (f) The digit 6 corresponding to the highlighted blue outlier in (d); (g,h) The representative samples from the clusters for digits 0 and 6, respectively; (i) The digit 9 corresponding to the highlighted orange outlier in (d); (j,k) The representative samples 9 and 4 from the two clusters, respectively. ", "caption_bbox": [63, 389, 762, 492]}], "737": [{"image_id": 0, "file_name": "737_00.png", "page": 3, "dpi": 300, "bbox": [78, 136, 387, 567], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Examples of radial axes plots. A principal component biplot of the Breakfast Cereal data set is shown in (a), where the specific configuration of the axis vectors leads to a PCA plot. The dots symbolize individual cereals, while the vectors and axes rep- resent data variables. Users can find optimal approximations (es- timates) of data attributes by projecting embedded points onto the labeled axes. In the example p represents the cereal \u201cAll-Bran with Extra Fiber\u201d, whose attribute values are x = (0, 50, 4, 25), for sugar, calories, protein and vitamin content. The corresponding es- timates obtained through orthogonal projections are x\u0302 = (-3.13, 67.32, 3.81, 15.21). The color bar represents caloric content. In the star coordinates plot in (b) users can manually select specific sets of axis vectors. In this case, healthier cereals are located towards the left. ", "caption_bbox": [63, 573, 397, 788]}, {"image_id": 1, "file_name": "737_01.png", "page": 5, "dpi": 300, "bbox": [412, 112, 764, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Estimation errors for sample 13 (Chevrolet Monte Carlo) of the Auto MPG data set according to the three plots in Fig. 5. ", "caption_bbox": [428, 267, 762, 300]}, {"image_id": 2, "file_name": "737_02.png", "page": 6, "dpi": 300, "bbox": [62, 112, 756, 325], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Linear radial axes plots involving the (standardized) data set used in Fig. 1. In (a) the visualization corresponds to a SC plot where the axis vectors have been chosen in order to depict healthy cereals towards the left. However, estimates of attribute values through projections onto labeled axes (in this case tick marks represent standard deviation units) are highly inaccurate in SC. In particular, the sum of squared estimation errors in this plot is 358.41. Our approach applies a different mapping, through the pseudoinverse matrix V \u2020 , which reduces the sum of squared estimation errors down to 171.18, maintaining the initial configuration of axis vectors, as shown in (b). Finally, (c) shows the related OSC plot, which also achieves the same enhanced estimation accuracy (171.18). However, the method needs to use a different set of axis vectors defined through a new orthonormalized matrix V\u22a5 (obtained through the Gram-Schmidt procedure). ", "caption_bbox": [63, 327, 762, 437]}, {"image_id": 3, "file_name": "737_03.png", "page": 6, "dpi": 300, "bbox": [89, 456, 737, 642], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Different views of a subset of the Auto MPG data set through the: (a) `22 , (b) `1 , and (c) `\u221e norms. In this example, users interested in searching for samples with large values for Acceleration, Horsepower, and Weight, but low values of MPG, would focus on points in the top-left corner of the plots, but may make different decisions depending on the visualization. The location of the marked dark red \u00d7 symbol ", "caption_bbox": [63, 645, 762, 703]}, {"image_id": 4, "file_name": "737_04.png", "page": 7, "dpi": 300, "bbox": [68, 831, 398, 958], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Average runtime needed to solve (10) 1000 times when using the `1 , `22 , and `\u221e norms. The running times for the `2 norm range from 100 to 200 microseconds. ", "caption_bbox": [63, 963, 397, 1011]}, {"image_id": 5, "file_name": "737_05.png", "page": 8, "dpi": 300, "bbox": [62, 112, 738, 521], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Strategies for ordering data according to one variable (axis). The example uses the four variables employed in Fig. 6. The color coding indicates values of MPG, where the samples represented by the red + and \u00d7 symbols contain the lowest and largest values for MPG, respectively. In (a) the values for MPG are not ordered correctly in the adaptable radial axes plot (note that the orthogonal projection of the \u00d7 symbol onto the MPG axis does not provide the largest estimate). In (b) the values of estimates for MPG are exact by applying (13). Another option consists of using (14), which orders the data correctly along one axis, as shown in (c) for k \u00b7 k 2F . Although the estimates for the variable MPG are not exact, the overall accuracy considering all of the attributes is increased with respect to the plot in (b). It is also possible to sort the values by increasing the length of the corresponding axis vectors. In (d) the values for MPG can be estimated well by increasing the length (to 4) of the corresponding axis vector. However, since this strategy compresses the points in the direction of the axis, users would require zooming-in in order to visualize the plot correctly, as shown in (e). An alternative approach, which is more efficient than solving (13), consists of increasing the weight related to the variable and solving (15), as illustrated in (f). In this example, the weight for MPG is 10 times larger than the rest of the weights. Note the similarity between the plots in (b) and (f). ", "caption_bbox": [63, 541, 762, 711]}, {"image_id": 6, "file_name": "737_06.png", "page": 9, "dpi": 300, "bbox": [429, 137, 764, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Average runtimes needed to solve (13) and (14), for N = 1000 data samples. ", "caption_bbox": [428, 286, 762, 319]}, {"image_id": 7, "file_name": "737_07.png", "page": 9, "dpi": 300, "bbox": [67, 136, 398, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Analogy between the problems in (13) and (15). The plot shows average distances between points plotted through (13), where the estimates are exact for the i-th variable, and the corre- sponding mapped points through (15), by scaling the weight (wi,i ) associated with the i-th variable, and where the rest of the weights are equal to 1. Using a larger weight for one variable is very simi- lar to solving (13), especially when using `1 or `22 . ", "caption_bbox": [63, 278, 397, 390]}], "738": [{"image_id": 0, "file_name": "738_00.png", "page": 1, "dpi": 300, "bbox": [412, 380, 764, 757], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Here we illustrate high-level characteristics impacting visual narrative flow: a reader\u2019s interactions with the story, the mechanisms tying the story components into a narrative, and the different forms of visual feedback perceived by the reader as they navigate, read, and interact with the visual data-driven story. ", "caption_bbox": [428, 770, 762, 844]}, {"image_id": 1, "file_name": "738_01.png", "page": 4, "dpi": 300, "bbox": [62, 112, 767, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Two examples of different visual narrative flow in a data visualization story. The scroller shown in (a), by Yee and Chu, walks through a story to teach a basic concept of machine learning [YC15], where scrolling not only moves down the page but moves visualizations and continuously controls their linked animated transitions. We transformed this into a stepper narrative flow, shown in (b) which uses buttons for navigating the story across the story text with timed animated transitions. ", "caption_bbox": [62, 379, 761, 438]}, {"image_id": 2, "file_name": "738_02.png", "page": 7, "dpi": 300, "bbox": [71, 112, 767, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The stories shown here are a scrolling (a) story which contains animations in the story that trigger discretely [GMA\u2217 16] and a stepper (b) which contains a slider for navigating through time points [Stu16]. ", "caption_bbox": [62, 363, 761, 395]}, {"image_id": 3, "file_name": "738_03.png", "page": 9, "dpi": 300, "bbox": [66, 112, 415, 231], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: This mixed-effects model represents the average engage- ment score and 95% confidence interval of all 14 questions for 240 participants across the conditions. The model shows increased en- gagement when using visuals and especially when using animated transitions, but the effect of the other visual narrative flows, stepper and scroller, were not significantly different. ", "caption_bbox": [63, 245, 397, 334]}, {"image_id": 4, "file_name": "738_04.png", "page": 10, "dpi": 300, "bbox": [62, 112, 759, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Participant preferences across all of the pairs of conditions (N = 240). There were 20 participants per pair, and balanced based on which condition was first or second. On the left, preference totals across all conditions emphasize that participants largely preferred conditions with visualizations and animation (stepper, scroller), otherwise they had no preference. ", "caption_bbox": [63, 300, 762, 343]}], "739": [{"image_id": 0, "file_name": "739_00.png", "page": 1, "dpi": 300, "bbox": [62, 496, 764, 739], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Views depicting reported cases of a disease across space and time. Even for this small set of views, many sequences are possible.", "caption_bbox": [65, 475, 760, 488]}, {"image_id": 1, "file_name": "739_01.png", "page": 3, "dpi": 300, "bbox": [412, 112, 764, 558], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Different types of sequences possible for a set of 8 views including different measures (e.g., Gross Domenstic Product (GDP) and birth rate) for four different spatial regions. A viewer could group spatial regions together (a) or measures together (b); she could keep the order of transitions the same across groupings (a, b), reverse them (c), or use inconsistent ordering within groups (d, e). Or, she can simply arrange views such that a minimum of transformations occur from one view to the next (f). ", "caption_bbox": [428, 573, 762, 693]}, {"image_id": 2, "file_name": "739_02.png", "page": 5, "dpi": 300, "bbox": [412, 112, 764, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Example 4-frame stimulus set for measure and hierarchy.", "caption_bbox": [428, 376, 762, 389]}, {"image_id": 3, "file_name": "739_03.png", "page": 5, "dpi": 300, "bbox": [65, 112, 415, 402], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The user interface used in the study. Users were able to reorder frames in the list on the left and flip through the set with the Previous and Next buttons. ", "caption_bbox": [63, 414, 397, 457]}, {"image_id": 4, "file_name": "739_04.png", "page": 9, "dpi": 300, "bbox": [63, 112, 415, 316], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Mean ratings of sequence effectiveness from viewers with 95% confidence intervals. For each combination of factors, the left- most bar represents the sequence where the first factor in the la- bel is the between-factor. We see the same pattern of preferences observed in Study 1 (as summarized in Table 3), with observable differences between all pairs of sequences except when using time versus measure as the between-factor. ", "caption_bbox": [63, 327, 397, 431]}], "740": [{"image_id": 0, "file_name": "740_00.png", "page": 1, "dpi": 300, "bbox": [412, 367, 764, 702], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Inferring a visual specification from a chart image. Given a bitmap image as input, we seek to recover visual encodings for purposes of indexing, search, and retargeting. ", "caption_bbox": [428, 713, 762, 756]}, {"image_id": 1, "file_name": "740_01.png", "page": 2, "dpi": 300, "bbox": [412, 112, 762, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Text role labels, shown for a Vega-generated scatter plot.", "caption_bbox": [428, 316, 762, 329]}, {"image_id": 2, "file_name": "740_02.png", "page": 3, "dpi": 300, "bbox": [63, 112, 764, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Examples chart images from the (a) Vega, (b) Quartz, and (c) Academic Papers corpora.", "caption_bbox": [165, 382, 659, 395]}, {"image_id": 3, "file_name": "740_03.png", "page": 4, "dpi": 300, "bbox": [62, 112, 763, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Text analysis pipeline. (a) Initial bitmap image. (b) Identify bounding boxes for words; note that some boxes are incorrect. (c) Use OCR to recover text for each box. (d) Merge words in lines. (e) Use geometric features of bounding boxes to classify their role in the chart. ", "caption_bbox": [63, 312, 762, 340]}, {"image_id": 4, "file_name": "740_04.png", "page": 4, "dpi": 300, "bbox": [427, 357, 764, 608], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Word detection process. (a) Initial binarized image. (b) Clean image with non-text pixels removed. (c) Connected compo- nents. (d) Filter region candidates using geometric properties. (e) Minimal Spanning Tree using boxes as vertices and distances as edges weights. (f) Detected words after pruning edges in the MST. ", "caption_bbox": [428, 618, 762, 692]}, {"image_id": 5, "file_name": "740_05.png", "page": 6, "dpi": 300, "bbox": [412, 112, 752, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Bounding box features using geometric information, showing the information to compute features for the red box. ", "caption_bbox": [428, 350, 762, 378]}, {"image_id": 6, "file_name": "740_06.png", "page": 8, "dpi": 300, "bbox": [62, 112, 415, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Specification induction. A chart specification is recov- ered for an input scatter plot, using information directly from ex- tracted text and mark type information (colored regions). The grey regions show additional sections that must be inferred (i.e., data type, axis type, and scale domain & range). ", "caption_bbox": [63, 354, 397, 428]}, {"image_id": 7, "file_name": "740_07.png", "page": 9, "dpi": 300, "bbox": [63, 112, 764, 596], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Successful examples of inferred specifications for bitmap inputs from each corpus.", "caption_bbox": [181, 601, 644, 614]}, {"image_id": 8, "file_name": "740_08.png", "page": 10, "dpi": 300, "bbox": [62, 112, 415, 509], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The three most common chart inference failure cases.", "caption_bbox": [70, 520, 390, 533]}], "741": [{"image_id": 0, "file_name": "741_00.png", "page": 1, "dpi": 300, "bbox": [62, 355, 764, 592], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The top images returned by Google-Image-Search for \u201cdrawings of graphs.\u201d Note that the overwhelming majority are graphs that are \u201csymmetric\u201d and also drawn in such a way as to highlight the underlying symmetries. ", "caption_bbox": [63, 602, 762, 630]}, {"image_id": 1, "file_name": "741_01.png", "page": 3, "dpi": 300, "bbox": [412, 112, 764, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: All axes of symmetry identified by the Purchase metric (thin red lines) along with a particular axis (thick red line) and its corresponding subgraph (blue edges). It seems unlikely that a human considering the symmetry of a layout would perceive reflec- tions across so many axes. ", "caption_bbox": [428, 396, 762, 470]}, {"image_id": 2, "file_name": "741_02.png", "page": 4, "dpi": 300, "bbox": [62, 112, 702, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The Purchase, Klapaukh, and stress measures of the graph layout on the right vary in response to the scale of the layout. Note that the Purchase and Klapaukh measures respond erratically to scale, while stress behaves predictably. ", "caption_bbox": [63, 256, 762, 284]}, {"image_id": 3, "file_name": "741_03.png", "page": 4, "dpi": 300, "bbox": [473, 776, 719, 915], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Two layouts of a graph and their reflective symmetry scores according to the Klapaukh metric. Although the layout on the left received a higher score, we would expect human judgment to select the layout on the right as more symmetric, as every edge on its convex hull is rougly reflected onto another across a common diagonal axis. ", "caption_bbox": [428, 921, 762, 1010]}, {"image_id": 4, "file_name": "741_04.png", "page": 5, "dpi": 300, "bbox": [461, 655, 731, 824], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The Purchase score is heavily dependent upon the selec- tion of a tolerance parameter. It is not clear a priori how to set this parameter. ", "caption_bbox": [428, 835, 762, 878]}, {"image_id": 5, "file_name": "741_05.png", "page": 5, "dpi": 300, "bbox": [412, 112, 764, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Two layouts of a graph and their reflective symmetry scores according to the Purchase and Klapaukh metrics. Although the layouts seem quite similar, they received very different scores by each metric. ", "caption_bbox": [428, 314, 762, 373]}, {"image_id": 6, "file_name": "741_06.png", "page": 5, "dpi": 300, "bbox": [456, 415, 736, 564], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a, b) Two layouts of a graph that received much higher scores using Purchase\u2019s metric for reflective symmetry than (c), a layout that a human would likely judge as more symmetric. ", "caption_bbox": [428, 570, 762, 613]}, {"image_id": 7, "file_name": "741_07.png", "page": 7, "dpi": 300, "bbox": [80, 112, 764, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Demographic characteristics of study participants. Math Background is coded as (1) K-12, (2) 100-200 level college, (3) 300-400 level college, (4) graduate. Math Enjoyment ranges from (1) \u201cMath is the absolute worst\u201d to (4) \u201cMath is really great.\u201d ", "caption_bbox": [63, 301, 762, 329]}, {"image_id": 8, "file_name": "741_08.png", "page": 8, "dpi": 300, "bbox": [91, 373, 371, 546], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: An example of a pair of layouts for which the amount of symmetry does not seem to differ, but for which humans demon- strated a preference for a vertical axis of symmetry. ", "caption_bbox": [63, 552, 397, 595]}, {"image_id": 9, "file_name": "741_09.png", "page": 8, "dpi": 300, "bbox": [62, 112, 415, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: On survey items in which layouts with higher P scores were compared to layouts with higher K scores, human judgment significantly preferred P over K (125 vs 85), supporting H1. There was no support for H2. ", "caption_bbox": [63, 277, 397, 336]}, {"image_id": 10, "file_name": "741_10.png", "page": 9, "dpi": 300, "bbox": [91, 112, 415, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Mean values of participants\u2019 responses (1-4) to the ques- tion \u201cHow important were each of the following when you made decisions about symmetry?\u201d ", "caption_bbox": [428, 300, 762, 343]}], "742": [{"image_id": 0, "file_name": "742_00.png", "page": 1, "dpi": 300, "bbox": [62, 618, 764, 824], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Our visual analysis workflow comprises several linked views: The set of patch descriptors (curvature distributions) is visualized after (a) k-medoids clustering, and (b) t-SNE dimensionality reduction and visualization. (c) Interface surface of a selected patch color-coded by Gaussian curvature. (d,e) Parallel coordinates views for (d) performance metrics, and (e) simulation parameters. The highlighted lines represent the currently selected patch. (f) Histogram of a selected performance indicator after filtering in the parallel coordinates views. ", "caption_bbox": [63, 551, 762, 610]}, {"image_id": 1, "file_name": "742_01.png", "page": 2, "dpi": 300, "bbox": [62, 112, 415, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of the four stages of the photoelectric current generation process in a BHJ morphology: I. photon absorption, II. exciton generation, III. exciton diffusion, IV. charge separation and transport. Right: Structural features that influence the quality of these stages, ultimately affecting the efficiency of OPV solar cells. ", "caption_bbox": [63, 258, 397, 332]}, {"image_id": 2, "file_name": "742_02.png", "page": 3, "dpi": 300, "bbox": [100, 112, 764, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Patches are small, local cubical regions that are extracted from the whole BHJ morphology (a) for local analysis. Patches are sampled along the backbone (b) of the BHJ morphology. This allows capturing more informative samples compared to sampling patches on a regular grid, as well as adapting patch size to the local size of the morphology. In (b) three example patches are shown via volume renderings embedded in the backbone of the morphology. Patches can be inspected via (c) a close-up view of a selected patch, showing the center of the patch (red dot) on the backbone, and (d) a visualization of the interface between acceptor and donor contained in the patch. ", "caption_bbox": [63, 309, 762, 383]}, {"image_id": 3, "file_name": "742_03.png", "page": 5, "dpi": 300, "bbox": [75, 773, 398, 925], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: PISD descriptor. Each patch, set of patches, or whole morphology, can be visualized via the corresponding patch inter- face shape distribution (PISD) in the domain of normalized prin- cipal curvatures. This helps with understanding shape characteris- tics and similarities/differences between patches/morphologies. ", "caption_bbox": [63, 936, 397, 1010]}, {"image_id": 4, "file_name": "742_04.png", "page": 6, "dpi": 300, "bbox": [62, 112, 759, 460], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparative visualization of patch interface shape distributions. We show the overall PISD of each of the 54 morphologies used in this study, and selected examples of the corresponding volumes (bottom row). By studying the PISDs, scientists can decide to quickly filter some volumes\u2014for example, less dense volumes. The PISD icons here show the total distribution of all patches in each morphology. ", "caption_bbox": [63, 470, 762, 513]}, {"image_id": 5, "file_name": "742_05.png", "page": 7, "dpi": 300, "bbox": [66, 112, 764, 595], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Patch cluster representatives. The cluster centers (medoids) of the 60 patch clusters. 3D views of example patches are shown at the bottom right (color-coded by Gaussian curvature). From these cluster centers, scientists can obtain a quick characterization of the major shapes generated by the corresponding simulation parameters with respect to curvature (PISD) characteristics. ", "caption_bbox": [62, 604, 761, 647]}, {"image_id": 6, "file_name": "742_06.png", "page": 8, "dpi": 300, "bbox": [62, 112, 415, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Charge paths traversing a selected patch. The charge paths passing through any given patch can be inspected individu- ally. Important path properties, such as their (global or local) tor- tuosity, can be color-coded on the visualization of the path line. ", "caption_bbox": [63, 323, 397, 382]}, {"image_id": 7, "file_name": "742_07.png", "page": 9, "dpi": 300, "bbox": [100, 112, 764, 437], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Case study 1. 3D views of patches that belong to clusters 31 and 37 as examples for the output generated during the analysis session for Case Study 1. This illustrates why these cases had low bottleneck values, although they are close to the anode. This is a new counterexample for a common domain expert belief. Moreover, they have some distribution of an \u201chour glass shape.\u201d For cluster 31, the figure shows that this is caused by the local topology, since few paths are allowed to pass through the patch, especially after branching. ", "caption_bbox": [63, 446, 762, 505]}, {"image_id": 8, "file_name": "742_08.png", "page": 10, "dpi": 300, "bbox": [62, 112, 725, 613], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Case study 2. (a): Before analysis using our system, the domain experts considered a tortuosity value of less than 1.1 as good. Using the Case Study 2 analysis, however, they could strengthen this assumption by jointly exploring good tortuosity values and bad bottleneck values for each patch, rather than for the whole volume; then generate histograms corresponding to this combination of properties instead. (b,c,d): A second question concerned bottlenecks close to the cathode (low z values). (a) query on very high bottlenecks after filtering 3,136 patches. (b) query on intermediate\u2013high bottleneck values; (c) one patch that resulted from the intermediate bottlenecks at low z values. ", "caption_bbox": [63, 618, 762, 692]}], "743": [{"image_id": 0, "file_name": "743_00.png", "page": 2, "dpi": 300, "bbox": [62, 112, 415, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example of the delay impact on traveling. The trav- eler may either use \u201cIC 141\u201d or \u201cIC 259\u201d. The traveler may miss \u201cIC 141\u201d because of the possible delay of \u201cICE 203\u201d and, in result, arrives too late for the appointment. ", "caption_bbox": [63, 225, 397, 284]}, {"image_id": 1, "file_name": "743_01.png", "page": 3, "dpi": 300, "bbox": [63, 112, 414, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Comparison of real cumulative and non-cumulative de- lay of an ICE train delay in Germany in 2016. We plot only the first 30 minutes of the potentially unbounded delay. The non-cumulative delay distribution shows that being 25 minutes late has a probabil- ity of 10%. Cumulative delay distribution shows that the train will arrive at most 25 minutes late with a probability of 55%. ", "caption_bbox": [63, 345, 397, 434]}, {"image_id": 2, "file_name": "743_02.png", "page": 5, "dpi": 300, "bbox": [63, 538, 394, 631], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visual representation of cumulative and non-cumulative delay probabilities. ", "caption_bbox": [63, 638, 397, 666]}, {"image_id": 3, "file_name": "743_03.png", "page": 5, "dpi": 300, "bbox": [63, 435, 390, 528], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visualization of available train connections with depar- ture and arrival times. The final design also shows the train number. ", "caption_bbox": [63, 377, 397, 405]}, {"image_id": 4, "file_name": "743_04.png", "page": 5, "dpi": 300, "bbox": [413, 112, 764, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Different designs for delay bars: the problem of (non- cumulative) train delays overlapping connecting trains and possi- ble solutions. ", "caption_bbox": [428, 391, 762, 434]}, {"image_id": 5, "file_name": "743_05.png", "page": 6, "dpi": 300, "bbox": [62, 112, 415, 375], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visual representation of cumulative and non-cumulative delay probabilities (final design). ", "caption_bbox": [63, 382, 397, 410]}, {"image_id": 6, "file_name": "743_06.png", "page": 6, "dpi": 300, "bbox": [414, 112, 742, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Different possibilities to emphasize critical transfers.", "caption_bbox": [436, 361, 754, 374]}, {"image_id": 7, "file_name": "743_07.png", "page": 7, "dpi": 300, "bbox": [62, 515, 403, 650], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: When the user hovers a connection, tooltips are dis- played. The mouse pointer is indicated as red circle. ", "caption_bbox": [63, 661, 397, 689]}, {"image_id": 8, "file_name": "743_08.png", "page": 7, "dpi": 300, "bbox": [80, 112, 414, 449], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Design options to show connections with alternative con- necting trains. ", "caption_bbox": [63, 458, 397, 486]}, {"image_id": 9, "file_name": "743_09.png", "page": 8, "dpi": 300, "bbox": [62, 112, 415, 336], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Train connection visualized in the study using Deutsche Bahn [DB a] and \u00d6ffi [Scha] display types. ", "caption_bbox": [63, 344, 397, 373]}, {"image_id": 10, "file_name": "743_10.png", "page": 9, "dpi": 300, "bbox": [413, 112, 764, 730], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: The percentage of correct answers for task set 1. Aster- isks denote significant results according to Fisher test, see Table 1. ", "caption_bbox": [428, 737, 762, 765]}, {"image_id": 11, "file_name": "743_11.png", "page": 9, "dpi": 300, "bbox": [62, 112, 414, 320], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Study data shown with the cumulative design.", "caption_bbox": [86, 330, 373, 343]}], "744": [{"image_id": 0, "file_name": "744_00.png", "page": 1, "dpi": 300, "bbox": [62, 560, 764, 804], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Abstracted movements are shown together with overviews on varying levels of abstraction. On the left, all attack turns of both teams with a shot on goal event of an entire soccer match are shown revealing the different attacking styles of the teams. On the right, several player trajectories are shown for a few seconds of movement revealing similarly moving groups on the soccer pitch. ", "caption_bbox": [62, 509, 761, 552]}, {"image_id": 1, "file_name": "744_01.png", "page": 4, "dpi": 300, "bbox": [62, 112, 729, 379], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The image illustrates our basic idea and implementation of chaining several different trajectory abstraction techniques. The different layers and used techniques are shown on top. In the center of the figure, we can see how the techniques are parameterized and mapped to a global level of abstraction parameter. The bottom shows the visual outputs for some of the steps within this abstraction space. ", "caption_bbox": [62, 392, 761, 435]}, {"image_id": 2, "file_name": "744_02.png", "page": 5, "dpi": 300, "bbox": [100, 112, 764, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Hovering interactions are provided in each layer: In the detail layer, hovering specific events will reveal tool-tips and player trajectories. In the simplification layer, the trajectory is highlighted and the events are shown. In the aggregation layer, the cluster is highlighted and different tool-tips reveal the involved players and event counts. Further, the sample points of the cluster representation are shown and the cluster member trajectories are visualized in the background including their convex hull. ", "caption_bbox": [62, 304, 761, 363]}, {"image_id": 3, "file_name": "744_03.png", "page": 7, "dpi": 300, "bbox": [65, 112, 764, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Exploratory Team-Turn Analysis: All turns of the teams are shown in A1 and B1 revealing different tactical attacking styles. The system lets the analyst explore and select clusters of interest interactively drilling down into particular team-turns of interest. In A1-A2-A3, the analyst investigated \u201cunsuccessful\u201d turns. In B1-B2-B3 the analyst investigated turns initiated by a long ball of the goal keeper. ", "caption_bbox": [62, 291, 761, 334]}, {"image_id": 4, "file_name": "744_04.png", "page": 7, "dpi": 300, "bbox": [66, 347, 761, 475], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Analyzing Player Segments: Player trajectory segments are created based on movement speed, acceleration, and straightness (A). All the sprint segments are filtered (B). The resulting sprint segments of this player can be abstracted using our approach (C). The aggregated sprint view allows us to discover the main sprint areas and a few outliers (D). ", "caption_bbox": [61, 487, 763, 530]}, {"image_id": 5, "file_name": "744_05.png", "page": 8, "dpi": 300, "bbox": [62, 112, 415, 389], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The participants had to perform the visual abstraction tasks manually on a sheet of paper. A few examples of the partici- pants drawings are shown on the left and the computed visualiza- tions are shown on the right (one example for each layer). ", "caption_bbox": [62, 400, 398, 459]}, {"image_id": 6, "file_name": "744_06.png", "page": 8, "dpi": 300, "bbox": [412, 112, 763, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Two clustering representations for the same trajectories. The k-Means method was considered useful to analyze an aggregated movement direction, whereas k-Medoids was considered more useful to identify soccer-specific patterns. ", "caption_bbox": [427, 281, 764, 340]}, {"image_id": 7, "file_name": "744_07.png", "page": 9, "dpi": 300, "bbox": [412, 112, 764, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The error rates between the manually chosen and recom- mended LoA parameters for both participants and two evaluation cases (personalized vs. \u201cdefault\u201d training). ", "caption_bbox": [427, 347, 763, 390]}], "745": [{"image_id": 0, "file_name": "745_00.png", "page": 3, "dpi": 300, "bbox": [89, 112, 415, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Person Image Concept Time Relation (PICTuRe) Dia- gram. ", "caption_bbox": [63, 287, 397, 315]}, {"image_id": 1, "file_name": "745_01.png", "page": 4, "dpi": 300, "bbox": [62, 112, 415, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Workflow diagram of a base use case. Big arrows show the overall direction, smaller arrows indicate correction steps. ", "caption_bbox": [63, 322, 397, 350]}, {"image_id": 2, "file_name": "745_02.png", "page": 4, "dpi": 300, "bbox": [412, 112, 760, 245], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Schematic overview of the selection model: green areas show the selected image properties; gray bars and dots show the distribution of all images; yellow bars and dots show the distri- bution of only the selections made in the other views; black dots in the time-person chart show images with selected locations and concepts. ", "caption_bbox": [428, 256, 762, 345]}, {"image_id": 3, "file_name": "745_03.png", "page": 5, "dpi": 300, "bbox": [62, 112, 764, 549], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Screenshot of the PICTuReVis system, which highlights a group of people that took pictures of ships at the Sail 2015 event in Amsterdam. (A) The person view shows a list of people, which can be sorted by name, count, similarity, and relevance. (B) The time-person chart shows the distribution of people\u2019s images over time. Glyphs indicate the selection and density of images, and highlight matching temporal and spatial patterns. (C) Controls for the concept threshold and a toggle between the time-person and map view. (D) The concept view shows a list of concepts and can be sorted the same way as the person view. (E) Controls for adjusting the time window w and distance threshold d. (F) The image view shows all images with the selected properties in the other views. (G) Controls that enable users to create custom concepts based on positive and negative example images. (H) A status bar gives information about the object under the cursor. ", "caption_bbox": [63, 561, 762, 665]}, {"image_id": 4, "file_name": "745_04.png", "page": 6, "dpi": 300, "bbox": [62, 112, 415, 372], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison between two people. Circles indicate non- selected images, dots indicate selected images, and lines between images indicate proximity. Only selected images that match within the time window and (an optional) distance threshold are taken into account. The number of matched intervals is the measure for similarity between the two people. ", "caption_bbox": [63, 384, 397, 473]}, {"image_id": 5, "file_name": "745_05.png", "page": 8, "dpi": 300, "bbox": [62, 112, 755, 516], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Steps of an example use case. (A) One person is selected. (B) The characteristics of this person are inspected. The time axis shows a typical irregular pattern. The map shows that images were mostly made in the same part of the country. The top relevant concepts are related to cycling. (C) Inspection of the best matching people on the concepts \u2018cycling\u2019 and \u2018costume\u2019, the top relevant concept not related to cycling. By selecting different concepts we find different matching people. The glyphs and the corresponding images indicate a cluster of people who regularly visit fantasy events. ", "caption_bbox": [63, 537, 762, 611]}], "746": [{"image_id": 0, "file_name": "746_00.png", "page": 4, "dpi": 300, "bbox": [72, 498, 385, 770], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The effect of the additional cost terms, with the number      of gradient descent iterations needed for convergence. ", "caption_bbox": [65, 786, 394, 814]}, {"image_id": 1, "file_name": "746_01.png", "page": 6, "dpi": 300, "bbox": [412, 112, 738, 680], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Plots of pairs of input (x-axis) and output (y-axis) distances. Gray value encodes the density of graph-distance vs. Euclidean-distance pairs. ", "caption_bbox": [428, 686, 762, 729]}, {"image_id": 2, "file_name": "746_02.png", "page": 7, "dpi": 300, "bbox": [412, 112, 764, 638], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: tsNET unbundled (left) and bundled layouts (right) for jazz, cage8, block_2000, and 3elt. Edge colors encode edge lengths ((dark) red = shortest, green = median, blue = longest). ", "caption_bbox": [428, 649, 762, 692]}, {"image_id": 3, "file_name": "746_03.png", "page": 8, "dpi": 300, "bbox": [104, 259, 357, 510], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Original 3D meshes (left) and meshes reconstructed with tsNET in 3D (right). ", "caption_bbox": [63, 521, 397, 549]}], "747": [{"image_id": 0, "file_name": "747_00.png", "page": 2, "dpi": 300, "bbox": [427, 405, 767, 557], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Structure of UN Comtrade data: The data has three char- acteristics, the commodities (green), the countries involved in trad- ing (red-yellow), and the level of time in years (blue). ", "caption_bbox": [428, 559, 762, 602]}, {"image_id": 1, "file_name": "747_01.png", "page": 2, "dpi": 300, "bbox": [428, 744, 763, 872], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: One compound graph: A tree is build containing the countries at its lowest level. The next higher level groups the coun- tries into classes based on their income. Those groups are then di- vided into global north and global south. The adjacency relations represent the global trade connections between countries and form a weighted, directed graph. ", "caption_bbox": [428, 882, 762, 971]}, {"image_id": 2, "file_name": "747_02.png", "page": 3, "dpi": 300, "bbox": [428, 533, 767, 574], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Stream graphs to enable a detailed view on demand: total import (blue) and export (red) evolution of countries can be understood quickly (black line at 2009: impact of financial crisis). ", "caption_bbox": [428, 576, 762, 620]}, {"image_id": 3, "file_name": "747_03.png", "page": 3, "dpi": 300, "bbox": [263, 824, 396, 955], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Fill Ratio a", "caption_bbox": [288, 960, 396, 973]}, {"image_id": 4, "file_name": "747_04.png", "page": 3, "dpi": 300, "bbox": [429, 167, 767, 374], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Overview of our visual design.", "caption_bbox": [492, 376, 698, 389]}, {"image_id": 5, "file_name": "747_05.png", "page": 3, "dpi": 300, "bbox": [63, 419, 395, 539], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Holton\u2019s hierarchical edge bundling scheme.", "caption_bbox": [91, 549, 368, 562]}, {"image_id": 6, "file_name": "747_06.png", "page": 3, "dpi": 300, "bbox": [427, 832, 774, 959], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Interactive selection of countries for 2006 (blue-red).", "caption_bbox": [435, 961, 754, 974]}, {"image_id": 7, "file_name": "747_07.png", "page": 4, "dpi": 300, "bbox": [412, 112, 764, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The construction scheme for our radial layer plot.", "caption_bbox": [443, 343, 746, 356]}, {"image_id": 8, "file_name": "747_08.png", "page": 5, "dpi": 300, "bbox": [62, 112, 415, 351], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Radial layer plot examples.", "caption_bbox": [134, 350, 324, 363]}, {"image_id": 9, "file_name": "747_09.png", "page": 5, "dpi": 300, "bbox": [62, 364, 402, 603], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Construction of the weighted radial tree.", "caption_bbox": [98, 602, 360, 615]}, {"image_id": 10, "file_name": "747_10.png", "page": 5, "dpi": 300, "bbox": [428, 776, 753, 881], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Our data-driven weighted radial tree visualizations for different years in time of the UN Comtrade data. ", "caption_bbox": [428, 884, 762, 912]}, {"image_id": 11, "file_name": "747_11.png", "page": 6, "dpi": 300, "bbox": [63, 383, 395, 591], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Construction of our control polygon c(k1 , k2 ).", "caption_bbox": [85, 595, 373, 610]}, {"image_id": 12, "file_name": "747_12.png", "page": 6, "dpi": 300, "bbox": [428, 590, 761, 782], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Geometrical influence to the bundling of parameter \u03b2\u03b1 in order to reduce overlapping of neighbored leafs (with \u03b2g = 1). ", "caption_bbox": [428, 784, 761, 814]}, {"image_id": 13, "file_name": "747_13.png", "page": 6, "dpi": 300, "bbox": [63, 838, 395, 950], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Start/end point of edges within the sectors.", "caption_bbox": [93, 952, 365, 965]}, {"image_id": 14, "file_name": "747_14.png", "page": 7, "dpi": 300, "bbox": [431, 190, 757, 591], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Weighted Bundling: varying of \u03b2g , \u03b2\u03b1 , \u03b2o .", "caption_bbox": [461, 594, 729, 609]}, {"image_id": 15, "file_name": "747_15.png", "page": 7, "dpi": 300, "bbox": [63, 464, 395, 658], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Weighting influence to bundling of \u03b2o (with \u03b2g = 1).", "caption_bbox": [70, 657, 389, 671]}, {"image_id": 16, "file_name": "747_16.png", "page": 8, "dpi": 300, "bbox": [62, 112, 411, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 17: Flowing Stripes: (top-left) Scheme and (top-right) de- tailed result, (bottom) two examples from USA and Japan in 2008. ", "caption_bbox": [63, 283, 397, 311]}, {"image_id": 17, "file_name": "747_17.png", "page": 9, "dpi": 300, "bbox": [425, 307, 779, 685], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 20: Reveal unknown economic hypotheses.", "caption_bbox": [468, 687, 721, 700]}, {"image_id": 18, "file_name": "747_18.png", "page": 9, "dpi": 300, "bbox": [62, 317, 415, 695], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 19: Investigate known economic facts.", "caption_bbox": [114, 697, 344, 710]}], "748": [{"image_id": 0, "file_name": "748_00.png", "page": 1, "dpi": 300, "bbox": [98, 355, 730, 594], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Dynamic call graph from the open source software project JHotDraw: 1,077 time steps, 982 vertices, and 32,259 directed and weighted edges. Visual parameters: 50 pixels stripe width, 15 times filtered with a box filter, integrated logarithmic weights, topographic color coding, and contour lines of 2 pixels width. ", "caption_bbox": [63, 606, 762, 649]}, {"image_id": 1, "file_name": "748_01.png", "page": 4, "dpi": 300, "bbox": [62, 112, 762, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Interleaving five time steps of a dynamic graph. The original bipartite layout shows every time step separately. We shift the time steps together until only a 1-pixel offset remains between the individual time steps. Patterns in the graph that exist for multiple time steps are elongated along the horizontal axis. ", "caption_bbox": [63, 325, 762, 368]}, {"image_id": 2, "file_name": "748_02.png", "page": 4, "dpi": 300, "bbox": [108, 416, 337, 556], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Variants of graph layouts for an example graph consist- ing of 5 vertices and 5 directed edges. (a) Node-link diagram in the 2D plane; graph structure visibility is traded for visual scalabil- ity. (b) Bipartite graph layout (1D) with links pointing from left to right; visual scalability is traded for graph structure visibility. ", "caption_bbox": [63, 564, 397, 638]}, {"image_id": 3, "file_name": "748_03.png", "page": 5, "dpi": 300, "bbox": [75, 112, 764, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Interleaving with 50 pixels wide stripes, 1 pixel offset, and varying box filter iterations: (a) no filter, (b) 10 times, (c) 20 times.", "caption_bbox": [70, 263, 753, 276]}, {"image_id": 4, "file_name": "748_04.png", "page": 5, "dpi": 300, "bbox": [74, 297, 754, 538], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Our technique with a box filter applied 5 times and varying stripe widths: (a) 1 pixel, (b) 2 pixels, (c) 10 pixels, (d) 50 pixels, (e) 75 pixels, (f) 100 pixels. ", "caption_bbox": [63, 546, 762, 574]}, {"image_id": 5, "file_name": "748_05.png", "page": 7, "dpi": 300, "bbox": [71, 112, 771, 402], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The JHotDraw dynamic call graph during runtime as an interleaved dynamic graph visualization where each vertical stripe is 50 pixels wide. A topographic color coding is applied and only the density information of the links is displayed. No low-pass filter was applied. ", "caption_bbox": [63, 419, 762, 447]}, {"image_id": 6, "file_name": "748_06.png", "page": 8, "dpi": 300, "bbox": [62, 112, 771, 403], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visualization of the JHotDraw dynamic call graph dataset. The stripe width is 50 pixels, a box filter was applied 15 times, and a topographic color coding is used to represent the edge density. Contour lines with 1 pixel width are added to enhance regions of similar densities. Different patterns in the visualization are annotated. ", "caption_bbox": [63, 419, 762, 462]}, {"image_id": 7, "file_name": "748_07.png", "page": 9, "dpi": 300, "bbox": [72, 112, 771, 414], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The US domestic flight traffic data for the time period from July 1st, 2001 to December 31st, 2001 on a per-hour basis. We can clearly see the gap after the 9/11 terror attacks and the changing dynamic graph patterns afterward. Visual parameters: 10 pixels stripe width, 3 times smoothed by a box filter, integrated logarithmic weights, topographic color coding, and contour lines added. Different patterns in the visualization are annotated. ", "caption_bbox": [63, 429, 762, 488]}], "749": [{"image_id": 0, "file_name": "749_00.png", "page": 1, "dpi": 300, "bbox": [63, 357, 764, 712], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Graffinity visualizing 11727 flight paths with length \u2264 3 connecting states in the mid-western USA (Minnesota, Iowa, North Dakota and South Dakota) to states in the Pacific Northwest (Oregon and Washington). Graffinity consists of five views: the query interface, the connectivity matrix, the intermediate node table, and two views showing details about selected paths: the path list and the node-link view. The 138 paths connecting the airport FSD (Sioux Falls, SD) to PDX (Portland, OR) are selected and displayed in the path list view. ", "caption_bbox": [63, 719, 762, 778]}, {"image_id": 1, "file_name": "749_01.png", "page": 3, "dpi": 300, "bbox": [62, 112, 415, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Analyzing node connectivity is challenging with tradi- tional graph encodings and path listing techniques. A query for paths connecting nodes A,B,C with nodes F,G returned a subgraph shown here. Node-link diagrams (left) give an overview of graph topology but require manual tracing to analyze relationships be- tween the start and end nodes. Adjacency matrices (middle) are ill suited for connectivity analysis as tracing paths is challenging in matrices. Path lists (right) do not provide a connectivity overview. ", "caption_bbox": [63, 241, 397, 361]}, {"image_id": 2, "file_name": "749_02.png", "page": 4, "dpi": 300, "bbox": [62, 112, 415, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The construction of a connectivity matrix using the sub- graph introduced in Figure 2. We create path sets based on common start and end nodes then represent those sets in a matrix where each cell shows a metric applied to paths connecting a pair of nodes. Examples of path-based metrics shown here are the count of paths connecting two nodes and the minimum distance between two nodes. Additionally, the matrix rows and columns can be ag- gregated by computing the union of the corresponding path sets. ", "caption_bbox": [63, 349, 397, 469]}, {"image_id": 3, "file_name": "749_03.png", "page": 5, "dpi": 300, "bbox": [62, 112, 415, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The intermediate node table for the connectivity matrix shown in Figure 3. Rows correspond to nodes and columns corre- spond to a node\u2019s position in a path of a certain length. Here, node D appears once as the middle node in paths of length two. Node E is included twice as the second node in paths of length three. ", "caption_bbox": [63, 324, 397, 398]}, {"image_id": 4, "file_name": "749_04.png", "page": 5, "dpi": 300, "bbox": [412, 112, 764, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The flight query interface defines paths by a maximum length as well as attributes of the start and end nodes. Here, the user can select any attributes matching the input string \u201cWA\u201d. ", "caption_bbox": [428, 365, 762, 408]}, {"image_id": 5, "file_name": "749_05.png", "page": 6, "dpi": 300, "bbox": [412, 112, 748, 523], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The connectivity matrix supports dynamic aggregation of nodes by attribute. Here, the connectivity matrix from Figure 1 is aggregated by starting node state; the airports in Minnesota (MN) are then expanded. Different color scales in aggregated cells ac- count for differences in scales and emphasize the aggregation. Dot- plots represent quantitative attributes for both the aggregated and expanded rows. ", "caption_bbox": [428, 534, 762, 638]}, {"image_id": 6, "file_name": "749_06.png", "page": 6, "dpi": 300, "bbox": [62, 410, 399, 582], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Two encodings for the number of paths connecting Cal- ifornia to New York. Left is a bar chart where height encodes the number of paths. Right is a bar chart where the left bar encodes paths of length one and the right bar encodes paths of length two. ", "caption_bbox": [63, 592, 397, 651]}, {"image_id": 7, "file_name": "749_07.png", "page": 6, "dpi": 300, "bbox": [62, 112, 415, 320], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Different metrics applied to direct flights between Los Angeles and San Francisco area airports. The count of flights is shown on the left, the percent of flights with more than a 15 minute delay is shown on the right. ", "caption_bbox": [63, 330, 397, 389]}, {"image_id": 8, "file_name": "749_08.png", "page": 7, "dpi": 300, "bbox": [412, 112, 764, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: A node-link view with geographic layout for the data selected in Figure 1. Graffinity also supports force-directed layouts for this diagram. ", "caption_bbox": [428, 380, 762, 423]}, {"image_id": 9, "file_name": "749_09.png", "page": 7, "dpi": 300, "bbox": [62, 112, 415, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The connectivity matrix supports dynamic ordering. The left matrix is in the order that was returned by the database query, while the right matrix is using an optimal leaf ordering algorithm. ", "caption_bbox": [63, 338, 397, 381]}, {"image_id": 10, "file_name": "749_10.png", "page": 8, "dpi": 300, "bbox": [62, 112, 760, 320], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Using Graffinity to discover anomalies in the connectome graph. Here, the connectivity matrix shows paths of length two con- necting cone bipolar cells to rod bipolar cells. (1) The intermediate node 179 with label YAC Ai participates in a large number of these crossover paths. Hovering on this row in the intermediate node table reveals the starting and ending nodes of these paths in the connectivity matrix. (2) The yellow boxes around matrix cells for the rows of CBb3 and CBb6 show that node 179 receives input from both of these classes. This is surprising as nodes with label YAC Ai should not form connections with CBb3 nodes, though they technically could access them. We questioned whether this anomaly was a biological wiring error or a data collection error. Ultimately, Graffinity guided access to the database images, showing the anomaly to be an annotation error. ", "caption_bbox": [63, 332, 762, 436]}], "750": [{"image_id": 0, "file_name": "750_00.png", "page": 2, "dpi": 300, "bbox": [62, 112, 415, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example CRM Spectra", "caption_bbox": [146, 266, 314, 279]}, {"image_id": 1, "file_name": "750_01.png", "page": 4, "dpi": 300, "bbox": [62, 112, 415, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Components of the interactive visual analysis tool.", "caption_bbox": [77, 353, 383, 366]}, {"image_id": 2, "file_name": "750_02.png", "page": 5, "dpi": 300, "bbox": [72, 112, 415, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Geometric primitives: Common blob for classification (left) and ]blob for (material transition or) property ratios (right) ", "caption_bbox": [63, 308, 397, 338]}, {"image_id": 3, "file_name": "750_03.png", "page": 6, "dpi": 300, "bbox": [62, 112, 760, 348], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visual discriminability comparison for RGB and CIE L\u2217C\u2217 h\u2217 color mapping: RGB mapping leads to low brightness and hue variations (left). CIE L\u2217C\u2217 h\u2217 mapping leads to more contrast and hue variations (middle). Sample spectra of four locations marked in the CIE L\u2217C\u2217 h\u2217 mapping (right). ", "caption_bbox": [63, 358, 762, 405]}, {"image_id": 4, "file_name": "750_04.png", "page": 7, "dpi": 300, "bbox": [119, 112, 764, 453], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The Main User Interface Components.", "caption_bbox": [289, 465, 535, 478]}, {"image_id": 5, "file_name": "750_05.png", "page": 8, "dpi": 300, "bbox": [72, 396, 389, 579], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Analyzing region (D) in Fig. 6a: The selection in the his- togram (left bottom) discriminates region (D) from a crystal facet not in focus of the microscope (right). Sample spectra of the two regions are shown in the upper left image. ", "caption_bbox": [63, 593, 397, 652]}, {"image_id": 6, "file_name": "750_06.png", "page": 8, "dpi": 300, "bbox": [62, 112, 750, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Material Discrimination: The reference visualization generated by a physicist expert (6a) showing the regions of interest. Resulting visualizations from the chemist and the image analyst using pyMCA (6b,6c) with our preprocessing, and the results using our method with a simple peak integration (6d) and an 2D TF additionally incorporating FWHM for all three bands (6e). All methods analyze three peaks, i.e., related to Ca(OH)2 (calcium hydroxide, green), CaCO3 (calciumcarbonat, red), and a secondary peak (blue). ", "caption_bbox": [63, 307, 762, 366]}, {"image_id": 7, "file_name": "750_07.png", "page": 9, "dpi": 300, "bbox": [62, 112, 764, 456], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Graphene Thickness & Transition: The reference results achieved by the physicist using his proprietary tool (8a), by the image analyst (8b) and the chemist (8c), both using pyMCA and the preprocessing of our system. In all cases, the \u2018D\u2019, \u2018G\u2019 and the \u20182D\u2019 integrated peak intensities are colored in blue, green, and red, respectively. Applying two 2D TFs for the \u2018D\u2019, \u2018G\u2019 and the \u20182D\u2019 peaks areas and FWHM in combination with a foreground selection yields improved boundaries (8d). Computing the spatial-spectral gradient magnitudes and color mapping according to the discriminative band visualizes clearly the material transitions (8e). The combined visualization shows the intrinsic material structure and the precise material boundaries highlighted in white (8f). The graphene histogram (8g) depicts the intensity ratios between the \u2018G\u2019 and the \u20182D\u2019 bands and separates background (A) from mono-layer (B) and multi-layer graphene (C). ", "caption_bbox": [63, 469, 762, 573]}, {"image_id": 8, "file_name": "750_08.png", "page": 9, "dpi": 300, "bbox": [428, 605, 763, 810], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: TF Graph: The graph shows the background deselec- tion (TF1, TF2 and TF6 cascading TF1 and TF2), the peak analy- sis (TF3\u2013TF5), which is cascaded with the background deselection (TF7\u2013TF9) for the homogeneity image. In a second visualization, the peak analysis is cascaded with the 2nd order multidimensional gradient in order to visualize the material transition (TF10\u2013TF12). ", "caption_bbox": [428, 823, 762, 912]}, {"image_id": 9, "file_name": "750_09.png", "page": 10, "dpi": 300, "bbox": [62, 112, 415, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Graphene Connectivity", "caption_bbox": [142, 325, 318, 338]}], "751": [{"image_id": 0, "file_name": "751_00.png", "page": 3, "dpi": 300, "bbox": [65, 114, 415, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Explanation of Cleveland\u2019s original cycle plot (adapted from Aigner et al. [AMST11]). Each individual day is labeled with the same letter in the conventional line plot (left) and the cycle plot (right). In the cycle plot the days within one group are connected to form a line. The average value for this day of week is indicated by a horizontal line. ", "caption_bbox": [63, 253, 397, 342]}, {"image_id": 1, "file_name": "751_01.png", "page": 5, "dpi": 300, "bbox": [72, 114, 764, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Transformation of an original cycle plot to a distance-based cycle plot. Considering the group centers \u00b51, . . ., \u00b5s as points forming a time series line plot and using the distance to the global center \u00b5, we construct the base of the groups, transformation f 1 , as described in Section 5.1. We do the same transformation f 2 for the pattern within each group. Both, the group centers and the points within each group, can form different patterns that are comparable to a seasonal pattern or trend in the original cycle plot. ", "caption_bbox": [62, 362, 761, 424]}, {"image_id": 2, "file_name": "751_02.png", "page": 6, "dpi": 300, "bbox": [62, 114, 764, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Construction of the distance-based cycle plot with a bivariate example. The construction of the bivariate cycle plot on the right is based on Mahalanobis distances of the bivariate data points to the respective group center (e.g., transformation g1 ) and on Mahalanobis distances of the group centers to the global center (transformation g2 and g3 ). The usage of distance measures that are applicable to p-dimensional space, is a key aspect applied in our data abstraction. The ellipses illustrate the spread of the data captured in the covariance matrix. ", "caption_bbox": [62, 356, 761, 430]}, {"image_id": 3, "file_name": "751_03.png", "page": 7, "dpi": 300, "bbox": [62, 114, 764, 437], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Prototype implementation of our interactive exploration environment utilizing the Mahalanobis-distance-based cycle plot. The prototype employs coordinated multiple views with the distance-based cycle plot (a) next to the underlying univariate plots: an original cycle plot (b) followed by the univariate time series line plot (c). In this screenshot we use space-efficient sparkline representations, in order to provide a comprehensive overview. The small plots on the right side (b+c) can be changed to a more detailed view with a scroll bar for detailed exploration. The bottom left shows the control panel for interactive exploration (d). Color encodes the type of outlier and sliders are used to specify outlier-boundary values. (b\u2019) is the original cycle plot of variable temperature, used as example in Section 5.1. ", "caption_bbox": [63, 447, 762, 536]}], "752": [{"image_id": 0, "file_name": "752_00.png", "page": 2, "dpi": 300, "bbox": [62, 112, 415, 403], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Entity Graph of the combined transcripts of the three presidential debates between Trump and Clinton. The minimum entity-pair frequency for this graph is set to 3, resulting in a high- level overview of all important entity pairs and the influence of cer- tain topics in the debate, such as taxes, jobs, and ISIS. ", "caption_bbox": [63, 419, 397, 493]}, {"image_id": 1, "file_name": "752_01.png", "page": 4, "dpi": 300, "bbox": [412, 112, 762, 228], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Example of generating entity-pairs with the distance- restricted entity-relationship model. ", "caption_bbox": [428, 241, 762, 269]}, {"image_id": 2, "file_name": "752_02.png", "page": 4, "dpi": 300, "bbox": [429, 870, 760, 988], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Abstraction of named-entities from the text-level to the abstracted distant-reading views. ", "caption_bbox": [428, 1002, 762, 1030]}, {"image_id": 3, "file_name": "752_03.png", "page": 6, "dpi": 300, "bbox": [62, 112, 762, 509], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Entity graph of the first presidential debate between Trump and Clinton, with a minimum entity-pair frequency of 2.", "caption_bbox": [98, 522, 727, 535]}, {"image_id": 4, "file_name": "752_04.png", "page": 7, "dpi": 300, "bbox": [86, 112, 764, 532], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A location-anchored concept graph depicting entities related to the topic \u201cwar on terror\u201d in the first 2016 presidential debate.", "caption_bbox": [71, 544, 754, 557]}, {"image_id": 5, "file_name": "752_05.png", "page": 7, "dpi": 300, "bbox": [81, 734, 360, 974], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Speaker-anchored concept graph from the first presiden- tial debate, focusing on the concept taxes. The graph is anchored by the two candidate speaker-nodes. ", "caption_bbox": [63, 986, 397, 1029]}, {"image_id": 6, "file_name": "752_06.png", "page": 8, "dpi": 300, "bbox": [62, 112, 415, 398], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A temporal graph from all presidential debates concate- nated, showing different perspectives on the concept taxes and that the concept occurs almost entirely during the first debate. ", "caption_bbox": [63, 410, 397, 453]}, {"image_id": 7, "file_name": "752_07.png", "page": 8, "dpi": 300, "bbox": [412, 112, 764, 283], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Search, filter, and visual query interfaces.", "caption_bbox": [465, 297, 726, 310]}, {"image_id": 8, "file_name": "752_08.png", "page": 10, "dpi": 300, "bbox": [430, 348, 761, 539], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparison of the speaker graphs of the presidential candidates of both major parties. ", "caption_bbox": [428, 552, 762, 580]}, {"image_id": 9, "file_name": "752_09.png", "page": 11, "dpi": 300, "bbox": [430, 806, 761, 993], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: A location-anchored concept graph based on one day (Nov 4, 2010) of the Stuttgart 21 mediation. ", "caption_bbox": [428, 1008, 762, 1036]}, {"image_id": 10, "file_name": "752_10.png", "page": 11, "dpi": 300, "bbox": [63, 112, 764, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Comparison between Democratic (D) and Republican (R) debates. From l-r: (R) on ISIS, (D) on ISIS, (R) on guns, (D) on guns.", "caption_bbox": [64, 339, 760, 352]}], "753": [{"image_id": 0, "file_name": "753_00.png", "page": 1, "dpi": 300, "bbox": [62, 660, 763, 873], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Interface featuring visual analytics support for open coding in grounded theory. Text data is processed at the server end to obtain linguistic metadata such as parts of speech, named entities and information content. These are displayed as a series of coordinated overview and detail visualizations to help the analyst identify concepts and relationships between them, and iteratively code the data. ", "caption_bbox": [62, 615, 761, 658]}, {"image_id": 1, "file_name": "753_01.png", "page": 2, "dpi": 300, "bbox": [436, 744, 754, 913], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The stages in grounded theory, from Dillon [Dil12].", "caption_bbox": [438, 928, 750, 941]}, {"image_id": 2, "file_name": "753_02.png", "page": 4, "dpi": 300, "bbox": [62, 112, 415, 186], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Options for highlighting concepts and attributes. Multi- ple checkboxes control the display of named entities and parts of speech in the text view. The checkboxes also function as scented widgets [WHA07], showing the number of occurrences of potential concepts (nouns/verbs) and their attributes (adjectives/adverbs). ", "caption_bbox": [62, 199, 396, 273]}, {"image_id": 3, "file_name": "753_03.png", "page": 4, "dpi": 300, "bbox": [412, 112, 763, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Illustration of a plain text view, skim formatting [BB15] that maps information content to word weight, and parts-of-speech highlighting to show nouns (purple) and adjectives (yellow). Po- tentially important words stand out and can be identified either as concepts (nouns/verbs) or their attributes (adjectives/adverbs). ", "caption_bbox": [427, 306, 761, 380]}, {"image_id": 4, "file_name": "753_04.png", "page": 5, "dpi": 300, "bbox": [65, 112, 415, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Coordination between overview and detail text visualiza- tions. An interaction with the text panel, updates the text overviews indicating the overall position of the current line in the text. When interacting with the text overviews, the corresponding line in the text panel is highlighted, and scrolls into view on mouse click. Overview element selection is aided by a fisheye distortion effect. ", "caption_bbox": [62, 391, 396, 480]}, {"image_id": 5, "file_name": "753_05.png", "page": 5, "dpi": 300, "bbox": [412, 112, 764, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The word cloud is linked to the text panel and the text overview visualizations, and reflects the frequency of word occur- rence. The words in the word cloud are also overlaid with informa- tion content-based skim formatting and parts-of-speech highlight- ing. Selecting a block of text from the transcript, or selecting a code distribution, updates the word cloud to reflect the selection. ", "caption_bbox": [427, 325, 761, 414]}, {"image_id": 6, "file_name": "753_06.png", "page": 6, "dpi": 300, "bbox": [428, 604, 762, 787], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The baseline version used for the user study. This inter- face is identical to the prototype interface, but has been stripped of all visual analytics support. The only visual representation is the interactive code overview, to help keep track of code assignment. ", "caption_bbox": [427, 800, 761, 859]}, {"image_id": 7, "file_name": "753_07.png", "page": 6, "dpi": 300, "bbox": [62, 112, 415, 364], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The topic modeling view shows three topics identified using the Gensim library. Each topic is associated with a group of words. Selecting a topic highlights all lines in the overview and text view with one or more occurrences of the words in the group. ", "caption_bbox": [62, 379, 396, 438]}, {"image_id": 8, "file_name": "753_08.png", "page": 8, "dpi": 300, "bbox": [62, 112, 728, 418], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Interaction patterns for code creation", "caption_bbox": [476, 515, 711, 528]}], "754": [{"image_id": 0, "file_name": "754_00.png", "page": 1, "dpi": 300, "bbox": [62, 678, 763, 907], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The process of merging entities in A MBIGUITY M ATRIX from left to right. On the left, the initial state of the visualization is shown. Users can explore the visualization, as well as the displayed data by tooltips. The middle image shows the process of merging, the prior selected row and column are moved on to the top left, as the arrows indicate. The right image depicts the state after the merge process. The visualizations are created with data from Harry Potter and the Sorcerer\u2019s Stone by J. K. Rowling. ", "caption_bbox": [61, 618, 763, 677]}, {"image_id": 1, "file_name": "754_01.png", "page": 3, "dpi": 300, "bbox": [75, 304, 385, 477], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A MBIGUITY M ATRIX at the example of George Orwell\u2019s 1984, generated by OpenNLP Name Finder. The initial sparse matrix got even sparser, most changes are visible in the upper left half depicting the semantic similarity measure. For visual clarity, we removed the entity labels. ", "caption_bbox": [61, 492, 396, 566]}, {"image_id": 2, "file_name": "754_02.png", "page": 6, "dpi": 300, "bbox": [459, 508, 732, 569], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Harry Potter is referenced in three different ways in three consecutive sentences. Excerpt from Harry Potter and the Sorcerer\u2019s Stone by J. K. Rowling [Row97, Chapter Five]. ", "caption_bbox": [427, 581, 761, 624]}, {"image_id": 3, "file_name": "754_03.png", "page": 7, "dpi": 300, "bbox": [75, 408, 385, 577], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Initial and final state of A MBIGUITY M ATRIX at the exam- ple of Doctor Sleep by Stephen King, generated with the OpenNLP Name Finder. ", "caption_bbox": [61, 592, 398, 635]}, {"image_id": 4, "file_name": "754_04.png", "page": 8, "dpi": 300, "bbox": [445, 112, 746, 414], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Initial view of data from the Stanford NER.", "caption_bbox": [460, 426, 728, 439]}, {"image_id": 5, "file_name": "754_05.png", "page": 8, "dpi": 300, "bbox": [63, 112, 326, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Illustration of the character cell tooltip. On top, basic information such as the co-occurrence and the overall similarity of contexts is shown. Below, two lists of the ten most important common (top) and distinct (word) are shown. At the bottom, the rectangles indicate Plutchik\u2019s basic emotions [Plu80] of each character to intensity, where low indicates light, and dark high intensity. ", "caption_bbox": [61, 270, 396, 359]}, {"image_id": 6, "file_name": "754_06.png", "page": 9, "dpi": 300, "bbox": [61, 112, 415, 471], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Final view of data from the Stanford NER that started with 25 entities. This view shows 18 entities. ", "caption_bbox": [62, 484, 396, 512]}, {"image_id": 7, "file_name": "754_07.png", "page": 10, "dpi": 300, "bbox": [63, 112, 744, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Illustration of visual author profiling by A MBIGUITY M ATRIX.", "caption_bbox": [228, 306, 595, 319]}], "755": [{"image_id": 0, "file_name": "755_00.png", "page": 2, "dpi": 300, "bbox": [63, 112, 738, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example visualizations created using the Stardust library for GPU-based rendering. For more examples, see Section 5 and visit https://stardustjs.github.io/examples. ", "caption_bbox": [63, 327, 762, 355]}, {"image_id": 1, "file_name": "755_01.png", "page": 4, "dpi": 300, "bbox": [63, 112, 755, 356], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Plotting a parametric function (Hypotrochoid) with Stardust. Left (1) creating a platform object with the given \u201ccanvasElement\u201d using the WebGL platform; (2) creating the polyline mark; (3) creating a custom scale for position; (4) setting the attributes for the polyline; (5) assigning data (here we create an array of 10,000 numbers from 0 to 2\u03c0); and (6) rendering the polyline. Right: The resulting plot. Refer to the supplemental material for an animated version of this example. ", "caption_bbox": [63, 356, 762, 415]}, {"image_id": 2, "file_name": "755_02.png", "page": 6, "dpi": 300, "bbox": [63, 112, 764, 414], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Stardust\u2019s rendering process: User code creates mark specifications and data bindings (1, 2). The mark specification is compiled into an internal representation (3). The platform backend, in this case stardust-webgl, converts the internal representation to WebGL shaders (4, 5), and converts the data bindings to WebGL buffers and uniforms (6, 7). Stardust executes the WebGL shaders along with its buffers and uniforms in the GPU to produce the graphics (8). ", "caption_bbox": [63, 415, 762, 474]}, {"image_id": 3, "file_name": "755_03.png", "page": 7, "dpi": 300, "bbox": [66, 112, 764, 279], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Reproduction of Isotype visualization (a) and \u201cThe Daily Routines of Famous Creative People\u201d in circular layout (b) and linear layout (c) with Stardust. ", "caption_bbox": [63, 284, 762, 312]}, {"image_id": 4, "file_name": "755_04.png", "page": 7, "dpi": 300, "bbox": [64, 331, 395, 501], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Reproduction of the Squares visualization [RAL\u2217 17] us- ing Stardust. ", "caption_bbox": [63, 500, 397, 532]}, {"image_id": 5, "file_name": "755_05.png", "page": 8, "dpi": 300, "bbox": [63, 112, 762, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A sample visualization created with Stardust in the coding playground. Developers can create 2D/3D visualizations for three different display environments with the same code. (a, b) run in browsers with WebGL; (c, d) run in the AlloSphere\u2019s Allofw framework with OpenGL 3.3; and (d) uses Omnistereo for a 360\u00b0 stereo effect. ", "caption_bbox": [63, 281, 762, 325]}, {"image_id": 6, "file_name": "755_06.png", "page": 9, "dpi": 300, "bbox": [64, 112, 415, 470], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Performance evaluation results plotted in log-log scales.", "caption_bbox": [63, 470, 397, 483]}], "756": [{"image_id": 0, "file_name": "756_00.png", "page": 1, "dpi": 300, "bbox": [62, 735, 764, 918], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The evolution of our technique. We adapt the commonly known technique of 1D function plots (a) to multiple dimensions by taking a small multiples approach and repeating each plot for each dimension (b). We address the focus point selection problem by sampling over the parameter space and then projecting the slices in the corresponding plot (c). The user can mouse over a particular slice in one plot and the corresponding slices are highlighted in the other dimension plots (d). This allows one to see the corresponding function behaviors in the other dimensions. Finally, we can cluster the function slices (e), to show groups of similar behavior in the manifold. ", "caption_bbox": [62, 660, 761, 734]}, {"image_id": 1, "file_name": "756_01.png", "page": 4, "dpi": 300, "bbox": [412, 111, 760, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: 500 projected slices of the 5th dimension of the 5D Za- kharov [B\u00e4c96] function. It is difficult to see if the slices are bowl shaped or two sets of monotonically decreasing and increasing curves. It is much clearer in the cluster view that there are actu- ally three sets of curves: there is a set of monotonically decreasing curves and a set of monotonically increasing curves. The very low- value curves form a third set. ", "caption_bbox": [428, 248, 762, 353]}, {"image_id": 2, "file_name": "756_02.png", "page": 4, "dpi": 300, "bbox": [439, 369, 763, 685], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The four techniques we used to compare with 1D slices. With the exception of HyperSlice, the images are from the respective papers and show different datasets used in their context. ", "caption_bbox": [428, 699, 762, 743]}, {"image_id": 3, "file_name": "756_03.png", "page": 7, "dpi": 300, "bbox": [66, 111, 415, 390], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Different views of the 2D sinc function. We show the sur- face plot in (a) for reference. Our 1D slice view is shown in (b). The central peak as well as the sub peaks are prominent. For com- parison we show the method of Gerber et al. [GBPW10] in (c)\u2013(e) at different levels of persistence filtering. With no filtering (c) the graph looks much like the original function. The plot is very sensi- tive to the filtering level. (d) and (e) are all very different from each other. ", "caption_bbox": [62, 404, 396, 524]}, {"image_id": 4, "file_name": "756_04.png", "page": 8, "dpi": 300, "bbox": [63, 111, 727, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Two different views of the predictions of four different machine learning regression models on the Boston housing dataset. The top row (a \u2013 d) shows predictions by each model compressed to two dimensions with t-SNE. We colored the points on a continuous color scale with dark blue being 0 and light blue the highest value. The bottom row (e \u2013 h) shows a 1D slice view of the first dimension of the dataset, crime rate. We show the slices of the remaining dimensions in the supplemental material. The 1D slices reveal interesting information about how the models perform and can assist with model selection. We may not want to use the SVM with polynomial kernel (f), for example, since it predicts that home price will go up with higher crime rates. ", "caption_bbox": [62, 444, 761, 533]}, {"image_id": 5, "file_name": "756_05.png", "page": 9, "dpi": 300, "bbox": [85, 111, 415, 411], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: 1D slice and HyperSlice views showing traces of an op- timization algorithm searching for the global minimum of a 5D Ackley function. (a) and (b) show the trace starting at the point (1, 1, 1, 1, 1) while (c) and (d) show the trace starting at the point (2, 2, 2, 2, 2). ", "caption_bbox": [62, 426, 396, 501]}], "757": [{"image_id": 0, "file_name": "757_00.png", "page": 3, "dpi": 300, "bbox": [427, 795, 760, 887], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Underfitting vs. Overfitting", "caption_bbox": [500, 895, 688, 908]}, {"image_id": 1, "file_name": "757_01.png", "page": 3, "dpi": 300, "bbox": [62, 691, 394, 782], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Regression models: (left) linear and (middle-right) non- linear models (blue) to explain the data (black). ", "caption_bbox": [62, 790, 398, 818]}, {"image_id": 2, "file_name": "757_02.png", "page": 4, "dpi": 300, "bbox": [62, 601, 395, 693], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Correlation: influence of the chosen independent and dependent variable to the appearance of a linear regression model. ", "caption_bbox": [62, 701, 396, 729]}, {"image_id": 3, "file_name": "757_03.png", "page": 4, "dpi": 300, "bbox": [428, 319, 760, 409], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Uniformity vs. clumpiness or global vs. local analysis.", "caption_bbox": [432, 417, 756, 430]}, {"image_id": 4, "file_name": "757_04.png", "page": 5, "dpi": 300, "bbox": [62, 601, 394, 691], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Two step process to find the best fitting regression model.", "caption_bbox": [62, 699, 396, 712]}, {"image_id": 5, "file_name": "757_05.png", "page": 5, "dpi": 300, "bbox": [412, 112, 764, 493], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visual Design of the Regression Lens.", "caption_bbox": [474, 500, 715, 513]}, {"image_id": 6, "file_name": "757_06.png", "page": 7, "dpi": 300, "bbox": [62, 112, 764, 498], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Our prototype is separated into four views: (a) visualizes multivariate data by means of a SPLOM; (b) is the interactive analysis area for the investigation of local regression models for a chosen cell from the SPLOM; (c) is a settings window to control regression computation; (d) shows additional information like selected points, regression coefficients and correlation measure for the current selection to be investigated. ", "caption_bbox": [62, 506, 761, 565]}, {"image_id": 7, "file_name": "757_07.png", "page": 8, "dpi": 300, "bbox": [428, 397, 760, 773], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Independent vs. Dependent Variable \u2013 Auto MPG data set: Impact of correlation measure demonstrated on extreme exam- ples for each polynomial model. Good correlation here means that the choice of direction is unimportant, whereas a bad correlation indicates that the models show to be very different. ", "caption_bbox": [427, 783, 763, 857]}, {"image_id": 8, "file_name": "757_08.png", "page": 8, "dpi": 300, "bbox": [65, 442, 393, 699], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Overplotting issue \u2013 Bosting Housing data set: By using the raw selected data points our regression lens returns a polynomial model of degree 4 as best fitted model (Overfitting). However, if we include the out-of-sample error into the regression determination, it changes the model to a quadratic model (Good fit). ", "caption_bbox": [62, 709, 396, 783]}, {"image_id": 9, "file_name": "757_09.png", "page": 8, "dpi": 300, "bbox": [61, 112, 761, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison between global and local regression analysis with the Iris data set. (a) Shows a scatter plot that visualizes petal length as independent variable (x) and petal length as dependent variable (y). The color coding denotes the different class labels of the data (species). (b) By applying a usual global regression analysis, we obtain a cubic function as best fitting model according to the test data subset (colored in dark blue). (c) Shows the result of local regression analysis for the different flower species setosa, versicolor and virginica. ", "caption_bbox": [61, 329, 763, 388]}, {"image_id": 10, "file_name": "757_10.png", "page": 9, "dpi": 300, "bbox": [63, 303, 394, 542], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Uniformity issue \u2013 Wine data set: Lens selections can be verified by comparing the axes histograms (visually) or by the h( f ) measure (analytically). In the background a bad selection with a relatively high h value is shown, which can be improved by using two separated lenses for the two clusters (cutouts on the right). ", "caption_bbox": [62, 551, 396, 625]}], "758": [{"image_id": 0, "file_name": "758_00.png", "page": 1, "dpi": 300, "bbox": [62, 355, 764, 593], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Left: a scatter plot matrix of a sampled cube in 4D, where a cone opening to one side has been cut out. This, however, is impossible to see in the scatter plots alone. Center: the same data set rendered using our sclow plot technique highlighting both the void and its orientation. Right: a close-up of one of the scatter plots showing both the origins of the flow, its concentration and orientation towards infinity using color gradients to illustrate the distance from the sample points. ", "caption_bbox": [63, 603, 762, 662]}, {"image_id": 1, "file_name": "758_01.png", "page": 3, "dpi": 300, "bbox": [71, 112, 764, 282], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Example flow line in two dimensions. Shown on the left is the starting point x of the flow line together with the starting flow direction that is determined by the smallest enclosing ball of N(x), which is here just a single data point. Then, shown from left to right are the points where the set N(x), and thus the direction of flow, changes. The flow line ends (shown on the right) in a local maximum of the distance function, i.e., x is contained in the convex hull of N(x). Note that smallest enclosing balls of more than one point in n dimensions are always n-dimensional. Here only the boundaries (circles in two dimensions) of the balls (disks in two dimensions) are shown. ", "caption_bbox": [63, 288, 762, 362]}, {"image_id": 2, "file_name": "758_02.png", "page": 4, "dpi": 300, "bbox": [431, 459, 760, 689], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Three types of flow lines from left to right, finite flow lines that end in a local maximum of the distance function and represent the interior of the full dimensional shape shown below, infinite flow lines with only one segment that originate on the boundary of the convex hull conv(supp(\u00b5)) shown below in light blue, and infinite flow lines with many segments that hit the medial axis at some finite point and thus represent the cavity shown below in light blue. ", "caption_bbox": [428, 694, 762, 798]}, {"image_id": 3, "file_name": "758_03.png", "page": 4, "dpi": 300, "bbox": [412, 112, 762, 320], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Voids do not need to be represented by critical points of the distance function. Shown are two similar compact sets C that both have a significant void, i.e., empty space in conv(C) \\ C. For both sets a maximal empty ball is shown together with the convex hull of its closest points in the boundary of C. The center of the ball is a local maximum of the distance function only for the set shown on the right, but it is contained in the medial axis for both sets. ", "caption_bbox": [428, 325, 762, 429]}, {"image_id": 4, "file_name": "758_04.png", "page": 5, "dpi": 300, "bbox": [79, 112, 764, 467], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Different types of flow lines. Top, from left to right: scatter plot of the sampled cube data set, flow lines that end in finite maxima [Resolution 250], flow lines that end in finite maxima [Resolution 750], and all infinite flow lines [Resolution 750]. Bottom, from left to right: all infinite flow lines with at most three segments [Resolution 750], all infinite flow lines with at least 38 segments [Resolution 50], all infinite flow lines with at least 38 segments [Resolution 250], and all infinite flow lines with at least 38 segments [Resolution 750]. ", "caption_bbox": [63, 477, 762, 536]}, {"image_id": 5, "file_name": "758_05.png", "page": 6, "dpi": 300, "bbox": [412, 112, 731, 406], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A scatter plot matrix for the sampled shape S together with infinite flow lines that have many segments. [Resolution 50] ", "caption_bbox": [428, 416, 762, 444]}, {"image_id": 6, "file_name": "758_06.png", "page": 6, "dpi": 300, "bbox": [439, 772, 753, 924], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Left: A scatter plot matrix for the sampled shape S after some space rotation. Right: The same scatter plot matrix together with infinite flow lines that have many segments. [Resolution 50] ", "caption_bbox": [428, 934, 762, 977]}, {"image_id": 7, "file_name": "758_07.png", "page": 7, "dpi": 300, "bbox": [436, 204, 764, 363], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Sclow plots for two Gaussians (300 sample points each) in four dimensions. The variance of the Gaussians on the left is 1.2, whereas it is 1.8 for the Gaussians on the right. [Resolution 250] ", "caption_bbox": [428, 372, 762, 415]}, {"image_id": 8, "file_name": "758_08.png", "page": 7, "dpi": 300, "bbox": [70, 237, 399, 396], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Left: A scatter plot matrix for the sampled shape S after a non-linear transformation. Right: The same scatter plot matrix to- gether with infinite flow lines that have many segments. [Resolution 50] ", "caption_bbox": [63, 405, 397, 464]}, {"image_id": 9, "file_name": "758_09.png", "page": 7, "dpi": 300, "bbox": [93, 723, 399, 881], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Left: The essential support of two Gaussians centered on diagonally opposite vertices of a unit cube is shown shown in pink, and the void that separates the support of the two Gaussians is shown in blue. In two dimensions as shown here that void has two components. In three dimensions it is a connected ring (torus). Right: An example in four dimensions where 300 points each have been sampled from two Gaussians with variance 1.4. [Resolution 250] ", "caption_bbox": [63, 891, 397, 1011]}, {"image_id": 10, "file_name": "758_10.png", "page": 7, "dpi": 300, "bbox": [436, 694, 764, 853], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Sclow plots for 500 points sampled from a Gaussian in three dimensions that has been lifted non-linearly into six dimen- sions. Here only finite flow lines are shown. Shown on the left is this data set from which the Dimensions 6 and 5 have been dropped and shown on the right is this data set from which the Dimensions 6, 5, and 4 have been dropped. Note that finite flow lines only appear af- ter three dimensions have been dropped. We should note that drop- ping any other three dimensions shows the same effect. [Resolution 250] ", "caption_bbox": [428, 863, 762, 998]}, {"image_id": 11, "file_name": "758_11.png", "page": 8, "dpi": 300, "bbox": [70, 267, 399, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Left: A sclow plot of 250 samples from a Gaussian in four dimensions. Finite flow lines allow to sketch the essential sup- port of the Gaussian. Infinite flow lines with few segments indicate the boundary points. Right: The same Gaussian together with 15 outliers on a large sphere. The infinite flow lines with few segments now highlight the outliers. [Resolution 350] ", "caption_bbox": [63, 435, 397, 524]}, {"image_id": 12, "file_name": "758_12.png", "page": 8, "dpi": 300, "bbox": [439, 182, 753, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Dimension inference. Left: A scatter plot matrix of all nine dimensions showing high correlation between the last four di- mensions and no visible finite maxima. Right: The same scatter plot matrix after the last four dimension have been removed\u2014note that the data set now is full dimensional which is witnessed by an abun- dance of finite maxima. [Resolution 250] ", "caption_bbox": [428, 343, 762, 432]}, {"image_id": 13, "file_name": "758_13.png", "page": 8, "dpi": 300, "bbox": [439, 767, 753, 918], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Left: A scatter plot of the torso dimensions. Right: The same scatter plot together with finite flow lines and with infinite flow lines with only very few segments. The finite flow lines allow to sketch the essential support of the data set, and the infinite flow lines highlight the extreme points. [Resolution 350] ", "caption_bbox": [428, 928, 762, 1002]}, {"image_id": 14, "file_name": "758_14.png", "page": 9, "dpi": 300, "bbox": [439, 805, 753, 956], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 17: Left: A cavity in the four dimensional projection of the MovieLens data set. Right: Finite flow lines at the tip of the cavity together with movie label information. [Resolution 250] ", "caption_bbox": [428, 966, 762, 1009]}, {"image_id": 15, "file_name": "758_15.png", "page": 9, "dpi": 300, "bbox": [446, 399, 746, 543], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Left: A sclow plot showing finite flow lines of MovieLens data set that has been projected onto the last seven dimensions. Right: The same sclow plot for the MovieLens data set projected onto the last six dimensions shows many more finite flow lines. [Resolution 250] ", "caption_bbox": [428, 553, 762, 627]}, {"image_id": 16, "file_name": "758_16.png", "page": 9, "dpi": 300, "bbox": [79, 112, 764, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Body Dimensions data set. From left to right: A sclow plot of the finite maxima in five dimensions, showing both the support (yellow-orange) and deep finite maxima (dark red) separating the male from the female cluster. A sclow plot showing infinite flow lines with many segments of the torso dimensions, computed on both the samples of the male and female cluster. The same sclow plot, this time computed only on the samples of the female cluster. The same sclow plot, this time computed only on the samples of the male cluster. [Resolution 250] ", "caption_bbox": [63, 304, 762, 363]}, {"image_id": 17, "file_name": "758_17.png", "page": 10, "dpi": 300, "bbox": [63, 112, 767, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 18: Sclow plots featuring finite flow lines for projections of the 14 dimensional MovieLens data set onto the first six, five, four and three, respectively, dimensions (from left to right). Finite flow lines stop to appear in large numbers in five dimensions. [Resolution 300] ", "caption_bbox": [63, 312, 762, 340]}, {"image_id": 18, "file_name": "758_18.png", "page": 11, "dpi": 300, "bbox": [71, 112, 764, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 19: Performance data for computing flow lines. Left: Flow lines per second as a function of the dimension. Middle: Time for computing 100 flow lines per data point again as a function of the dimension. Right: Compute time as a function of the number of seed points per data point. ", "caption_bbox": [63, 314, 762, 357]}], "759": [{"image_id": 0, "file_name": "759_00.png", "page": 1, "dpi": 300, "bbox": [62, 694, 764, 938], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Segmentation of an MRI scan of a malignant tumor in the right hemisphere of the brain. (a) Graph cuts segmentation of the tumor with annotation to denote tumor (green) and not tumor (purple striped). The segmentation (green contour) misses important tumor structure. Our alternative path extraction finds a valid alternative segmentation (blue) that includes this structure. (\u03b2 = 0.6) (b) The uncertainty in the smoothness term that encodes both the noise and blur in the data and also the ridge of the alternate path. (c) Our fast approximation to the smoothness stability that still finds all salient uncertainty features. (d) This structure is lost in the min-marginal visualization [KT06]. (e) A live-wire, partial segmentation of the tumor with an alternative path (blue) on the middle segment (\u03b2 = 0.1) (f) Our uncertainty visualization can be applied to both graph cuts and live-wire segmentations, even partial live-wire segmentations as illustrated. Image courtesy of Kyrre E. Emblem et al [Eea13]. ", "caption_bbox": [63, 567, 762, 687]}, {"image_id": 1, "file_name": "759_01.png", "page": 3, "dpi": 300, "bbox": [412, 112, 764, 296], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) A pixel graph, G used for graph cuts segmentation. The nodes in the graph can have a per node per label data energy, Ed . These are encoded in the edges to logical source, s, and target, t, nodes in the graph. (b) G can also have edges weighted with the smoothness energy, Es . For a planar graph, a dual graph G \u2217 can be used for live-wire, minimum path segmentations. ", "caption_bbox": [427, 303, 761, 393]}, {"image_id": 2, "file_name": "759_02.png", "page": 4, "dpi": 300, "bbox": [412, 112, 764, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Synthetic examples made from a grey object. (a) The rightmost copy has been blurred with a Gaussian filter. Gaussian noise is additionally added on the bottom. Initial foreground label- ing is in green. (b) A naive stability measure is the residual of the minimum cut. Artifacts (erroneous ridges) can be misleading and the instability of the segmentation due to noise is obscured. (c) Vi- sualizing the min-marginal energy [KT06] has similar problems. (d) Our visualization based on min-path stability encodes blur as thicker bands of uncertainty. Noise is also well represented as a chaotic \"flowering\" pattern in the bands. ", "caption_bbox": [428, 321, 762, 471]}, {"image_id": 3, "file_name": "759_03.png", "page": 5, "dpi": 300, "bbox": [63, 112, 415, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Graph cuts uncertainty visualization. (a) Each connected component of the foreground annotation is considered a separate cut of our graph creating a logical annulus. (b) Each annulus is split by the minimum cost path from interior to exterior nodes. Given a node on the annulus, the minimum segmentation passing through it is constructed as the union of two minimum paths going to a split node. The related cost is the basis of our stability measure. ", "caption_bbox": [63, 365, 397, 469]}, {"image_id": 4, "file_name": "759_04.png", "page": 6, "dpi": 300, "bbox": [63, 112, 415, 279], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Alternative Minimum Paths/Cuts procedure for a tree. (a) For each node in our queue, the path formed by a node is traversed, from its endpoint to the root, c, or a previously visited node. A run- ning down count of non-overlapping, \u03c5, (white) and overlapping, \u03c9, (red) nodes to previously accepted paths are recorded. (b) If a path is not accepted, its up count is recorded and its nodes are marked as visited. (c) If the down traversal hits a node previously visited, the values used for acceptance testing (along with the values from the other tree) are the down count plus the recorded tuple of the in- tersecting node. (d) If the path is not accepted, walk down the path while adding the intersecting node\u2019s values. This process is con- tinued until an acceptable path is found, i.e. if a non-rejected path with ratio of overlap to previous paths \u03b1 = \u03c9/(\u03c9 + \u03c5) is lower than a user threshold \u03b2. Then the bookkeeping is reset and re-initialized. ", "caption_bbox": [63, 289, 397, 500]}, {"image_id": 5, "file_name": "759_05.png", "page": 7, "dpi": 300, "bbox": [62, 607, 399, 765], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: 2D time-migrated seismic section from the southern North Sea Silverpit Basin. (a) A horizon trace targeting a low lu- minance pixel path. The expected horizon (orange arrow) given the constraints is missed in favor of another (red). (b) Slight perturba- tion of the right constraint leads to a different trace. (c) The min- path stability illustrates the sensitivity of the constraints, leading to either horizon being a likely trace. (d) Our alternative extraction allows the identification of all horizons in this image (\u03b2 = 0.2). Im- age courtesy of The Virtual Seismic Atlas user Simon Stewart. ", "caption_bbox": [63, 771, 397, 906]}, {"image_id": 6, "file_name": "759_06.png", "page": 7, "dpi": 300, "bbox": [62, 375, 399, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) 2-photon microscopy image of a neuron from a macaque brain. (b) A user can trace two neural paths as minimum paths of high luminance (red) between constraints (squares). (c) The min-path stability illustrating the uncertainty of the tracing. Slight changes of the input can result in a variety of different paths for the data. (d) Our system allows users to find additional, distinct minimum paths (left path: \u03b2 = 0.7; right path: \u03b2 = 0.8) to both determine the stability of the trace, and also automatically extract alternate pathways. Image courtesy of Alessandra Angelucci. ", "caption_bbox": [63, 468, 397, 603]}, {"image_id": 7, "file_name": "759_07.png", "page": 7, "dpi": 300, "bbox": [62, 112, 764, 269], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Confocal microscopy image of a surgically removed prostate gland. (a) Nerve tissue appears as faint bright bands in the image although with much noise. (b) Using live-wire, a user can trace nerves as minimum paths of high luminance (red) between constraints (squares). (c) The min-path stability encodes where the paths could have gone. This not only encodes stability of the minimum paths and alternative paths, but also highlights possible nerves almost imperceptible in the source image. (d) With our approach a user can also extract alternative minimum paths (orange) to both quantify the stability of the trace and save effort by automatically finding other nerve paths (top path: \u03b2 = 0.5, bottom path: \u03b2 = 0.2). Image courtesy of J. Quincy Brown [Wea16]. ", "caption_bbox": [63, 277, 762, 367]}, {"image_id": 8, "file_name": "759_08.png", "page": 8, "dpi": 300, "bbox": [427, 382, 764, 481], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Understanding the uncertainty of a segmentation al- gorithm by inspecting data and smoothness min-path stability. (a) A graph cuts segmentation of an MRI with contrast scan of CNS lymphoma in the left hemisphere of the brain. (b) User annotation denotes tumor (green) and not tumor (purple striped). The segmen- tation misses important structure (orange). (c) Min-marginal visu- alization [KT06] with a combined data and smoothness energies shows the uncertainty, although it is still unclear what is the cause. (d) Looking at the min-path stability measure there is uncertainty in this area that covers the areas missed by the segmentation. (e) Looking at the data term we can see it is ill defined to include this area and will need to be adjusted for future segmentations. Image courtesy of neurosciencecriticalcare.wordpress.com. ", "caption_bbox": [428, 487, 762, 683]}, {"image_id": 9, "file_name": "759_09.png", "page": 8, "dpi": 300, "bbox": [62, 112, 764, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Tumor segmentation of a CT image of pancreatic cancer with multiple liver metastases. (a) The original image. (b) User annotation to denote tumor (green) and not tumor (purple striped). The graph cuts solution is provided in transparent green. Note that tumors 1 and 2 are considered a single region despite the user input and the separation between 3 and 4 is not clear cut. (c) The min-path stability for the data cost shows that the data energy isolates the tumors well but with much noise. More intensity of green denotes a higher likelihood that the pixel is considered tumor. (d) The min-path stability of the smoothness energy illustrates why there may be problems between 1-2 and 3-4. More intensity of green denotes a higher likelihood of the segmentation location given the user\u2019s labels. Notice the ridges of high intensity between the two problem boundaries. (e) Our approximate uncertainty visualization of the smoothness energy. Note that it still illustrates the major structures. (f) Our alternative segmentation calculation can be used to represent the uncertainty when overlaid on the segmentation (\u03b2 = 0.8). (g,h) Comparing to the visualization of the min-marginal energy [KT06] using both data and smoothness or just smoothness. While the pertinent structure exists, it is far more difficult to distinguish from the background noise in the data. Image courtesy of radRounds.com. ", "caption_bbox": [63, 223, 762, 373]}, {"image_id": 10, "file_name": "759_10.png", "page": 8, "dpi": 300, "bbox": [63, 383, 399, 543], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Random walker segmentation [Gra06] for our liver example (top). The segmentation produced, whether considering the foreground as a single or multiple labels or discounting the free parameter (1) or using the value from the previous work (4000), bears little resemblance to the graph cuts segmentation of Fig. 9 (b). The uncertainty visualization of Pra\u00dfni et al. [PRH10] (bot- tom) provides a good visualization of the random walker\u2019s stability, but cannot be generally applied to graph cuts. ", "caption_bbox": [63, 549, 397, 669]}, {"image_id": 11, "file_name": "759_11.png", "page": 9, "dpi": 300, "bbox": [427, 348, 764, 433], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Alternative approaches to visualize our stability field using (a) color maps motivated by perceptual studies [KRC02] (b) HDR gamma correction, and (c) isocontours of our stability field. ", "caption_bbox": [428, 439, 762, 482]}, {"image_id": 12, "file_name": "759_12.png", "page": 9, "dpi": 300, "bbox": [62, 112, 415, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Performance results in seconds for our example datasets. For our technique, we provide timings for the standard calculation, using the calculation cut-off of the previous work [SGSP14], using our dynamic tree update routine, and our fast approximation. In addition, we provide the running times for the state-of-the-art min- marginal calculation [KT06] with and without tree reuse. ", "caption_bbox": [428, 254, 762, 343]}, {"image_id": 13, "file_name": "759_13.png", "page": 10, "dpi": 300, "bbox": [63, 112, 415, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Dynamic shortest path tree update from split path node n j to n j+1 . Subtrees rooted at split path nodes > j are decreased by the cost of edge (n j+1 , n j ). Subtrees rooted at split path nodes \u2264 j are increased by the cost of edge (n j , n j+1 ). Dijkstra\u2019s priority queue is then fed with the decreased nodes on the front between these two forests. ", "caption_bbox": [62, 276, 396, 365]}], "760": [{"image_id": 0, "file_name": "760_00.png", "page": 3, "dpi": 300, "bbox": [434, 858, 761, 923], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Two types of mean tensors for (a) 10 linear anisotropic tensors with the same eigenvalues (0.7, 0.15, 0.15) but different eigenvectors. (b) is the Euclidean mean and (c) is the ensemble mean calculated according to Equation (3). ", "caption_bbox": [428, 951, 762, 1010]}, {"image_id": 1, "file_name": "760_01.png", "page": 4, "dpi": 300, "bbox": [63, 112, 415, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Tensor shape space is defined by the sorted and nor- malized eigenvalues \u03bb\u0303 j . Three glyphs are placed at the corners as reference, colored according to their \u03bb\u0303 j . ", "caption_bbox": [62, 275, 396, 321]}, {"image_id": 2, "file_name": "760_02.png", "page": 4, "dpi": 300, "bbox": [68, 768, 398, 923], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) A group of linear tensors with two distinct orienta- tions. (b) The Euclidean mean tensor. A mean tensor generated ac- cording to Equation (3) would comprise the same scale and shape as the tensors in a) but with a random orientation (thus not shown). ", "caption_bbox": [63, 951, 397, 1010]}, {"image_id": 3, "file_name": "760_03.png", "page": 4, "dpi": 300, "bbox": [432, 801, 758, 925], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) The corresponding dODF glyph for the tensor en- semble in Figure 3a. A conventional direction-encoded colormap is used. (b) The glyph with the threshold set to 60% of the maximum variation. (c) The glyph of (b) min-max normalized to enhance the direction with a large diffusion probability density. ", "caption_bbox": [428, 936, 762, 1010]}, {"image_id": 4, "file_name": "760_04.png", "page": 6, "dpi": 300, "bbox": [412, 112, 755, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Three dODF-based glyphs for (a) an ensemble with grad- ually varying shape and orientation and two ensembles of linear tensors with crossing angle of (b) 60 \u00b0 and (c) 45 \u00b0, respectively. The variation threshold is set to 60% of the maximum variation. The ensembles are illustrated by the small black icons on top. ", "caption_bbox": [428, 280, 762, 354]}, {"image_id": 5, "file_name": "760_05.png", "page": 6, "dpi": 300, "bbox": [62, 112, 415, 420], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualization of the same mean tensor with different types/extents of variations (a): scale, (b&c): shape with Perline noise and halftone pattern, (d): orientation, (e): all combined. The variation gradually increases from left to right. ", "caption_bbox": [63, 446, 397, 505]}, {"image_id": 6, "file_name": "760_06.png", "page": 7, "dpi": 300, "bbox": [78, 112, 764, 399], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Our framework for the linked detail views. (a) shows a direct visualization of a synthetic set of tensors containing one isotropic tensor and two planar-anisotropic tensors, similar to small multiples. (b) shows the shape space view, (c) the scale space view, and (d) the orientation dissimilarity matrix view with a perceptually linear magma colormap for all the tensors in (a). ", "caption_bbox": [63, 410, 762, 453]}, {"image_id": 7, "file_name": "760_07.png", "page": 8, "dpi": 300, "bbox": [428, 596, 764, 879], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison of two different aggregate visualizations for two different synthetic ensembles ((a) and (e)). (b) and (f) show the glyph-based eigenmodes visualization and IGRT matrix view. (c) and (g) show our tensor glyphs, depicting the variations in instinct properties. (d) and (h) show the dODF-based glyphs. The direction with large variations are colored in gray. For the purpose of clear illustration, images are generated from different viewpoints. ", "caption_bbox": [428, 905, 762, 1009]}, {"image_id": 8, "file_name": "760_08.png", "page": 10, "dpi": 300, "bbox": [62, 112, 763, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Visual analysis results for a border region of ventricle, CC, and IFO (a). The glyph-based overview (b) guides the selection of a voxel of interest for further exploration via shape space (c), scale line plot (d), orientation difference matrix (e), and age information (f). ", "caption_bbox": [63, 343, 762, 371]}, {"image_id": 9, "file_name": "760_09.png", "page": 10, "dpi": 300, "bbox": [430, 398, 763, 586], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Identification of potential outliers in a region of the corpus callosum, highlighted in blue in Figure 9a. (a) shows the overview glyph visualization. (b) and (c) show the shape space view and scale line plot for (top) the selected voxel in (a) and (bottom) the complete ROI, respectively. ", "caption_bbox": [428, 613, 762, 687]}], "761": [{"image_id": 0, "file_name": "761_00.png", "page": 3, "dpi": 300, "bbox": [149, 112, 764, 356], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: TNM classification sub-network from a therapy decision model for laryngeal cancer [SCD\u2217 14]. The sub-network consists of 303 variables with 334 dependencies. The colored rectangles represent thematically related nodes. Specifically in this figure, nodes are distinguished by three colors: purple representing decisions, orange representing the patient situation, and yellow representing examination methods [CSK\u2217 17]. ", "caption_bbox": [63, 363, 762, 426]}, {"image_id": 1, "file_name": "761_01.png", "page": 3, "dpi": 300, "bbox": [63, 605, 398, 664], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Clinical decision workflow in head and neck oncology.", "caption_bbox": [65, 676, 394, 689]}, {"image_id": 2, "file_name": "761_02.png", "page": 6, "dpi": 300, "bbox": [63, 112, 764, 601], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The graphical interface of the visual analysis component is separated into 1) graph view, 2) basic patient information summary, 3) variable selector, and 4) tool set. For quick variable access, the selector comprises a list view of all identifiers and a search bar. The tool set allows for switching between graph analysis modes. ", "caption_bbox": [63, 612, 762, 655]}, {"image_id": 3, "file_name": "761_03.png", "page": 7, "dpi": 300, "bbox": [88, 112, 415, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Detail view of a node glyph representing the T-state vari- able. The possible states of the variable are represented by slices and sorted from best (no tumor, T0) to worse (high-grade tumor, T4b) in a clockwise fashion starting at 12 o\u2019clock. A segment\u2019s fill level indicates the associated relative probability value. A label per segment shows the identifier of the state and the absolute probabil- ity value. ", "caption_bbox": [63, 328, 397, 432]}, {"image_id": 4, "file_name": "761_04.png", "page": 7, "dpi": 300, "bbox": [412, 112, 764, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Example glyphs for the comparison of two TNM model computations (blue and yellow) showing different degrees of agree- ment of the computed probability distributions: a) high, b) accept- able, c) low, and d) no agreement. A high degree of agreement is indicated by a black slice filling. Detailed information regarding the encoding is given in the text. ", "caption_bbox": [428, 359, 762, 448]}, {"image_id": 5, "file_name": "761_05.png", "page": 7, "dpi": 300, "bbox": [64, 462, 398, 603], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Example glyphs for the encoding of observed (a) and computed information (b,c). Observed nodes have one completely filled slice and an empty inner circle. Computed nodes have one completely filled slice of the most probable state while the remain- ing slices are filled relative to the most probable state. ", "caption_bbox": [63, 614, 397, 688]}, {"image_id": 6, "file_name": "761_06.png", "page": 8, "dpi": 300, "bbox": [63, 112, 737, 978], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Verification workflow of a TNM staging given in a patient record (see Section 5.3 for details).", "caption_bbox": [151, 990, 673, 1003]}, {"image_id": 7, "file_name": "761_07.png", "page": 10, "dpi": 300, "bbox": [69, 307, 756, 546], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Study results of the five participants (R1, R2, R3, S1, and S2) with 21 patient cases; one to introduce our component and 20 for the evaluation. This diagram combines a bar chart and a table presenting the required time for each patient case and the answer quality of stagings with conclusion. ", "caption_bbox": [63, 564, 762, 607]}], "762": [{"image_id": 0, "file_name": "762_00.png", "page": 2, "dpi": 300, "bbox": [63, 112, 764, 307], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Comparative visualization of aneurysm stress tensors by using four glyph-based techniques. In (a) optimal views on the aneurysm surface are shown that support the data exploration. In (b) superquadrics and in (c) kite-shaped glyphs show the local tensor on the inner (yellow) and outer wall (blue). In (d), streamlines indicate the tensor main direction for the inner (yellow, purple) and outer wall (blue, green). Scatterplots (e) show the distribution of the main directions within a surface region. ", "caption_bbox": [63, 317, 762, 376]}, {"image_id": 1, "file_name": "762_01.png", "page": 3, "dpi": 300, "bbox": [64, 112, 764, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of our approach to visualize stress tensor information. First, clinical image data is acquired from which the vessel surface is reconstructed as input for the FSI. The exploration of the simulation results is realized with our 3D glyph-based depictions. ", "caption_bbox": [63, 254, 762, 282]}, {"image_id": 2, "file_name": "762_02.png", "page": 5, "dpi": 300, "bbox": [62, 112, 764, 276], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration of the region-based glyph placement for different zoom levels. N represents the number of glyphs per level, where the size of the glyphs is adopted to the level. For lower levels, the glyphs appear larger, getting smaller for higher levels. ", "caption_bbox": [63, 286, 762, 314]}, {"image_id": 3, "file_name": "762_03.png", "page": 5, "dpi": 300, "bbox": [62, 685, 131, 771], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: SQ    glyph with empha- sized   first PSD. ", "caption_bbox": [63, 782, 128, 856]}, {"image_id": 4, "file_name": "762_04.png", "page": 6, "dpi": 300, "bbox": [427, 337, 497, 404], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: SP     shows the distribu- tion of the PSDs of a region. ", "caption_bbox": [428, 416, 493, 505]}, {"image_id": 5, "file_name": "762_05.png", "page": 6, "dpi": 300, "bbox": [63, 112, 415, 196], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The transition from the arrow glyph to the kite glyph with increasing zoom level. ", "caption_bbox": [63, 206, 397, 234]}, {"image_id": 6, "file_name": "762_06.png", "page": 6, "dpi": 300, "bbox": [62, 577, 398, 620], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: SL glyph,     where the yellow part represents     the main stress value and the purple area shows the second      stress value along the main direction. ", "caption_bbox": [63, 622, 152, 772]}, {"image_id": 7, "file_name": "762_07.png", "page": 8, "dpi": 300, "bbox": [461, 414, 730, 578], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: In both pictures, SL are depicted on the surface together with the stress of von Mises. Using SL, the experts were able to find opposite areas on the aneurysm, in which the first PSD extend in very different directions and the stress is very high. In (a) the first PSD proceed from the ostium to the aneurysm dome, whereas in (b) it runs almost orthogonally that are assessed as suspicious regions. ", "caption_bbox": [428, 586, 762, 675]}, {"image_id": 8, "file_name": "762_08.png", "page": 8, "dpi": 300, "bbox": [63, 182, 398, 433], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Results of the user study.", "caption_bbox": [139, 445, 319, 458]}, {"image_id": 9, "file_name": "762_09.png", "page": 8, "dpi": 300, "bbox": [412, 112, 731, 296], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: In (a), path lines are depicted together with SL. This can be used to find possible correlations between specific flow patterns such as vortices and suspicious stress tensors. With the kites, the ex- perts could identify regions with a strong local change of the PSDs easily, which are assessed as possible rupture-prone. The green boxes show kites with strong local change of the PSDs, where the strength of the changes is color-coded on the surface. ", "caption_bbox": [428, 301, 762, 405]}, {"image_id": 10, "file_name": "762_10.png", "page": 9, "dpi": 300, "bbox": [65, 112, 415, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The SP illustrates the homogeneity of the PSDs within a surface region. In (a), the wall thickness is color-coded. Within the framed area, the wall is very thin, but the PSDs are very ho- mogeneous, whereas (b) shows a region with high WSS and a very diffuse distribution of the PSDs. ", "caption_bbox": [63, 275, 397, 349]}], "763": [{"image_id": 0, "file_name": "763_00.png", "page": 1, "dpi": 300, "bbox": [62, 342, 765, 602], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visual comparison of eye movement patterns using radial transition graphs. A) The Comparison List View with an overview of all transition graphs. B) The Radial Transition Graph View shows one transition graph and transition sequence. C) A place holder for the stimulus of a study. D) The Comparison Grid View to visually contrast multiple transition graphs. E) The Transition Graph Diff View to compare two transition graphs. F) The toolbar to switch between views. ", "caption_bbox": [63, 613, 762, 672]}, {"image_id": 1, "file_name": "763_01.png", "page": 5, "dpi": 300, "bbox": [112, 112, 415, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The tooltip of a merged transition shows details about the connected AOIs, compared participants, and the resulting color coding of the transition. ", "caption_bbox": [63, 297, 397, 340]}, {"image_id": 2, "file_name": "763_02.png", "page": 6, "dpi": 300, "bbox": [62, 112, 762, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Summary of the data sets used in the expert evaluation.", "caption_bbox": [434, 352, 757, 365]}, {"image_id": 3, "file_name": "763_03.png", "page": 7, "dpi": 300, "bbox": [412, 112, 764, 486], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The Comparison Grid View of selected participants P01, P04, P16, P21, P24, P33, and P36 from the metro map study. ", "caption_bbox": [428, 497, 762, 525]}, {"image_id": 4, "file_name": "763_04.png", "page": 7, "dpi": 300, "bbox": [62, 112, 415, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Detailed comparison using the Transition Graph Diff View and the equal sector mode to compare participant P04 to par- ticipants P24 and P32 in the metro map study. ", "caption_bbox": [63, 335, 397, 378]}, {"image_id": 5, "file_name": "763_05.png", "page": 8, "dpi": 300, "bbox": [62, 457, 399, 749], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Data from the VarifcoalReader study using the Transition Graph Diff View to compare participant P01 with P15. ", "caption_bbox": [63, 760, 397, 788]}, {"image_id": 6, "file_name": "763_06.png", "page": 8, "dpi": 300, "bbox": [412, 112, 764, 451], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: In the UNO game data set participant P06 is selected in the Comparison List View. Only participants P06 to P20 are shown. ", "caption_bbox": [428, 462, 762, 490]}, {"image_id": 7, "file_name": "763_07.png", "page": 8, "dpi": 300, "bbox": [62, 112, 415, 402], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Data from the VarifcoalReader study with participant P10 selected in the Comparison List View. ", "caption_bbox": [63, 414, 397, 442]}, {"image_id": 8, "file_name": "763_08.png", "page": 9, "dpi": 300, "bbox": [62, 112, 415, 440], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparing participants P07 and P09 using the Transi- tion Graph Diff View for the UNO game study. ", "caption_bbox": [63, 451, 397, 479]}], "764": [{"image_id": 0, "file_name": "764_00.png", "page": 1, "dpi": 300, "bbox": [412, 339, 764, 631], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: During visualization, human viewers are able to judge if a visual object is valid (e.g., v1 ), unlikely (e.g., v2 ), or invalid (e.g., v3 ) using their soft knowledge about the probability distribution of the data alphabet. The halos around d1 , d2 , and d3 indicate that vi- sual decoding features uncertainty since visual encoding is usually a many-to-one mapping. ", "caption_bbox": [428, 644, 762, 733]}, {"image_id": 1, "file_name": "764_01.png", "page": 3, "dpi": 300, "bbox": [78, 112, 764, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Time series captured in different contexts usually have some characteristic visual signatures. Through their lives, humans have acquired, often unconsciously, the knowledge for recognizing the visual signatures of commonly-seen time series. ", "caption_bbox": [63, 314, 762, 342]}, {"image_id": 2, "file_name": "764_02.png", "page": 5, "dpi": 300, "bbox": [96, 591, 731, 990], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A question screen, consisting of a statistical indicator as the third clue and eight time series plots as optional answers.", "caption_bbox": [90, 1000, 734, 1013]}, {"image_id": 3, "file_name": "764_03.png", "page": 5, "dpi": 300, "bbox": [96, 112, 764, 535], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An information screen in the form of a magazine article, which offers the participants with two clues about the time series to be identified: (i) the contextual type is ECG, and (ii) the specific pattern is a wandering baseline trending upwards. ", "caption_bbox": [63, 545, 762, 573]}, {"image_id": 4, "file_name": "764_04.png", "page": 6, "dpi": 300, "bbox": [62, 112, 763, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Three information screens for the contextual types of stock market, weather temperature, and electricity production.", "caption_bbox": [96, 335, 726, 348]}, {"image_id": 5, "file_name": "764_05.png", "page": 8, "dpi": 300, "bbox": [62, 112, 415, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 5: Condition-specific analysis of three contextual types.", "caption_bbox": [439, 321, 750, 334]}, {"image_id": 6, "file_name": "764_06.png", "page": 9, "dpi": 300, "bbox": [85, 112, 764, 855], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Glyph-based visualization of the 36 trials grouped based on contextual types (top), specific patterns (middle), and statistical measures (bottom). Each glyph encodes the three attributes of a trial. The y-location of each glyph depicts the mean value of the accuracy of a trial (left) or the mean of the response time of a trial (right). The x-location within a group is randomly assigned to minimize overlappings. ", "caption_bbox": [63, 863, 762, 906]}], "765": [{"image_id": 0, "file_name": "765_00.png", "page": 3, "dpi": 300, "bbox": [69, 112, 764, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Geometric specifications of four types of variations.", "caption_bbox": [255, 319, 570, 332]}, {"image_id": 1, "file_name": "765_01.png", "page": 4, "dpi": 300, "bbox": [62, 112, 757, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The set values for different control variables associated with the six null hypotheses. For H6 (fine set), the 3rd row consists of the four PPMCC reference points, each of which is to be paired with the six sets of control values below. ", "caption_bbox": [62, 334, 761, 362]}, {"image_id": 2, "file_name": "765_02.png", "page": 4, "dpi": 300, "bbox": [428, 384, 765, 621], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Each trial consists of two stimuli. This generic design enables trials for JND (Just Noticeable Difference) evaluation to be integrated with other trials seamlessly. ", "caption_bbox": [428, 627, 762, 670]}, {"image_id": 3, "file_name": "765_03.png", "page": 5, "dpi": 300, "bbox": [64, 112, 764, 527], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A selection of stimuli that are designed for different hypotheses.", "caption_bbox": [225, 535, 599, 548]}, {"image_id": 4, "file_name": "765_04.png", "page": 7, "dpi": 300, "bbox": [69, 112, 764, 587], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Summary statistics for H1: Varying PPMCC. (a) MSOs and MAOs for CR \u2208 [\u22120.9, 0.9], indicating a symmetric pattern between positive and negative CR values; (b) MSOs and MAOs for CR \u2208 [0.0, 0.9], showing a non-linear pattern of underestimation. (c) the numbers of participants with positive, zero, and negative offsets while estimating non-negative correlation, (d) while estimating negative correlation, and (e) p-values for pairwise t-tests (in terms of MSOs, CR \u2208 [0.0, 0.9]) with insignificant pairs marked in red. ", "caption_bbox": [63, 594, 762, 654]}, {"image_id": 5, "file_name": "765_05.png", "page": 8, "dpi": 300, "bbox": [62, 112, 415, 695], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Summary statistics for H2: Varying Density.", "caption_bbox": [88, 704, 368, 717]}, {"image_id": 6, "file_name": "765_06.png", "page": 9, "dpi": 300, "bbox": [78, 112, 764, 435], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Summary statistics for H3: Reflective Symmetry. Samples labelled with 3 : 3, 2.5 : 2.5, and 2 : 2 are symmetric samples. The variations between them and asymmetric samples are observable. However, finer sampling will be desirable for a conclusive finding. ", "caption_bbox": [63, 444, 762, 472]}, {"image_id": 7, "file_name": "765_07.png", "page": 9, "dpi": 300, "bbox": [72, 487, 752, 777], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Summary statistics for H4: Progressive Symmetry. The comparisons between r = 0 and r > 0 show significant variations.", "caption_bbox": [80, 786, 745, 799]}, {"image_id": 8, "file_name": "765_08.png", "page": 10, "dpi": 300, "bbox": [62, 112, 754, 607], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Summary statistics for H5: Spatial Distribution. In (d) and (f), comparisons with MSOs in H1 indicate significant variations.", "caption_bbox": [72, 616, 753, 629]}, {"image_id": 9, "file_name": "765_09.png", "page": 11, "dpi": 300, "bbox": [64, 112, 415, 489], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Summary statistics for H6. (a) The results of two sets of JND trials for two negative reference points. (b) Results for two positive reference points. ", "caption_bbox": [63, 497, 397, 540]}], "766": [{"image_id": 0, "file_name": "766_00.png", "page": 5, "dpi": 300, "bbox": [62, 112, 764, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Task generation: summary of methods, threats to validity, and approaches for mitigating threats.", "caption_bbox": [144, 408, 681, 421]}, {"image_id": 1, "file_name": "766_01.png", "page": 7, "dpi": 300, "bbox": [63, 112, 764, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Task categorisation: summary of methods, threats to validity, and approaches for mitigating threats.", "caption_bbox": [135, 295, 690, 308]}, {"image_id": 2, "file_name": "766_02.png", "page": 7, "dpi": 300, "bbox": [62, 329, 740, 418], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Description: summary of methods, threats to validity, and approaches for mitigating threats.", "caption_bbox": [154, 461, 671, 474]}, {"image_id": 3, "file_name": "766_03.png", "page": 8, "dpi": 300, "bbox": [62, 112, 757, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Conceptual approaches: summary of methods, threats to validity, and approaches for mitigating threats.", "caption_bbox": [124, 256, 700, 269]}, {"image_id": 4, "file_name": "766_04.png", "page": 9, "dpi": 300, "bbox": [62, 112, 764, 488], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Aspects of task classifications which can be evaluated and associated evaluation strategies", "caption_bbox": [158, 531, 666, 544]}], "767": [{"image_id": 0, "file_name": "767_00.png", "page": 2, "dpi": 300, "bbox": [62, 112, 675, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The Cartesian (CC) and Body Centered Cubic (BCC) lattice, left and right respectively. Notice the coset structure of the BCC lattice, denoted by the red and blue node colouring. The support of the linear box spline on the BCC lattice is shown by the green rhombic dodecahedron. ", "caption_bbox": [62, 361, 761, 389]}, {"image_id": 1, "file_name": "767_01.png", "page": 5, "dpi": 300, "bbox": [111, 112, 764, 432], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: The Z-domain polynomials of all filters given in Figure 3. The first three filters correspond to the filters along the cardinal axes, and the last four correspond to the filters about the diagonal axes. ", "caption_bbox": [427, 711, 761, 754]}, {"image_id": 2, "file_name": "767_02.png", "page": 6, "dpi": 300, "bbox": [61, 112, 696, 352], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Filter weights for the starting high pass filters. There are two families of filters we start with. m1 is depicted in the left sub-figure; it is a simple 1D filter extended along the golden vector. The other two vectors in that image denote the directions along which we extend the same filter to obtain m2 and m3 . Similarly, the rest of the starting high pass filters are given on the right; they are extended along 4 diagonal directions. This gives a total of 7 high-pass channels. Notice how this reflects the symmetries of the BCC lattice; we further remark that the configuration thus obtained is similar to the D3bQ15 discretization of the lattice-Boltzmann method [AEM09]. ", "caption_bbox": [62, 363, 761, 437]}, {"image_id": 3, "file_name": "767_03.png", "page": 7, "dpi": 300, "bbox": [65, 112, 415, 463], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A medley of the original high-resolution datasets. The Stent data set is depicted in gray (original resolution: 512 \u00d7 512 \u00d7 174, iso-value: 206), Head in yellow (original resolution: 256\u00d7256\u00d7256, iso-value: 127.5) Carp in blue (original resolution: 256 \u00d7 256 \u00d7 512, iso-value: 1435.5), and finally the Marschner-Lobb test function in red (iso-value: 0.5) ", "caption_bbox": [62, 484, 399, 573]}, {"image_id": 4, "file_name": "767_04.png", "page": 8, "dpi": 300, "bbox": [109, 365, 704, 693], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Approximate PNSR for various reconstructions. As the percentage grows, more data are kept, thus the approximation becomes better. Here, higher values on the y-axis indicate a better approximation. ", "caption_bbox": [62, 716, 764, 744]}, {"image_id": 5, "file_name": "767_05.png", "page": 8, "dpi": 300, "bbox": [61, 112, 708, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: From left to right we have the frequency responses of low pass primal, low pass dual, high pass primal and high pass dual respectively. Note that these are periodized about an FCC lattice, so the fundamental region is replicated in a rhombic dodecahedral pattern. The red indicates the frequencies that will be passed by the filter, whereas blue indicates the frequencies that will be muted. Only one high pass filter is shown here, the rest are symmetric. ", "caption_bbox": [62, 299, 761, 343]}, {"image_id": 6, "file_name": "767_06.png", "page": 9, "dpi": 300, "bbox": [146, 112, 764, 481], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparisons with other wavelet thresholding schemes. For the region indicated in each dataset, we show a reconstruction with 95% of the detail coefficients removed. On the left is the tensor product CC wavelet family, the center BCC linear box spline wavelet, and the right is the BCC 2,1 wavelet. We removed most of the detail coefficients to amplify the appearance of compression artifacts. ", "caption_bbox": [62, 492, 762, 535]}, {"image_id": 7, "file_name": "767_07.png", "page": 9, "dpi": 300, "bbox": [99, 574, 727, 886], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Reconstructions of the synthetic Marschner Lobb function at 5%, 15%, 25% and 100% of detail coefficients, left to right, respectively. The top row are the reconstructions on the BCC lattice, where the bottom row are reconstructions on the CC lattice. ", "caption_bbox": [62, 898, 761, 926]}, {"image_id": 8, "file_name": "767_08.png", "page": 10, "dpi": 300, "bbox": [61, 112, 714, 967], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Reconstructions of the test data with 5%, 15%, 25% and 100% of the detail coefficients, left to right, respectively. Within each pair of rows, the top row are the reconstructions on the BCC lattice, whereas the bottom are the reconstructions on the CC lattice. ", "caption_bbox": [62, 982, 764, 1010]}], "768": [{"image_id": 0, "file_name": "768_00.png", "page": 1, "dpi": 300, "bbox": [412, 353, 764, 745], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) A 2D scalar field with two maxima (red) in the in- terior, two maxima on the boundary, one minimum (blue) in the interior, and three minima on the boundary. (b) Contour tree of the scalar field, whose nodes are exactly the critical points of the scalar field. ", "caption_bbox": [428, 760, 762, 834]}, {"image_id": 1, "file_name": "768_01.png", "page": 2, "dpi": 300, "bbox": [484, 484, 725, 634], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Join tree (a) and split tree (b) of the function described in Figure 1. The contour tree is the union of the join and split trees. ", "caption_bbox": [428, 649, 762, 677]}, {"image_id": 2, "file_name": "768_02.png", "page": 3, "dpi": 300, "bbox": [412, 112, 764, 382], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Linear and higher order interpolation over a triangle for a function sampled at multiple points (black). (a) Linear interpola- tion within each of the four triangles obtained by subdividing the input triangle. (b) Quadratic polynomial function interpolating the sample points. (c) Cubic polynomial function interpolating 10 sam- ple points. (d) Piecewise continuous quadratic polynomial sampled at 6 points each over two triangles. (e) Piecewise continuous cubic polynomial sampled at 10 points within each triangle. Isolines are continuous across common boundary. ", "caption_bbox": [428, 396, 762, 531]}, {"image_id": 3, "file_name": "768_03.png", "page": 4, "dpi": 300, "bbox": [62, 112, 755, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Tracing a monotone descending path from c1 . The steepest descent direction (blue) helps locate monotonic segments. If a path reaches the boundary, it is restricted to the boundary. ", "caption_bbox": [63, 312, 762, 340]}, {"image_id": 4, "file_name": "768_04.png", "page": 5, "dpi": 300, "bbox": [474, 575, 716, 698], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) A degenerate patch. (b) Subdividing the patch into triangles after inserting all line-critical points. The local join tree and local split tree is computed by assuming piecewise linear inter- polation within each smaller triangle. ", "caption_bbox": [428, 712, 762, 771]}, {"image_id": 5, "file_name": "768_05.png", "page": 7, "dpi": 300, "bbox": [444, 696, 747, 835], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Top of the conductor contains multiple degeneracies. The algorithm identifies all the critical points and handles the degener- ate patches gracefully. ", "caption_bbox": [428, 888, 762, 931]}, {"image_id": 6, "file_name": "768_06.png", "page": 8, "dpi": 300, "bbox": [62, 112, 766, 561], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Contour trees for piecewise quadratic and cubic polynomials (a) Temperature distribution on the surface of a thermal conductor as a piecewise quadratic function. (b) Critical points and contour lines. (c) Contour tree consisting of 530 nodes. (d) Contour tree after simplification using a persistence threshold of 0.1% contains 67 nodes. It contains two similar subtrees as expected. (e) A cubic function defined on a heater geometry. (f) Critical points and contour lines. (g) Contour tree consisting of 268 nodes. (h) Contour tree with 178 nodes obtained after simplifying using a persistence threshold of 0.5%. ", "caption_bbox": [63, 574, 762, 648]}, {"image_id": 7, "file_name": "768_07.png", "page": 9, "dpi": 300, "bbox": [469, 320, 720, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) Bounding box Rc for a critical point c showing its neighborhood Nc . (b) A box containing c, which is larger than the required bounding box. ", "caption_bbox": [428, 476, 762, 519]}, {"image_id": 8, "file_name": "768_08.png", "page": 10, "dpi": 300, "bbox": [185, 729, 638, 899], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Visual comparison with PL approximations for the heater dataset. A 10-fold increase in number of triangles is required to obtain similar contours for the PL approximation. (a) Close up view. Critical points computed using a PL approximation on a mesh with 12438 triangles.(d) Corresponding contour tree containing 210 nodes. (b) PL approximation with 111942 triangles. (e) Corresponding contour tree with 208 critical points. (c) Close up of heater showing critical points computed using a piecewise cubic function with 12438 triangles. (f) Corresponding contour tree containing 212 critical points. ", "caption_bbox": [63, 913, 762, 987]}, {"image_id": 9, "file_name": "768_09.png", "page": 10, "dpi": 300, "bbox": [169, 544, 655, 714], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Visual comparison with PL approximations for the conductor dataset. (a) A PL approximation of the temperature field. (f) Contour tree for the PL approximation. (b-d) Close up of region of thermal conductor showing critical points and contours for successive PL subdivi- sions of conductor containing 4298, 17192, and 68768 triangles, respectively. Topology of contours is not captured in the PL approximations even after a 15-fold increase in number of triangles. (g-i) Corresponding nodes and arcs in the contour tree. (e) Critical points and contour lines for piecewise quadratic function with 4298 triangles. (j) Nodes and arcs from contour tree of the piecewise quadratic function. ", "caption_bbox": [63, 442, 762, 516]}], "769": [{"image_id": 0, "file_name": "769_00.png", "page": 1, "dpi": 300, "bbox": [62, 637, 764, 835], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Nested tracking graph for one ensemble member of the viscous finger dataset with highest particle resolution. In contrast to common tracking graphs\u2014where edges only encode the evolution of components for a single level\u2014nested tracking graphs additionally illustrate the nesting hierarchy of components across levels. The x-axis represents time and the y-axis is used to minimize edge crossings. The density levels 25, 30, and 35 are shown from dark to light red, and the width of edges encodes the size of their associated components. ", "caption_bbox": [63, 553, 762, 612]}, {"image_id": 1, "file_name": "769_01.png", "page": 3, "dpi": 300, "bbox": [412, 112, 764, 573], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (Top) 3D illustration of a nested tracking graph where tracking graphs for one level are shown in shades of blue, and nesting trees for each timestep in shades of red. Each level is also highlighted via gray planes. (Middle) Nested graph representation where edge colors encode levels, and edges are nested inside each other according to the nesting tree. (Bottom) Three timesteps of a time-varying scalar-field that was used to derive the nested track- ing graph where each timestep is shown via three contours. ", "caption_bbox": [428, 588, 762, 708]}, {"image_id": 2, "file_name": "769_02.png", "page": 4, "dpi": 300, "bbox": [63, 112, 415, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A split tree (left) and a nesting tree (right).", "caption_bbox": [96, 276, 362, 289]}, {"image_id": 3, "file_name": "769_03.png", "page": 6, "dpi": 300, "bbox": [62, 112, 764, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Interface of our visual analytics framework consisting of a DVR window (left) and the interactive nested tracking graph (right).", "caption_bbox": [68, 312, 756, 325]}, {"image_id": 4, "file_name": "769_04.png", "page": 7, "dpi": 300, "bbox": [62, 112, 764, 510], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Nested graphs for three simulation runs with the lowest particle resolution of the viscous finger dataset. Edges encode the evolution of components, and their width the size of their associated components. Different levels are shown in different colors, i.e., the levels 25, 30, and 35 are shown from dark to light red, respectively. The x-axis represents time and the y-axis is used to minimize edge crossings. Although stochastic effects alter simulation results, the graphs show similar trends such as the initial phase where small fingers originate from the salt supply and then merge into larger finger structures. ", "caption_bbox": [63, 523, 762, 597]}, {"image_id": 5, "file_name": "769_05.png", "page": 8, "dpi": 300, "bbox": [412, 112, 756, 644], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (Top) Individual components of the jet dataset at timestep 302 for vorticity magnitude level 85 (left) and 117 (right). (Bot- tom) Nested tracking graph with focus on layer 85, i.e., layer 117 is grayed out and the edge colors of layer 85 match the components of Figure 6 top left. The graph indicates that the top component (or- ange) split from the main component (red) at timestep 295. ", "caption_bbox": [428, 656, 762, 745]}, {"image_id": 6, "file_name": "769_06.png", "page": 9, "dpi": 300, "bbox": [62, 112, 764, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Nested tracking graph for one filament of the halo dataset where the density levels 2.632497 \u00d7 1012 , 1 \u00d7 1012 , and 5 \u00d7 1011 are shown in red, dark blue, and light blue, respectively. ", "caption_bbox": [63, 282, 762, 313]}, {"image_id": 7, "file_name": "769_07.png", "page": 9, "dpi": 300, "bbox": [64, 324, 397, 591], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (Top) DVR image of the Halo dataset at timestep 850 that highlights halos with density 2.632497 \u00d7 1012 (red), 1 \u00d7 1012 (dark blue), and 5 \u00d7 1011 (light blue). (Bottom) Nested tracking graph for one galaxy filament (light blue) that illustrates the evolution of halos (dark blue) and sub-halos (red). ", "caption_bbox": [62, 603, 396, 677]}], "770": [{"image_id": 0, "file_name": "770_00.png", "page": 3, "dpi": 300, "bbox": [68, 112, 414, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Superlevel and sublevel sets of a scalar field may appear, join, split, and disappear with changing isovalues. The join and split tree represent that behavior. They are collectively referred to as merge trees. ", "caption_bbox": [62, 271, 398, 330]}, {"image_id": 1, "file_name": "770_01.png", "page": 4, "dpi": 300, "bbox": [61, 112, 760, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Tracking regions solely based on local decisions leads to broken tracks. In this simple example, a small fluctuation between time steps t3 and t5 causes the creation of a region C that has significant overlap and similarity with region A. Assigning the locally best match neglects that there can be more than one suitable track between two time steps (e.g., between t5 and t6 ), and causes tracks to break. See Figure 3 for our graph structure solving this issue. ", "caption_bbox": [61, 344, 761, 403]}, {"image_id": 2, "file_name": "770_02.png", "page": 4, "dpi": 300, "bbox": [99, 428, 727, 535], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: We record suitable tracking information in a directed acyclic graph. The edges connect overlapping regions between consecutive time steps and are weighted with our combined region distance de . This minimal memory overhead allows us to track the regions without breaks, since we can solve ambiguities on a global level. See Figure 5 for region tracks that have been computed from this graph. ", "caption_bbox": [62, 549, 761, 592]}, {"image_id": 3, "file_name": "770_03.png", "page": 5, "dpi": 300, "bbox": [84, 112, 414, 498], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The number of edges between two consecutive time steps in the DAG is very small, since we only establish edges between overlapping regions. The dot matrix on the top reveals this sparsity of the DAG for the Square Cylinder flow. Edges are depicted as grayscale dots where darker dots refer to lower distances between the regions according to the edge weight de . The histogram at the bottom shows that most nodes connect to 0 to 4 nodes in the next time step. ", "caption_bbox": [62, 512, 396, 632]}, {"image_id": 4, "file_name": "770_04.png", "page": 6, "dpi": 300, "bbox": [62, 112, 733, 248], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Starting from a given region, we use the Dijkstra algorithm to find the shortest path through the DAG, which represents the track of this region. In this example, the shortest path was computed starting from A1 and is shown as a green band. ", "caption_bbox": [62, 262, 761, 290]}, {"image_id": 5, "file_name": "770_05.png", "page": 6, "dpi": 300, "bbox": [427, 327, 763, 432], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Dynamic Time Warping matches two signals while allo- wing for temporal contractions and expansions. The arrows indicate the matched time steps. DTW employs an optimality criterion such that the sum of distances between the matches is minimal. ", "caption_bbox": [427, 442, 763, 501]}, {"image_id": 6, "file_name": "770_06.png", "page": 8, "dpi": 300, "bbox": [430, 390, 760, 509], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Plot of spatial (blue) and spatio-temporal (red) matching costs of the selection from Figure 10(a). The discrepancy between spatial and spatio-temporal ranks reveals that adding the temporal dimension aids in discriminating structures with similar spatial scores based on their temporal evolution. Compare to Figure 10. ", "caption_bbox": [427, 524, 761, 598]}, {"image_id": 7, "file_name": "770_07.png", "page": 8, "dpi": 300, "bbox": [413, 112, 764, 249], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The shown primary and secondary vortex structures are close matches when considering only spatial information, but including their temporal development by means of DTW allows us to tell them apart: the secondary vortex is the 10th best spatial match of the primary vortex out of over 16000 regions in all time steps, but only the 82nd best spatio-temporal match out of the 100 best spatial matches. Compare to Figure 11. ", "caption_bbox": [427, 261, 761, 365]}, {"image_id": 8, "file_name": "770_08.png", "page": 8, "dpi": 300, "bbox": [61, 112, 415, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Our method performs significantly faster than Oesterling et. al. [OHW\u2217 15] and may serve as a faster alternative when the focus is on tracking Morse cells independent of their hierarchy. However, if a record of the merge tree hierarchy evolution is desired, the method of Oesterling et. al. [OHW\u2217 15] is to be preferred. See Figure 9 for the data set. Note also that we report the timings in seconds and milliseconds, respectively. ", "caption_bbox": [61, 336, 398, 440]}, {"image_id": 9, "file_name": "770_09.png", "page": 9, "dpi": 300, "bbox": [412, 112, 764, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Our method is able to track regions even if they change their properties drastically over the course of the track. Shown are tracked regions in the streak line curvature field for a 2D flow around a cylinder. These regions indicate vortex activity. ", "caption_bbox": [427, 277, 761, 336]}, {"image_id": 10, "file_name": "770_10.png", "page": 9, "dpi": 300, "bbox": [62, 112, 414, 880], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: A primary and secondary vortex structure have been selected at T = 45 and tracked backwards and forwards in time. Their tracks have been used to find spatio-temporally similar struc- tures in the entire data set. Note how the discriminative power of our signature distance ds enables us to distinguish between both types of vortices, and how the matched vortex tracks span through the entire time of the data set. ", "caption_bbox": [61, 892, 398, 996]}, {"image_id": 11, "file_name": "770_11.png", "page": 10, "dpi": 300, "bbox": [62, 112, 415, 694], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Our method is useful to reveal structure and symmetry in seemingly chaotic data. The Trefoil data set shows the decay of three interlocked magnetic flux tubes. The left column shows a full volume rendering. The middle column shows the user selection and its track. The right column shows the spatio-temporally similar regions revealing the 3-symmetry of the data set. ", "caption_bbox": [62, 704, 396, 793]}], "771": [{"image_id": 0, "file_name": "771_00.png", "page": 1, "dpi": 300, "bbox": [68, 472, 762, 622], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: T REE S COPE enables interactive and unified exploration of network traffic for large-scale fat-tree networks, including the visual analytics of network counters, job queue logs, job placements, and routing scheme. The figure shows the network traffic during the execution of the same application using two routing schemes, ftree routing (left) and SAR scheme (right). The visualization shows temporal and distributional statistics (top), and detailed per-link traffic on half of the 1296-node fat-tree cluster in use (bottom). The free routing distributes the traffic more uniformly (average traffic maps to yellow) and is about 15% faster than the SAR scheme. T REE S COPE helps users explore the data and formulate hypotheses on the causes for performance degradation, such as the presence of hotspots in the traffic on the right. ", "caption_bbox": [62, 633, 761, 722]}, {"image_id": 1, "file_name": "771_01.png", "page": 3, "dpi": 300, "bbox": [87, 112, 415, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A small fat-tree network for k = 4 contains 8 L1, 8 L2, 4 L3 switches, and up to 16 compute nodes. The L1 and L2 switches are logically grouped into four separate closely connected pods, and the L3 switches (from 2 bundles) connect different pods. The bold dashed line shows an example of the path between two compute nodes in different pods, which takes five hops. ", "caption_bbox": [63, 251, 397, 340]}, {"image_id": 2, "file_name": "771_02.png", "page": 6, "dpi": 300, "bbox": [412, 112, 761, 348], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: T REE S COPE encodes large-scale graphs implied by the fat-tree topology using matrix-based representations. The figure shows one of the many pods (superscripted 0) and two bundles (subscripted 0 and 1) in the network. The connectivity within a given pod is visualized using a set of adjacency matrices between nodes at adjacent levels, i.e., {L1}0 \u00d7 {L2}00 , {L3}0 \u00d7 {L2}00 , etc. The key features of the encoding include (1) omission of the less important, {L0}0 \u21d2 {L1}0 , connectivity, (2) hierarchical view of the pod by splitting the pod with respect to bundles (within dashed boxes), (3) separate matrices for \u201cup\u201d and \u201cdown\u201d traffic (different colors), (4) duplication of L2 switches (solid vs. hollow gray switches) to enable visualization of directional traffic, and (5) reordering of directional submatrices to allow consistent aggregation (incoming or outgoing) of traffic for L2 switches. ", "caption_bbox": [428, 358, 762, 569]}, {"image_id": 3, "file_name": "771_03.png", "page": 7, "dpi": 300, "bbox": [71, 112, 415, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Job-placement schemes can be visualized on L1 switches by color-coding them in proportion to the number of compute nodes occupied by corresponding jobs to the total number of compute nodes connected to them (the L1 switches). For selected jobs in the table, a stacked-histogram type visualization conveys which L1 switches contain compute nodes corresponding to different jobs. ", "caption_bbox": [63, 251, 397, 340]}, {"image_id": 4, "file_name": "771_04.png", "page": 8, "dpi": 300, "bbox": [62, 112, 415, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The route between a pair of end nodes (or switches) can be visualized by highlighting the switches and links that the corresponding traffic goes through. The arrows denote the direction of routes, and show how the traffic is routed. Since the L3 switches are repeated in every pod, the traffic goes into a particular L3 switch but may come out from the same switch in a different pod. ", "caption_bbox": [63, 316, 397, 405]}, {"image_id": 5, "file_name": "771_05.png", "page": 9, "dpi": 300, "bbox": [69, 112, 764, 498], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Interactive filtering in T REE S COPE allows the user to visualize only the hotspot links (using histogram selection) to refine the understanding of network congestion. It is noted that whereas ftree routing (left) results in many links with above-average traffic (Figure 1), the number of hotspots links is significantly smaller in comparison to SAR routing (right). This explains the 17% better performance obtained with ftree routing for the selected application. The figure uses a diverging colormap for traffic, with yellow mapped to the average value. ", "caption_bbox": [62, 511, 761, 570]}, {"image_id": 6, "file_name": "771_06.png", "page": 10, "dpi": 300, "bbox": [68, 329, 758, 461], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The same experiment (compare with Figure 8), when performed with a different job-placement policy, shows that much fewer links are overloaded (left), suggesting less network congestion overall. Right: Visualizing the job-placement and traffic for the same job (Qbox), which is now mapped to pods 2 and 3 only, creates fewer hotspots, restricted locally to the corresponding pods, thus avoiding reducing congestion due to job interference. ", "caption_bbox": [63, 471, 762, 530]}, {"image_id": 7, "file_name": "771_07.png", "page": 10, "dpi": 300, "bbox": [62, 112, 758, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Network traffic during the execution of several jobs on a 8-pod cluster is mapped to a white\u2013orange color scale. Left: The overall traffic is high, yet no perceivable traffic patterns are observed. Right: Restricting the visualization to congested links and the traffic from a particular job, Qbox, highlights the connection between the two, suggesting the culpability of Qbox for creating congestion in all pods. ", "caption_bbox": [63, 278, 762, 322]}, {"image_id": 8, "file_name": "771_08.png", "page": 11, "dpi": 300, "bbox": [62, 112, 415, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Visualizing links that can be used for communication from a switch or between a pair of switches show that task-to-node mapping and routing policy result in overloading some links while underutilizing other links. Traffic for two different jobs is shown. ", "caption_bbox": [63, 231, 397, 290]}], "772": [{"image_id": 0, "file_name": "772_00.png", "page": 1, "dpi": 300, "bbox": [62, 557, 764, 816], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example of WAOW-Vis for a bipartite graph containing a collection U of 9.4M Twitter users is linked to a collection of 228 V of Twitter feeds associated to programming languages and US\u2019 news outlets. The bipartite graph is preprocessed by the HSNE algorithm that extracts a hierarchy of landmarks, i.e., sets of vertices. In the overview, landmarks in the highest scale for the two collections are placed in (b,d) 1- and (a,e) 2-dimensional embeddings that reveal major clusters of similarly connected vertices (c). The hierarchy is explored with an overview-first and details-on-demand approach that reveals hierarchies of sub-clusters (f). ", "caption_bbox": [63, 475, 762, 550]}, {"image_id": 1, "file_name": "772_01.png", "page": 2, "dpi": 300, "bbox": [412, 112, 731, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Computation of the similarities between the vertices in U. Vertices in U are seen as sets of elements in V (b). The Jac- card similarities are computed as the cardinality of the intersection divided by the cardinality of the union (c). ", "caption_bbox": [428, 369, 762, 428]}, {"image_id": 2, "file_name": "772_02.png", "page": 3, "dpi": 300, "bbox": [414, 112, 764, 470], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Overview of WAOW-Vis. Two hierarchical representa- tions of the collections U and V are computed. The elements in the collections are encoded via compressed bitmaps (a). The k-nearest neighborhood graph are computed for the non-duplicated bitmaps (b) and the hierarchy is computed by HSNE (c). In WAOW-Vis, we first present an overview of the data (d). The user may focus on specific regions of interest and generate more detailed visualiza- tions (e). ", "caption_bbox": [428, 481, 762, 601]}, {"image_id": 3, "file_name": "772_03.png", "page": 4, "dpi": 300, "bbox": [412, 112, 752, 422], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Bipartite graphs as high-dimensional data. A bipartite graph connects a collection of users U with a collection of Twit- ter feeds V. To avoid clutter, here we show only the links connect- ing u2 and v3 (a). The bipartite graph is represented by an ad- jacency matrix (b). The adjacency matrix contains two symmetric biadjacency matrices (c). The elements in U and V are seen as two high-dimensional datasets. To reduce the memory occupation and speed up the similarities computation, the data points are saved as compressed bitmaps using, for example, a Run-Length Encod- ing [RC67](d). ", "caption_bbox": [428, 433, 762, 583]}, {"image_id": 4, "file_name": "772_04.png", "page": 5, "dpi": 300, "bbox": [97, 112, 764, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Sets Intersection Tree Bitmaps are organized in a number of subtrees. (a) Every tree contains bitmaps that are intersecting with the pivot, p00 and p01 in this case. Every sub tree is recursively divided in subtrees. (b) The SIT is implemented with a left-child right-sibling binary-tree. Bitmaps are not actually inserted in the tree but every node references to a linear array of indices. (c) The query for a set q starts from the root, i.e., p00 . All the siblings of a visited node are traversed, i.e., p01 . Children of a node are visited if the union of the sets in the subtree are intersecting q. Both p10 and p00 are visited in the example. ", "caption_bbox": [62, 288, 761, 366]}, {"image_id": 5, "file_name": "772_05.png", "page": 7, "dpi": 300, "bbox": [74, 112, 415, 472], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Possible problems that arise if the embeddings are gener- ated independently from each other. Here, the same data presented in Figure 1a-e is embedded with a tSNE minimization [vdMH08] instead of our approach as presented in Section 5.2. Elements in U and V are badly aligned, hence cluttering the visualization of the links between the two collections. Moreover, the same cluster of landmarks may appear in different positions along the vertical axis (a). Bundling the lines reduces clutter but does not produce a neat layout as in Figure 1a-e (b,c). ", "caption_bbox": [63, 488, 397, 623]}, {"image_id": 6, "file_name": "772_06.png", "page": 9, "dpi": 300, "bbox": [66, 112, 764, 591], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Analysis of the United States\u2019 politics and news datasets. The News dataset comprises a collection V of Twitter accounts of journalists from two of the United States\u2019 major news outlets, CNN and Fox News. Users that follows the feeds in V are in the collection U. Two echo chambers [Gar09] are identified in the dataset (a,b). Users in the top cluster are following only journalists from Fox News (a), while the ones at the bottom are following only CNN\u2019s journalists (b). In the two visualizations (a,b) only the edges linked to the selection are shown. In the right embedding, landmarks are visualized with a green-to-orange color scale that shows the percentage of incoming edges in the current selection. The clusters of orange-colored landmarks in V confirms the strong association for the selection in U. By drilling into the CNN cluster, a sub community that follows Fox News accounts is identified (c) The analysis of the politics datasets does not show strong evidence of a polarized audience (d). A cluster containing users that follow all the senators is highlighted in purple (d,e). The cluster in gray contains users following the senators with the largest audience, while users in the red cluster follow senators with not so many followers (d,e). A detailed visualization of the red cluster reveal that a polarized audience exists for these senators (f). ", "caption_bbox": [63, 628, 762, 779]}], "773": [{"image_id": 0, "file_name": "773_00.png", "page": 1, "dpi": 300, "bbox": [412, 297, 764, 937], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The layout for the TLR4 biological system produced using (a) Cerebral [BMGK08], a domain-specific layout tool, as compared to (b) SetCoLa. The layers correspond to the location of the biomolecule within a cell and show immune response outcomes at the bottom of the graph, grouped by molecular function. ", "caption_bbox": [428, 948, 762, 1022]}, {"image_id": 1, "file_name": "773_01.png", "page": 3, "dpi": 300, "bbox": [412, 112, 764, 561], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) The SetCoLa specification and data for (b) a tree with six nodes. The nodes are split into three sets based on their depth and aligned. A new set definition uses composition to include only the \u201clayer\u201d set and orders each layer by its depth to form the tree. (c) The WebCoLa specification created by the SetCoLa compiler. ", "caption_bbox": [428, 567, 762, 641]}, {"image_id": 2, "file_name": "773_02.png", "page": 5, "dpi": 300, "bbox": [62, 112, 764, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The number of nodes, links, and constraints for each example. The columns labeled Constraint Definitions and SetCoLa Constraints list the number of definitions or constraints written by the user. We compare the number of SetCoLa Constraints to the number of WebCoLa Constraints generated by the SetCoLa compiler to determine the factor by which the number of constraints increases (Ratio). ", "caption_bbox": [63, 252, 762, 296]}, {"image_id": 3, "file_name": "773_03.png", "page": 7, "dpi": 300, "bbox": [63, 112, 764, 450], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The layout for the syphilis social network from (a) Rothenberg et al. [RST\u2217 98]. (b) We recreated and improved the layout in SetCoLa by introducing additional padding, alignment, and circle constraints to further highlight the relative number of interactions among the different groups. For both figures, the nodes are split into three groups, from left to right: young affluent white men, younger white women, and young African-American men. Individuals not associated with any of these \u201ccore\u201d groups are positioned above the others. In both figures, individuals diagnosed with syphilis during the outbreak are labeled with an \u201cS\u201d on the node label. ", "caption_bbox": [63, 452, 762, 530]}, {"image_id": 4, "file_name": "773_04.png", "page": 7, "dpi": 300, "bbox": [62, 538, 399, 815], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The SetCoLa specification for the syphilis social network shown in Figure 4. The code is annotated with the number of sets produced (green), the number of WebCoLa constraints generated for the final layout (blue), and the behavior of SetCoLa constraints not directly converted to WebCoLa constraints (purple). ", "caption_bbox": [63, 820, 397, 894]}, {"image_id": 5, "file_name": "773_05.png", "page": 8, "dpi": 300, "bbox": [412, 112, 764, 480], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A subset of the food web for Kruger National park arranged by trophic level (i.e., carnivore, herbivore, and plant), as seen on the website [Kru17] and (b) recreated using SetCoLa. ", "caption_bbox": [428, 485, 762, 528]}, {"image_id": 6, "file_name": "773_06.png", "page": 8, "dpi": 300, "bbox": [62, 112, 415, 381], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The SetCoLa specification for the TLR4 biological system shown in Figure 1. ", "caption_bbox": [63, 386, 397, 414]}, {"image_id": 7, "file_name": "773_07.png", "page": 9, "dpi": 300, "bbox": [62, 112, 415, 938], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The customized layout for the Serengeti food web from (a) Baskerville et al. [BDB\u2217 11a] as compared to (b) the layout recreated with SetCoLa. Nodes are layered by trophic level (e.g., plant, herbivore, carnivore) and clustered into groups using a Bayesian analysis method. (c) The SetCoLa specification. ", "caption_bbox": [63, 943, 397, 1017]}], "774": [{"image_id": 0, "file_name": "774_00.png", "page": 1, "dpi": 300, "bbox": [62, 650, 764, 890], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Direct volume renderings (top row) and meshes (bottom row) show the structure of one synthetic dataset. One program computed all renderings, and another computed the mesh vertices. Between features (columns), the only differences in their source code were functions for computing a Newton step to the feature, and for measuring feature strength. These functions were shared between the two programs, achieving orthogonality between implementing visualization algorithms, and specifying the particular features of interest. ", "caption_bbox": [63, 586, 762, 649]}, {"image_id": 1, "file_name": "774_01.png", "page": 5, "dpi": 300, "bbox": [426, 428, 764, 522], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Minimal but complete program results: Fig. 2 volume renderer creates (a), Fig. 4 particle system creates (b), (c), and (d; converged) after indicated iterations. ", "caption_bbox": [428, 526, 762, 574]}, {"image_id": 2, "file_name": "774_02.png", "page": 7, "dpi": 300, "bbox": [427, 445, 761, 559], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Particles on surface features (a) are meshed by adding inter-particle edges (b), uncrossing edges (c), adding triangles (d), fixing stray edges (e), and filling holes (f). ", "caption_bbox": [428, 558, 762, 606]}, {"image_id": 3, "file_name": "774_03.png", "page": 8, "dpi": 300, "bbox": [427, 788, 764, 907], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Curvature-based transfer functions do a poor job (a) of isolating surface crease lines, but feature steps toward curvature extrema permit their clean rendering (b), (c). ", "caption_bbox": [428, 911, 762, 959]}, {"image_id": 4, "file_name": "774_04.png", "page": 8, "dpi": 300, "bbox": [432, 476, 764, 663], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A three-way intersection of sheets (a) creates a complex configuration of ridge surfaces (b), seen closer in (c). The analytic ridge boundary can be rendered in isolation (d), and regularly sam- pled with a particle system (e); different view (f). ", "caption_bbox": [428, 666, 762, 729]}, {"image_id": 5, "file_name": "774_05.png", "page": 8, "dpi": 300, "bbox": [62, 584, 399, 759], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Green cell nucleii can be traditionally rendered with MIP (a), or with MIP computed only within the membrane of cells of interest (b). Maxima rendering (c) clarifies nucleii number and depth. ", "caption_bbox": [63, 760, 397, 823]}, {"image_id": 6, "file_name": "774_06.png", "page": 9, "dpi": 300, "bbox": [510, 302, 678, 557], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Volume rendering of Q isosurfaces around extracted polylines of Q ridge lines ", "caption_bbox": [428, 556, 762, 589]}, {"image_id": 7, "file_name": "774_07.png", "page": 10, "dpi": 300, "bbox": [62, 112, 737, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Different feature step functions reveal a variety of Fractional Anisotropy (FA) features from a DTI volume.", "caption_bbox": [116, 297, 708, 315]}], "775": [{"image_id": 0, "file_name": "775_00.png", "page": 3, "dpi": 300, "bbox": [61, 111, 415, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of spatio-temporal contour visualization: sam- ples S are generated via deep raycasting, and the distances between image cells (captured by a temporal histogram of distances H and                          \u02c6 are determined by sample matching for ", "caption_bbox": [61, 241, 397, 294]}, {"image_id": 1, "file_name": "775_01.png", "page": 4, "dpi": 300, "bbox": [412, 111, 738, 373], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Impact of T time on the contours of the Droplet Mea- surement data, an experiment of a droplet forming at the top and ", "caption_bbox": [426, 379, 762, 403]}, {"image_id": 2, "file_name": "775_02.png", "page": 5, "dpi": 300, "bbox": [412, 111, 764, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Simulation of a supernova, in which the supernova con- stantly rotates throughout the course of the time series. A large temporal threshold Ttime = 0.4 is used, and the spatial threshold is ", "caption_bbox": [426, 323, 762, 376]}, {"image_id": 3, "file_name": "775_03.png", "page": 6, "dpi": 300, "bbox": [66, 479, 392, 625], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The Bottle data set depicts a laser pulse traveling through a bottle (captured via Femto Photography [VWJ\u2217 13]). As indicated by the contours (Ttime = 0.06), on its way through the bottle from left to right, the laser gets reflected and scattered in different ways with sharp process transitions. Here, the contour image is complemented with the temporal selection of Frey and Ertl [FE16] with five selected time steps (cf. Fig.1b for just our contours). ", "caption_bbox": [61, 625, 395, 730]}, {"image_id": 4, "file_name": "775_04.png", "page": 6, "dpi": 300, "bbox": [55, 111, 775, 344], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Two drops fly toward each other (i), collide asymmetrically, and form a disk from which then individual droplets emerge again (ii) (a). The splash out movement for droplets closer to the center of the disk (iii-a) is much smaller compared to droplets at the vicinity of the disk (iii-b). For the larger droplets, their contours indicate constant changes due to droplet oscillation, e.g., (iii-c). We also show the results for different resolution parameters \u03c1 ((b) & (c)) as well as respective results of the temporal selection technique by Frey and Ertl [FE16], both by itself (d) and in combination with our contour-based visualization (e). ", "caption_bbox": [60, 349, 761, 423]}, {"image_id": 5, "file_name": "775_05.png", "page": 7, "dpi": 300, "bbox": [64, 111, 773, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The 5Jets data set is the result of a simulation modeling five jets. It depicts an upward movement which splits into waves of different speeds (with a large wave going all the way to the top). The dense color transition at the five jets at the bottom indicates steadily high variation in the upward movement in their vicinity, while the blue and green \u201ccurves\u201d indicate small, quickly moving waves that also terminate quickly. With the contour image acting as a reference (c), we also show the results for different resolution parameters \u03c1 ((a) & (b)), different spatial thresholds Tspace ((d) & (e)), as well as a combination with the temporal selection technique by Frey and Ertl [FE16] (f). ", "caption_bbox": [60, 366, 763, 450]}, {"image_id": 6, "file_name": "775_06.png", "page": 9, "dpi": 300, "bbox": [68, 305, 392, 570], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: CFD simulation of a von K\u00e1rm\u00e1n vortex street. (a) Dif- ferent stages of development can be seen (Ttime = 0.04). In the beginning of the simulation, the process develops mainly horizon- tally, with smaller scale swings from the left to the right (Fig.9c & Fig.9d). After that, there is a transition to recurrent behavior mov- ing from top to bottom in what are essentially two lanes (Fig.9g & Fig.9h). (b) This is shown more clearly in the contour visualization only depicting the second half of the time series. ", "caption_bbox": [60, 575, 397, 695]}], "776": [{"image_id": 0, "file_name": "776_00.png", "page": 3, "dpi": 300, "bbox": [412, 112, 764, 677], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Reconstructions of the ML test signal from 303 \u00d7 4 FCC samples using different interpolation schemes of approximation or- der two. ", "caption_bbox": [428, 700, 762, 747]}, {"image_id": 1, "file_name": "776_01.png", "page": 3, "dpi": 300, "bbox": [80, 112, 415, 677], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Reconstructions of the Marschner-Lobb (ML) [ML94] test signal from 253 \u00d7 4 FCC samples using different interpola- tion schemes of approximation order two. The black-and-white im- ages show the angular errors of the gradients estimated by cen- tral differencing on the reconstructed signal throughout the paper. Angular error of 15 degrees is mapped to white, whereas angu- lar error of zero degree is mapped to black. Additionally, the ML signal is rotated by 45 degrees before sampling as suggested by Vad et al. [VCRG14, VCG12], which maximizes the prealiasing ef- fect [ML94], that is, the overlapping of the primary spectrum and the aliasing spectra in the frequency domain. ", "caption_bbox": [62, 700, 396, 865]}, {"image_id": 2, "file_name": "776_02.png", "page": 5, "dpi": 300, "bbox": [412, 112, 764, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: RMS error of CWLB and CWCB reconstructions of the ML signal depending on the value of parameter \u03bb. ", "caption_bbox": [428, 321, 762, 350]}, {"image_id": 3, "file_name": "776_03.png", "page": 5, "dpi": 300, "bbox": [466, 373, 728, 602], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: RMS error of CWLB and CWCB reconstructions of the ML signal depending on the data resolution. ", "caption_bbox": [428, 615, 762, 643]}, {"image_id": 4, "file_name": "776_04.png", "page": 5, "dpi": 300, "bbox": [80, 112, 415, 677], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Reconstructions of the ML test signal from 253 \u00d7 4 FCC samples using different interpolation schemes of approximation or- der four. ", "caption_bbox": [62, 700, 396, 747]}, {"image_id": 5, "file_name": "776_05.png", "page": 6, "dpi": 300, "bbox": [412, 112, 746, 677], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Reconstructions of the ML test signal from 403 CC sam- ples using different interpolation schemes of approximation order four. An intermediate FCC-sampled representation is calculated by a frequency-domain phase shifting. ", "caption_bbox": [428, 700, 762, 762]}, {"image_id": 6, "file_name": "776_06.png", "page": 6, "dpi": 300, "bbox": [62, 112, 415, 677], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Reconstructions of the ML test signal from 403 CC sam- ples using different interpolation schemes of approximation order two. An intermediate FCC-sampled representation is calculated by a frequency-domain phase shifting. ", "caption_bbox": [63, 700, 397, 762]}, {"image_id": 7, "file_name": "776_07.png", "page": 7, "dpi": 300, "bbox": [103, 112, 764, 903], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Reconstructions of a carp from 128 \u00d7 128 \u00d7 256 \u00d7 4 FCC samples using different interpolation schemes of approximation orders of two (a, c, e) and four (b, d, f). The FCC representation was calculated from 128 \u00d7 128 \u00d7 256 original CC samples using a frequency-domain phase shifting. ", "caption_bbox": [62, 925, 761, 969]}, {"image_id": 8, "file_name": "776_08.png", "page": 8, "dpi": 300, "bbox": [62, 112, 724, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Reconstructions of a carp from 128 \u00d7 128 \u00d7 256 CC samples using trilinear B-spline interpolation and prefiltered tricubic B-spline interpolation. ", "caption_bbox": [62, 405, 761, 434]}], "777": [{"image_id": 0, "file_name": "777_00.png", "page": 1, "dpi": 300, "bbox": [79, 381, 747, 711], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization of a Toronto Blue Jays vs Boston Red Socks play. (1) Batter hits the ball. (2-3) Center fielder throws ball to second baseman. (4) Runner reaches home. (5) Rundown, batter stranded between two bases. (6) Batter changes direction. (7) Batter is tagged out. ", "caption_bbox": [63, 726, 762, 754]}, {"image_id": 1, "file_name": "777_01.png", "page": 2, "dpi": 300, "bbox": [412, 112, 728, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An example of the way the MLB Statcast [Med15] project makes use of Play Diagrams. Each play containing interesting fea- tures, like the speed of a throw, for example, is published as a dia- gram and a brief description of what set it apart. ", "caption_bbox": [428, 444, 762, 503]}, {"image_id": 2, "file_name": "777_02.png", "page": 4, "dpi": 300, "bbox": [412, 112, 728, 351], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Baseball field of play and player positions: pitcher (P), batter (B), catcher (C), infielders (1B, 2B, 3B and SS) and outfield- ers (LF, CF and RF). ", "caption_bbox": [428, 363, 762, 406]}, {"image_id": 3, "file_name": "777_03.png", "page": 5, "dpi": 300, "bbox": [416, 112, 764, 512], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Design attempts that did not meet our requirements.", "caption_bbox": [438, 527, 751, 540]}, {"image_id": 4, "file_name": "777_04.png", "page": 6, "dpi": 300, "bbox": [412, 112, 743, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Mapping of the player position to angle. (a) Infield with angle annotations and reference vector from Pitcher\u2019s Mound to Home Plate (b) Representation of player position in the Y axis. ", "caption_bbox": [428, 280, 762, 323]}, {"image_id": 5, "file_name": "777_05.png", "page": 7, "dpi": 300, "bbox": [62, 112, 415, 283], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: 06/03/2017 - Los Angeles Dodgers @ Milwaukee Brew- ers: Travis Shaw hits a Grand Slam ", "caption_bbox": [63, 294, 397, 322]}, {"image_id": 6, "file_name": "777_06.png", "page": 8, "dpi": 300, "bbox": [61, 112, 754, 714], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Six baseball plays represented by Baseball Timeline.", "caption_bbox": [255, 727, 570, 740]}], "778": [{"image_id": 0, "file_name": "778_00.png", "page": 1, "dpi": 300, "bbox": [98, 399, 728, 725], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The c|swarm user interface, showing S&P 500 (US large capitalisation) stocks\u2019 correlations of daily returns for the three months to 22 July, 2014. The utilities industry sector is selected; the analysis workflow suggests that these stocks could be useful diversifiers. ", "caption_bbox": [63, 737, 762, 765]}, {"image_id": 1, "file_name": "778_01.png", "page": 2, "dpi": 300, "bbox": [412, 112, 762, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Correlations between stock returns vary over time and are generally higher in times of market stress. Here, we see how the distribution of rolling three-month pairwise correlation coeffi- cients (r) between S&P 500 (US large-capitalisation stocks) index constituents\u2019 daily price returns has fluctuated since 2006. ", "caption_bbox": [428, 313, 762, 387]}, {"image_id": 2, "file_name": "778_02.png", "page": 5, "dpi": 300, "bbox": [70, 112, 764, 550], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Context-sensitive interactive displays in the c|swarm user interface. Main and auxiliary displays change depending on whether, and how many, nodes are selected. For example, in the main display, selecting only one node switches on all links between that stock and others (subject to interactive filtering). Selecting two or more nodes shows only links between the highlighted stocks. Interactive tooltips show further detail when hovering over nodes and edges. The analysis time window is moved by double-clicking on any of the line displays. ", "caption_bbox": [63, 575, 762, 634]}, {"image_id": 3, "file_name": "778_03.png", "page": 6, "dpi": 300, "bbox": [61, 112, 415, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The \u2018Sorter\u2019 view rearranges the main display by sector and size to support easy selection of nodes and groups; the full range of interactions and animation is available in this mode. ", "caption_bbox": [63, 401, 397, 444]}, {"image_id": 4, "file_name": "778_04.png", "page": 7, "dpi": 300, "bbox": [129, 112, 764, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The swarm \u201cclenches\u201d (B1) in times of market stress (such as the 2011 debt default crisis, right): when correlations are high, less-correlated stocks are of particular interest. Many of the stocks in the periphery are in \u2019defensive\u2019 sectors such as Consumer Staples, Health Care, Technology and Utilities; Newmont Mining, a \u2018safe haven\u2019 gold mining stock, is a great distance from the rest of the swarm. ", "caption_bbox": [63, 395, 762, 438]}, {"image_id": 5, "file_name": "778_05.png", "page": 8, "dpi": 300, "bbox": [412, 112, 759, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Top: The layout algorithm effectively encodes correla- tion stability as layout stability in all test data. Number of nodes in parentheses. Bottom: Layout calculation speed is driven by the number of nodes in the data with a weak response to change in the correlations within the frames. Note: Log scales used on all axes. ", "caption_bbox": [428, 305, 762, 379]}, {"image_id": 6, "file_name": "778_06.png", "page": 8, "dpi": 300, "bbox": [61, 112, 415, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Rotation (B9): from May to August 2016, we see a great deal of movement in nodes\u2019 positions relative to each other, sug- gesting that the underlying correlation structure has changed sub- stantially. Many financials stocks are closely bunched (B3; red dot- ted line), indicating strong correlations within that group. ", "caption_bbox": [63, 301, 397, 375]}, {"image_id": 7, "file_name": "778_07.png", "page": 9, "dpi": 300, "bbox": [62, 112, 415, 547], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Industry sectors with different levels of homogeneity ex- hibit different behaviours in the swarm (links for r < 0.7 filtered out in all examples). Upper: Central clustering (B4): stocks in the financials group (red) are less tightly bunched than utilities or en- ergy stocks, but occupy a central location in the swarm. Lower: Broad dispersion (B6): IT sector (magenta) stocks are scattered throughout a wide area of the swarm. The histogram shows that their correlation structure is similar to that of the entire market\u2019s. In fig. 1: Peripheral bunching (B5): the utilities sector exhibits high intra-sector correlation and low correlation to other stocks. ", "caption_bbox": [63, 558, 397, 708]}, {"image_id": 8, "file_name": "778_08.png", "page": 10, "dpi": 300, "bbox": [61, 112, 762, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: \u201cOrbiting:\u201d in a period where the swarm was generally quite stable (a-f), Apple (AAPL; magenta; edges for positive correlations filtered out) \u201corbited\u201d (B7) around the plot, indicating low, variable correlations to other stocks. By mid-2015 (g), the correlation behaviour had changed and the stock had \u201cmeandered\u201d (B8) to a position near the swarm\u2019s centre. ", "caption_bbox": [63, 245, 762, 288]}], "779": [{"image_id": 0, "file_name": "779_00.png", "page": 2, "dpi": 300, "bbox": [412, 112, 757, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Illustrative scheme of the steps involved in creating a 3D geological model to be used in dynamic simulation. ", "caption_bbox": [428, 307, 762, 335]}, {"image_id": 1, "file_name": "779_01.png", "page": 4, "dpi": 300, "bbox": [412, 112, 697, 157], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Pastel colormaps (from ColorBrewer [BH]).", "caption_bbox": [458, 160, 733, 173]}, {"image_id": 2, "file_name": "779_02.png", "page": 5, "dpi": 300, "bbox": [112, 112, 415, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Porosity sampling illustration using our strategy.", "caption_bbox": [81, 255, 378, 268]}, {"image_id": 3, "file_name": "779_03.png", "page": 5, "dpi": 300, "bbox": [412, 112, 764, 222], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) Permeability illustration. (b) Permeability decals.", "caption_bbox": [436, 225, 754, 238]}, {"image_id": 4, "file_name": "779_04.png", "page": 5, "dpi": 300, "bbox": [427, 242, 766, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Permeability as 2D decal-maps.", "caption_bbox": [488, 360, 701, 373]}, {"image_id": 5, "file_name": "779_05.png", "page": 5, "dpi": 300, "bbox": [67, 280, 391, 433], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Porosity distribution on the surface of a geological model using our sampling approach. (a) No jittering; (b) jittering of 0.2. ", "caption_bbox": [63, 435, 397, 463]}, {"image_id": 6, "file_name": "779_06.png", "page": 6, "dpi": 300, "bbox": [61, 112, 415, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Permeability as 3D tensor glyph. (a) Orientation schematics; (b) design representation. ", "caption_bbox": [63, 261, 397, 289]}, {"image_id": 7, "file_name": "779_07.png", "page": 8, "dpi": 300, "bbox": [61, 112, 754, 352], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Implementation overview. (Left) Multiple layers are selected from the 3D geological model as input to the layering framework. (Middle) In the layering framework, attribute layers are computed and the G-buffer information (depth) stored in pixel-space. After this process, the layers are available in image space, but the depth relationship in object-space is lost. (Right) The A-Layers are rendered to a 2D texture array (layered framebuffer) and serve as input for a rendered screen quad in a subsequent pass. The layers are then sorted at the fragment level and the final image generated. After this process, filters such as SSAO can be applied. ", "caption_bbox": [63, 355, 762, 429]}, {"image_id": 8, "file_name": "779_08.png", "page": 9, "dpi": 300, "bbox": [69, 112, 764, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Illustrative multivariate geological visualization using our approach. (a) Two cross-sections depicting rock type, porosity, and the permeability tensor. (b) Hybrid visualization approach combining decals and 3D glyph tensor visualization. The 3D ellipsoid glyphs depict areas of high average permeability magnitude encoded by size. The glyphs shape illustrates the strong direction of permeability. (c) Illustrative geological visualization with an alternative design inspired by traditional geological illustrations [Bak16]. ", "caption_bbox": [63, 336, 762, 395]}, {"image_id": 9, "file_name": "779_09.png", "page": 10, "dpi": 300, "bbox": [61, 112, 752, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Illustrations of the secondary recovery analysis. At the reservoir surface, layered decals exhibit four properties that exert control over fluid behavior within the reservoir (namely, permeability, porosity, rock type, and oil saturation). From left to right: (a) top view of a geological model extracting oil using a pair of (b) injector and (c) producer wells. ", "caption_bbox": [63, 341, 762, 384]}, {"image_id": 10, "file_name": "779_10.png", "page": 11, "dpi": 300, "bbox": [442, 372, 746, 540], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Geological model illustrating permeability as decal- tensor composition. ", "caption_bbox": [428, 543, 762, 571]}, {"image_id": 11, "file_name": "779_11.png", "page": 11, "dpi": 300, "bbox": [69, 112, 764, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Illustrations of the inter-well connectivity analysis. (a) Permeability decals display no connection between wells at surface level. (b) 3D permeability tensors exhibit internal channeling networks. (c) Decals reveal interior inter-well connection in sandstone sheet. (d) Internal layer illustrating hybrid permeability encoding. ", "caption_bbox": [63, 319, 762, 362]}], "780": [{"image_id": 0, "file_name": "780_00.png", "page": 1, "dpi": 300, "bbox": [62, 382, 764, 649], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: CFGExplorer helps researchers analyze programs and correlate control flow (a) and trace data (b). We designed a domain-specific layout approach to elucidate loop structure (orange). Users can animate execution using the linked blue gradient (c). ", "caption_bbox": [63, 660, 762, 688]}, {"image_id": 1, "file_name": "780_01.png", "page": 2, "dpi": 300, "bbox": [645, 815, 760, 956], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Loop.", "caption_bbox": [661, 969, 743, 982]}, {"image_id": 2, "file_name": "780_02.png", "page": 5, "dpi": 300, "bbox": [412, 112, 764, 733], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: CFG of the mini-flux-div benchmark [OSG\u2217 14] as ren- dered by Dagre, dot, and our domain-specific approach. Our lay- out reveals multiple simple, but deeply nested loops. ", "caption_bbox": [428, 750, 762, 797]}, {"image_id": 3, "file_name": "780_03.png", "page": 5, "dpi": 300, "bbox": [74, 727, 388, 879], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: CFG of a simple while loop as generated by LLVM [LA04]. To modify the results of a general layered layout (a), we add an invisible edge (red) from the tail node to all outer nodes (b). In dot, we also route the back edge using ports (c) and color the loop based on its bounding nodes and edges (d). ", "caption_bbox": [63, 887, 397, 961]}, {"image_id": 4, "file_name": "780_04.png", "page": 6, "dpi": 300, "bbox": [412, 112, 764, 440], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Functions and loops can be automatically centered via the slide-out navigation menu. A bounding box is drawn around the function or loop and all member nodes are selected (teal border). ", "caption_bbox": [428, 451, 762, 494]}, {"image_id": 5, "file_name": "780_05.png", "page": 6, "dpi": 300, "bbox": [61, 112, 415, 804], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Loop boundaries (orange) are drawn as the convex hull of the loop nodes and back edge, darker indicates loop nesting. This approach does not capture all loop edges (left) as doing so can create difficult-to-interpret results in more complicated graphs. ", "caption_bbox": [63, 816, 397, 875]}, {"image_id": 6, "file_name": "780_06.png", "page": 7, "dpi": 300, "bbox": [412, 112, 764, 325], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The visible portions of the trace and corresponding nodes in the CFG are colored using a blue gradient. Researchers can see the sequence of a portion of the trace in the CFG. Scrolling acts as animation to understand execution. ", "caption_bbox": [428, 336, 762, 395]}, {"image_id": 7, "file_name": "780_07.png", "page": 8, "dpi": 300, "bbox": [61, 112, 415, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The backtainted addresses from the query address 40059E (denoted here with a floating arrow) are highlighted in pur- ple. Darker implies a closer address in the data dependency chain. ", "caption_bbox": [63, 328, 397, 371]}], "781": [{"image_id": 0, "file_name": "781_00.png", "page": 1, "dpi": 300, "bbox": [81, 416, 751, 591], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Left: A satellite image from Google Maps. Right: Our 3D printed model of the same area.", "caption_bbox": [162, 625, 662, 638]}, {"image_id": 1, "file_name": "781_01.png", "page": 4, "dpi": 300, "bbox": [432, 585, 760, 709], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: For any number of features (a), we use CDT to create an initial mesh (b). A region growing algorithm is applied later to determine what feature each face belongs to (c). ", "caption_bbox": [428, 723, 762, 766]}, {"image_id": 2, "file_name": "781_02.png", "page": 4, "dpi": 300, "bbox": [61, 112, 755, 460], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: We use several 2D GIS sources to retrieve the required features and elevation data for the region of interest. A Constrained Delaunay Triangulation is employed to create an initial 3D model. Using a technique based on winding numbers, feature submeshes are extracted from this model. These submeshes are used to create extruded layers. Each of these layers is designed based on the characteristics of its corresponding feature to create a more realistic model. For extruded layers that do not fit inside the 3D printer, a grid segmentation method is used to create appropriate smaller pieces. Eventually, printing all the pieces and assembling them creates the final physical model. ", "caption_bbox": [63, 481, 762, 555]}, {"image_id": 3, "file_name": "781_03.png", "page": 5, "dpi": 300, "bbox": [462, 828, 756, 943], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: In (a), the red feature submesh is inside two other fea- ture submeshes. To detect this situation, as shown in (b), we cast an infinite ray to determine the hierarchy of surrounding feature sub- meshes. Each arrow here shows a crossing for a feature boundary. ", "caption_bbox": [428, 957, 762, 1016]}, {"image_id": 4, "file_name": "781_04.png", "page": 5, "dpi": 300, "bbox": [65, 112, 415, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: In order to assign different materials to each feature, we create separate layers for each feature. ", "caption_bbox": [63, 264, 397, 292]}, {"image_id": 5, "file_name": "781_05.png", "page": 6, "dpi": 300, "bbox": [179, 857, 282, 961], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Each piece is a connected component of a feature sub- mesh after segmentation. We need to evaluate each piece based on how appropriate they are for 3D printing. ", "caption_bbox": [63, 972, 397, 1015]}, {"image_id": 6, "file_name": "781_06.png", "page": 6, "dpi": 300, "bbox": [461, 596, 699, 895], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: For each orientation of a feature submesh on a regular grid, where L is the grid cell size, we search different possible trans- lations, shown as a 2D vector in the figure. To speed up this search, each translation axis is uniformly discretized to m values and ori- entation is uniformly discretized to d values. We choose the optimal configuration for breaking the submesh into smaller pieces, shown as red. ", "caption_bbox": [428, 912, 762, 1016]}, {"image_id": 7, "file_name": "781_07.png", "page": 7, "dpi": 300, "bbox": [95, 112, 415, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The shape in (a), can be repositioned on the grid to create equal area pieces (b). In (c), there is no way to create 2 equal area pieces with two grid cells, and achieving the lower bound cost is not possible. If we allow for the creation of more pieces, we can create 3 equal area pieces (d). ", "caption_bbox": [63, 240, 397, 314]}, {"image_id": 8, "file_name": "781_08.png", "page": 7, "dpi": 300, "bbox": [412, 112, 764, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The blue pieces in (a) after post-processing can include neighbor pieces as well, as in (b). ", "caption_bbox": [428, 241, 762, 269]}, {"image_id": 9, "file_name": "781_09.png", "page": 8, "dpi": 300, "bbox": [61, 112, 415, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Here a part of a feature submesh and its corresponding connectivity graph is shown. The size of the nodes in the graph is proportional to the cost of their corresponding pieces. The node with the highest cost is shown in red. ", "caption_bbox": [63, 232, 397, 291]}, {"image_id": 10, "file_name": "781_10.png", "page": 8, "dpi": 300, "bbox": [117, 890, 344, 970], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: We connect offset polylines as a simple and fast ap- proach to create an offset polygon for pathways. ", "caption_bbox": [63, 988, 397, 1016]}, {"image_id": 11, "file_name": "781_11.png", "page": 8, "dpi": 300, "bbox": [429, 888, 762, 973], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Combining all the tree models into a single layer is beneficial for 3D printing. ", "caption_bbox": [428, 988, 762, 1016]}, {"image_id": 12, "file_name": "781_12.png", "page": 9, "dpi": 300, "bbox": [70, 112, 415, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Adding tree primitives to the extruded layer. (b) and (c) use displacement mapping to blend the tree primitives in densely populated regions. ", "caption_bbox": [63, 254, 397, 297]}, {"image_id": 13, "file_name": "781_13.png", "page": 9, "dpi": 300, "bbox": [412, 112, 764, 259], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: We overlay stencil layers, on top of buildings to add missing and otherwise fragile feature types. ", "caption_bbox": [428, 274, 762, 302]}, {"image_id": 14, "file_name": "781_14.png", "page": 9, "dpi": 300, "bbox": [441, 316, 751, 441], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Different types of generated roofs.", "caption_bbox": [480, 454, 710, 467]}, {"image_id": 15, "file_name": "781_15.png", "page": 9, "dpi": 300, "bbox": [62, 791, 399, 973], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: 3D render of a set of buildings combined into a single extruded layer. ", "caption_bbox": [63, 988, 397, 1016]}, {"image_id": 16, "file_name": "781_16.png", "page": 10, "dpi": 300, "bbox": [429, 873, 763, 989], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 18: We use pillars to reduce printing time and material use.", "caption_bbox": [428, 1003, 762, 1016]}, {"image_id": 17, "file_name": "781_17.png", "page": 10, "dpi": 300, "bbox": [412, 112, 764, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 17: The resulting physical model of Lake Louise area. For more images, please refer to supplementary material. ", "caption_bbox": [428, 339, 762, 367]}, {"image_id": 18, "file_name": "781_18.png", "page": 11, "dpi": 300, "bbox": [412, 112, 764, 767], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 19: The resulting physical model of Lauterbrunnen valley.", "caption_bbox": [430, 781, 759, 794]}, {"image_id": 19, "file_name": "781_19.png", "page": 12, "dpi": 300, "bbox": [61, 112, 415, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 20: Using more indentation, our system can account for accumulated imprecision of stencil layers. ", "caption_bbox": [63, 340, 397, 368]}], "782": [{"image_id": 0, "file_name": "782_00.png", "page": 1, "dpi": 300, "bbox": [62, 488, 764, 713], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Four interactive visualisations for geographic data in Virtual Reality (VR).", "caption_bbox": [199, 467, 625, 480]}, {"image_id": 1, "file_name": "782_01.png", "page": 3, "dpi": 300, "bbox": [412, 112, 764, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Distortion of an egocentric globe changes with user po- sition: (b) view at the initial location; (a) view from left close to the sphere\u2019s hull; (c) close view from right. ", "caption_bbox": [428, 241, 762, 284]}, {"image_id": 2, "file_name": "782_02.png", "page": 4, "dpi": 300, "bbox": [414, 112, 736, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Tissot indicatrices on the Natural Earth raster map with a graticule, (a) on an exocentric globe, (b) on a flat map. ", "caption_bbox": [428, 243, 762, 271]}, {"image_id": 3, "file_name": "782_03.png", "page": 6, "dpi": 300, "bbox": [61, 112, 415, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a1) Average performance of distance comparison task per visualisation, with 95% confidence interval, (a2) graphical de- piction of results of pairwise post-hoc test. ", "caption_bbox": [62, 279, 396, 322]}, {"image_id": 4, "file_name": "782_04.png", "page": 6, "dpi": 300, "bbox": [414, 112, 753, 560], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Break down of distance comparison task into different difficulty conditions. (a1,b1,c1) Average performance per visuali- sation with 95% confidence interval, (a2,b2,c2,c3) graphical de- piction of result of pairwise post-hoc test. ", "caption_bbox": [428, 561, 762, 620]}, {"image_id": 5, "file_name": "782_05.png", "page": 7, "dpi": 300, "bbox": [412, 112, 764, 560], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Break down of area comparison task into different diffi- culty conditions. (a1,b1,c1) Average performance per visualisation with 95% confidence interval, (a2,a3,b2,b3,c2,c3) graphical depic- tion of results of pairwise post-hoc test. ", "caption_bbox": [428, 561, 762, 620]}, {"image_id": 6, "file_name": "782_06.png", "page": 7, "dpi": 300, "bbox": [71, 112, 414, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a1) Average performance of area comparison task per visualisation, with 95% confidence interval, (a2, a3) graphical de- piction of results of pairwise post-hoc test. ", "caption_bbox": [63, 279, 397, 322]}, {"image_id": 7, "file_name": "782_07.png", "page": 8, "dpi": 300, "bbox": [71, 329, 387, 619], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Break down of direction estimation task into different difficulty conditions. (a1,b1) Average performance per visualisa- tion with 95% confidence interval, (a2,a3,b2,b3) graphical depic- tion of results of pairwise post-hoc test. ", "caption_bbox": [63, 620, 397, 679]}, {"image_id": 8, "file_name": "782_08.png", "page": 8, "dpi": 300, "bbox": [414, 112, 741, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: (a) Average accumulated movements of head and con- troller per task; (b) average accumulated rotations of head and controller per task. ", "caption_bbox": [428, 271, 762, 314]}, {"image_id": 9, "file_name": "782_09.png", "page": 8, "dpi": 300, "bbox": [61, 112, 415, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a1) Average performance of direction estimation task per visualisation, with 95% confidence interval, (a2, a3) graphical depiction of results of pairwise post-hoc test. ", "caption_bbox": [62, 279, 396, 322]}, {"image_id": 10, "file_name": "782_10.png", "page": 10, "dpi": 300, "bbox": [414, 112, 773, 346], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Animated transformation from a flat map to an exocen- tric globe: top row - top view; second row - front view and bottom row - side view. The touchpad dynamically controls the progress. ", "caption_bbox": [428, 359, 762, 402]}], "783": [{"image_id": 0, "file_name": "783_00.png", "page": 1, "dpi": 300, "bbox": [62, 382, 764, 607], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: In the VirtualDesk prototype, data is rendered at arm\u2019s reach and manipulated only by mid-air natural hand gestures (center). A reproduction of the analyst\u2019s real desk is included (left) to enable tangible interaction with coordinated views and controls (right). ", "caption_bbox": [63, 618, 762, 646]}, {"image_id": 1, "file_name": "783_01.png", "page": 3, "dpi": 300, "bbox": [412, 112, 764, 232], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: In the VirtualDesk prototype, all system control and data manipulation are performed by tabletop tangible interaction (left) or controller-agnostic mid-air natural gestures, such as grabbing and tapping (right). ", "caption_bbox": [428, 243, 762, 302]}, {"image_id": 2, "file_name": "783_02.png", "page": 5, "dpi": 300, "bbox": [62, 672, 399, 865], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The desktop-based implementation provides all the same functionalities as the immersive environment, but employing a two- panels interface and Rotate-Pan-Dolly interaction for the 3D point cloud exploration. ", "caption_bbox": [63, 876, 397, 935]}, {"image_id": 3, "file_name": "783_03.png", "page": 7, "dpi": 300, "bbox": [64, 112, 764, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Average task completion times for all tasks and conditions, with standard deviations indicated by error bars. For T8b, reported times are normalized per selected point. The immersive environment was only significantly slower in tasks which required higher amounts of interaction with the tabletop controls. ", "caption_bbox": [63, 311, 762, 354]}, {"image_id": 4, "file_name": "783_04.png", "page": 7, "dpi": 300, "bbox": [63, 378, 763, 539], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Average error rates for all tasks and conditions, with standard deviations. For the interaction tasks, errors are given by the number of unintended selections. All perception tasks were performed equally well or better in the immersive environment. Point selection, however, was more accurate in Desktop. ", "caption_bbox": [63, 550, 762, 593]}, {"image_id": 5, "file_name": "783_05.png", "page": 8, "dpi": 300, "bbox": [412, 112, 763, 269], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: User agreements with different assertions, ranging from completely disagree (dark red) to completely agree (dark green), for Desktop (D) and VirtualDesk (VD). Intuitive embodied data ma- nipulation gestures were well received and allowed easy and rapid inspection and information finding in any region of the dataset. ", "caption_bbox": [428, 280, 762, 354]}, {"image_id": 6, "file_name": "783_06.png", "page": 8, "dpi": 300, "bbox": [61, 112, 415, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Average accumulated dataset rotations per task question in degrees. This form of exploration was performed 5.8 times more in VirtualDesk, probably due to the intuitiveness of the grabbing action. This increased task accuracy with minimal time overhead. ", "caption_bbox": [63, 307, 397, 366]}, {"image_id": 7, "file_name": "783_07.png", "page": 9, "dpi": 300, "bbox": [64, 831, 399, 948], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Due to its more natural and comfortable navigation paradigm, VirtualDesk achieved a 7x smaller SSQ score than the previous Flying approach, despite very similar VR exposure times. ", "caption_bbox": [63, 959, 397, 1002]}, {"image_id": 8, "file_name": "783_08.png", "page": 9, "dpi": 300, "bbox": [64, 112, 764, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison between VirtualDesk and a previous implementation employing Flying navigation. Embodied data manipulation resulted in up to 51% shorter average completion times and 30% smaller error rates. ", "caption_bbox": [63, 344, 762, 372]}], "784": [{"image_id": 0, "file_name": "784_00.png", "page": 1, "dpi": 300, "bbox": [61, 371, 763, 550], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A nanotube transitions from a 3D shape model to a diagrammatic 2D representation and finally to a clean 1D alignment of single strands. Orthogonal to the dimension axis is the scale axis, which shows different semantic scales. The orange rectangle tracks a single strand through the dimensions and scales. ", "caption_bbox": [62, 556, 761, 599]}, {"image_id": 1, "file_name": "784_01.png", "page": 2, "dpi": 300, "bbox": [412, 112, 758, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The DimSUM abstraction map is spanned by a dimension and a scale axis and integrates existing and novel representations. ", "caption_bbox": [427, 333, 761, 361]}, {"image_id": 2, "file_name": "784_02.png", "page": 5, "dpi": 300, "bbox": [68, 112, 415, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: We provide many ways of interacting with and seamlessly transition between multiple structural representations using the DimSUM. Here we show which parts of the abstraction map depict equivalent content as the state-of-the-art tool caDNAno. ", "caption_bbox": [61, 399, 396, 458]}, {"image_id": 3, "file_name": "784_03.png", "page": 5, "dpi": 300, "bbox": [412, 112, 779, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Cylindrical nanotube: examples of representations in 3D, i. e., d = 3.0 and variable scales s. ", "caption_bbox": [427, 314, 763, 343]}, {"image_id": 4, "file_name": "784_04.png", "page": 5, "dpi": 300, "bbox": [465, 358, 726, 491], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The 2D diagrammatic representation and several exam- ples of views are shown where d = 2. ", "caption_bbox": [427, 502, 763, 531]}, {"image_id": 5, "file_name": "784_05.png", "page": 6, "dpi": 300, "bbox": [412, 112, 763, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: After two strands are selected in 1D, we transition along the orange arrow and show examples of the changing representation. ", "caption_bbox": [427, 373, 761, 401]}, {"image_id": 6, "file_name": "784_06.png", "page": 6, "dpi": 300, "bbox": [61, 112, 415, 282], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Examples of representations in 1D, shown at different scales and sorting by (a) strand ID, (b) GC content, and (c) length. ", "caption_bbox": [62, 291, 396, 319]}, {"image_id": 7, "file_name": "784_07.png", "page": 7, "dpi": 300, "bbox": [461, 435, 729, 589], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Deleting of undesired short strands. Left: a sort by length in 1D reveals the short strands. Top row: one of them is selected in 1D and deleted. The same strand is shown in 2D and 3D. Bottom row: representations in all dimensions show that the strand is removed. ", "caption_bbox": [427, 596, 764, 670]}, {"image_id": 8, "file_name": "784_08.png", "page": 7, "dpi": 300, "bbox": [412, 112, 764, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The addition of a bridging strand inside the nanotube re- quires work in different dimensions and scales. Top row: crossovers are broken in 2D. Bottom row: after breaking, the broken strands are connected with a specific sequence. ", "caption_bbox": [427, 357, 763, 416]}, {"image_id": 9, "file_name": "784_09.png", "page": 7, "dpi": 300, "bbox": [61, 112, 415, 283], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Crossovers are highlighted in green. Short segments be- tween crossovers could have an adverse effect on the stability, which is best observed in 1D. ", "caption_bbox": [62, 289, 398, 332]}, {"image_id": 10, "file_name": "784_10.png", "page": 9, "dpi": 300, "bbox": [61, 322, 399, 464], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Demonstration of the detection of specific surface strand.", "caption_bbox": [62, 472, 396, 485]}, {"image_id": 11, "file_name": "784_11.png", "page": 10, "dpi": 300, "bbox": [61, 112, 415, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Using transition to mentally link between 3D to 2D.", "caption_bbox": [70, 312, 388, 325]}], "785": [{"image_id": 0, "file_name": "785_00.png", "page": 1, "dpi": 300, "bbox": [97, 366, 729, 606], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Two examples of our molecular interactions visualization. The left image shows the initial inspection of the secondary structures and the residues in the protein. By hovering on a secondary structure (top right) or residue (bottom right), we obtain the details. The right image shows the energy inspection mode, with the ligand shown in the center of the display. Here, the user can see both aggregate information, in the form of the maximum energies reached along the simulation path and inspect details about individual steps, such as the energy components (i. e. van der Waals, Coulomb Solvent, and Coulomb Vacuum) of the interaction energy (by hovering onto the energy bars) or the intra-molecular bond that is formed (in orange) at this step of the simulation. ", "caption_bbox": [63, 616, 762, 705]}, {"image_id": 1, "file_name": "785_01.png", "page": 5, "dpi": 300, "bbox": [66, 112, 415, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Hydrogen bonds visualization. The dynamically created bonds between the drug and the protein are shown using a line and a circle. The position of the circle (next to the ligand or to the backbone) encodes the acceptor, and the color of the linking encodes the type of bond, side chain (grey) or backbone (orange). ", "caption_bbox": [63, 403, 397, 477]}, {"image_id": 2, "file_name": "785_02.png", "page": 5, "dpi": 300, "bbox": [412, 112, 764, 397], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Inter-molecular hydrogen bonds. The transparency level encode the bonds persistence, and hovering over a bond (top-right) or a residue (bottom-right) reveals its details. ", "caption_bbox": [428, 407, 762, 450]}, {"image_id": 3, "file_name": "785_03.png", "page": 6, "dpi": 300, "bbox": [62, 112, 415, 414], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Root Mean Square Fluctuation (RMSF) encoding. This component shows the aggregated information of the RMSF along the path, overlaid to the molecule structure. This is, in turn, de- emphasized to avoid catching the user\u2019s attention. By hovering over a bar, the details are revealed (bottom right). ", "caption_bbox": [63, 424, 397, 498]}, {"image_id": 4, "file_name": "785_04.png", "page": 7, "dpi": 300, "bbox": [79, 112, 764, 517], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A global view of the application with most of the features toggled on. The left half shows the main view, where the user will spend most of her time analyzing a molecule. Centered below is the slider controlling the steps of the MS. During the visual inspection process, the secondary view (right) can be used for comparing different views of the same molecule, or different molecules, as explained below. The bottom part shows the energy chart, which can also be used to control the step under scrutiny by moving over the curve. ", "caption_bbox": [63, 533, 762, 592]}, {"image_id": 5, "file_name": "785_05.png", "page": 8, "dpi": 300, "bbox": [427, 470, 764, 647], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Capturing the protein-ligand recognition motif of the aspirin to the phospholipase protein through the analysis of in- tramolecular bonds. -The serine residue (selected) does not form a persistent bond that sometimes creates a secondary or a tertiary structure, but an h-bond with low persistence that may have formed to favor the binding. The RMSF around the Arg62, bound to it, indi- cates high fluctuation, suggesting the idea of an induced fit between the protein and the ligand in that region. ", "caption_bbox": [428, 657, 762, 777]}, {"image_id": 6, "file_name": "785_06.png", "page": 8, "dpi": 300, "bbox": [62, 112, 415, 473], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Analysis of a binding study of phospholipase with niflu- mic acid. The top image shows a stage of the simulation close to the binding position. It is simple to detect that just a few residues are involved in the binding process and with low energies (see the insets), which may indicate a loose binding. Scrolling through the simulation, one can see that the attractive energies come from dif- ferent residues along the path, thus not generating a strong binding. This can also be seen in the energy chart on the bottom, where the energy reduces, but not as much as in other cases analyzed. ", "caption_bbox": [63, 485, 397, 620]}, {"image_id": 7, "file_name": "785_07.png", "page": 8, "dpi": 300, "bbox": [412, 112, 754, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The RMSF view and the final energies view found by interacting with the RMSF and min-max energies. The left view shows that, by searching for mobile parts on the RMSF view, we found a double step h-bond that is formed due to the attractive force exerted by the Tyr64 amino acid. ", "caption_bbox": [428, 372, 762, 446]}, {"image_id": 8, "file_name": "785_08.png", "page": 10, "dpi": 300, "bbox": [79, 573, 382, 802], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: 3D view of a concrete frame viewed using a Qt window.", "caption_bbox": [63, 813, 397, 826]}, {"image_id": 9, "file_name": "785_09.png", "page": 10, "dpi": 300, "bbox": [61, 112, 742, 461], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparison of two different binding studies: binding of aspirin to Phospholipase A2 (left), and progesterone nuclear hormone receptor and progesterone (right). With a simple analysis, one can detect that in the first case, just a few residues are involved in the binding process, but one of them exhibits a very strong attractive energy. The progesterone nuclear hormone receptor behaves completely opposed to this, with many residues acting with levels of attraction close to their maximum, suggesting a good binding. ", "caption_bbox": [63, 478, 762, 537]}], "786": [{"image_id": 0, "file_name": "786_00.png", "page": 1, "dpi": 300, "bbox": [62, 413, 765, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: From an input molecule (left), we derive a surface proximity term (center, left) that represents the closeness of an atom to the molecule surface. We apply this method to a Molecular Dynamics simulation to obtain a color-coded map, representing the trajectory for each atom or residue (center). Single time-steps can be visualized in 3D (right), e.g., VdW-spheres or in a combined backbone-helix form. ", "caption_bbox": [63, 545, 762, 588]}, {"image_id": 1, "file_name": "786_01.png", "page": 2, "dpi": 300, "bbox": [412, 112, 740, 336], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Definitions of molecular surface. VdW-spheres (gray). Probe sphere (green). Extended hull (magenta). SAS (dashed hull). SES (purple). Internal atom (orange). ", "caption_bbox": [428, 348, 762, 391]}, {"image_id": 2, "file_name": "786_02.png", "page": 4, "dpi": 300, "bbox": [412, 112, 731, 194], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: User workflow and the application feature flow. The Presentation and Analysis steps form a repetitive process, where filtered data is visualized, motivating further analysis and filtering. ", "caption_bbox": [428, 205, 762, 248]}, {"image_id": 3, "file_name": "786_03.png", "page": 5, "dpi": 300, "bbox": [70, 112, 415, 367], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Link between RSP-map (top, showing one residue) and 3D-view (center). The highlighted residue (inverted colors) is part of the core until 39ns (center, left). It then emerges for a short pe- riod (center) before going back to the core after 48ns (center, right). Information per atom can also be obtained in a detail view (bot- tom). A tracker (top, red bar) selects a time-step from the RSP-map. ", "caption_bbox": [63, 378, 397, 467]}, {"image_id": 4, "file_name": "786_04.png", "page": 6, "dpi": 300, "bbox": [412, 112, 747, 190], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Neighbor configurations for two spheres.", "caption_bbox": [464, 198, 725, 211]}, {"image_id": 5, "file_name": "786_05.png", "page": 6, "dpi": 300, "bbox": [62, 112, 415, 510], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The raw RSP-map data (top) has been modified by a fil- ter expression (center) to highlight significant changes in the rep- resentation. The following expression was used: Quantize(Sum(- 100, 100, ResidueLayer(Frame + x), x) / 201, 0.5). This command smooths the residue layer in a window of 201 time-steps and rounds them to the next multiple of 0.5. Another filter has been applied (bottom) to display the smoothed layer difference of adjacent time steps. ", "caption_bbox": [63, 521, 397, 641]}, {"image_id": 6, "file_name": "786_06.png", "page": 6, "dpi": 300, "bbox": [478, 824, 715, 977], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Illustration of the intersection distance ei j in dependence of the cutting plane (x \u2212 oi j ) \u00b7 ni j = 0. ", "caption_bbox": [428, 988, 762, 1018]}, {"image_id": 7, "file_name": "786_07.png", "page": 7, "dpi": 300, "bbox": [60, 811, 389, 976], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Cutting face configurations. The striped area is cut from the gray sphere by the respective cutting face. ", "caption_bbox": [63, 988, 397, 1016]}, {"image_id": 8, "file_name": "786_08.png", "page": 7, "dpi": 300, "bbox": [412, 112, 764, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Determination of the variables h\u0302i,AB and m\u0302i,AB , where A (green) and B (orange) cut i (gray sphere). The orange cutting planes represent the minimal and maximal cutting distance for B. The dashed orange lines depict the center of the range. ", "caption_bbox": [428, 285, 762, 344]}, {"image_id": 9, "file_name": "786_09.png", "page": 7, "dpi": 300, "bbox": [446, 768, 747, 946], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Plot for a fixed intersection depth e\u0302iA = 0.5. The labels refer to the cutting face configurations in Fig. 8, where CbA , CbB cover the case Cb (A or B survives, respectively). The orange line depicts the possible values for e\u0302iB , if nA and nB are orthogonal. ", "caption_bbox": [428, 957, 762, 1016]}, {"image_id": 10, "file_name": "786_10.png", "page": 8, "dpi": 300, "bbox": [95, 828, 366, 977], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Determination of the intersection points p0,1 on sphere i in dependence of the intersection planes of spheres A (green) and B (orange). ", "caption_bbox": [63, 988, 397, 1031]}, {"image_id": 11, "file_name": "786_11.png", "page": 9, "dpi": 300, "bbox": [72, 112, 415, 225], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Screen-shot of our application with a PIIIA protein loaded. ", "caption_bbox": [428, 339, 762, 367]}, {"image_id": 12, "file_name": "786_12.png", "page": 9, "dpi": 300, "bbox": [64, 823, 398, 961], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: A filter expression can contain up to five different token types (top). The tokens are then evaluated and inserted into a tree structure (bottom). ", "caption_bbox": [63, 972, 397, 1015]}, {"image_id": 13, "file_name": "786_13.png", "page": 9, "dpi": 300, "bbox": [412, 112, 765, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Timings of our application to compute the RSP for 20k time-steps. Results are shown in seconds for a probe radius of 1.4\u00c5 and 2.8\u00c5. The maximum number of extracted atom layers was 3 and 5, respectively. ", "caption_bbox": [428, 872, 762, 931]}], "787": [{"image_id": 0, "file_name": "787_00.png", "page": 1, "dpi": 300, "bbox": [73, 364, 754, 534], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example of using our new diffuse illumination model for molecules. The system uses a regression analysis over a strategically sampled set of spatial configurations to create a set of equations that can be evaluated in real time to shade molecular models based on cylinders and spheres. The images illustrate the application of our illumination model to different representations of the same molecule. ", "caption_bbox": [63, 544, 762, 586]}, {"image_id": 1, "file_name": "787_01.png", "page": 4, "dpi": 300, "bbox": [412, 112, 681, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The diffuse interaction between two objects, A and B, is defined as the environmental light that reaches our point of interest from both, the environment and reflected at object B (grey rays). ", "caption_bbox": [428, 283, 762, 325]}, {"image_id": 2, "file_name": "787_02.png", "page": 6, "dpi": 300, "bbox": [412, 112, 698, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Parameterization of the cylinder-sphere spatial config- uration. We need up to 4 parameters to define the relative position of a sphere with respect to a cylinder. ", "caption_bbox": [428, 275, 762, 317]}, {"image_id": 3, "file_name": "787_03.png", "page": 6, "dpi": 300, "bbox": [62, 112, 415, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Cylinder-to-cylinder parameterization. The relative po- sition of a cylinder with respect to another can be determined by the use of 6 parameters. ", "caption_bbox": [63, 390, 397, 432]}, {"image_id": 4, "file_name": "787_04.png", "page": 6, "dpi": 300, "bbox": [75, 683, 399, 920], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Although during regression analysis we used a fixed ra- dius to define cylinders, our analytical solution to the diffuse inter- reflection can be scaled to approximate the diffuse interreflection between cylinders with other radius. In the left figure we scaled by 0.8 the result of our function to simulate a thiner Licorice model. ", "caption_bbox": [63, 937, 397, 1009]}, {"image_id": 5, "file_name": "787_05.png", "page": 7, "dpi": 300, "bbox": [465, 780, 757, 891], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: These images present the evaluation in real-time of the functions obtained by the regression analysis to simulate the dif- fuse interaction between spheres and cylinders. The objects are rendered without color, to illustrate the diffuse interactions they re- ceive. These are calculated assuming the vertical cylinder is blue, while the horizontal one and the sphere are white. ", "caption_bbox": [428, 923, 762, 1009]}, {"image_id": 6, "file_name": "787_06.png", "page": 7, "dpi": 300, "bbox": [104, 792, 358, 913], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: In order to compute the value of the radiance for our sampling points, we used a path-tracing algorithm. Each pixel on the left image presents the radiance reaching different points at the surface of a cylinder reflected by another cylinder. The right im- age, on the other hand, presents the radiance that reaches different points at the surface of a cylinder reflected by a sphere. ", "caption_bbox": [63, 923, 397, 1009]}, {"image_id": 7, "file_name": "787_07.png", "page": 7, "dpi": 300, "bbox": [120, 112, 415, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: We reparameterize our samples, describing the cylinders by their spherical coordinates with respect to our sampling points. By this reparameterization we are able to introduce more vari- ability in our values (for given cylinder, its spherical coordinates are different for each sample) and introduce information about the problem we want to solve into the regression analysis (our function is basically an integral over the hemisphere defined at each point). ", "caption_bbox": [63, 374, 397, 475]}, {"image_id": 8, "file_name": "787_08.png", "page": 7, "dpi": 300, "bbox": [412, 112, 764, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: As with the case of cylinder-cylinder interaction, we pa- rameterize the position of a sphere relative to a point using spher- ical coordinates. Using this parametrization we are able to obtain better approximations with the symbolic regression algorithm. ", "caption_bbox": [428, 283, 762, 340]}, {"image_id": 9, "file_name": "787_09.png", "page": 9, "dpi": 300, "bbox": [412, 112, 773, 356], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Parameter s f is used to modulate the diffuse inter- reflection. By increasing this parameter we are able to exaggerate the color bleeding effect. Top image was obtained using s f = 0.5 whilst the bottom image used a s f = 1.0. ", "caption_bbox": [428, 365, 762, 424]}, {"image_id": 10, "file_name": "787_10.png", "page": 9, "dpi": 300, "bbox": [71, 112, 415, 356], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: These images illustrate the effect of the parameter ko , used to approximate the occlusion generated by the nearby objects. The top image was obtained using ko = 0.75 whilst the bottom one was obtained by ko = 0.95. Note that, since ko divides fB\u2212                                                          \u2192A , lower values of this parameter generates higher occlusions. ", "caption_bbox": [62, 365, 396, 437]}, {"image_id": 11, "file_name": "787_11.png", "page": 10, "dpi": 300, "bbox": [412, 112, 756, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: We compared our illumination model (right images) with the results of a path-tracing algorithm (left images). Whilst the Balls-and-Sticks and Licorice models achieve very similar results, the Space-filling model generates less pronounced shadows, though still plausible. And the diffuse interactions appear in the same areas as with the path tracing algorithm. ", "caption_bbox": [428, 471, 762, 557]}, {"image_id": 12, "file_name": "787_12.png", "page": 10, "dpi": 300, "bbox": [62, 112, 415, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Although solvent excluded surfaces are not formed by spheres and/or cylinders, the representation is derived from the Space-filling model. Using the same illumination model to compute the reflected light by near structures as if our scene was composed only of spheres works well in these cases. ", "caption_bbox": [63, 384, 397, 456]}], "788": [{"image_id": 0, "file_name": "788_00.png", "page": 1, "dpi": 300, "bbox": [62, 717, 763, 892], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Thematic-Forest (1b) of untangled reply-chains from a full-conversation (1a) according to a content-focused query (left arcs) compared to a random-forest model trained on 13 features (right arcs). Model agreement and match to ground truth are shown using color. ", "caption_bbox": [62, 683, 762, 711]}, {"image_id": 1, "file_name": "788_01.png", "page": 2, "dpi": 300, "bbox": [412, 112, 758, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The architecture of ThreadReconstructor.", "caption_bbox": [465, 298, 724, 311]}, {"image_id": 2, "file_name": "788_02.png", "page": 6, "dpi": 300, "bbox": [62, 112, 760, 362], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Text-Level view showing all connections of a selected post, according to a content-focused query and a random forest model.", "caption_bbox": [74, 374, 749, 387]}, {"image_id": 3, "file_name": "788_03.png", "page": 8, "dpi": 300, "bbox": [62, 112, 755, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Close-up views on the Parent-Candidate View shown in Figure 5b, using one selected child-node as an example.", "caption_bbox": [106, 407, 718, 420]}, {"image_id": 4, "file_name": "788_04.png", "page": 11, "dpi": 300, "bbox": [63, 112, 764, 560], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Thematic-Forest View showing the three first connected-components from the untangled view of Figure 1b and their top features (in the top row). They are based on a discussion about the reasons and impact of climate-change and indicate the altered arguments of the debate, i.e. (a) the validity of the scientific work, (b) the impact of greenhouse gases, (c) the frustration with the deniers of climate-change. The second row shows the first three connected-components of an untangled discussion about immigration in the US and the political strategy of Donald Trump in comparison to Barack Obama, especially concerning boarder safety and the number of arrests of undocumented immigrants. ", "caption_bbox": [61, 573, 763, 647]}], "789": [{"image_id": 0, "file_name": "789_00.png", "page": 1, "dpi": 300, "bbox": [62, 832, 399, 949], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Improving model development life cycle. Track Xplorer enhances the comparative evaluation of multiple predictive models through contextual visual analysis. ", "caption_bbox": [62, 967, 396, 1009]}, {"image_id": 1, "file_name": "789_01.png", "page": 2, "dpi": 300, "bbox": [62, 112, 763, 527], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Track Xplorer interface. The main view shows a timeline for a set of stacked linear tracks. A track can represent the sequence of event predictions generated by a classifier (d, in blue) or the series of annotations used as ground-truth labels (f, in green). Tracks are associated to the predicted motor activity, to the name of the person who generated the results or labels and to the model version (in case of classifiers). This information is displayed at the left margin of each track (e), together with four buttons that enable performing track operations. A dedicated protocol track (c) can be used to easily navigate to regions of interest, while a synchronized video player (g) lets users validate the context of event predictions. Users can customize the appearance of tracks through a collapsible sidebar on the left (b). A command-line interface (a) lets users run commands from Track Xplorer\u2019s command set, which also supports the operations of a visual track algebra. ", "caption_bbox": [62, 538, 763, 638]}, {"image_id": 2, "file_name": "789_02.png", "page": 4, "dpi": 300, "bbox": [62, 112, 415, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: System design. Our analytics pipeline automatically loads models from the code repository and generates classification results for sensor data, storing the output in the database. Classification results and model metadata are then exported as a compressed (.BSX) file that Xplorer uses as input. Xplorer optionally supports direct access to the database through ssh tunneling (shown with blue arrows in the figure above), avoiding the need for sharing .BSX files. ", "caption_bbox": [62, 297, 396, 397]}, {"image_id": 3, "file_name": "789_03.png", "page": 4, "dpi": 300, "bbox": [412, 112, 764, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Track definition. A track in Xplorer corresponds to a list of non-overlapping time periods (\u201cevents\u201d). The two track types are based on the form of the data they represent: classifier tracks and label tracks. A classifier track contains probability scores associated to each event and can be visualized either as an area chart or as horizontal bars (\u201cblocks\u201d), whereas a label track contains only information about time intervals. A classifier track can be converted into a label track by applying a threshold on the classifier track\u2019s prediction scores. ", "caption_bbox": [426, 249, 763, 363]}, {"image_id": 4, "file_name": "789_04.png", "page": 4, "dpi": 300, "bbox": [62, 420, 398, 565], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Data compression. Prediction results adjacent to each other in time and meeting specific similarity criteria can be aggregated into a single longer prediction. For each classifier prediction pi , si denotes its confidence value, ai j its attribute values and \u2206t its time distance from the end of the previous prediction. Compression is performed if these values do not vary beyond certain thresholds \u03b5k from the first prediction. ", "caption_bbox": [62, 575, 396, 662]}, {"image_id": 5, "file_name": "789_05.png", "page": 5, "dpi": 300, "bbox": [412, 112, 764, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Validation of classifiers through track algebra. A represents a classifier track and B represents a label track containing ground-truth labels. By computing the intersection and subtraction of the two tracks, users can quickly identify correct and incorrect predictions. ", "caption_bbox": [427, 284, 763, 340]}, {"image_id": 6, "file_name": "789_06.png", "page": 5, "dpi": 300, "bbox": [61, 112, 415, 284], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Sample track configuration in Xplorer. It is obvious from the pattern of green and blue boxes (label and classifier tracks, respectively) that the subject is alternating between walking and turning movements. Visual alignment, video playback and variable inspection can be used in combination to better understand predicted motor events. ", "caption_bbox": [61, 294, 398, 365]}, {"image_id": 7, "file_name": "789_07.png", "page": 6, "dpi": 300, "bbox": [412, 112, 763, 642], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Performance metrics (top) and classifier information (bottom) modal windows. Xplorer features a modal window (top) to display different performance measures for a classifier track and includes an interactive ROC (Receiver Operating Characteristic) curve to help the user choose an adequate threshold for the selected model. The information modal (bottom) displays model metadata and summarizes commits and modifications performed on the code repository. ", "caption_bbox": [427, 658, 762, 758]}, {"image_id": 8, "file_name": "789_08.png", "page": 6, "dpi": 300, "bbox": [68, 548, 387, 687], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Common performance metrics computed through track algebra. A is a classifier track and B is a label track containing ground-truth labels. Accuracy, precision and recall scores can be visualized as a \u201ccontainer\u201d track with partial color fill. Mispredictions affecting a specific perfor- mance metric are localized in the non-filled (blank) regions of the track. ", "caption_bbox": [61, 701, 399, 772]}, {"image_id": 9, "file_name": "789_09.png", "page": 6, "dpi": 300, "bbox": [62, 112, 415, 446], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Commands of the Xplorer command line. P1 and P2 are the parameters required by each command. T is a placeholder for a generic track\u2019s identifier, whereas C and L indicate a classifier and a label track respectively. Track type conversion is handled automatically according to Fig. 5. ", "caption_bbox": [62, 451, 396, 522]}, {"image_id": 10, "file_name": "789_10.png", "page": 8, "dpi": 300, "bbox": [62, 385, 763, 684], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Sample screens from our use case: (a) combining track algebra and video playback to identify false positives; (b) using filtering to identify and remove tremor mispredictions; (c) removing regions of uncertainty from validation; (d) comparing classifier version and inspecting attributes; (e) handling inconsistent labeling with track algebra; (f) using smart ordering to identify tracks of interest. ", "caption_bbox": [61, 696, 763, 738]}, {"image_id": 11, "file_name": "789_11.png", "page": 8, "dpi": 300, "bbox": [62, 112, 759, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Advanced algebraic applications. Track algebra can also be applied among classifier tracks, e.g., to quantify their correlation (a) or to estimate their combined performance if they were executed together (b). Other relevant applications relate to obtaining a more legitimate performance estimate when dealing with missing labels (d), unclear motor events (f), or multiple sources of ground-truth information (e). The \u201c~\u201d operator is also introduced to emphasize event detection over precise temporal matching (c). ", "caption_bbox": [62, 307, 761, 363]}, {"image_id": 12, "file_name": "789_12.png", "page": 9, "dpi": 300, "bbox": [412, 112, 764, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Classifier versioning. Track Xplorer supports a hybrid versioning based on the combination of classic version control systems (e.g. git) and a standardized model definition. Track algebra can also be used to visualize differences between classifier versions. ", "caption_bbox": [426, 257, 761, 313]}, {"image_id": 13, "file_name": "789_13.png", "page": 10, "dpi": 300, "bbox": [412, 112, 753, 215], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: A probabilistic approach to ground truth information. Labels could be better modeled as a function over time to take into account the confidence on the event and the uncertainty in precisely identifying its start and end timepoints. ", "caption_bbox": [427, 234, 761, 290]}, {"image_id": 14, "file_name": "789_14.png", "page": 10, "dpi": 300, "bbox": [62, 112, 415, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Enhanced performance analysis through visual track algebra. Track Xplorer lets data scientists reason about the tradeoffs of each performance metric, helping them decide which ones to adopt. It also helps them gain insights for developing new, effective performance metrics tailored to the classification task at hand. ", "caption_bbox": [61, 368, 398, 439]}], "790": [{"image_id": 0, "file_name": "790_00.png", "page": 1, "dpi": 300, "bbox": [412, 337, 764, 788], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Eigenvector trajectories in a stress tensor field induced by applying a torque to a cylindrical shaft. Trajectories of both major (blue) and minor (red) eigenvectors show a swirling behavior around a common core line (yellow). ", "caption_bbox": [428, 814, 762, 873]}, {"image_id": 1, "file_name": "790_01.png", "page": 4, "dpi": 300, "bbox": [62, 112, 415, 269], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Example of seven distinct core lines in a random linear tensor field. ", "caption_bbox": [63, 284, 397, 312]}, {"image_id": 2, "file_name": "790_02.png", "page": 5, "dpi": 300, "bbox": [412, 112, 764, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The search space is parameterized on triangles \u2206x in position space and \u2206r on the hemisphere of possible eigenvector directions. The figure shows a pair of triangles after several subdivi- sion steps. ", "caption_bbox": [428, 277, 764, 336]}, {"image_id": 3, "file_name": "790_03.png", "page": 8, "dpi": 300, "bbox": [62, 782, 780, 946], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Tensor core lines in a crane arm with a load applied to the end. The resulting deformation on the left is scaled 1500 times. Significant tensor core lines are only found in the lower diagonal rods. The detail image on the right shows the tensors are indeed aligned around a common core. ", "caption_bbox": [63, 958, 762, 1001]}, {"image_id": 4, "file_name": "790_04.png", "page": 8, "dpi": 300, "bbox": [62, 555, 766, 714], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Tensor core lines in a truck bumper with a load applied to one end. The deformation shown on the left is scaled 500 times for illustrative purposes. The right shows detail views of two interesting lines. ", "caption_bbox": [63, 725, 762, 753]}, {"image_id": 5, "file_name": "790_05.png", "page": 8, "dpi": 300, "bbox": [62, 112, 764, 461], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Tensor core lines for two different deformations induced in a handle-like object by applying a displacement to an end surface. On the left side, we show the resulting deformations. The von Mises stress \u03c3vM is color-coded on the surface. We represent the tensor core line as tubes in the undeformed coordinate system. Their color indicates the numerical stability s. The tensor field is shown for context using elliptical glyphs. ", "caption_bbox": [63, 468, 762, 527]}, {"image_id": 6, "file_name": "790_06.png", "page": 9, "dpi": 300, "bbox": [432, 380, 759, 607], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Run times and number of found lines in the cylinder dataset for various different parameters. We show the total number of lines found ( ) and the number of lines remaining after filtering out numerically unstable lines ( ). ", "caption_bbox": [428, 614, 762, 673]}, {"image_id": 7, "file_name": "790_07.png", "page": 9, "dpi": 300, "bbox": [72, 112, 766, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A coil spring being compressed and slightly bent between two plates. We visualize the tensors near the core line with box glyphs in this case. They make it easier to see the hyperbolic behavior of the eigenvectors that occurs in the coil\u2019s cross-section. ", "caption_bbox": [63, 311, 762, 339]}, {"image_id": 8, "file_name": "790_08.png", "page": 10, "dpi": 300, "bbox": [62, 427, 399, 613], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Results of our algorithm on the Cylinder dataset for different choices of M. Increasing M results in more numerically unstable lines being found. If we filter them out, the result is virtually identical. ", "caption_bbox": [63, 350, 397, 409]}, {"image_id": 9, "file_name": "790_09.png", "page": 10, "dpi": 300, "bbox": [62, 618, 387, 808], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Comparison of unfiltered tensor core lines (red/yellow) and degenerate tensor lines (blue) for the Truck Bumper (top) and Crane dataset (bottom). The red box marks the coincidence of a numerically stable tensor core line with a degenerate tensor line. ", "caption_bbox": [62, 826, 397, 885]}], "791": [{"image_id": 0, "file_name": "791_00.png", "page": 2, "dpi": 300, "bbox": [62, 112, 735, 395], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Left: Eight different members of an ensemble dataset that represents different outcomes of CFD simulations of blood flow though an aneurysm with varying pressure parameters. Each member is visualized with several streamlines seeded at the flow inlet as well as parallel vector feature lines calculated from the derived acceleration field. Right: A spaghetti plot visualization of all parallel vectors lines is only of limited use for insight in the ensemble data. ", "caption_bbox": [62, 412, 761, 471]}, {"image_id": 1, "file_name": "791_01.png", "page": 4, "dpi": 300, "bbox": [62, 112, 415, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A location x is part of an APV line if the mean vector a is an eigenvector of the covariance matrix DDT . The filtered fAPV operator requires additionally that this is the eigenvector corresponding to the largest eigenvalue. ", "caption_bbox": [62, 252, 396, 311]}, {"image_id": 2, "file_name": "791_02.png", "page": 5, "dpi": 300, "bbox": [68, 112, 415, 243], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Streamlines and corresponding PV lines for three different members of an ensemble of random linear flows rotating around a vertical axis with varying locations, rotational direction and speed. ", "caption_bbox": [62, 258, 396, 301]}, {"image_id": 3, "file_name": "791_03.png", "page": 5, "dpi": 300, "bbox": [414, 112, 764, 269], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Scalar fields s that measure local alignment of ensemble members. (a) Accumulated norm of the cross product of all vectors at a given location (see (4)). (b) Accumulated angle of all vectors at a given location (see (3)). Both fields indicate that locations of high alignment of all vectors lie vertically in the center of the domain. ", "caption_bbox": [428, 285, 762, 359]}, {"image_id": 4, "file_name": "791_04.png", "page": 5, "dpi": 300, "bbox": [83, 318, 378, 510], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Several PV feature lines of the ensemble are shown in different shades of green. The blue PV line of the mean velocity and its acceleration appears at a significant offset, while the red APV line is centered within the members\u2019 PV lines and runs closely through the origin. The close-ups right display velocity and acceler- ation vectors of all members displayed at three distinct points on a member, on PV and on APV The alignment of vectors seems best for the APV sample. ", "caption_bbox": [62, 522, 399, 642]}, {"image_id": 5, "file_name": "791_05.png", "page": 6, "dpi": 300, "bbox": [427, 622, 763, 743], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) Spaghetti plot of all PV feature lines. (b) The APV operator finds locations where the PV feature lines are close to each other. (c) APV lines of all velocity and acceleration fields. ", "caption_bbox": [428, 758, 762, 802]}, {"image_id": 6, "file_name": "791_06.png", "page": 6, "dpi": 300, "bbox": [62, 112, 766, 484], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: APV lines for aneurysm ensemble: (a) using all eight velocity fields. (e) using all eight velocity fields and their acceleration fields. The closeups give examples for the color coding (right): (b) Locations with input vectors aligned closely with the major eigenvector are depicted in red color. (c) Is an example of a non-feature location. (d) Blue lines refer to locations with vectors aligned closely to one of the minor eigenvalues. They would be removed in filtered fAPV in Figure 7. ", "caption_bbox": [62, 515, 764, 574]}, {"image_id": 7, "file_name": "791_07.png", "page": 6, "dpi": 300, "bbox": [62, 600, 399, 743], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The APV operator finds structures of closed lines, which can be filtered: (a) APV lines w/o filtering. (b) Only lines with at least one fAPV segment. (c) Structures of fAPV line segments may be non-closed. ", "caption_bbox": [62, 758, 396, 817]}, {"image_id": 8, "file_name": "791_08.png", "page": 7, "dpi": 300, "bbox": [79, 112, 415, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Streamlines of the wind flow around a hovering helicopter for a fixed time step. Swirling behavior can be seen behind the helicopter. ", "caption_bbox": [62, 320, 396, 363]}, {"image_id": 9, "file_name": "791_09.png", "page": 8, "dpi": 300, "bbox": [62, 112, 744, 629], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Timings for the given ensemble data. The column APV refers to the computation of the derived fields, the mean a and b = DDT a. The PV column refers to the extraction of PV(a, b). ", "caption_bbox": [62, 835, 762, 866]}, {"image_id": 10, "file_name": "791_10.png", "page": 9, "dpi": 300, "bbox": [84, 399, 366, 532], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Streamlines for one time step of rotating mixer dataset.", "caption_bbox": [63, 550, 397, 563]}, {"image_id": 11, "file_name": "791_11.png", "page": 9, "dpi": 300, "bbox": [62, 112, 415, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: (a) A combined visualization of all core lines extracted with the PV operator from each ensemble member and its derived acceleration field. (b) Same with an additional overlay of APV feature lines for the same input data. ", "caption_bbox": [62, 304, 397, 363]}, {"image_id": 12, "file_name": "791_12.png", "page": 10, "dpi": 300, "bbox": [62, 112, 701, 550], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Flow inside a rotating mixer. Left: (a) PV core lines extracted from one member and the derived acceleration field. (b) Combined visualization of all PV core lines extracted from each ensemble member and derived acceleration fields. Center: APV features for the same data, unfiltered (c) and filtered (d). Right: APV features for velocity members only, unfiltered (e) and filtered (f). ", "caption_bbox": [62, 565, 761, 609]}], "792": [{"image_id": 0, "file_name": "792_00.png", "page": 1, "dpi": 300, "bbox": [62, 328, 764, 585], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: 3D projection of topological structures of a 4D vector field, with critical points depicted by 4D glyphs, their stable and unstable invariant manifolds (blue and red, respectively) by volumes in 4D, together with 4D streamlines for context. The 4D camera moves in 4D space along a selected streamline (striped red\u2013white), while maintaining a view which minimizes the amount of clutter in the 3D projection. ", "caption_bbox": [62, 596, 762, 640]}, {"image_id": 1, "file_name": "792_01.png", "page": 6, "dpi": 300, "bbox": [412, 112, 763, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: 4D clipping sphere for removal of projection-induced intersection in 3D space. (a) Projection along wc from 4D space into 3D image plane with camera coordinates xc , yc , and zc (Sec- tion 5). (b) Inside sphere (solid-line circle), same projection as in (a). Outside clipping sphere, projection along dashed curves. Both projections provide a single 3D image for interactive exploration. ", "caption_bbox": [428, 269, 762, 358]}, {"image_id": 2, "file_name": "792_02.png", "page": 9, "dpi": 300, "bbox": [67, 112, 764, 732], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Two linear vector fields with different saddle-type critical points, a 2:s2 saddle (a)\u2013(c) and a 3:1 saddle (d)\u2013(f). Each case is shown in a regular view (a), (d), as well as two degenerate views (b), (c), and (e), (f). While the manifolds of the 2:s2 saddle cause no occlusion in all views, the three-dimensional manifold of the 3:1 saddle causes the least occlusion in the degenerate view (e). ", "caption_bbox": [62, 735, 761, 779]}, {"image_id": 3, "file_name": "792_03.png", "page": 10, "dpi": 300, "bbox": [412, 112, 757, 809], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Line-type saddle connector between a 3:1 saddle and a 2:2 saddle. Same views as Figure 4, including distance field. ", "caption_bbox": [428, 812, 762, 841]}, {"image_id": 4, "file_name": "792_04.png", "page": 10, "dpi": 300, "bbox": [62, 112, 415, 809], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Surface-type saddle connector between a 3:1 saddle and a 1:3 saddle, without (left column) and with (right column) distance field (green) in regular (a), (b), and degenerate (c)\u2013(f) views. ", "caption_bbox": [62, 812, 396, 856]}, {"image_id": 5, "file_name": "792_05.png", "page": 11, "dpi": 300, "bbox": [66, 112, 764, 597], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Five Critical Points dataset, overview using glyphs (a), separatrices (b), and the distance field mapped to green (c). Initially, no clipping of the 1:3 saddle (box in (a)) is performed (d). Using a small clipping sphere (e), and aligning the view to the manifold (f) yields the least cluttered view. The saddle connectors in the dataset can be revealed using either a larger clipping sphere (g) or the distance field (h). ", "caption_bbox": [62, 599, 761, 643]}, {"image_id": 6, "file_name": "792_06.png", "page": 12, "dpi": 300, "bbox": [68, 427, 755, 653], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Random 4D Field dataset, with global structure shown using glyphs (a), and separatrices (b). The dataset is explored by aligning the view to a manifold (c) near a saddle point, providing a planar 3D projection, with further context projected in the background. Increasing the radius of the clipping sphere reveals more structures that are nearby (d). The last view with streamlines is shown in Figure 1. ", "caption_bbox": [62, 656, 761, 700]}, {"image_id": 7, "file_name": "792_07.png", "page": 12, "dpi": 300, "bbox": [62, 112, 757, 362], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Acceleration Field dataset with five point masses (yellow spheres, scaled proportionally to mass) distributed on the 2D space domain (a), overview of the phase space using glyphs (b), and separatrices (c). Using a small clipping sphere, and seeding two trajectories (seeds cyan, trajectories magenta) near a saddle point (box in (a)) shows separating property of the manifold in phase space (d). ", "caption_bbox": [62, 366, 761, 410]}], "793": [{"image_id": 0, "file_name": "793_00.png", "page": 1, "dpi": 300, "bbox": [63, 655, 765, 926], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Our coordinated visualizations of inertial particle motion give insights into size-dependent separation, clustering and attraction. The left image shows the individual particle trajectories of a continuous range of differently-sized particles in space-time, which can become cluttered. Thus, the second visualization displays the trajectory density, which reveals clustering regions and easier conveys an impression of the general motion. The trajectories of differently-sized particles are clearly separated in the third view. The motion of inertial particles is governed by a size-dependent attracting manifold. The last view focuses on a selection of trajectories and displays for each the distance to the attracting manifold by connecting the trajectories to the closest curve on the manifold. As shown here, heavy particles generally converge slower due to their momentum and inertia. Here, in the B ORROMEAN flow with d p = 100 \u00b5m (\u2022), d p = 200 \u00b5m (\u2022) and d p = 300 \u00b5m (\u2022). ", "caption_bbox": [63, 539, 765, 644]}, {"image_id": 1, "file_name": "793_01.png", "page": 3, "dpi": 300, "bbox": [67, 112, 413, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Convergence of an inertial particle with d p = 100 \u00b5m, and seed (x0 , v0 ) = (0, 1.2) toward the attracting manifold in the space- velocity plot. The underlying flow u(x) = 1 \u2212 3x2 + 2x3 is shown in black. Note the shallow extremum of the manifold at 0.054. ", "caption_bbox": [64, 287, 400, 346]}, {"image_id": 2, "file_name": "793_02.png", "page": 4, "dpi": 300, "bbox": [62, 112, 744, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Schematic illustrations of our three coordinated views. Each view maps one aspect of the inertial phase space into a 3D subspace.", "caption_bbox": [64, 276, 763, 289]}, {"image_id": 3, "file_name": "793_03.png", "page": 5, "dpi": 300, "bbox": [412, 112, 766, 296], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Space-response view of the B ORROMEAN data set. Left: continuous heterogeneous mixture of inertial particles. Right: d p = 100 \u00b5m (\u2022) and d p = 300 \u00b5m (\u2022). ", "caption_bbox": [429, 301, 765, 345]}, {"image_id": 4, "file_name": "793_04.png", "page": 5, "dpi": 300, "bbox": [63, 112, 413, 431], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The four components of the space-time view, here shown for the B ORROMEAN data set for two particle sizes d p = 100 \u00b5m (\u2022) and d p = 300 \u00b5m (\u2022), and a range of initial velocities. ", "caption_bbox": [64, 436, 399, 480]}, {"image_id": 5, "file_name": "793_05.png", "page": 6, "dpi": 300, "bbox": [413, 112, 764, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Two coordinated views on the B ENZENE data set. In the center of the domain (magenta box), a focus region is applied, while the remaining trajectories are shown semi-transparently as context. ", "caption_bbox": [429, 335, 763, 378]}, {"image_id": 6, "file_name": "793_06.png", "page": 6, "dpi": 300, "bbox": [62, 112, 415, 445], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Space-velocity view of B ORROMEAN data set for d p = 100 \u00b5m (\u2022) and d p = 300 \u00b5m (\u2022). First row, trajectories with their manifold. Second row, ribbons and density volume for both sizes. ", "caption_bbox": [63, 451, 397, 494]}, {"image_id": 7, "file_name": "793_07.png", "page": 6, "dpi": 300, "bbox": [107, 850, 353, 969], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Illustration of the velocity disc, which is used to select the range of initial velocities in polar coordinates. The magnitude range is given by [vmin , vmax ] and the angle range by [\u03b1min , \u03b1max ]. ", "caption_bbox": [64, 972, 398, 1016]}, {"image_id": 8, "file_name": "793_08.png", "page": 7, "dpi": 300, "bbox": [66, 112, 413, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Space-time views on the B ENZENE data set for d p = 100 \u00b5m (\u2022) and d p = 500 \u00b5m (\u2022). The isosurface slabs provide a better view on the inner nested surfaces. ", "caption_bbox": [63, 335, 397, 378]}, {"image_id": 9, "file_name": "793_09.png", "page": 7, "dpi": 300, "bbox": [428, 378, 766, 509], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Space-velocity view on the B ORROMEAN data set for zero initial velocity. A focus region is selected to point out the different flow behaviour in the vicinity of an attracting critical point. ", "caption_bbox": [429, 514, 763, 557]}, {"image_id": 10, "file_name": "793_10.png", "page": 7, "dpi": 300, "bbox": [412, 112, 766, 316], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Inertial particle trajectories for different gravity vectors in the space-time view of the B ORROMEAN data set. Adding gravity exerts a pull in a certain direction. In 10b, along the positive y-axis. ", "caption_bbox": [429, 318, 763, 361]}, {"image_id": 11, "file_name": "793_11.png", "page": 8, "dpi": 300, "bbox": [62, 112, 415, 480], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Study of swirling motion in the T REFOIL K NOT data set with differently-sized inertial particles and initial velocities. Here, for d p = 100 \u00b5m (\u2022), d p = 200 \u00b5m (\u2022) and d p = 300 \u00b5m (\u2022). ", "caption_bbox": [64, 486, 400, 530]}, {"image_id": 12, "file_name": "793_12.png", "page": 8, "dpi": 300, "bbox": [413, 112, 766, 444], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Coordinated views of the D OUBLE G YRE data set for dif- ferent initial velocities, here d p = 100 \u00b5m (\u2022) and d p = 500 \u00b5m (\u2022). ", "caption_bbox": [429, 450, 765, 479]}, {"image_id": 13, "file_name": "793_13.png", "page": 8, "dpi": 300, "bbox": [432, 490, 769, 699], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Trapping of inertial particles in the B OUSSINESQ flow. Here, for d p = 40 \u00b5m (\u2022) and d p = 300 \u00b5m (\u2022). ", "caption_bbox": [429, 705, 766, 734]}, {"image_id": 14, "file_name": "793_14.png", "page": 9, "dpi": 300, "bbox": [63, 112, 413, 545], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Inertial particles in the C YLINDER flow reveal the char- acteristic size-dependent preferential particle settling. Here with d p = 40 \u00b5m (\u2022) and d p = 300 \u00b5m (\u2022). ", "caption_bbox": [64, 549, 400, 593]}, {"image_id": 15, "file_name": "793_15.png", "page": 9, "dpi": 300, "bbox": [412, 112, 766, 237], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Close-up of the progressive computation of a density volume. The result converges quickly to the reference image. ", "caption_bbox": [429, 243, 763, 271]}], "794": [{"image_id": 0, "file_name": "794_00.png", "page": 2, "dpi": 300, "bbox": [412, 112, 763, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) Bivariate bagplot and (b) high density region (HDR) boxplot visualizations of El Nino dataset (12-dimensional temper- ature data for each year from 1951 to 2007) generated using the R Rainbow package [SHS16]. ", "caption_bbox": [428, 322, 762, 381]}, {"image_id": 1, "file_name": "794_01.png", "page": 5, "dpi": 300, "bbox": [77, 112, 773, 629], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Various stages during the proposed methods. a) Points from an anisotropic, 3D normal distribution projected on a 2D plane using MDS. Circle sizes indicate half space depth of points in the original 3D space. b) The initial interpolated field in the background of the MDS projection. c) The initial monotonic field in background obtained from initial interpolated field. d) Field overlay plot using order aware projection (OAP) after optimization is complete. The final monotonic field shown in the background. e) Projection bagplot visualization. Median is shown in yellow. Deep blue indicates 50 percent band and light blue indicates 100 percent band. ", "caption_bbox": [63, 637, 762, 711]}, {"image_id": 2, "file_name": "794_02.png", "page": 6, "dpi": 300, "bbox": [412, 112, 701, 321], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The typical profile for MDS stress and depth penalty dur- ing the optimization process. MDS stress increases slightly. The depth penalty undergoes sharp drops periodically at iterations with monotonic field updates. ", "caption_bbox": [428, 334, 762, 393]}, {"image_id": 3, "file_name": "794_03.png", "page": 7, "dpi": 300, "bbox": [127, 112, 764, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: MNIST data sample visualizations: (a) MDS, and (b) field overlay plot using order aware projection (OAP). Outliers and cliques appear more prominent in the field overlay plot. ", "caption_bbox": [63, 438, 762, 466]}, {"image_id": 4, "file_name": "794_04.png", "page": 7, "dpi": 300, "bbox": [78, 503, 394, 817], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: MNIST data sample visualization for multiple digits (0, 1, and 7) with field overlay plot using order aware projection (OAP). Monotonic fields corresponding to 0,1, and 7, are shown using heatmaps and isocontour lines drawn in green, blue, and red, respectively. Higher saturation of colors in the heatmaps indicate higher value of monotonic field. Unusual members are apparent on tracing outermost isocontours. ", "caption_bbox": [63, 830, 397, 934]}, {"image_id": 5, "file_name": "794_05.png", "page": 8, "dpi": 300, "bbox": [62, 112, 696, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Iris flower data visualization: (a) bivariate bagplot using MDS, and (b) projection bagplot using order aware projection (OAP). There are three species of flowers, each represented by a color, and each circle represents an individual flower. For the blue and green classes, 50 percent and 100 percent bands overlap due to a large proportion of members with identical, lowest value of depth. For the red class, only the projection bagplot conveys band associations of the flowers correctly. ", "caption_bbox": [63, 438, 762, 497]}, {"image_id": 6, "file_name": "794_06.png", "page": 9, "dpi": 300, "bbox": [147, 112, 764, 416], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Unidentified flying object (UFO) encounters data visualizations: (a) bivariate bagplot using MDS, and (b) projection bagplot using order aware projection (OAP). Each circle represents an encounter. Deep blue, light blue and red circle colors indicate association to the 50 percent band, 100 percent band, and outliers. The projection bagplot is able to show correct band associations for members while the bivariate bagplot misplaces some encounter instances with respect to bands. ", "caption_bbox": [63, 424, 762, 483]}, {"image_id": 7, "file_name": "794_07.png", "page": 10, "dpi": 300, "bbox": [70, 525, 406, 693], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Field overlay plots using order aware projection (OAP) for synthetically generated 3D multimodal data set with unknown class membership. Order statistics are computed using half space depth (a) for all points in data set together, and (b) for each cluster separately after a clustering step using k-means method. ", "caption_bbox": [63, 701, 397, 775]}, {"image_id": 8, "file_name": "794_08.png", "page": 10, "dpi": 300, "bbox": [62, 112, 672, 423], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Breast cancer data visualizations: (a) bivariate bagplot using MDS, and (b) projection bagplot using order aware projection (OAP). Each circle represents a set of patient attributes. The data contains two classes based on patient outcomes: recurrence (red) and nonrecurrence (blue). The recurrence class is seen to deviate from normal while the nonrecurrence class presents a more coherent distribution based on recorded attributes. ", "caption_bbox": [63, 431, 762, 490]}], "795": [{"image_id": 0, "file_name": "795_00.png", "page": 3, "dpi": 300, "bbox": [120, 112, 765, 351], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview of the proposed PixelSNE in comparison with the BH-SNE", "caption_bbox": [215, 362, 611, 375]}, {"image_id": 1, "file_name": "795_01.png", "page": 7, "dpi": 300, "bbox": [65, 112, 415, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Neighborhood precision (Eq. (16)) of PixelSNE-RP on the 10,000 samples of the MNIST dataset. The numbers in the paren- theses represent the standard deviation from ten repetitions. ", "caption_bbox": [428, 330, 762, 373]}, {"image_id": 2, "file_name": "795_02.png", "page": 7, "dpi": 300, "bbox": [63, 333, 402, 461], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: k-NN classification accuracy of PixelSNE-RP on the 10,000 samples of the MNIST dataset. The numbers in parenthe- ses represent the standard deviation from ten repetitions. ", "caption_bbox": [428, 570, 762, 613]}, {"image_id": 3, "file_name": "795_03.png", "page": 8, "dpi": 300, "bbox": [81, 318, 743, 540], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 4: Comparison of cost function values between BH-SNE and PixelSNE-RP. The numbers in parentheses represent the standard deviation from ten repetitions. ", "caption_bbox": [63, 719, 397, 762]}, {"image_id": 4, "file_name": "795_04.png", "page": 8, "dpi": 300, "bbox": [62, 112, 776, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: 2D embedding of the Yelp dataset. The numbers in parentheses indicate the computing time.", "caption_bbox": [157, 555, 668, 568]}, {"image_id": 5, "file_name": "795_05.png", "page": 9, "dpi": 300, "bbox": [114, 112, 764, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: 2D embedding of the NewsAgg dataset generated by PixelSNE-RP.", "caption_bbox": [219, 397, 605, 410]}], "796": [{"image_id": 0, "file_name": "796_00.png", "page": 5, "dpi": 300, "bbox": [412, 112, 764, 175], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The ten nearest neighbors of elephant. Distance on the axis encodes distances from the selected word in the embedding space. To get a sense of the density of the neighborhood compared to others in the embedding, hovering the gray padding shows a tool tip with the quartile in which the size of the neighborhood falls (<= Q2 means that the shown neighborhood is in the second quartile). ", "caption_bbox": [428, 187, 762, 276]}, {"image_id": 1, "file_name": "796_01.png", "page": 6, "dpi": 300, "bbox": [62, 112, 415, 178], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Comparing the differences in neighborhoods between uncle and aunt. The colors on the first axis encode positions in the second axis. We can see that there is no overlap between the neigh- borhoods, but that one nearest neighbor of uncle is closer than the others to aunt (it is selected and linked across the axes). Hovering it reveals that it is the word cousin (shown by the tooltip). ", "caption_bbox": [63, 189, 397, 278]}, {"image_id": 2, "file_name": "796_02.png", "page": 7, "dpi": 300, "bbox": [62, 112, 415, 205], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparing the offset between man and woman and that between brother and sister when added to aunt to the word uncle. The axis for uncle (red) is selected as the reference for the oth- ers. This reveals an interesting pattern. Both resulting vectors have uncle as their nearest neighbor (the two black circles). While the bottom structure seems to have a similar neighborhood to uncle (most of the words are male relatives, including brother, nephew, and grandfather), this is not true for the vector on top. The words are shown as tooltips when hovering them with the mouse, either individually, or, as shown for the bottom axis, for an entire axis. ", "caption_bbox": [62, 216, 396, 366]}, {"image_id": 3, "file_name": "796_03.png", "page": 7, "dpi": 300, "bbox": [412, 112, 764, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparing the reconstructed co-occurrences between a set of words. The rows of the matrix show selected words, the columns show the reconstructed co-occurrences (the set of recon- structed co-occurrences shown as columns in the matrix is selected based on their high variance between the selected words). Color encodes the reconstructed strength of co-occurrence. Words that denote family relations and nobility titles have higher reconstructed co-occurrence strengths with the first four terms. ", "caption_bbox": [428, 315, 762, 435]}, {"image_id": 4, "file_name": "796_04.png", "page": 8, "dpi": 300, "bbox": [412, 112, 760, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Words for animals projected along the axis food - pet on two different embeddings. Exploring this space provides insights into the influences of different corpora on the resulting embedding. The lens facilitates exploration by summarizing words underneath it. ", "caption_bbox": [428, 325, 762, 399]}, {"image_id": 5, "file_name": "796_05.png", "page": 8, "dpi": 300, "bbox": [62, 112, 415, 205], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparing the highest reconstructed co-occurrence dif- ferences between man and uncle across two different embeddings. Color encodes reconstructed co-occurrence strength. The fully filled matrix cells are those selected because of their high vari- ance between the words (lines) in the corresponding embedding. All others are included for comparison. Nobility titles are more pro- nounced for uncle, especially in the EBBO-TCP embedding. ", "caption_bbox": [63, 216, 397, 321]}, {"image_id": 6, "file_name": "796_06.png", "page": 9, "dpi": 300, "bbox": [412, 112, 764, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Nearest neighbors of the word broadcast in multiple word embeddings trained on corpora from different decades. The 1990s embedding is selected and the color on each axis encodes distance on the 1990s axis. Prior to 1930, words close to broadcast in the 1990s (red marks) are farther from it. The word stations is selected and linked across the axes. The color ramp is chosen for clarity in print. ", "caption_bbox": [428, 285, 762, 389]}, {"image_id": 7, "file_name": "796_07.png", "page": 10, "dpi": 300, "bbox": [429, 291, 758, 461], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Comparing family relations along the uncle - aunt axis in embedding 2 and 3. For the figure, two lenses are shown in the same plot. The lower one has links between words and their points activated. Surprisingly, there is no correlation between word posi- tions in both embeddings. ", "caption_bbox": [428, 473, 762, 547]}, {"image_id": 8, "file_name": "796_08.png", "page": 10, "dpi": 300, "bbox": [412, 112, 764, 190], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparing the neighborhoods of vec(aunt) \u2212 vec(sister) + vec(brother) across five embeddings trained with the same parameters and on the same corpus (wikipedia). One of the embeddings, embedding 3 (selected) shows a very different neigh- borhood than all others. ", "caption_bbox": [428, 201, 762, 276]}, {"image_id": 9, "file_name": "796_09.png", "page": 10, "dpi": 300, "bbox": [62, 112, 415, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparing reconstructed co-occurrences between em- bedding 2 and 3 trained on the wikipedia data set. Color encodes co-occurrence strength. The fully filled matrix cells are those se- lected because of their high variance between the words (lines) in the corresponding embedding. All others are included for compar- ison. Generally, aunt has very low and uniform co-occurrence val- ues in embedding 3, compared to embedding 2. ", "caption_bbox": [63, 224, 397, 328]}], "797": [{"image_id": 0, "file_name": "797_00.png", "page": 1, "dpi": 300, "bbox": [63, 636, 764, 872], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The proposed method decomposes carefully selected linear projections into a set of axis-aligned projections, which are easier to understand yet still retain the structure insight captured by the original linear projections. In the seawater temperature forecasting example shown above, the first axis-aligned projection captures the dominant periodic structure, while the second one highlights an additional loop that is different from one observed in the first projection. The relationship between linear projections and their axis-aligned decompositions is encoded as a bipartite graph (shown in (a)). Dynamic projection transitions are used to illustrate the structural correspondence between the linear and axis-aligned projections (shown in (b)). ", "caption_bbox": [63, 539, 762, 628]}, {"image_id": 1, "file_name": "797_01.png", "page": 3, "dpi": 300, "bbox": [476, 228, 713, 362], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of the linear projection decomposition algo- rithm. Given a linear subspace, we iteratively find a best matching axis-aligned one, remove its contribution from the linear projection and continue until no additional axis-aligned subspace can provide better structure preservation than the ones picked so far. ", "caption_bbox": [428, 369, 762, 443]}, {"image_id": 2, "file_name": "797_02.png", "page": 5, "dpi": 300, "bbox": [105, 266, 358, 536], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Formulating linear dimensionality reduction techniques using the unified graph embedding framework in [YXZ\u2217 07] ", "caption_bbox": [428, 773, 762, 801]}, {"image_id": 3, "file_name": "797_03.png", "page": 5, "dpi": 300, "bbox": [413, 112, 764, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Illustration of the linear projection searching algorithm. The proposed optimization is carried out on the Grassmannian (i.e., the space of all 2D linear subspaces). When selecting a new linear projection, we consider both the projection quality (i.e., how well the projection preserves high-dimensional neighborhoods), as well as diversity (i.e., is the projection sufficiently different from the ones we already selected). ", "caption_bbox": [428, 326, 762, 430]}, {"image_id": 4, "file_name": "797_04.png", "page": 7, "dpi": 300, "bbox": [76, 112, 764, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Projection Relationship View. As showed in (a)(b), the decomposition relationship is illustrated by a bipartite graph, the edges of the graph connect linear projections and their constituent axis-aligned projections from the proposed decomposition. The currently selected projection is highlighted with a red background. As illustrated in (c), for each projection, the histogram of per-point precision-recall quality measure is shown for illustrating how well a given projection preserves the neighborhood structure of the full dimensional data. ", "caption_bbox": [63, 269, 762, 328]}, {"image_id": 5, "file_name": "797_05.png", "page": 8, "dpi": 300, "bbox": [449, 462, 742, 698], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: UCI Wine dataset. The red, brown and green classes cor- respond to three types of wines. The axis-aligned projections illus- trate which dimensions can produce a class separation structure agree with the linear projections obtained with the LDE objective. ", "caption_bbox": [428, 703, 762, 762]}, {"image_id": 6, "file_name": "797_06.png", "page": 8, "dpi": 300, "bbox": [79, 419, 383, 517], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Animation projection transition from a linear projection to one of its constituent axis-aligned projections. As we can observe from the transition, the structure of the linear projection is well preserved in the axis-aligned one, which can be easily explained using the chosen variables. ", "caption_bbox": [63, 528, 397, 602]}, {"image_id": 7, "file_name": "797_07.png", "page": 9, "dpi": 300, "bbox": [78, 497, 381, 713], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Climate Simulation Run Crashes. The red points corre- spond to the simulation crashes, and the green ones correspond to successful runs. ", "caption_bbox": [63, 716, 397, 759]}, {"image_id": 8, "file_name": "797_08.png", "page": 10, "dpi": 300, "bbox": [443, 275, 746, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Comparison with scagnostics using the wine data. Scagnostics is designed to capture nine pre-determined patterns such as \"Monotonic\", \"Convex\", \"Clumpy\" shown here. By refer- ring back to the result from the proposed method (Figure 7), we can see both methods highlight the importance color intensify for achieving class separation in a 2D axis-aligned subspace. ", "caption_bbox": [428, 386, 762, 475]}, {"image_id": 9, "file_name": "797_09.png", "page": 10, "dpi": 300, "bbox": [82, 245, 376, 577], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: NIF Simulation Data. Our proposed approach reveals the presence of two true clusters in the attribute pv and a strong correlation between the attributes dsf and totrhorba, though the projection artifacts mask the neighborhood structure. ", "caption_bbox": [63, 576, 397, 635]}], "798": [{"image_id": 0, "file_name": "798_00.png", "page": 4, "dpi": 300, "bbox": [62, 112, 733, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An overview of how our algorithm functions. The goal is to compute the intersection of a slice with a polytope defined as a simplical mesh (a). The slice is defined by selecting a focus point and then extending it in two directions. We (b) treat each simplex in the mesh independently and compute the intersection of the simplex with the slice (see Algorithm 2). The collection of all intersections for a particular plane is shown as a line plot (c). This process is repeated over a number of randomly sampled focus points. ", "caption_bbox": [63, 306, 762, 365]}, {"image_id": 1, "file_name": "798_01.png", "page": 6, "dpi": 300, "bbox": [412, 112, 752, 509], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: We show the 16-cell, the 4-dimensional regular ortho- plex (4D version of an octahedron) as (a) a Schlegel diagram and (b) the Hypersliceplorer view. The Hypersliceplorer view shows the outside shape of the figure and the repeating structure. We can also see the repeating structure in the 3D (c) and 5D (d) views. ", "caption_bbox": [428, 523, 762, 597]}, {"image_id": 2, "file_name": "798_02.png", "page": 6, "dpi": 300, "bbox": [435, 614, 755, 737], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: 3-, 4-, and 5-dimensional hypercubes. We can see the regular structure in the cubes. The cross sections are all the same size since the cube is oriented to the axes. The cross lines in the plots are due to the simplical mesh. ", "caption_bbox": [428, 751, 762, 810]}, {"image_id": 3, "file_name": "798_03.png", "page": 6, "dpi": 300, "bbox": [435, 827, 754, 949], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: 3-, 4-, and 5-dimensional hyperspheres. We can see the concentric rings from slicing the sphere at different points. The ir- regularity of the slices is due to sampling. ", "caption_bbox": [428, 963, 762, 1006]}, {"image_id": 4, "file_name": "798_04.png", "page": 8, "dpi": 300, "bbox": [62, 112, 734, 367], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Examining differences in the space of general positive polynomials and Bernstein polynomials with positive Bernstein coefficients. In this example the x2 term is set to 1. We can see that across degrees of polynomials, the space differences in the a0 and a1 coefficients is relatively consistent. The single slice in c for the a3 , a4 plot is because the focus point sampling rarely hit a particular slice. The solution is to add additional focus point samples. ", "caption_bbox": [62, 381, 761, 440]}, {"image_id": 5, "file_name": "798_05.png", "page": 9, "dpi": 300, "bbox": [92, 572, 711, 891], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Hypersliceplorer views of spherical Pareto fronts in 3D (a) and 5D (b). The smoothest possible Pareto front is the positive orthant of a hypersphere. From the Hypersliceplorer view we can clearly see the concentric arcs. Each arc allows the user to compare the trade-offs between two objectives given that all other objectives are fixed. Changing from one arc to another means changing other objective settings. ", "caption_bbox": [63, 906, 762, 949]}, {"image_id": 6, "file_name": "798_06.png", "page": 9, "dpi": 300, "bbox": [92, 112, 764, 471], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The difference between possible coefficient values for general positive polynomials, a0 + a1 x + a2 x2 + a3 x3 + x4 , and polynomials that can be represented with positive Bernstein coefficients. From the global view (a) we can see that the area of the slices is quite large. This means that the difference between spaces is quite large, especially with respect to the higher-order coefficients. We can focus our view on a few particular slices in the local view (b) where we can see the orthogonal faces to the slice in the a2 \u00d7 a3 plot. ", "caption_bbox": [62, 482, 761, 544]}, {"image_id": 7, "file_name": "798_07.png", "page": 10, "dpi": 300, "bbox": [432, 577, 756, 794], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Chart showing the number of slicing operations (sim- plices \u00d7 number of plots) versus timing results from running our algorithm on a number of different datasets. The axes are on a log- log scale. The points are all clustered around the \u201c1 ms/simplex\u201d line showing that the running time is roughly one millisecond per slicing operation. ", "caption_bbox": [428, 810, 762, 899]}, {"image_id": 8, "file_name": "798_08.png", "page": 10, "dpi": 300, "bbox": [62, 112, 729, 470], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Visualization of the 3-objective (a) and 5-objective (b) DLTZ1 problems [DTLZ02] in Hypersliceplorer. The DLTZ1 Pareto front is a hyperplane that cuts diagonally across the objective dimensions. In the 3-objective case we can see the slices of the hyperplane. The NSGA-II [DPAM02] algorithm tends to push points towards one objective. This becomes much more pronounced in higher dimensions (b) where the Pareto front is squared off. ", "caption_bbox": [63, 484, 762, 543]}], "799": [{"image_id": 0, "file_name": "799_00.png", "page": 3, "dpi": 300, "bbox": [62, 859, 402, 984], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An overview of our solution in Sections 3, 4 & 5.", "caption_bbox": [82, 995, 378, 1008]}, {"image_id": 1, "file_name": "799_01.png", "page": 5, "dpi": 300, "bbox": [131, 112, 764, 398], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of our visualization design. (a) map view 1: bubble-based cluster map; (b) map view 2: boundary-based cluster map, and the multidimensional view with a cluster highlighted (properties in the selected cluster is compared to that of the entire state based on 7 user-selected measures (sold price, personal income, rent price, household income, distance to CBD, nearest hospital and nearest doctor. ", "caption_bbox": [63, 402, 762, 445]}, {"image_id": 2, "file_name": "799_02.png", "page": 5, "dpi": 300, "bbox": [102, 452, 721, 617], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A comparison of 4 geographical visualizations based on the real estate data in Melbourne. (a) Heatmaps and (b) binned plots, which imMens [LJH13], Nanocubes [LKS13] and Hashedcubes [PSSC17] support; (c) bubble-based cluster maps and (d) boundary-based cluster maps that our proposed ConcaveCubes supports. ", "caption_bbox": [63, 617, 762, 660]}, {"image_id": 3, "file_name": "799_03.png", "page": 6, "dpi": 300, "bbox": [62, 112, 693, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: A comparison between our proposed algorithm and 7 existing hull construction algorithms.", "caption_bbox": [161, 347, 665, 360]}, {"image_id": 4, "file_name": "799_04.png", "page": 7, "dpi": 300, "bbox": [62, 112, 415, 352], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Illustration of the proposed Concave hull algorithm. (a) the process of separating clusters after a global triangulation; (b- c), two examples of non-Jordan boundaries: how the boundary is formed and how we eliminate it. ", "caption_bbox": [63, 365, 397, 424]}, {"image_id": 5, "file_name": "799_05.png", "page": 8, "dpi": 300, "bbox": [412, 112, 751, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The procedure of constructing ConcaveCubes.", "caption_bbox": [453, 242, 738, 255]}, {"image_id": 6, "file_name": "799_06.png", "page": 8, "dpi": 300, "bbox": [67, 698, 392, 834], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An example of ConcaveCubes with the real estate data.", "caption_bbox": [65, 840, 394, 853]}, {"image_id": 7, "file_name": "799_07.png", "page": 10, "dpi": 300, "bbox": [64, 810, 397, 975], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Visualization of the Australian census data: Concave- Cubes is efficient to support cluster maps (a), which could be an approximate solution of the traditional cholepleth maps (b). ", "caption_bbox": [63, 987, 397, 1030]}, {"image_id": 8, "file_name": "799_08.png", "page": 10, "dpi": 300, "bbox": [442, 724, 748, 932], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Query latency per type of user interactions based on the real estate dataset. ", "caption_bbox": [428, 931, 762, 959]}, {"image_id": 9, "file_name": "799_09.png", "page": 10, "dpi": 300, "bbox": [65, 457, 397, 576], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visualization of the Brightkite dataset. (a) cluster maps (with a cluster selected) supported by our proposed Concave- Cubes: colour represents no. of check-ins; (b) heatmaps supported by Nanocubes, Hashedcubes, and imMens (screenshot is taken from the online demo of Nanocubes). ", "caption_bbox": [63, 587, 397, 661]}], "800": [{"image_id": 0, "file_name": "800_00.png", "page": 2, "dpi": 300, "bbox": [414, 112, 720, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example of a Dose-Volume Histogram (DVH). High relative RT doses (60%) affect a small amount of the bladder volume (5%) of Patient 1 (blue), in comparison to the other two patients. ", "caption_bbox": [426, 331, 761, 374]}, {"image_id": 1, "file_name": "800_01.png", "page": 4, "dpi": 300, "bbox": [62, 112, 653, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Schematical representation of our available cohort data and links to exploratory tasks (T1) and (T2) of the Bladder Runner.", "caption_bbox": [73, 430, 747, 443]}, {"image_id": 2, "file_name": "800_02.png", "page": 4, "dpi": 300, "bbox": [75, 454, 746, 732], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Steps conducted in our approach for the exploration and analysis of an individual patient through the treatment period (T1).", "caption_bbox": [72, 737, 749, 750]}, {"image_id": 3, "file_name": "800_03.png", "page": 5, "dpi": 300, "bbox": [221, 112, 764, 323], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Contingency matrix for the exploration of the bladder variation of patients (rows) through adaptation time (columns) (T1-a). The area of the bubbles indicates the bladder volume. The color assignment results from the Gaussian Mean Shift (GMS) clustering. ", "caption_bbox": [62, 326, 761, 354]}, {"image_id": 4, "file_name": "800_04.png", "page": 6, "dpi": 300, "bbox": [62, 112, 592, 336], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Coverage probability levels showing one patient with large bladder shape variation (T1-a), and one with small variation.", "caption_bbox": [79, 340, 741, 353]}, {"image_id": 5, "file_name": "800_05.png", "page": 7, "dpi": 300, "bbox": [64, 827, 394, 966], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Computation, and visualization for the exploration and analysis of the toxicity risk in an individual patient (T1-c). ", "caption_bbox": [62, 981, 396, 1009]}, {"image_id": 6, "file_name": "800_06.png", "page": 7, "dpi": 300, "bbox": [143, 112, 764, 420], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Matryoshka pyramids of the five coverage probability levels, depicted in two ways (unfolded and flattened) (T1-b).", "caption_bbox": [97, 431, 723, 444]}, {"image_id": 7, "file_name": "800_07.png", "page": 8, "dpi": 300, "bbox": [62, 112, 712, 691], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Evaluation participants.", "caption_bbox": [510, 890, 679, 903]}, {"image_id": 8, "file_name": "800_08.png", "page": 9, "dpi": 300, "bbox": [444, 754, 746, 970], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Inter-patient exploration and analysis of the bladder shape variation across the treatment period (T2-a), as performed in the usage scenario. ", "caption_bbox": [427, 983, 761, 1026]}, {"image_id": 9, "file_name": "800_09.png", "page": 9, "dpi": 300, "bbox": [440, 426, 744, 691], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Individual patient exploration and analysis of the im- pact of bladder shape variation on the dose distribution (T1-b), as performed in the usage scenario. ", "caption_bbox": [427, 696, 763, 739]}, {"image_id": 10, "file_name": "800_10.png", "page": 10, "dpi": 300, "bbox": [79, 592, 378, 980], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Evaluation results. We denote particularly the grading of Participant I, as he was involved in the design of our tool. ", "caption_bbox": [62, 981, 396, 1009]}], "801": [{"image_id": 0, "file_name": "801_00.png", "page": 1, "dpi": 300, "bbox": [62, 737, 764, 1074], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Patient with ascending aorta aneurysm. a) Our time-dependent visualization of the flow jet position (colored tube) and area of the 20 % highest velocities (magenta net) during peak systole. b) Combined visualization with vortex flow. ", "caption_bbox": [63, 707, 762, 736]}, {"image_id": 1, "file_name": "801_01.png", "page": 2, "dpi": 300, "bbox": [412, 112, 764, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: a) Flow jet to centerline angle (green). b\u2013d) Measuring plane, orthogonal to the aorta\u2019s centerline (gray), with sampled velocities (rainbow color scale). Flow displacement (b) as distance between the centerline position on the plane (red) and the velocity-weighted plane center (green). Small (c) and large (d) high-velocity area (blue contour). ", "caption_bbox": [428, 265, 762, 354]}, {"image_id": 2, "file_name": "801_02.png", "page": 3, "dpi": 300, "bbox": [62, 112, 764, 416], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Processing pipeline overview. The phase (flow) images are automatically corrected and then used for flow integration and vortex extraction. A temporal maximum intensity projection (TMIP) is performed on the magnitude images. This serves as anatomical context via direct volume rendering (DVR) and as basis for a 3D vessel segmentation. The subsequently extracted surface and centerline are employed in the measuring plane-based extraction of flow jet information. Time-dependent, geometric visualizations are established. Measuring planes facilitate flow jet quantification. A cross-sectional abstraction of flow jet characteristics is created as overview. ", "caption_bbox": [63, 426, 762, 500]}, {"image_id": 3, "file_name": "801_03.png", "page": 5, "dpi": 300, "bbox": [108, 112, 415, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: a) Schematic measuring plane grid with forward velocity vector magnitudes in a heat color scale. The blue vectors are the plane\u2019s local coordinate system, red is the rasterized vessel boundary. b) Mask (white) of the highest velocities. ", "caption_bbox": [63, 295, 397, 354]}, {"image_id": 4, "file_name": "801_04.png", "page": 5, "dpi": 300, "bbox": [412, 112, 764, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Flow jet of a patient with ascending aorta aneurysm during the end of systole without (a) and with (b) transparently fading out low velocities. The flow jet position tube is colored from green to yellow to red according to its displacement. ", "caption_bbox": [428, 282, 762, 341]}, {"image_id": 5, "file_name": "801_05.png", "page": 6, "dpi": 300, "bbox": [412, 112, 763, 276], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Flow jet area visualization without (a) and with (b) darkened back sides for improved recognition. ", "caption_bbox": [428, 282, 762, 310]}, {"image_id": 6, "file_name": "801_06.png", "page": 6, "dpi": 300, "bbox": [62, 112, 415, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: a) Principal component analysis (PCA) of the mask (recall Fig. 4) within the rasterized vessel boundary (red). a\u2013c) Original area ellipses (green) from the PCA and approximate area ellipses (magenta) with higher visual quality that are aligned with the plane\u2019s local coordinate system (blue vectors). ", "caption_bbox": [62, 293, 396, 367]}, {"image_id": 7, "file_name": "801_07.png", "page": 7, "dpi": 300, "bbox": [62, 112, 415, 471], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: 2D plot visualization of an aneurysm patient\u2019s flow jet characteristics for one measuring plane (bottom right). ", "caption_bbox": [63, 482, 397, 510]}, {"image_id": 8, "file_name": "801_08.png", "page": 8, "dpi": 300, "bbox": [62, 112, 746, 691], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: a) Non-pulsatile flow in a straight phantom. From left to right: High-velocity flow, our proposed flow jet visualization, combined view. b) Peak-systolic flow jet of a healthy volunteer. c) Patient with ascending aorta aneurysm and systolic vortex flow. The eccentric flow jet causes increased wall shear stress. d) Elderly healthy volunteer with vortex flow and peripheral flow jet in the ascending aorta vortex during systole. e) The flow jet bypasses the small vortex in this patient\u2019s aortic arch. f) Pulmonary artery of a healthy volunteer with each one flow jet for the branching left and right pulmonary artery. g\u2013j) Development of the flow jet over the cardiac cycle (T = 635 ms) in a BAV patient with an ascending aorta aneurysm. ", "caption_bbox": [63, 695, 762, 784]}, {"image_id": 9, "file_name": "801_09.png", "page": 9, "dpi": 300, "bbox": [62, 112, 415, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Comparison of a healthy volunteer (a) and patient with pathologically widened aorta (b). ", "caption_bbox": [63, 341, 397, 369]}], "802": [{"image_id": 0, "file_name": "802_00.png", "page": 4, "dpi": 300, "bbox": [63, 112, 764, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Workflow for our application starting with the medical image acquisition.", "caption_bbox": [199, 419, 622, 432]}, {"image_id": 1, "file_name": "802_01.png", "page": 5, "dpi": 300, "bbox": [412, 112, 764, 548], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Different rendering modes for the vessel surface in the pathline viewer; Disabled (A,B) and enabled (C,D) glass lighting, disabled (A,C) and enabled opaque backfaces. ", "caption_bbox": [428, 558, 762, 601]}, {"image_id": 2, "file_name": "802_02.png", "page": 5, "dpi": 300, "bbox": [429, 623, 763, 722], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparison of parameter visualization using a smooth (left) and discrete color scale with five shades (right). ", "caption_bbox": [428, 732, 762, 760]}, {"image_id": 3, "file_name": "802_03.png", "page": 6, "dpi": 300, "bbox": [63, 112, 415, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Wall shear stress visualized on the vessel surface using a color scale with 2 (left), 5 (middle) and 10 (right) discrete shades ranging from white to orange. ", "caption_bbox": [63, 300, 397, 343]}, {"image_id": 4, "file_name": "802_04.png", "page": 6, "dpi": 300, "bbox": [412, 112, 763, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison of a color scale mapped to the entire pa- rameter range (left) against only mapping the currently visible range of parameter values (right). ", "caption_bbox": [428, 277, 762, 320]}, {"image_id": 5, "file_name": "802_05.png", "page": 7, "dpi": 300, "bbox": [64, 112, 415, 450], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Workflow of selecting surface patches; surface visual- ization without any selection (top left), selection of one patch (red arrow), second selection using a different parameter (green ar- row); pathlines passing each of the selected patches highlighted with matching colors (bottom). ", "caption_bbox": [63, 461, 397, 535]}, {"image_id": 6, "file_name": "802_06.png", "page": 8, "dpi": 300, "bbox": [64, 421, 397, 962], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Scatterplot and parallel coordinates view showing three parameters of the same line bundle with synchronized selection. ", "caption_bbox": [63, 972, 397, 1000]}, {"image_id": 7, "file_name": "802_07.png", "page": 8, "dpi": 300, "bbox": [412, 112, 763, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Line chart comparing two pathline bundles with the global set of pathlines with respect to their speed and flow distance. ", "caption_bbox": [428, 347, 762, 375]}, {"image_id": 8, "file_name": "802_08.png", "page": 8, "dpi": 300, "bbox": [63, 112, 415, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visualization highlighting long-residing flow in an aneurysm by mapping residence time on line width, opacity and color (temperature scale) at the same time. ", "caption_bbox": [63, 355, 397, 398]}, {"image_id": 9, "file_name": "802_09.png", "page": 9, "dpi": 300, "bbox": [429, 371, 763, 655], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Using the line chart plotting average residence time over flow distance to differentiate multiple vortices from a com- plex flow structure; the line chart (bottom) clearly shows multiple structures being present in a flow bundle (A) and helps creating a selection that only contains one of the structures (B, green lines). ", "caption_bbox": [428, 665, 762, 739]}, {"image_id": 10, "file_name": "802_10.png", "page": 9, "dpi": 300, "bbox": [64, 112, 415, 459], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The six different combinations of filtering settings; vertex-based selection (A,D), line-based selection (B,E) and line- based selection with vertex highlights (C,F). Vertices / lines outside the selected parameter range are removed completely (A,B,C) or have their opacity reduced to 20% (D,E,F). Icons used to represent these option in the user interface (bottom). ", "caption_bbox": [63, 469, 397, 558]}, {"image_id": 11, "file_name": "802_11.png", "page": 9, "dpi": 300, "bbox": [412, 112, 764, 296], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Original surface patch used to select a pathline bundle (left); additional surface regions extracted using the same bundle, with wall shear stress mapped to the color scale (right). ", "caption_bbox": [428, 307, 762, 350]}, {"image_id": 12, "file_name": "802_12.png", "page": 11, "dpi": 300, "bbox": [64, 392, 397, 511], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Comparison of the same aneurysm acquired in 2011 (left) and 2014 (right); the residence time is mapped onto a tem- perature color scale. ", "caption_bbox": [63, 522, 397, 565]}, {"image_id": 13, "file_name": "802_13.png", "page": 11, "dpi": 300, "bbox": [62, 112, 764, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Flow selection performed by one of the neuroradiologists from three different perspectives; the right image has the flow velocity mapped onto the pathlines using a temperature color scale. ", "caption_bbox": [63, 328, 762, 356]}], "803": [{"image_id": 0, "file_name": "803_00.png", "page": 3, "dpi": 300, "bbox": [412, 112, 764, 398], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) A sample starting comparison with target value d = 0.2 on the left and d = 0.3 on the right. Participants were asked to choose which one has a higher graph density. (b) The staircase procedure converges to the JND by gradually making comparisons more difficult: d = 0.3 on the left and d = 0.28 on the right. ", "caption_bbox": [428, 410, 762, 484]}, {"image_id": 1, "file_name": "803_01.png", "page": 7, "dpi": 300, "bbox": [98, 112, 764, 395], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Regression results for graph density user studies. (a) The model fit for the averaged individual JNDs. (b) The model fit for individual points after the Box-Cox transformation where the colored area indicates the 95% confidence interval. ", "caption_bbox": [63, 409, 762, 437]}, {"image_id": 2, "file_name": "803_02.png", "page": 8, "dpi": 300, "bbox": [62, 112, 415, 503], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The left shows that residual distributions were skewed before the transformation and the right shows the distribution is more Normal after the transformation. ", "caption_bbox": [63, 517, 397, 560]}, {"image_id": 3, "file_name": "803_03.png", "page": 10, "dpi": 300, "bbox": [63, 112, 725, 395], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Regression results for the average local clustering coefficient user studies. (a) The model fit for the averaged individual JNDs (b) The model fit for individual points after the Box-Cox transformation where the colored area indicates the 95% confidence interval. ", "caption_bbox": [63, 409, 762, 437]}, {"image_id": 4, "file_name": "803_04.png", "page": 11, "dpi": 300, "bbox": [62, 112, 415, 385], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The left shows that residual distributions were skewed before the transformation and the right shows the distribution is more Normal after the transformation. ", "caption_bbox": [63, 399, 397, 442]}], "804": [{"image_id": 0, "file_name": "804_00.png", "page": 3, "dpi": 300, "bbox": [412, 112, 764, 596], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Data distributions characterized according to four data attributes: number of records per category and cardinality (on rows), and normalized entropies for Q1 and Q2 (on columns). Each subplot encodes Q1 , Q2 , and N on x, y, and color). ", "caption_bbox": [428, 605, 762, 664]}, {"image_id": 1, "file_name": "804_01.png", "page": 4, "dpi": 300, "bbox": [41, 112, 796, 434], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Attributes used to characterize trivariate data distribu- tions. All Conditions are stratified values of each attribute with representatives, quantiles, and specified intervals. For feasibility, we limit the Experimental Conditions to a subset of 24 conditions. ", "caption_bbox": [63, 634, 397, 693]}, {"image_id": 2, "file_name": "804_02.png", "page": 5, "dpi": 300, "bbox": [412, 112, 764, 544], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: We compose four tasks as binary questions. The first two types ask subjects to read or compate individual values marked with arrow annotations. The last two aggregate tasks ask subjects to find maximum values and compare averages. ", "caption_bbox": [428, 551, 762, 610]}, {"image_id": 3, "file_name": "804_03.png", "page": 6, "dpi": 300, "bbox": [63, 112, 415, 538], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visual encoding effectiveness rankings. Higher is better; groupings indicate encodings of identical rank. The left side com- pares value tasks and summary tasks with a baseline ranking by APT [Mac86]. The right side compares performance for all tasks, averaged across data distribution conditions. Gray lines indicate sig. differences (p < 0.05) between groups in terms of error (E) or completion time (T). ", "caption_bbox": [63, 549, 397, 653]}, {"image_id": 4, "file_name": "804_04.png", "page": 6, "dpi": 300, "bbox": [412, 112, 760, 573], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Bootstrapped means and 95% confidence intervals for error rates and log completion times across tasks. For example, and     exhibit reasonable error rates but longer completion times. ", "caption_bbox": [428, 581, 762, 624]}, {"image_id": 5, "file_name": "804_05.png", "page": 8, "dpi": 300, "bbox": [46, 529, 784, 957], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Bootstrapped means and 95% confidence intervals for error rates and log completion times across data characteristics, again showing differing effects by task group. For example, as #/Category increases, the performance of and   degrades for value tasks, but not for summary tasks. ", "caption_bbox": [63, 956, 762, 999]}, {"image_id": 6, "file_name": "804_06.png", "page": 8, "dpi": 300, "bbox": [63, 112, 762, 469], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Encoding effectiveness rankings by data distribution conditions, subdivided by task groups. Data characteristics exhibit different effects for value tasks and summary tasks. For example, increasing cardinality degrades    and     for summary tasks, but not value tasks. ", "caption_bbox": [63, 473, 762, 501]}], "805": [{"image_id": 0, "file_name": "805_00.png", "page": 2, "dpi": 300, "bbox": [63, 112, 722, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A schematic of a generalized process for visual analytics with data summarization. A dataset (left) is reduced using data sum- marization techniques (center), comprised of four basic methods (aggregate, project, subsample, filter), and is presented visually to support judgments of high-level data characteristics (right). Both the summarization and visual presentation are factors that influence the efficacy of summary visualization to enable viewers to make high-level judgments. ", "caption_bbox": [63, 377, 762, 436]}, {"image_id": 1, "file_name": "805_01.png", "page": 6, "dpi": 300, "bbox": [89, 490, 372, 650], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The distribution of summary designs using each data summarization method across 104 coded visual summaries. ", "caption_bbox": [63, 661, 397, 689]}, {"image_id": 2, "file_name": "805_02.png", "page": 6, "dpi": 300, "bbox": [493, 495, 698, 636], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Most network summaries, such as Networks of Names [KLB14], combine aggregation and filtering to summarize data. The system aggregates different relations across pairs of en- tities and filters these patterns according to their frequencies to encode the relationships that best characterize the dataset. ", "caption_bbox": [428, 649, 762, 723]}, {"image_id": 3, "file_name": "805_03.png", "page": 7, "dpi": 300, "bbox": [111, 112, 415, 366], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Splatterplots [MG13] represent two-dimensional points by combining a kernel density estimation with filtering and subsam- pling of representative outlier points. Combining aggregation and filtering takes advantage of the trade-offs between these methods to support a broader variety of tasks. ", "caption_bbox": [63, 378, 397, 452]}, {"image_id": 4, "file_name": "805_04.png", "page": 7, "dpi": 300, "bbox": [412, 112, 764, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The distribution of summaries designed for each purpose over 64 fully-coded summaries. ", "caption_bbox": [428, 306, 762, 334]}, {"image_id": 5, "file_name": "805_05.png", "page": 8, "dpi": 300, "bbox": [123, 334, 335, 465], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: World Lines [WFR\u2217 10] aggregates spatial data across different simulation runs to allow viewers to directly search for the simulation with the best outcome. ", "caption_bbox": [62, 478, 396, 525]}, {"image_id": 6, "file_name": "805_06.png", "page": 8, "dpi": 300, "bbox": [412, 112, 702, 351], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Summaries act as roadmaps for exploration, starting at a high-level of abstraction and letting viewers drill down into data. Glyph SPLOMs [YWS\u2217 14] summarizes clustering patterns in com- ponent SPLOM scatterplots to help identify scatterplots to further explore. ", "caption_bbox": [428, 364, 762, 438]}, {"image_id": 7, "file_name": "805_07.png", "page": 8, "dpi": 300, "bbox": [63, 112, 415, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A visual summary in the system built by Chen, et al. [CYW\u2217 16] uses both aggregation and filtering in order to sup- port a wide range of high-level analysis tasks. ", "caption_bbox": [63, 272, 397, 315]}, {"image_id": 8, "file_name": "805_08.png", "page": 9, "dpi": 300, "bbox": [65, 112, 764, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The distribution of summary designs supporting different kinds of analysis tasks across 64 fully-coded summaries.", "caption_bbox": [102, 343, 723, 356]}], "806": [{"image_id": 0, "file_name": "806_00.png", "page": 1, "dpi": 300, "bbox": [62, 320, 763, 570], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Repertory grid technique applied to information visualization: A Construct elicitation by formulating bipolar terms to describe the visualizations. B Each visualization is assessed according to the formulated terms. C Qualitative and quantitative analysis methods provide insight into important factors for visualization design. ", "caption_bbox": [63, 581, 762, 624]}, {"image_id": 1, "file_name": "806_01.png", "page": 2, "dpi": 300, "bbox": [412, 112, 764, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Procedure of the repertory grid technique. From a set of elements, constructs are elicited and assessed on a scale. ", "caption_bbox": [428, 282, 762, 310]}, {"image_id": 2, "file_name": "806_02.png", "page": 5, "dpi": 300, "bbox": [97, 112, 764, 556], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visual interface for conducting a repertory grid interview.", "caption_bbox": [239, 571, 581, 584]}, {"image_id": 3, "file_name": "806_03.png", "page": 7, "dpi": 300, "bbox": [79, 112, 764, 455], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Example correlations and clustered matrix for one expert and one nonexpert.", "caption_bbox": [193, 469, 631, 482]}], "807": [{"image_id": 0, "file_name": "807_00.png", "page": 7, "dpi": 300, "bbox": [62, 112, 764, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Average performance of strategies in the first 50 iterations of the labeling process (MNIST data set). Most data-based user strategies perform particularly well in the very first iterations (Ideal Labels First, Centroids First, Dense Areas First). Most model-based user strategies perform below Random. Focusing on the distinction between density-based and outlier-based strategies, the density-based strategies perform particularly well, while outlier-based strategies perform poorly. The performance of AL strategies is rather low at start, but increases with more iterations. Boxplots at the bottom show the distribution of the iteration numbers when strategies produced at least one label for each class. The Ideal Labels First strategy visits all class labels remarkably early (all 10 labels in 11 iterations on average), thus, it uses the set of a-priori given ideal representatives as expected. Model-based strategies require more iterations to see each label at least one time. As a general rule, strategies with good accuracies also visited every class label earlier. We conclude that data-based strategies are better suited to tackle the bootstrap problem than the other strategies. At the beginning of the labeling process the class boundaries generated in model-based strategies seem to be less expressive (i.e. they may jump around chaotically) and thus it is more robust to go for data and structure. ", "caption_bbox": [63, 441, 762, 591]}, {"image_id": 1, "file_name": "807_01.png", "page": 9, "dpi": 300, "bbox": [62, 112, 764, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Average performance of strategies after the initialization with one labeled instance per class (MNIST data set). The ULoP still outperforms remaining strategies significantly. Three data-based user strategies (Centroid First, Dense Areas First, Ideal Labels First) perform considerably good at start. AL strategies start at a moderate level, but achieve particularly good performances in later phases. Using the aforementioned data-based user strategies and the AL strategies, we assess a break-even point in the performance at the 35th iteration. Class Intersection is at random level, remaining model-based strategies perform below Random. In general, data-based strategies with a focus on dense areas perform particularly well. ", "caption_bbox": [63, 348, 762, 437]}, {"image_id": 2, "file_name": "807_02.png", "page": 10, "dpi": 300, "bbox": [62, 112, 764, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Average performance of strategies after the initialization with one labeled instance per class (GENDER VOICE). ULoP shows the best performance by far. Dense Areas First, Ideal Labels First, and Equal Spread start strong, but get outperformed by AL strategies between the 10th and 20th iteration. Class Intersection Minimization is the best model-based strategy that almost competes with AL. The remaining model-based strategies perform below Random. Centroid First shows particularly weak performance, potentially suffering from outliers. ", "caption_bbox": [63, 324, 762, 383]}], "808": [{"image_id": 0, "file_name": "808_00.png", "page": 3, "dpi": 300, "bbox": [412, 112, 764, 465], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of our fast and accurate brushing technique: For sketching, the user clicks into the middle of the data subset to be selected and drags the pointer to the border of the subset; The CNN then sees the data distribution near the interaction as a 2D histogram. It delivers a degree-of-selection value per histogram bin, from which we can compute, which data subset is selected. ", "caption_bbox": [428, 480, 762, 569]}, {"image_id": 1, "file_name": "808_01.png", "page": 3, "dpi": 300, "bbox": [65, 112, 415, 336], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Illustration of our principal approach: To be fast, we use sketching as interaction; to estimate which data to actually brush, we use a CNN trained with data from two user studies. ", "caption_bbox": [63, 349, 397, 392]}, {"image_id": 2, "file_name": "808_02.png", "page": 4, "dpi": 300, "bbox": [63, 112, 726, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Computing the input to the CNN: A, a square area is specified by the interaction (red line segment); B, after rotating to the horizontal; C, histogram of the local data distribution (CNN input). ", "caption_bbox": [63, 397, 762, 425]}, {"image_id": 3, "file_name": "808_03.png", "page": 5, "dpi": 300, "bbox": [65, 112, 764, 296], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The proposed CNN model. C, M and F represent the convolutional layers, max-pooling layers, and fully connected layers, re- spectively. The purple arrows from the last layer illustrate the association between the final layer\u2019s outputs and histogram-aligned grid of degree-of-selection values. ", "caption_bbox": [63, 311, 762, 354]}, {"image_id": 4, "file_name": "808_04.png", "page": 5, "dpi": 300, "bbox": [63, 394, 398, 566], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualization of the weights of 8 selected neurons among 64 in the second fully connected layer of the CNN. ", "caption_bbox": [63, 581, 397, 609]}, {"image_id": 5, "file_name": "808_05.png", "page": 5, "dpi": 300, "bbox": [431, 393, 763, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Left: output of the CNN. Right: the points colored in green are the brushing result (inside the Marching Squares contour, surrounding the pink area). ", "caption_bbox": [428, 548, 762, 591]}, {"image_id": 6, "file_name": "808_06.png", "page": 6, "dpi": 300, "bbox": [412, 112, 720, 370], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Left: Two cases from the second user study, 10 interac- tions for a specific brushing target in each case. Right: 15 modeled interactions per case (semi-transparent) with the original user in- teraction shown as solid line. ", "caption_bbox": [428, 381, 762, 440]}, {"image_id": 7, "file_name": "808_07.png", "page": 6, "dpi": 300, "bbox": [63, 112, 415, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Left: binary select (yellow) vs. disregard (red) informa- tion from the user study. Right: the image-based reference output computed with an adapted nearest neighbor algorithm. ", "caption_bbox": [63, 284, 397, 327]}, {"image_id": 8, "file_name": "808_08.png", "page": 7, "dpi": 300, "bbox": [412, 112, 764, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Two typical examples of a good match between the user\u2019s goal and the CNN-based brushing technique. ", "caption_bbox": [428, 317, 762, 345]}, {"image_id": 9, "file_name": "808_09.png", "page": 8, "dpi": 300, "bbox": [63, 112, 726, 348], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Three (most extreme) cases of suboptimal matches between the user\u2019s goal and the new brushing technique.", "caption_bbox": [114, 360, 710, 373]}], "809": [{"image_id": 0, "file_name": "809_00.png", "page": 2, "dpi": 300, "bbox": [62, 112, 764, 428], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The SPLOM view 1 can be examined for interesting patterns (rectangular regions). The colours of records (points) simply indicate the class they belong to. A query pattern can be specified interactively by dragging a bounding rectangle 2 in a scatterplot of interest. The query pattern can further be adjusted using the floating toolbox 3 . Matching patterns in the SPLOM are highlighted by coloured overlays according to their similarity to the query pattern. Dark red ones are the most similar and yellow ones are least similar 4 . The patterns with the green overlay are patterns marked by the user as relevant 5 . ", "caption_bbox": [63, 441, 762, 494]}, {"image_id": 1, "file_name": "809_01.png", "page": 3, "dpi": 300, "bbox": [62, 136, 764, 307], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Finding similar local patterns in a SPLOM. First, the user selects a rectangular portion of a scatterplot to create the initial query 1 . Next, all identifiable patterns are extracted from the SPLOM using a sliding-window approach. Their feature vectors and purity scores are calculated, leading to a similarity score between each pattern and the query 2 . The most similar patterns are visualised in the SPLOM 3 . The user can then indicate which of the matching patterns are most relevant to their needs, thus refining the query 4 . ", "caption_bbox": [63, 321, 762, 374]}, {"image_id": 2, "file_name": "809_02.png", "page": 4, "dpi": 300, "bbox": [412, 112, 764, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A user-defined query pattern and one matching pattern.", "caption_bbox": [448, 355, 742, 367]}, {"image_id": 3, "file_name": "809_03.png", "page": 5, "dpi": 300, "bbox": [62, 136, 764, 428], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A snapshot of the application showing the Countries dataset from the World Bank [TWB18]. The scatterplot outlined in red in the SPLOM is selected and is shown enlarged in the scatterplot view to the left. The user has already specified a query pattern and chosen to visualise the patterns in aggregation mode using shape-based descriptor colour-coding. In aggregation mode, all patterns similar to the query are highlighted in the SPLOM. The greenish colour-coding indicates the strength of the similarity according to shape-based descriptors. ", "caption_bbox": [63, 442, 762, 495]}, {"image_id": 4, "file_name": "809_04.png", "page": 6, "dpi": 300, "bbox": [63, 112, 415, 232], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Possible user interactions with the scatterplot. (a) The user first draws an arbitrary shape around the points. (b) The bounding box appears around the records. (c) The user can translate the box. (d) By placing two fingers on the top side of the box, the user scales the box vertically. (e) By placing two fingers on the right side of the box, the user scales the box horizontally. ", "caption_bbox": [63, 247, 397, 328]}, {"image_id": 5, "file_name": "809_05.png", "page": 7, "dpi": 300, "bbox": [427, 359, 760, 482], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Three different techniques are used to highlight matching patterns in a scatterplot. In (a), all matching patterns are shown in aggregation. In (b), the best matching patterns are highlighted. In (c), the union of all matching patterns is highlighted. ", "caption_bbox": [428, 497, 762, 550]}, {"image_id": 6, "file_name": "809_06.png", "page": 7, "dpi": 300, "bbox": [62, 150, 398, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The coloured records (red, green, and blue) are chosen by the user in the query. In (a), the user chooses to filter only patterns having a high similarity of records with the query, while in (b) there is no restriction. ", "caption_bbox": [63, 331, 397, 370]}, {"image_id": 7, "file_name": "809_07.png", "page": 7, "dpi": 300, "bbox": [427, 150, 761, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) The user selects a query. Since both shape and model-based feature vectors are scale-invariant, all four patterns in scatterplots (b) and (c) are marked as similar. ", "caption_bbox": [428, 287, 762, 326]}, {"image_id": 8, "file_name": "809_08.png", "page": 8, "dpi": 300, "bbox": [62, 112, 761, 405], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The results of the query shown in Figure 8a. The first row shows the best matches in the initial search results, where the weight of both shape-based and model-based descriptors are the same. The second row shows the five best matches after the user chose the first and the last matches in the initial search result and the relevance feedback module has adjusted the search parameters accordingly. ", "caption_bbox": [62, 422, 761, 461]}, {"image_id": 9, "file_name": "809_09.png", "page": 9, "dpi": 300, "bbox": [429, 150, 764, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Since the result pattern looks very similar to the initial query, a possible relationship might be expected between the two horizontal scatter- plot dimensions. ", "caption_bbox": [428, 304, 762, 343]}, {"image_id": 10, "file_name": "809_10.png", "page": 9, "dpi": 300, "bbox": [62, 150, 399, 344], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Three local patterns are found, indicating similar behaviour of three countries in another scatterplot. ", "caption_bbox": [62, 359, 396, 385]}, {"image_id": 11, "file_name": "809_11.png", "page": 10, "dpi": 300, "bbox": [63, 112, 415, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: There is some similarity between the initial query on the left and the matching local pattern on the right. There is a local negative correlation between the two horizontal scatterplot dimensions. ", "caption_bbox": [63, 304, 397, 343]}], "810": [{"image_id": 0, "file_name": "810_00.png", "page": 3, "dpi": 300, "bbox": [102, 112, 764, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Pipeline of preprocessing steps to create a visualization of query expansion results: given a user query (here consisting of two terms), n expanded queries are generated from ConceptNet. Each of the n expanded queries, plus the original query, results in up to 10 document surrogates. From these document surrogates, k topics are extracted, and labeled by m key terms each, which serve as input for the visualization. In this example, we use n = 4, k = 3, and m = 5, and the List View for visualization. ", "caption_bbox": [63, 308, 762, 367]}, {"image_id": 1, "file_name": "810_01.png", "page": 5, "dpi": 300, "bbox": [72, 112, 415, 376], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Density-based Compact Euler Diagram showing results for n = 9 expanded queries of \u201crock art\u201d with 21 key terms (from k = 7 topics and m = 3 key terms per topic). The user is hover- ing the expanded query \u201crock art museum\u201d to reveal the key terms associated with the split query. Two of the query expansion sugges- tions are not revealed to the user because all their associated key terms are shared with other queries. ", "caption_bbox": [63, 388, 397, 492]}, {"image_id": 2, "file_name": "810_02.png", "page": 5, "dpi": 300, "bbox": [446, 465, 744, 626], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: List View showing results for n = 9 expanded queries of \u201crock art\u201d with k = 7 topics and m = 3 key terms per topic. The user is hovering the topic \u201croll punk bang\u201d to reveal the queries associated with it. ", "caption_bbox": [428, 638, 762, 697]}, {"image_id": 3, "file_name": "810_03.png", "page": 5, "dpi": 300, "bbox": [65, 744, 394, 910], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Parallel Tag Clouds showing results for n = 9 expanded queries of \u201crock art\u201d with 21 unique key terms (from k = 7 topics and m = 3 key terms per topic). The user is hovering the key term \u201croll\u201d to reveal the queries associated with it. ", "caption_bbox": [63, 924, 397, 983]}, {"image_id": 4, "file_name": "810_04.png", "page": 6, "dpi": 300, "bbox": [62, 112, 415, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Example sub-topics from TREC ambiguous web queries.", "caption_bbox": [429, 878, 758, 891]}, {"image_id": 5, "file_name": "810_05.png", "page": 7, "dpi": 300, "bbox": [437, 701, 753, 857], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Precision (a) and recall (b) per condition.", "caption_bbox": [462, 870, 725, 883]}, {"image_id": 6, "file_name": "810_06.png", "page": 8, "dpi": 300, "bbox": [87, 751, 376, 906], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: User preference ratings for solving the task using the four interfaces on a five-point Likert scale. ", "caption_bbox": [63, 921, 397, 949]}, {"image_id": 7, "file_name": "810_07.png", "page": 8, "dpi": 300, "bbox": [83, 340, 376, 496], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Query expansion suggestions for the sub-topic \u201cHow are premature ventricular contractions treated?\u201d. ", "caption_bbox": [428, 617, 762, 645]}, {"image_id": 8, "file_name": "810_08.png", "page": 9, "dpi": 300, "bbox": [412, 112, 764, 440], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: ComED showing image results for every top-level en- closure with k = 6 topics and m = 4 key terms per topic. ", "caption_bbox": [428, 460, 762, 489]}, {"image_id": 9, "file_name": "810_09.png", "page": 9, "dpi": 300, "bbox": [64, 112, 415, 232], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Selecting the best query expansion (\u201cpvc abs\u201d) for the sub-topic \u201cFind information about PVC pipes and fittings\u201d using the List View. ", "caption_bbox": [63, 243, 397, 286]}, {"image_id": 10, "file_name": "810_10.png", "page": 10, "dpi": 300, "bbox": [64, 616, 396, 706], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: List View showing results for an expansion of the query \u201clawyer\u201d. The associated key terms reveal that the synonymous term \u201cattorney\u201d is more common in the US, while \u201csolicitor\u201d is more common in the UK. Furthermore, it reveals a polysemy of the term \u201clawyer\u201d, which is also a name for a fish species. ", "caption_bbox": [63, 718, 397, 792]}], "811": [{"image_id": 0, "file_name": "811_00.png", "page": 1, "dpi": 300, "bbox": [119, 414, 764, 639], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An analyst is using Constellations to investigate results generated by previous analysts. Constellations organizes these visual- izations with projection and clustering. Adjusting the data coverage, encoding choice, and keywords sliders changes how pairwise chart similarities are scored and updates the projected layout and cluster groupings. Several charts are tagged to show how their positions change. ", "caption_bbox": [63, 638, 762, 681]}, {"image_id": 1, "file_name": "811_01.png", "page": 4, "dpi": 300, "bbox": [412, 112, 763, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An overview of the Constellations system, showing the three primary modules and their associated features. Arrows de- note navigation or data transfer connections. ", "caption_bbox": [428, 357, 762, 400]}, {"image_id": 2, "file_name": "811_02.png", "page": 5, "dpi": 300, "bbox": [62, 112, 764, 445], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The Constellations interface. (A) The Collab View projects visualizations as circles. (B) Updating distance weights adjusts the projected layout. (C) The data coverage panel allows for review of prior dimensional exploration, intersection, and correlation. (D) The Chart View facilitates inspection of existing charts and the creation of new ones. (E) Adding new charts updates the projection in the Collab View. See the case study in Section 5 for an explanation of label tags and arrows. Figure 9 in the Appendix shows a larger version of this ", "caption_bbox": [62, 446, 761, 505]}, {"image_id": 3, "file_name": "811_03.png", "page": 7, "dpi": 300, "bbox": [412, 112, 764, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The user study flow. Participants were assigned either the Kernels or Constellations interface. For each stage, we note the data points collected for analysis. ", "caption_bbox": [428, 274, 762, 317]}, {"image_id": 4, "file_name": "811_04.png", "page": 8, "dpi": 300, "bbox": [412, 112, 763, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Plots of participant investigation patterns during the Freeform Stage. The x-axis represents time in minutes (10 minute limit). Numbers on the right indicate total counts of the actions. ", "caption_bbox": [428, 301, 762, 344]}, {"image_id": 5, "file_name": "811_05.png", "page": 8, "dpi": 300, "bbox": [62, 112, 415, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Completion time for tasks t1\u2013t3 in the Task Stage. Bars show mean completion time in seconds; error bars indicate 95% confidence intervals. For each task, Constellations is significantly faster than Kernels (p < 0.005). ", "caption_bbox": [63, 277, 397, 336]}, {"image_id": 6, "file_name": "811_06.png", "page": 9, "dpi": 300, "bbox": [63, 371, 752, 490], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The average number of insights discovered by a participant during the Freeform Stage. Error bars indicate 95% confidence intervals. Label asterisks indicate a statistical difference of p < 0.05 between Constellations and Kernels for that insight. ", "caption_bbox": [63, 490, 762, 519]}, {"image_id": 7, "file_name": "811_07.png", "page": 10, "dpi": 300, "bbox": [62, 112, 415, 583], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Participants\u2019 ratings about various system aspects dur- ing the Review Stage. Median ratings are indicated in gray. Aster- isks indicate a statistical difference of p < 0.05 between Constella- tions and Kernels for that system aspect. ", "caption_bbox": [62, 583, 396, 642]}], "812": [{"image_id": 0, "file_name": "812_00.png", "page": 3, "dpi": 300, "bbox": [79, 112, 764, 503], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The user interface of E-Comp. (A) Control panel allows users to filter the data and change other views. (B) Map view shows glyphs encoding the basic attributes of local businesses, where the selected businesses are marked with a blue rectangle. (C) Common customer comparison view shows the rating difference of common customers. (D) Temporal view visualizes the temporal trend of reviews and encodes the helpfulness of individual reviews through the rectangle or circle size. (E) Augmented word cloud view compares the adjective-noun word pairs with high frequency for one feature dimension in the review text. (F) Detailed review text view shows the details of the selected review (the dotted red rectangle) in Temporal View. (G) Business table lists the local businesses in the selected region. ", "caption_bbox": [63, 510, 762, 599]}, {"image_id": 1, "file_name": "812_01.png", "page": 4, "dpi": 300, "bbox": [414, 112, 740, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visual design for the glyph overlaid on the map. (a) A radar-diagram based glyph design, (b) a bar-chart based glyph de- sign, (c) a pie-chart based glyph design. ", "caption_bbox": [428, 245, 762, 288]}, {"image_id": 2, "file_name": "812_02.png", "page": 5, "dpi": 300, "bbox": [120, 112, 414, 208], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Color scheme for the rating. The diverging color scheme is finally chosen to emphasize both the higher and lower ratings. ", "caption_bbox": [63, 210, 397, 238]}, {"image_id": 3, "file_name": "812_03.png", "page": 5, "dpi": 300, "bbox": [412, 112, 764, 249], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Alternative designs for common customer comparison: (a) bipartite graph, (b) matrix, (c) traditional Sankey diagram. ", "caption_bbox": [428, 252, 762, 280]}, {"image_id": 4, "file_name": "812_04.png", "page": 7, "dpi": 300, "bbox": [412, 112, 764, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The map view showing the restaurants filtered by the user in the local region around Arizona State University. Restaurants A,B,C receive more reviews and share many common customers. ", "caption_bbox": [428, 264, 762, 307]}, {"image_id": 5, "file_name": "812_05.png", "page": 8, "dpi": 300, "bbox": [103, 363, 362, 686], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The temporal view shows the temporal trend of reviews. Top: Chuck Box, bottom: ChopShop. The stacked layout can be switched to a layered layout. The circles represent reviews by com- mon customers and the size of rectangle and circle encodes the helpfulness of reviews. ", "caption_bbox": [63, 689, 397, 763]}, {"image_id": 6, "file_name": "812_06.png", "page": 8, "dpi": 300, "bbox": [62, 112, 415, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The common customer comparison view shows the dif- ference of the ratings by the common customers of Chuck Box and ChopShop. The top and bottom grouped bars marked in red dot- ted rectangles represent the common customers who give a better rating to Chuck Box and ChopShop, respectively. ", "caption_bbox": [63, 273, 397, 347]}, {"image_id": 7, "file_name": "812_07.png", "page": 9, "dpi": 300, "bbox": [81, 381, 382, 557], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The results of the post-study. User responded to Ques- tions 1-8 on a 5-point Likert scale, where 1 to 5 represent the diffi- culty levels from \u201cvery easy\u201d to \u201cvery difficult\u201d. ", "caption_bbox": [63, 560, 397, 603]}, {"image_id": 8, "file_name": "812_08.png", "page": 9, "dpi": 300, "bbox": [77, 112, 414, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The augmented word cloud view shows the clustered adjective-noun word pairs of food feature. Left: Chuck Box, right: ChopShop. An example of negative expression (i.e., \u201cnot-good\u201d) is shown in the cluster highlighted in a red rounded rectangle. ", "caption_bbox": [63, 306, 397, 365]}], "813": [{"image_id": 0, "file_name": "813_00.png", "page": 5, "dpi": 300, "bbox": [92, 112, 764, 598], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview of ChangeCatcher consisting of Overview Bars, Visualization Panel, and Detail View. This example shows the differences between five consecutive versions of a Tableau workbook. The figure is annotated in yellow. ", "caption_bbox": [62, 611, 761, 639]}, {"image_id": 1, "file_name": "813_01.png", "page": 5, "dpi": 300, "bbox": [136, 649, 323, 722], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Tooltips show detail about the underlying changes.", "caption_bbox": [75, 735, 382, 748]}, {"image_id": 2, "file_name": "813_02.png", "page": 5, "dpi": 300, "bbox": [429, 649, 764, 719], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A textual tooltip describing that an attribute was renamed.", "caption_bbox": [427, 729, 763, 742]}, {"image_id": 3, "file_name": "813_03.png", "page": 6, "dpi": 300, "bbox": [427, 732, 748, 1007], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: ChangeCatcher showing the Detail View of V3-to-V4.", "caption_bbox": [427, 1009, 747, 1022]}, {"image_id": 4, "file_name": "813_04.png", "page": 6, "dpi": 300, "bbox": [427, 653, 748, 696], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Overview Bars of version changes with all details collapsed. ", "caption_bbox": [427, 697, 744, 725]}, {"image_id": 5, "file_name": "813_05.png", "page": 6, "dpi": 300, "bbox": [412, 112, 748, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A typical workbook without any changes shown.", "caption_bbox": [439, 308, 733, 321]}, {"image_id": 6, "file_name": "813_06.png", "page": 6, "dpi": 300, "bbox": [427, 327, 748, 602], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Worbook status after checking the \u201cShow Changes\u201d checkbox. It shows the Overview Bar and Detail View of V4-to- V5 as well as Overview Bars of changes in previous versions. ", "caption_bbox": [426, 604, 747, 647]}, {"image_id": 7, "file_name": "813_07.png", "page": 7, "dpi": 300, "bbox": [412, 112, 764, 198], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Overall usefulness of features in ChangeCatcher.", "caption_bbox": [445, 209, 744, 222]}], "814": [{"image_id": 0, "file_name": "814_00.png", "page": 2, "dpi": 300, "bbox": [65, 276, 393, 442], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Results of our in-core/accurate method (under VI) on Isabel-TC: (a) the Selection Table; (b) the curve of Total Informa- tion Difference. ", "caption_bbox": [62, 463, 396, 507]}, {"image_id": 1, "file_name": "814_01.png", "page": 3, "dpi": 300, "bbox": [412, 109, 764, 248], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Conditional entropy and variation of information (VI).", "caption_bbox": [432, 264, 757, 277]}, {"image_id": 2, "file_name": "814_02.png", "page": 4, "dpi": 300, "bbox": [61, 109, 415, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Information difference (InfoD) at time step r when time steps i and j are selected. ", "caption_bbox": [62, 258, 396, 286]}, {"image_id": 3, "file_name": "814_03.png", "page": 6, "dpi": 300, "bbox": [133, 574, 269, 679], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Approximation of information difference.", "caption_bbox": [101, 701, 359, 714]}, {"image_id": 4, "file_name": "814_04.png", "page": 8, "dpi": 300, "bbox": [61, 109, 415, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Results for large datasets (under VI). N: # grid points at each time step; T : # time steps in the dataset; t: # time steps kept in core; Runtime: total runtime in seconds; I/O: I/O time in seconds; DP: dynamic programming time in milliseconds; c\u0302-time: time to compute c\u0302() in seconds; Mem: memory footprint; Est-Err: estimated error (see Sec. 4.3). ", "caption_bbox": [62, 378, 396, 467]}, {"image_id": 5, "file_name": "814_05.png", "page": 8, "dpi": 300, "bbox": [412, 110, 744, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Results of our approximate method under VI (t = 12) on (a)(b) TeraShake and (c)(d) Radiation. ", "caption_bbox": [428, 407, 762, 436]}, {"image_id": 6, "file_name": "814_06.png", "page": 9, "dpi": 300, "bbox": [79, 775, 747, 930], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Selecting 10 time steps from TeraShake using Greedy under VI. The selected time steps {1, 57, 61, 63, 66, 68, 70, 74, 86, 227} are shown in row-first order. The selection quality is much worse than ours (Fig. 7) with much slower running time (see Fig. 15(b)). ", "caption_bbox": [62, 946, 761, 974]}, {"image_id": 7, "file_name": "814_07.png", "page": 9, "dpi": 300, "bbox": [79, 561, 747, 716], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Selecting 10 time steps from TeraShake using uniform sampling under VI. The selected time steps {1, 27, 53, 79, 105, 131, 157, 183, 209, 227} are shown in row-first order. The selection quality is much worse than ours in Fig. 7 (see Fig. 15(b)). ", "caption_bbox": [62, 732, 761, 760]}, {"image_id": 8, "file_name": "814_08.png", "page": 9, "dpi": 300, "bbox": [79, 109, 764, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Selecting 10 time steps from TeraShake using our approximate method under VI (t = 12). The selected time steps {1, 31, 48, 61, 73, 87, 102, 125, 140, 227} are shown in row-first order. ", "caption_bbox": [62, 303, 761, 332]}, {"image_id": 9, "file_name": "814_09.png", "page": 9, "dpi": 300, "bbox": [79, 347, 747, 502], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Selecting 10 time steps from TeraShake using DTW under VI. The selected time steps {13, 32, 45, 54, 65, 79, 92, 107, 138, 199} are shown in row-first order. The selection quality and ours (Fig. 7) are similar but DTW took much longer time (see Figs. 15(b), 16(b)). ", "caption_bbox": [62, 518, 761, 546]}, {"image_id": 10, "file_name": "814_10.png", "page": 10, "dpi": 300, "bbox": [65, 499, 395, 622], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: The NRMSE, estimated error (Est-Err) and runtime (under VI) for small datasets: (a) Isabel-TC; (b) Vortex. ", "caption_bbox": [62, 639, 396, 667]}, {"image_id": 11, "file_name": "814_11.png", "page": 10, "dpi": 300, "bbox": [446, 311, 745, 441], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: The curves of total InfoD of our accurate method, ap- proximate method (estimated total InfoD and actual total InfoD; t = 8, 10 for (a), (b)), and DTW: (a) Isabel-TC; (b) Vortex. ", "caption_bbox": [427, 457, 761, 501]}, {"image_id": 12, "file_name": "814_12.png", "page": 11, "dpi": 300, "bbox": [79, 109, 764, 352], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Selecting 10 time steps from Radiation using our approximate method under VI (t = 12). The selected time steps {1, 29, 58, 80, 102, 117, 135, 156, 180, 200} are shown in row-first order. ", "caption_bbox": [62, 367, 761, 396]}, {"image_id": 13, "file_name": "814_13.png", "page": 12, "dpi": 300, "bbox": [79, 731, 375, 846], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 4: Run-Time Results of our approximate method (t = 12) under InfoD for the largest datasets. T : # time steps in the datasets; Total: total runtime in hours (h); I/O: I/O time in minutes (m); DP: time for dynamic programming in seconds (s). All entries had the same memory footprint 1.91GB. ", "caption_bbox": [428, 885, 762, 960]}, {"image_id": 14, "file_name": "814_14.png", "page": 12, "dpi": 300, "bbox": [62, 276, 390, 534], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: The curves of actual total InfoD of our approximate method (t = 12) and DTW for (a) Radiation and (b) TeraShake, all under DTW\u2019s metric, which favors DTW. For DTW they are the same as those in Fig. 15(a)(b). ", "caption_bbox": [62, 863, 396, 922]}], "815": [{"image_id": 0, "file_name": "815_00.png", "page": 1, "dpi": 300, "bbox": [62, 669, 763, 905], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Using Noise Profiler to analyze OLAP queries over acoustic data from sensors deployed in New York City. A group-by hour is used as a baseline for ambient noise (smooth line), highlighting the difference between the noise profile of two locations during weekdays. One sensor (blue) is close to a main road (Broadway Av.) and has a constant dBA level throughout the hours of the day; the other sensor (orange) is close to a major construction site and has a distinctly higher dBA level during construction hours between 7 a.m. and 5 p.m. The live streaming data (fluctuating line) can be used to get instantaneous information about the noise level captured by the sensors, and inform city agency noise enforcement teams about possible noise code violations such as construction sites operating outside of their allotted construction hours. ", "caption_bbox": [62, 572, 761, 661]}, {"image_id": 1, "file_name": "815_01.png", "page": 4, "dpi": 300, "bbox": [62, 112, 651, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Data cube with D = {hour, dayweek , month} has a total of 2|D| cuboids, where each cuboid stores the aggregations for all possible values of its dimensions. ", "caption_bbox": [62, 305, 761, 336]}, {"image_id": 2, "file_name": "815_02.png", "page": 5, "dpi": 300, "bbox": [70, 112, 415, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Association functions. Here y(), m() returns the year and month respectively for a given time stamp, and weeksbetween() returns then number of weeks between two time stamps. ", "caption_bbox": [427, 249, 762, 292]}, {"image_id": 3, "file_name": "815_03.png", "page": 6, "dpi": 300, "bbox": [412, 112, 708, 279], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Drilldown performed (w.r.t. one of the months) when a query groups-by month over all Saturdays from 18:30 to 23:59. ", "caption_bbox": [427, 283, 761, 311]}, {"image_id": 4, "file_name": "815_04.png", "page": 7, "dpi": 300, "bbox": [412, 112, 764, 227], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Expanded materialization between the resolutions hour and day. Recall that the array corresponding to day is shared for the resolutions dayweek and daymonth . ", "caption_bbox": [427, 231, 761, 274]}, {"image_id": 5, "file_name": "815_05.png", "page": 7, "dpi": 300, "bbox": [116, 112, 415, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An additional histogram corresponding to a second time series is stored in the cuboids to support joins in queries. ", "caption_bbox": [62, 314, 396, 342]}, {"image_id": 6, "file_name": "815_06.png", "page": 8, "dpi": 300, "bbox": [412, 112, 740, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Query execution time for the four test queries as the size of the data increases. ", "caption_bbox": [427, 274, 761, 302]}, {"image_id": 7, "file_name": "815_07.png", "page": 8, "dpi": 300, "bbox": [62, 112, 415, 283], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Queries used in the experiments.", "caption_bbox": [124, 666, 335, 679]}, {"image_id": 8, "file_name": "815_08.png", "page": 9, "dpi": 300, "bbox": [81, 301, 374, 441], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Average time per update. Note that the update time remains consistent (\u2248 0.012 ms) even when adding new data to a Time Lattice built on a time series of size close to a billion points. ", "caption_bbox": [61, 442, 396, 485]}, {"image_id": 9, "file_name": "815_09.png", "page": 11, "dpi": 300, "bbox": [443, 505, 745, 680], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Comparing live data with two different ambient noise baselines for a given sensor. ", "caption_bbox": [427, 682, 761, 710]}, {"image_id": 10, "file_name": "815_10.png", "page": 11, "dpi": 300, "bbox": [152, 112, 764, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Comparing daily patterns of noise in back streets with noise in main streets.", "caption_bbox": [192, 294, 630, 307]}, {"image_id": 11, "file_name": "815_11.png", "page": 11, "dpi": 300, "bbox": [64, 318, 762, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: The two plots on the left show noise patterns on weekdays vs. weekends on diverse locations around Washington Square Park and Central Park. The two plots on the right show the weekly noise patterns for 4am and 8am. ", "caption_bbox": [61, 468, 761, 496]}], "816": [{"image_id": 0, "file_name": "816_00.png", "page": 3, "dpi": 300, "bbox": [241, 844, 390, 956], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A set of random 2D points along with a collection of triangles. The most central ob- servation is colored in red. ", "caption_bbox": [234, 955, 396, 1014]}, {"image_id": 1, "file_name": "816_01.png", "page": 4, "dpi": 300, "bbox": [240, 580, 379, 640], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Local windows around a chosen point in the domain, rep- resented by the arrow. ", "caption_bbox": [221, 644, 397, 687]}, {"image_id": 2, "file_name": "816_02.png", "page": 5, "dpi": 300, "bbox": [488, 581, 700, 683], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Synthetic ensemble consisting of two members that are contaminated with local but highly varying sinusoidal-type noise (right), two members that are elongated in different directions, and a perfect circle (left). Each image is of size 512 \u00d7 512. ", "caption_bbox": [428, 694, 762, 753]}, {"image_id": 3, "file_name": "816_03.png", "page": 7, "dpi": 300, "bbox": [66, 112, 771, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visualization of the ensemble presented in Figure 3. In comparison to PMC with the mean isocontour, the proposed technique is insensitive to the presence of outliers. The limited number of ensemble members also makes it hard and unreliable for the contour boxplot to pick a single ensemble member to be the global most representative member, whereas the proposed technique provides a fusion of the most prominent and stable features shared among the ensemble members to construct the representative consensus. ", "caption_bbox": [63, 344, 762, 403]}, {"image_id": 4, "file_name": "816_04.png", "page": 7, "dpi": 300, "bbox": [96, 424, 727, 713], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The localized depth values have been computed using r = 15 pixels for the ostrich and whale examples, respectively, and a constant global prior was used for the STAPLE algorithm. The regions of difference have been marked using white circles. Notice that compared to STAPLE, the proposed technique provides a more reliable and robust result for the flipper (where large irregularities or disagreements exist between the ensemble members) and tighter delineation around the tail area compared to the majority voting. The majority voting does not take any shape or spatial coherency information into account, and results in over-estimation of the segmentation in this area. ", "caption_bbox": [63, 721, 762, 795]}, {"image_id": 5, "file_name": "816_05.png", "page": 8, "dpi": 300, "bbox": [62, 112, 756, 555], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualization of the SREF temperature ensemble for negative perturbation of the NMB model. The consensus constructed using the proposed technique provides a balance between preserving representative local features while allowing smoothing in regions where the ensemble members highly disagree. This behavior is in contrast to the two extremes: the mean washes out local features significantly, whereas the contour boxplot, by definition, picks a single ensemble member globally to be the most representative, which is unreliable in the presence of limited-size ensemble. The enlarged region shows an example where the representative consensus (drawn in orange and denoted as IBD) is providing a balance between the two extremes. ", "caption_bbox": [63, 563, 762, 652]}, {"image_id": 6, "file_name": "816_06.png", "page": 9, "dpi": 300, "bbox": [71, 112, 415, 510], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The effect of changing the ensemble size and window size on R before denoising: The ensemble was generated using ran- dom draws from a Gaussian distribution (with mean value (1, 1) and standard deviation = 2) specifying the semimajor and semimi- nor axis of an ellipse as described in the synthetic example. Notice that as the ensemble size increases, the local order statistics be- come more reliable even without the denoising step. Notice that decreasing the window size can also result in noisier R because the analysis becomes less sensitive to (shape) features, and it be- comes harder to retain spatial coherency by ordering of the ensem- ble members locally. ", "caption_bbox": [63, 520, 397, 685]}], "817": [{"image_id": 0, "file_name": "817_00.png", "page": 3, "dpi": 300, "bbox": [111, 112, 764, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview over clustering pipeline and the corresponding paper sections (blue boxes). Yellow and blue parts mark optional steps for handling negative correlation and point count reduction. ", "caption_bbox": [63, 303, 762, 331]}, {"image_id": 1, "file_name": "817_01.png", "page": 4, "dpi": 300, "bbox": [412, 112, 731, 284], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The process of converting a dendrogram into a topolog- ical landscape (top) and the construction steps for individual node types (bottom). ", "caption_bbox": [428, 291, 762, 334]}, {"image_id": 2, "file_name": "817_02.png", "page": 6, "dpi": 300, "bbox": [62, 112, 763, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Agglomerative correlation clustering on a synthetic 2D point cloud. 5000 points were generated following a Gaussian mixture density distribution (a)(bottom), which is defined on the circle (a)(top). Different edge measures (b) lead to different cluster separation and noise stability. Note that in (A)-(E), the vertical axis represents a correlation or density measure while the plot width equals the number of points. As there is no single best measure for all data types, we give a basic recommendation for choosing an edge measure (c). ", "caption_bbox": [63, 271, 762, 330]}, {"image_id": 3, "file_name": "817_03.png", "page": 8, "dpi": 300, "bbox": [62, 112, 415, 210], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Process of handling negative correlation for an exem- plary set of scalar fields. By first inserting twin points with inverse behavior, positive correlation clustering yields correlated regions in both parts of the domain. A final merging step produces a consis- tent clustering that incorporates positive and negative correlation. ", "caption_bbox": [63, 218, 397, 292]}, {"image_id": 4, "file_name": "817_04.png", "page": 8, "dpi": 300, "bbox": [412, 112, 749, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Reduction of the clustering using the symmetry intro- duced by twin insertion. Only two rules (bottom) are required in order to modify the clustering (top) to only contain one represen- tative for every grid point. Yellow and purple nodes represent mir- rored neighborhood graph edges while red/blue coloring marks the ratio between original and twin points in a cluster. ", "caption_bbox": [428, 280, 762, 369]}, {"image_id": 5, "file_name": "817_05.png", "page": 9, "dpi": 300, "bbox": [412, 112, 766, 216], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Computation times with varying parameters. The method depends polynomially on point count (a), almost linearly on dimen- sion (b), and inverse exponentially on neighborhood graph com- plexity \u03b2. ", "caption_bbox": [428, 224, 762, 283]}, {"image_id": 6, "file_name": "817_06.png", "page": 9, "dpi": 300, "bbox": [67, 112, 415, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Different texture patterns used to highlight the type of correlation (left) and an exemplary topological landscape with polygonal texturing (right). Color marks different selected clusters and the user can freely specify contrast to either put focus on color or texture. ", "caption_bbox": [63, 246, 397, 320]}, {"image_id": 7, "file_name": "817_07.png", "page": 10, "dpi": 300, "bbox": [412, 112, 727, 448], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Hierarchical correlation clustering for temperature data. While the overview (a,b) shows global structure and cluster shapes, a closer investigation through selection and highlighting mechan- ics (c-f) unveils different correlation structures, such as prominent clusters, negative correlation, or independent regions. ", "caption_bbox": [428, 456, 762, 530]}, {"image_id": 8, "file_name": "817_08.png", "page": 10, "dpi": 300, "bbox": [63, 112, 415, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A set of synthetic scalar fields (top) and the resulting hierarchical clustering (bottom). The domain view (left) exactly re- sembles the modeled structures and the landscape (right) shows cluster nesting information. ", "caption_bbox": [63, 301, 397, 360]}, {"image_id": 9, "file_name": "817_09.png", "page": 11, "dpi": 300, "bbox": [72, 112, 415, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Hierarchical correlation clustering for the CORS data set (c) and the spatial context in the domain view (a,b). Close-ups on Alaska (a) and the contiguous US (b) reveal strong spatial de- pendencies, which can also be seen in the clustering landscape (c). ", "caption_bbox": [63, 293, 397, 352]}], "818": [{"image_id": 0, "file_name": "818_00.png", "page": 1, "dpi": 300, "bbox": [62, 645, 763, 839], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Iterative layouts of the TVCG collaboration graph (4,345 vertices and 11,732 edges) created using the random vertex sampling layout algorithm, which runs in O(|V | + |E|) time. This figure shows the initial vertex positions (a), and the layout after 20 (b), 100 (c), and 300 (d) iterations of the algorithm. This took about 7.0 seconds, whereas a Barnes-Hut based algorithm took about 17.7 seconds. ", "caption_bbox": [62, 593, 761, 636]}, {"image_id": 1, "file_name": "818_01.png", "page": 5, "dpi": 300, "bbox": [412, 101, 765, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Summary of the 109 evaluation graphs: The number of graphs in each class, and the vertex (|V |), edge (|E|), normalized components (C), and density (D) ranges rounded to two decimal places (i.e. 0.00 indicates a small value rounded to 0.00, and 0 in- dicates the value is exactly 0). The normalized component metric for a graph is calculated by subtracting 1 from the number of com- ponents and then dividing by |V | \u2212 1. ", "caption_bbox": [427, 505, 761, 610]}, {"image_id": 2, "file_name": "818_02.png", "page": 6, "dpi": 300, "bbox": [412, 101, 764, 709], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Each corresponding set of red, blue, and black dots rep- resent the runtimes of the RVS, RVS&BH, and BH layout algo- rithms on a given graph. ", "caption_bbox": [428, 735, 762, 778]}, {"image_id": 3, "file_name": "818_03.png", "page": 6, "dpi": 300, "bbox": [459, 803, 729, 956], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Runtime on large graphs. The x-axis is log scale.", "caption_bbox": [447, 967, 744, 980]}, {"image_id": 4, "file_name": "818_04.png", "page": 8, "dpi": 300, "bbox": [62, 244, 399, 546], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Box plot of each graph class on each readability metric (minimum, 1st quartile, median, 3rd quartile, maximum). ", "caption_bbox": [63, 561, 397, 589]}, {"image_id": 5, "file_name": "818_05.png", "page": 8, "dpi": 300, "bbox": [61, 101, 728, 173], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Bootstrap 99.6% confidence interval (CI) of the effect sizes of the graph readability metrics. CIs are percentile bootstrap with 10,000 samples. CIs that touch zero indicate no statistically significant difference. Circles indicate effect size (sample mean difference). For a row (e.g. RVS \u2212 BH) a positive effect size indicates that the first algorithm (e.g. RVS) performs better. Note the differences in x-axis scales. ", "caption_bbox": [63, 175, 762, 219]}, {"image_id": 6, "file_name": "818_06.png", "page": 9, "dpi": 300, "bbox": [169, 101, 765, 770], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparison of random vertex sampling (RVS), Barnes-Hut (BH), and RVS combined with BH (RVS&BH) graph layouts.", "caption_bbox": [85, 772, 741, 785]}, {"image_id": 7, "file_name": "818_07.png", "page": 10, "dpi": 300, "bbox": [61, 101, 415, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Stress (y axis) over time (x axis, seconds) of six graphs for the RVS, BH, and RVS&BH combination layout algorithms for 300 iterations. Averaged over 40 runs of each algorithm. ", "caption_bbox": [64, 270, 398, 313]}, {"image_id": 8, "file_name": "818_08.png", "page": 10, "dpi": 300, "bbox": [64, 856, 399, 946], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Visualization of the Les Miserables data set by compos- ing spring-electric forces with a gravitational force for each Vol- ume and rectangular constraints on x,y vertex coordinates. ", "caption_bbox": [64, 963, 398, 1006]}, {"image_id": 9, "file_name": "818_09.png", "page": 10, "dpi": 300, "bbox": [96, 337, 365, 486], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The dwt_1005 (a) and plat1919 (b) graphs using the RVS layout with alpha decay \u03b1d = 0 and no gravitational force. ", "caption_bbox": [64, 497, 398, 526]}, {"image_id": 10, "file_name": "818_10.png", "page": 13, "dpi": 300, "bbox": [147, 101, 765, 979], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Comparison of random vertex sampling (RVS), Barnes-Hut (BH), and RVS combined with BH (RVS&BH) graph layouts.", "caption_bbox": [91, 981, 753, 994]}], "819": [{"image_id": 0, "file_name": "819_00.png", "page": 2, "dpi": 300, "bbox": [61, 101, 643, 582], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Graphs A and B show the same process as graphs C and D, respectively. The layouts in A and B are computed by the industry standard [GKN15], where the actual process is poorly represented, while graphs C and D are computed by our novel graph layout algorithm where the process is easy to follow. Graphs B and D are obtained after removing the edge highlighted in red from A and C. As we can see, B differs significantly from A; especially note how nodes 1 and 2 swap vertically. Consequently, the mental map of the user is lost. On the other hand, C and D barely differ, preserving the mental map of the user. ", "caption_bbox": [62, 594, 761, 668]}, {"image_id": 1, "file_name": "819_01.png", "page": 4, "dpi": 300, "bbox": [61, 101, 415, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Our approach follows the Sugiyama framework.", "caption_bbox": [451, 276, 739, 289]}, {"image_id": 2, "file_name": "819_02.png", "page": 6, "dpi": 300, "bbox": [61, 101, 683, 448], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Connected blue elements, where dashed nodes and edges represent an arbitrary number of nodes and edges, represent sequences that still need to be added or are being added to RG. Beige rectangles and black arrows represent nodes and edges in RG. A) The different types of sequences we consider. B) An illustration of running Algorithm 2 with parameters: n, m, and 1 with before and after shown left and right, respectively. Edge (n, m) is the horizontal edge we are fixing. Note that node D is not moved down because edge (D, m) has a length that is longer than 1. C) A visual representation of how we create forward edges when processing sequence types Type III Node-Edge or Type IV Edge-Node. For Type III, we add the chain of nodes to the ranks above node m and for Type IV, we add the chain of nodes to the ranks below node n. D) and E) An illustration of how sequence Type VI Edge-Edge is handled for forward and backward sequences respectively when there are insufficient ranks between n and m. Using Algorithm 2, we obtain sequences of forward and back edges, respectively. ", "caption_bbox": [63, 460, 762, 580]}, {"image_id": 3, "file_name": "819_03.png", "page": 6, "dpi": 300, "bbox": [460, 616, 730, 753], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A horizontal edge (red) on a rank \u03c8i is fixed. Dashed nodes and edges represent an arbitrary set of nodes and edges on the adjacent ranks, and circles represent virtual nodes that are cre- ated. By moving node B down to a new rank \u03c80i , we obtain a forward edge. The original adjacent ranks to \u03c8i are are not modified. ", "caption_bbox": [428, 764, 762, 839]}, {"image_id": 4, "file_name": "819_04.png", "page": 8, "dpi": 300, "bbox": [61, 101, 727, 458], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Every \u03c8i represents a global rank. In A and B, squares and circles represent real and virtual sequence nodes, respectively. The numbers match the numbering in C and represent the order in which the node sequences are discovered by the global ranking algorithm. Sequence nodes with a red border belong to the backbone. A) The node sequence graph after sorting each rank based on backbone connect- edness. B) The final node sequence graph. C) Illustration of the order in which the node sequences (outlined in red) are discovered by the global ranking algorithm. The number next to a red outline indicates the order of discovery. Red squares represent virtual sequence nodes. ", "caption_bbox": [62, 471, 761, 545]}, {"image_id": 5, "file_name": "819_05.png", "page": 9, "dpi": 300, "bbox": [412, 101, 765, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A graph layout computed using R EL M INCROSS with \u03b5 = 0.001. Red and green numbers indicate the init(n) values for the sequence and non-sequence nodes respectively. Red squares represent virtual sequence nodes while green squares represent non-sequence virtual nodes. ", "caption_bbox": [428, 407, 762, 481]}, {"image_id": 6, "file_name": "819_06.png", "page": 10, "dpi": 300, "bbox": [434, 309, 757, 466], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The running time results for the BPI2018 dataset", "caption_bbox": [446, 499, 744, 512]}, {"image_id": 7, "file_name": "819_07.png", "page": 10, "dpi": 300, "bbox": [412, 101, 764, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The combined statistical test results.", "caption_bbox": [478, 268, 713, 281]}], "820": [{"image_id": 0, "file_name": "820_00.png", "page": 1, "dpi": 300, "bbox": [104, 386, 723, 532], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Left: example input of overlapping diamonds. Middle: output of the suggested linear program, having minimal displacement and maintaining the orthogonal order. Right: overlay visualizing the displacement of each diamond. ", "caption_bbox": [63, 542, 762, 570]}, {"image_id": 1, "file_name": "820_01.png", "page": 3, "dpi": 300, "bbox": [85, 101, 415, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Two example inputs. Left: Sparse, Uniform, Random, N = 200. Right: Dense, Weighted, Clustered, N = 400. ", "caption_bbox": [63, 272, 397, 301]}, {"image_id": 2, "file_name": "820_02.png", "page": 3, "dpi": 300, "bbox": [448, 720, 743, 853], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Feasible space (purple) for the placement of b with re- spect to a, for squares (left) and diamonds (right). The blue+purple region is dictated by the orthogonal order: b must start left of h for the horizontal order and below of v for the vertical order. In this quadrant, b must remain left of s1 or below s2 in the square case to avoid overlap (red+purple region), causing a nonconvex feasible space. For the diamond case, it must simply remain below separa- tor s. Note that these separators are at distance wa + wb from a, measured with L\u221e (square) and L1 (diamond). ", "caption_bbox": [428, 864, 762, 1001]}, {"image_id": 3, "file_name": "820_03.png", "page": 4, "dpi": 300, "bbox": [83, 796, 378, 929], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Consider the placement of just two overlapping symbols. Left: the closest point to a is the same for L2 (Euclidean distance) and L\u221e . Right: for L1 , all center positions on the thick black line have the same quality. ", "caption_bbox": [63, 940, 397, 999]}, {"image_id": 4, "file_name": "820_04.png", "page": 5, "dpi": 300, "bbox": [64, 571, 382, 913], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Efficacy of reducing the number of constraints via the dominance relations. Top: constraints remaining (black line) and the quadratic upper bound (red). Bottom: percentage of remain- ing constraints as a function of N, with breakdown per generation method. Note the cropped y-axis. ", "caption_bbox": [63, 925, 397, 999]}, {"image_id": 5, "file_name": "820_05.png", "page": 5, "dpi": 300, "bbox": [441, 249, 748, 943], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Running times in seconds for the 30 runs of the LP using constraint-reduction techniques, as a function of N, split between Dense and Sparse data sets. ", "caption_bbox": [428, 955, 762, 999]}, {"image_id": 6, "file_name": "820_06.png", "page": 6, "dpi": 300, "bbox": [440, 749, 764, 958], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Results showing the sum of Euclidean distances, as a ratio to the \u03c2 = 2 case, as a function of \u03c2. Each line is one input. ", "caption_bbox": [428, 970, 762, 999]}, {"image_id": 7, "file_name": "820_07.png", "page": 7, "dpi": 300, "bbox": [83, 796, 377, 929], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Left: orthogonal order requires b to be placed in the blue+purple region w.r.t. a; the disjointness constraint requires it to be placed in the purple+red area. Right: rotating the order con- straints, with \u03b1 = \u03c0/16. ", "caption_bbox": [62, 939, 396, 998]}, {"image_id": 8, "file_name": "820_08.png", "page": 8, "dpi": 300, "bbox": [61, 101, 413, 470], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Displacement as a function of \u03b1, for the two constraint programs. Vertical axis expresses the displacement at \u03b1 as a ratio of the displacement for \u03b1 = 0. Each line is an instance. ", "caption_bbox": [63, 483, 397, 527]}, {"image_id": 9, "file_name": "820_09.png", "page": 9, "dpi": 300, "bbox": [78, 601, 383, 943], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Stability measurements. Horizontally, \u03c3 varies from 0 to 0.99. Vertically, the two plots show the ratio of displacement (top) and stability (bottom) to the unstable case (\u03c3 = 0). ", "caption_bbox": [62, 955, 396, 999]}, {"image_id": 10, "file_name": "820_10.png", "page": 10, "dpi": 300, "bbox": [61, 101, 744, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Left: Iris data in barycentric coordinates, each of the attributes normalized to [0, 1]. Middle: minimal displacement for hexagonal symbols and order constraints, using a regular 6-gon as \u03b4. Right: minimal displacement with weak order constraints. ", "caption_bbox": [62, 320, 761, 349]}], "821": [{"image_id": 0, "file_name": "821_00.png", "page": 1, "dpi": 300, "bbox": [102, 402, 728, 726], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The visual exploration tool netflower supports journalists in investigating quantitative flows in dynamic network data for story- finding. The example above shows the media transparency dataset which tracks quarterly money flows between government institutions and media outlets. The main visualization is a Sankey diagram (a) showing the flows between legal entities and media institutions. Bar chart sparklines on both sides (b) give a temporal overview of outgoing (source nodes) and incoming money (target nodes). To load more data than visible at first glance, the \u201cshow more\u201d and \u201cshow less\u201d buttons (g) can be used. An on-demand bar chart (h) is provided to show the temporal evolution of one particular flow. Tags can be assigned to the nodes on both sides (i) and then filtered for. Below the header area (c), netflower provides functions for filtering, sorting and ordering (d, e). Moreover, a notebook is integrated into a sidebar (f) for investigative provenance. ", "caption_bbox": [63, 739, 762, 859]}, {"image_id": 1, "file_name": "821_01.png", "page": 3, "dpi": 300, "bbox": [67, 101, 765, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Timeline of netflower\u2019s development and validation phases from 2015 to end of 2018", "caption_bbox": [173, 275, 651, 288]}, {"image_id": 2, "file_name": "821_02.png", "page": 5, "dpi": 300, "bbox": [132, 485, 338, 564], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A node\u2019s area encodes the total weights of all ingoing or outgoing edges. The hatched area represents the portion of flows not currently displayed on the screen. ", "caption_bbox": [63, 574, 397, 617]}, {"image_id": 3, "file_name": "821_03.png", "page": 7, "dpi": 300, "bbox": [183, 101, 765, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: This figure presents a screenshot of one of the journalist diary studies showing the OECD aid development dataset [OEC18] in netflower. Our journalist participant investigated money flows originating from Austria to receiving countries (on the right of the visualiza- tion). The journalist opened the details of the flow Austria-Ukraine, thus learning that the money flow increased over time. The sparklines on the left and right show overall money flows to or from the respective countries over time and are not restricted to the current selection. ", "caption_bbox": [63, 326, 762, 385]}, {"image_id": 4, "file_name": "821_04.png", "page": 9, "dpi": 300, "bbox": [142, 101, 765, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: It takes many different steps to write a data-driven story and present the results to an audience. Starting out by finding a topic, then collecting the data sources, data cleaning (preparation) and analysis (exploration & story finding) as well as building, visualizing and publishing (presentation) the product [UK15]. The netflower prototype focuses on supporting journalists in the exploration and story-finding phase of their work. ", "caption_bbox": [63, 279, 762, 338]}], "822": [{"image_id": 0, "file_name": "822_00.png", "page": 1, "dpi": 300, "bbox": [61, 384, 764, 519], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An online interactive article How To: Tune A Guitar (left) and visualizations of collected reader activity data. HopScroll (center) visualizes reader progress over time, revealing reading patterns and fixation points. Readuction (right) uses dimensionality reduction of reader feature vectors to enable nuanced segment analysis; linked views show timing and event information for selected points. Along with these tools we present Idyll language extensions for automating the collection of detailed log data, and discuss reading patterns discovered. ", "caption_bbox": [62, 530, 761, 589]}, {"image_id": 1, "file_name": "822_01.png", "page": 2, "dpi": 300, "bbox": [61, 101, 415, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Beat Basics was produced by an undergraduate com- puter science student. She designed it to teach curious readers the basics of rhythmic time signatures in music. ", "caption_bbox": [63, 329, 397, 372]}, {"image_id": 2, "file_name": "822_02.png", "page": 3, "dpi": 300, "bbox": [412, 101, 765, 331], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The Beginner\u2019s Guide to Dimensionality Reduction uses artworks from the Metropolitan Museum of Art as examples for in- troducing dimensionality reduction techniques. ", "caption_bbox": [428, 332, 762, 375]}, {"image_id": 3, "file_name": "822_03.png", "page": 4, "dpi": 300, "bbox": [412, 101, 752, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Scroll positions over time for How To: Tune A Guitar. Plots highlight exemplary patterns: (A) Preview & Read, (B) Super Tuners, (C) Scroll & Bounce, and (D) Balanced Engagement. ", "caption_bbox": [428, 347, 762, 390]}, {"image_id": 4, "file_name": "822_04.png", "page": 6, "dpi": 300, "bbox": [412, 101, 747, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Example scroll paths from Beat Basics. (A) shows a reader who backtracks in the content several times; (B) a reader progresses linearly before scrolling down quickly to preview a sec- tion and subsequently spend time reading it; (C) shows a reader who read through the content forward and then in reverse. ", "caption_bbox": [429, 268, 763, 342]}, {"image_id": 5, "file_name": "822_05.png", "page": 6, "dpi": 300, "bbox": [61, 101, 415, 563], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: An annotated UMAP projection of Beat Basics reader sessions. We used the Readuction tool to identify cohorts of read- ers exhibiting similar behavior by observing the distributions of feature vectors for subsets of reader sessions. The feature vectors consist of counts of variable changes (a proxy for engagement with interactive widgets) and time spent on each section of content. ", "caption_bbox": [63, 568, 397, 657]}, {"image_id": 6, "file_name": "822_06.png", "page": 7, "dpi": 300, "bbox": [412, 101, 765, 225], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The distribution of minimum values of a range slider in The Beginner\u2019s Guide to Dimensionality Reduction. The slider started in the far right position. Many users did not engage with it; others moved it all the way to the left. ", "caption_bbox": [428, 224, 762, 283]}, {"image_id": 7, "file_name": "822_07.png", "page": 8, "dpi": 300, "bbox": [412, 101, 757, 614], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: UMAP projection of feature vectors for Beginner\u2019s Guide to Dimensionality Reduction readers. The projection reveals broad clusters of readers, such as those who consume all the content, those who leave the page quickly, those who engage heavily with article features, and those read the content multiple times. ", "caption_bbox": [428, 623, 762, 697]}, {"image_id": 8, "file_name": "822_08.png", "page": 8, "dpi": 300, "bbox": [61, 101, 415, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Example scroll paths from the Beginner\u2019s Guide to Di- mensionality Reduction. (A) shows a reader who skimmed the be- ginning of the article, but spent more time in the later sections; (B) shows a reader who quickly reached the end of the article, spent time there, and then went back to re-read earlier content. ", "caption_bbox": [63, 226, 397, 300]}, {"image_id": 9, "file_name": "822_09.png", "page": 9, "dpi": 300, "bbox": [412, 101, 765, 591], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: UMAP projection of feature vectors for readers of How To: Tune a Guitar. This article offered the most polished mobile experience of the three, and we see a less stark difference in the distributions between the desktop and mobile readers. Through in- teractive use of our Readuction tool we identify clusters of users who exhibit interesting engagement patterns. ", "caption_bbox": [428, 590, 762, 679]}], "823": [{"image_id": 0, "file_name": "823_00.png", "page": 1, "dpi": 300, "bbox": [433, 714, 761, 850], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An example story using a linked text and visualization technique. When readers click \u201cWorld War II\u201d, the corresponding circle will be highlighted to show the related information ", "caption_bbox": [428, 867, 762, 910]}, {"image_id": 1, "file_name": "823_01.png", "page": 4, "dpi": 300, "bbox": [61, 101, 415, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Three example questions. The first question is a Vis and Ext task, the second is a TextVis and Com task, the third is a Text and Com task. ", "caption_bbox": [428, 773, 762, 817]}, {"image_id": 2, "file_name": "823_02.png", "page": 4, "dpi": 300, "bbox": [412, 101, 746, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The study interfaces for slideshow with linking study condition. It shows that the explanatory visualization elements are highlighted when participants hovering over the first sentence in section \u201cSome Have Prospered\u201d. ", "caption_bbox": [428, 304, 762, 363]}, {"image_id": 3, "file_name": "823_03.png", "page": 5, "dpi": 300, "bbox": [66, 101, 415, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The \u201cpopulation move to US\u201d chart in the narrative visu- alization. It shows the arrival pattern of immigrants from the seven countries. ", "caption_bbox": [63, 266, 397, 309]}, {"image_id": 4, "file_name": "823_04.png", "page": 6, "dpi": 300, "bbox": [412, 101, 758, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The Comprehension IES for all participants across the different conditions in the study. Higher scores indicates lower performance and the error bars are 95% CIs. We found that the slideshow is more effective than the vertical layout at supporting comprehension. ", "caption_bbox": [428, 260, 762, 334]}, {"image_id": 5, "file_name": "823_05.png", "page": 7, "dpi": 300, "bbox": [432, 487, 759, 600], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Time spent results for linking and no-linking conditions. Error bars are 95% CIs. Results show participants spent more time on reading the story under linking conditions. ", "caption_bbox": [428, 622, 762, 665]}, {"image_id": 6, "file_name": "823_06.png", "page": 7, "dpi": 300, "bbox": [68, 341, 392, 453], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The Recall IES for all participants across the different conditions in the study. Higher scores indicates lower performance and the error bars are 95% CIs. We found that slideshow is more effective than vertical layout for recall tasks under linking condi- tions. ", "caption_bbox": [63, 469, 397, 543]}, {"image_id": 7, "file_name": "823_07.png", "page": 7, "dpi": 300, "bbox": [412, 101, 765, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: User-perceived engagement results for linking and no- linking conditions. Error bars are 95% CIs. Results show partici- pants in linking conditions had higher engagement. ", "caption_bbox": [428, 269, 762, 312]}, {"image_id": 8, "file_name": "823_08.png", "page": 8, "dpi": 300, "bbox": [61, 101, 415, 245], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: User-performed interaction results for linking and no- linking conditions. Error bars are 95% CIs. Results show partici- pants performed more interactions under linking conditions. ", "caption_bbox": [63, 266, 397, 309]}, {"image_id": 9, "file_name": "823_09.png", "page": 8, "dpi": 300, "bbox": [63, 782, 392, 927], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: User-performed transition results for various layout setting conditions. Error bars are 95% CIs. We found participants performed more Text-to-Vis transitions in the vertical layout. ", "caption_bbox": [63, 942, 397, 985]}], "824": [{"image_id": 0, "file_name": "824_00.png", "page": 1, "dpi": 300, "bbox": [412, 369, 764, 746], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization construction process using MVS and VbD.", "caption_bbox": [428, 758, 761, 771]}, {"image_id": 1, "file_name": "824_01.png", "page": 4, "dpi": 300, "bbox": [61, 101, 750, 400], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A screenshot of VisExemplar and Polestar.", "caption_bbox": [278, 417, 542, 430]}, {"image_id": 2, "file_name": "824_02.png", "page": 7, "dpi": 300, "bbox": [68, 234, 395, 452], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Average performance time of participants for each type of task using Polestar and VisExemplar. ", "caption_bbox": [62, 469, 396, 497]}, {"image_id": 3, "file_name": "824_03.png", "page": 7, "dpi": 300, "bbox": [69, 646, 394, 811], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Average performance time of participants for each phras- ing method using Polestar and VisExemplar. ", "caption_bbox": [62, 828, 398, 856]}, {"image_id": 4, "file_name": "824_04.png", "page": 9, "dpi": 300, "bbox": [412, 101, 765, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Combining MVS and VbD into a single interface opens interesting user interface opportunities that can leverage aspects of both paradigms. ", "caption_bbox": [427, 332, 761, 375]}], "825": [{"image_id": 0, "file_name": "825_00.png", "page": 1, "dpi": 300, "bbox": [62, 669, 764, 894], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The InsideInsights system: (a) a narration hierarchy allows gradually expanding and reviewing details. The annotation cells are linked to presentation views, either showing (b) selected visualizations, or (c) a part of the underlying analysis pipeline. Furthermore, (d) annotation cells can encapsulate multiple states for a linked component. ", "caption_bbox": [63, 618, 762, 661]}, {"image_id": 1, "file_name": "825_01.png", "page": 4, "dpi": 300, "bbox": [412, 101, 764, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Bridging narration and analysis: (a) the dynamic anno- tation hierarchy ties low-level insights to analysis states and links them to higher-order schemas; further, (b) the annotations can be linked to specific presentation views. ", "caption_bbox": [428, 284, 762, 343]}, {"image_id": 2, "file_name": "825_02.png", "page": 5, "dpi": 300, "bbox": [412, 101, 765, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The hierarchical presentation concept. Navigating the report entails not just visiting annotations on one level, but also ascending and descending the hierarchy. ", "caption_bbox": [428, 249, 762, 292]}, {"image_id": 3, "file_name": "825_03.png", "page": 6, "dpi": 300, "bbox": [412, 101, 747, 197], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Creating an annotation cell linked to a component state can be done simply using the pen icon on the specific component. Whenever the state of the component changes active (orange dots) and inactive (grey dots) annotations update accordingly. ", "caption_bbox": [428, 207, 762, 266]}, {"image_id": 4, "file_name": "825_04.png", "page": 6, "dpi": 300, "bbox": [427, 281, 765, 451], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Illustration of bottom-up (a) vs. top-down (b) analysis workflows as supported by InsideInsights. In (a) multiple annota- tions are summarized in a new parent, and in (b) a high-level goal is further specified with a new child. ", "caption_bbox": [428, 462, 762, 521]}, {"image_id": 5, "file_name": "825_05.png", "page": 7, "dpi": 300, "bbox": [64, 219, 397, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A presentation slide with two freely arranged views; an event flow visualization and a prediction accuracy view. The pre- sentation slide is linked to the bottom narration cell as indicated by the link icon next to the cell. ", "caption_bbox": [62, 442, 396, 501]}, {"image_id": 6, "file_name": "825_06.png", "page": 8, "dpi": 300, "bbox": [64, 750, 399, 960], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Crime peaks analysis document after John\u2019s initial anal- ysis session. ", "caption_bbox": [63, 970, 397, 998]}, {"image_id": 7, "file_name": "825_07.png", "page": 9, "dpi": 300, "bbox": [64, 101, 415, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Company event analysis document with an active model that is good for separating the bankrupt (dark) from the normal (light) event sequence flows [MG17]. ", "caption_bbox": [62, 317, 396, 360]}], "826": [{"image_id": 0, "file_name": "826_00.png", "page": 4, "dpi": 300, "bbox": [68, 266, 394, 355], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Force threshold setting: (a) initial calibration, users touch at specific positions; (b) slider-based adjustment. ", "caption_bbox": [63, 360, 397, 388]}, {"image_id": 1, "file_name": "826_01.png", "page": 4, "dpi": 300, "bbox": [61, 100, 764, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a): touch+pressure manipulation of 3D data. Interaction mapping: (b) one-finger motions and (c) two-finger motions.", "caption_bbox": [90, 228, 734, 241]}, {"image_id": 2, "file_name": "826_02.png", "page": 4, "dpi": 300, "bbox": [430, 266, 763, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Example of visual feedback for volumetric flow data: (a) no touch; (b) light mode; (c) hard mode; and (d) integrated RST mode. We map brighter colors to more force and only change the brightness, not hue, to avoid misperception. ", "caption_bbox": [428, 361, 763, 420]}, {"image_id": 3, "file_name": "826_03.png", "page": 6, "dpi": 300, "bbox": [428, 312, 764, 500], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Accuracy: (a),(c) Euclidean and (b),(d) angular distances, (a),(b) absolute values and (c),(d) pair-wise ratios. Error bars: 95% bootstrapped CIs. Colors as in Figure 4. ", "caption_bbox": [427, 503, 764, 546]}, {"image_id": 4, "file_name": "826_04.png", "page": 6, "dpi": 300, "bbox": [412, 101, 759, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Task completion time: (a) absolute values and (b) pair- wise ratios. Error bars: 95% bootstrapped CIs. ", "caption_bbox": [428, 266, 764, 294]}, {"image_id": 5, "file_name": "826_05.png", "page": 7, "dpi": 300, "bbox": [65, 290, 398, 362], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Fatigue measurement for (a) fingers, (b) hands, (c) arms, and (d) shoulders. Error bars: 95% bootstrapped CIs. ", "caption_bbox": [65, 367, 401, 395]}, {"image_id": 6, "file_name": "826_06.png", "page": 7, "dpi": 300, "bbox": [65, 101, 415, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Workload in TLX units (lower is better) for (a) physical, (b) mental, and (c) temporal demand, (d) performance, (e) effort, (f) frustration. Error bars: 95% bootstrapped CIs. ", "caption_bbox": [64, 231, 401, 274]}, {"image_id": 7, "file_name": "826_07.png", "page": 10, "dpi": 300, "bbox": [61, 101, 415, 320], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Pressure for different study conditions: (a) left and right hand; (b) holding the phone and put it on table; (c) different ar- eas, the red line is the threshold over all screen. Error bars: 95% bootstrapped CIs. ", "caption_bbox": [62, 337, 398, 396]}], "827": [{"image_id": 0, "file_name": "827_00.png", "page": 3, "dpi": 300, "bbox": [73, 101, 413, 232], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The high-level Segmentifier analysis model features an iterative view-refine-record loop to create segments. Analysis paths can conclude with an answer, end by abandoning the segment, or result in exporting the segment for further analysis. ", "caption_bbox": [62, 244, 396, 303]}, {"image_id": 1, "file_name": "827_01.png", "page": 6, "dpi": 300, "bbox": [61, 101, 764, 483], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The Segmentifier interface. The Operation Manager View (A) is responsible for the inspection and creation of operations used to refine segments. The Analysis Paths View (B) is a graphical history that records all segments (gray rectangles) and operations (rectangular glyphs) created during analysis; the selected segment is highlighted in blue with a black outline. The Segment Inspector View (C) shows the attributes and raw sequences associated with the selected segment. ", "caption_bbox": [63, 493, 762, 552]}, {"image_id": 2, "file_name": "827_02.png", "page": 8, "dpi": 300, "bbox": [61, 101, 764, 626], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Usage scenario workflow broken down into the analysis of 7 segments/operations. Details of each in Section 6.1. View boxes with checkmarks means answers were found at this step. ", "caption_bbox": [62, 637, 761, 665]}, {"image_id": 3, "file_name": "827_03.png", "page": 10, "dpi": 300, "bbox": [61, 101, 762, 406], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Annotated Analysis Paths View representing the four analyses done in case study with domain expert.", "caption_bbox": [133, 417, 691, 430]}], "828": [{"image_id": 0, "file_name": "828_00.png", "page": 3, "dpi": 300, "bbox": [412, 101, 765, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview of TopTom architecture. Once that the sys- tem is configured, it is able to run the entire pipeline autonomously providing near-real time results to the visual interface. ", "caption_bbox": [428, 323, 762, 366]}, {"image_id": 1, "file_name": "828_01.png", "page": 4, "dpi": 300, "bbox": [465, 367, 729, 676], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Analytics pipeline. a) For each temporal chunk the document-term matrix X (t) is decomposed in a document-topic ma- trix W (t) and a topic-term matrix H (t) using NMF. b) The agglomer- ative clustering produces a hierarchical representation of the top- ics. c) Each node in the hierarchy is represented as a temporal topic. d) An anomalous trend is detected in the stream vector s of a temporal topic. ", "caption_bbox": [429, 690, 763, 794]}, {"image_id": 2, "file_name": "828_02.png", "page": 6, "dpi": 300, "bbox": [462, 454, 729, 701], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: TopTom interaction flow A visual summary of TopTom interaction flow. From the list of anomalies on the calendar view (a) users access the focus view (d) with the highlighted anomaly. From the focus view it is possible to go back to the flow view (d) or look inside a single time chunk by browsing the cut-view (c). From both (c) and (d) users have access to the lists of topic documents. ", "caption_bbox": [428, 714, 762, 803]}, {"image_id": 3, "file_name": "828_03.png", "page": 7, "dpi": 300, "bbox": [135, 101, 765, 411], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Focus view and interface overview. A screen-shot of the application opened on the focus view (see section 4.2.2), with interface components highlighted. A breadcrumbs system allows users to browse different views (a). As a litmus paper, the depth bar (b) indicates where anomalies are located along the hierarchical structure. Users can change anomaly type (c), source (d) and time interval (e) using the drop-down menus on the top. Each time chunk (g) on the interactive timeline (f) allows to explore the temporal cut view (see section 4.2.3). ", "caption_bbox": [63, 425, 762, 484]}, {"image_id": 4, "file_name": "828_04.png", "page": 7, "dpi": 300, "bbox": [98, 528, 363, 674], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Tomographic sections. An abstract representation of the hierarchical structure. The foreground sketch represents the most detailed aspect of the streamgraph. Changing the depth level, the user can ideally move on the z axis and see how topics aggregate. ", "caption_bbox": [63, 689, 397, 748]}, {"image_id": 5, "file_name": "828_05.png", "page": 8, "dpi": 300, "bbox": [431, 391, 768, 610], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Depth slider. Users can navigate the hierarchical struc- ture of topics on the different views through the depth slider. ", "caption_bbox": [431, 623, 765, 651]}, {"image_id": 6, "file_name": "828_06.png", "page": 8, "dpi": 300, "bbox": [412, 101, 731, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Anomalies. When users select a specific type of anomaly from the dropdown menu (Figure 4c), it will be highlighted along the flow view (a) the focus view (b) and the temporal cut view (c). ", "caption_bbox": [431, 308, 765, 351]}, {"image_id": 7, "file_name": "828_07.png", "page": 8, "dpi": 300, "bbox": [61, 101, 415, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Temporal cut view. When users select a time chunk (Fig- ure 4f) the temporal cut view shows the details of topics composi- tion (b). ", "caption_bbox": [66, 338, 400, 381]}, {"image_id": 8, "file_name": "828_08.png", "page": 9, "dpi": 300, "bbox": [95, 101, 415, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Glyph for the calendar view. In the calendar view, each day that contains at least one anomaly is surrounded by a circular glyph. ", "caption_bbox": [62, 280, 396, 323]}], "829": [{"image_id": 0, "file_name": "829_00.png", "page": 2, "dpi": 300, "bbox": [61, 101, 762, 437], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Bird\u2019s-Eye\u2019s interactive visual interface consists of multiple coordinated views. Top: A geographic map can be overlayed with social location information, encoded with spatial clusters and tagmaps. A mobility graph shows transitions between clusters (here Tokyo). Bottom: Two different timeline components help to understand temporal patterns of visited places (per category) and the transitions in-between them. Right: The sidebar allows users to enable or disable categories, steer clustering and outlier detection, and to inspect locations in detail. ", "caption_bbox": [62, 442, 764, 501]}, {"image_id": 1, "file_name": "829_01.png", "page": 5, "dpi": 300, "bbox": [62, 101, 765, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Bird\u2019s-Eye\u2019s architecture consists of a monitoring component (A) that records and stores Foursquare and Twitter data in a No-SQL database (B). An autonomous aggregator routine accesses the data stored in the database in parallel and processes it into hourly, weekly, and monthly chunks for faster point-based and transition-based queries from the visual analysis components (C). The interface consists of interactively linked visualizations, including a map with different data layers, time series using stacked area chart and alluvial diagrams, as well as controllers for parameter steering for, e.g., clustering. Users can access historic or near real-time data. Once loaded, selections in the timeline trigger data requests that leverage the pre-aggregates in the database. ", "caption_bbox": [62, 316, 764, 405]}, {"image_id": 2, "file_name": "829_02.png", "page": 5, "dpi": 300, "bbox": [427, 750, 764, 935], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The near real-time mode gives a configurable view over the last few hours with updates every 10 minutes. The full system functionality can be used to monitor events with information about check-in counts as well as mobility patterns. ", "caption_bbox": [427, 946, 761, 1005]}, {"image_id": 3, "file_name": "829_03.png", "page": 6, "dpi": 300, "bbox": [61, 101, 415, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Scattered Kernel Density Estimation: Venues (B,C,D) sur- rounding venue (A) contribute to its Gaussian splat by multiplying (A)\u2019s grid value with the other venue\u2019s check-in counts. ", "caption_bbox": [61, 315, 398, 358]}, {"image_id": 4, "file_name": "829_04.png", "page": 6, "dpi": 300, "bbox": [412, 101, 764, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Density-based clustering allows to detect functional zones (here food districts in Tokyo). On a city level, it gives an aggregated overview of the main areas (left). By zooming in, one can reveal smaller restaurant clusters (Tokyo-Akhibara, right image). To em- phasize cohesiveness we compute concave hulls. ", "caption_bbox": [427, 315, 764, 389]}, {"image_id": 5, "file_name": "829_05.png", "page": 7, "dpi": 300, "bbox": [72, 101, 765, 428], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Clusters can be overlayed with radial area charts showing hourly (top) or weekly (bottom) patterns of check-in counts of the clusters\u2019 places. (a) Akhibara, an electronic shopping mile, and (b) Shibuya, an entertainment area, are mostly visited in the afternoon. (c) Near downtown, there are some restaurant districts, most busy during lunch and dinner time. (d) The Convention center is frequented in the morning. (e) Disneyland has many visitors all day. (f) Tokyo station, the city\u2019s busy metro station. (g) Shibaura University is less visited during the weekend. This does not account for (h) Gina, an elegant shopping area, and (i) Shuntory concert mall, mostly visited on Saturday and Sunday. (j) The Tokyo tower, a landmark, is most busy during the weekend but also during weekdays. Colormap: Travel & Transport, Shop & Services, Residence, Professional & other Places, Outdoors & Recreation, Nightlife Spots, Food, Event, College & University, Arts & Entertainment. ", "caption_bbox": [62, 444, 764, 548]}, {"image_id": 6, "file_name": "829_06.png", "page": 8, "dpi": 300, "bbox": [62, 872, 399, 950], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The alluvial diagram shows citizens\u2019 transitions between places using color-encoded categories. Hovering over the ribbons highlights incoming and outgoing flows (here blue ribbon). ", "caption_bbox": [62, 961, 396, 1004]}, {"image_id": 7, "file_name": "829_07.png", "page": 8, "dpi": 300, "bbox": [61, 101, 763, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Zoom-adaptive clustering to explore mobility patterns to, from, and in Tokyo\u2019s Disneyland from overview (left) to detail (right).", "caption_bbox": [69, 361, 756, 374]}, {"image_id": 8, "file_name": "829_08.png", "page": 9, "dpi": 300, "bbox": [64, 101, 415, 378], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: In focus is a three-day music festival in Nippon Budokan, an indoor arena. The map shows the cluster (in purple) and incom- ing and outgoing transitions. The table gives details about places within the cluster. Radial stacked area charts show the hourly (top) and daily (bottom) visiting distribution. ", "caption_bbox": [62, 391, 398, 465]}, {"image_id": 9, "file_name": "829_09.png", "page": 10, "dpi": 300, "bbox": [412, 101, 764, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Ease of use of the features. The chart illustrates the number of different answers to the question \u201cThe following feature was easy and intuitive to use\u201d ranging from \u201cstrongly disagree\u201d to ", "caption_bbox": [429, 351, 763, 394]}, {"image_id": 10, "file_name": "829_10.png", "page": 10, "dpi": 300, "bbox": [61, 101, 415, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Usefulness of the individual features. The chart illus- trates the number of different answers to the question \u201cThe following feature was helpful in solving the tasks\u201d from \u201cstrongly disagree\u201d to \u201cstrongly agree.\u201d ", "caption_bbox": [64, 350, 401, 409]}], "830": [{"image_id": 0, "file_name": "830_00.png", "page": 2, "dpi": 300, "bbox": [412, 101, 758, 344], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Methods for visualizing urban-traffic OD trails: (a) den- sity maps; (b,c) KDEEB bundles colored by density and direction, respectively; (d) vector maps. See Sec. 2. ", "caption_bbox": [423, 357, 764, 399]}, {"image_id": 1, "file_name": "830_01.png", "page": 3, "dpi": 300, "bbox": [420, 151, 763, 463], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: KDEEB applied to Manhattan taxi trips with different kernel sizes pr : (a) 120, (b) 80, (c) 40, and (d) 20. See Sec. 3.2. ", "caption_bbox": [421, 470, 760, 499]}, {"image_id": 2, "file_name": "830_02.png", "page": 4, "dpi": 300, "bbox": [61, 101, 757, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Overview of RAEB pipeline. RAEB consists of three phases: Preprocessing creates an initial control structure; bundling does the actual trail grouping; and evaluation determines when to stop bundling. See Sec. 3.3. ", "caption_bbox": [62, 259, 761, 286]}, {"image_id": 3, "file_name": "830_03.png", "page": 5, "dpi": 300, "bbox": [437, 578, 747, 770], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Hierarchical route structure and OD trail abstraction: (a) Three route levels are constructed (blue, purple and green). A raw OD trail is abstracted on (b) level 3, (c) level 2, and (d) level 1. ", "caption_bbox": [422, 772, 763, 814]}, {"image_id": 4, "file_name": "830_04.png", "page": 6, "dpi": 300, "bbox": [426, 780, 759, 910], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Left: Bundling stability ps measured at each bundling iter- ation for different decay ratios \u03bb . Right: Visually indistinguishable images are generated at iteration 10 and 11 for \u03bb = 0.9. See Sec. 6.1. ", "caption_bbox": [423, 913, 764, 955]}, {"image_id": 5, "file_name": "830_05.png", "page": 7, "dpi": 300, "bbox": [434, 391, 750, 537], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Left: Raw 100K artificial OD trails on a hierarchical road network. Right: RAEB bundling result with pra = 2. See Sec. 7.1. ", "caption_bbox": [422, 543, 761, 572]}, {"image_id": 6, "file_name": "830_06.png", "page": 7, "dpi": 300, "bbox": [98, 101, 765, 269], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Leftmost: 100K raw artificial OD trails on a grid road network represented by three hierarchy levels. (a) - (d): RAEB bundling results with route awareness parameter pra set to 0, . . . , 3, respectively. See Sec. 7.1. ", "caption_bbox": [62, 268, 761, 297]}, {"image_id": 7, "file_name": "830_07.png", "page": 8, "dpi": 300, "bbox": [85, 648, 378, 823], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Fine scale density maps of NYC taxi trips in Queens zone generated by (a) KDEEB, and (b) RAEB. See Sec. 7.2. ", "caption_bbox": [62, 822, 401, 849]}, {"image_id": 8, "file_name": "830_08.png", "page": 8, "dpi": 300, "bbox": [61, 101, 758, 593], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Density maps of NYC taxi trips: (a) shortest paths mapped onto the road network; (b-d) KDEEB bundles with three kernel sizes; (e-h) our RAEB method with pr = 21 and three different hierarchy levels. See Sec. 7.2. ", "caption_bbox": [61, 598, 763, 627]}, {"image_id": 9, "file_name": "830_09.png", "page": 9, "dpi": 300, "bbox": [63, 101, 765, 735], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Density maps of Shenzhen taxi trips: (a) Raw GPS records are mapped onto road network. KDEEB bundles trips on close arterial roads together (b), while RAEB keeps trips along these roads separate (c). Trails are colored according to the OD directions. See Sec. 7.3. ", "caption_bbox": [62, 739, 761, 766]}, {"image_id": 10, "file_name": "830_10.png", "page": 10, "dpi": 300, "bbox": [412, 101, 750, 591], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Manhattan taxi maps generated with KDEEB, for four kernel radius pr (a-d)); and with RAEB, using the optimal kernel size pr = 40, and four simplification levels pra (e-h). See Sec. 7.4. ", "caption_bbox": [422, 594, 761, 637]}], "831": [{"image_id": 0, "file_name": "831_00.png", "page": 2, "dpi": 300, "bbox": [412, 101, 763, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of an Exploration of a hierarchical embed- ding through a set of disconnected plots/views. ", "caption_bbox": [428, 240, 762, 268]}, {"image_id": 1, "file_name": "831_01.png", "page": 2, "dpi": 300, "bbox": [64, 832, 397, 940], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Illustration of Typical Exploration Paths for hierarchi- cal embeddings. Paths indicated by blue nodes in the hierarchy. Repeated zooming into one subset, a), recursive subset selection and zooming, b), and zooming into two groups for comparison, c). ", "caption_bbox": [63, 946, 397, 1005]}, {"image_id": 2, "file_name": "831_02.png", "page": 3, "dpi": 300, "bbox": [430, 859, 763, 972], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration of a Focus+Context Exploration of a hier- archical embedding in a single view. ", "caption_bbox": [428, 977, 762, 1005]}, {"image_id": 3, "file_name": "831_03.png", "page": 4, "dpi": 300, "bbox": [61, 294, 400, 940], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Scheme of the Proposed Focus+Context Interactions. The left column shows generic interactions, while the right column shows interactions, specific to Focus+Context with interactions for comparative Focus+Context below the dashed line. ", "caption_bbox": [64, 946, 398, 1005]}, {"image_id": 4, "file_name": "831_04.png", "page": 5, "dpi": 300, "bbox": [91, 101, 765, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Interactions and their Effect on the Focus+Context Tree. r(D )resets the tree to the root node, a). The result of dc (X k )depends on the selection. If we only have a single node (the root) and the selection is part of the root, a minimal tree is appended, b). If the selection is part of a context, the tree below the first branching node above the corresponding context node is cut off and replaced by the minimal tree, c). Finally, if the selection is part of a focus, a minimal tree is appended to the corresponding focus node, d). Faded nodes indicate no change. ", "caption_bbox": [63, 364, 762, 426]}, {"image_id": 5, "file_name": "831_05.png", "page": 6, "dpi": 300, "bbox": [437, 727, 754, 895], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Example for Traversing the HSNE Hierarchy Up- wards. To find the landmarks best representing the selection S 0 = {L10 , L20 , L30 } in L1 we compute the fractional influence IL norm (S 0 ) for all landmarks and select those above a user-defined threshold. For example using 0.5 would yield S 1 = {L11 , L21 }. Note that this is not the only possible set S 1 as expanding L11 alone would yield the same S 0 ", "caption_bbox": [428, 903, 762, 1009]}, {"image_id": 6, "file_name": "831_06.png", "page": 7, "dpi": 300, "bbox": [429, 798, 757, 952], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Distance Matrix Combination Modes with 3 levels of detail. A new focus was defined on F 1 from Figure 7, a), resulting in the respective nested distance matrices in b) and c). ", "caption_bbox": [427, 961, 761, 1004]}, {"image_id": 7, "file_name": "831_07.png", "page": 7, "dpi": 300, "bbox": [412, 101, 765, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Distance Matrix Combination Modes for a basic Focus+Context graph shown in a). Simple Combination, b). Con- nections between focus and context are set to 0. Pull-Up, c). The focus is pulled up to the context level to extract the partial matrix between focus and context. ", "caption_bbox": [427, 269, 761, 343]}, {"image_id": 8, "file_name": "831_08.png", "page": 8, "dpi": 300, "bbox": [61, 101, 763, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparison of Embeddings resulting from different matrix combination modes. A high-level embedding of a single-cell dataset [vULM\u2217 16] consisting of one million data points is shown in a). Computing the hierarchy took 4:20 minutes, but only needs to be done once. We focus on and differentiate the highlighted points (blue halos) in the inset of a) which are part of the larger structure indi- cated by the magenta line. The connection between focus and context is lost in the simple matrix combination mode in b) (the line illustrating the global structure breaks), in the pull up approach, c), the structure bends the context towards the focus, indicating the connection. Still, a clear separation between focus and context is preserved. Finally, d) shows only the focus landmarks embedded with standard HSNE. The structure is highly similar to the structure of the foci in b) and c). Starting from the embedding in a), computing b) and c) took 1:10 minutes. Computing the embedding in d) took slightly longer with 1:25 minutes, despite showing fewer data points. This is mostly caused by the fact that we initialized b) and c) with the previous embedding, while d) was computed from scratch, requiring more iterations until convergence. ", "caption_bbox": [63, 326, 762, 461]}, {"image_id": 9, "file_name": "831_09.png", "page": 9, "dpi": 300, "bbox": [62, 101, 765, 454], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Example of a Focus+Context Exploration with HSNE. The input data are shown in a). Each of the images corresponds to one dimension. Focus+Context HSNE embeddings shown in b) to g). Landmarks are colored according to their (x,y)-coordinates in the embedding using the 2D colormap shown in b). Required computation time to achieve the presented results shown below the embeddings. Images with pixels colored according to their corresponding landmarks shown in h) to m). ", "caption_bbox": [62, 461, 761, 520]}], "832": [{"image_id": 0, "file_name": "832_00.png", "page": 1, "dpi": 300, "bbox": [62, 530, 763, 705], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Tangible Brush technique: (a) drawing selection shape; (b) tangible shape extrusion; and (c) selection result.", "caption_bbox": [112, 499, 710, 512]}, {"image_id": 1, "file_name": "832_01.png", "page": 6, "dpi": 300, "bbox": [61, 101, 415, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Tablet interface to control the selection.", "caption_bbox": [103, 323, 355, 336]}, {"image_id": 2, "file_name": "832_02.png", "page": 6, "dpi": 300, "bbox": [62, 344, 399, 485], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The tablet being used together with the synchronized split-screen view that is shown on a separate, large display. ", "caption_bbox": [62, 490, 396, 518]}, {"image_id": 3, "file_name": "832_03.png", "page": 8, "dpi": 300, "bbox": [61, 101, 415, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Datasets from our study; particles to be selected are red.", "caption_bbox": [62, 467, 398, 480]}, {"image_id": 4, "file_name": "832_04.png", "page": 9, "dpi": 300, "bbox": [429, 279, 765, 397], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Technique preferences shown by dataset.", "caption_bbox": [468, 401, 724, 414]}, {"image_id": 5, "file_name": "832_05.png", "page": 9, "dpi": 300, "bbox": [412, 101, 765, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "                                                 Total Figure 8: Fatigue measurements (scale 0\u201310) for (a) fingers, (b) hands, (c) arms, (d) shoulders, and (e) total. Error bars: 95% CIs. ", "caption_bbox": [429, 241, 764, 269]}, {"image_id": 6, "file_name": "832_06.png", "page": 9, "dpi": 300, "bbox": [64, 299, 396, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: MCC (a) and F1 (b) accuracy. Error bars: 95% CIs.", "caption_bbox": [73, 348, 388, 361]}, {"image_id": 7, "file_name": "832_07.png", "page": 9, "dpi": 300, "bbox": [64, 374, 392, 521], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "                                              Total Workload Figure 7: Workload measurement in TLX units (\u2208     \u2208 [0, 100], 0 is best) for (a) mental, (b) physical, and (c) temporal demand, (d) effort, (e) performance, (f) frustration, and (g) total. Error bars: 95% CIs. ", "caption_bbox": [63, 520, 400, 571]}, {"image_id": 8, "file_name": "832_08.png", "page": 9, "dpi": 300, "bbox": [64, 101, 415, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Task completion time in sec. (a), direct comparisons by dataset/overall (b), number of selections (c). Error bars: 95% CIs. ", "caption_bbox": [64, 258, 398, 286]}], "833": [{"image_id": 0, "file_name": "833_00.png", "page": 1, "dpi": 300, "bbox": [62, 561, 764, 771], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Staged animated transition for conveying the arithmetic mean (average). Individual data points shift and transform to lines to convey residual values. The residual lines then collapse synchronously, such that the upper and lower parts cancel out to form the average. ", "caption_bbox": [63, 525, 762, 553]}, {"image_id": 1, "file_name": "833_01.png", "page": 4, "dpi": 300, "bbox": [36, 101, 790, 944], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Designs of animated transitions for 8 aggregate operations with captured frames. Frames with border lines are key frames so that changes happen between them. Each grey line under each series of the frames is a timeline of the animation. The dark grey spans indicate the moves or changes of the graphic objects, and the light grey spans indicate pauses. ", "caption_bbox": [57, 959, 756, 1002]}, {"image_id": 2, "file_name": "833_02.png", "page": 6, "dpi": 300, "bbox": [61, 101, 745, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Confusion matrices for pilot study judgments of transition / operation correspondences. Values along the diagonal indicate correct responses, all others are incorrect. For each transition style, we consistently find three groups of aggregate operations that are confused with each other as shown in orange squares; {count, sum, max}, {average, median}, and{stdev, iqr}. ", "caption_bbox": [63, 335, 762, 378]}, {"image_id": 3, "file_name": "833_03.png", "page": 7, "dpi": 300, "bbox": [65, 101, 415, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Identification task interface. Subjects view a chart tran- sition and then indicate whether or not it matches the named ag- gregation operation. ", "caption_bbox": [63, 282, 397, 325]}, {"image_id": 4, "file_name": "833_04.png", "page": 7, "dpi": 300, "bbox": [66, 343, 397, 595], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Rank task interface. Subjects view each transition type for a given aggregation operation, rank order them by preference, and provide a textual rationale for their choices. ", "caption_bbox": [63, 602, 397, 645]}, {"image_id": 5, "file_name": "833_05.png", "page": 8, "dpi": 300, "bbox": [61, 101, 763, 729], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Rankings of participants\u2019 preferred transition style across aggregate operation.", "caption_bbox": [187, 734, 636, 747]}, {"image_id": 6, "file_name": "833_06.png", "page": 10, "dpi": 300, "bbox": [61, 101, 415, 529], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Animated transition designs for more complex aggregate operations, from a univariate dot plot to a box plot, histogram, or bootstrapped mean and confidence interval. ", "caption_bbox": [63, 536, 397, 579]}], "834": [{"image_id": 0, "file_name": "834_00.png", "page": 1, "dpi": 300, "bbox": [62, 752, 764, 1077], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Two example visualizations created using Kyrix: (a) a visualization of the 2017-2018 regular season of the NBA, where the user can zoom from one view showing NBA team logos to another view showing a timeline of NBA games and (b) a pannable and zoomable EEG time series consisting of 100 million data points. ", "caption_bbox": [63, 701, 762, 744]}, {"image_id": 1, "file_name": "834_01.png", "page": 2, "dpi": 300, "bbox": [412, 101, 731, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Kyrix system architecture.", "caption_bbox": [505, 295, 685, 308]}, {"image_id": 2, "file_name": "834_02.png", "page": 4, "dpi": 300, "bbox": [61, 101, 413, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Kyrix\u2019s declarative model. Canvases are \u201czoom levels\u201d connected by zooms. A canvas has multiple layers. A data trans- form prepares the data source for rendering a layer. A rendering function maps data to visual objects. A placement function provides spatial information of objects to enable fast data fetching. ", "caption_bbox": [64, 282, 398, 356]}, {"image_id": 3, "file_name": "834_03.png", "page": 4, "dpi": 300, "bbox": [412, 101, 778, 495], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Specifications of canvases and layers for the NBA exam- ple in Figure 1a. ", "caption_bbox": [429, 506, 763, 534]}, {"image_id": 4, "file_name": "834_04.png", "page": 5, "dpi": 300, "bbox": [476, 351, 672, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Specification of the placement function for a dynamic layer in the NBA example in Figure 1a. ", "caption_bbox": [427, 440, 761, 468]}, {"image_id": 5, "file_name": "834_05.png", "page": 5, "dpi": 300, "bbox": [65, 101, 415, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Specification of the zoom from the logo canvas to the timeline canvas for the NBA example in Figure 1a. ", "caption_bbox": [62, 407, 396, 435]}, {"image_id": 6, "file_name": "834_06.png", "page": 5, "dpi": 300, "bbox": [412, 101, 777, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Specification of the data transform for a layer in the NBA example in Figure 1a. ", "caption_bbox": [427, 306, 761, 334]}, {"image_id": 7, "file_name": "834_07.png", "page": 6, "dpi": 300, "bbox": [61, 101, 737, 449], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: An illustration of performance optimizations in Kyrix.", "caption_bbox": [251, 467, 570, 480]}, {"image_id": 8, "file_name": "834_08.png", "page": 8, "dpi": 300, "bbox": [61, 101, 759, 372], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Four more example applications created using Kyrix: (a) a scatterplot visualizing 17 million 2-second EEG segments; (b) a map of animals in the Amazon rainforest; (c) a zoomable crime rate map of the US; (d) a zoomable circle packing layout of the class hierarchy in Flare, an ActionScript library for visualization [UC 08]. ", "caption_bbox": [63, 385, 762, 428]}, {"image_id": 9, "file_name": "834_09.png", "page": 9, "dpi": 300, "bbox": [412, 101, 765, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The scatterplot visualization used both in Task 1 of the developer study and in the performance evaluation: (a) the top- level canvas; (b) the bottom-level canvas. Two canvases are con- nected by a zoom. The zoom factor is 2. ", "caption_bbox": [429, 316, 763, 375]}, {"image_id": 10, "file_name": "834_10.png", "page": 10, "dpi": 300, "bbox": [412, 101, 720, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Kyrix\u2019s ability to scale with increasing data size. The scatterplot in Figure 10 is used as the benchmark visualization. Average response time and network latency are shown. ", "caption_bbox": [428, 319, 762, 362]}], "835": [{"image_id": 0, "file_name": "835_00.png", "page": 4, "dpi": 300, "bbox": [61, 101, 414, 457], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: A list of the compression ratios corresponding to the four variables used in the study images: TS (surface temperature), FS- NTC (clear sky net solar flux), NUMLIQ (averaged cloud liquid number), and PRECCDZM (convective precipitation rate). Note that because SPECK is a fixed-rate method, the compression ratios (CRs) are equivalent across variable type. ", "caption_bbox": [428, 343, 762, 432]}, {"image_id": 1, "file_name": "835_01.png", "page": 5, "dpi": 300, "bbox": [412, 101, 765, 450], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: The high and low compression categories used to deter- mine the randomized set of image comparisons seen by each par- ticipant. One image was chosen from the high compression set and two from the low compression set. Note that speck_1 (which would be considered high compression) is not listed as it was seen by all participants for each variable. ", "caption_bbox": [428, 760, 762, 849]}, {"image_id": 2, "file_name": "835_02.png", "page": 6, "dpi": 300, "bbox": [61, 101, 414, 611], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Three images are shown for PRECCDZM (convective precipitation rate). The top is the visualization from the uncom- pressed data. The middle image has the speck_4 compression applied and the bottom has fpzip_12 applied. Despite the two \"high compression\" approaches (speck_4 and fpzip_12) resulting in nearly identical compression ratios, there are a number of obvi- ous differences particularly near the equator. In this example, the speck_4 image is closer to the original (e.g., see Table 5), and 42% of the study participants noticed a difference. For fpzip_12, 100% of the study participants noted a difference. ", "caption_bbox": [63, 621, 397, 771]}, {"image_id": 3, "file_name": "835_03.png", "page": 7, "dpi": 300, "bbox": [412, 101, 765, 611], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Example visualizations are shown for NUMLIQ, the grid box averaged cloud liquid number. The top image is from the un- compressed data. The middle image has the fpzip_20 compression applied to the data, and no study participants noticed the differ- ence. The bottom image has speck_8 applied to the data, and while the resulting image is equivalent to the original image, one partic- ipant noted a difference. ", "caption_bbox": [428, 621, 762, 725]}, {"image_id": 4, "file_name": "835_04.png", "page": 8, "dpi": 300, "bbox": [450, 463, 734, 692], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Worst fitting model using log-transformed MAD as a predictor and the logit link function. ", "caption_bbox": [428, 709, 762, 737]}, {"image_id": 5, "file_name": "835_05.png", "page": 8, "dpi": 300, "bbox": [412, 101, 734, 373], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Best fitting model using log-transformed SSIM as a pre- dictor and the logit link function. ", "caption_bbox": [428, 389, 762, 417]}], "836": [{"image_id": 0, "file_name": "836_00.png", "page": 1, "dpi": 300, "bbox": [62, 396, 765, 642], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The clustering-related views of our system. Here, the hierarchical clustering result has been pruned to seven clusters. By manually expanding the pink cluster, an outlier is detected (lightest of the four pink leaves) ", "caption_bbox": [63, 668, 762, 696]}, {"image_id": 1, "file_name": "836_01.png", "page": 4, "dpi": 300, "bbox": [412, 101, 764, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The complete dendrogram is visualized by lines which are grayed out for parts that do not concern points from the cur- rently selected time step. Up to a user-defined depth, the subtrees have a colored background. Bottom: The mean fields of the five low- level clusters are rendered together with the parent of the turquoise and the yellow cluster. ", "caption_bbox": [428, 364, 762, 453]}, {"image_id": 2, "file_name": "836_02.png", "page": 6, "dpi": 300, "bbox": [61, 101, 413, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Schematic drawing of the Clustering Timeline (only one level of clusters). All three members are in the same cluster at the first time step, then they split, change not or only little from the second to the third time step and finally all members are separate, with member m0 being close to the initial state again. ", "caption_bbox": [64, 312, 398, 386]}, {"image_id": 3, "file_name": "836_03.png", "page": 6, "dpi": 300, "bbox": [63, 410, 400, 659], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Hierarchical Clustering Timeline for a dataset with 10 members and 24 time steps. ", "caption_bbox": [64, 684, 398, 712]}, {"image_id": 4, "file_name": "836_04.png", "page": 8, "dpi": 300, "bbox": [61, 101, 763, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The MiKlip ensemble (center) compared to real observation data (left) with the absolute difference (right). It turns out that the ensemble member that is in the dark blue cluster in the later part of the simulation (see Figure 1 and Figure 2) comes close to the ground truth regarding the warming at the north pole (see also the respective supplementary video). ", "caption_bbox": [62, 340, 761, 383]}, {"image_id": 5, "file_name": "836_05.png", "page": 9, "dpi": 300, "bbox": [62, 101, 765, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Dendrogram and timeline for the MiKlip dataset with seven automatically chosen leaf clusters.", "caption_bbox": [149, 264, 676, 277]}, {"image_id": 6, "file_name": "836_06.png", "page": 9, "dpi": 300, "bbox": [62, 298, 765, 467], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Timeline and cluster means for the MiKlip dataset with seven automatically chosen leaf clusters as in Figure 6 but with a red- yellow-blue color scheme for the cluster colors. ", "caption_bbox": [63, 493, 762, 521]}, {"image_id": 7, "file_name": "836_07.png", "page": 10, "dpi": 300, "bbox": [123, 661, 700, 875], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Timeline, dendrogram and cluster means for the HAPPI Plus2 dataset generated by complete-linkage top-down clustering. With the complete-linkage cluster-to-cluster distance we uncover a division of the temporal and the ensemble range with five clusters. ", "caption_bbox": [63, 885, 762, 913]}, {"image_id": 8, "file_name": "836_08.png", "page": 10, "dpi": 300, "bbox": [123, 396, 700, 587], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Timeline and cluster means for the HAPPI Plus2 dataset, average-linkage bottom-up clustering, automatic selection of five clusters. The result is similar to Figure 8 because the simulation initialization is similar (constant 2 \u25e6C temperature offset). ", "caption_bbox": [63, 598, 762, 627]}, {"image_id": 9, "file_name": "836_09.png", "page": 10, "dpi": 300, "bbox": [61, 101, 700, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Timeline and means for the HAPPI Current Decade dataset, average-linkage, bottom-up, manual selection of five clusters. Clusters mostly divide the time lapse, not the ensemble. The bottom view lets us (roughly) read the timeline as neutral \u2192 cold \u2192 neutral \u2192 warm. ", "caption_bbox": [63, 333, 762, 361]}, {"image_id": 10, "file_name": "836_10.png", "page": 11, "dpi": 300, "bbox": [62, 101, 415, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Result of single-linkage bottom-up clustering of the HAPPI Plus2 dataset. Ensemble members never switch clusters. Bottom: The coloring and spacing reflecting the cluster hierarchy convey a sense of (dis-)similarity among the clusters. ", "caption_bbox": [63, 329, 397, 388]}], "837": [{"image_id": 0, "file_name": "837_00.png", "page": 1, "dpi": 300, "bbox": [62, 396, 765, 703], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A screen capture of the IGM-Vis visualization application, which facilitates a range of analysis tasks using quasar sightline data in order to better understand intergalactic medium and circumgalactic medium absorption features. The Universe Panel (upper left) shows a 3D map of galaxies in the Coma Supercluster, along with \u201cskewers\u201d representing absorption signals in spectra of background quasar sightlines. The Galaxy Panel (lower left) provides descriptive metrics for selected galaxies. The Spectrum Panel (right) displays the spectra and marks nearby galaxies, facilitating comparative analysis between galaxies and absorption, and provides interactive controls with to select which regions of the 3D map are visible, to choose the zoom level of the spectra, and to update the profile plot to its left in the Equivalent Width Plot Panel. ", "caption_bbox": [63, 713, 762, 817]}, {"image_id": 1, "file_name": "837_01.png", "page": 4, "dpi": 300, "bbox": [61, 101, 415, 442], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Zooming into a specific region of the Coma Supercluster dataset in the Universe Panel. To reduce visual clutter, a user can toggle on or off different elements or filter the number of galaxies displayed. The top image displays an overview of a large number of galaxies; the middle panel zooms into a region of interest, with skewers and labels toggled on; the bottom image filters out galaxies beyond a user-specified distance threshold from the skewers. ", "caption_bbox": [63, 452, 397, 556]}, {"image_id": 2, "file_name": "837_02.png", "page": 6, "dpi": 300, "bbox": [61, 101, 764, 396], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The same \u201cskewer,\u201d sightline SBS1116+523, represented in the Universe Panel (top) and in the Spectrum Panel (bottom). On the top, the brighter coloring along the skewer indicates absorption, which a user can explore in more detail in the associated spectral plot. ", "caption_bbox": [62, 406, 761, 434]}, {"image_id": 3, "file_name": "837_03.png", "page": 7, "dpi": 300, "bbox": [412, 101, 765, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A screen capture of the IGM-Vis interface while investi- gating Use Case 1. The Universe Panel shows 4 skewers with ab- sorption (brighter shading) at similar redshifts, and the Spectrum Panel shows each sightline\u2019s spectrum with the absorption features of interest labeled with yellow arrows. The slider below these spec- tra (not shown here) has been set to mark the redshifts of galax- ies within \u223c500 kpc of the skewers (white vertical lines), only the SDSSJ111443.70+525834.0 sightline has a galaxy present near the redshift of interest (green vertical line). ", "caption_bbox": [428, 304, 762, 439]}, {"image_id": 4, "file_name": "837_04.png", "page": 9, "dpi": 300, "bbox": [62, 101, 765, 355], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Title and research areas of the experts who provided feedback, along with the datasets and software tools they commonly use.", "caption_bbox": [75, 691, 747, 704]}], "838": [{"image_id": 0, "file_name": "838_00.png", "page": 1, "dpi": 300, "bbox": [412, 393, 764, 848], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) Setup of an organic solar cell consisting of two in- terpenetrated materials. (b) Direct visualization of the trajectories obtained from a Kinetic Monte Carlo simulation. Electron trajecto- ries are displayed as green lines, hole trajectories as orange lines. The acceptor material (blue) provides the morphological context. ", "caption_bbox": [428, 856, 762, 930]}, {"image_id": 1, "file_name": "838_01.png", "page": 2, "dpi": 300, "bbox": [61, 101, 764, 366], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of our charge flow network pipeline. Given the raw data, the pipeline generates the network abstraction and network visualization. ", "caption_bbox": [62, 377, 761, 405]}, {"image_id": 2, "file_name": "838_02.png", "page": 4, "dpi": 300, "bbox": [479, 393, 711, 542], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A pair of pockets is merged if either center is located within the influence sphere of the other pocket. ", "caption_bbox": [428, 555, 762, 583]}, {"image_id": 3, "file_name": "838_03.png", "page": 4, "dpi": 300, "bbox": [61, 101, 758, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Pocket extraction. (a) The distance field computed for the morphology (acceptor material in blue, donor material in orange). (b) Red and blue points show the maxima of the distance field, while yellow points show the voxels in the ascending manifold of one of the maxima, i.e. one pocket. (c) morphology segmentation corresponding to 182 originally extracted local maxima. (d) the segmentation corresponding to 125 pockets obtained after pocket simplification. ", "caption_bbox": [62, 293, 761, 352]}, {"image_id": 4, "file_name": "838_04.png", "page": 5, "dpi": 300, "bbox": [428, 595, 764, 796], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) The charge flow network for one material of the mor- phology. The starting pocket is highlighted in red while the end pockets are shown in blue. Two selected pockets and the associated charge positions are shown in green and yellow, respectively. Note that the periodic boundary conditions are taken into account indi- cated by the open-ended connections. (b) Top: Radial density plot for the yellow pocket shown below. Bottom: The charge positions within a pocket of interest are highlighted in yellow. The morphol- ogy skeleton represented as lines and the volume rendering of the distance field of the skeleton are shown for context. ", "caption_bbox": [427, 803, 761, 953]}, {"image_id": 5, "file_name": "838_05.png", "page": 5, "dpi": 300, "bbox": [412, 101, 765, 478], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Trajectory bundling using a spring mass system embed- ded in a force field, which is defined by the gradient of the distance field, During the bundling process the trajectories are first drawn to planar structures before they move toward the ridges of the mor- phological skeleton. ", "caption_bbox": [427, 485, 761, 559]}, {"image_id": 6, "file_name": "838_06.png", "page": 6, "dpi": 300, "bbox": [61, 101, 415, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Radial pocket charge distributions. The radial distance r for a given charge position (red) depends on the distance to the morphology boundary dmorph and the distance to the skeleton dtraj . ", "caption_bbox": [63, 271, 397, 315]}, {"image_id": 7, "file_name": "838_07.png", "page": 6, "dpi": 300, "bbox": [413, 101, 689, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Planar pocket interfaces are constructed using principal component analysis of the boundary voxels. ", "caption_bbox": [428, 289, 762, 317]}, {"image_id": 8, "file_name": "838_08.png", "page": 7, "dpi": 300, "bbox": [63, 101, 415, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Pocket interfaces between a single pocket (orange) and all its neighbors. Charge transitions from one pocket to another are represented as heatmap on the cross section: inflows from neigh- boring pockets (top left) and corresponding outflows (top right) embedded in the network visualization; extracted cross sectional pocket interface hulls (bottom). Charges (yellow) are only shown for the selected pocket. ", "caption_bbox": [64, 369, 398, 473]}, {"image_id": 9, "file_name": "838_09.png", "page": 7, "dpi": 300, "bbox": [413, 101, 765, 494], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Two datasets in comparison. Left: trajectories embed- ded within the morphology. Right: expansion of the trajectories considering periodic boundary conditions. ", "caption_bbox": [429, 501, 763, 544]}, {"image_id": 10, "file_name": "838_10.png", "page": 8, "dpi": 300, "bbox": [413, 101, 741, 550], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Trajectory bundling. DATASET 3 (bottom) exhibits more planar structures than DATASET 2 (top). Charge positions shown on the right represent an intermediate state of the bundling process. ", "caption_bbox": [428, 557, 762, 600]}, {"image_id": 11, "file_name": "838_11.png", "page": 8, "dpi": 300, "bbox": [61, 101, 415, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Morphology analysis. Distance fields of the morphology (top) and pocket shape distributions (bottom) of DATASET 2 (a) and DATASET 3 (b). ", "caption_bbox": [63, 399, 397, 443]}, {"image_id": 12, "file_name": "838_12.png", "page": 9, "dpi": 300, "bbox": [412, 101, 765, 574], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Charge flow network of DATASET 2. (a) spatial net- work embedding with two highlighted pockets; associated charge distributions in green (electrons) and orange (holes). Pockets are represented by ellipsoids whose shape corresponds to the local charge distributions (red: start pockets; blue: end pockets at the electrodes; light orange/green: transit pockets). Periodic bound- ary conditions are indicated by open-ended connections. (b) tra- jectory inspection of a single charge pair where both electron and hole move toward the same electrode. (c) In depth inspection of the transport behavior is facilitated in combination with chord dia- grams (hole left, electrons right). Both diagrams feature end pock- ets (blue) at the top and left which correspond to the bottom elec- trode and the top electrode, respectively. This indicates that charge pairs are not separating, as e.g. depicted in (b). ", "caption_bbox": [427, 581, 761, 792]}, {"image_id": 13, "file_name": "838_13.png", "page": 10, "dpi": 300, "bbox": [94, 482, 395, 650], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Exploration of pockets with two neighbors. Three seg- mented pockets of acceptor and donor channels form a narrow channel (left). These pockets are identified using the chord diagram of a single trajectory (right). ", "caption_bbox": [62, 664, 396, 723]}, {"image_id": 14, "file_name": "838_14.png", "page": 10, "dpi": 300, "bbox": [64, 771, 394, 948], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Single Trajectory Analysis of an electron-hole charge pair. Pockets traversed by either electron or hole are color mapped to (a) pocket entry time and (b) charge count. ", "caption_bbox": [62, 955, 396, 998]}, {"image_id": 15, "file_name": "838_15.png", "page": 11, "dpi": 300, "bbox": [65, 101, 765, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Chord diagram of the adjacency matrix derived from the charge flow network. The numbers relate to unique pocket IDs while colors differentiate electron and hole trajectories (green/orange), respectively. Red and blue pocket colors indicate start and end nodes of a trajectory. (a) aggregated transitions of all pockets. (b)-(d) the trajectories of a single charge pair, i.e. an electron and a hole, are selected from the aggregated network. (c) connections of two pockets (IDs 214 and 1174), which exhibit higher activity within the trajectory. (d) connections of start and end nodes. ", "caption_bbox": [62, 334, 761, 408]}], "839": [{"image_id": 0, "file_name": "839_00.png", "page": 1, "dpi": 300, "bbox": [63, 318, 761, 663], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualizations using our \u201cgeneralized tube\u201d primitives. (a): DTI tractography data, semi-transparent fixed-radius streamlines (218K line segments). (b): A generated neuron assembly test case, streamlines with varying radii and bifurcations (3.2M l. s.). (c): Aneurysm morphology, semi-transparent streamlines with varying radii and bifurcations (3.9K l. s.) and an opaque center line with fixed radius and bifurcations (3.9K l. s.). (d): A tornado simulation, with radius used to encode the velocity magnitude (3.56M l. s.). (e): Flow past a torus, fixed-radius pathlines (6.5M l. s.). Rendered at: (a) 0.38FPS, (b) 7.2FPS, (c) 0.25FPS, (d) 18.8FPS, with a 20482 framebuffer; (e) 23FPS with a 2048\u00d7786 framebuffer. Performance measured on a dual Intel\u00ae Xeon\u00ae E5-2640 v4 workstation, with shadows and ambient occlusion. ", "caption_bbox": [62, 665, 764, 754]}, {"image_id": 1, "file_name": "839_01.png", "page": 3, "dpi": 300, "bbox": [62, 101, 415, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of the input data structure. We make a list of control points, each with a position, radius, and predecessor index. Each control point and its cylinder or cone stump connection to its predecessor is refered to as a \u201clink\u201d. ", "caption_bbox": [62, 295, 399, 354]}, {"image_id": 2, "file_name": "839_02.png", "page": 4, "dpi": 300, "bbox": [66, 311, 394, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Our method for computing a tangent cone stump to con- nect control points of varying radii. ", "caption_bbox": [62, 434, 398, 462]}, {"image_id": 3, "file_name": "839_03.png", "page": 4, "dpi": 300, "bbox": [61, 101, 738, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: When linking control points of varying radii, cylinders are clearly the wrong choice (a); however, incorrectly chosen cones will also produce artifacts (b). To smoothly link the control points, we compute cones that are tangent to the spheres at their intersection (c). ", "caption_bbox": [62, 279, 761, 307]}, {"image_id": 4, "file_name": "839_04.png", "page": 6, "dpi": 300, "bbox": [412, 101, 764, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Our geometry module integrated into OSPRay can be combined with volumes (left, 9.4 FPS) or other geometry (right, 22.8 FPS) to create interactive, high-quality visualizations. ", "caption_bbox": [427, 289, 764, 333]}, {"image_id": 5, "file_name": "839_05.png", "page": 6, "dpi": 300, "bbox": [61, 101, 415, 488], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) Without our CSG interior surface removal approach, interior surfaces can be seen, producing visual artifacts. (b) Our CSG intersection computation correctly finds only exterior surfaces ", "caption_bbox": [62, 490, 399, 534]}, {"image_id": 6, "file_name": "839_06.png", "page": 7, "dpi": 300, "bbox": [62, 101, 415, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: An illustrative visualization of neuron activity rendered using OSPRay\u2019s path tracer with emissive materials. ", "caption_bbox": [62, 275, 396, 304]}, {"image_id": 7, "file_name": "839_07.png", "page": 7, "dpi": 300, "bbox": [62, 306, 399, 469], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The far and near views used for benchmarks on the DTI dataset, with ambient occlusion and shadows. ", "caption_bbox": [62, 477, 396, 505]}, {"image_id": 8, "file_name": "839_08.png", "page": 8, "dpi": 300, "bbox": [61, 101, 739, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Performance on the Desktop with a 10242 framebuffer.", "caption_bbox": [434, 476, 755, 494]}, {"image_id": 9, "file_name": "839_09.png", "page": 9, "dpi": 300, "bbox": [64, 101, 415, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Triangulated models (Triangles) compared to our non- polygonal generalized tubes (GT) on the Workstation (top) and FSM (bottom). \u2217 indicates out of memory. GT consumes far less memory and provides higher framerates. ", "caption_bbox": [62, 331, 399, 390]}, {"image_id": 10, "file_name": "839_10.png", "page": 9, "dpi": 300, "bbox": [412, 101, 765, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Performance impact of the CSG ray traversal required for correct transparency. Benchmarks were performed rendering opaque geometry in both cases, with only the traversal method switched. Although the CSG traversal comes with a performance impact, it remains interactive in most cases. ", "caption_bbox": [428, 281, 762, 355]}, {"image_id": 11, "file_name": "839_11.png", "page": 9, "dpi": 300, "bbox": [430, 365, 763, 512], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Performance impact of the CSG ray traversal required for correct transparency. Benchmarks were performed by increasing the number of layers of semi-transparent geometry per pixel. Our method remains interactive, even at 6000 layers of transparency. ", "caption_bbox": [428, 516, 762, 575]}, {"image_id": 12, "file_name": "839_12.png", "page": 10, "dpi": 300, "bbox": [65, 328, 384, 483], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Comparison of rendering performance of our general- ized tubes and Embree\u2019s curve primitive. We find our method is up to 2\u00d7 to 4\u00d7 faster for scientific visualization style use cases. ", "caption_bbox": [62, 486, 398, 530]}, {"image_id": 13, "file_name": "839_13.png", "page": 10, "dpi": 300, "bbox": [61, 101, 415, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 4: Average memory consumption of our generalized tube and Embree\u2019s curve primitive. In all cases, our method consumes memory similar to that for Embree\u2019s curve primitive. ", "caption_bbox": [427, 121, 761, 165]}], "840": [{"image_id": 0, "file_name": "840_00.png", "page": 1, "dpi": 300, "bbox": [130, 278, 694, 506], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Large-scale interactive visualization using the Distributed FrameBuffer. Top left: Image-parallel rendering of two transparent isosurfaces from the Richtmyer-Meshkov [CDD\u2217 02] (516M triangles), 8FPS with a 20482 framebuffer using 16 Stampede2 Intel\u00ae Xeon\u00ae Platinum 8160 SKX nodes. Top right: Data-parallel rendering of the Cosmic Web [ISM\u2217 08] (29B transparent spheres), 2FPS at 20482 using 128 Theta Intel\u00ae Xeon Phi\u2122 Knight\u2019s Landing (KNL) nodes. Bottom: Data-parallel rendering of the 951GB DNS volume [LM15] combined with a transparent isosurface (4.35B triangles), 5FPS at 4096 \u00d7 1024 using 64 Stampede2 Intel\u00ae Xeon Phi\u2122 KNL nodes. ", "caption_bbox": [61, 506, 761, 580]}, {"image_id": 1, "file_name": "840_01.png", "page": 3, "dpi": 300, "bbox": [119, 101, 765, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An example of the Distributed FrameBuffer\u2019s tile processing pipeline in a data-parallel renderer. Dependencies are specified on the fly per-tile and can be extended by child tiles. To compute the highlighted tile owned by rank 0, the owner sends a background color tile for generation 0, which specifies that two additional tiles will arrive in generation 1, potentially from different ranks. After receiving the full dependency tree, the tile operation produces the finished tile, which is tone-mapped by a pixel operation and sent to the display rank. ", "caption_bbox": [63, 289, 762, 348]}, {"image_id": 2, "file_name": "840_02.png", "page": 6, "dpi": 300, "bbox": [61, 101, 415, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Tile ownership and dependency trees for a data-parallel renderer using the DFB. Each rank owns its highlighted tile, and receives input tiles from ranks whose data projects to the tile. Com- positing runs in parallel to local rendering, reducing overhead. ", "caption_bbox": [74, 357, 410, 416]}, {"image_id": 3, "file_name": "840_03.png", "page": 7, "dpi": 300, "bbox": [413, 101, 765, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A prototype display wall system using DFB pixel opera- tions to send tiles in parallel from an image-parallel path tracer. ", "caption_bbox": [427, 269, 763, 297]}, {"image_id": 4, "file_name": "840_04.png", "page": 8, "dpi": 300, "bbox": [61, 101, 753, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The data sets used in our benchmarks. (a) Two transparent isosurfaces on the Richtmyer-Meshkov [CDD\u2217 02], 516M triangles total. (b) A combined visualization of the 451GB single-precision DNS [LM15] with two transparent isosurfaces, 5.43B triangles total. (c) A 53 subset of the 83 Cosmic Web [ISM\u2217 08], 7.08B particles rendered as transparent spheres. (d) The generated volume data set used in the compositing benchmarks, shown for 64 nodes. Each node has a single 643 brick of data. ", "caption_bbox": [62, 317, 762, 377]}, {"image_id": 5, "file_name": "840_05.png", "page": 8, "dpi": 300, "bbox": [439, 390, 746, 520], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Image-parallel strong-scaling on the R-M transparent isosurfaces data set on Stampede2 SKX nodes. The image-parallel renderer using the DFB scales to provide interactive rendering of expensive, high-resolution scenes. ", "caption_bbox": [427, 521, 761, 580]}, {"image_id": 6, "file_name": "840_06.png", "page": 9, "dpi": 300, "bbox": [74, 327, 383, 623], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Data-parallel strong-scaling on the DNS with isosurfaces on Stampede2 KNLs. The lack of scaling from 32 to 64 nodes is attributable to a poor local work distribution (b), which can be partially addressed by using our mixed-parallel renderer. ", "caption_bbox": [62, 626, 396, 685]}, {"image_id": 7, "file_name": "840_07.png", "page": 9, "dpi": 300, "bbox": [74, 101, 414, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Data-parallel strong-scaling on the Cosmic Web data set on Theta. We find close to ideal scaling at moderate image sizes and node counts, with somewhat poorer scaling at very high resolutions. ", "caption_bbox": [62, 263, 396, 307]}, {"image_id": 8, "file_name": "840_08.png", "page": 10, "dpi": 300, "bbox": [432, 506, 760, 820], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Improving load-balancing on the DNS with isosurfaces with partial data-replication in the mixed-parallel renderer. Sharing rendering between two nodes (two bricks per-node) gives a consis- tent improvement, between four tends to give further improvement. ", "caption_bbox": [427, 823, 763, 882]}, {"image_id": 9, "file_name": "840_09.png", "page": 10, "dpi": 300, "bbox": [61, 101, 754, 442], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Compositing benchmark performance comparison of the DFB and IceT on the synthetic data set. We find that our approach achieves better, or at least similar, scaling as IceT, while providing faster absolute rendering times. In the timing breakdowns (d-f), we observe this difference is due to the DFB achieving a significant reduction in compositing overhead. ", "caption_bbox": [62, 443, 761, 487]}], "841": [{"image_id": 0, "file_name": "841_00.png", "page": 1, "dpi": 300, "bbox": [62, 622, 764, 847], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Workflow supported by our proposed approach. The input dataset, formed by long MD simulations, is analyzed by combining different properties in a 2D plot. From the graph, the user can extract the important events, which control the temporal and spatial focus and context 3D view by adjusting the visual representation and the animation speed. ", "caption_bbox": [63, 577, 762, 620]}, {"image_id": 1, "file_name": "841_01.png", "page": 4, "dpi": 300, "bbox": [116, 487, 343, 647], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A 2D plot created by one of our domain experts as the starting point for his analysis. It shows the distance of the alcohol (green) and chloride Cl- (blue) products to the buried active site of haloalkane dehalogenase DhaA (PDB entry 4E46) during an MD simulation. The protein boundary is approximated and depicted by the horizontal dashed lines. The running average of the distances over 0.5 ns for the alcohol and Cl- are colored according to the location with respect to the protein boundary. ", "caption_bbox": [62, 660, 396, 780]}, {"image_id": 2, "file_name": "841_02.png", "page": 5, "dpi": 300, "bbox": [427, 498, 764, 624], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Three different levels of abstraction for focus and con- text: The whole protein (i.e., context) is rendered in cartoon repre- sentation, the main focus element (i.e., ligand) is rendered using balls-and-sticks, and its surroundings (i.e., nearby amino acids) are shown as sticks. The image shows the same closeup view with ghosting turned off (left) and on (right). ", "caption_bbox": [428, 635, 762, 724]}, {"image_id": 3, "file_name": "841_03.png", "page": 6, "dpi": 300, "bbox": [448, 651, 746, 916], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The 2D time series view showing the number of water molecules in the protein active site in the MD simulation consisting of 100,000 time steps without (a) and with (b) smoothing and active thresholds. The blue and red lines denote the upper and bottom threshold value, respectively. ", "caption_bbox": [428, 931, 762, 1005]}, {"image_id": 4, "file_name": "841_04.png", "page": 7, "dpi": 300, "bbox": [414, 101, 765, 500], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The min combination of the ligand speed (top) and its thresholded distance (middle) to the protein surface suppressing unimportant parts of the simulation where the ligand was not in- side the protein. It is obvious that the high peaks from the original function representing the ligand speed (top) were removed, allow- ing the before insignificant changes to the ligand speed inside the protein to become more prominent. ", "caption_bbox": [428, 513, 762, 617]}, {"image_id": 5, "file_name": "841_05.png", "page": 8, "dpi": 300, "bbox": [427, 326, 764, 507], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualization of all water molecules present in the sim- ulation of DhaA (PDB entry 4E46) (a) and our proposed fo- cus+context visualization (b) depicting only water molecules inside the protein. ", "caption_bbox": [427, 521, 761, 580]}, {"image_id": 6, "file_name": "841_06.png", "page": 9, "dpi": 300, "bbox": [62, 483, 399, 602], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Residue 149 of DhaA (PDB entry 4E46) (left) moves to the back (right) when the ligand (TCP substrate) enters the tunnel. ", "caption_bbox": [63, 613, 397, 641]}, {"image_id": 7, "file_name": "841_07.png", "page": 10, "dpi": 300, "bbox": [61, 101, 755, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The superimposed 2D plots of the three ligands (gray \u2013 distance to active site) and tunnel cost (red): from time step 16,000 to \u223c 30,000, there is at least one ligand close to the active site and the tunnel cost is low (left blue box). It increases as the ligands leave again (time steps 30,000 to 32,000) and drops again afterwards, when two ligands move back towards the active site (right blue box). At the beginning of the simulation (time step 5,000 to 12,000, yellow box), the tunnel cost is low even though there is no ligand close to the active site, which could be caused by the presence of water molecules. ", "caption_bbox": [62, 276, 761, 350]}], "842": [{"image_id": 0, "file_name": "842_00.png", "page": 1, "dpi": 300, "bbox": [66, 424, 761, 640], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Pipeline overview: the proposed framework takes as input Electron Microscopy stacks representing brain cells at nanometric reso- lution, labelled structures, and glycogen energy sources. After computing volumetric absorption maps and abstract connectivity information, it provides real-time interactive visual exploration of brain structures augmented with absorption metadata ", "caption_bbox": [63, 651, 762, 694]}, {"image_id": 1, "file_name": "842_01.png", "page": 3, "dpi": 300, "bbox": [412, 101, 765, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Neurites from nanoscale reconstruction. Left: domain scientists interpret and recognize neural structures from electron micrographs. Right: manual or semiautomatic processing provides 3D reconstruction of neurites. ", "caption_bbox": [428, 300, 762, 359]}, {"image_id": 2, "file_name": "842_02.png", "page": 5, "dpi": 300, "bbox": [70, 476, 391, 626], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Absorption map computation: for each position x, we compute energy contributions from neighbor glycogen granules. We use a Russian roulette scheme for sampling density values along directions connecting x to the glycogen granules. ", "caption_bbox": [62, 637, 396, 696]}, {"image_id": 3, "file_name": "842_03.png", "page": 5, "dpi": 300, "bbox": [435, 556, 756, 699], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Absorption map: the output of computation is a volume of absorption values at the same resolution of the input EM stack. ", "caption_bbox": [428, 710, 762, 738]}, {"image_id": 4, "file_name": "842_04.png", "page": 6, "dpi": 300, "bbox": [61, 101, 415, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Glycogen and synapse distribution: spatial information about glycogen and synapse distribution can be useful to under- stand absorption pattern in the various neurites. We color map glycogen granules and synapses according to glycogen density val- ues. ", "caption_bbox": [62, 284, 396, 358]}, {"image_id": 5, "file_name": "842_05.png", "page": 6, "dpi": 300, "bbox": [65, 474, 396, 655], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Connection representation: we use a node-link 2D graph to represent the connections between the different neural structures. Edges represent synapses, while main nodes represent dendrites and axons. We also include small nodes to represent spine and boutons. We color-map all elements according to the energy absorption values \u03bbi as computed through the model in equation 1. ", "caption_bbox": [62, 666, 396, 756]}, {"image_id": 6, "file_name": "842_06.png", "page": 7, "dpi": 300, "bbox": [430, 817, 764, 914], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Spatial information: glycogen and synapses distribution provide references for highlighting the areas of interests during se- lective analysis. ", "caption_bbox": [429, 925, 763, 968]}, {"image_id": 7, "file_name": "842_07.png", "page": 7, "dpi": 300, "bbox": [412, 101, 765, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Volume view: absorption glow volumes are blended with original EM stacks (on the top), and the composed signal is mod- ulated by labelled volumes for providing 3D raycasted representa- tion of objects with absorption signals (bottom view). ", "caption_bbox": [429, 312, 763, 371]}, {"image_id": 8, "file_name": "842_08.png", "page": 7, "dpi": 300, "bbox": [65, 455, 399, 634], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visualization framework: the interactive visualization framework integrates two main views, one for real time visualiza- tion of composed volumes, and one for showing abstract layouts of neural structure connections. The GUI contains also widgets for various visualization options, and for changing transfer functions. ", "caption_bbox": [64, 645, 398, 719]}, {"image_id": 9, "file_name": "842_09.png", "page": 8, "dpi": 300, "bbox": [64, 352, 397, 540], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Graph interaction: different rendering patterns can be created by selecting objects in the graph widget. Connected objects can be selected and visualized together. ", "caption_bbox": [62, 550, 396, 593]}, {"image_id": 10, "file_name": "842_10.png", "page": 10, "dpi": 300, "bbox": [412, 101, 759, 219], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Comparison with Abstractocyte (top) [MAAB\u2217 18] and GLAM (bottom) [ABG\u2217 18]: our framework can be considered complementary to both systems, but it provides more accurate ab- sorption analysis, since the visualization uses directly EM data. Same feature visualized with both frameworks: at the top a Multi Synaptic bouton from Mouse 3 visualized with Abstractocyte (left), and with our system (right), at the bottom a dendrite from Hip- pocampus visualized with GLAM (left), and with our system (right). ", "caption_bbox": [429, 226, 763, 350]}, {"image_id": 11, "file_name": "842_11.png", "page": 10, "dpi": 300, "bbox": [61, 101, 415, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: System evaluation. Left: expert neuroscientist performs analysis sessions by using a large scale tiled display wall. Right: by using the system, domain experts can accurately track features related to a synapse and details related to glycogen derived energy fluxes. ", "caption_bbox": [63, 301, 397, 375]}, {"image_id": 12, "file_name": "842_12.png", "page": 11, "dpi": 300, "bbox": [83, 101, 765, 523], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Snapshots from data inspection: features visualized with our frameworks on datasets in table 1. In order from top left to bottom right, from mouse1 to mouse6, one frame per data set is shown. Arrows indicate specific absorption patterns recognized by domain scientists: absorption peaks in boutons (in blue), in dendrite shafts (in green), and in synapses and spines (in red). ", "caption_bbox": [62, 534, 761, 577]}], "843": [{"image_id": 0, "file_name": "843_00.png", "page": 1, "dpi": 300, "bbox": [98, 357, 726, 593], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: From an input mesh representing the surface of a vessel, our algorithm detects and segments the aneurysms in the vessel. After- wards, a report is generated including meta information on the patient as well as summaries of characteristics of the aneurysms, e.g., their widths and heights. ", "caption_bbox": [63, 608, 762, 651]}, {"image_id": 1, "file_name": "843_01.png", "page": 4, "dpi": 300, "bbox": [61, 101, 758, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of our pipeline. First, an input mesh is loaded, a data structure storing the mesh\u2019s dual edges is constructed, and the shape indices of all triangles are computed. Then, an optimization problem is solved to generate a list of candidate patches on the surface. Finally, a classifier identifies the aneurysms in the candidate list. ", "caption_bbox": [62, 236, 761, 279]}, {"image_id": 2, "file_name": "843_02.png", "page": 5, "dpi": 300, "bbox": [73, 101, 765, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Different shape index values for the depicted surface.", "caption_bbox": [251, 224, 573, 237]}, {"image_id": 3, "file_name": "843_03.png", "page": 6, "dpi": 300, "bbox": [61, 101, 760, 284], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Left the input mesh is shown. After the graph cut algorithm was applied the aneurysm was detected, but the ostium needs to be corrected. Thus, the user brushes aneurysm and vessel parts in light red and blue, respectively. The result is shown right. ", "caption_bbox": [62, 297, 761, 325]}, {"image_id": 4, "file_name": "843_04.png", "page": 7, "dpi": 300, "bbox": [439, 782, 761, 948], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Illustration of the evolution of the ostium curve during the smoothing process. The plot on the right shows the decrease of length of the ostium curve during smoothing. ", "caption_bbox": [428, 961, 762, 1004]}, {"image_id": 5, "file_name": "843_05.png", "page": 7, "dpi": 300, "bbox": [66, 778, 392, 941], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A result of the smoothing process: On the left the segmented aneurysm before and on the right after smoothing are shown. ", "caption_bbox": [62, 961, 396, 1004]}, {"image_id": 6, "file_name": "843_06.png", "page": 7, "dpi": 300, "bbox": [68, 101, 765, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Left the input mesh is shown. Based on the ostium surface, different morphological descriptors are calculated and rendered within the semi-transparent aneurysm surface. The start and endpoints of each descriptor are depicted as spheres and the connecting lines are visualized as tube. From left to right the aneurysm\u2019s height, its width, and the width of the ostium curve are shown. ", "caption_bbox": [62, 282, 761, 325]}, {"image_id": 7, "file_name": "843_07.png", "page": 9, "dpi": 300, "bbox": [70, 101, 765, 249], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Left the result by Meuschke et al. [MGW\u2217 18] is shown. The ostium curve should follow the dashed line as shown by our approach. Additionally, with our method the smaller aneurysm is detected. ", "caption_bbox": [63, 258, 762, 290]}, {"image_id": 8, "file_name": "843_08.png", "page": 10, "dpi": 300, "bbox": [64, 874, 397, 964], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The influence of the parameter \u03b3 on the results is illus- trated. The values of \u03b3 from left to right are 1, 3, 4. ", "caption_bbox": [62, 977, 396, 1006]}, {"image_id": 9, "file_name": "843_09.png", "page": 10, "dpi": 300, "bbox": [61, 101, 758, 406], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The results of our algorithm tested with different level of noise. The first row shows case 31 with an average edge length of 0.3713 and the second row shows case 37 with an average edge length of 0.3620. We randomly shifted the vertex positions along normal direction with a random value of [0, 1/2], [0, 1/3], [0, 1/4], [0, 1/5] for the column from left to right. ", "caption_bbox": [62, 424, 761, 468]}, {"image_id": 10, "file_name": "843_10.png", "page": 12, "dpi": 300, "bbox": [431, 348, 763, 511], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Results of our method tested on surface meshes ex- tracted from digital subtraction angiography image data using Slicer. ", "caption_bbox": [428, 524, 762, 567]}, {"image_id": 11, "file_name": "843_11.png", "page": 12, "dpi": 300, "bbox": [61, 101, 753, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Results when testing our system on surfaces meshes directly extracted from 3D MRA TOF image data using the Slicer software.", "caption_bbox": [63, 305, 761, 318]}, {"image_id": 12, "file_name": "843_12.png", "page": 12, "dpi": 300, "bbox": [65, 681, 396, 947], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: The results of our algorithm tested with different res- olutions of the vessel surface mesh. From top left to bottom right: meshes with 10.000, 70.000, 150.000, 200.000 triangles. ", "caption_bbox": [62, 961, 396, 1004]}], "844": [{"image_id": 0, "file_name": "844_00.png", "page": 1, "dpi": 300, "bbox": [62, 357, 765, 477], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visual analysis of a moving average routine applied to multivariate time series (here: 2 dimensions). The uncertainty information over time introduced by the pre-processing routine is fed back into the approach (heat map) and can be related to the individual dimensions. Visual comparison of multiple parameterizations (encoded with color) allows the effective optimization of steering parameters. ", "caption_bbox": [63, 488, 762, 530]}, {"image_id": 1, "file_name": "844_01.png", "page": 3, "dpi": 300, "bbox": [412, 101, 765, 187], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Two requirements for PP MVTS: adding \u201cvisual sen- sors\u201d everywhere in the pipeline, to conduct Single-Routine As- sessment (I), or Multi-Routine Assessment (II). Both interactions enable all five analysis tasks, except TO , which requires (II). ", "caption_bbox": [428, 198, 762, 255]}, {"image_id": 2, "file_name": "844_02.png", "page": 4, "dpi": 300, "bbox": [61, 101, 765, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visual-interactive tool for the creation of PP pipelines for MVTS (Usage Scenario 1). The left window shows the tool for the creation and modification of the pipeline (TC , TO ): The tree view at the left contains a structured overview of the input- processing- and visualization modules. The center of the window shows the processing flow, in this case consisting of one module for loading, six PP routines as well as two \u201cvisual sensors\u201d to interactively couple the pipeline with visualizations (TR ). The visualization module in the window at the right window shows an intermediate result of the pipeline: The juxtaposed and the dimensionality-reduced visual representation for seven dimensions of the MVTS are shown side-by-side. Both techniques enable the visual comparison of input (dark gray) and output (light gray) MVTS (TR ). In both cases, color facilitates the visual comparison of three different parameterizations (blue, light gray, orange) (TP ). Juxtaposition is preferable for the detail-rich visualizations of few dimensions whereas dimensionality reduction helps to validate changes made to all dimensions at a glance. The uncertainty visualization at the bottom (TU ) uses boxplot charts over time to scale for both: dimensions and time stamps. ", "caption_bbox": [63, 315, 762, 445]}, {"image_id": 3, "file_name": "844_03.png", "page": 5, "dpi": 300, "bbox": [62, 101, 415, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Three classes of techniques for the visual input-output comparison of MVTS. A: small multiples for every juxtaposed di- mension show input (gray) and output (black). B: superposition of multiple dimensions. The approach requires color-coding, thus, it is limited to 7 \u00b1 2 dimensions. Input-output comparison requires another visual encoding. C: dimensionality reduction of MVTS re- veals a path metaphor in 2D, allowing the visual input-output com- parison of all dimensions in a large-singles display. ", "caption_bbox": [63, 223, 397, 338]}, {"image_id": 4, "file_name": "844_04.png", "page": 7, "dpi": 300, "bbox": [412, 101, 765, 231], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Missing value replacement with an interpolation rou- tine (TR ). Zooming to an interval of 6 days for three dimensions reveals a series of missing values (red dots). The uncertainty visu- alization shows where missing values were imputed (TU ). ", "caption_bbox": [428, 241, 762, 298]}, {"image_id": 5, "file_name": "844_05.png", "page": 7, "dpi": 300, "bbox": [62, 101, 415, 219], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Overview of temporal uncertainties introduced by five routines of a pipeline (TO ). Stacking of the uncertainties of the five color-coded routines allows the uncertainty-aware analysis of indi- vidual routines as well as the overall pipeline (TU ). In the example, the most uncertainty is introduced with the moving average (or- ange), the sampling (pink), and the perceptually important points (green). Large green areas of uncertainty in the lower dimension indicate that there is room for improvement of the respective pa- rameterization (TP ). ", "caption_bbox": [63, 229, 397, 359]}, {"image_id": 6, "file_name": "844_06.png", "page": 8, "dpi": 300, "bbox": [412, 101, 764, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Calibration of the perceptual important points (PIP) al- gorithm to achieve a compact and still representative data reduc- tion (TR , TP , TU ). A single dimension was selected to demonstrate the parameter calibration. For the time interval of four days (5760 time-value pairs in the original data), the PIP algorithm requires about 100 time-value pairs to represent the signal in a perceptually similar way (overall compression of 98%). ", "caption_bbox": [428, 199, 762, 300]}, {"image_id": 7, "file_name": "844_07.png", "page": 8, "dpi": 300, "bbox": [61, 101, 415, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Assessment of the effect of a sampling routine to six se- lected dimensions (TR , TP , TD ). The Quartile Trend Chart at the bottom depicts the uncertainty for every parameterization (aggre- gated over dimensions, cf. Table 2). The blue parameterization (5 minute kernel) almost introduces no uncertainty, in contrast to con- siderable changes caused by the orange kernel (40 minutes) (TU ). ", "caption_bbox": [62, 257, 396, 343]}, {"image_id": 8, "file_name": "844_08.png", "page": 9, "dpi": 300, "bbox": [412, 101, 765, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Final pipeline applied on the longitudinal climate data set. The analyst has put two \u201cvisual sensors\u201d to the output of the OutlierTreatment and Sampling routine to facilitate the visual com- parison of different branches. Right: the comparison reveals that the outlier routine (gray) would have cut considerable parts of the peaks, which have been preserved with the final branch (white). ", "caption_bbox": [428, 271, 762, 357]}, {"image_id": 9, "file_name": "844_09.png", "page": 9, "dpi": 300, "bbox": [62, 101, 415, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Statistical outlier treatment routine working in terms of distances of standard deviations to the mean. The routine cuts low and high and peaks, regardless of the time-orientation of the data, which may be very error-prone for time-oriented data. ", "caption_bbox": [62, 246, 396, 303]}], "845": [{"image_id": 0, "file_name": "845_00.png", "page": 1, "dpi": 300, "bbox": [62, 575, 764, 769], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The concept of ChronoCorrelator: enable users to combine both event sequences and time series to discover correlations between the two using a visual analytics approach and enable them to filter, group and inspect events on the fly. ", "caption_bbox": [62, 539, 761, 567]}, {"image_id": 1, "file_name": "845_01.png", "page": 4, "dpi": 300, "bbox": [61, 101, 754, 504], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The main user interface of ChronoCorrelator: (A) Scented widgets to quickly filter out events; (B) Detail view; (C) A density plot showing the global density of events, as well as a legend for the correlation results; (D) Beneath the density plot: the shared time axis; (E) Event sequence; (F) Time series, represented by simple line charts; (G) Collapsed time series, event sequences; (H) A correlation result, showing events, time series and glyphs in a common chart. A summary is shown in the chart description to the left; (I) Search bar allows searching for events containing specific values; (J) Inset: the parameter GUI shown to select correlation settings. ", "caption_bbox": [62, 510, 764, 584]}, {"image_id": 2, "file_name": "845_02.png", "page": 5, "dpi": 300, "bbox": [412, 101, 765, 382], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Sampling approach shown for a single event and window size k = 4. \u0393front takes the four preceding entries from the time series, \u0393rear takes the four entries following the event and for \u0398 entries are randomly sampled from the entire time series. This forms three samples of length k. One directly preceding the event, one directly following it and one bootstrapped from the entire time series. ", "caption_bbox": [428, 394, 764, 483]}, {"image_id": 3, "file_name": "845_03.png", "page": 7, "dpi": 300, "bbox": [66, 101, 765, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Glyphs used to convey correlation, direction and effect. The results are displayed over a combined display of the time series, in gray, and the event sequence (colored diamonds) beneath it. Results are encoded into flag-like glyphs. Images: (a) shows a correlation where an event is followed by a positive increase in the time series. The local correlation is in agreement with the global correlation. (b) An event following a drop in the time series. Again, both local and global scores agree. (c) An event where both \u0393front and \u0393rear differ significantly globally from the rest of the time series, however for the event shown we are unable to detect a local correlation, hence the gray color. ", "caption_bbox": [63, 309, 762, 383]}, {"image_id": 4, "file_name": "845_04.png", "page": 8, "dpi": 300, "bbox": [61, 101, 415, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Legend for the color scale used in the application.", "caption_bbox": [77, 265, 381, 278]}, {"image_id": 5, "file_name": "845_05.png", "page": 8, "dpi": 300, "bbox": [297, 777, 765, 1004], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Evolution of the glyph design.", "caption_bbox": [311, 1008, 514, 1021]}, {"image_id": 6, "file_name": "845_06.png", "page": 9, "dpi": 300, "bbox": [412, 101, 769, 1000], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Server administration example, showing several steps in the exploration. ", "caption_bbox": [424, 1006, 758, 1034]}, {"image_id": 7, "file_name": "845_07.png", "page": 9, "dpi": 300, "bbox": [59, 101, 415, 176], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Summary view example, global (circles) and local (stacked bars) results are not in agreement. ", "caption_bbox": [58, 181, 393, 209]}], "846": [{"image_id": 0, "file_name": "846_00.png", "page": 1, "dpi": 300, "bbox": [62, 843, 764, 1077], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A three-component summarized line graph showing Nasdaq stock prices of the transportation industry in the air freight/delivery service during 2016 (21 stocks over a year). The tan line is the representative data: an average curve providing the mean value for the entire summarized dataset. Along the time axis, analytical highlights are shown as ranges, trends, correlations, outliers, and key moments called out using dotted lines and triangles; red triangles represent the absolute minimums of each line, and blue triangles the absolute maximums. Finally, the light blue bands in the background provide the data envelope representing the data distribution over the entire time. ", "caption_bbox": [62, 764, 764, 838]}, {"image_id": 1, "file_name": "846_01.png", "page": 6, "dpi": 300, "bbox": [412, 101, 764, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An alternative summarized line graph design using corre- lation analytical highlights, showing the number of reports for 30 crime subcategories from the city of Seattle between 2008 and 2018. ", "caption_bbox": [428, 301, 764, 344]}, {"image_id": 2, "file_name": "846_02.png", "page": 7, "dpi": 300, "bbox": [83, 101, 765, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Examples of the five visualization techniques and the four tasks used in the study: identifying the original graph using a band graph (left), identifying the overall trend using a stream graph (top center), identifying the overall trend using a traditional line graph (top right), identifying the outlier using a summarized line graph (bottom center), and locating the key moment using a horizon graph (bottom right). ", "caption_bbox": [61, 441, 763, 484]}, {"image_id": 3, "file_name": "846_03.png", "page": 9, "dpi": 300, "bbox": [198, 504, 687, 614], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: 95% confidence interval plots for the different techniques in accuracy (left) and completion time (right).", "caption_bbox": [126, 641, 697, 654]}, {"image_id": 4, "file_name": "846_04.png", "page": 9, "dpi": 300, "bbox": [142, 101, 765, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: 95% confidence interval plots of the study results in accuracy (left) and completion time (right) separated by task and technique.", "caption_bbox": [65, 450, 759, 463]}], "847": [{"image_id": 0, "file_name": "847_00.png", "page": 3, "dpi": 300, "bbox": [501, 328, 691, 471], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The term rainbow color map can refer to a variety of spectral schemes that do not necessarily suffer from the same prob- lems to the same extent. Notable examples include: (a) the tradi- tional rainbow color map (truncated at blue), (b) Gresh\u2019s perceptu- ally linearized rainbow, (c) the jet color map popularized by MAT- LAB , (d) the traditional rainbow color map (cycling to magenta), (e) the rainbow color map specified by matplotlib, (f) Kindlmann\u2019s isoluminant rainbow, and (g) the Kindlmann color map. ", "caption_bbox": [428, 476, 762, 596]}, {"image_id": 1, "file_name": "847_01.png", "page": 3, "dpi": 300, "bbox": [136, 101, 765, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Campbell-Robson contrast sensitivity charts visualized using (a) grayscale, (b) the traditional rainbow color map, (c) Gresh\u2019s perceptually linearized rainbow, (d) the jet color map, and (e) the Kindlmann color map show pronounced differences in the extents to which rainbow color maps capture data variation. In each image, spatial frequency increases left to right, and contrast increases bottom to top. ", "caption_bbox": [62, 273, 761, 316]}, {"image_id": 2, "file_name": "847_02.png", "page": 5, "dpi": 300, "bbox": [117, 101, 765, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The CIELCh lightness (L*), chroma (C*), and hue (h) profiles for the four color maps we looked at in our exploratory study, with dotted and dashed lines showing the derived locations of cusps and inflection points. ", "caption_bbox": [63, 315, 762, 343]}, {"image_id": 3, "file_name": "847_03.png", "page": 5, "dpi": 300, "bbox": [474, 351, 717, 674], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Experimental stimuli encoding a linear ramp, a radial gradient, and a complex 2D geospatial dataset using four color maps: (a)-(c) the traditional rainbow, (d)-(f) jet, (g)-(i) the Kindl- mann color map, and (j)-(l) perceptual grayscale. ", "caption_bbox": [428, 679, 762, 738]}, {"image_id": 4, "file_name": "847_04.png", "page": 6, "dpi": 300, "bbox": [412, 101, 716, 325], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Deriving the chroma (C*) indicators for the traditional rainbow color map: (upper) the cubic spline approximation of the chroma profile, (center) the derived gradient magnitude, and (bot- tom) the derived curvature magnitude. Horizontal lines show the thresholds used to isolate the cusps and inflection points, which are represented by the vertical lines overlaid on the chroma profile. ", "caption_bbox": [428, 327, 762, 416]}, {"image_id": 5, "file_name": "847_05.png", "page": 6, "dpi": 300, "bbox": [487, 431, 704, 556], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Two fundamentally different response patterns illustrated for the salient cyan feature in the traditional rainbow color map using the study\u2019s boundary placement interface: (a) treating the feature as an explicit boundary vs. (b) treating the feature as a pro- totype subsumed by a larger color category. ", "caption_bbox": [428, 563, 762, 637]}, {"image_id": 6, "file_name": "847_06.png", "page": 7, "dpi": 300, "bbox": [412, 101, 765, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The mean number of delineations that participants per- ceived and/or placed along with the 95% confidence interval for each color map and dataset. Descriptive statistical analysis indi- cates that each rainbow color map elicited significantly more de- lineations than grayscale, that the 1D dataset elicited significantly more delineations than the complex dataset, and that there were significant color-map:dataset interactions. ", "caption_bbox": [427, 307, 761, 411]}, {"image_id": 7, "file_name": "847_07.png", "page": 8, "dpi": 300, "bbox": [61, 101, 415, 461], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Probability density functions fit to the participants\u2019 col- lective delimiter placements, partitioned by wording condition, color map, and dataset. Peaks highlight clusters in participants\u2019 re- sponses for all three rainbow color maps across all three datasets. Participants\u2019 greyscale responses also show a few larger clusters but, overall, are more uniformly distributed. ", "caption_bbox": [63, 478, 397, 567]}, {"image_id": 8, "file_name": "847_08.png", "page": 9, "dpi": 300, "bbox": [144, 101, 765, 455], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: An overview of participants\u2019 delimiter placements in the 1D experimental stimuli. In the top and bottom plots, each row of marks contains the delimiters placed by a single participant with participants ordered along the y-axis by the average number of delimiters they placed overall. For each rainbow color map stimuli, dotted lines show the locations of cusps (top) and inflection points (bottom), with corresponding bands showing the expected individual variation for color category boundaries [WK12]. The same indicators are also overlaid on the pdfs (center) estimated from the delimiters. Convenience labels (a)-(n) are included for indicators referred to in the text. For the grayscale stimuli, dotted lines mark the locations of color map artifacts, with doubled values corresponding to a large response cluster. ", "caption_bbox": [62, 459, 761, 548]}, {"image_id": 9, "file_name": "847_09.png", "page": 10, "dpi": 300, "bbox": [423, 101, 753, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The probability density plots of participants\u2019 de- limiter placements for both the jet and Kindlmann stimuli also exhibit significant variation in participants\u2019 response trends across all three datasets. Notable differences between the adjacent plots are marked with a \u2022 symbol. ", "caption_bbox": [458, 393, 760, 467]}, {"image_id": 10, "file_name": "847_10.png", "page": 10, "dpi": 300, "bbox": [61, 101, 459, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: An overview of participants\u2019 boundary placements within the traditional rainbow color map stimuli, showing changes in participants\u2019 response trends across the different datasets. Contrary to expectations, the changes include noticeable shifts in responses between 1D and 2D. Further, the underlying data features in the complex dataset appear to have had minimal impact on participants\u2019 responses. Convenience labels (a)-(d) are included for specific indicators referred to in the text. ", "caption_bbox": [63, 360, 424, 464]}], "848": [{"image_id": 0, "file_name": "848_00.png", "page": 2, "dpi": 300, "bbox": [412, 101, 707, 323], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Character based visualization of the expression tree for                  j the expression \u03b4i Xak + Xdc \u03b4d j \u03b4cb \u03b4bk                                       ia as used by the developer of the matrix calculus algorithm. Here, indices are represented by num- bers. ", "caption_bbox": [428, 340, 762, 399]}, {"image_id": 1, "file_name": "848_01.png", "page": 3, "dpi": 300, "bbox": [89, 616, 368, 762], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Possible tensor diagrams for the Kempe invariant. In contrast to its algebraic expression, it is obvious from the tensor diagrams that the invariant is a scalar, since there are no arrows without a source or target. Also, from the tensor diagrams one sees immediately that the Kempe invariant is highly symmetric (left) and bipartite (right). ", "caption_bbox": [62, 787, 396, 876]}, {"image_id": 2, "file_name": "848_02.png", "page": 3, "dpi": 300, "bbox": [447, 380, 742, 436], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Projective incidences encoded by vanishing tensor dia- grams, where elementary tensors are drawn as disks. From left to right: point pi on line li , three incident points pi , q j , rk , and three lines li , m j , nk that intersect in a common point. The black third or- der tensors that appear in the latter two diagrams are the totally antisymmetric \u03b5-tensors \u03b5i jk and \u03b5i jk , respectively. ", "caption_bbox": [428, 460, 762, 550]}, {"image_id": 3, "file_name": "848_03.png", "page": 5, "dpi": 300, "bbox": [82, 308, 380, 516], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The expression tree for the objective function of the lo- gistic regression problem. Tensor nodes are shown in orange, oper- ator nodes in gray, and index nodes in different colors for different indices. ", "caption_bbox": [63, 532, 397, 591]}, {"image_id": 4, "file_name": "848_04.png", "page": 6, "dpi": 300, "bbox": [61, 101, 699, 479], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The transformation rules for three node types of an expression tree (here subtrees of the expression tree for the logistic regression example). Tensor nodes are shown in orange, index nodes in light blue and in green, operator nodes in gray, and nil nodes in black. Empty nodes are represented by empty disks. Expression tree nodes are shown in the top row, their transformation into an index network in the middle row, and their rendering as a tensor diagram in the bottom row. The color coding of tensors, operators and indices/edges is kept consistent over the transformation steps. ", "caption_bbox": [63, 497, 762, 571]}, {"image_id": 5, "file_name": "848_05.png", "page": 6, "dpi": 300, "bbox": [71, 609, 391, 685], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Graphical elements (from left to right): (1) The result of the inner product of the vector w and the second order tensor X is again a vector (first order tensor). (2) The outer product of the vectors w and y is a second order tensor with two contravariant components. (3) The unary exp function applied to the second or- der tensor X. (4) Entrywise addition of the two vectors (first order tensors) w and y. ", "caption_bbox": [63, 706, 397, 810]}, {"image_id": 6, "file_name": "848_06.png", "page": 7, "dpi": 300, "bbox": [147, 533, 315, 689], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Tensor network representation of the logistic regression problem. Comparing the diagram with the corresponding vector- ized expression in Section 3 shows that the sum is realized in the diagram as a dot product with the all ones vector 1 . ", "caption_bbox": [62, 706, 396, 765]}, {"image_id": 7, "file_name": "848_07.png", "page": 7, "dpi": 300, "bbox": [434, 285, 763, 443], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Extracted common subexpressions (or collapsed subex- pressions) can be explored by clicking on them in the left pane that shows the full tensor diagram. The selected (highlighted) common subexpression (or collapsed subexpression) is shown in the right pane. Here the common subexpression CSE0 has been expanded on the right pane. ", "caption_bbox": [427, 458, 761, 547]}, {"image_id": 8, "file_name": "848_08.png", "page": 8, "dpi": 300, "bbox": [412, 101, 717, 367], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Tensor diagrams of two non-matching subexpressions that were computed as intermediate results by the matrix calculus algorithm while computing the derivative for the softmax regres- sion problem. The (common) subexpressions that have been fac- tored out by the user are shown in Figure 10. The problem here is that the index structure suggests two inner products, one through index i and the other through the index l. But in the expression the two tensors are actually combined by an entrywise multiplication which is not supported by the index structure. ", "caption_bbox": [428, 379, 762, 514]}, {"image_id": 9, "file_name": "848_09.png", "page": 8, "dpi": 300, "bbox": [427, 531, 754, 679], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Common subexpressions of the two non-matching subexpressions for the softmax regression example. ", "caption_bbox": [428, 691, 762, 719]}, {"image_id": 10, "file_name": "848_10.png", "page": 9, "dpi": 300, "bbox": [412, 101, 765, 320], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: The core of the display exception problem for second order tensors shown in a tensor diagram and the corresponding expression tree. The critical index i in the tensor digram and 0 in the expression tree, respectively, is more localized in the tensor dia- gram. The tensor triangle in the tensor diagram shown on top leads to the solution shown in the tensor diagram at the bottom. The lo- calization of the critical index was crucial for the solution. ", "caption_bbox": [428, 348, 762, 452]}, {"image_id": 11, "file_name": "848_11.png", "page": 9, "dpi": 300, "bbox": [71, 101, 415, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: On top, the tensor diagram of one of the two subexpres- sions that could not be combined before index flipping. Comparing this diagram to the corresponding diagram in Figure 9 shows that collapsing non-relevant subexpressions makes the diagram more legible. At the bottom, the tensor diagram of the correct combina- tion of the two subexpressions by an entrywise multiplication after index flipping via two \u03b4-tensors. ", "caption_bbox": [62, 475, 396, 580]}, {"image_id": 12, "file_name": "848_12.png", "page": 10, "dpi": 300, "bbox": [89, 205, 381, 438], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: The essence of the index matching problem in form of tensor diagrams and expression trees, respectively. The problem was a missing rule for partially entrywise multiplying the two ten- sors over the shared index k in the tensor diagrams, and 0, respec- tively, in the expression trees. Note that here only part of a much larger expression is shown that has been reduced to this example by collapsing non-relevant subexpressions in the tensor diagram. ", "caption_bbox": [63, 450, 397, 554]}], "849": [{"image_id": 0, "file_name": "849_00.png", "page": 1, "dpi": 300, "bbox": [442, 767, 749, 931], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A topological skeleton of a 2D slice from a stress tensor field. The background texture is aligned to the eigenvector fields. Left: the red and blue lines represent the full topological skeleton of the major and minor eigenvector fields. Right: the structure of the field that one would like to extract, here sketched by hand. ", "caption_bbox": [427, 939, 761, 1013]}, {"image_id": 1, "file_name": "849_01.png", "page": 3, "dpi": 300, "bbox": [450, 298, 738, 619], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Typical structure of the eigenvector field in the vicinity of degenerate points for linear tensor fields. The winding number of a degenerate point counts the number of rotations when circling once around the degenerate point. In the linear case, degenerate points have a winding number of \u00b11/2. Top: a trisector with wind- ", "caption_bbox": [428, 631, 762, 714]}, {"image_id": 2, "file_name": "849_02.png", "page": 4, "dpi": 300, "bbox": [130, 687, 332, 885], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Geometric interpretation of an r-perturbation of a tensor field at a point x in the space of tensors. The gray plane represents the deviatoric space D 2 with tr(T ) = 0, \u2200T \u2208 T 2 . If a tensor T 0 ", "caption_bbox": [63, 897, 397, 950]}, {"image_id": 3, "file_name": "849_03.png", "page": 4, "dpi": 300, "bbox": [462, 416, 732, 504], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Map a tensor field to an anisotropy vector field via a projection p and an isometry \u2126 between a deviator field and an anisotropy vector field. ", "caption_bbox": [429, 514, 763, 557]}, {"image_id": 4, "file_name": "849_04.png", "page": 5, "dpi": 300, "bbox": [431, 504, 768, 749], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Left: Fr denotes the sublevel sets of the tensor anisotropy. The set F0 is the set of all degenerate points of the field. Right: Given a r-perturbation h, then the set of degenerate points of h is a subset of the levelset Fr . ", "caption_bbox": [431, 757, 765, 821]}, {"image_id": 5, "file_name": "849_05.png", "page": 5, "dpi": 300, "bbox": [66, 126, 405, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: An analytically defined tensor field (left) and its corre- sponding anisotropy vector field (right) displayed using a texture visualization. The degenerate points from the tensor field on the left correspond to the critical points from the vector field on the right. A trisector (white dot) on the left is transformed into a saddle point on the right. A wedge point (black dot) on the left becomes a source or a sink on the right. ", "caption_bbox": [66, 291, 400, 395]}, {"image_id": 6, "file_name": "849_06.png", "page": 5, "dpi": 300, "bbox": [431, 128, 768, 396], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Left: A texture representation of the major eigenvector field of a tensor field T overlaid with red dots marking the degen- erate points of T. Right: Perturbing the field T has resulted in a tensor field T0 whose degenerate points in blue are overlaid with the texture of T. ", "caption_bbox": [431, 406, 765, 483]}, {"image_id": 7, "file_name": "849_07.png", "page": 7, "dpi": 300, "bbox": [96, 669, 365, 754], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The detection and classification of degenerate cells is based on edge labels encoding the rotation direction of the eigen- vectors. The labels are computed only once to ensure a consistent detection of degenerate cells. ", "caption_bbox": [62, 765, 396, 824]}, {"image_id": 8, "file_name": "849_08.png", "page": 7, "dpi": 300, "bbox": [101, 124, 366, 532], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Interpolation schemes between two tensors T1 and T2 . (a) Component-wise interpolation. (b) Feature-based interpola- tion, which decouples directions from eigenvalues. Note that the component-wise interpolated field changes continuously at T (.5) when one of the tensor changes from T2 to T20 and to T200 , respec- tively; whereas the feature-based interpolated field introduces dis- continuities. ", "caption_bbox": [62, 540, 396, 644]}, {"image_id": 9, "file_name": "849_09.png", "page": 8, "dpi": 300, "bbox": [106, 125, 340, 450], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Direction encoding edge labels allows simple detection and classification of degenerate cells. (a) For a triangle without a degenerate point, the rotation directions along the edges differ, resulting in different edge labels for the edges. (b) For a degenerate triangle containing a wedge point, the rotation along all edges is the same and thus all edge labels have the same sign. ", "caption_bbox": [63, 458, 397, 547]}, {"image_id": 10, "file_name": "849_10.png", "page": 9, "dpi": 300, "bbox": [81, 125, 770, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: (a) Two adjacent triangles, each containing a degenerate point. The field is defined by liner interpolation of tensor components for the tensors given in the vertices. The robustness of the degenerate points is low due to a low anisotropy value on the edge e. (b) Applying a small perturbation to the tensor at vertex P, the degenerate points cancel each other and disappear. (c) The quadratic behavior of the anisotropy in the two adjacent cells in (a) is shown as colored height field (brown means low and turquoise means high value, respectively). The light green triangles on top show the linearly interpolated anisotropy in these triangles. However, in this case, the computation leads to incorrect, high robustness for the degenerate points. (d) When applying a subdivision of the triangles around local minima, the piecewise linear anisotropy interpolation results in correct robustness values in (e). (e) The triangles on top demonstrate the behavior of the linearly interpolated anisotropy. ", "caption_bbox": [63, 305, 762, 425]}, {"image_id": 11, "file_name": "849_11.png", "page": 10, "dpi": 300, "bbox": [69, 127, 762, 666], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: (a) and (c): Two tensor fields, Variant I / II, are generated as a composition of six isolated degenerate points. The two fields differ only in the anisotropy of two generating tensors, as shown in blue in (c). The two tensor fields are visualized with texture in (e) and (f). For each field, the contours related to the cancellation of two degenerate points are highlighted. The anisotropy is shown for Variant I. ", "caption_bbox": [61, 674, 760, 717]}, {"image_id": 12, "file_name": "849_12.png", "page": 11, "dpi": 300, "bbox": [74, 127, 767, 619], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Visualization of the robustness of a slice of a stress tensor field. (a) A single slice of the data embedded in a 3D context visualized using volume rendering. (b) A textured slice with degenerate cells. White triangles represent trisectors and black ones represent wedges. Degenerate points in each cell are visualized with a brown-to-turquoise colormap. Degenerate points with infinite robustness are in red. (c) The full merge tree. (d) A close-up of the upper right region of (b) with numbered degenerate points. (e) The merge tree encoding the pairwise cancellation of the degenerate points in (d); it is also geometrically embedded in the domain of (d). ", "caption_bbox": [66, 626, 765, 700]}, {"image_id": 13, "file_name": "849_13.png", "page": 12, "dpi": 300, "bbox": [61, 101, 730, 649], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: A slice of a diffusion tensor imaging data set. (a) 3D context visualization using volume rendering of the anisotropy. (b) The histogram of the robustness values of degenerate points. (c) All degenerate cells are color-coded according to their robustness values. (d) Most robust degenerate cells are highlighted in turquoise. ", "caption_bbox": [62, 656, 761, 699]}], "850": [{"image_id": 0, "file_name": "850_00.png", "page": 4, "dpi": 300, "bbox": [412, 101, 670, 208], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The normal velocity r of a time-dependent surface.", "caption_bbox": [441, 233, 747, 246]}, {"image_id": 1, "file_name": "850_01.png", "page": 7, "dpi": 300, "bbox": [412, 101, 765, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Three visualizations of the same 2D tensor ensemble: as points in the vector space of tensor components s = v(S), the red point denotes the mean tensor S\u0304 (left); as overlaid superquadric glyph curves (center); as uncertain glyph: mean G(S\u0304) is depicted as orange curve, the filled region is bounded by the outward/inward offset curves defined by q (right). ", "caption_bbox": [427, 287, 761, 376]}, {"image_id": 2, "file_name": "850_02.png", "page": 7, "dpi": 300, "bbox": [72, 101, 415, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) For an increasing number of samples on G, uniqueness u increases. The experiment shows random samples on the tensor v(S\u0304) = (1, 0.5, 0.4, 0, 0, 0)T . For both choices of Q we observe a converging behavior of u. (b) Uniqueness u(G) for different mean tensors using [GRT17a]. \u03bb1 = 1 is fixed, and \u03bb2 , \u03bb3 \u2208 [\u22121, 1] vary. The tensor is unique, if u(G) 6= 0. ", "caption_bbox": [61, 270, 399, 359]}, {"image_id": 3, "file_name": "850_03.png", "page": 7, "dpi": 300, "bbox": [453, 396, 744, 487], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Four different sets of tensor samples. Each set consists of 5 tensors that are generated by varying the eigenvalues (with constant eigenvectors). The top row shows overlaid superquadric glyphs. The bottom row shows our corresponding uncertain glyphs. ", "caption_bbox": [427, 508, 761, 567]}, {"image_id": 4, "file_name": "850_04.png", "page": 7, "dpi": 300, "bbox": [440, 585, 751, 683], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Five different sets of tensor samples. Each set consists of 5 tensors that are generated by varying the direction of eigen- vectors (with constant eigenvalues). The top row shows overlaid superquadric glyphs. The bottom row shows our corresponding uncertain glyphs. ", "caption_bbox": [427, 698, 764, 772]}, {"image_id": 5, "file_name": "850_05.png", "page": 7, "dpi": 300, "bbox": [430, 790, 759, 857], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Glyphs for uncertain tensor with v(S\u0304) = (1, 0.8, 0.5, 0, 0, 0)T , C = diag(0, 0, 0.2, 0, 0, 0). The ten- sor varies in one principal direction. From left: ellipsoid glyph with u(G) = 0, superquadric glyph with u(G) \u2248 9.1 \u00b7 10\u22124 , glyph by [GRT17a] with u(G) \u2248 1 \u00b7 10\u22124 . ", "caption_bbox": [427, 871, 764, 947]}, {"image_id": 6, "file_name": "850_06.png", "page": 8, "dpi": 300, "bbox": [73, 512, 380, 580], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Glyphs for uncertain tensor                                    \uf8eb with ", "caption_bbox": [62, 597, 278, 610]}, {"image_id": 7, "file_name": "850_07.png", "page": 8, "dpi": 300, "bbox": [68, 309, 379, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Glyphs for uncertain tensor with indefinite mean v(S\u0304) = (1, 0.6, \u22120.5, 0, 0, 0)T and C = diag(0, 0.65, 0.03, 0, 0, 0). The tensor varies in one principal direction. Left: su- perquadric glyph with u(G) \u2248 1.5 \u00b7 10\u22124 . Right: glyph by [GRT17a] with u(G) \u2248 3 \u00b7 10\u22126 . (There exists no ellipsoid glyphs in the indefinite case.) ", "caption_bbox": [61, 402, 399, 491]}, {"image_id": 8, "file_name": "850_08.png", "page": 8, "dpi": 300, "bbox": [61, 101, 415, 193], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Glyphs for uncertain tensor with v(S\u0304) = (0.9, 0.7, 0.3, 0, 0, 0)T and covariance that corresponds to varying plane rotation of eigenvectors. From left: ellipsoid glyph with u(G) = 0, superquadric glyph with u(G) \u2248 3.4 \u00b7 10\u22124 , glyph by [GRT17a] with u(G) \u2248 2 \u00b7 10\u22126 . ", "caption_bbox": [62, 208, 399, 284]}, {"image_id": 9, "file_name": "850_09.png", "page": 9, "dpi": 300, "bbox": [63, 101, 765, 325], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Uncertain superquadric glyphs for an ensemble of Diffusion Tensor Imaging data of the human brain.", "caption_bbox": [128, 340, 695, 353]}, {"image_id": 10, "file_name": "850_10.png", "page": 9, "dpi": 300, "bbox": [83, 583, 378, 725], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Uncertain superquadric glyphs for an ensemble of simu- lated stress tensors from changing torque applied to a steel cylinder. The colors indicate the signs of eigenvalues, the transparent offset surfaces indicate uncertainty. ", "caption_bbox": [61, 746, 399, 805]}, {"image_id": 11, "file_name": "850_11.png", "page": 9, "dpi": 300, "bbox": [101, 388, 364, 490], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Top: Linear blending of zero matrix and traceless matrix. Bottom: Linear blending of traceless matrix and original covariance matrix. ", "caption_bbox": [62, 505, 399, 548]}, {"image_id": 12, "file_name": "850_12.png", "page": 10, "dpi": 300, "bbox": [61, 101, 415, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Three different uncertain tensors visualized by our method (top row) and [BP07] (bottom row). While our method clearly shows different glyphs, the glyphs by [BP07] are identi- cal: [BP07] is not unique. ", "caption_bbox": [62, 327, 399, 386]}, {"image_id": 13, "file_name": "850_13.png", "page": 11, "dpi": 300, "bbox": [59, 399, 768, 1052], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Two almost identical uncertain tensors having almost identical glyphs by our method ((a) and (c)) but significantly different glyphs in the visualizations of [AWHS16] ((b) and (d)): [AWHS16] is not continuous. ", "caption_bbox": [60, 337, 759, 365]}, {"image_id": 14, "file_name": "850_14.png", "page": 12, "dpi": 300, "bbox": [113, 847, 338, 949], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: The proof of theorem 2 involves two functions that must not vanish iff M has full rank. The plots visualize f1 (left) and f1 (right) for \u03bb1 = 1 in the range \u03bb2 \u2208 [0, 1] and \u03b3 \u2208 [0, 2] ", "caption_bbox": [61, 961, 396, 1005]}], "851": [{"image_id": 0, "file_name": "851_00.png", "page": 2, "dpi": 300, "bbox": [412, 101, 760, 283], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Simple 1D example. (a) Function in domain \u2126 repre- sentation, with boundary points B1 and B2 , silhouette points S1 and S2 , projected boundaries B11 and B12 , projected silhouette S1 , multiplicities (circled), and equivalent regions (letters). (b) Corre- sponding representation in codomain \u03a8, illustrating \u201cfolding\u201d. ", "caption_bbox": [428, 294, 762, 369]}, {"image_id": 1, "file_name": "851_01.png", "page": 3, "dpi": 300, "bbox": [63, 101, 415, 652], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Mapping u(x) (R2 \u2192 R2 ) in domain (left column) and codomain (right column). (a) Field in domain representa- tion. Space by arrow position, value by arrow orientation/length. (b) Field in codomain representation, showing only value, due to varying cardinality of preimage. Mapping u(x) maps domain manifold (c) to codomain, i.e., distorts and \u201cfolds\u201d it (d), lead- ing to varying number of \u201clayers\u201d, i.e., multiplicities \u00b5(u) (f). As previously shown [LT10], silhouette curves (green) and boundary curves (red) ((d) and (e)) separate regions of uniform \u00b5(u). ", "caption_bbox": [63, 660, 397, 800]}, {"image_id": 2, "file_name": "851_02.png", "page": 3, "dpi": 300, "bbox": [412, 101, 765, 652], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Mapping from Figure 2, same color-coding. (a) Multi- plicity \u00b5 mapped to domain (from Figure 2f). Silhouette curves S and boundary curves B (Figure 2e) do not separate regions of uni- form \u00b5(x). (b) \u201cProjection\u201d of S (blue) and B (orange) on manifold \u201clayers\u201d (see also (d)). (c) Projected S and B from (b) separate re- gions of uniform \u00b5(x) in domain. (f) Uniform regions extracted in codomain from S and B (Figure 2f), and uniform regions extracted in domain from projected S, projected B, and B (e). Equivalent region correspondence by colors ((e) and (f)). ", "caption_bbox": [428, 664, 762, 799]}, {"image_id": 3, "file_name": "851_03.png", "page": 5, "dpi": 300, "bbox": [63, 101, 765, 478], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Mapping from Figure 2. ((a) and (b)) Same as Figure 3e and 3f, but with arrow glyphs and point correspondences (1)\u2013(10). ((d) and (e)) Equivalent regions (ii) from (a) and (b). (c) Equivalent regions that exhibit symmetry lines (green curves). ", "caption_bbox": [63, 489, 762, 518]}, {"image_id": 4, "file_name": "851_04.png", "page": 6, "dpi": 300, "bbox": [61, 101, 415, 646], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparative visualization of mapping from Figure 2 ((a) and (c)), and a similar field ((b) and (d)). ((a) and (b)) LIC [CL93], with higher magnitudes by brighter colors (see (c) and (d) for flow orientation). Equivalent regions in domain ((c) and (d)), and in the common codomain (f), obtained from merged representation (e). ", "caption_bbox": [62, 657, 396, 731]}, {"image_id": 5, "file_name": "851_05.png", "page": 6, "dpi": 300, "bbox": [412, 101, 764, 646], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Same as Figure 5, but with more different field ((b) and (d)). Comparison of (f) with Figure 5f, and (c) and (d) with Fig- ure 5c and 5d shows more white regions, i.e., less equivalence. ", "caption_bbox": [428, 657, 762, 701]}, {"image_id": 6, "file_name": "851_06.png", "page": 7, "dpi": 300, "bbox": [412, 101, 765, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Mapping from Figure 2. (a) Smallest closed loops ex- tracted from silhouettes and boundaries in codomain split at inter- sections, and each loop triangulated, provides regions in codomain (Figure 3f). (b) Projected silhouettes, projected boundaries, and edges of original grid, in domain. (c) Triangulation of (b) and com- puting correspondences provides regions in domain (Figure 3e). ", "caption_bbox": [428, 253, 762, 343]}, {"image_id": 7, "file_name": "851_07.png", "page": 8, "dpi": 300, "bbox": [61, 101, 763, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Interaction techniques. Domain (left) and codomain (right). (a) Point-based exploration, including isolines. (b) Region-based exploration. (c) Mapping between domain and codomain by animation, revealing folding etc. (see accompanying video). ", "caption_bbox": [65, 250, 764, 279]}, {"image_id": 8, "file_name": "851_08.png", "page": 9, "dpi": 300, "bbox": [412, 101, 765, 628], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: K\u00e1rm\u00e1n flow around obstacle (white disc). Vortic- ity \u03c9(x) (a) and pressure p(x) (b) in domain. Multiplicity in do- main (c) and codomain (f). Equivalent regions in domain (d) and codomain (g). Selected regions in domain (e) and codomain (h). ", "caption_bbox": [428, 639, 762, 698]}, {"image_id": 9, "file_name": "851_09.png", "page": 10, "dpi": 300, "bbox": [61, 101, 415, 621], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Case from Figure 9, but smoothed with \u03c3 = 6. Vortic- ity (a), pressure (b), multiplicity (c), and equivalent regions (d) in domain. Multiplicity (e) and equivalent regions (f) in codomain. ", "caption_bbox": [63, 631, 397, 676]}, {"image_id": 10, "file_name": "851_10.png", "page": 10, "dpi": 300, "bbox": [412, 101, 765, 373], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Investigation of robustness by application to time se- ries of case from Figure 10. (c) Same as Figure 10d, together with preceding time step (b), and time step (a) preceding that step. ", "caption_bbox": [428, 384, 762, 428]}, {"image_id": 11, "file_name": "851_11.png", "page": 11, "dpi": 300, "bbox": [63, 101, 765, 713], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Climate Zones example based on averaged temperature and precipitation from 1979 until 2015, with Gaussian smoothing with \u03c3 = 4 ((a)\u2013(c) and (g)\u2013(i)), and with \u03c3 = 14 ((d)\u2013(f) and (j)\u2013(l)). Temperature \u03c4(x) ((a), (d)), precipitation \u03c1(x) ((b), (e)), multiplicity in domain ((c), (f)), equivalent regions in domain ((g), (j)), multiplicity in codomain ((h), (k)), and equivalent regions in codomain ((i), (l)). ", "caption_bbox": [63, 723, 762, 767]}, {"image_id": 12, "file_name": "851_12.png", "page": 12, "dpi": 300, "bbox": [61, 101, 764, 501], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Dataset sizes, and timings (computations in codomain \u03a8 / domain \u2126), measured on an Intel Core i5-6300HQ CPU (2.30 GHz). Timings are only given for the CPU-based im- plementation. The shader alternative, which replaces the computa- tions in \u2126, takes 0.51 s for refresh for the K\u00e1rm\u00e1n dataset. ", "caption_bbox": [428, 812, 762, 887]}], "852": [{"image_id": 0, "file_name": "852_00.png", "page": 5, "dpi": 300, "bbox": [412, 101, 765, 664], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: When rendering lines into a heat map using the graph- ics pipeline, perceptually significant inaccuracies can occur in the result due to varying numbers of pixels used by lines of different orientation. Top) A table showing the relative number of pixels by angle. This was computed by rendering many lines at different an- gles and then counting the non-zero pixels. Second from top) A de- piction of the problem: each of the three lines are drawn with the same number of pixels even though they have different distances. Bottom left) The rendering artifact: when rendering the time av- eraged particle density heat map using lines, without accounting                                                                    \u25e6 for angle, the regions where the particle paths are nearer to 45 are under sampled (producing the x-shaped darker region). Bottom middle) lines are used and the artifact is corrected. Bottom right) Points are rendered without interpolation. ", "caption_bbox": [428, 676, 762, 888]}, {"image_id": 1, "file_name": "852_01.png", "page": 5, "dpi": 300, "bbox": [77, 101, 415, 758], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Examples of the aggregated phase plots described in Sec- tion 4.2. These plots represent particle statistics from a Tokamak dataset. The axes are vk and \u03c8N . The dataset and variables are de- scribed in Section 6.1. A) shows time averaged particle density. B) shows path/curve density. C) shows weighted particle density (us- ing the simulation weights from XGC). D, E, F, G, and H) show mean, min, max, and range and variance of v\u22a5 respectively. The color maps are shown at the bottom of the figure. For plot C a di- vergent color map that is centered at 0 is used, since the particle weights can be negative. The other plots are colored based on the upper most color legend at the bottom of the figure. In both cases, darker means high magnitude. ", "caption_bbox": [63, 770, 397, 950]}, {"image_id": 2, "file_name": "852_02.png", "page": 6, "dpi": 300, "bbox": [78, 259, 381, 780], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Examples of interactive lenses used in our design. Top row) an aggregate phase plot showing momentum (p) vs. radius (r) from a particle accelerator simulation. The dataset and vari- ables are described in Section 6.2. Faint features in the plot on the left are brought out by a color-map localization lens (middle and right). Middle row) a kinetic energy (Ek ) vs. \u03c8N plot from a Toka- mak simulation. Direction change events are plotted over it (green points). A \"de-occlude\" lens is used (right) to look through the plot- ted points. Bottom row) mean v\u22a5 in (w0 \u00d7 w1) vs. \u03c8N space from a Tokamak fusion simulation (Section 6.1). A subset representing particles with lower energy is shown in the forefront, while the ex- tent of the full data is in the background. An interactive lens (right) brings the aggregation of the full data to the forefront for compari- son. ", "caption_bbox": [63, 790, 397, 1001]}, {"image_id": 3, "file_name": "852_03.png", "page": 7, "dpi": 300, "bbox": [68, 101, 765, 531], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An interface for our Focus+Context visualization scheme. A) subsets, events, and Boolean combinations are managed. B) a layout for multiple linked phase space visualizations. C) a timeline view. D) 1D density plots for each active variable. E) groups of trajectories populate a list of IDs from which to select individual trajectories. The trajectories of the listed particles are plotted in dark gray, while the selected trajectory is plotted in bright green. While not shown in this view, the distance plots are optionally computed from the selected trajectory and added into the phase space plot layout. ", "caption_bbox": [63, 542, 762, 616]}, {"image_id": 4, "file_name": "852_04.png", "page": 8, "dpi": 300, "bbox": [433, 286, 760, 495], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Computation times for the aggregate plots. On the hor- izontal axis is number of data elements, (time-steps \u00d7 particles). D refers to number density, P refers to path density, and W refers to weighted density. Since each of these had very similar computa- tion times, we averaged them into one curve. Also, the min and max times were averaged. The time to compute a Boolean combination,  fC = (A \\ ((B \u2229C \u2229 D)4E)) \u222a F is shown as well. ", "caption_bbox": [428, 510, 762, 614]}, {"image_id": 5, "file_name": "852_05.png", "page": 9, "dpi": 300, "bbox": [442, 737, 747, 850], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Top) an ILC 8-Cavity Cryomodule particle accelerator. Bottom Right) a 9-cell cavity (image courtesy of the Linear Col- lider Collaboration). The irises are the regions between the cells. Bottom left) a full cryomodule assembly (image courtesy of the Lin- ear Collider Collaboration). ", "caption_bbox": [428, 863, 762, 937]}, {"image_id": 6, "file_name": "852_06.png", "page": 9, "dpi": 300, "bbox": [77, 616, 382, 751], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A Tokamak device. Left) A cross section of the device showing examples of trapped and passing particles. The 3D trajec- tories are also projected onto the 2D poloidal plane (white). Right) An inside look at a real Tokamak (image courtesy EUROfusion). ", "caption_bbox": [63, 763, 397, 822]}, {"image_id": 7, "file_name": "852_07.png", "page": 9, "dpi": 300, "bbox": [412, 101, 765, 621], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Annotated screenshot frames from a visualization session with the XGCa dataset. The plots in the left column are in vk vs w0 \u00d7 w1 space, while the plots in the right column are in vk vs \u03c8N space. The blue arrows are used to point out action applied through the interface and the associated visual elements. The figure is explained in detail in Section 6.1 ", "caption_bbox": [428, 631, 762, 720]}, {"image_id": 8, "file_name": "852_08.png", "page": 10, "dpi": 300, "bbox": [61, 101, 756, 323], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Trajectories of electrons (from the accelerator dataset) in r-z space (Section 6.2). A) the cavity in which the particles are emitted is enclosed in the purple rectangle. B) manually selecting the \u2018long range right\u2019 trajectories (those which reach the end of the full assembly on the right side). The selection radius is the small inner red circle, and the resulting selection of trajectories is plotted in dark gray. The bold outer red circles have been added to the figure to help make it more clear where selections were made. C) selecting the \u2018long range left\u2019 trajectories in the same manner. Both the \u2018long range right\u2019 and \u2018long range left\u2019 trajectories are exported to saved subsets so that they can be plotted as heatmaps and used in other Boolean combinations. D) after changing the focused Boolean combination to the \u2018long range left\u2019 subset, a manual selection, from these trajectories, was made, just past the right side of the cavity that the particles were emitted from. This selects the particles which escape the initial cavity in the opposite direction before turning around and becoming \u2018long range left\u2019 trajectories. E) a zoomed in view before exporting this selection to a saved subset. An individual trajectory is highlighted in green. ", "caption_bbox": [63, 333, 762, 468]}, {"image_id": 9, "file_name": "852_09.png", "page": 11, "dpi": 300, "bbox": [78, 480, 381, 776], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Probing groups of trajectories (dark gray) of long range particles emitted from the 5th iris in a cryomodule cavity, and then exploring different individual trajectories around conditions from which outcomes diverge (green). The region targeted by the selec- tion tool is within the small red circle. Each of the green trajecto- ries in the 3 plots were emitted from nearby locations in the same iris. Particles emitted from this region appear to diverge based on small differences in their initial location. The trajectory highlighted in the top plot diverges, turning left. The trajectory highlighted in the middle plot stays right at first, but is then diverted near one of iris 8, and turns around. The trajectory in the bottom plot follows almost the same course as the one in the middle plot, except right after turning around near iris 8, it again changes direction and then stays right for the rest of the simulation. ", "caption_bbox": [63, 788, 397, 999]}], "853": [{"image_id": 0, "file_name": "853_00.png", "page": 1, "dpi": 300, "bbox": [62, 592, 763, 832], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: We developed a novel CNN-based reference frame extraction algorithm that is trained to handle inputs with noise and resampling artifacts. Compared to a linear reference frame optimization [GGT17], our method is more robust to artifacts. The input vector field (w/ and w/o noise) is shown on the left, and the extraction of vortex centers (orange and yellow), compared to a ground truth (blue) is shown on the right. By combining filtering and reference frame extraction via CNNs, vortex extraction becomes more robust. Note that in the experiment above, the CNN has not seen the cylinder flow during training. In fact, it only trained on a synthetic data base that we introduce in the paper. ", "caption_bbox": [62, 494, 761, 568]}, {"image_id": 1, "file_name": "853_01.png", "page": 4, "dpi": 300, "bbox": [62, 783, 398, 911], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Plot of common vortex velocity profiles. Starting from the center, the tangential velocity increases up until a certain maximum (here at rc = 1). Afterwards, it decays with increasing distance. The Vatistas model [VKM91] contains Kaufmann [Kau62] for n = 1 and Rankine for n \u2192 \u221e as special cases. For n = 2, Vatistas is similar to the Lamb-Oseen model [Ose12]. ", "caption_bbox": [61, 916, 396, 1005]}, {"image_id": 2, "file_name": "853_02.png", "page": 5, "dpi": 300, "bbox": [427, 820, 756, 950], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Our CNN Architecture. The numbers below each box represent the dimension of feature maps. ", "caption_bbox": [427, 965, 761, 993]}, {"image_id": 3, "file_name": "853_03.png", "page": 6, "dpi": 300, "bbox": [61, 101, 415, 496], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Examples of training data pairs. From left to right, steady field, transformed unsteady field and distorted field. You can see some spots on magnitude plots of degenerated flows. ", "caption_bbox": [63, 508, 397, 551]}, {"image_id": 4, "file_name": "853_04.png", "page": 7, "dpi": 300, "bbox": [69, 101, 415, 446], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Results of vortex extraction on test splits. The numbers in parenthesis are MSE, and our method robustly handles degenerated flows where linear optimization method fails. ", "caption_bbox": [61, 457, 395, 500]}, {"image_id": 5, "file_name": "853_05.png", "page": 9, "dpi": 300, "bbox": [430, 351, 760, 608], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Common parameters for data synthesis and analysis.", "caption_bbox": [438, 992, 750, 1005]}, {"image_id": 6, "file_name": "853_06.png", "page": 9, "dpi": 300, "bbox": [64, 351, 396, 481], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Heat maps of the fitting residual for different vector field distance functions. The mean relative distances are 0.2028, 0.1947 and 0.1906, from top to bottom. ", "caption_bbox": [62, 493, 396, 536]}, {"image_id": 7, "file_name": "853_07.png", "page": 9, "dpi": 300, "bbox": [64, 101, 765, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Heat maps of the fitting residual in the B OUSSINESQ data set for varying number of mixture model components m. ", "caption_bbox": [427, 620, 761, 648]}], "854": [{"image_id": 0, "file_name": "854_00.png", "page": 2, "dpi": 300, "bbox": [413, 101, 766, 381], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Schematic of fiber characterization pipelines: A spec- imen (a) is scanned via computed tomography, the scanned pro- jection images (b) are reconstructed to a 3D volume (c), which is segmented (d). The characteristics of each fiber (e) are quantified either from the segmented data or from the projection images. ", "caption_bbox": [429, 391, 763, 465]}, {"image_id": 1, "file_name": "854_01.png", "page": 4, "dpi": 300, "bbox": [63, 399, 400, 1011], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Fiber characteristics (a): Start point sa , center point ca , end point ea , length la , diameter da . Overlap-based dissimilarity measure computation (b): Points in reference are sampled, checked for inclusion in result fiber, result is the ratio between included and total. ", "caption_bbox": [63, 269, 397, 343]}, {"image_id": 2, "file_name": "854_02.png", "page": 5, "dpi": 300, "bbox": [62, 101, 765, 491], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The main interface of FIAKER consists of a list of all results (a), a spatial view displaying one or more results (b), which in this case is color coded by the value of the d3o measure for each fiber. The iteration step chart (c) provides details on the progression of iterative refinement algorithms. The scatter plot matrix (d) provides details on the characteristics of each single fiber. A selection view (e), an interaction protocol (f) and a settings widget (g) provide additional information and control where required. ", "caption_bbox": [62, 502, 761, 561]}, {"image_id": 3, "file_name": "854_03.png", "page": 6, "dpi": 300, "bbox": [61, 101, 415, 493], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: FIAKER workflow: Input data (a) is loaded, then a ref- erence is set (b), fibers in other results are matched to the reference (c), and finally exploration starts with the result list and spatial overview visualizations (d). ", "caption_bbox": [64, 503, 398, 562]}, {"image_id": 4, "file_name": "854_04.png", "page": 7, "dpi": 300, "bbox": [62, 101, 415, 603], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Fibers of the synthetic dataset, color-coded by dissimi- larity to reference (a); the color-mapping is given in the distribu- tion chart (b). Fibers with the worst reference match are selected in the scatter plot (c). The long vertical fiber in the middle (green) and its development over the iterations is analyzed in the 3D view in comparison to closest reference fibers (grayish-violet) as well as in the iteration steps chart (d). ", "caption_bbox": [62, 612, 396, 716]}, {"image_id": 5, "file_name": "854_05.png", "page": 8, "dpi": 300, "bbox": [412, 101, 762, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: List of results computed with PARE. Results lower in the list were computed from input data containing higher levels of noise. This is reflected in the average length difference to the ref- erence (a), which increases with higher noise as well as the distri- bution of d3o across the fibers of each result (b), which is flattening with higher noise. ", "caption_bbox": [426, 407, 760, 496]}, {"image_id": 6, "file_name": "854_06.png", "page": 8, "dpi": 300, "bbox": [60, 101, 415, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Worst-case examples for dissimilarity measures. d2c matches fibers similar in angle and length but at a different po-                     p                                                 p sition (a), while d3 matches a more suitable, shorter fiber (b). d3 fails for another fiber where it prefers a close position-wise match with no overlap (c), where d3o prefers a shorter fiber with overlap (d). However, the highest scoring fiber for d3o is also among the first                          p four best matches for d3 (e). ", "caption_bbox": [61, 352, 395, 456]}, {"image_id": 7, "file_name": "854_07.png", "page": 9, "dpi": 300, "bbox": [63, 101, 413, 640], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Fiber characterization results computed from CT scans with different resolutions, the resolution decreases with positions further down in the list (a), reference is the last item, highlighted in gray. The reference is color coded by the match quality (b), the color map is on the left. Selections: Shortest fibers in the lowest- resolution result (c), Five worst-matching fibers in the lowest (d) and second-lowest (e) resolution results, the color map for (c-e) is encoded in the histograms in (a) ", "caption_bbox": [63, 650, 397, 770]}, {"image_id": 8, "file_name": "854_08.png", "page": 10, "dpi": 300, "bbox": [61, 101, 413, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Pore characterization results loaded in FIAKER", "caption_bbox": [83, 252, 376, 265]}], "855": [{"image_id": 0, "file_name": "855_00.png", "page": 1, "dpi": 300, "bbox": [62, 703, 764, 837], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Vortex core manifolds (blue) in higher dimensions. 1-vortex core manifolds in 3D (a), 4D (b), and 5D (c), are one-, two-, and three-dimensional, while a 2-vortex core manifold in 5D is one-dimensional (d). The latter has two planes of rotation (orange and green streamlines), i.e., a streamline seeded in between them exhibits a rotation within two planes of rotations simultaneously (magenta streamline). ", "caption_bbox": [63, 658, 762, 702]}, {"image_id": 1, "file_name": "855_01.png", "page": 5, "dpi": 300, "bbox": [65, 101, 765, 595], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Triangulation of dependent vectors solution manifolds. Case k = 1 in 2D (a)\u2013(b), 3D (c)\u2013(d), and 4D (e)\u2013(f) results in lines, case k = 2 in 3D (g)\u2013(i) and 4D (j)\u2013(l) results in surfaces, and case k = 3 in 4D (m)\u2013(p) results in volumes. Points (red dots) on codimension k faces (blue) are connected to lines (red lines), and further to triangles and tetrahedra (in the cases k = 2 and k = 3, respectively), by inserting points at the centers of masses (white dots) of the previous steps. The 4D cases are shown in 3D perspective projection. Currently active faces in each step are marked blue, with lines for 1-faces, quads for 2-faces, transparent cubes for 3-faces, and lines (wireframe) for 4-faces. ", "caption_bbox": [64, 603, 763, 678]}, {"image_id": 2, "file_name": "855_02.png", "page": 8, "dpi": 300, "bbox": [415, 101, 766, 459], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Details and computational cost of the datasets. Listed are the sizes of the regular grids, the number of processed cell faces, and the number of initial solution points. Timings for computing the derivatives on (all) grid nodes (Deriv.), the dependent vectors operator (DV), filtering (F), triangulation (T), and total computation times (\u03a3). The timings of the triangulation step include the removal of unused vertices. ", "caption_bbox": [63, 812, 762, 856]}, {"image_id": 3, "file_name": "855_03.png", "page": 9, "dpi": 300, "bbox": [63, 101, 765, 510], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: 4D phase space of a double pendulum (h), with bifurcation manifolds (red), and vortex core manifolds (blue) (see Figure 3). The trajectories of the pendulum in Euclidean coordinates are shown for selected seeds, offset in direction of the major eigenvector on a bifurcation manifold (I) (a),(d), and offset within the complex eigenplane on a vortex core manifold (II) (b),(e). Trajectories not near a bifurcation or vortex core manifold ((c),(f), magenta and yellow) exhibit behavior different than near one (a),(b). A trajectory near one of the curved vortex core manifolds ((c), green) diverges from it, while its second arm (\u03b82 ) performs full rotations (g). The colored streamlines started from the circled seeds in (a)\u2013(c) correspond to the motion of the pendulum in Euclidean space, shown in the same color (d)\u2013(g). Temporal positions of the pendulum are indicated by saturation (older are less saturated), and the paths of the second mass by dashed lines. ", "caption_bbox": [62, 517, 761, 622]}, {"image_id": 4, "file_name": "855_04.png", "page": 10, "dpi": 300, "bbox": [414, 101, 758, 418], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Vortex core surfaces in the space-time domain of a flow behind an obstacle in the time range 0.60 s to 0.62 s. Projection into the spatial domain (x red, y green, z blue axis), with time colored in shades of blue. Swirling particle cores [WSTH07] are extracted in each time slice and tracked (a) within our framework. Vortex core surfaces extracted by the DV operator in the 4D space-time domain results in noisy raw solutions (b), which requires stronger filters (c). ", "caption_bbox": [428, 427, 762, 532]}, {"image_id": 5, "file_name": "855_05.png", "page": 10, "dpi": 300, "bbox": [61, 101, 415, 355], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Recirculation surface of the 2D double gyre in space- time view (x red, y green, time blue axis). The fourth coordinate of the surface, advection time, is shown in shades of blue. Points on this surface in 4D correspond to parameters (x,t, \u03c4) of a path- line. Randomly chosen points on this manifold, together with their pathlines in their starting time slices, are shown in different colors. ", "caption_bbox": [63, 372, 397, 462]}, {"image_id": 6, "file_name": "855_06.png", "page": 11, "dpi": 300, "bbox": [62, 101, 414, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Tracking of critical points by means of valley lines of velocity magnitude in the 4D space-time domain of the Convective Flow. Critical points extracted in each time step ((a), spheres) are tracked in the time interval [50, 55]s (saturation) by valley lines ((b), tubes). Vortex core manifolds are shown for context (surfaces). ", "caption_bbox": [62, 290, 396, 364]}], "856": [{"image_id": 0, "file_name": "856_00.png", "page": 1, "dpi": 300, "bbox": [134, 379, 693, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview of our pipeline enabling visualizing data for visually impaired users. A barchart stored as a raster image is retrieved from the web. Our pipeline automatically detects the chart type, extracts the shapes, recovers the substrate, and parses the labels. The data are extracted as a data table, which can then be used for several purposes (from the top): with a screen reader for a visually impaired person, re-visualized for a sighted person, or as raw data for a search engine. ", "caption_bbox": [63, 549, 762, 608]}, {"image_id": 1, "file_name": "856_01.png", "page": 4, "dpi": 300, "bbox": [61, 101, 761, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of our automatic pipeline for extracting chart data, in this case for a bar chart. (1) We first classify the input image, and (2) extract labels in the chart with their values and roles. (3) Next, we extract basic graphical elements, such as rectangles, lines, etc, using our object detection model. (4) Finally, we reconstruct data values and visual encoding. ", "caption_bbox": [62, 274, 761, 317]}, {"image_id": 2, "file_name": "856_02.png", "page": 5, "dpi": 300, "bbox": [412, 101, 765, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: FigureQA example composed of chart images with anno- tated data and their types as well as labels and bounding boxes. ", "caption_bbox": [427, 289, 761, 317]}, {"image_id": 3, "file_name": "856_03.png", "page": 6, "dpi": 300, "bbox": [61, 101, 415, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Data extraction for a bar chart. Our method first detects bars and finds the baseline coordinate. Next, it determines the tick value, the tick span, and the conversion rate from a single pixel to the data value. We then convert the height of bars into values. ", "caption_bbox": [63, 306, 397, 365]}, {"image_id": 4, "file_name": "856_04.png", "page": 6, "dpi": 300, "bbox": [412, 101, 764, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Data extraction for a pie chart. We first convert the ex- tracted patches into gray scale. Next, we find the most frequent col- ors for each patch. We then crop the circle and obtain its pixel col- ors. Finally, we calculate the color distribution from the histogram. ", "caption_bbox": [428, 345, 762, 404]}, {"image_id": 5, "file_name": "856_05.png", "page": 7, "dpi": 300, "bbox": [433, 377, 760, 647], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Example of a generated data table from a chart image. The data table can be read through text-to-speech conversion by screen reader tool or played with a third-party sonification tool. ", "caption_bbox": [428, 657, 762, 700]}, {"image_id": 6, "file_name": "856_06.png", "page": 7, "dpi": 300, "bbox": [64, 101, 765, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Line chart data extraction process. We count pixels with respect to tick value. Next, we find the baseline of the chart. We then convert pixels into HSV and find the most frequent color values. We calculate the distance of the x-tick and a line. ", "caption_bbox": [63, 310, 762, 338]}, {"image_id": 7, "file_name": "856_07.png", "page": 8, "dpi": 300, "bbox": [61, 101, 415, 473], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Text detection results for both datasets.", "caption_bbox": [473, 500, 716, 513]}, {"image_id": 8, "file_name": "856_08.png", "page": 9, "dpi": 300, "bbox": [70, 305, 395, 570], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Common examples of data extraction failure. Object de- tection errors, text classification errors, and text detection errors account for 21.6%, 49.7%, and 29.7% of total number of errors. Most errors occur in low resolution images. ", "caption_bbox": [62, 581, 396, 640]}], "857": [{"image_id": 0, "file_name": "857_00.png", "page": 1, "dpi": 300, "bbox": [131, 386, 694, 623], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: SurgeryCuts allows to create arbitrary cuts on maps for additional canvas area. This example shows two cuts in different size and orientation. The outlined area is the area affected by distortion. The inset explains the interactive configuration and creation of a cut. ", "caption_bbox": [62, 634, 761, 662]}, {"image_id": 1, "file_name": "857_01.png", "page": 2, "dpi": 300, "bbox": [61, 101, 740, 390], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A comparison of techniques related to SurgeryCuts and examples for each kind of approach.", "caption_bbox": [155, 406, 668, 419]}, {"image_id": 2, "file_name": "857_02.png", "page": 4, "dpi": 300, "bbox": [61, 101, 710, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Five different shapes for the cut expansion. The distortion is orthogonal to the cutline, the length of the arrows indicates the amount of space available to distribute the amount of distortion. The arrangement of the arrows indicates breaking points in the amount of distortion introduced. Longer arrows indicate more space to distribute the distortion, thus introducing less intense changes on the map. ", "caption_bbox": [62, 343, 761, 386]}, {"image_id": 3, "file_name": "857_03.png", "page": 5, "dpi": 300, "bbox": [490, 540, 707, 668], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A lenticular SurgeryCut. The yellow area represents the distorted space, the inner white area represents the additional can- vas area, ACA, produced by the cut, while the rest of the space is unchanged. Distortion is not constant: for \u03b2 = \u03b1 is 0 and for \u03b2 = 0 it exhibits the maximum value. ", "caption_bbox": [429, 680, 765, 754]}, {"image_id": 4, "file_name": "857_04.png", "page": 7, "dpi": 300, "bbox": [412, 101, 765, 206], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparing SurgeryCuts with SpaceCuts.", "caption_bbox": [465, 218, 724, 231]}, {"image_id": 5, "file_name": "857_05.png", "page": 7, "dpi": 300, "bbox": [510, 641, 681, 797], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Comparing SurgeryCuts with Route-Zooming. The back- ground image has been taken from [SLQW17]. ", "caption_bbox": [427, 808, 763, 836]}, {"image_id": 6, "file_name": "857_06.png", "page": 8, "dpi": 300, "bbox": [412, 101, 767, 735], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Applying SurgeryCuts to a power distribution network: all the multi-node glyphs of sub-networks are accommodated in specific cuts, keeping both the whole network and contextual information visible. A detail of one of the glyph is magnified in the bottom-right corner. Being the inserted information a square matrix we used a trapezoid-shape cut that better fits w.r.t. the lenticular-shape ", "caption_bbox": [429, 746, 763, 835]}, {"image_id": 7, "file_name": "857_07.png", "page": 9, "dpi": 300, "bbox": [412, 101, 765, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Effectiveness, completion time, and efficiency of the participants. The box-plot on the left shows the distribution of the average scores obtained by counting participants\u2019 correct answers and normalizing that value to 10. The box-plot on the middle depicts the distribution of the average time spent to complete the experiment (in minutes). The box-plot on the right illustrates the ratio score/time. ", "caption_bbox": [427, 275, 762, 364]}, {"image_id": 8, "file_name": "857_08.png", "page": 9, "dpi": 300, "bbox": [70, 779, 390, 907], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The Milan subway exits labeled with names and list of the buses they are close to (using the same font size of the map labels and minimizing occlusion). The resulting clutter makes hard to read exit names and buses information (see the bottom left part of the image). A dashed ellipse shows the cut location and size; displaying the textual information on that area will hide 5 subway exits. ", "caption_bbox": [62, 919, 396, 1008]}, {"image_id": 9, "file_name": "857_09.png", "page": 9, "dpi": 300, "bbox": [70, 551, 390, 679], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The Milan Duomo subway exits labeled within a cut, together with additional information about adjacent bus stops. The textual information is linked to exits locations through blue lines, making easy to locate shops and other facilities. ", "caption_bbox": [62, 690, 398, 749]}], "858": [{"image_id": 0, "file_name": "858_00.png", "page": 3, "dpi": 300, "bbox": [65, 101, 765, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Experiment 2: collecting pairwise judgments on how much scatterplots are clustered                                                        Use: Compare ClustMe and other VQMs vs Human pairwise ranks Figure 1: Experiment 1: (1) The space of possible                         grouping patterns \u0398 is defined by a bivariate Gaussian Mixture Model (GMM) with 2                                                                   Which is more     257 pictures            30 pictures - 435 pairs components.      (2) 1000 scatterplots       Xi are generated           by the GMM \u0398i . (3)                                                           structured/clustered/clumpy?               34 human subjects H are asked to judge if they see 1 or moreVanbelle                                                                                                  ClustMe                                                                                                                                                                                       than 1                                                                              i                                                                           Hsep    . (4) 7 merging techniques Mm are run to evaluate each                                              Kappa cluster for each Xi giving a probability of separation                                                                                                       \u2026 scatterplot (\u0398i , Xi ) giving                                                              31       \u201cLeft\u201d                                                                                \u201cRight\u201d                                                                                                                                              >                                  > matches                 >                                                                                                                         to find the merging technique >         Mvs sep that=best                                                                                                                                                                     \u2217 a separation decision Misep . (5) Both, human and machine decisions(8,9)                           are (7,9)                                                                                                         compared                                                                                                              (7,7) (6,9) (5,5) (4,5) (3,7) (2,8) (2,6) (1,3)                                                                                                                                                                                       +0.8 the human judgment Samplingwith the Mathew Correlation                                                     Judge            Coefficient       and   the Vanbelle Kappa index. The result of this process is our VQM ClustMe.                                                                                        Evaluate                                       \u2026                             \u201cSame\u201d                                                                                 \u201cLeft\u201d                                                                                                  Other VQMs (Clumpiness, X-means, CLIQUE, DBSCAN) (6) ClustMe can then be used to automatically quantify grouping patterns in new scatterplots (red frame): it runs a GMM for which we find the optimal number of components MBIC according to the Bayesian Information Criterion                                      > (BIC). Then, we\u2026 use the          vs best =   > M                                                                                                                                                                             merger     -0.6\u2217                                                                                                                                                                                            sep   >        >                                                                                                  0.87  0.79  0.78components                                                                                                                     0.67 0.54 0.52to0.43   0.42   0.39 0.23 approximating the human perception to decide about=merging                >    >        pairs   of  the M   BIC                         get  the  final   number  of  clusters C. The    pair (C, MBIC ) defines the ClustMe Visual Quality Measure of the scatterplot. ClustMe VQM allows ranking scatterplots based on the complexity of their grouping patterns. ", "caption_bbox": [63, 307, 762, 466]}, {"image_id": 1, "file_name": "858_01.png", "page": 6, "dpi": 300, "bbox": [61, 101, 415, 403], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Subset of the 1000 scatterplots judged by the 34 human subjects with the percentage of human raters (Hsep ) judging they display more than a single cluster. ", "caption_bbox": [60, 412, 394, 455]}, {"image_id": 2, "file_name": "858_02.png", "page": 7, "dpi": 300, "bbox": [412, 101, 765, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Left: median and variance bootstrap estimate of the Matthews Correlation Coefficient (MCC) accuracy of each merg- ing technique decision Mmrg to predict the human merging deci- sion Hmrg from Experiment 1. Demp is the most accurate model of the human merging decision. Right: from top to bottom, example of an original scatterplot, points assigned to color-coded components of the BIC-optimal GMM, and ClustMe output after merging with Demp. ", "caption_bbox": [427, 364, 761, 484]}, {"image_id": 3, "file_name": "858_03.png", "page": 8, "dpi": 300, "bbox": [71, 352, 398, 683], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The 30 scatterplots randomly picked from the 257 bench- mark data used for gathering human judegments in Experiment 2. ", "caption_bbox": [63, 691, 397, 719]}, {"image_id": 4, "file_name": "858_04.png", "page": 8, "dpi": 300, "bbox": [61, 101, 760, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Experiment 2: 31 human subjects decide which one of two scatterplots is more structured/clustered/clumpy for 435 pairs built from 30 out of 257 real and synthetic yet unseen scatterplots. The agreement between ClustMe, Clumpiness, X-means, CLIQUE, and DBSCAN rankings of these 435 pairs to the human rankings is evaluated with Vanbelle\u2019s Kappa index. ", "caption_bbox": [63, 287, 762, 331]}, {"image_id": 5, "file_name": "858_05.png", "page": 9, "dpi": 300, "bbox": [412, 101, 765, 276], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: ClustMe computing time in seconds per number of points N in the scatterplot for all 257 benchmark scatterplots (Left) and zoom in on the ones with less than 4000 points (Right). The com- puting time is roughly linear with the number of points ", "caption_bbox": [428, 287, 762, 346]}, {"image_id": 6, "file_name": "858_06.png", "page": 9, "dpi": 300, "bbox": [73, 101, 415, 331], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Top: Number of subjects selecting equal complexity for a given proportion of the 435 trials. Bottom: Vanbelle Kappa in- dex results from Experiment 2 with agreement interpretation as per Landis and Koch [LK77]. ", "caption_bbox": [62, 342, 396, 401]}, {"image_id": 7, "file_name": "858_07.png", "page": 10, "dpi": 300, "bbox": [61, 101, 415, 927], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Top 7 and bottom 7 of the 257 scatterplots ranked with ClustMe, Clumpiness, the best settings of CLIQUE and DBSCAN, and X-means. The actual rank is displayed in the corner of the pic- tures, equally-ranked plots are displayed in random order. ", "caption_bbox": [62, 950, 396, 1009]}], "859": [{"image_id": 0, "file_name": "859_00.png", "page": 1, "dpi": 300, "bbox": [62, 833, 764, 1077], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Understanding and interpreting outliers of the Wine dataset using Oui: (A) a Data Table showing raw data and allowing quick searching; (B) a Data Overview displaying an overview of the whole dataset including both outliers and normal data; (C) an Algorithm Matrix View displaying the diverse sets of outliers detected by different algorithms as well as the similarities between these outlier sets; (D) a Value Distribution View allowing users to understand and interpret outliers by showing the attribute values of outliers and statistics of each dimension in diverse contexts. ", "caption_bbox": [63, 757, 762, 831]}, {"image_id": 1, "file_name": "859_01.png", "page": 5, "dpi": 300, "bbox": [64, 101, 415, 269], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visual encoding of the Algorithm Matrix View: (a) the default mode that displays the outliers detected by a single al- gorithm and different algorithm combinations and (b) the outlier score mode that displays outlier score distribution of each algo- rithm. ", "caption_bbox": [62, 277, 396, 351]}, {"image_id": 2, "file_name": "859_02.png", "page": 6, "dpi": 300, "bbox": [61, 101, 415, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visual encoding of the Value Distribution View in (a) the absolute position mode and (b) the relative position mode. The con- text component is a violin diagram that illustrates the statistics and distribution of the context on a dimension; The outlier component part utilizes divergent bar charts to display the values and devia- tions of the selected outliers. ", "caption_bbox": [63, 347, 397, 436]}, {"image_id": 3, "file_name": "859_03.png", "page": 7, "dpi": 300, "bbox": [65, 101, 415, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Examining wine 147 in the Value Distribution View: (a) the context is the whole dataset; (b) the context is the selected local neighborhood points of wine 147. ", "caption_bbox": [62, 306, 396, 349]}, {"image_id": 4, "file_name": "859_04.png", "page": 9, "dpi": 300, "bbox": [441, 396, 751, 568], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Average completion times for each task. Error bars show 95% confidence intervals (n = 12). ", "caption_bbox": [428, 571, 762, 600]}], "860": [{"image_id": 0, "file_name": "860_00.png", "page": 3, "dpi": 300, "bbox": [75, 101, 765, 617], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The seven recommendations (B-H) in our interface for alleviating over-plotting problems in the (A) specified scatterplots.", "caption_bbox": [83, 633, 742, 646]}, {"image_id": 1, "file_name": "860_01.png", "page": 4, "dpi": 300, "bbox": [412, 101, 765, 323], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Overall interface of the modified PoleStar [WQM\u2217 17] with the recommendation interface: (A) data panel, (B) encoding panel, (C) specified view, (D) pinned view, and (E) recommendation interface. ", "caption_bbox": [427, 332, 761, 395]}, {"image_id": 2, "file_name": "860_02.png", "page": 4, "dpi": 300, "bbox": [61, 101, 415, 376], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Three representation methods for a visualization recom- mendation: (A) Preview, (B) Animated Transition on mouse hover, and (C1-4) Textual Description. ", "caption_bbox": [62, 401, 396, 444]}, {"image_id": 3, "file_name": "860_03.png", "page": 5, "dpi": 300, "bbox": [66, 101, 415, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Configuration interfaces for recommendations: (A) tog- gle button for Represent Points Using Outlines and Represent Den- sity of Points Using Color, (B) nominal field picker for Aggregate Points To Mean Position and Separate Graph By Category, (C) cat- egory picker for Filter By Category, and (D) slider bar for Change Point Size and Change Point Opacity. ", "caption_bbox": [61, 325, 395, 414]}, {"image_id": 4, "file_name": "860_04.png", "page": 5, "dpi": 300, "bbox": [412, 101, 765, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Three combinations of representation methods used in our study: (A) Preview + Title (PT), (B) PT + Animated Transition (PTA), and (C) PTA + remaining Textual Description (PTAT). ", "caption_bbox": [427, 311, 761, 354]}, {"image_id": 5, "file_name": "860_05.png", "page": 7, "dpi": 300, "bbox": [72, 101, 765, 618], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Scatterplots constructed by the participants in our study in response to Question 1 to 6. Each scatterplot is labelled with the name of recommendations which are used to make the visualization. Recommendation names are abbreviated: 1) Filter By Category, 2) Change Point Opacity, 3) Change Point Size, 4) Represent Points Using Outlines, 5) Aggregate Points To Mean Position, 6) Separate Graph By Category, and 7) Represent Density of Points Using Color. The number in parentheses represents the number of participants who constructed the visualizations. ", "caption_bbox": [62, 640, 761, 714]}, {"image_id": 6, "file_name": "860_06.png", "page": 8, "dpi": 300, "bbox": [429, 799, 764, 957], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The number of times recommendations were chosen by their order during the task. ", "caption_bbox": [427, 970, 761, 998]}], "861": [{"image_id": 0, "file_name": "861_00.png", "page": 1, "dpi": 300, "bbox": [62, 813, 764, 1077], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The proposed EMA visual analytics workflow for discovery and generation of machine learning models. In step 1, the system uses interactive visualizations (such as histograms or graphs) to provide an initial data overview. The system then generates a number of possible modeling problems based on analyzing the data set (step 2) from which the user analyzes and selects one to try (step 3). Next, (step 4) an automated ML system trains and generates candidate models based on the data set and given problem. In step 5, the system shows comparisons of the generated prediction models through interactive visualizations of their predictions on a holdout set. Lastly, in step 6, users can select a number of preferable models, which are then exported by the system during step 7 for predictions on unseen test data. At any time, users can return to step 3 and try different modeling problems on the same dataset. ", "caption_bbox": [62, 704, 761, 809]}, {"image_id": 1, "file_name": "861_01.png", "page": 4, "dpi": 300, "bbox": [62, 101, 415, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The model generation framework of visual analytics by Andrienko et al. [ALA\u2217 ]. ", "caption_bbox": [63, 288, 397, 316]}, {"image_id": 2, "file_name": "861_02.png", "page": 5, "dpi": 300, "bbox": [435, 268, 756, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A prototype EMA visual analytics system used to deter- mine task requirements. Classification is shown in this figure. Dur- ing a feedback study with expert users, participants were asked to complete model selection tasks using this view. This process is re- peated for regression models (not shown). Feedback from this pro- totype was used to distill common steps in model exploration and selection across different model types. ", "caption_bbox": [428, 403, 762, 507]}, {"image_id": 3, "file_name": "861_03.png", "page": 8, "dpi": 300, "bbox": [80, 394, 746, 740], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "         Instances Figure 4: Components of the experimental system. The box in the center shows the system layout, which consists of two parts, the left- side workflow panel and the right-side card panel. (a) shows EMA workflow at different stages in the experimental system, (b) shows three examples of data visualization cards, and (c) shows two examples of model visualization cards. ", "caption_bbox": [62, 752, 761, 800]}, {"image_id": 4, "file_name": "861_04.png", "page": 11, "dpi": 300, "bbox": [412, 101, 765, 481], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A set of confusion matrices showing the different clas- sification models predicting Goal of students in the Popular Kids dataset [CD92]. The user is able to see visually that, while the middle model has the highest overall accuracy, it performs much better on students who have high grades as their goal. Instead, the user chooses the bottom model, because it performs more equally on all classes. ", "caption_bbox": [428, 496, 762, 600]}, {"image_id": 5, "file_name": "861_05.png", "page": 12, "dpi": 300, "bbox": [62, 101, 415, 476], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Regression plots of the two best models returned by a machine learning backend. ", "caption_bbox": [61, 488, 395, 516]}], "862": [{"image_id": 0, "file_name": "862_00.png", "page": 3, "dpi": 300, "bbox": [442, 277, 750, 458], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Graphical models of (a) a mediator, (b) our user study\u2019s dataset ", "caption_bbox": [428, 471, 762, 499]}, {"image_id": 1, "file_name": "862_01.png", "page": 4, "dpi": 300, "bbox": [62, 101, 415, 307], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: This figure compiles the key visualizations that are mandatory to correctly identify M, MX0 , or MY0 in our user study. The green arrows and red crosses represent the existence or nonex- istence of key correlations respectively. Note that the arrows and crosses were not shown in our actual user study. ", "caption_bbox": [63, 319, 397, 393]}, {"image_id": 2, "file_name": "862_02.png", "page": 5, "dpi": 300, "bbox": [63, 101, 415, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Description of the variables in our user study\u2019s dataset", "caption_bbox": [66, 280, 394, 293]}, {"image_id": 3, "file_name": "862_03.png", "page": 5, "dpi": 300, "bbox": [412, 101, 765, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Interface of the visual analytics system in our studies. The graph panel (B) is an experimental feature that is only avail- able in the treatment group. ", "caption_bbox": [428, 307, 762, 350]}, {"image_id": 4, "file_name": "862_04.png", "page": 7, "dpi": 300, "bbox": [412, 101, 765, 307], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Participants having more major categories performed better in our task. ", "caption_bbox": [428, 324, 762, 352]}, {"image_id": 5, "file_name": "862_05.png", "page": 7, "dpi": 300, "bbox": [78, 101, 415, 476], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The summary of participant performance in terms of (a) overall correctness rate, and (b) number of total errors and d\u2019. ", "caption_bbox": [62, 490, 396, 518]}, {"image_id": 6, "file_name": "862_06.png", "page": 8, "dpi": 300, "bbox": [62, 101, 728, 399], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Nine representative participants\u2019 visualization sequences during the task and their major categories. Three participants who had 1, 2, or 3 major categories were selected to show the similarities and differences in exploration strategies. ", "caption_bbox": [62, 412, 761, 441]}, {"image_id": 7, "file_name": "862_07.png", "page": 9, "dpi": 300, "bbox": [64, 101, 415, 429], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Scatter plots of how many times a visualization is plot- ted and the average time users spent reading it per plotting. The top scatter plot shows the aggregated pattern; in the bottom, three participants\u2019 behavior pattern are plotted for comparison. ", "caption_bbox": [63, 441, 397, 500]}, {"image_id": 8, "file_name": "862_08.png", "page": 10, "dpi": 300, "bbox": [62, 101, 415, 248], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: An example of when a participant missed recognizing a mediator due to false impression. ", "caption_bbox": [63, 260, 397, 288]}], "863": [{"image_id": 0, "file_name": "863_00.png", "page": 2, "dpi": 300, "bbox": [412, 101, 764, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Screenshot of Verifi. Verifi is comprised of four views: (A) Language Features View, (B) Social Network View, (C) Tweets Panel View, and (D) Entities View. Progress Bar and Form Submit buttons are at the top. ", "caption_bbox": [428, 325, 762, 384]}, {"image_id": 1, "file_name": "863_01.png", "page": 3, "dpi": 300, "bbox": [412, 101, 765, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Form Submit view of Verifi for Account #02 (@ABC). This pop-up provides an interface for the user decisions and feed- back per account (e.g., strategy cues use, view importance, and open-ended comments (not shown).) ", "caption_bbox": [428, 342, 762, 401]}, {"image_id": 2, "file_name": "863_02.png", "page": 3, "dpi": 300, "bbox": [453, 425, 738, 685], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The experiment flow for each participant session.", "caption_bbox": [445, 695, 744, 708]}, {"image_id": 3, "file_name": "863_03.png", "page": 5, "dpi": 300, "bbox": [437, 655, 758, 740], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Primary outcomes means and bootstrapped 95% confi- dence intervals on a user-level (n = 94). ", "caption_bbox": [428, 758, 762, 786]}, {"image_id": 4, "file_name": "863_04.png", "page": 5, "dpi": 300, "bbox": [66, 101, 415, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Dependent variable groups in our experiment.", "caption_bbox": [88, 324, 372, 337]}, {"image_id": 5, "file_name": "863_05.png", "page": 6, "dpi": 300, "bbox": [446, 541, 760, 740], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Posterior distributions of differences in means of user accuracy and confidence level. For both plots, the conditions are relative to the Control (no cues) treatment. CIs of differences are at 95% and 66%. ", "caption_bbox": [429, 752, 763, 811]}, {"image_id": 6, "file_name": "863_06.png", "page": 6, "dpi": 300, "bbox": [412, 101, 764, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Accuracy by Twitter account and bootstrapped 95% con- fidence intervals on decision-level (n = 748). (R) indicates a \"real\" news account and (M) indicates a \"misinformation\" account. The figure uses the same color and shape encodings as Figure 5. ", "caption_bbox": [429, 299, 763, 358]}, {"image_id": 7, "file_name": "863_07.png", "page": 6, "dpi": 300, "bbox": [62, 101, 415, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Secondary outcomes means and bootstrapped 95% con- fidence intervals on a user-level (n = 94). The figure uses the same color and shape encodings as Figure 5. ", "caption_bbox": [63, 331, 397, 374]}, {"image_id": 8, "file_name": "863_08.png", "page": 7, "dpi": 300, "bbox": [76, 746, 396, 932], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Coverage metrics means and bootstrapped 95% con- fidence intervals on user-level (n = 94). The figure uses the same shape and color encodings as Figure 9. ", "caption_bbox": [63, 948, 397, 991]}, {"image_id": 9, "file_name": "863_09.png", "page": 7, "dpi": 300, "bbox": [63, 478, 396, 672], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Time spent per view means and bootstrapped 95% confi- dence intervals on user-level (n = 94). ", "caption_bbox": [63, 686, 397, 714]}, {"image_id": 10, "file_name": "863_10.png", "page": 8, "dpi": 300, "bbox": [62, 101, 757, 356], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Heatmap clustering of interaction logs (Ward.D2 [ML14]) by columns (users) and rows (metrics). Each column is normalized for its percentile ranks. Users with a high feature rank are yellow while users with a low rank usage are dark blue. The bottom two rows indicate user\u2019s group and anchor condition. Both metrics were not used in clustering and provided for comparison. ", "caption_bbox": [63, 372, 762, 415]}, {"image_id": 11, "file_name": "863_11.png", "page": 9, "dpi": 300, "bbox": [83, 101, 765, 461], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Experiment interaction logs of Verifi. Each plot is a user\u2019s interaction log. Each dot is a user action: click (red), hover (green), scroll (blue), and submit (purple). The x-axis is the time of the action. The y-axis is the respective view associated with that action. The order corresponds to critical functionality (e.g., Form Submit) to primary view (e.g., Language Features vs. Social Network) to secondary views (e.g., Tweet Panel or Entities). Chart columns indicate user-level strategies based on user-level dendrogram clustering. Chart row order represents, in descending order, highly accurate users (7+ out of 8, top row), average users (5-6 out of 8, middle row), and inaccurate users (4 or less of 8, bottom row). ", "caption_bbox": [63, 489, 762, 578]}], "864": [{"image_id": 0, "file_name": "864_00.png", "page": 8, "dpi": 300, "bbox": [412, 101, 746, 206], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Task performance by dataset, labeled as: correct answer, incorrect answer, or did not finish (incomplete). ", "caption_bbox": [428, 209, 762, 237]}, {"image_id": 1, "file_name": "864_01.png", "page": 8, "dpi": 300, "bbox": [445, 242, 745, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Total answers observed for each dataset and task, and the total participants that arrived at each answer. ", "caption_bbox": [428, 311, 762, 339]}, {"image_id": 2, "file_name": "864_02.png", "page": 9, "dpi": 300, "bbox": [137, 101, 415, 200], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Mean interaction rates and 95% CIs of the mean.", "caption_bbox": [79, 200, 379, 213]}, {"image_id": 3, "file_name": "864_03.png", "page": 9, "dpi": 300, "bbox": [138, 214, 330, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Mean think times, with 95% CIs of the mean.", "caption_bbox": [90, 288, 368, 301]}, {"image_id": 4, "file_name": "864_04.png", "page": 10, "dpi": 300, "bbox": [137, 362, 691, 496], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Raw graph (a) and matching search tree (b) for one participant, task Weather T4. (c) Distribution of tree aspect ratios.", "caption_bbox": [87, 495, 732, 508]}, {"image_id": 5, "file_name": "864_05.png", "page": 10, "dpi": 300, "bbox": [61, 101, 767, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) Means and 95% confidence intervals for think time before each interaction (left), and total records per interaction type (right). (b) Observed think times for FAA T4, colored light blue when below mean think time, dark blue when above the mean. ", "caption_bbox": [60, 312, 759, 340]}, {"image_id": 6, "file_name": "864_06.png", "page": 12, "dpi": 300, "bbox": [62, 101, 764, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) Counts of users that overlap per state. Means and 95% confidence intervals for normalized max (b) breadth and (c) depth.", "caption_bbox": [74, 250, 755, 263]}], "865": [{"image_id": 0, "file_name": "865_00.png", "page": 1, "dpi": 300, "bbox": [60, 623, 763, 1079], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An ontology can support the design and evaluation of visual analytics systems by enabling systematic recording of symptoms, causes, remedies, and side-effects, facilitating the analysis of causal relations, search for solutions, and comparison of different design options. (a) An ontology that records only concrete entities (e.g., instances in practice) will take years and decades to build. (b) An ontology built around abstract entities can enable abstract reasoning in a scalable manner while allowing gradual addition of concrete entities. ", "caption_bbox": [61, 556, 760, 615]}, {"image_id": 1, "file_name": "865_01.png", "page": 5, "dpi": 300, "bbox": [69, 101, 415, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The cost-benefit of each process can be measured using three fundamental measures, Alphabet Compression (AC), Poten- tial Distortion (PD), and Cost (Ct). The changes of these measures in one process may affect the measures in the subsequent processes. ", "caption_bbox": [66, 261, 400, 320]}, {"image_id": 2, "file_name": "865_02.png", "page": 6, "dpi": 300, "bbox": [62, 101, 415, 796], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The main components of the ontological framework of IVAS are shown in their visual notations. ", "caption_bbox": [66, 804, 400, 832]}, {"image_id": 3, "file_name": "865_03.png", "page": 7, "dpi": 300, "bbox": [84, 101, 415, 563], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The possible paths from symptoms, to causes, remedies, and side-effects in abstract reasoning. All paths are of a downward direction, and arrows are omitted for alleviating cluttering. ", "caption_bbox": [66, 575, 400, 618]}, {"image_id": 4, "file_name": "865_04.png", "page": 8, "dpi": 300, "bbox": [62, 101, 766, 543], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Using the abstract entities, one can conduct abstract reasoning from symptoms to causes, to remedies, and to side-effects in a scalable manner. The rows in this figure are extracted from three 24 \u00d7 24 adjacency matrices in Appendix B.1. ", "caption_bbox": [66, 551, 765, 580]}, {"image_id": 5, "file_name": "865_05.png", "page": 8, "dpi": 300, "bbox": [78, 603, 756, 867], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The corresponding graph representations for the first row in Figure 5(a) and the first two rows in Figure 5(b).", "caption_bbox": [116, 874, 715, 887]}, {"image_id": 6, "file_name": "865_06.png", "page": 10, "dpi": 300, "bbox": [62, 101, 766, 530], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Application of the proposed ontological framework and the methodology of abstract reasoning to the analysis of problems-solutions in three practical case studies. ", "caption_bbox": [66, 538, 765, 566]}], "866": [{"image_id": 0, "file_name": "866_00.png", "page": 1, "dpi": 300, "bbox": [83, 327, 740, 509], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Left: Single segment analysis in VIAN showing its timeline and perceptual color widgets. Right: Global view showing a vocabulary navigator for interactive semantic analysis and annotation, keyword-filtered ensemble of screenshots, and visualization of the film\u2019s frames over time according to their chromatic qualities. ", "caption_bbox": [63, 514, 762, 557]}, {"image_id": 1, "file_name": "866_01.png", "page": 3, "dpi": 300, "bbox": [63, 101, 765, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Scope and features supported by related film visualization and analysis tools, as compared to VIAN. ", "caption_bbox": [63, 808, 397, 836]}, {"image_id": 2, "file_name": "866_02.png", "page": 5, "dpi": 300, "bbox": [95, 101, 765, 482], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: VIAN\u2019s most important widgets. The upper left showcases the outliner [A], player [B], and transparent overlay [C] widgets. The colorimetry widget [D] shows the current color palette. The screenshot manager [E] on top displays the screenshots sorted by the first segmentation. The inspector widget [F] gives details on the currently selected entity. Below is the timeline widget [G] showing two tiers of temporal segments and two tiers of screenshots (I WANT YOU, UK 1998, Michael Winterbottom). ", "caption_bbox": [62, 488, 761, 547]}, {"image_id": 3, "file_name": "866_03.png", "page": 6, "dpi": 300, "bbox": [62, 101, 728, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparative display between a manual segmentation (top row) and three automatic hierarchical segmentations (bottom rows) at three levels of aggregation in the timeline widget. (I WANT YOU, UK 1998, Michael Winterbottom) ", "caption_bbox": [63, 263, 762, 292]}, {"image_id": 4, "file_name": "866_04.png", "page": 6, "dpi": 300, "bbox": [62, 622, 399, 823], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: VIAN\u2019s classification widget. The upper tabs represent the classification object, the lower correspond to the vocabulary categories. For each vocabulary a set of checkboxes is shown in an expandable area. ", "caption_bbox": [63, 844, 397, 903]}, {"image_id": 5, "file_name": "866_05.png", "page": 7, "dpi": 300, "bbox": [62, 593, 402, 976], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Average screenshot color in the LAB color space.", "caption_bbox": [80, 975, 380, 988]}, {"image_id": 6, "file_name": "866_06.png", "page": 7, "dpi": 300, "bbox": [428, 465, 761, 568], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Hilbert-sorted color histogram visualization (L ES PARAPLUIES DE C HERBOURG, France, 1964, Jacques Demy). ", "caption_bbox": [428, 574, 762, 603]}, {"image_id": 7, "file_name": "866_07.png", "page": 7, "dpi": 300, "bbox": [64, 101, 415, 401], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Saturation of screenshots extracted over time for figure and background (U NE FEMME EST UNE FEMME, France, 1961, Jean-Luc Godard). ", "caption_bbox": [63, 410, 397, 453]}, {"image_id": 8, "file_name": "866_08.png", "page": 8, "dpi": 300, "bbox": [412, 101, 758, 494], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Palette plot comparison of U NE FEMME EST UNE FEMME , France, 1961, Jean-Luc Godard (a) and (b) and W EST S IDE S TORY, USA, 1961, Jerome Robbins and Robert Wise (c) and (d). n = 800 ", "caption_bbox": [428, 501, 762, 560]}, {"image_id": 9, "file_name": "866_09.png", "page": 9, "dpi": 300, "bbox": [96, 101, 765, 666], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Corpus visualization: VIAN can display large collections of films according to chroma, saturation, year of production, labels, etc. Here we compare and analyze aesthetic trends from 414 films produced over three historical periods. ", "caption_bbox": [63, 675, 762, 703]}], "867": [{"image_id": 0, "file_name": "867_00.png", "page": 1, "dpi": 300, "bbox": [84, 358, 746, 618], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualizations in the Compare View. Cards (A) show general information such as age, occupation, years of experience, number of languages known, mobility, and average duration per employment. The Skill tree (B) shows the selected candidates combined skill sets. ", "caption_bbox": [62, 629, 761, 657]}, {"image_id": 1, "file_name": "867_01.png", "page": 6, "dpi": 300, "bbox": [412, 101, 748, 457], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Scatterplot showing the score of the candidates. The dif- ferent sectors convey a different level of knowledge. ", "caption_bbox": [428, 469, 762, 497]}, {"image_id": 2, "file_name": "867_02.png", "page": 7, "dpi": 300, "bbox": [97, 101, 765, 441], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Common skills visualization. According to the number of common scores we use different techniques. For a single skill we use a bar chart with the candidates portraits stacked depending on their knowledge (A). For two common skills we display the candidates expertise in a scatterplot where we plot the common skills on the x- and y-axis (B). For three or more matched skills we construct a radar-chart where each axis is a unique common skill (C). ", "caption_bbox": [63, 453, 762, 512]}, {"image_id": 3, "file_name": "867_03.png", "page": 8, "dpi": 300, "bbox": [62, 101, 730, 511], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Timeline (A) and Map (B-D), the linked views of the candidates\u2019 events. In case of overlapping markers these are clustered together (C). Each event in the timeline is associated with a tooltip where we display detailed information related to the event (D). ", "caption_bbox": [63, 522, 762, 550]}], "868": [{"image_id": 0, "file_name": "868_00.png", "page": 1, "dpi": 300, "bbox": [61, 791, 764, 1084], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The user interface of DIVA, a web-based visual analytics system for exploring and verifying Drug-Drug Interactions (DDIs) proposed via machine learning methods. (a) Screening Overview \u2013 showing candidate Drug-Drug Interactions for selected score. (b) Signal Triage View \u2013 enables drug-centric analysis of interactions, including the number of severe Adverse Reactions (ADRs). (c) Signal Forensics View \u2013 a view of the interaction profile of a drug of interest, including all ADRs triggered by each signal. (d) Controls facilitate navigation between views, and direct filtering by drugs of interest. (e) Legends for colors. ", "caption_bbox": [62, 720, 761, 788]}, {"image_id": 1, "file_name": "868_01.png", "page": 2, "dpi": 300, "bbox": [412, 101, 762, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The current Drug Review Process, composed of Signal Screening, Detection, and Evaluation phases. ", "caption_bbox": [427, 273, 763, 300]}, {"image_id": 2, "file_name": "868_02.png", "page": 4, "dpi": 300, "bbox": [463, 547, 731, 689], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Augmented Interaction Model (AIM) describes the data entities, their properties and relationships which consist of a drug-drug interaction related reaction signal. Each signal encodes a casual relationship from a set of interacting drugs Ds to a set of triggered adverse reactions Rs . ", "caption_bbox": [429, 699, 765, 754]}, {"image_id": 3, "file_name": "868_03.png", "page": 6, "dpi": 300, "bbox": [62, 101, 415, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Overview of the DIVA framework consisting of two main compo- nents: the AIM Constructor and the DIVA Visualizer. ", "caption_bbox": [65, 302, 401, 329]}, {"image_id": 4, "file_name": "868_04.png", "page": 6, "dpi": 300, "bbox": [64, 353, 403, 916], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: FAERS Reports associated with interaction Lansoprazole and Digoxin. Every report has Furosemide which is used to treat kidney disorders. ", "caption_bbox": [65, 923, 401, 950]}, {"image_id": 5, "file_name": "868_05.png", "page": 7, "dpi": 300, "bbox": [414, 101, 765, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The Triage View - (a) Sort. (b) Pinned drugs (c) Color of box represents total number of severe reactions present in all signals related to Omeprazole. (d) Zoom in to view the Profile of Omeprazole. (e) Pin a drug. Interacting drugs with an (f) unknown and high score signal, (h) unknown and low score signal, (i) known and low score signal. ", "caption_bbox": [431, 314, 767, 382]}, {"image_id": 6, "file_name": "868_06.png", "page": 7, "dpi": 300, "bbox": [66, 101, 415, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a): Screening View gives an overview of interactions between drugs. Each node is a drug and edge depicts an interaction between two drugs. (b): Color Legends for: (i) Interestingness score in all views, (ii) Severe adverse reactions (or \u201cDME\u201d) count in the Triage View, (iii) Shape of links representing label status in the Screening and Forensics view. ", "caption_bbox": [66, 307, 401, 375]}, {"image_id": 7, "file_name": "868_07.png", "page": 8, "dpi": 300, "bbox": [87, 356, 372, 590], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Signal Forensics View: a tree layout allows an analyst to view and analyze the whole Augmented Interaction Model of a drug. (a) The root node represents the drug of interest \u2013 Omeprazole. (b) The second level represents drugs interacting with Omeprazole. (c) The third level represents the reactions related to each DDI \u2013 grey color represents non-severe reac- tions. (d) Severe reactions. (e) A signal with highest score - dark color. (f) Link between Omeprazole-Simavastatin depicts the aggregated score and unknown status because some of the signals are unknown. ", "caption_bbox": [63, 593, 399, 703]}, {"image_id": 8, "file_name": "868_08.png", "page": 9, "dpi": 300, "bbox": [427, 643, 764, 686], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Forensics View for Byetta. Interaction with Victoza and Januvia is just a co-occurrence and not an interaction as all three of these drugs belong to same drug class that treats diabetes. ", "caption_bbox": [428, 699, 762, 739]}, {"image_id": 9, "file_name": "868_09.png", "page": 9, "dpi": 300, "bbox": [61, 722, 400, 1052], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Forensics View for drug Lansoprazole. Interaction with Digoxin leading to acute kidney injury, a DME, is unknown, and is highly scored by the rule mining hence worthy of further investigation. ", "caption_bbox": [62, 667, 396, 707]}, {"image_id": 10, "file_name": "868_10.png", "page": 10, "dpi": 300, "bbox": [64, 901, 399, 945], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Forensics View for Ondansetron. Interaction with lithium lead- ing to severe and rare adverse reaction (ADR) \u2018serotonin syndrome\u2019 has been labeled by the FDA recently. ", "caption_bbox": [62, 958, 398, 998]}], "869": [{"image_id": 0, "file_name": "869_00.png", "page": 6, "dpi": 300, "bbox": [61, 101, 704, 385], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Two figures showing the top fifty thesaurus words for the lemma view . Left depicts view as a noun. Right shows view as a verb. The position is determined by the LogDice score (closer to the centre is a larger score; circle size depicts frequency. ", "caption_bbox": [63, 396, 762, 424]}], "870": [{"image_id": 0, "file_name": "870_00.png", "page": 1, "dpi": 300, "bbox": [62, 629, 763, 839], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Interpreting latent spaces from variational autoencoders trained on emoji images. (a) The user starts with summary metrics for latent space variants, (b) then drills down to an overview distribution of a chosen latent space. (c) To map out a semantic relationship, the user defines an attribute vector, examines the custom projection to the vector axis, applies analogies and assesses the relationship uncertainty. ", "caption_bbox": [62, 584, 761, 627]}, {"image_id": 1, "file_name": "870_01.png", "page": 4, "dpi": 300, "bbox": [412, 101, 759, 320], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A workflow for latent space interpretation. Background loops signify that all activities may be iteratively performed. ", "caption_bbox": [428, 323, 762, 351]}, {"image_id": 2, "file_name": "870_02.png", "page": 5, "dpi": 300, "bbox": [429, 294, 759, 500], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Vector space overview. We apply (a) t-SNE, (b) UMAP, and (c) PCA to visualize sample distributions. Here each dot rep- resents an emoji image, colored by its average pixel color. ", "caption_bbox": [428, 243, 762, 286]}, {"image_id": 3, "file_name": "870_03.png", "page": 6, "dpi": 300, "bbox": [61, 101, 415, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Analogy. An analogy vector (a) is obtained by adding the attribute vector (b) to an emoji example. In (c), the nearest neighbor in the training data is shown beside each reconstructed result. ", "caption_bbox": [63, 295, 397, 338]}, {"image_id": 4, "file_name": "870_04.png", "page": 6, "dpi": 300, "bbox": [96, 352, 366, 455], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Pair alignment to assess relationship saliency. We com- pare a histogram of pairwise cosine distances between attribute pairs to a background distribution of random pairs. We standardize the unit using pooled standard deviation. ", "caption_bbox": [63, 467, 397, 526]}, {"image_id": 5, "file_name": "870_05.png", "page": 7, "dpi": 300, "bbox": [66, 492, 394, 694], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) An attribute vector between man and woman faces. (b) Applying the attribute vector to man emojis often \u201cgrows\u201d the hair, but fails for faces without shoulders or full-body views. ", "caption_bbox": [63, 693, 397, 736]}, {"image_id": 6, "file_name": "870_06.png", "page": 7, "dpi": 300, "bbox": [66, 101, 415, 459], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visualizing attribute vectors in a global view, including (a) t-SNE, (b) UMAP, (c) PCA and (d) attribute vector projection. ", "caption_bbox": [63, 461, 397, 489]}, {"image_id": 7, "file_name": "870_07.png", "page": 8, "dpi": 300, "bbox": [412, 101, 759, 343], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Re-analyzing a latent space of gene expression profiles of cancer patients, fit using a VAE by [WG18]. ", "caption_bbox": [428, 346, 762, 374]}, {"image_id": 8, "file_name": "870_08.png", "page": 8, "dpi": 300, "bbox": [61, 101, 415, 351], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparing an attribute vector across latent spaces. The attribute vector adds an outline stroke to smileys. The relationship begins to be entangled with other image properties (e.g., the color or shape) when applied to a cookie emoji in lower dimensions. ", "caption_bbox": [62, 360, 396, 419]}, {"image_id": 9, "file_name": "870_09.png", "page": 9, "dpi": 300, "bbox": [63, 390, 396, 568], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Gender bias in word embeddings. Words are projected onto an attribute vector for gendered names. Brushing the female concept convex hull reveals words that reflect gender stereotypes. ", "caption_bbox": [63, 570, 397, 613]}, {"image_id": 10, "file_name": "870_10.png", "page": 9, "dpi": 300, "bbox": [77, 101, 765, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Analysis of an attribute vector between two high grade serous ovarian cancer subtypes, differentiated and proliferative. We change the y-axis (a) of the projection and confirm that samples in both subtypes are well-separated along the attribute vector axis (b). The list on the right (c) shows genes that are most differentially expressed in one subtype, which can be exported (d) for further analysis. ", "caption_bbox": [63, 337, 762, 380]}, {"image_id": 11, "file_name": "870_11.png", "page": 10, "dpi": 300, "bbox": [64, 454, 390, 660], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Original nearest neighbors of (a) slow and (b) dance, and nearest neighbors after adding the present:participle attribute vector (in the \u201canswer\u201d column). ", "caption_bbox": [63, 659, 397, 702]}, {"image_id": 12, "file_name": "870_12.png", "page": 10, "dpi": 300, "bbox": [61, 101, 744, 415], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: An attribute vector defining present tense verbs and participles in Google\u2019s analogy test dataset. Both the appearance of projected pairs (a) and the pair alignment statistics (b) agree with the analogy test scores. ", "caption_bbox": [63, 416, 762, 444]}], "871": [{"image_id": 0, "file_name": "871_00.png", "page": 1, "dpi": 300, "bbox": [130, 395, 696, 557], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Fat and thin client. Our flexible framework supports fully interactive spatiotemporal exploration of simulations with thousands of multi-billion-voxel frames. Left: fat client performing local rendering on a 1920x1080 touch screen driven by a single graphics PC with NVIDIA GTX 1080Ti. Right: thin client on Samsung Galaxy Note Pro SM-P905 Android tablet connected to a remote rendering server. ", "caption_bbox": [62, 557, 762, 594]}, {"image_id": 1, "file_name": "871_01.png", "page": 3, "dpi": 300, "bbox": [414, 101, 765, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Architecture overview. A near-lossless and a low-bitrate represen- tation are built from the input rectilinear scalar volumes. The near-lossless representation is exploited for computing, server side, high quality still frames, while the low-bitrate one is used for high-framerate image genera- tion. Thin clients receive images from a server-side renderer, while fat clients perform local rendering on a locally downloaded copy of low-bitrate data. ", "caption_bbox": [427, 256, 763, 330]}, {"image_id": 2, "file_name": "871_02.png", "page": 4, "dpi": 300, "bbox": [95, 177, 365, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: General data layout. Three parallel fixed-size HTA structures with the same layout are used to represent a frame. In order to support high-quality encoding the near-lossless representation uses the fixed-size structure as an index to variable-rate representation. ", "caption_bbox": [62, 289, 396, 338]}, {"image_id": 3, "file_name": "871_03.png", "page": 5, "dpi": 300, "bbox": [461, 192, 731, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Lossy data page layout. A constant-size page is composed by B brick headers and B brick data blocks. The headers (second row) are constant size and point to the associated variable-sized data block. ", "caption_bbox": [428, 290, 762, 327]}, {"image_id": 4, "file_name": "871_04.png", "page": 6, "dpi": 300, "bbox": [61, 101, 415, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: GPU data structures. We support rendering several timesteps in a single frame. On board, we perform rendering by accessing bricks stored in the HTA structure. The low-bandwidth representation is mapped to graphics memory through a paging process. A decoded brick cache as well as other transient structures support ray-guided streaming and rendering. ", "caption_bbox": [62, 241, 396, 303]}, {"image_id": 5, "file_name": "871_05.png", "page": 7, "dpi": 300, "bbox": [413, 101, 765, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Apron Filler. The apron voxels of destination yellow brick D are filled following these steps: (1) find cache slot of ID ; (2) from cache slot and voxel position, compute global (level, x, y, z); (3) convert (level, x, y, z) to an offset in the HTA layout to identify source brick (green); (4) find corresponding position in cache, fetch voxel and copy to destination position. Only one apron layer (instead of two) is depicted here for simplicity. ", "caption_bbox": [427, 233, 763, 307]}, {"image_id": 6, "file_name": "871_06.png", "page": 7, "dpi": 300, "bbox": [80, 101, 415, 534], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Cache buffers. Slot list contains all the slots in the 3D buffer. The index of the corresponding brick is stored for each used slot (in cyan). The indices of the new bricks to be decoded are in magenta. Corresponding slots are copied from the slot list to the decoded positions buffer. ", "caption_bbox": [62, 533, 396, 582]}, {"image_id": 7, "file_name": "871_07.png", "page": 8, "dpi": 300, "bbox": [428, 506, 762, 795], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Temporal multiview rendering. Three time steps of the HBDT dataset synchronously inspected within the same frame. ", "caption_bbox": [427, 794, 761, 818]}, {"image_id": 8, "file_name": "871_08.png", "page": 10, "dpi": 300, "bbox": [61, 101, 758, 385], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Decoding performance. Uploading and decoding speed in GVox/s for the various codecs. Real-time codecs have to support over 1 GVox/frame at 10 frames/s. Column D reports pure decoding speed for data in device memory for GPU codecs and in RAM for CPU ones, while column H reports the speed of moving data from host to device and decompressing it. ", "caption_bbox": [427, 511, 761, 573]}, {"image_id": 9, "file_name": "871_09.png", "page": 11, "dpi": 300, "bbox": [66, 101, 765, 203], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: HBDT isosurface rendering quality. From left to right: uncompressed, ZFP near-lossless (7.4 bps, volume PSNR=92.06, SSIM=0.999), elastic sparse coding (0.45 bps, SSIM=0.856), fixed sparse coding (0.43 bps, SSIM=0.809), ASTC (0.59 bps, SSIM=0.697), HVQ (0.50 bps, SSIM=0.351), CC (0.45 bps, 0.833), ZFP (0.41 bps, SSIM=0.206), SZ (0.46 bps, SSIM=0.347). Codecs supporting real-time decoding are marked in cyan, while others are marked in blue. ", "caption_bbox": [62, 203, 763, 240]}, {"image_id": 10, "file_name": "871_10.png", "page": 12, "dpi": 300, "bbox": [66, 194, 395, 334], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Dynamic dataset exploration. Top Left: frame time with intra- frame occlusion culling. Top Right: frame time without intra-frame occlu- sion culling. Bottom Left: decoded voxels/frame with intra-frame occlusion culling. Bottom Right: decoded voxels/frame without intra-frame occlusion culling. ", "caption_bbox": [63, 336, 399, 398]}, {"image_id": 11, "file_name": "871_11.png", "page": 12, "dpi": 300, "bbox": [412, 101, 760, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Static dataset exploration. Top Left: frame time with occlu- sion culling. Top Right: frame time without occlusion culling. Bottom Left: decoded voxels/frame with occlusion culling. Bottom Right: decoded vox- els/frame without occlusion culling. ", "caption_bbox": [428, 268, 764, 317]}], "872": [{"image_id": 0, "file_name": "872_00.png", "page": 3, "dpi": 300, "bbox": [68, 777, 413, 915], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A hidden Markov model approach to modeling attention and actions. We represent evolving attention as a sequence of latent variables in the hidden state space. Observable states are the user\u2019s actions. The conditional distribution of each observation depends on the state of the corresponding latent variable. ", "caption_bbox": [62, 931, 396, 1005]}, {"image_id": 1, "file_name": "872_01.png", "page": 3, "dpi": 300, "bbox": [73, 101, 765, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Extracting low-level features.", "caption_bbox": [313, 407, 510, 420]}, {"image_id": 2, "file_name": "872_02.png", "page": 5, "dpi": 300, "bbox": [83, 101, 765, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The first row shows the initial state of the particles as well as the inferences after the first four clicks for participant #311. The arrows indicate the observed clicks. Within a few clicks, the predictions for the user\u2019s evolving attention converge to circles within the general area of the observed clicks. The second row shows the particles from participant #116 who clicked points of a single color across different regions of the map. Here, we see a broad spread for the location parameters but a convergence of the type parameters over time. ", "caption_bbox": [59, 376, 758, 435]}, {"image_id": 3, "file_name": "872_03.png", "page": 6, "dpi": 300, "bbox": [412, 101, 765, 396], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The interface used in our experiment. Participants used their mouse to pan and zoom the map. A tooltip displayed informa- tion about the crimes on click. ", "caption_bbox": [428, 408, 762, 452]}, {"image_id": 4, "file_name": "872_04.png", "page": 8, "dpi": 300, "bbox": [61, 101, 743, 436], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The average prediction accuracy across the three type of tasks (Geo-Based, Type-Based, and Mixed) for varying values of the prediction set size. We report our results as top-K accuracy. For K = 100 our algorithm successfully predicted the users\u2019 next click, on average, 95% of the times. This means that we can successful predict that the next click will be within a small subset of the dataset. ", "caption_bbox": [57, 462, 756, 506]}, {"image_id": 5, "file_name": "872_05.png", "page": 9, "dpi": 300, "bbox": [412, 101, 765, 378], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The average accuracy over time for the three types of tasks in the study. After learning from 3 click interactions, the al- gorithm immediately achieves high prediction accuracy. We found that prediction accuracies remain fairly constant over time. ", "caption_bbox": [428, 390, 762, 449]}], "873": [{"image_id": 0, "file_name": "873_00.png", "page": 1, "dpi": 300, "bbox": [61, 359, 763, 557], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization of smoothly interpolated flood simulation results and terrain defined on adaptive grids. (Left) Large-scale flooding of villages by a nearby river. (Right) Stormwater runoff in a mountainous region. High velocities are indicated by white foam. ", "caption_bbox": [62, 567, 761, 595]}, {"image_id": 1, "file_name": "873_01.png", "page": 2, "dpi": 300, "bbox": [61, 101, 415, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Surface reconstruction with interpolation. (a) Nearest- neighbor and (b) bilinear interpolation lead to linear and angular shoreline features. A smoother shoreline is obtained by bicubic interpolation with (c) Catmull-Rom splines and (d) cubic B-splines. ", "caption_bbox": [62, 330, 398, 389]}, {"image_id": 2, "file_name": "873_02.png", "page": 2, "dpi": 300, "bbox": [412, 101, 764, 417], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Common artifacts with standard interpolation (left col- umn) compared to our results (right column). (a) Climbing. (b) Diving. (c) Leaking. ", "caption_bbox": [427, 427, 764, 470]}, {"image_id": 3, "file_name": "873_03.png", "page": 4, "dpi": 300, "bbox": [61, 101, 764, 487], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Bilinear interpolation within an adaptive grid. (a) Enumerated cells of the adaptive grid (black). Height-field values (blue) defined on wet cells shaded in blue. Dry cells are not shaded. (b)\u2013(d) Individual grid levels. (e)\u2013(g) Missing values have to be reconstructed for the interpolation patches on the two levels. (h) Blending of individual interpolation results within the transition region across levels. ", "caption_bbox": [62, 499, 761, 542]}, {"image_id": 4, "file_name": "873_04.png", "page": 8, "dpi": 300, "bbox": [61, 101, 415, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Removal of leaking artifacts at walls. (a) Comparison of a wetness value for each fragment pi and mirror position pi 0 . If higher at pi 0 , pi is discarded (red), unless the cell containing pi touches an overtopped wall cell (green). (b) Result without leaking. ", "caption_bbox": [61, 323, 397, 382]}, {"image_id": 5, "file_name": "873_05.png", "page": 9, "dpi": 300, "bbox": [61, 101, 765, 734], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Results of our proposed technique. (a) Large-scale visualization of a river valley (C1). (b) Stormwater runoff on a high-resolution grid (C3). (c) Coloring of water and buildings by water depth. (d) Failing floodwall in an urban scenario (C5). Foam indicates current overtopping regions. (e) Terrain overlay of wave arrival times after a dike breach (C6). (f) Tsunami impact on a city (C7). ", "caption_bbox": [62, 745, 761, 788]}, {"image_id": 6, "file_name": "873_06.png", "page": 11, "dpi": 300, "bbox": [62, 101, 415, 227], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Average rating results per group of participants with 95 % confidence intervals. ", "caption_bbox": [62, 237, 397, 265]}, {"image_id": 7, "file_name": "873_07.png", "page": 12, "dpi": 300, "bbox": [412, 101, 762, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Evaluation results per question averaged over the results of all domain experts with 95 % confidence intervals. ", "caption_bbox": [428, 379, 762, 407]}, {"image_id": 8, "file_name": "873_08.png", "page": 12, "dpi": 300, "bbox": [61, 101, 415, 343], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Evaluation results per group of participants. Each data point represents the average result of one question within the group. ", "caption_bbox": [62, 355, 398, 383]}, {"image_id": 9, "file_name": "873_09.png", "page": 15, "dpi": 300, "bbox": [62, 101, 765, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Overview of tile-based wave synthesis. (a) Average velocity of each tile for a single wavelength, normalized for display. (b) Sine waves of a single wavelength oriented towards flow direction. (c) Layout of four overlapping tiles around sample position p for seamless blending of values between tiles. (d) Blended waves of a single wavelength. (e) Superposition of sine waves of multiple wavelengths for vertex displacement. ", "caption_bbox": [62, 274, 761, 333]}], "874": [{"image_id": 0, "file_name": "874_00.png", "page": 1, "dpi": 300, "bbox": [62, 625, 763, 850], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Side-by-side comparison of the interpolation method between two set diagrams. (a) A simple interpolation in which elements are linearly translated simultaneously. (b) Our optimized stepwise animation in which the transition is decomposed to a sorted sequence of atomic changes. Each element is represented as an image of the alphabet and each set is represented as a colored region. ", "caption_bbox": [62, 574, 761, 618]}, {"image_id": 1, "file_name": "874_01.png", "page": 3, "dpi": 300, "bbox": [61, 101, 765, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of the proposed approach. The asterisk \u201c\u2217\u201d indicates an optional step.", "caption_bbox": [183, 334, 639, 347]}, {"image_id": 2, "file_name": "874_02.png", "page": 5, "dpi": 300, "bbox": [63, 101, 765, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Adjusting the priority values of edges in the Delaunay triangulation of each set for our specific purpose. This allows us to compose a shortest-path graph for each set such that the graph respects the following three criteria: (a) local temporal coherence, (b) global temporal coherence, and (c) set connectivity. ", "caption_bbox": [64, 314, 763, 358]}, {"image_id": 3, "file_name": "874_03.png", "page": 5, "dpi": 300, "bbox": [429, 394, 765, 503], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Five types of actions in our approach.", "caption_bbox": [475, 529, 717, 542]}, {"image_id": 4, "file_name": "874_04.png", "page": 6, "dpi": 300, "bbox": [62, 101, 415, 214], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Spatial and motion conditions for grouping actions as a cluster: (a) spatial closeness and (b) motion similarity (clustered actions are indicated by the red font). ", "caption_bbox": [63, 223, 397, 267]}, {"image_id": 5, "file_name": "874_05.png", "page": 7, "dpi": 300, "bbox": [70, 616, 390, 810], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Optimizing the order of actions. From the leftmost dia- gram to the rightmost one, the sequence of actions aG\u2212 , aR\u2212 , and aB\u2212 is the optimal order among possible action sequences. ", "caption_bbox": [62, 821, 396, 866]}, {"image_id": 6, "file_name": "874_06.png", "page": 7, "dpi": 300, "bbox": [69, 422, 390, 556], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Reordering action clusters, each of which consists of in- dividual actions. ", "caption_bbox": [62, 561, 396, 589]}, {"image_id": 7, "file_name": "874_07.png", "page": 7, "dpi": 300, "bbox": [64, 101, 765, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Conditions for grouping actions as a cluster that corresponds to a single animation step. Appearance/Disappearance actions are applied to (a) an element of (b) a set. Translation actions are applied to (c) an element or (d) a set. Inclusion/Exclusion actions are applied to (e) an element or (f) a set. Inclusion and exclusion actions are applied to (h) an element or (g) a set. ", "caption_bbox": [62, 342, 761, 386]}, {"image_id": 8, "file_name": "874_08.png", "page": 9, "dpi": 300, "bbox": [414, 334, 759, 450], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Results of the online questionnaire for D.2. (a) Answer categories and (b) task completion times for the four tasks. The error bars represent the standard errors. ", "caption_bbox": [413, 464, 757, 508]}, {"image_id": 9, "file_name": "874_09.png", "page": 9, "dpi": 300, "bbox": [63, 334, 407, 449], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Results of the online questionnaire for D.1. (a) Answer categories and (b) task completion times for the four tasks. The error bars represent the standard errors. ", "caption_bbox": [63, 463, 407, 507]}, {"image_id": 10, "file_name": "874_10.png", "page": 9, "dpi": 300, "bbox": [68, 101, 765, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Average heatmaps of eye-gaze distribution. The white regions correspond to dense regions of the eye-gaze distribution, while the yellow circles indicate local animated regions. The white numbers on the lower right of the images represent the corresponding time (in seconds). ", "caption_bbox": [63, 267, 762, 311]}, {"image_id": 11, "file_name": "874_11.png", "page": 11, "dpi": 300, "bbox": [138, 515, 685, 873], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Snapshots of the stepwise animation of the authorship dataset D.2. The sequence contains 48 actions and 13 action clusters.", "caption_bbox": [69, 884, 751, 897]}, {"image_id": 12, "file_name": "874_12.png", "page": 11, "dpi": 300, "bbox": [138, 101, 765, 483], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Snapshots of the stepwise animation of the flu dataset D.1. This animation sequence contains 22 actions and 16 action clusters.", "caption_bbox": [62, 494, 759, 507]}], "875": [{"image_id": 0, "file_name": "875_00.png", "page": 1, "dpi": 300, "bbox": [60, 839, 762, 1077], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Depiction of the main components of V-Awake. First, a patient is selected (1) and the predictions from the deep learning model are displayed in 2, 3 and 4. Next, some of the predictions are selected (2) and the data in the dimensionality reduction plot is highlighted (3). Some regions in the scatter plot are selected and the corresponding predictions are marked in the blocks view (4). Finally, selecting a prediction block makes the input view display the corresponding input (5), which can be analyzed to determine if the prediction is correct. ", "caption_bbox": [60, 775, 759, 834]}, {"image_id": 1, "file_name": "875_01.png", "page": 3, "dpi": 300, "bbox": [62, 141, 400, 395], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Five 30-second epochs depicting the five different sleep stages described by the AASM. Stages from top to bottom repre- sent respectively lighter and deeper sleep. Stages N1 to N3 de- pict the non-rem stages, while REM stage depicts the rapid-eye- movement phase of sleep. Signals are recordings from Fpz-Cz derivation [KZT\u2217 00]. ", "caption_bbox": [63, 406, 397, 495]}, {"image_id": 2, "file_name": "875_02.png", "page": 4, "dpi": 300, "bbox": [61, 101, 415, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Deep learning model for sleep stage scoring [SDWG17]. It comprises two convolutional branches with different kernel sizes, a shortcut connection and two bidirectional LSTM layers. ", "caption_bbox": [62, 210, 396, 253]}, {"image_id": 3, "file_name": "875_03.png", "page": 4, "dpi": 300, "bbox": [427, 402, 764, 945], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Illustration of the data used in our approach for patient j and session k. An example of signal is given for epoch E2, j,k which is classified as stage N2 after being run through the model. ", "caption_bbox": [427, 955, 761, 999]}, {"image_id": 4, "file_name": "875_04.png", "page": 5, "dpi": 300, "bbox": [66, 101, 415, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Depiction of our workflow and the mapping to the views of our design. Arrows depict a common way of interaction, al- though other routes are possible. Upper case words summarize the most important actions performed in each view. The tasks that each view performs are also shown in the diagram. ", "caption_bbox": [66, 314, 400, 388]}, {"image_id": 5, "file_name": "875_05.png", "page": 6, "dpi": 300, "bbox": [61, 101, 763, 503], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: User interface of V-Awake. Numbers depict the views and components of our approach: cohort view (1) and confusion matrix (1.1), predictions view with sleep cycles view (2.1) and blocks view (2.2), dimensionality reduction view (3), selections view (4) and input view (5). ", "caption_bbox": [63, 513, 762, 541]}, {"image_id": 6, "file_name": "875_06.png", "page": 7, "dpi": 300, "bbox": [63, 101, 415, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparison of tSNE, MDS and PCA for two subjects in a setting with ground truth available. Each square represents a prediction, the color depicts the predicted sleep stage. Circles with a black border represent predictions from the model that do not match the label assigned as ground truth. tSNE works, in general, better than other methods to identify borderline cases. ", "caption_bbox": [63, 360, 397, 449]}, {"image_id": 7, "file_name": "875_07.png", "page": 8, "dpi": 300, "bbox": [428, 865, 764, 975], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The four selections made in the exploratory use case.", "caption_bbox": [436, 986, 754, 999]}, {"image_id": 8, "file_name": "875_08.png", "page": 9, "dpi": 300, "bbox": [62, 874, 399, 960], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Strange artifact found during exploratory process. It is too regular and free of noise to depict a bio-signal. ", "caption_bbox": [62, 970, 396, 998]}, {"image_id": 9, "file_name": "875_09.png", "page": 9, "dpi": 300, "bbox": [97, 101, 415, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Selection of possible misclassifications. For instance, S5 depicts an area of N2 predominance, but N1 and N3 predictions are found. ", "caption_bbox": [62, 311, 396, 354]}]}