{"100": [{"image_id": 0, "file_name": "100_00.png", "page": 3, "dpi": 300, "bbox": [82, 542, 352, 790], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An example of Section page", "caption_bbox": [127, 805, 355, 820]}, {"image_id": 1, "file_name": "100_01.png", "page": 3, "dpi": 300, "bbox": [206, 93, 626, 469], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Hyper-link structure of the digital book", "caption_bbox": [264, 488, 560, 503]}, {"image_id": 2, "file_name": "100_02.png", "page": 6, "dpi": 300, "bbox": [92, 102, 735, 846], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Generated relevance maps", "caption_bbox": [303, 858, 521, 873]}, {"image_id": 3, "file_name": "100_03.png", "page": 8, "dpi": 300, "bbox": [95, 367, 729, 1046], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Various navigation facilities", "caption_bbox": [299, 1064, 526, 1079]}], "101": [{"image_id": 0, "file_name": "101_00.png", "page": 1, "dpi": 300, "bbox": [427, 721, 761, 850], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Structure of well-known network motifs", "caption_bbox": [427, 857, 748, 876]}, {"image_id": 1, "file_name": "101_01.png", "page": 2, "dpi": 300, "bbox": [427, 53, 761, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A graph (left) with a match of the motif", "caption_bbox": [427, 281, 748, 300]}, {"image_id": 2, "file_name": "101_02.png", "page": 3, "dpi": 300, "bbox": [427, 530, 761, 877], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Motif View showing the structure of mo-", "caption_bbox": [427, 884, 748, 903]}, {"image_id": 3, "file_name": "101_03.png", "page": 3, "dpi": 300, "bbox": [427, 55, 761, 441], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Motif Table showing label, size, structure,", "caption_bbox": [427, 448, 748, 467]}, {"image_id": 4, "file_name": "101_04.png", "page": 4, "dpi": 300, "bbox": [82, 54, 758, 579], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Use case diagram showing the different perspectives and possibilities for user interaction. For a", "caption_bbox": [83, 586, 749, 605]}, {"image_id": 5, "file_name": "101_05.png", "page": 4, "dpi": 300, "bbox": [427, 640, 761, 897], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The Motif Fingerprint shows a motif fre-", "caption_bbox": [427, 904, 748, 923]}, {"image_id": 6, "file_name": "101_06.png", "page": 5, "dpi": 300, "bbox": [82, 54, 415, 457], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Network with highlighted motif matches", "caption_bbox": [83, 464, 404, 483]}, {"image_id": 7, "file_name": "101_07.png", "page": 6, "dpi": 300, "bbox": [82, 53, 415, 456], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Network with highlighted motif matches", "caption_bbox": [83, 463, 404, 482]}, {"image_id": 8, "file_name": "101_08.png", "page": 7, "dpi": 300, "bbox": [82, 54, 415, 463], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Matches of the feed-forward loop motif", "caption_bbox": [83, 470, 404, 489]}, {"image_id": 9, "file_name": "101_09.png", "page": 8, "dpi": 300, "bbox": [82, 54, 415, 390], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: F3 . The l is shown in ", "caption_bbox": [83, 397, 150, 440]}, {"image_id": 10, "file_name": "101_10.png", "page": 9, "dpi": 300, "bbox": [82, 54, 415, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Cluster layout for frequency concept F1 . Strong cluster-forces separate both clusters in the drawing. The right side shows the network theme, ", "caption_bbox": [83, 311, 404, 358]}, {"image_id": 11, "file_name": "101_11.png", "page": 10, "dpi": 300, "bbox": [82, 54, 758, 578], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 17: Screenshot of the system showing a step of the anlysis of the E. coli transcriptional regulatory", "caption_bbox": [83, 585, 749, 604]}], "102": [{"image_id": 0, "file_name": "102_00.png", "page": 2, "dpi": 300, "bbox": [441, 53, 732, 221], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: This figures illustrates the decomposition of", "caption_bbox": [427, 231, 748, 250]}, {"image_id": 1, "file_name": "102_01.png", "page": 3, "dpi": 300, "bbox": [100, 59, 383, 348], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A definition of a portal for a triangulated", "caption_bbox": [83, 363, 404, 382]}, {"image_id": 2, "file_name": "102_02.png", "page": 3, "dpi": 300, "bbox": [97, 463, 388, 947], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: This figure illustrates the abstract form", "caption_bbox": [83, 958, 404, 977]}, {"image_id": 3, "file_name": "102_03.png", "page": 4, "dpi": 300, "bbox": [96, 643, 388, 862], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A first person view from the current loca-", "caption_bbox": [83, 871, 404, 890]}, {"image_id": 4, "file_name": "102_04.png", "page": 4, "dpi": 300, "bbox": [96, 53, 388, 478], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: This figure shows the different 3D views", "caption_bbox": [83, 488, 404, 507]}], "103": [{"image_id": 0, "file_name": "103_00.png", "page": 2, "dpi": 300, "bbox": [465, 140, 707, 231], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Shows that a cube with 3 subdivisions can be  transformed into a GAEA-3 whose face-normals form the vectors for the codebook of the Ellipsoidal Schema. ", "caption_bbox": [426, 249, 743, 296]}, {"image_id": 1, "file_name": "103_01.png", "page": 2, "dpi": 300, "bbox": [81, 132, 404, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Shows the overall process of our mesh simpli-                   fication technique. ", "caption_bbox": [80, 391, 400, 423]}, {"image_id": 2, "file_name": "103_02.png", "page": 3, "dpi": 300, "bbox": [89, 134, 392, 224], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Shows (A) original mesh (B) after applying GAEA-3 codebook (C) after applying GAEA-5-4-3. ", "caption_bbox": [87, 232, 392, 264]}, {"image_id": 3, "file_name": "103_03.png", "page": 3, "dpi": 300, "bbox": [427, 136, 742, 228], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Illustration of the flattening process of a patch      using a series of edge collapse transformation. ", "caption_bbox": [422, 239, 746, 271]}, {"image_id": 4, "file_name": "103_04.png", "page": 4, "dpi": 300, "bbox": [91, 126, 391, 215], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Shows the polygon counts after applying the   mesh simplification technique on several models. ", "caption_bbox": [432, 249, 738, 281]}, {"image_id": 5, "file_name": "103_05.png", "page": 4, "dpi": 300, "bbox": [79, 258, 402, 352], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Shows the results when iterative simplification         and non-uniform codebooks were used. ", "caption_bbox": [425, 411, 744, 443]}], "104": [{"image_id": 0, "file_name": "104_00.png", "page": 1, "dpi": 300, "bbox": [476, 523, 709, 733], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1. Example of hierarchical data visualization", "caption_bbox": [450, 745, 746, 760]}, {"image_id": 1, "file_name": "104_01.png", "page": 3, "dpi": 300, "bbox": [98, 878, 398, 1016], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2. Processing flow of HeiankyoView.", "caption_bbox": [130, 1031, 381, 1046]}, {"image_id": 2, "file_name": "104_02.png", "page": 3, "dpi": 300, "bbox": [438, 832, 750, 952], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3. (Left) Already placed rectangles. (Right)", "caption_bbox": [449, 976, 745, 991]}, {"image_id": 3, "file_name": "104_03.png", "page": 4, "dpi": 300, "bbox": [462, 252, 745, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5. (Left) Integer values j,k,l,m and coordinates", "caption_bbox": [444, 453, 742, 468]}, {"image_id": 4, "file_name": "104_04.png", "page": 4, "dpi": 300, "bbox": [112, 238, 415, 672], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. Four candidate positions for placing a", "caption_bbox": [119, 686, 385, 701]}, {"image_id": 5, "file_name": "104_05.png", "page": 5, "dpi": 300, "bbox": [423, 200, 743, 421], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7. Example of SOM classified according to the", "caption_bbox": [429, 439, 734, 454]}, {"image_id": 6, "file_name": "104_06.png", "page": 5, "dpi": 300, "bbox": [92, 217, 383, 598], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6. Five stages of priority of candidate", "caption_bbox": [122, 605, 372, 620]}, {"image_id": 7, "file_name": "104_07.png", "page": 6, "dpi": 300, "bbox": [86, 203, 398, 612], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8. Visualization of hierarchical data of the 161", "caption_bbox": [96, 633, 393, 648]}], "105": [{"image_id": 0, "file_name": "105_00.png", "page": 1, "dpi": 300, "bbox": [508, 645, 670, 758], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Leader cj is oriented towards corner A and leader ci is oriented away of corner A. ", "caption_bbox": [427, 771, 749, 803]}, {"image_id": 1, "file_name": "105_01.png", "page": 2, "dpi": 300, "bbox": [166, 53, 335, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Type-opo (top) and type-po (bottom) leaders.", "caption_bbox": [83, 303, 417, 320]}, {"image_id": 2, "file_name": "105_02.png", "page": 5, "dpi": 300, "bbox": [461, 54, 697, 157], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Case (a): Leader cj is oriented away of corner A and leader ci is oriented towards corner A. ", "caption_bbox": [427, 169, 728, 213]}, {"image_id": 3, "file_name": "105_03.png", "page": 5, "dpi": 300, "bbox": [453, 214, 705, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Case (b): Both leaders ci and cj are oriented away of corner A. ", "caption_bbox": [427, 326, 728, 356]}, {"image_id": 4, "file_name": "105_04.png", "page": 5, "dpi": 300, "bbox": [110, 54, 392, 137], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Leaders ci and cj overlap", "caption_bbox": [142, 149, 358, 167]}, {"image_id": 5, "file_name": "105_05.png", "page": 5, "dpi": 300, "bbox": [106, 168, 395, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Leaders ci and cj intersect", "caption_bbox": [138, 262, 361, 280]}, {"image_id": 6, "file_name": "105_06.png", "page": 5, "dpi": 300, "bbox": [97, 281, 404, 363], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Leaders ci and cj overlap", "caption_bbox": [142, 375, 358, 393]}, {"image_id": 7, "file_name": "105_07.png", "page": 5, "dpi": 300, "bbox": [459, 357, 698, 459], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Case (c): Both leaders ci and cj are oriented towards corner A. ", "caption_bbox": [427, 471, 728, 501]}, {"image_id": 8, "file_name": "105_08.png", "page": 6, "dpi": 300, "bbox": [151, 385, 317, 508], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: We can not introduce any east-to-west crossing during the west-to-east pass (the new leaders are with dotted lines). ", "caption_bbox": [83, 519, 384, 563]}, {"image_id": 9, "file_name": "105_09.png", "page": 6, "dpi": 300, "bbox": [161, 54, 308, 177], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A west-to-east pass. First the crossing of leaders ci and ck must be eliminated. ", "caption_bbox": [83, 189, 384, 221]}, {"image_id": 10, "file_name": "105_10.png", "page": 6, "dpi": 300, "bbox": [430, 320, 748, 575], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: A regional map of Germany; a point is the representative of each region. ", "caption_bbox": [427, 586, 748, 616]}, {"image_id": 11, "file_name": "105_11.png", "page": 6, "dpi": 300, "bbox": [434, 617, 744, 871], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: A visually improved map; a rectangle is the representative of each region. ", "caption_bbox": [427, 882, 748, 912]}, {"image_id": 12, "file_name": "105_12.png", "page": 6, "dpi": 300, "bbox": [162, 222, 306, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Rerouting used to eliminate crossings in an type opo-labelling. ", "caption_bbox": [83, 354, 384, 384]}, {"image_id": 13, "file_name": "105_13.png", "page": 7, "dpi": 300, "bbox": [427, 340, 767, 583], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: A visually improved map; a rectangle is the representative of each region. ", "caption_bbox": [427, 594, 748, 624]}, {"image_id": 14, "file_name": "105_14.png", "page": 7, "dpi": 300, "bbox": [427, 53, 767, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: A regional map of France; a point is the representative of each region. ", "caption_bbox": [427, 309, 748, 339]}], "106": [{"image_id": 0, "file_name": "106_00.png", "page": 1, "dpi": 300, "bbox": [421, 566, 740, 793], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: \u201cHaseya\uff4da Shugetsu\u201d from Eight Views of       Kinjo. Individual collection. Edo period. ", "caption_bbox": [424, 805, 743, 836]}, {"image_id": 1, "file_name": "106_01.png", "page": 2, "dpi": 300, "bbox": [443, 134, 736, 431], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Photo of a pit dwelling", "caption_bbox": [485, 438, 683, 453]}, {"image_id": 2, "file_name": "106_02.png", "page": 2, "dpi": 300, "bbox": [77, 328, 402, 778], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Photo of Katsura-Rikyu", "caption_bbox": [139, 789, 343, 804]}, {"image_id": 3, "file_name": "106_03.png", "page": 3, "dpi": 300, "bbox": [127, 775, 356, 1046], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Japonism painting by Vincent van Gogh", "caption_bbox": [78, 1053, 378, 1068]}, {"image_id": 4, "file_name": "106_04.png", "page": 4, "dpi": 300, "bbox": [163, 752, 322, 968], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A stepladder (Nagaoka district, Niigata)", "caption_bbox": [78, 1010, 376, 1025]}, {"image_id": 5, "file_name": "106_05.png", "page": 4, "dpi": 300, "bbox": [144, 460, 341, 648], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A part of box-shaped small dining table (Furniture Museum) ", "caption_bbox": [78, 677, 403, 707]}, {"image_id": 6, "file_name": "106_06.png", "page": 4, "dpi": 300, "bbox": [136, 167, 354, 376], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: An armrest (Furniture Museum)", "caption_bbox": [78, 400, 321, 415]}], "107": [{"image_id": 0, "file_name": "107_00.png", "page": 1, "dpi": 300, "bbox": [404, 80, 757, 617], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The process of visual data analysis is in- herently iterative to see both summary and details in context. ", "caption_bbox": [427, 627, 749, 671]}, {"image_id": 1, "file_name": "107_01.png", "page": 2, "dpi": 300, "bbox": [82, 53, 412, 189], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A two-level aggregate data browser can cover a wide range of granularity. Bottom: At the overview level, the analyst first looks at the aggre- gate information of the entire time period (typically one year) and specifies a period to focus on. Top: At the next level, the focus can be further narrowed down to a period of several minutes. ", "caption_bbox": [83, 199, 405, 298]}, {"image_id": 2, "file_name": "107_02.png", "page": 2, "dpi": 300, "bbox": [82, 310, 412, 529], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Left: Text visualization of a sequence of Au- tonomous System (AS) path announcements. Each unique AS path is shown in a different color, which effectively forms visual patterns of the updates such as oscillations, repeats, or slow convergences. Right: Statistical measures corresponding to each announce- ment can be used to help verify any detected anomaly. ", "caption_bbox": [83, 539, 405, 638]}, {"image_id": 3, "file_name": "107_03.png", "page": 3, "dpi": 300, "bbox": [82, 52, 412, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A drill-down process for finding network scans by applying it to a 24 hour long dataset at 10 minute resolution. Starting at the timeline on the left, a spike is found on a high port that crosses sev- eral hours. One of these hours is then selected for viewing in the grid based visualization shown in the middle. In it, there is exactly one port with unusu- ally large values in the range of ports that correspond to the spike. The range around this port is zoomed into which reveals in the bottom-right image that an abnormally large number of destinations being con- nected to by a small number of sources, which means that this is likely a network scan. ", "caption_bbox": [83, 285, 405, 467]}], "108": [{"image_id": 0, "file_name": "108_00.png", "page": 1, "dpi": 300, "bbox": [424, 85, 761, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Left: A visual similarity matrix for a 50 vertex small world graph (k = 10, p = 20%). The main diagonal starts at the origin of the two axes in the lower-left corner. The gray line shows the path from a \u2212 e that follows the edges a \u2212 b, b \u2212 c, c \u2212 d, d \u2212 e. Right: Viewing an undirected graph using the upper triangle, mirror, and lower triangle views. ", "caption_bbox": [440, 441, 775, 519]}, {"image_id": 1, "file_name": "108_01.png", "page": 2, "dpi": 300, "bbox": [148, 74, 344, 160], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A graph with three edges represented with a visual similarity matrix and a node-link diagram. Note that by removing the edge a \u2212 y, a diagonal feature is present in the VSM without adding any meaning to the interpretation. ", "caption_bbox": [73, 174, 408, 225]}, {"image_id": 2, "file_name": "108_02.png", "page": 2, "dpi": 300, "bbox": [515, 74, 711, 160], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A straight line indicates that vertex a is connected to vertices b, x and y in a star pattern. ", "caption_bbox": [440, 173, 775, 198]}, {"image_id": 3, "file_name": "108_03.png", "page": 3, "dpi": 300, "bbox": [98, 73, 394, 184], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Two different interpretations of the same diagonal line. Without the supporting edges, the vertex sequences wxyz and abcd have no intra-sequence relationships. However, the addition of the two hollow edges on the right provides paths between b, c, and d. Be- cause supporting edges may be in another area on the plot, diagonal lines are very difficult to interpret correctly. ", "caption_bbox": [73, 198, 408, 276]}, {"image_id": 4, "file_name": "108_04.png", "page": 3, "dpi": 300, "bbox": [95, 278, 394, 348], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A wedge (left) and a block (right) in a VSM. A wedge falls on the diagonal and indicates a clique or a cluster. A block is off the diagonal and indicates a bipartite graph. If a block is aligned vertically or horizontally with a wedge, then the block can be considered part of the cluster. ", "caption_bbox": [73, 359, 408, 423]}, {"image_id": 5, "file_name": "108_05.png", "page": 3, "dpi": 300, "bbox": [456, 73, 761, 158], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Algorithmic footprints. From left: Envelopes are indicative of breadth-first search ordering algorithms, horizons are left by depth- first searches, and galaxies result from spectral methods. ", "caption_bbox": [440, 169, 775, 207]}, {"image_id": 6, "file_name": "108_06.png", "page": 4, "dpi": 300, "bbox": [90, 74, 393, 194], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The effects of good anti-aliasing on a VSM. Both images show the same graph. The left image was rendered on an nVidia 6800 graphics card and the right image on an older ATI Radeon 9600. Anti-aliasing was turned on for both images, but the 6800 produced a more interpretable image. Toggling anti-aliasing on the nVidia card produces an image similar to the anti-aliased image from the Radeon card and helps the user find outliers. Toggling between single and multi-color images has a similar effect. ", "caption_bbox": [73, 206, 408, 310]}], "109": [{"image_id": 0, "file_name": "109_00.png", "page": 1, "dpi": 300, "bbox": [468, 452, 761, 553], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Matrix and node-link diagrams of the same graph. The axes of the matrix view are labeled with the vertices (data items) and edges (relationships) are dots in the plot area. ", "caption_bbox": [440, 569, 775, 607]}, {"image_id": 1, "file_name": "109_01.png", "page": 1, "dpi": 300, "bbox": [424, 85, 769, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Two visual similarity matrix visualizations of the National Cancer Institute\u2019s AIDS screen data using different data orderings. The one on the left, ordered by an expert, reveals structure within the data while the one on the right ordered by a randomizer, is indecipherable. ", "caption_bbox": [440, 370, 775, 434]}, {"image_id": 2, "file_name": "109_02.png", "page": 4, "dpi": 300, "bbox": [482, 74, 736, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Stability and Interpretability Measurements. Thumbnails for a 100 vertex small world graph ordered using DFS, starting with the default ordering (left) and a shuffled ordering (right). In both images, structure is visible. Using our stability evaluation criteria, this pairing is assigned \u2018structure (I)\u2019. Both fine and coarse structure is visible, giving it a \u2018coarse and fine (CF)\u2019 rating for interpretability. ", "caption_bbox": [440, 207, 775, 285]}, {"image_id": 3, "file_name": "109_03.png", "page": 5, "dpi": 300, "bbox": [457, 246, 760, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Three different orderings (left to right: BFS, DFS, degree) of a 100 vertex power law graph show enevelope, horizon, and galaxy footprints, respectively. ", "caption_bbox": [440, 351, 775, 389]}, {"image_id": 4, "file_name": "109_04.png", "page": 6, "dpi": 300, "bbox": [456, 74, 761, 164], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Three different orderings (left to right: BFS, RCM, King) of a 1000 vertex 5-linear-partite graph demonstrate how refinements of a core algorithm add additional structure. RCM and King are built on BFS and maintain the same overall structure. But, RCM further separates the dense areas into comb-like structures while King adds combs and a faint hash pattern to the image. ", "caption_bbox": [440, 175, 775, 253]}, {"image_id": 5, "file_name": "109_05.png", "page": 8, "dpi": 300, "bbox": [75, 73, 777, 255], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: All orderings for the COGsimilar data set. The top row contains orderings using the default initial ordering from the COG database and the bottom row used the shuffled initial ordering. ", "caption_bbox": [73, 265, 775, 290]}], "111": [{"image_id": 0, "file_name": "111_00.png", "page": 1, "dpi": 300, "bbox": [103, 86, 733, 334], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Rendering results of lobster data (128x128x34, 5M particles) using the proposed method. These rendering images show the change in the level of semi-transparency with respect to the change in the sub-pixel level (from 2 to 6). ", "caption_bbox": [94, 377, 742, 404]}, {"image_id": 1, "file_name": "111_01.png", "page": 2, "dpi": 300, "bbox": [466, 81, 758, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Particle generation and projection.", "caption_bbox": [504, 250, 721, 264]}, {"image_id": 2, "file_name": "111_02.png", "page": 3, "dpi": 300, "bbox": [462, 803, 778, 938], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Image quality improvement using the Metropolis                              3 method for tornado data (256 ). ", "caption_bbox": [469, 950, 754, 977]}, {"image_id": 3, "file_name": "111_03.png", "page": 4, "dpi": 300, "bbox": [472, 83, 761, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Rendering of irregular volume data (Aorta data).", "caption_bbox": [473, 374, 757, 388]}, {"image_id": 4, "file_name": "111_04.png", "page": 4, "dpi": 300, "bbox": [84, 85, 404, 312], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Simultaneous rendering of multiple volume data.", "caption_bbox": [99, 337, 385, 351]}], "112": [{"image_id": 0, "file_name": "112_00.png", "page": 2, "dpi": 300, "bbox": [448, 75, 767, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A 2D example of the opening and closing operations. (a) the original region; (b) the region after an opening (c) the region after a closing. ", "caption_bbox": [440, 232, 775, 271]}, {"image_id": 1, "file_name": "112_01.png", "page": 2, "dpi": 300, "bbox": [76, 75, 408, 248], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The process of multi-scale morphological data exploration involving multiple steps from data preparation, rendering, interactive editing, to feature refinement. ", "caption_bbox": [73, 263, 408, 302]}, {"image_id": 2, "file_name": "112_02.png", "page": 4, "dpi": 300, "bbox": [84, 77, 400, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An example of the region graph: (a) the regions obtained through a set of morphological operations. R, C and O represent the contributions from the original data, morphological data generated by closing, and opening, respectively; for example, graph node 9 is marked ROC which means it receives the contributions from all three data sets. (b) the graph of the regions in (a). The shaded nodes form the definite part of the feature. ", "caption_bbox": [73, 264, 408, 356]}, {"image_id": 3, "file_name": "112_03.png", "page": 4, "dpi": 300, "bbox": [443, 76, 774, 398], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Finding the connecting graph nodes: (a) the region graph G; the shaded graph nodes are the primary graph nodes which form three subgraphs G1 , G2 and G3 . (b) the condensed region graph G\u2032 ; Gi ,i = 1..3 are the condensed graph nodes, and the thick edges are the shortest paths between G1, G2 and G3; ei ,i = 1..7 are their edge weights. (c) the minimum condensed tree of G1, G2 and G3; Ei ,i = 1..3 are the edge weights. E3 is not included. (d) the desired consequent graph; the white nodes are the connecting graph nodes. ", "caption_bbox": [440, 414, 775, 519]}, {"image_id": 4, "file_name": "112_04.png", "page": 5, "dpi": 300, "bbox": [80, 75, 402, 255], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A simple region graph. (a) the simple region graph G; the shaded graph nodes are the primary graph nodes which form two subgraphs G1 and G2 . (b) the simple condensed region graph G\u2032 ; Gi ,i = 1..2 are the condensed graph nodes, and the bold edges are the shortest paths between G1 and G2. (c) the simple minimum condensed tree of G\u2032 ; graph node 5 is the connecting graph node. ", "caption_bbox": [73, 276, 408, 354]}, {"image_id": 5, "file_name": "112_05.png", "page": 6, "dpi": 300, "bbox": [84, 82, 400, 849], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Segmenting a kidney tumor from a CT volume (512\u00d7512\u00d7180). (a) Volume rendering of the CT volume using a 1-d transfer function. (b) A slice of the volume outlining the segmented area in red. The objective is to segment the kidney on the right side but region growing picked up a much larger region. (c) Boundary surface rendering of the segmented result. (d) Boundary surface col- ored according to the contributions from different morphological data. (e) After direct region removal. (f) After non-seeded region removal. (g) Boundary surface rendering of the segmented kidney. (h) volume rendering of the segmented kidney. ", "caption_bbox": [73, 861, 408, 992]}, {"image_id": 6, "file_name": "112_06.png", "page": 7, "dpi": 300, "bbox": [424, 1038, 802, 1094], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The regions of MRI head data generated using region re- moval operations. The red color in the bottom two images highlights those regions which receive the contribution of O2 data, while the green color in the bottom right image shows the contribution of O2.5 data. This coloring guides the user in the segmentation process. ", "caption_bbox": [440, 921, 775, 986]}, {"image_id": 7, "file_name": "112_07.png", "page": 7, "dpi": 300, "bbox": [93, 84, 405, 355], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The regions of the aneurysm obtained with connection re- taining. Top Left: Region growing of features from the R data. Top Right: Region growing of features from the RC2 data; the green re- gions are the ones only receiving contributions from the C2 data. Bot- tom Left: After applying connection retaining. Bottom Right: Close- up view of the area marked with blue line in the bottom left image. ", "caption_bbox": [73, 369, 408, 447]}, {"image_id": 8, "file_name": "112_08.png", "page": 8, "dpi": 300, "bbox": [105, 328, 372, 535], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The brain, tumor, vessels and skull rendered with vol- ume rendering. The four features are segmented individually, and rendered together for making this visualization. ", "caption_bbox": [73, 559, 408, 598]}, {"image_id": 9, "file_name": "112_09.png", "page": 8, "dpi": 300, "bbox": [78, 75, 405, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The brain rendered with volume rendering. The left im- age are produced with the original data using a 2D transfer function, while the right one is generated with anti-aliased feature volume seg- mented with our approach. ", "caption_bbox": [73, 252, 408, 304]}], "113": [{"image_id": 0, "file_name": "113_00.png", "page": 2, "dpi": 300, "bbox": [469, 82, 735, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Adaptive sampling on view rays according to an oracle, which computes a sampling distance d (represented by gray levels) for each sampling point. Filled black dots represent skipped sampling points. ", "caption_bbox": [440, 274, 775, 328]}, {"image_id": 1, "file_name": "113_01.png", "page": 2, "dpi": 300, "bbox": [102, 101, 351, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Sampling on view-aligned slices for volume rendering", "caption_bbox": [86, 274, 396, 289]}, {"image_id": 2, "file_name": "113_02.png", "page": 3, "dpi": 300, "bbox": [100, 275, 374, 419], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Adaptive sampling of a slice (lslice = lmax = 2). Gray levels represent sampling distances returned by an oracle. Filled black dots represent skipped sampling points. ", "caption_bbox": [73, 440, 408, 481]}, {"image_id": 3, "file_name": "113_03.png", "page": 3, "dpi": 300, "bbox": [460, 73, 757, 456], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Pseudo code for adaptive sampling of the islice -th slice. See Figure 7 for the specification of S YNTHESIZE DATA, S YNTHESIZE - O RACLE, S AMPLE DATA, and S AMPLE O RACLE; ACCUMULATE C OLOR is specified in Figure 8.. ", "caption_bbox": [440, 465, 775, 519]}, {"image_id": 4, "file_name": "113_04.png", "page": 4, "dpi": 300, "bbox": [139, 407, 344, 562], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Employed synthesis scheme for pixel data of a finer level (gray) from pixel data of a coarser level (black) ", "caption_bbox": [73, 574, 408, 602]}, {"image_id": 5, "file_name": "113_05.png", "page": 4, "dpi": 300, "bbox": [100, 86, 375, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "                                       3             9              1 Figure 5: Synthesis of s0 [4, 1] = 16    s1 [1, 0] + 16 s1 [2, 0] + 16 s1 [1, 1] +  3 16 s1 [2, 1]. The gray dot indicates the texture coordinates for the cor- responding bilinear texture lookup. ", "caption_bbox": [73, 344, 408, 389]}, {"image_id": 6, "file_name": "113_06.png", "page": 4, "dpi": 300, "bbox": [441, 73, 776, 404], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Pseudo code for synthesizing data and sampling scalar data and the oracle. The functions are employed in Figure 4. ", "caption_bbox": [440, 413, 775, 441]}, {"image_id": 7, "file_name": "113_07.png", "page": 5, "dpi": 300, "bbox": [462, 73, 755, 636], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Pseudo code for a variant of the algorithm presented in Figure 4, which is suitable for an implementation based on an early fragment-depth test. ", "caption_bbox": [440, 645, 775, 686]}, {"image_id": 8, "file_name": "113_08.png", "page": 5, "dpi": 300, "bbox": [113, 73, 371, 439], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Pseudo code for the color accumulation employed in Fig- ure 4 and the main loop over all slices for volume rendering. ", "caption_bbox": [73, 447, 408, 475]}, {"image_id": 9, "file_name": "113_09.png", "page": 8, "dpi": 300, "bbox": [72, 581, 777, 942], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Abdomen data set: (a) texture-based and (b) with our adaptive sampling algorithm.", "caption_bbox": [194, 951, 654, 966]}, {"image_id": 10, "file_name": "113_10.png", "page": 8, "dpi": 300, "bbox": [72, 107, 777, 468], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Volume rendering of the aneurysm data set: (a) Texture-based volume rendering for comparison. (b) Our adaptive sampling according to a pre-computed ad-hoc oracle. ", "caption_bbox": [73, 477, 775, 505]}], "114": [{"image_id": 0, "file_name": "114_00.png", "page": 1, "dpi": 300, "bbox": [424, 86, 754, 541], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) A planar graph G, (b) a straight-line grid drawing of G with area O(n2 ), (c) a doughnut embedding of G and (d) a straight-line grid drawing of G with area O(n). ", "caption_bbox": [440, 549, 775, 589]}, {"image_id": 1, "file_name": "114_01.png", "page": 3, "dpi": 300, "bbox": [84, 73, 385, 187], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration for the construction of a planar embedding \u0393 of a p-doughnut graph G for p = 4; (a) embedding of the three cycles C1 , C2 and C3 on three concentric circles, (b) addition of edges for the case where k is even in zk and (c) \u0393. ", "caption_bbox": [72, 192, 408, 249]}, {"image_id": 2, "file_name": "114_02.png", "page": 4, "dpi": 300, "bbox": [77, 75, 398, 427], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) A doughnut embedding of a p-doughnut graph of G, (b) edges between four corner vertices of R1 and R2 are drawn as straight-line segments, (c) edges between vertices on R1 and R2 are drawn, (d) edges between four corner vertices of R2 and R3 are drawn as straight-line segments, and (e) a straight-line grid drawing of G. ", "caption_bbox": [73, 435, 408, 501]}], "115": [{"image_id": 0, "file_name": "115_00.png", "page": 1, "dpi": 300, "bbox": [440, 242, 782, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Ad-hoc placement (adjusted fullness for an aspect ratio of 1:1: 32%), advanced placement as being described in [14] (43%), and our solution (60%). Using our approach results in an improvement of 40% for this example. ", "caption_bbox": [440, 374, 775, 427]}, {"image_id": 1, "file_name": "115_01.png", "page": 2, "dpi": 300, "bbox": [86, 73, 396, 201], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A set of rectangles packed two-dimensionally by Strip- Packing (a), Tiling (b) and Alternate Bisection (c). ", "caption_bbox": [73, 215, 408, 241]}, {"image_id": 2, "file_name": "115_02.png", "page": 2, "dpi": 300, "bbox": [462, 73, 755, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The generation of a polyomino from a graph object and the filling of bounded grid cells. ", "caption_bbox": [440, 202, 775, 228]}, {"image_id": 3, "file_name": "115_03.png", "page": 3, "dpi": 300, "bbox": [543, 72, 674, 121], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) the layout returned by a greedy algorithm (DAR 1:1) and (b) the optimal solution returned by our algorithm. ", "caption_bbox": [440, 136, 775, 162]}, {"image_id": 4, "file_name": "115_04.png", "page": 3, "dpi": 300, "bbox": [122, 73, 361, 154], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Applying Polyomino-based algorithms to polygonal objects (desired aspect ratio: 3:2). Our algorithm (b) generates results that are more compact and better sorted than the results of the greedy algorithm by Freivalds et al. (a). ", "caption_bbox": [73, 170, 408, 223]}, {"image_id": 5, "file_name": "115_05.png", "page": 3, "dpi": 300, "bbox": [493, 191, 724, 423], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Importance of variability: Three polyominoes are placed successively to fulfill an aspect ratio of 1:1. After the first placing step, two similar configurations are selected which both lead to a similar suboptimal result after the second placing step. The third configuration selected after the first placing step, which has a lower similarity with the other two, leads to an optimal solution. ", "caption_bbox": [440, 437, 775, 516]}, {"image_id": 6, "file_name": "115_06.png", "page": 4, "dpi": 300, "bbox": [462, 75, 755, 128], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Surface as a quality measure: All shown polyominoes have the same fullness (0.64). The polyomino shown in (a) has a surface of 20, the one in (b) 34. It is striking that it is more likely that empty spaces in configuration (a) will be filled by other polyominoes than in (b). Both examples in (c) and (d) have the same surface (20). Nevertheless, the example in (c) seems to be the better choice over (d) since non-filled grid cells form a larger connected area that can be used to place other components. Using the effective surface (highlighted in light grey), example (c) retrieves a better score (6) than (d) (13). ", "caption_bbox": [440, 145, 775, 276]}, {"image_id": 7, "file_name": "115_07.png", "page": 4, "dpi": 300, "bbox": [170, 72, 314, 134], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Adjusted fullness AF U vs. fullness F U : The adjusted fullness for a desired aspect ratio of 1:1 of the configuration shown in (a) is higher (0.64) than in (b) (0.44), whereas the fullness in (b) (0.89) is higher than in (a) (0.64). Obviously, the configuration shown in (b) is suited better if further components will be placed. ", "caption_bbox": [73, 148, 408, 214]}, {"image_id": 8, "file_name": "115_08.png", "page": 5, "dpi": 300, "bbox": [124, 254, 358, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The calculation of the refined profile homogeneity: Avertical and Ahorizontal represent the area that is included by the vertical and horizontal borders. In this example, the pseudo in- clusion count adds up to 19 + 19 \u2212 2 \u2217 16 = 6, resulting in a refined profile homogeneity of 17. ", "caption_bbox": [73, 368, 408, 434]}, {"image_id": 9, "file_name": "115_09.png", "page": 5, "dpi": 300, "bbox": [188, 75, 296, 183], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The calculation of the profile homogeneity of a configura- tion (here: 12). ", "caption_bbox": [73, 198, 408, 224]}, {"image_id": 10, "file_name": "115_10.png", "page": 6, "dpi": 300, "bbox": [469, 73, 750, 191], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Example for the advanced placing strategy: The left grid shows a base grid with filled (grey/dark grey) and empty (white) cells, onto which a polyomino (black/dark grey) should be placed. If the polyomino is placed at B3, it will give an overlap at D5. Con- sequently, we know that the polyomino cannot be placed at this position. Furthermore, it cannot be placed at the positions indicated in black on the right grid, because some part of the polyomino will lie on position D5. If the polyomino is placed at I4, another overlap is found at I6. The polyomino is turned by 180 degree and the position that caused the overlap is drawn at I4. ", "caption_bbox": [440, 205, 775, 336]}, {"image_id": 11, "file_name": "115_11.png", "page": 6, "dpi": 300, "bbox": [104, 72, 379, 228], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Finding possible positions for polyomino (a) on the base shown in (b) and (c). Hatched grid cells indicate positions that are checked by different placing strategies, placing the upper left grid cell of the polyomino onto that cell. (a): basic placing strategy, (b): fast placing strategy. ", "caption_bbox": [73, 242, 408, 308]}, {"image_id": 12, "file_name": "115_12.png", "page": 7, "dpi": 300, "bbox": [213, 702, 637, 874], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Runtimes observed when applying different placing strategies, averaged over 5 random sets of objects. The left part shows the runtime as a function of the object count. All four placing strategies show consistent runtimes with the theoretical runtime of O(n 2 ) and only varying by factor 2 from each other. The right picture shows the dependence of the average polyomino size. Using the basic strategy, the runtime increases rapidly with increasing polyomino size. Meanwhile, possible positions were found much faster using one of the other three strategies. ", "caption_bbox": [73, 890, 775, 956]}, {"image_id": 13, "file_name": "115_13.png", "page": 7, "dpi": 300, "bbox": [166, 404, 684, 576], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Percentage reduction of adjusted wasted space in results obtained by our algorithms compared to those of the greedy algorithm. The results are averaged over 30 random samples. ", "caption_bbox": [73, 591, 774, 617]}, {"image_id": 14, "file_name": "115_14.png", "page": 7, "dpi": 300, "bbox": [166, 105, 685, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: The space wasted in results that were returned by the three algorithms, averaged over 30 random samples. The new algorithms were run with increasing numbers of configurations (k) stored in each placing step. ", "caption_bbox": [73, 292, 774, 318]}], "116": [{"image_id": 0, "file_name": "116_00.png", "page": 1, "dpi": 300, "bbox": [510, 291, 709, 455], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Two drawings of the same graph. (a) k-planarization draw- ing, (b) minimal-crossing-number drawing. Adopted from [8, Figure 2] ", "caption_bbox": [440, 472, 775, 512]}, {"image_id": 1, "file_name": "116_01.png", "page": 2, "dpi": 300, "bbox": [84, 118, 411, 431], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of geometric-path tendency. Note that the dashed line is not part of the graph. To find the path between nodes 1 and 2, if search always starts from node 1, people tend to follow the path 1-7-5-6 first, the path 1-3-5-6 second, and the path 1-3-4-2 third. ", "caption_bbox": [73, 445, 409, 511]}, {"image_id": 2, "file_name": "116_02.png", "page": 4, "dpi": 300, "bbox": [519, 191, 699, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Geometric-path tendency suggests that the path between nodes 1 and 2 in the left drawing should be easier to detect than that in the right. ", "caption_bbox": [440, 345, 775, 385]}], "117": [{"image_id": 0, "file_name": "117_00.png", "page": 3, "dpi": 300, "bbox": [77, 73, 407, 499], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An application to a social network.", "caption_bbox": [132, 511, 349, 523]}, {"image_id": 1, "file_name": "117_01.png", "page": 4, "dpi": 300, "bbox": [77, 615, 407, 794], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Graph layouts based on (a) Hall\u2019s and (b) the HK methods.", "caption_bbox": [73, 806, 408, 818]}, {"image_id": 2, "file_name": "117_02.png", "page": 4, "dpi": 300, "bbox": [93, 72, 757, 561], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Results of (a1)\u2013(a3) the TKS, (b1)\u2013(b3) Hall\u2019s, and (c1)\u2013(c3) the HK methods.", "caption_bbox": [210, 577, 639, 589]}], "118": [{"image_id": 0, "file_name": "118_00.png", "page": 2, "dpi": 300, "bbox": [454, 388, 746, 624], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 2: Three types of dummy vertices.", "caption_bbox": [505, 349, 702, 365]}, {"image_id": 1, "file_name": "118_01.png", "page": 2, "dpi": 300, "bbox": [103, 404, 372, 603], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 1: A diagram of an intersecting clustered graph.", "caption_bbox": [98, 606, 362, 622]}, {"image_id": 2, "file_name": "118_02.png", "page": 4, "dpi": 300, "bbox": [442, 191, 767, 456], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 4: Scheduling of forces and their purposes.", "caption_bbox": [483, 460, 722, 476]}, {"image_id": 3, "file_name": "118_03.png", "page": 5, "dpi": 300, "bbox": [464, 382, 755, 915], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 7: Results of evaluation for Experiment 3.", "caption_bbox": [486, 926, 721, 942]}, {"image_id": 4, "file_name": "118_04.png", "page": 5, "dpi": 300, "bbox": [73, 75, 402, 677], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 5: Results of evaluation for Experiment 1.", "caption_bbox": [119, 688, 354, 704]}, {"image_id": 5, "file_name": "118_05.png", "page": 5, "dpi": 300, "bbox": [462, 94, 749, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 6: Results of evaluation for Experiment 2.", "caption_bbox": [486, 326, 721, 342]}, {"image_id": 6, "file_name": "118_06.png", "page": 6, "dpi": 300, "bbox": [111, 376, 363, 857], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Drawing example 1.", "caption_bbox": [160, 856, 312, 872]}, {"image_id": 7, "file_name": "118_07.png", "page": 6, "dpi": 300, "bbox": [459, 369, 749, 765], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 10: Drawing example 3.", "caption_bbox": [530, 765, 676, 781]}, {"image_id": 8, "file_name": "118_08.png", "page": 6, "dpi": 300, "bbox": [454, 76, 755, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 9: Drawing example 2.", "caption_bbox": [533, 352, 673, 368]}, {"image_id": 9, "file_name": "118_09.png", "page": 7, "dpi": 300, "bbox": [136, 498, 705, 955], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 12: Snapshot of the screen of our drawing tool for intersecting clustered graphs.", "caption_bbox": [208, 969, 632, 985]}, {"image_id": 10, "file_name": "118_10.png", "page": 7, "dpi": 300, "bbox": [188, 90, 653, 463], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 11: Drawing example 4.", "caption_bbox": [347, 463, 492, 479]}], "119": [{"image_id": 0, "file_name": "119_00.png", "page": 2, "dpi": 300, "bbox": [447, 677, 781, 943], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Tree-curl navigation sequence", "caption_bbox": [509, 961, 706, 973]}, {"image_id": 1, "file_name": "119_01.png", "page": 2, "dpi": 300, "bbox": [448, 83, 781, 382], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Folding sub-trees navigation sequence", "caption_bbox": [488, 400, 727, 412]}, {"image_id": 2, "file_name": "119_02.png", "page": 2, "dpi": 300, "bbox": [87, 532, 411, 646], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Folding sub-trees", "caption_bbox": [173, 665, 308, 677]}, {"image_id": 3, "file_name": "119_03.png", "page": 3, "dpi": 300, "bbox": [81, 562, 415, 845], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Path hierarchical graph navigation sequence", "caption_bbox": [107, 863, 374, 875]}, {"image_id": 4, "file_name": "119_04.png", "page": 3, "dpi": 300, "bbox": [448, 531, 781, 826], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Focusing on a selected layer in a hierarchical graph", "caption_bbox": [457, 844, 758, 856]}, {"image_id": 5, "file_name": "119_05.png", "page": 4, "dpi": 300, "bbox": [81, 306, 415, 456], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: PhylloTree layout of a simple cluster graph", "caption_bbox": [113, 474, 369, 486]}], "120": [{"image_id": 0, "file_name": "120_00.png", "page": 1, "dpi": 300, "bbox": [509, 307, 705, 636], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) A non c-planar drawing of a clustered graph. (b) A c- planar drawing of the same clustered graph.Vertices with the same color belong to the same cluster. ", "caption_bbox": [440, 654, 775, 693]}, {"image_id": 1, "file_name": "120_01.png", "page": 3, "dpi": 300, "bbox": [141, 74, 342, 571], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) A c-graph C = (G,T ); the clusters are represented as rectangles. (b) The inclusion tree T of C. ", "caption_bbox": [73, 588, 408, 616]}, {"image_id": 2, "file_name": "120_02.png", "page": 3, "dpi": 300, "bbox": [494, 73, 720, 502], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) An oc-graph W ; the clusters are depicted as rectangles. Clusters \u03bc1 , \u03bd1 and clusters \u03bc2 , \u03bd2 are overlapping clusters. (b) The inclusion digraph of W . ", "caption_bbox": [440, 521, 775, 560]}, {"image_id": 3, "file_name": "120_03.png", "page": 4, "dpi": 300, "bbox": [508, 74, 707, 415], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Illustration of the procedure that constructs a cluster region, described in the proof of Theorem 2. R(\u03b1 ) is constructed from the drawings of G and of regions R(\u03b3 ),R(\u03b4 ). ", "caption_bbox": [440, 433, 775, 473]}, {"image_id": 4, "file_name": "120_04.png", "page": 5, "dpi": 300, "bbox": [131, 73, 352, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) An oc-planar toc-graph W . Grey vertices belong to the overlap. (b) The c-image C of W ; C is not c-planar. ", "caption_bbox": [73, 340, 408, 366]}, {"image_id": 5, "file_name": "120_05.png", "page": 5, "dpi": 300, "bbox": [496, 75, 719, 444], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) A toc-graph W ; the drawing depicted in the figure is not oc-planar, since the two edges in bold are not completely inside the region of \u03bc ; an oc-planar drawing of W with this embedding cannot exist. (b) A c-planar drawing of the c-image C of W . (c) An oc-planar drawing of W obtained by changing its original embedding; namely, face f is chosen as the new external face. ", "caption_bbox": [440, 463, 775, 541]}, {"image_id": 6, "file_name": "120_06.png", "page": 6, "dpi": 300, "bbox": [111, 434, 359, 738], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Illustration of the procedure described in Lemma 2 to mod- ify an oc-planar drawing of a toc-graph W into a c-planar drawing of the c-image of W . ", "caption_bbox": [73, 756, 408, 795]}, {"image_id": 7, "file_name": "120_07.png", "page": 7, "dpi": 300, "bbox": [102, 73, 382, 374], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) A moc-graph W that is not oc-planar; the drawing in the figure is not oc-planar since the three edges in bold should be completely inside the region of \u03bc . (b) A c-planar drawing of the c- image C of W . ", "caption_bbox": [73, 392, 409, 444]}], "121": [{"image_id": 0, "file_name": "121_00.png", "page": 2, "dpi": 300, "bbox": [84, 271, 410, 583], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A 4-side many-to-one labeling with type-s leaders.", "caption_bbox": [94, 616, 387, 628]}, {"image_id": 1, "file_name": "121_01.png", "page": 2, "dpi": 300, "bbox": [157, 66, 694, 198], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Illustration of leaders.", "caption_bbox": [347, 228, 501, 240]}, {"image_id": 2, "file_name": "121_02.png", "page": 3, "dpi": 300, "bbox": [512, 160, 706, 381], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An example reducing from DCP to DMCP.", "caption_bbox": [480, 412, 734, 424]}, {"image_id": 3, "file_name": "121_03.png", "page": 3, "dpi": 300, "bbox": [545, 456, 670, 540], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The first category of crossings.", "caption_bbox": [507, 571, 707, 583]}, {"image_id": 4, "file_name": "121_04.png", "page": 3, "dpi": 300, "bbox": [506, 614, 711, 713], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The second category of crossings.", "caption_bbox": [498, 749, 716, 761]}, {"image_id": 5, "file_name": "121_05.png", "page": 4, "dpi": 300, "bbox": [85, 565, 398, 883], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The distribution of some animals in Taiwan, which is repre- sented by one-side many-to-one labeling with type-opo leaders. ", "caption_bbox": [73, 913, 408, 938]}, {"image_id": 6, "file_name": "121_06.png", "page": 5, "dpi": 300, "bbox": [162, 70, 324, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "                                                            N                N  Figure 7: G0 (L00 , LL0 , LR0 , E 0 ) with |L00 | = N + n(2 2 + 2) = N + 5(2 2 + 2), |LL0 | = 5, and LR0 = L1 . ", "caption_bbox": [74, 415, 409, 445]}, {"image_id": 7, "file_name": "121_07.png", "page": 6, "dpi": 300, "bbox": [86, 420, 397, 669], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The distribution of some animals in Taiwan, which is repre- sented by two-side many-to-one labeling with type-opo leaders. ", "caption_bbox": [73, 696, 408, 721]}, {"image_id": 8, "file_name": "121_08.png", "page": 6, "dpi": 300, "bbox": [533, 377, 684, 463], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A special case of DCP1ML-po where the y-coordinate of any site is less than that of the top border of the lowest label. Note that some of the edges are not shown in the figure. ", "caption_bbox": [440, 493, 775, 532]}, {"image_id": 9, "file_name": "121_09.png", "page": 7, "dpi": 300, "bbox": [449, 69, 771, 604], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The experimental results for the special case of DCP1ML- po where the y-coordinate of any site is less than that of the top border of the lowest label. ", "caption_bbox": [440, 635, 775, 674]}], "122": [{"image_id": 0, "file_name": "122_00.png", "page": 1, "dpi": 300, "bbox": [424, 144, 750, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Traditional drawing and rectangular layout of tree.", "caption_bbox": [462, 382, 752, 395]}, {"image_id": 1, "file_name": "122_01.png", "page": 2, "dpi": 300, "bbox": [589, 287, 627, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Middle edge", "caption_bbox": [552, 338, 662, 351]}, {"image_id": 2, "file_name": "122_02.png", "page": 2, "dpi": 300, "bbox": [125, 231, 359, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) st-graph G (b) extended st-graph G with edge sets T1 (dotted) and T2 ", "caption_bbox": [73, 376, 408, 403]}, {"image_id": 3, "file_name": "122_03.png", "page": 3, "dpi": 300, "bbox": [483, 75, 742, 164], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) The forbidden graph F . (b) Quadrilateral face (c) Trian- gulation of a quadrilateral face ", "caption_bbox": [440, 176, 775, 202]}, {"image_id": 4, "file_name": "122_04.png", "page": 4, "dpi": 300, "bbox": [112, 723, 359, 797], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) Filled triangle yielding F (b) All embeddings with filled triangle (c) Subgraph F but no filled triangle ", "caption_bbox": [73, 808, 408, 834]}, {"image_id": 5, "file_name": "122_05.png", "page": 4, "dpi": 300, "bbox": [140, 76, 357, 227], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) Triangulation of a non-quadrilateral face (b) Triangulat- ing a boundary path ", "caption_bbox": [73, 238, 408, 264]}], "123": [{"image_id": 0, "file_name": "123_00.png", "page": 2, "dpi": 300, "bbox": [460, 76, 756, 257], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The Base Case.", "caption_bbox": [543, 273, 672, 286]}, {"image_id": 1, "file_name": "123_01.png", "page": 2, "dpi": 300, "bbox": [96, 74, 385, 209], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A non-level planar and level planar drawing of spanning tree DAGs (solid edges). ", "caption_bbox": [73, 226, 408, 252]}, {"image_id": 2, "file_name": "123_02.png", "page": 3, "dpi": 300, "bbox": [462, 74, 755, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Tv smothers r.", "caption_bbox": [548, 279, 667, 293]}, {"image_id": 3, "file_name": "123_03.png", "page": 3, "dpi": 300, "bbox": [93, 74, 389, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Row j of M(T ) has more than two entries and so T with leveling \u03c6 is not level planar. ", "caption_bbox": [73, 356, 408, 382]}, {"image_id": 4, "file_name": "123_04.png", "page": 4, "dpi": 300, "bbox": [459, 93, 757, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Storing M(T ) in sparse form.", "caption_bbox": [512, 262, 702, 275]}, {"image_id": 5, "file_name": "123_05.png", "page": 4, "dpi": 300, "bbox": [94, 74, 386, 331], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Two typical examples of the MNLP tree pattern ((a) and (b)) and the dummy vertices added to each to ensure level planarity ((c) and (d) respectively). ", "caption_bbox": [73, 347, 408, 386]}, {"image_id": 6, "file_name": "123_06.png", "page": 5, "dpi": 300, "bbox": [93, 291, 372, 657], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The partitioning of the edge set in Fig. 7.", "caption_bbox": [117, 673, 365, 686]}, {"image_id": 7, "file_name": "123_07.png", "page": 5, "dpi": 300, "bbox": [94, 93, 365, 221], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Each edge in E \\ ET (the dashed edges) completes a fun- damental cycle. ", "caption_bbox": [73, 236, 408, 262]}, {"image_id": 8, "file_name": "123_08.png", "page": 6, "dpi": 300, "bbox": [128, 75, 722, 503], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The dependency graph for Python packages.", "caption_bbox": [289, 518, 558, 531]}], "124": [{"image_id": 0, "file_name": "124_00.png", "page": 1, "dpi": 300, "bbox": [492, 757, 725, 901], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Sloping input line.", "caption_bbox": [550, 918, 664, 929]}, {"image_id": 1, "file_name": "124_01.png", "page": 1, "dpi": 300, "bbox": [461, 620, 754, 696], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Horizontal input line.", "caption_bbox": [544, 713, 670, 724]}, {"image_id": 2, "file_name": "124_02.png", "page": 2, "dpi": 300, "bbox": [457, 75, 595, 163], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration of 4P model.", "caption_bbox": [456, 180, 594, 191]}, {"image_id": 3, "file_name": "124_03.png", "page": 2, "dpi": 300, "bbox": [627, 75, 765, 163], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Illustration of 4S model.", "caption_bbox": [626, 180, 763, 191]}, {"image_id": 4, "file_name": "124_04.png", "page": 3, "dpi": 300, "bbox": [131, 585, 355, 919], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Different schedules obtained for the i-th job Ji .", "caption_bbox": [129, 934, 353, 946]}, {"image_id": 5, "file_name": "124_05.png", "page": 4, "dpi": 300, "bbox": [115, 668, 367, 750], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: For each site si , a job Ji of processing times wi is introduced.", "caption_bbox": [102, 768, 380, 780]}, {"image_id": 6, "file_name": "124_06.png", "page": 5, "dpi": 300, "bbox": [509, 233, 708, 532], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Processing time pi of job Ji .", "caption_bbox": [531, 547, 683, 559]}, {"image_id": 7, "file_name": "124_07.png", "page": 6, "dpi": 300, "bbox": [136, 453, 347, 631], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A label of large height effects the placement of a label later on the order", "caption_bbox": [80, 649, 401, 660]}], "125": [{"image_id": 0, "file_name": "125_00.png", "page": 2, "dpi": 300, "bbox": [89, 431, 396, 597], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Information \ufb02ow", "caption_bbox": [177, 618, 304, 630]}, {"image_id": 1, "file_name": "125_01.png", "page": 2, "dpi": 300, "bbox": [107, 73, 367, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview", "caption_bbox": [193, 314, 288, 326]}, {"image_id": 2, "file_name": "125_02.png", "page": 2, "dpi": 300, "bbox": [440, 705, 714, 962], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visualization of TCP port and interaction", "caption_bbox": [484, 987, 731, 999]}, {"image_id": 3, "file_name": "125_03.png", "page": 3, "dpi": 300, "bbox": [103, 632, 385, 857], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An expansion view", "caption_bbox": [170, 876, 311, 888]}, {"image_id": 4, "file_name": "125_04.png", "page": 4, "dpi": 300, "bbox": [103, 73, 393, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualizing only attacks to SSH.", "caption_bbox": [138, 320, 343, 332]}, {"image_id": 5, "file_name": "125_05.png", "page": 4, "dpi": 300, "bbox": [92, 346, 399, 574], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Hiding attacks to SSH", "caption_bbox": [162, 593, 319, 605]}], "126": [{"image_id": 0, "file_name": "126_00.png", "page": 2, "dpi": 300, "bbox": [99, 93, 364, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Multiple networks", "caption_bbox": [173, 250, 308, 262]}, {"image_id": 1, "file_name": "126_01.png", "page": 2, "dpi": 300, "bbox": [466, 74, 751, 194], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: PivotGraph", "caption_bbox": [555, 210, 659, 222]}, {"image_id": 2, "file_name": "126_02.png", "page": 3, "dpi": 300, "bbox": [108, 73, 741, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Landscape-metaphor visualization", "caption_bbox": [315, 251, 532, 263]}, {"image_id": 3, "file_name": "126_03.png", "page": 4, "dpi": 300, "bbox": [501, 418, 714, 557], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The e(n, v) f unction", "caption_bbox": [537, 574, 677, 586]}, {"image_id": 4, "file_name": "126_04.png", "page": 5, "dpi": 300, "bbox": [87, 83, 768, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visual parameters of attribute surface", "caption_bbox": [308, 265, 541, 277]}, {"image_id": 5, "file_name": "126_05.png", "page": 6, "dpi": 300, "bbox": [88, 82, 768, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Reducing attribute surface polygon number", "caption_bbox": [294, 232, 555, 244]}, {"image_id": 6, "file_name": "126_06.png", "page": 7, "dpi": 300, "bbox": [108, 321, 748, 495], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Various parameter settings of GraphScape.", "caption_bbox": [293, 513, 554, 525]}, {"image_id": 7, "file_name": "126_07.png", "page": 7, "dpi": 300, "bbox": [102, 80, 752, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Scale-free network with 101 nodes and 153 edges.", "caption_bbox": [275, 287, 574, 299]}, {"image_id": 8, "file_name": "126_08.png", "page": 8, "dpi": 300, "bbox": [104, 482, 384, 934], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Combination with existing approach and the effect of new layout algorithm ", "caption_bbox": [73, 952, 408, 977]}, {"image_id": 9, "file_name": "126_09.png", "page": 8, "dpi": 300, "bbox": [123, 114, 364, 375], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Padgett\u2019s Florentine families with \u201cwealth\u201d and \u201cpriorates\u201d", "caption_bbox": [77, 403, 404, 415]}, {"image_id": 10, "file_name": "126_10.png", "page": 8, "dpi": 300, "bbox": [470, 95, 743, 938], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Protein-protein interaction network with 1458 nodes and 1948 edges. ", "caption_bbox": [440, 956, 775, 981]}], "127": [{"image_id": 0, "file_name": "127_00.png", "page": 2, "dpi": 300, "bbox": [73, 73, 778, 437], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A view of the overall interface.", "caption_bbox": [326, 452, 522, 464]}, {"image_id": 1, "file_name": "127_01.png", "page": 3, "dpi": 300, "bbox": [74, 485, 409, 731], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A view of the file repository. The repository directory hier- archy structure appears on the left and the file evolution sparklines appear on the right. The highlighted file shows typical growth. ", "caption_bbox": [73, 746, 408, 785]}, {"image_id": 2, "file_name": "127_02.png", "page": 3, "dpi": 300, "bbox": [441, 73, 776, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A file details dialog. The contributions from William A. Rowe, Sander Striker, and Allan Edwards have been highlighted. ", "caption_bbox": [440, 271, 775, 296]}, {"image_id": 3, "file_name": "127_03.png", "page": 4, "dpi": 300, "bbox": [439, 74, 737, 375], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Expanding the diagram shows more edge detail.", "caption_bbox": [464, 391, 750, 403]}, {"image_id": 4, "file_name": "127_04.png", "page": 4, "dpi": 300, "bbox": [73, 305, 376, 626], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Compressing the diagram displays more timesteps at once. Hiding edges provides a cleaner visualization. ", "caption_bbox": [73, 641, 408, 666]}, {"image_id": 5, "file_name": "127_05.png", "page": 5, "dpi": 300, "bbox": [439, 450, 774, 652], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Email header information corresponding to Ben Laurie in September, 1998. ", "caption_bbox": [440, 666, 775, 691]}, {"image_id": 6, "file_name": "127_06.png", "page": 5, "dpi": 300, "bbox": [73, 73, 366, 522], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An example of selection highlighting. The selected person\u2019s nodes and edges are colored in red. ", "caption_bbox": [73, 536, 408, 561]}, {"image_id": 7, "file_name": "127_07.png", "page": 5, "dpi": 300, "bbox": [439, 73, 739, 406], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Multiple people may be selected.", "caption_bbox": [502, 421, 712, 433]}, {"image_id": 8, "file_name": "127_08.png", "page": 6, "dpi": 300, "bbox": [73, 468, 360, 918], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The period leading up to the alpha release of Apache 2.0 in March, 2000. The graph appears uniform at the top, then more small clusters form as each month passes. There is a dramatic frag- mentation of clusters in February, 2000, before finally returning to uniformity. ", "caption_bbox": [73, 933, 408, 998]}, {"image_id": 9, "file_name": "127_09.png", "page": 6, "dpi": 300, "bbox": [73, 75, 343, 427], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Overview of the Apache email network.", "caption_bbox": [120, 442, 361, 454]}, {"image_id": 10, "file_name": "127_10.png", "page": 6, "dpi": 300, "bbox": [439, 545, 737, 939], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Ken Coar (highlighted in red) joined the email list in De- cember, 1996. He is still a regular code contributor, though his email list involvement has become more sporadic. ", "caption_bbox": [440, 954, 775, 993]}, {"image_id": 11, "file_name": "127_11.png", "page": 6, "dpi": 300, "bbox": [439, 85, 549, 481], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Rob McCool, author of the original HTTP daemon, helped the Apache project during its infancy, then left the discussion. ", "caption_bbox": [440, 495, 775, 520]}, {"image_id": 12, "file_name": "127_12.png", "page": 7, "dpi": 300, "bbox": [439, 524, 707, 956], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Two anomalies at 1999.04 and 2000.04 in the PostgreSQL email network. ", "caption_bbox": [440, 971, 775, 996]}, {"image_id": 13, "file_name": "127_13.png", "page": 7, "dpi": 300, "bbox": [439, 79, 743, 476], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Overview of the PostgreSQL email network.", "caption_bbox": [473, 491, 743, 503]}], "128": [{"image_id": 0, "file_name": "128_00.png", "page": 2, "dpi": 300, "bbox": [102, 74, 381, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: (p, q : n1 , n2 ) for IMDB", "caption_bbox": [533, 85, 682, 101]}, {"image_id": 1, "file_name": "128_01.png", "page": 3, "dpi": 300, "bbox": [479, 294, 738, 545], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Charlie Brown", "caption_bbox": [548, 576, 667, 589]}, {"image_id": 2, "file_name": "128_02.png", "page": 3, "dpi": 300, "bbox": [112, 576, 372, 857], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (27,22)-core", "caption_bbox": [186, 886, 296, 899]}, {"image_id": 3, "file_name": "128_03.png", "page": 3, "dpi": 300, "bbox": [125, 75, 358, 513], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (247,2)-core", "caption_bbox": [186, 543, 296, 556]}, {"image_id": 4, "file_name": "128_04.png", "page": 4, "dpi": 300, "bbox": [477, 74, 740, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Shawqi, Farid and El-Meliguy, Mahmoud", "caption_bbox": [483, 344, 730, 357]}, {"image_id": 5, "file_name": "128_05.png", "page": 4, "dpi": 300, "bbox": [113, 74, 371, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Mower, Jack and Phelps, Lee", "caption_bbox": [144, 418, 337, 431]}, {"image_id": 6, "file_name": "128_06.png", "page": 4, "dpi": 300, "bbox": [114, 451, 372, 714], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Adult", "caption_bbox": [203, 744, 278, 757]}, {"image_id": 7, "file_name": "128_07.png", "page": 4, "dpi": 300, "bbox": [491, 381, 724, 717], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Polizeiruf 110 and Starkes Team", "caption_bbox": [503, 749, 711, 762]}, {"image_id": 8, "file_name": "128_08.png", "page": 5, "dpi": 300, "bbox": [111, 74, 373, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Graph sizes per decade of co-starring network", "caption_bbox": [105, 577, 376, 590]}, {"image_id": 9, "file_name": "128_09.png", "page": 5, "dpi": 300, "bbox": [497, 97, 783, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The co-starring actors visualisation (1960s)", "caption_bbox": [474, 370, 741, 383]}, {"image_id": 10, "file_name": "128_10.png", "page": 5, "dpi": 300, "bbox": [447, 399, 789, 659], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The co-starring actors visualisation (1970s)", "caption_bbox": [474, 696, 741, 709]}, {"image_id": 11, "file_name": "128_11.png", "page": 6, "dpi": 300, "bbox": [104, 411, 351, 659], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: The co-starring actors visualisation (1990s)", "caption_bbox": [107, 695, 374, 708]}, {"image_id": 12, "file_name": "128_12.png", "page": 6, "dpi": 300, "bbox": [72, 76, 421, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: The co-starring actors visualisation (1980s)", "caption_bbox": [107, 370, 374, 383]}, {"image_id": 13, "file_name": "128_13.png", "page": 6, "dpi": 300, "bbox": [455, 85, 750, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: The co-starring actors visualisation (2000s)", "caption_bbox": [474, 370, 741, 383]}, {"image_id": 14, "file_name": "128_14.png", "page": 7, "dpi": 300, "bbox": [501, 358, 716, 562], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 18: Same group of people in several movie.", "caption_bbox": [483, 591, 733, 604]}, {"image_id": 15, "file_name": "128_15.png", "page": 7, "dpi": 300, "bbox": [82, 73, 402, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: A frame from the galaxy of stars animation", "caption_bbox": [109, 359, 372, 372]}, {"image_id": 16, "file_name": "128_16.png", "page": 7, "dpi": 300, "bbox": [501, 73, 716, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 17: Many actors co-starring one movie.", "caption_bbox": [493, 331, 721, 344]}, {"image_id": 17, "file_name": "128_17.png", "page": 7, "dpi": 300, "bbox": [134, 385, 349, 595], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Actor collaboration pattern in early years.", "caption_bbox": [112, 625, 369, 638]}, {"image_id": 18, "file_name": "128_18.png", "page": 8, "dpi": 300, "bbox": [448, 601, 768, 898], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 22: Layout of 1994", "caption_bbox": [543, 927, 671, 940]}, {"image_id": 19, "file_name": "128_19.png", "page": 8, "dpi": 300, "bbox": [82, 598, 402, 902], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 20: Layout of 1988", "caption_bbox": [176, 931, 304, 944]}, {"image_id": 20, "file_name": "128_20.png", "page": 8, "dpi": 300, "bbox": [448, 133, 768, 431], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 21: Layout of 1991", "caption_bbox": [543, 460, 671, 473]}, {"image_id": 21, "file_name": "128_21.png", "page": 8, "dpi": 300, "bbox": [82, 129, 402, 435], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 19: Layout of 1985", "caption_bbox": [176, 464, 304, 477]}], "129": [{"image_id": 0, "file_name": "129_00.png", "page": 3, "dpi": 300, "bbox": [73, 74, 411, 412], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A graph of emails over the period of 1 hour. Sources are on the left, destinations on the right, and semitransparent lines are drawn between them to represent emails (known spam is colored red). Blue delimitates different domains, and the orange line desig- nates the current focus, which is labeled. Bulk email (such as spam) forms fan like shapes from one source to many destinations. As can be seen, in this hour most of the spam originated from a select few sources. ", "caption_bbox": [73, 427, 409, 532]}, {"image_id": 1, "file_name": "129_01.png", "page": 3, "dpi": 300, "bbox": [73, 541, 411, 879], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A months worth of emails shown in a scatterplot. Sources are on the left, destinations are along the bottom. Points represent emails. Bulk mail, such as most spam, appear as horizontal lines (one source, many destinations). Another odd pattern revealed here is the set of vertical lines (many sources, one destination). Interest- ingly, many of these vertical lines have very similar patterns, indicat- ing the same set of sources. This might indicate a spammer that is using a botnet to send email from distributed, compromised sources. ", "caption_bbox": [73, 893, 409, 998]}, {"image_id": 2, "file_name": "129_02.png", "page": 4, "dpi": 300, "bbox": [439, 534, 777, 872], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A detail view of the email originating from a selected ad- dress, and the emails originating from the addresses it sent emails to. The size of each segment of the ring corresponds to what per- centage of the email was sent there, and the color is random. Color and position of the nodes in the middle are derived from the color and position of each address in the first level that sent it email. This is useful for showing patterns such as email relays, where spam is forwarded by a compromised user. ", "caption_bbox": [440, 886, 776, 991]}, {"image_id": 3, "file_name": "129_03.png", "page": 4, "dpi": 300, "bbox": [73, 73, 778, 159], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A timeline view of the emails per hour over a month. The red area represents the portion of the emails that are known spam according to Spam Assassin. The grey region is the currently selected time period. A repeating pattern of five large peaks followed by two smaller (or nonexistent) peaks corresponds to the five day work week plus two day weekends. ", "caption_bbox": [73, 173, 775, 212]}, {"image_id": 4, "file_name": "129_04.png", "page": 4, "dpi": 300, "bbox": [73, 237, 411, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: One option for presenting the time aspect of the data is to animate it, either by showing sequential time-steps or by showing a sliding time window. Three consecutive frames are shown here. In them, it can be seen that some patterns are persistent while others come and go. ", "caption_bbox": [73, 379, 408, 444]}, {"image_id": 5, "file_name": "129_05.png", "page": 4, "dpi": 300, "bbox": [439, 246, 777, 414], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: In order to see details more clearly, a capability was added to zoom into regions of the scatterplot. In this image, the ucdavis.edu domain was focused on for both sources and destinations. This re- veals an interesting pattern of a diagonal line, which is indicative of people emailing themselves. Zooming into the graph is done very similarly. ", "caption_bbox": [440, 429, 775, 507]}, {"image_id": 6, "file_name": "129_06.png", "page": 5, "dpi": 300, "bbox": [76, 74, 408, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Email marked as spam by Spam Assassin over the whole month. (b), (c), and (d) focus on some of the larger domains. In it we can see that ucdavis.edu is the source for a lot of spam, yahoo.com for less, and hotmail.com for even less. ", "caption_bbox": [73, 443, 408, 495]}, {"image_id": 7, "file_name": "129_07.png", "page": 5, "dpi": 300, "bbox": [439, 374, 591, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: One to many and many to one spam patterns. These kinds of patterns are fairly common to spam. ", "caption_bbox": [440, 314, 775, 340]}, {"image_id": 8, "file_name": "129_08.png", "page": 6, "dpi": 300, "bbox": [49, 1038, 740, 1094], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: An email pattern similar to that of a set of spam relays. However, in this case this traffic was not actually spam.", "caption_bbox": [126, 936, 721, 949]}, {"image_id": 9, "file_name": "129_09.png", "page": 7, "dpi": 300, "bbox": [73, 73, 778, 421], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: A recurring traffic burst. About a day apart, these patterns show emails from one source to one destination that were sent many times. Investigation reveals that these are emails that were repeatedly deferred by the server. ", "caption_bbox": [73, 435, 775, 461]}, {"image_id": 10, "file_name": "129_10.png", "page": 8, "dpi": 300, "bbox": [76, 74, 410, 255], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: An anomalous pattern. These emails match up with the standard work week pattern yet are from one source to exactly two destinations. Possibly caused by an automatic forwarding script. ", "caption_bbox": [73, 272, 408, 311]}], "130": [{"image_id": 0, "file_name": "130_00.png", "page": 2, "dpi": 300, "bbox": [134, 145, 349, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The NICTA email network.", "caption_bbox": [152, 368, 330, 380]}, {"image_id": 1, "file_name": "130_01.png", "page": 3, "dpi": 300, "bbox": [516, 75, 713, 200], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The giant component of the e-mail network, with edges representing at least 100 e-mail messages. ", "caption_bbox": [440, 228, 775, 253]}, {"image_id": 2, "file_name": "130_02.png", "page": 3, "dpi": 300, "bbox": [134, 75, 347, 536], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Spherical drawing of the NICTA email network.", "caption_bbox": [102, 555, 380, 567]}, {"image_id": 3, "file_name": "130_03.png", "page": 4, "dpi": 300, "bbox": [136, 79, 346, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The giant component of an email network with 2.5D hierar- chical layout ", "caption_bbox": [73, 410, 408, 435]}, {"image_id": 4, "file_name": "130_04.png", "page": 4, "dpi": 300, "bbox": [502, 480, 731, 731], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Long inter-plate edges.", "caption_bbox": [526, 789, 689, 801]}, {"image_id": 5, "file_name": "130_05.png", "page": 4, "dpi": 300, "bbox": [142, 456, 345, 596], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Combined visual representation of two centrality values: edge directions related to degree centrality values; node size related to eigenvector centrality values. ", "caption_bbox": [73, 613, 408, 652]}, {"image_id": 6, "file_name": "130_06.png", "page": 5, "dpi": 300, "bbox": [531, 78, 694, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Draw one plate after another using good initialization.", "caption_bbox": [452, 359, 762, 371]}, {"image_id": 7, "file_name": "130_07.png", "page": 5, "dpi": 300, "bbox": [155, 166, 328, 889], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Using a supergraph with added forces between plates.", "caption_bbox": [83, 908, 399, 920]}, {"image_id": 8, "file_name": "130_08.png", "page": 6, "dpi": 300, "bbox": [100, 647, 382, 901], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Virus Infection.", "caption_bbox": [176, 931, 305, 943]}, {"image_id": 9, "file_name": "130_09.png", "page": 6, "dpi": 300, "bbox": [466, 343, 751, 635], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Highlight the infected server by applying degree centrality.", "caption_bbox": [440, 664, 775, 676]}, {"image_id": 10, "file_name": "130_10.png", "page": 6, "dpi": 300, "bbox": [121, 322, 367, 561], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Two-mode Email Network.", "caption_bbox": [152, 593, 330, 605]}, {"image_id": 11, "file_name": "130_11.png", "page": 7, "dpi": 300, "bbox": [134, 804, 349, 961], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Ambient display of an email network.", "caption_bbox": [123, 976, 359, 988]}, {"image_id": 12, "file_name": "130_12.png", "page": 7, "dpi": 300, "bbox": [424, 1038, 802, 1094], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Ambient display in general environment.", "caption_bbox": [481, 942, 733, 954]}, {"image_id": 13, "file_name": "130_13.png", "page": 7, "dpi": 300, "bbox": [99, 483, 384, 732], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Infected computers acted as fake servers", "caption_bbox": [112, 761, 369, 773]}, {"image_id": 14, "file_name": "130_14.png", "page": 7, "dpi": 300, "bbox": [501, 781, 716, 926], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Social circles.", "caption_bbox": [546, 668, 669, 680]}, {"image_id": 15, "file_name": "130_15.png", "page": 7, "dpi": 300, "bbox": [178, 73, 672, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Email virus propagation.", "caption_bbox": [337, 413, 512, 425]}], "131": [{"image_id": 0, "file_name": "131_00.png", "page": 2, "dpi": 300, "bbox": [178, 74, 672, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A graph laid out using our treemap based approach. This graph portrays the links between websites that came from a search on the word \u201cCalifornia\u201d [7]. Nodes are clustered into a hierarchy, and laid out by applying a treemap to this hierarchy. Levels of the hierarchy below a threshold are clustered together into larger nodes. It can very easily be seen that there are three primary groups of websites that link to each other, and a plethora of others that are not as tightly linked. ", "caption_bbox": [73, 372, 775, 424]}, {"image_id": 1, "file_name": "131_01.png", "page": 3, "dpi": 300, "bbox": [76, 73, 405, 207], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The overall method. Divide screenspace into regions by applying a treemap to a hierarchical clustering of a graph, then place each node in its associated region. ", "caption_bbox": [73, 225, 408, 264]}, {"image_id": 2, "file_name": "131_02.png", "page": 3, "dpi": 300, "bbox": [481, 73, 736, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A graph laid out with our technique. The dataset shown is a graph of similarity between network scans [19]. ", "caption_bbox": [440, 342, 775, 367]}, {"image_id": 3, "file_name": "131_03.png", "page": 4, "dpi": 300, "bbox": [76, 74, 777, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Enhancements to the approach. Difficulties due to the use of treemaps (a), and two techniques to alleviate problems due to collinear vertices: splining (b) and randomization (c). Randomization also helps with narrow regions of the treemap. ", "caption_bbox": [73, 293, 775, 318]}, {"image_id": 4, "file_name": "131_04.png", "page": 4, "dpi": 300, "bbox": [85, 369, 399, 540], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Improved treemap splitting. Edges can sometimes stretch across clusters. By taking these edges into account during the treemap subdivision process, quality can be improved at the cost of complexity. ", "caption_bbox": [73, 572, 408, 624]}, {"image_id": 5, "file_name": "131_05.png", "page": 5, "dpi": 300, "bbox": [456, 73, 761, 378], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Scalability. Our approach can scale to very large networks while still maintaining interactivity. |V | = 321, 270, |E| = 800, 172 ", "caption_bbox": [440, 406, 775, 431]}, {"image_id": 6, "file_name": "131_06.png", "page": 5, "dpi": 300, "bbox": [89, 73, 394, 378], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Cluster seperation. Nesting the first n levels of the treemap separates clusters, which better shows inter-cluster relationships. ", "caption_bbox": [73, 406, 408, 431]}, {"image_id": 7, "file_name": "131_07.png", "page": 6, "dpi": 300, "bbox": [108, 73, 374, 931], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Treemap Layout versus force-directed layouts (LinLog [21] and the Grid-Variant Algorithm (GVA) [13] based on Fruchterman- Reingold). The treemap based layout takes far less time to produce, and details such as the interior of the clusters can be clearly seen. ", "caption_bbox": [73, 950, 408, 1002]}, {"image_id": 8, "file_name": "131_08.png", "page": 7, "dpi": 300, "bbox": [76, 423, 796, 915], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: A treemap based layout can also be used as a preprocessing step for a force-directed layout. After only 10 iterations of the force- directed layout starting with the treemap layout the results are comparable to 135 iterations starting from randomized positions. The value of the energy function being minimized by LinLog is given for each iteration. ", "caption_bbox": [73, 947, 775, 986]}, {"image_id": 9, "file_name": "131_09.png", "page": 7, "dpi": 300, "bbox": [79, 88, 809, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A treemap based layout can be used to show focus plus context easily through means of semantic zooming and distortion. (a) shows a high level abstraction of the \u201cCalifornia\u201d graph [7]. In (b) one of the clusters has been expanded with a semantic zoom, and in (c) the graph has been distorted to show the expanded cluster in more detail. ", "caption_bbox": [73, 346, 775, 385]}], "132": [{"image_id": 0, "file_name": "132_00.png", "page": 2, "dpi": 300, "bbox": [501, 75, 716, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Two visualizations of the same multivariate network.", "caption_bbox": [456, 335, 759, 347]}, {"image_id": 1, "file_name": "132_01.png", "page": 4, "dpi": 300, "bbox": [168, 368, 313, 480], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Graph distance distributions of the friendship network and the advice network. ", "caption_bbox": [73, 481, 408, 506]}, {"image_id": 2, "file_name": "132_02.png", "page": 4, "dpi": 300, "bbox": [490, 398, 726, 676], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visualizations of the student friendship network.", "caption_bbox": [466, 681, 750, 693]}, {"image_id": 3, "file_name": "132_03.png", "page": 6, "dpi": 300, "bbox": [141, 73, 342, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualizations of network 4 in user study.", "caption_bbox": [117, 334, 365, 346]}, {"image_id": 4, "file_name": "132_04.png", "page": 7, "dpi": 300, "bbox": [456, 558, 761, 899], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: World military expenditure and arms transfer networks.", "caption_bbox": [449, 904, 766, 916]}, {"image_id": 5, "file_name": "132_05.png", "page": 7, "dpi": 300, "bbox": [119, 479, 365, 624], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Part 1: Average response time and accuracy.", "caption_bbox": [104, 629, 374, 641]}, {"image_id": 6, "file_name": "132_06.png", "page": 8, "dpi": 300, "bbox": [466, 74, 751, 400], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The ratios of military to non-military imports in two periods.", "caption_bbox": [440, 405, 775, 417]}], "133": [{"image_id": 0, "file_name": "133_00.png", "page": 1, "dpi": 300, "bbox": [73, 86, 777, 480], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A protein-protein interaction dataset (100,000 nodes and 1,000,000 edges) visualized using ZAME at two different levels of zoom.", "caption_bbox": [83, 495, 765, 507]}, {"image_id": 1, "file_name": "133_01.png", "page": 2, "dpi": 300, "bbox": [440, 76, 777, 164], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of the components of ZAME.", "caption_bbox": [488, 194, 727, 206]}, {"image_id": 2, "file_name": "133_02.png", "page": 3, "dpi": 300, "bbox": [440, 75, 776, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Conceptual structure of the aggregated graph pyramid.", "caption_bbox": [448, 303, 766, 315]}, {"image_id": 3, "file_name": "133_03.png", "page": 5, "dpi": 300, "bbox": [444, 284, 772, 449], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Results of the HDE (left) and NNTSP (right) reordering algorithms applied to a social network. ", "caption_bbox": [440, 478, 775, 503]}, {"image_id": 4, "file_name": "133_04.png", "page": 6, "dpi": 300, "bbox": [440, 76, 777, 245], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Matrix visualization rendering pipeline.", "caption_bbox": [489, 274, 726, 286]}, {"image_id": 5, "file_name": "133_05.png", "page": 7, "dpi": 300, "bbox": [440, 75, 770, 375], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Schematic overview of the glyph fragment shader.", "caption_bbox": [460, 407, 754, 419]}, {"image_id": 6, "file_name": "133_06.png", "page": 7, "dpi": 300, "bbox": [74, 75, 410, 108], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Eight different glyphs for aggregated edges (color shade, average, min/max histogram, min/max range, min/max tribox, Tukey box, smooth histogram, step histogram). ", "caption_bbox": [73, 137, 408, 176]}, {"image_id": 7, "file_name": "133_07.png", "page": 8, "dpi": 300, "bbox": [73, 74, 777, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Overview (left image, with aggregation) and detail (right image, no aggregation) from visualizing the French Wikipedia using ZAME.", "caption_bbox": [79, 368, 768, 380]}], "134": [{"image_id": 0, "file_name": "134_00.png", "page": 2, "dpi": 300, "bbox": [442, 76, 772, 243], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2. These images show the FLASH dataset. Each image shows a different wrapping offset of the same data from the same view,, and the circled clusters are the same in each image. The clusters and sparse regions of the particles are clearly visible. The coloring is based on velocity magnitude which correlates highly with dense clusters of particles. Red represents low velocity, while light yellow represents high velocity. ", "caption_bbox": [440, 254, 775, 343]}, {"image_id": 1, "file_name": "134_01.png", "page": 2, "dpi": 300, "bbox": [76, 76, 409, 196], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1.. (a) The particles are arranged evenly on a 3D grid. (b) They are then perturbed slightly to satisfy the cosmological initial conditions. (c) The simulation then moves the particles based on gravitational forces                   es forming dense clusters and sparse regions. Notice that that the red particle moves so far left that it wraps around the edge. In reality, the particles are of course much smaller and the simulation has no collisions,, i.e. particle scattering is very small and ideally does not occur. ", "caption_bbox": [73, 207, 408, 309]}, {"image_id": 2, "file_name": "134_02.png", "page": 3, "dpi": 300, "bbox": [73, 77, 776, 666], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3. This zoomed view shows a comparison of the FLASH and HOT simulation results with the particles colored based on the velocity uncertainty. Yellow particles have the highest velocity uncertainty, while blue particles are more certain. The parallel coordinates view on the bottom shows a smooth gradient along the leftmost axes, velocity magnitude (Vmag) and location uncertainty (Loc Uncert). The bright yellow lines along the center of X, Y, and Z axes (on the left) represent the position of the dense and highly uncertain clusters in the center of the view. The difference in the force resolution of the two simulators results in high variation in the dense regions, which are bright yellow. ", "caption_bbox": [71, 676, 774, 740]}, {"image_id": 3, "file_name": "134_03.png", "page": 4, "dpi": 300, "bbox": [75, 679, 410, 900], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. The particles are colored based on the projection of their velocities along the Z axis. The blue particles are moving up, and the red particles are moving down. The image shows that the particles are gravitating toward the dense regions in the center. The positional axes (left three) show a clear correlation due to the bands of different color, whereas the uncertainty and velocity magnitude axes (right three) have a consistent intermediate color. ", "caption_bbox": [73, 910, 410, 999]}, {"image_id": 4, "file_name": "134_04.png", "page": 5, "dpi": 300, "bbox": [79, 76, 406, 182], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5.. This diagram illustrates the correlation of datasets. The grid (black box on the left) is the unperturbed locations for all of the particles. The Zel\u2019dovich approximation (red lines) progresses the particles to a particular time step. The simulation (blue lines) then progresses until the present time (time 0). Each circle represents a dataset that we have. We interpolated ted to obtain intermediate time steps. ", "caption_bbox": [73, 192, 408, 281]}, {"image_id": 5, "file_name": "134_05.png", "page": 5, "dpi": 300, "bbox": [442, 75, 778, 792], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6. The top image shows time step 50. The particles have high velocities and are still fairly even distributed. The parallel coordinates view provides a lot of insight about the data. The pattern between the X, Y, and Z axes on the left and the even brightness show that                    hat the data is evenly distributed and has little or no clusters. The velocity uncertainty and location uncertainty (rightmost axes) have log scales and show the limited variation at this time step caused by the approximation (which the dim red color also illustrates). ", "caption_bbox": [440, 815, 775, 930]}, {"image_id": 6, "file_name": "134_06.png", "page": 6, "dpi": 300, "bbox": [75, 472, 777, 899], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7. The top images are zoomed into a region of particles at redshift 10. Each particle is rendered as a small line oriented and sized by the velocity vector, and the color is representative of velocity uncertainty. The left image shows the particle positions and velocities if the Zel\u2019dovich approximation were taken to redshift 250. The particles in the right image were approximated to redshift 50. The structural                                                                                                                                s         forma- tion and coalescence of the particles is much more significant with the reduced approximation (left) tthan                                                                                                        han with the longer approximation (right), and varied density of the bright clusters best demonstrates this observation. ", "caption_bbox": [73, 910, 775, 974]}, {"image_id": 7, "file_name": "134_07.png", "page": 7, "dpi": 300, "bbox": [75, 236, 777, 939], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8. These images show a progression from redshift 50 to redshift 1. For each particle, a line colored by velocity extends from the  th position in one series to the position in another. As time advances, the variation between the series grows and becomes more structured. The time and series selection interface can be seen in the bottom left of each image with the darkened circles representing the currently                                                                                                                              c        active timesteps. ", "caption_bbox": [73, 949, 775, 1000]}], "135": [{"image_id": 0, "file_name": "135_00.png", "page": 1, "dpi": 300, "bbox": [73, 86, 777, 363], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Geographic map of the Washington Metropolitan Area with positions of metro network stations superimposed (left). A metro map layout of the same area optimized for readability (middle). In our compound map (right), the metro map is annotated with the warped geographic map. ", "caption_bbox": [73, 376, 775, 402]}, {"image_id": 1, "file_name": "135_01.png", "page": 4, "dpi": 300, "bbox": [111, 80, 741, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Undistorted grid (a) with \ufb01xed control points at the corners and one control point moving the middle of the grid p to a position outside of the grid q. The MLS method results in overlap in the 2D mapping function (b). Scaling the mapping yields a mapping function (c) which moves the control point closer to its destination position. Iterating this process and concatenating the partial mappings results in a mapping function (d) ful\ufb01lling the constraints without overlap. Note how the angles at the corner are still right angles after the mapping. ", "caption_bbox": [73, 265, 775, 317]}, {"image_id": 2, "file_name": "135_02.png", "page": 5, "dpi": 300, "bbox": [74, 117, 777, 903], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Geographic maps of Washington (top left) and Boston (bottom left). On the right, the maps are \ufb01tted to the respective schematic metro maps. Note that it is now possible to discern details in the cities\u2019 centers, which are not visible on the left, due to the \ufb01sheye-like character of the implied mapping functions. ", "caption_bbox": [73, 917, 775, 956]}, {"image_id": 3, "file_name": "135_03.png", "page": 7, "dpi": 300, "bbox": [78, 79, 779, 938], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The Warping Zoom (here shown on the diagonal in red) is a combination of zooming and at the same time warping between the schematized and the geographically correct map: This makes it possible to employ the schematized layout for an overview, and to employ a detailed geographical layout for localization and street-level navigation. Note that it is not possible to discern the connections in the center of Washington in the geographic overview (top left) in this resolution. ", "caption_bbox": [73, 958, 775, 1010]}, {"image_id": 4, "file_name": "135_04.png", "page": 8, "dpi": 300, "bbox": [439, 74, 779, 428], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Isolines around stations. The lines are at constant geo- graphic distance to the closest station, so that nearby stations are connected by blob-like shapes, while gaps between these shapes indicate large distances. ", "caption_bbox": [440, 441, 775, 493]}, {"image_id": 5, "file_name": "135_05.png", "page": 8, "dpi": 300, "bbox": [99, 79, 382, 423], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A regular grid distorted with the same mapping as the one used for warping the Washington data in Figure 3. The grid is used to render isolines around the stations in order to aid in the understand- ing of the geographical distance relations. ", "caption_bbox": [73, 444, 408, 496]}], "136": [{"image_id": 0, "file_name": "136_00.png", "page": 2, "dpi": 300, "bbox": [441, 74, 776, 407], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A typical view of StarGate.", "caption_bbox": [518, 422, 697, 435]}, {"image_id": 1, "file_name": "136_01.png", "page": 3, "dpi": 300, "bbox": [73, 74, 417, 402], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The Gate component. This is the directory hierarchy of the PostgreSQL version control repository. The documents directory is colored green (at the top) and the source code directory is colored in various shades of blue. ", "caption_bbox": [73, 417, 408, 469]}, {"image_id": 2, "file_name": "136_02.png", "page": 3, "dpi": 300, "bbox": [448, 74, 768, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Varied Gate visual parameters.", "caption_bbox": [507, 458, 708, 471]}, {"image_id": 3, "file_name": "136_03.png", "page": 4, "dpi": 300, "bbox": [496, 74, 721, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Positioning the stars. The positions are determined by the weighted centroid of the files the developer has modified. More modifications to a file means more weight is given to a file. ", "caption_bbox": [440, 323, 775, 362]}, {"image_id": 4, "file_name": "136_04.png", "page": 4, "dpi": 300, "bbox": [74, 74, 409, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The developer stars, sized in proportion to their project con- tributions. The top cluster (green) is the documenters. The bottom cluster (red) is the core developers. The blue stars in the middle have been selected. Their network connections are colored. ", "caption_bbox": [73, 408, 408, 460]}, {"image_id": 5, "file_name": "136_05.png", "page": 5, "dpi": 300, "bbox": [441, 74, 775, 407], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Three bursts of longitudinal activity in the /docs/icons/ directory. This indicates that the files in the directory were all modi- fied at about the same time. In chronological order, they were made by Roy T. Fielding (red), Martin Kraemer (yellow) and Jean-Jacques Clar (blue). ", "caption_bbox": [440, 422, 775, 487]}, {"image_id": 6, "file_name": "136_06.png", "page": 5, "dpi": 300, "bbox": [79, 74, 411, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The stardust. Each line represents a file. Each colored dot on the line represents a change to the file. Dot color corresponds to the developer that made that change. Time flows radially outward. ", "caption_bbox": [73, 351, 408, 390]}, {"image_id": 7, "file_name": "136_07.png", "page": 6, "dpi": 300, "bbox": [441, 275, 776, 625], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Overview of the Apache project at the latest timestep. The documentation directory and documenters have been colored green. The source code directory and core developers have been colored red. ", "caption_bbox": [440, 639, 775, 691]}, {"image_id": 8, "file_name": "136_08.png", "page": 6, "dpi": 300, "bbox": [74, 275, 409, 602], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Star trails in the Apache project. While some core develop- ers (in red) started at the top and moved down, the documenters (in green) stayed more or less in the same area. ", "caption_bbox": [73, 616, 408, 655]}, {"image_id": 9, "file_name": "136_09.png", "page": 6, "dpi": 300, "bbox": [79, 74, 781, 206], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Evolution of the Apache project. Documenters are colored green and core developers are colored red. Other developers are colored blue. We can tell by the red trails that some core developers start as documenters but not vice versa. ", "caption_bbox": [73, 224, 774, 250]}, {"image_id": 10, "file_name": "136_10.png", "page": 7, "dpi": 300, "bbox": [443, 74, 779, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Comparison of Ralf S. Engelschall (left) to other develop- ers who worked on the SSL module (right). Note that Ralf did not communicate using the mailing list. ", "caption_bbox": [440, 271, 775, 310]}, {"image_id": 11, "file_name": "136_11.png", "page": 7, "dpi": 300, "bbox": [76, 74, 416, 438], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Clusters of Apache contributors and their communications networks. (a) The core developers form a dense communications network. (b) The documenters form a sparse network. (c) The docu- menters talk to the core developers, but not amonst themselves. ", "caption_bbox": [73, 456, 408, 508]}, {"image_id": 12, "file_name": "136_12.png", "page": 8, "dpi": 300, "bbox": [441, 74, 775, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: PostgreSQL. Selecting the developers on the periphery (i.e. not the core), we see that there is a fair amount of communica- tion happening between them. ", "caption_bbox": [440, 408, 775, 447]}, {"image_id": 13, "file_name": "136_13.png", "page": 8, "dpi": 300, "bbox": [74, 74, 409, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: The PostgreSQL project. The current timestep is Feb. 6, 2006. The top two contributors (blue and red) are selected. There is no clear distinction between documenters and core developers. ", "caption_bbox": [73, 422, 408, 461]}], "137": [{"image_id": 0, "file_name": "137_00.png", "page": 1, "dpi": 300, "bbox": [424, 86, 736, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: NSF organization structure", "caption_bbox": [517, 288, 698, 302]}, {"image_id": 1, "file_name": "137_01.png", "page": 2, "dpi": 300, "bbox": [439, 74, 777, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Labeled Treemaps.", "caption_bbox": [536, 306, 679, 320]}, {"image_id": 2, "file_name": "137_02.png", "page": 2, "dpi": 300, "bbox": [72, 74, 410, 325], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Treemap of a balanced tree.", "caption_bbox": [147, 339, 334, 353]}, {"image_id": 3, "file_name": "137_03.png", "page": 2, "dpi": 300, "bbox": [440, 341, 769, 440], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Representation of child-parent relations.", "caption_bbox": [485, 458, 731, 472]}, {"image_id": 4, "file_name": "137_04.png", "page": 3, "dpi": 300, "bbox": [72, 74, 411, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: 2.5D labeled treemaps.", "caption_bbox": [159, 307, 323, 321]}, {"image_id": 5, "file_name": "137_05.png", "page": 3, "dpi": 300, "bbox": [72, 337, 411, 529], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Convert nested treemaps to 2.5D treemaps.", "caption_bbox": [108, 544, 373, 558]}, {"image_id": 6, "file_name": "137_06.png", "page": 4, "dpi": 300, "bbox": [72, 73, 777, 525], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Some of the awards funded since Jan 1, 2005", "caption_bbox": [473, 739, 742, 753]}, {"image_id": 7, "file_name": "137_07.png", "page": 5, "dpi": 300, "bbox": [72, 265, 411, 520], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: User interface of the visual funding navigator.", "caption_bbox": [105, 534, 376, 548]}, {"image_id": 8, "file_name": "137_08.png", "page": 5, "dpi": 300, "bbox": [439, 37, 777, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: An overview of popularity view.", "caption_bbox": [507, 341, 707, 355]}, {"image_id": 9, "file_name": "137_09.png", "page": 6, "dpi": 300, "bbox": [439, 373, 777, 606], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Search function of the visual funding navigator.", "caption_bbox": [465, 620, 750, 634]}, {"image_id": 10, "file_name": "137_10.png", "page": 6, "dpi": 300, "bbox": [72, 330, 411, 585], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: synchronization of multi views.", "caption_bbox": [138, 598, 343, 612]}, {"image_id": 11, "file_name": "137_11.png", "page": 6, "dpi": 300, "bbox": [439, 73, 777, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: NSF awards of California.", "caption_bbox": [517, 341, 698, 355]}, {"image_id": 12, "file_name": "137_12.png", "page": 6, "dpi": 300, "bbox": [72, 72, 411, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: An overview of ProgramVoyager view.", "caption_bbox": [121, 301, 361, 315]}], "138": [{"image_id": 0, "file_name": "138_00.png", "page": 2, "dpi": 300, "bbox": [454, 81, 768, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Using heterogeneous network to present both spatial and social information in mobile data. The spatial view at the top and the social network view at the bottom are integrated into one single heterogeneous network on the right. ", "caption_bbox": [440, 275, 775, 327]}, {"image_id": 1, "file_name": "138_01.png", "page": 3, "dpi": 300, "bbox": [109, 74, 374, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Ontology graph of the mobile social network derived from MIT Reality Mining dataset. The data is formulated as a time-varying heterogeneous network. There are 20 node types, including person, location, and 18 survey questions. There are 21 edge types. Two types of edges exist between two person nodes: call and proximity. Nodes are static, while edges associated to proximity relations, calls, and locations are time-varying. ", "caption_bbox": [73, 339, 408, 430]}, {"image_id": 2, "file_name": "138_02.png", "page": 4, "dpi": 300, "bbox": [190, 126, 722, 618], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Network with person, position and hangout places. It shows subjects\u2019 occupations and usual hangout places from the user survey. There are five major groups of people: Sloan students, Media Lab graduates, students, new graduates, and senior graduates. The three most popular hangout places are gyms, restaurants/bars and friend\u2019s places. ", "caption_bbox": [73, 678, 775, 717]}, {"image_id": 3, "file_name": "138_03.png", "page": 4, "dpi": 300, "bbox": [78, 762, 771, 941], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Time chart whowing the number of subjects at work. Repetitive patterns can be observed in views of different timescales. In both views, there are two large breaks: Thanksgiving and Christmas holidays. ", "caption_bbox": [73, 959, 775, 985]}, {"image_id": 4, "file_name": "138_04.png", "page": 5, "dpi": 300, "bbox": [97, 81, 755, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: In a behavior ring, occurrences of selected activities are arranged radially around a subject in counter-clockwise order. The rings provide an abstraction of subjects\u2019 behaviors and allow users to compare across different individuals in the network view. In this example, daily and hourly rings of phone calls for four subjects are illustrated. More phone calls are made after work, since only phone calls among participants, who are colleagues, are counted. ", "caption_bbox": [73, 346, 775, 398]}, {"image_id": 5, "file_name": "138_05.png", "page": 5, "dpi": 300, "bbox": [78, 427, 413, 556], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Time chart showing the locations of subject 57 over time. Subject 57 usually goes to work around noon, and returns home around midnight. Drawing a time window in the time chart, the activi- ties between 9pm and midnight and within the three-week span from 2004/9/5 to 2004/9/25 are selected. ", "caption_bbox": [73, 570, 408, 635]}, {"image_id": 6, "file_name": "138_06.png", "page": 6, "dpi": 300, "bbox": [88, 79, 397, 351], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparison of group behaviors using behavior rings. Per- sons are divided into groups by their academic positions. Rings of proximity activities are enabled. The visualization reveals that per- sons in group \u201cStudent\u201d, \u201cMedia Lab Grad\u201d, and \u201cNew Grad\u201d are of- ten close to someone else. People are closer to each other during weekdays. ", "caption_bbox": [73, 367, 408, 445]}, {"image_id": 7, "file_name": "138_07.png", "page": 7, "dpi": 300, "bbox": [80, 544, 773, 923], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparison of behavior patterns of groups in the friendship network derived by phone calls. Group behavior rings are added to Fig. 8(a). For each group, its behavior ring illustrates the total frequency of a certain activity during every hour of a day. Both visualizations reveal that students of Sloan business school have different working hours from those of Media Lab. ", "caption_bbox": [73, 941, 775, 980]}, {"image_id": 8, "file_name": "138_08.png", "page": 7, "dpi": 300, "bbox": [80, 99, 772, 428], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Inferring friendship network from observed behaviors. Phone calls and proximity relations on Saturday nights indicate that subjects are more likely to call or hangout with colleagues, respectively. With the assumption, that phone calls and gathering during weekend night can infer friendships, we can conclude that subjects are more likely to make friends with their colleagues in the MIT Reality Mining experiment. ", "caption_bbox": [73, 446, 775, 485]}, {"image_id": 9, "file_name": "138_09.png", "page": 8, "dpi": 300, "bbox": [78, 301, 415, 417], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Location occurrence of subject 92. Visualization shows an abnormal activity, i.e., the subject stays at home all the time from July to October. Checking the original data reveals an error in the dataset. ", "caption_bbox": [73, 432, 408, 484]}, {"image_id": 10, "file_name": "138_10.png", "page": 8, "dpi": 300, "bbox": [77, 76, 414, 202], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Location occurrence of subject 24. The subject stays at a location with a unrecognizable name, \u201cBurton connor,\u201d every night. Based on the the pattern of staying time, it is inferred to be home for the subject. Investigation results of \u201cBurton connor\u201d confirm that it is an undergraduate dorm in MIT. ", "caption_bbox": [73, 217, 408, 282]}], "139": [{"image_id": 0, "file_name": "139_00.png", "page": 3, "dpi": 300, "bbox": [76, 75, 400, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A map for the query \u201cVisualization\u201d in the orthogonal layout in- terface. The two categories \u201cComputer Graphics\u201d and \u201cJournal Visualization\u201d have been expanded by the user: The first contains five new subcategories, while the second contains two pages. ", "caption_bbox": [73, 306, 408, 355]}, {"image_id": 1, "file_name": "139_01.png", "page": 4, "dpi": 300, "bbox": [449, 76, 760, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A map for the query \u201cVisualization\u201d in the layered layout interface.", "caption_bbox": [443, 441, 772, 453]}, {"image_id": 2, "file_name": "139_02.png", "page": 4, "dpi": 300, "bbox": [74, 398, 410, 661], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A map for the query \u201cVisualization\u201d in the radial layout interface. Two categories have been expanded by the user. Non-parental links for the node \u201cComputer Graphics\u201d are displayed, due to a mouse-over operation on this node. ", "caption_bbox": [73, 675, 408, 724]}, {"image_id": 3, "file_name": "139_03.png", "page": 6, "dpi": 300, "bbox": [473, 598, 743, 779], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Growth of the average percentage of correct pages found with each layout interface over time. ", "caption_bbox": [440, 793, 775, 817]}, {"image_id": 4, "file_name": "139_04.png", "page": 6, "dpi": 300, "bbox": [88, 74, 762, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) The first map computed by the treemap layout interface for the query \u201cVisualization\u201d. With a mouse-over operation on node \u201cData\u201d all the related categories are highlighted with different color intensity in the red scale. (b) Expanding node \u201cData\u201d a new panel is opened to display its subcategories; the subcategory \u201cVisualization System\u201d is further expanded and all its Web pages are listed inside; the snippet of the AT&T Labs is visualized by means of a mouse-over operation. ", "caption_bbox": [73, 283, 775, 320]}, {"image_id": 5, "file_name": "139_05.png", "page": 6, "dpi": 300, "bbox": [444, 345, 772, 463], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) Distribution of the scores for the best layout interface. (b) Dis- tribution of the scores for the worst layout interface. T=TreeMap, L=Layered, R=Radial, O=Orthogonal. ", "caption_bbox": [440, 482, 775, 519]}, {"image_id": 6, "file_name": "139_06.png", "page": 7, "dpi": 300, "bbox": [80, 414, 404, 642], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Running times of algorithms WMinCut (dashed line) and WStar (solid line) for increasing number of snippets. The time is in seconds and the values are averaged over all queries of Table 1. For 1000 snippets WMinCut takes more than one hour and therefore we do not report data. ", "caption_bbox": [73, 662, 408, 711]}, {"image_id": 7, "file_name": "139_07.png", "page": 7, "dpi": 300, "bbox": [441, 353, 776, 590], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8:       Cluster similarity results for the two algorithms WStar and WMinCut. For each query it is shown the value of similarity between: (i) WStar and the Ground Truth (leftmost bar), (ii) WMinCut and the Ground Truth (middle bar), and (iii) WStar and WMinCut (rightmost bar). ", "caption_bbox": [440, 606, 775, 655]}], "140": [{"image_id": 0, "file_name": "140_00.png", "page": 3, "dpi": 300, "bbox": [103, 73, 747, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Two stills from Cenimation depicting the U.S. Census 2000 ethnic breakdown for the state of Maryland. The left image uses circular glyphs with randomized maximum size while the right images uses \u201cdrunken,\u201d or arbitrarily-oriented square glyphs. In Cenimation, users can control the glyph size and shape, as well as the growth rate and number of planted glyphs per unit time to affect a variety of animations. ", "caption_bbox": [73, 323, 775, 362]}, {"image_id": 1, "file_name": "140_01.png", "page": 4, "dpi": 300, "bbox": [496, 76, 720, 848], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: These four treemaps show different rendering techniques applied to a directory hierachy containing media files which are color- coded by file type. In the slice-and-dice treemap, it\u2019s hard to distin- guish the individual small files in the rightmost directory. Using a cushion, squarified treemap greatly improves the situation, but the many .mp3 and .aac files are still realtively small, and could be hard to select or label. The bottom two images show stills from our two animated treemap representations. Both offer larger, more visible representations of the contained files at the expense of showing only a portion at a given moment of time. ", "caption_bbox": [440, 866, 775, 997]}, {"image_id": 2, "file_name": "140_02.png", "page": 6, "dpi": 300, "bbox": [133, 73, 717, 597], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Figures 3(a) and 3(b) show the two background modes available in Paramation. In Ghosting mode, lines fade to a neutral gray color and remain in the background as the animation progresses. This serves to indicate global trends so far, and can be cleared by the user. In Standard mode a more traditional parallel coordinates display (using an alpha-accumulation of all 1,000,000 samples) is utilized. This view offers an overall global view of the data set during animation. Figure 3(c) shows how axis crossings (1st and 2nd axes) and other low-level details are revealed using slower, less populous animation, while global context is preserved by the chosen background mode. Figure 3(d) is a still from a more frenetic animation, in which axis hot spots jump out at the user without manual axis interaction. For example, it is clear that on the axis second from the right (labeled \u201cM\u201d), many more points pass through the lower portion despite the uniform gray background provided by the standard parallel coordinates view. ", "caption_bbox": [73, 615, 775, 719]}, {"image_id": 3, "file_name": "140_03.png", "page": 7, "dpi": 300, "bbox": [103, 401, 381, 889], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The top image shows the complete \u2018California\u2019 search graph. The large, dense cluster in the middle resists any understand- ing of what is happening with this graph. The bottom image shows one still from a continuous animation of the same graph using SRS sampling. Over many such samples, the user gains an understand- ing of the overall graph structure and can more easily identify areas for more detailed exploration. ", "caption_bbox": [73, 907, 408, 998]}, {"image_id": 4, "file_name": "140_04.png", "page": 7, "dpi": 300, "bbox": [103, 76, 381, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Restriction of available points via user-defined selection of axis locations. Here, only the particles that have data values in a se- lected region on each axis will be available for random selection. An axis with no selection does not contribute to the restriction of avail- able particles. ", "caption_bbox": [73, 324, 408, 389]}], "141": [{"image_id": 0, "file_name": "141_00.png", "page": 1, "dpi": 300, "bbox": [408, 144, 747, 590], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An example of FanLens visualization, an incremental, radial space-filling visualization. ", "caption_bbox": [440, 608, 775, 634]}, {"image_id": 1, "file_name": "141_01.png", "page": 2, "dpi": 300, "bbox": [408, 709, 777, 1094], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Examples of base level visualization and redefinition. (a) Three levels are defined as base levels by default; (b) Increase the base levels into four levels. ", "caption_bbox": [440, 641, 775, 680]}, {"image_id": 2, "file_name": "141_02.png", "page": 2, "dpi": 300, "bbox": [440, 388, 793, 597], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An example of structuring the hierarchy from the tabular data in the order of Gender, Nationality and then Name. ", "caption_bbox": [73, 551, 408, 578]}, {"image_id": 3, "file_name": "141_03.png", "page": 2, "dpi": 300, "bbox": [466, 74, 751, 257], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The interface for dynamic hierarchy specification.", "caption_bbox": [463, 272, 752, 284]}, {"image_id": 4, "file_name": "141_04.png", "page": 3, "dpi": 300, "bbox": [74, 74, 427, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Examples of expanding/collapsing mechanism. (a) Ex- panding one branch from the base levels; (b) Drill down deeper into the branch. ", "caption_bbox": [73, 259, 408, 298]}, {"image_id": 5, "file_name": "141_05.png", "page": 3, "dpi": 300, "bbox": [75, 312, 466, 600], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An example of multiple foci in FanLens.", "caption_bbox": [120, 616, 361, 628]}, {"image_id": 6, "file_name": "141_06.png", "page": 3, "dpi": 300, "bbox": [407, 650, 801, 1094], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Illustration of the basic idea of fisheye distortion.", "caption_bbox": [465, 615, 750, 627]}, {"image_id": 7, "file_name": "141_07.png", "page": 4, "dpi": 300, "bbox": [76, 586, 428, 758], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: An example of dynamic mapping of angle. (b) Mapping angle to professor\u2019s salary; (b) Mapping angle to number of profes- sors. ", "caption_bbox": [73, 773, 409, 812]}, {"image_id": 8, "file_name": "141_08.png", "page": 4, "dpi": 300, "bbox": [408, 793, 777, 1094], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: An example of animation: expanding branch grows out of its parent slice. ", "caption_bbox": [440, 736, 775, 761]}, {"image_id": 9, "file_name": "141_09.png", "page": 5, "dpi": 300, "bbox": [408, 900, 801, 1094], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: An example of re-defining the base levels to discover ex- treme value. (a) Default base levels cover the top two levels; (b) Increase the base levels to discover unusual value in lower levels. ", "caption_bbox": [440, 837, 775, 876]}, {"image_id": 10, "file_name": "141_10.png", "page": 6, "dpi": 300, "bbox": [408, 975, 777, 1094], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 18: An example of overall evaluation for studying the balance of the NBA league. ", "caption_bbox": [440, 906, 775, 932]}, {"image_id": 11, "file_name": "141_11.png", "page": 6, "dpi": 300, "bbox": [440, 538, 793, 892], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 17: An example of multiple foci data analysis for inspecting colleges in California with different types. ", "caption_bbox": [440, 484, 775, 509]}, {"image_id": 12, "file_name": "141_12.png", "page": 6, "dpi": 300, "bbox": [73, 160, 427, 490], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: An example of partial data exploration for colleges in Cal- ifornia. ", "caption_bbox": [73, 506, 409, 532]}, {"image_id": 13, "file_name": "141_13.png", "page": 7, "dpi": 300, "bbox": [407, 875, 802, 1094], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 20: An example of hypothesis testing for studying the connec- tion between players\u2019 scoring ability and turnovers. (a)Use overview to evaluate players\u2019 scoring and turnover. (b) Reconfigure the hi- erarchy and get a direct understanding of the connection between players\u2019 scoring ability and turnovers. ", "caption_bbox": [440, 777, 775, 842]}, {"image_id": 14, "file_name": "141_14.png", "page": 8, "dpi": 300, "bbox": [73, 77, 777, 325], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 21: Comparison of readability between Sunburst and Fan- Lens. (a) Focus in Sunburst; (b) Same focus in FanLens. ", "caption_bbox": [73, 324, 409, 350]}], "142": [{"image_id": 0, "file_name": "142_00.png", "page": 2, "dpi": 300, "bbox": [456, 73, 761, 307], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Our system architecture: We integrate the information of data analysis (b, c) and a single 3D data visualization method (d) for users to explore and visualize overall time-varying data contents (e). For a time-varying dataset (a), we calculate data dissimilari- ties according to selected data features (b) and select representative datasets by analyzing the distribution of time steps (c). The integra- tion of data analysis results reduces the visualized data amount and keeps the essential information for more efficient time-varying data visualization. ", "caption_bbox": [440, 319, 775, 440]}, {"image_id": 1, "file_name": "142_01.png", "page": 4, "dpi": 300, "bbox": [458, 73, 759, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The top row illustrates the selection process of representa- tive datasets. The bottom row demonstrates the two general proper- ties of reconstructed data distributions: time sequence (left of each pair) and cluster tendency (right of each pair). ", "caption_bbox": [440, 207, 775, 262]}, {"image_id": 2, "file_name": "142_02.png", "page": 5, "dpi": 300, "bbox": [81, 74, 402, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visualization design. (Top) The right images show our time- lines for the 5 left datasets respectively. Smaller data changes on the second row result closer MDS point positions. (Bottom) Similarly, point positions in a complete color/grey timeline represent informa- tion of data dissimilarity and time sequence, which will be further used to visualize overall time-varying data contents. ", "caption_bbox": [73, 216, 408, 297]}, {"image_id": 3, "file_name": "142_03.png", "page": 5, "dpi": 300, "bbox": [469, 74, 747, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) Final dissimilarity matrix for a simple sphere time- varying data shows that it is difficult to select the representative datasets (in red dots) directly. (b) An example of the automatic layout generation process by adding circle templates and organizing point positions. (c) Our storyboard describing a sphere moves back and forth when the timeline changes from blue to red. ", "caption_bbox": [440, 285, 775, 366]}, {"image_id": 4, "file_name": "142_04.png", "page": 6, "dpi": 300, "bbox": [89, 73, 394, 488], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Storyboards for an energy dataset with different level-of- details. The storyboard on the top clearly shows the most impor- tant data information along the timeline: the main object starts from the bottom, expands to the top, shrinks to the bottom, and finalizes around the center. The bottom storyboard contains more details by using less smoothed timeline and more representative datasets. ", "caption_bbox": [73, 500, 408, 581]}, {"image_id": 5, "file_name": "142_05.png", "page": 7, "dpi": 300, "bbox": [90, 513, 394, 644], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Concentration on a particular time step. When a user se- lects time step 58, which is highlighted with a red template boundary, the storyboard automatically update representative datasets for visu- alizing overall data relations around the selected time step. ", "caption_bbox": [73, 656, 408, 711]}, {"image_id": 6, "file_name": "142_06.png", "page": 7, "dpi": 300, "bbox": [78, 726, 406, 891], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The storyboard system is composed of the bottom timeline portion and the top key frames portion. In this figure, the bottom is a 3D storyboard for an energy data with three key time steps. The red dot in the middle is used to control the time step shown in the right top corner and a separate single data rendering window where a user can perform common interaction tasks, such as rotating and selecting regions-of-interest. ", "caption_bbox": [73, 903, 408, 998]}, {"image_id": 7, "file_name": "142_07.png", "page": 7, "dpi": 300, "bbox": [99, 77, 384, 417], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Storyboards for a vortex dataset. Representative datasets are connected by smooth timelines to visualize overall time-varying data contents and changes. A user can interactively select their in- terested time ranges and explore additional information by expanding corresponding portions of the storyboard. ", "caption_bbox": [73, 429, 408, 497]}], "143": [{"image_id": 0, "file_name": "143_00.png", "page": 2, "dpi": 300, "bbox": [442, 403, 794, 796], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The compression process.", "caption_bbox": [530, 795, 710, 811]}, {"image_id": 1, "file_name": "143_01.png", "page": 3, "dpi": 300, "bbox": [139, 73, 353, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Construction of the wavelet tree.", "caption_bbox": [137, 241, 351, 257]}, {"image_id": 2, "file_name": "143_02.png", "page": 3, "dpi": 300, "bbox": [492, 72, 726, 245], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The compression of P-frame.", "caption_bbox": [512, 246, 709, 262]}, {"image_id": 3, "file_name": "143_03.png", "page": 3, "dpi": 300, "bbox": [162, 271, 326, 411], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The compressed wavelet tree of an I-frame.", "caption_bbox": [110, 416, 378, 432]}, {"image_id": 4, "file_name": "143_04.png", "page": 3, "dpi": 300, "bbox": [468, 275, 771, 412], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Motion-compensation-based prediction for a block", "caption_bbox": [457, 414, 762, 430]}, {"image_id": 5, "file_name": "143_05.png", "page": 4, "dpi": 300, "bbox": [492, 355, 750, 581], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Rendering with view-aligned slices.", "caption_bbox": [501, 584, 732, 600]}, {"image_id": 6, "file_name": "143_06.png", "page": 5, "dpi": 300, "bbox": [127, 822, 362, 984], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Rendering result of the Jet-large data set.", "caption_bbox": [114, 983, 374, 999]}, {"image_id": 7, "file_name": "143_07.png", "page": 6, "dpi": 300, "bbox": [447, 85, 771, 509], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Results of testing with a set of blocks of size 10~20MB.", "caption_bbox": [442, 508, 773, 524]}, {"image_id": 8, "file_name": "143_08.png", "page": 6, "dpi": 300, "bbox": [447, 537, 771, 960], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Results of testing with a set of blocks of size 40~50MB.", "caption_bbox": [442, 960, 773, 976]}, {"image_id": 9, "file_name": "143_09.png", "page": 8, "dpi": 300, "bbox": [73, 76, 413, 983], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The temporal ROI selection.", "caption_bbox": [141, 982, 340, 998]}, {"image_id": 10, "file_name": "143_10.png", "page": 8, "dpi": 300, "bbox": [435, 79, 789, 956], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Rendering results of three different scalar factors.", "caption_bbox": [453, 955, 758, 971]}], "145": [{"image_id": 0, "file_name": "145_00.png", "page": 3, "dpi": 300, "bbox": [77, 74, 406, 442], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Height function f (x, y) = cos(ax)cos(by) with ridges (red) and valleys (blue). (a) Raw features. (b) Subset accepted by FE , or equally, FL . (c) Subset accepted by FC . In (b) and (c), thin lines mean: rejected by F45\u25e6 . ", "caption_bbox": [73, 456, 408, 493]}, {"image_id": 1, "file_name": "145_01.png", "page": 5, "dpi": 300, "bbox": [440, 73, 776, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Ridges (red) and valleys (blue), with contour distance and 45\u25e6 filters applied. ", "caption_bbox": [440, 419, 775, 444]}, {"image_id": 2, "file_name": "145_02.png", "page": 5, "dpi": 300, "bbox": [77, 73, 406, 633], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: \u201cMonkey saddle\u201d example f (x, y) = x2 y from [5] with ridges (red) and valleys (blue). Thin lines represent segments rejected by the angle filter F45\u25e6 . (a) Unperturbed field. (b,c) Perturbed field f (x, y) = x2 y + 0.02y. (d-f) Perturbed field f (x, y) = x2 y \u2212 0.2y. ", "caption_bbox": [73, 646, 408, 696]}, {"image_id": 3, "file_name": "145_03.png", "page": 5, "dpi": 300, "bbox": [444, 463, 773, 833], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Close-up of Figure 3. Comparison of filters, and combination with F45\u25e6 (thin lines). ", "caption_bbox": [440, 847, 775, 872]}, {"image_id": 4, "file_name": "145_04.png", "page": 6, "dpi": 300, "bbox": [86, 274, 398, 440], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) Height function f (x, y) = x \u2212 61 y2 + 12 cos(x). Along the ridge on the x-axis, eigenvectors are axis-aligned. Eigenvalues are \u2212 12 cos(x) and \u2212 13 for the x and y directions, respectively. (b) Raw features and effect of FC (thick lines). The filter FC , as well as FE , would interrupt the main ridge around the points ((2k + 1)\u03c0, 0) where \u2212 12 cos(x) falls below \u2212 13 . FL would create additional gaps where it exceeds 13 , that is, around the points (2k\u03c0, 0). ", "caption_bbox": [73, 453, 408, 531]}, {"image_id": 5, "file_name": "145_05.png", "page": 7, "dpi": 300, "bbox": [162, 73, 688, 927], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Steady simulation of flow in a Pelton distributor ring. Black tubes are valley lines of pressure, yellow tubes are vortex core lines (for comparison). Isosurfaces of pressure are shown in red (high) and blue (low). Two out of three streamline bundles confirm longitudinal vortices. ", "caption_bbox": [73, 941, 775, 964]}, {"image_id": 6, "file_name": "145_06.png", "page": 8, "dpi": 300, "bbox": [445, 348, 773, 541], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Pair of a watershed and non-watershed ridge. (a) Graph of the height field, (b) Contours, and extracted ridges and valleys, filtered with FC . Thin lines: rejected by F45\u25e6 . ", "caption_bbox": [440, 555, 775, 592]}, {"image_id": 7, "file_name": "145_07.png", "page": 8, "dpi": 300, "bbox": [100, 458, 383, 865], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) \u201cCurved gutter\u201d example with two straight segments added. (b) Slope lines (blue) converging to the watercourse. Height ridge (red) has a ra- dial offset. (c) \u201cBlended gutter\u201d obtained by replacing the curved part (shaded region) by a linear blend of the two height fields of the straight parts. Water- course (blue) converges to, but is not identical with, the obvious valley line in the lower segment. ", "caption_bbox": [73, 879, 408, 952]}], "146": [{"image_id": 0, "file_name": "146_00.png", "page": 2, "dpi": 300, "bbox": [445, 650, 773, 903], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A business process instance is given as a set of correlated events. The semantic correlation is based on the event attribute order ID. ", "caption_bbox": [440, 923, 775, 962]}, {"image_id": 1, "file_name": "146_01.png", "page": 2, "dpi": 300, "bbox": [447, 108, 762, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The event-space backend system contains processed events for analysis and retrieval. ", "caption_bbox": [440, 411, 775, 436]}, {"image_id": 2, "file_name": "146_02.png", "page": 3, "dpi": 300, "bbox": [74, 463, 407, 746], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The event-tunnel visualization: Side view and top view onto the stream of events. ", "caption_bbox": [73, 764, 408, 789]}, {"image_id": 3, "file_name": "146_03.png", "page": 4, "dpi": 300, "bbox": [118, 74, 368, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Interpretation of business-process patterns in the CESP pol- icy. ", "caption_bbox": [73, 410, 408, 435]}, {"image_id": 4, "file_name": "146_04.png", "page": 4, "dpi": 300, "bbox": [462, 393, 752, 583], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Event attributes can be mapped to colors and sizes of event glyph parameters. ", "caption_bbox": [440, 614, 775, 639]}, {"image_id": 5, "file_name": "146_05.png", "page": 5, "dpi": 300, "bbox": [73, 73, 777, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The analysis workspace: event-tunnel top-view (a), event-tunnel side-view (b), text view (c), metric charting view (d), text box (e), graphical query builder (f), filter manager (g), clustering management console (h), configuration manager (i), snapshot management console (j). ", "caption_bbox": [73, 409, 775, 434]}, {"image_id": 6, "file_name": "146_06.png", "page": 7, "dpi": 300, "bbox": [73, 74, 776, 543], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Example of a step-wise investigation of online-betting data. Account histories of two users (a), bet amount distribution for a selected sport event (b), suspicious occurrences at a certain point in time (c), a putter-on account profile (d), cluster of high-stake bets with abnormal outlier (e). ", "caption_bbox": [73, 557, 775, 596]}, {"image_id": 7, "file_name": "146_07.png", "page": 8, "dpi": 300, "bbox": [73, 73, 410, 422], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Supply chains in an event-driven logistics application (a); available transports and their decision-relevant parameters (b) ", "caption_bbox": [73, 440, 408, 465]}], "147": [{"image_id": 0, "file_name": "147_00.png", "page": 1, "dpi": 300, "bbox": [439, 145, 777, 736], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A snapshot of the running 3D visualization system for ex- pressive facial motion data exploration. The six windows (from top to bottom, from left to right) are for forehead region, left eye region, right eye region, left cheek region, right cheek region, and mouth/jaw region. Here, red for anger, green for happiness, and blue for sad- ness. ", "caption_bbox": [440, 750, 775, 828]}, {"image_id": 1, "file_name": "147_01.png", "page": 2, "dpi": 300, "bbox": [441, 74, 775, 181], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The left shows a facial motion capture system, the middle is a snapshot of the captured actress. In the right panel, blue and red points represent the 102 captured markers, where the red points are the 90 markers used for this work. ", "caption_bbox": [440, 196, 775, 248]}, {"image_id": 2, "file_name": "147_02.png", "page": 2, "dpi": 300, "bbox": [439, 276, 778, 863], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration of region-based dimension reduction for expres- sive facial motion data. The left panel shows how the face is divided into six regions, the middle panels shows the 3D position of markers in one region is packed into a vector, and the right panel shows the concatenated vector is reduced to a 3D point in the reduced PCA space. ", "caption_bbox": [440, 880, 776, 958]}, {"image_id": 3, "file_name": "147_03.png", "page": 3, "dpi": 300, "bbox": [413, 87, 751, 923], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A comparison result of three visualization techniques of (a) simple line, (b) volume rendering, (c) 3D tube rendering with alpha values, and (d) solid 3D tube rendering. ", "caption_bbox": [440, 947, 776, 986]}, {"image_id": 4, "file_name": "147_04.png", "page": 4, "dpi": 300, "bbox": [441, 74, 776, 450], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualization results for one facial region (right cheek) using the solid 3D tube technique. Red, green and blue correspond to the emotion of angry, happy and sad respectively. ", "caption_bbox": [440, 470, 775, 509]}, {"image_id": 5, "file_name": "147_05.png", "page": 5, "dpi": 300, "bbox": [183, 542, 678, 958], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The second example of novel facial motion synthesis by visually picking 3D trajectories in visualization windows. Here heavy white trajectories represent selected ones. The right shows the synthesized face. ", "caption_bbox": [73, 972, 775, 998]}, {"image_id": 6, "file_name": "147_06.png", "page": 5, "dpi": 300, "bbox": [182, 74, 678, 490], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The first example of novel facial motion synthesis by visually picking 3D trajectories in visualization windows. Here heavy white trajectories represent selected ones. The right shows the synthesized face. ", "caption_bbox": [73, 504, 775, 530]}, {"image_id": 7, "file_name": "147_07.png", "page": 7, "dpi": 300, "bbox": [147, 548, 702, 952], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A snapshot of the running visualization system for emotion recognition, where the white trajectories are the another 20% of the data set corresponding to a novel test facial motion sequence (happy). ", "caption_bbox": [73, 966, 775, 992]}, {"image_id": 8, "file_name": "147_08.png", "page": 7, "dpi": 300, "bbox": [147, 80, 702, 484], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A snapshot of the running visualization system for emotion recognition, where the white trajectory is the one corresponding to a novel test facial motion sequence (happy). ", "caption_bbox": [73, 498, 775, 524]}], "148": [{"image_id": 0, "file_name": "148_00.png", "page": 1, "dpi": 300, "bbox": [424, 86, 702, 325], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Common perspectives on multivariate system traces.", "caption_bbox": [453, 340, 761, 353]}, {"image_id": 1, "file_name": "148_01.png", "page": 2, "dpi": 300, "bbox": [82, 75, 402, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: System trace as a graph.", "caption_bbox": [155, 258, 327, 271]}, {"image_id": 2, "file_name": "148_02.png", "page": 3, "dpi": 300, "bbox": [73, 74, 777, 621], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visualization of multivariate system traces.", "caption_bbox": [295, 635, 552, 648]}, {"image_id": 3, "file_name": "148_03.png", "page": 4, "dpi": 300, "bbox": [192, 73, 658, 475], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Integrated graphical editor.", "caption_bbox": [334, 490, 514, 503]}, {"image_id": 4, "file_name": "148_04.png", "page": 4, "dpi": 300, "bbox": [82, 838, 400, 971], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: User defined diagrams.", "caption_bbox": [159, 987, 322, 1000]}, {"image_id": 5, "file_name": "148_05.png", "page": 4, "dpi": 300, "bbox": [473, 648, 743, 972], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Variable-based clustering.", "caption_bbox": [519, 987, 696, 1000]}, {"image_id": 6, "file_name": "148_06.png", "page": 5, "dpi": 300, "bbox": [439, 73, 777, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Industrial steam generator.", "caption_bbox": [517, 273, 698, 286]}, {"image_id": 7, "file_name": "148_07.png", "page": 6, "dpi": 300, "bbox": [439, 820, 777, 972], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Steam flow, drum pressure and water level.", "caption_bbox": [474, 987, 741, 1000]}, {"image_id": 8, "file_name": "148_08.png", "page": 6, "dpi": 300, "bbox": [156, 800, 328, 972], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: High steam flow.", "caption_bbox": [176, 987, 306, 1000]}, {"image_id": 9, "file_name": "148_09.png", "page": 6, "dpi": 300, "bbox": [441, 73, 776, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Drum pressure versus steam flow.", "caption_bbox": [496, 301, 719, 314]}, {"image_id": 10, "file_name": "148_10.png", "page": 6, "dpi": 300, "bbox": [73, 73, 411, 343], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Steam generator, time series view.", "caption_bbox": [131, 358, 350, 371]}, {"image_id": 11, "file_name": "148_11.png", "page": 7, "dpi": 300, "bbox": [192, 74, 659, 437], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Multiple views on an industrial steam generator.", "caption_bbox": [280, 451, 569, 464]}], "149": [{"image_id": 0, "file_name": "149_00.png", "page": 1, "dpi": 300, "bbox": [424, 92, 774, 542], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1. Different partitions for flow fields", "caption_bbox": [511, 548, 710, 562]}, {"image_id": 1, "file_name": "149_01.png", "page": 6, "dpi": 300, "bbox": [66, 485, 410, 681], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3. Mesh repartition for the flow simulation passing through an ellipsoidal cylinder. ", "caption_bbox": [66, 680, 402, 708]}, {"image_id": 2, "file_name": "149_02.png", "page": 6, "dpi": 300, "bbox": [98, 86, 387, 435], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2. A flow simulation passing through an ellipsoidal cylinder", "caption_bbox": [79, 451, 380, 465]}, {"image_id": 3, "file_name": "149_03.png", "page": 6, "dpi": 300, "bbox": [444, 91, 768, 725], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. Parallel streamline performance tests for the small data set(2,531,790 grid cells). The elapsed time using 1PE to 32 PEs for generating 80 streamlines and 700 streamlines with the original mesh partition and the new one respectively is shown as (top), and the speedup performance is shown as (bottom) ", "caption_bbox": [449, 737, 769, 803]}, {"image_id": 4, "file_name": "149_04.png", "page": 7, "dpi": 300, "bbox": [78, 323, 408, 518], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5. A 3D air flow simulation in a room", "caption_bbox": [135, 283, 337, 297]}, {"image_id": 5, "file_name": "149_05.png", "page": 7, "dpi": 300, "bbox": [440, 313, 778, 549], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7. A tornado flow dataset", "caption_bbox": [546, 279, 692, 293]}], "151": [{"image_id": 0, "file_name": "151_00.png", "page": 2, "dpi": 300, "bbox": [73, 73, 777, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Different particle-based strategies are used to visualize 3D flow fields. (Left) Focus+context visualization using an importance measure based on helicity density and user-defined region of interest. (Middle) Particles seeded in the vicinity of anchor lines show the extend and speed at which particles separate over time. (Right) Cluster arrows are used to show regions of coherent motion. ", "caption_bbox": [73, 254, 775, 293]}, {"image_id": 1, "file_name": "151_01.png", "page": 3, "dpi": 300, "bbox": [73, 74, 777, 331], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Different approaches for 3D flow visualization using particles are shown. Image A shows one time step of an unsteady flow around a cylinder, visualized by a large amount of particles. In image B, a region of interest has been selected, and with increasing distance to the center of this region the particle density is decreased. Image C shows the effect of importance-driven density adjustment (vorticity was used as importance measure in this example). Particles out of focus regions are removed. In image D, the particle shape is adjusted according to the importance of the region they are traveling through. In this example, the shape is morphed from a small arrow (high importance) to a large ellipsoid (low importance). In image E, in addition to the shape transformation the transparency and color of the particles are transformed. Image F shows the integration of transparent stream lines to sketch the flow structure in less important regions. ", "caption_bbox": [73, 359, 775, 450]}, {"image_id": 2, "file_name": "151_02.png", "page": 4, "dpi": 300, "bbox": [73, 414, 411, 739], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The velocity magnitude at different resolution levels is used as an importance measures (coarser levels from top to bottom). The color coding is from opaque red (low velocity) to transparent grey (high velocity). Different views of the same data set are shown. ", "caption_bbox": [73, 753, 408, 805]}, {"image_id": 3, "file_name": "151_03.png", "page": 4, "dpi": 300, "bbox": [439, 530, 777, 774], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: In the top image, cluster arrows and transparent lines are used to indicate coherent and less coherent motion in the flow, re- spectively. The size of the arrows corresponds to the size of the cluster they represent. In the bottom image (right), the same visu- alization technique is used. It is compared to a visualization of the same double-vortex flow using arrows as particle primitives (left). ", "caption_bbox": [440, 788, 775, 866]}, {"image_id": 4, "file_name": "151_04.png", "page": 5, "dpi": 300, "bbox": [439, 74, 778, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Anchor lines (path lines) and particles seeded close to their starting points are shown. While particles exactly follow some of the lines (blue, red, yellow), along other lines the particles diverge from their anchor lines at different speed (green, purple). To improve the visual perception of the correspondence between anchor lines and particles, every anchor line gets assigned a unique color that is inherited by the particles seeded close to it. Particle transparency is inversely proportional to the separation distance from the anchor line. ", "caption_bbox": [440, 384, 775, 502]}, {"image_id": 5, "file_name": "151_05.png", "page": 6, "dpi": 300, "bbox": [439, 426, 778, 682], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Rendering transparent particle primitives without sorting does not impose serious problems in the current scenario. ", "caption_bbox": [440, 696, 775, 722]}, {"image_id": 6, "file_name": "151_06.png", "page": 6, "dpi": 300, "bbox": [73, 739, 411, 860], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Image-based morphing from an arrow into an ellipsoid.", "caption_bbox": [82, 875, 400, 888]}, {"image_id": 7, "file_name": "151_07.png", "page": 6, "dpi": 300, "bbox": [73, 74, 411, 444], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Anchor lines placed in regions of high Lyapunov exponent can effectively emphasize the dual vortex structure of the flow. ", "caption_bbox": [73, 458, 408, 484]}, {"image_id": 8, "file_name": "151_08.png", "page": 7, "dpi": 300, "bbox": [439, 74, 777, 442], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The top image depicts an iso-surface of the FTLE in the Ka\u0301rma\u0301n vortex street. The visualization of this data set using anchor lines is shown in the bottom image. Two anchor lines have been placed in the region of high FTLE. From the particle distribution one can see where particles start to separate from their anchor, and the transparency coding shows how fast they separate. ", "caption_bbox": [440, 456, 775, 534]}, {"image_id": 9, "file_name": "151_09.png", "page": 8, "dpi": 300, "bbox": [73, 74, 411, 480], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Top: One anchor line seeded in the region of high FTLE in the Ka\u0301rma\u0301n vortex street. Bottom: Two anchor lines seeded in the region of high FTLE in the flow around a box. In both images, the distribution of the Lyapunov exponent is visualized using volume rendering. ", "caption_bbox": [73, 494, 409, 559]}], "153": [{"image_id": 0, "file_name": "153_00.png", "page": 2, "dpi": 300, "bbox": [73, 74, 777, 447], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Hierarchical edge clustering algorithm overview. Step 1: performing Delaunay triangulation; Step 2: sampling the graph edges; Step 3: building the control map of the graph; Step 4: generating edge hierarchy (hierarchical clustering). The figures (e) and (f) enclosed in the dotted rectangle are the intermediate graphs during the hierarchical clustering. ", "caption_bbox": [73, 462, 775, 501]}, {"image_id": 1, "file_name": "153_01.png", "page": 3, "dpi": 300, "bbox": [109, 74, 374, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Sampling the graph edges based on Delaunay triangula- tion. Edge AD is intersected with Delaunay triangulation edges BF, BE, and CE. Four segments AG\u2032 , G\u2032 G\u2032\u2032 , G\u2032\u2032 G\u2032\u2032\u2032 , and G\u2032\u2032\u2032 D are sampled for edge AD. ", "caption_bbox": [73, 293, 409, 345]}, {"image_id": 2, "file_name": "153_02.png", "page": 3, "dpi": 300, "bbox": [441, 73, 776, 473], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparison between uniform sampling and our proposed non-uniform sampling scheme based on Delaunay triangulation: (a) - (c) uniform sampling schemes with regular grids at difference sam- pling rate; (d) Delaunay-triangulation-based non-uniform sampling scheme. ", "caption_bbox": [440, 488, 775, 553]}, {"image_id": 3, "file_name": "153_03.png", "page": 5, "dpi": 300, "bbox": [74, 75, 410, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The user interface of our system using energy-based hi- erarchical edge clustering. Left: display region; Right: parameter region accepting user input. ", "caption_bbox": [73, 345, 409, 384]}, {"image_id": 4, "file_name": "153_04.png", "page": 5, "dpi": 300, "bbox": [465, 80, 754, 434], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Results of hierarchical edge clustering. The images in the top row are the initial graphs. The images in the bottom row are the corresponding clustered graphs drawn with curved edges. ", "caption_bbox": [440, 446, 775, 485]}, {"image_id": 5, "file_name": "153_05.png", "page": 6, "dpi": 300, "bbox": [79, 77, 775, 482], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Results of hierarchical edge clustering on an artificial dataset with 13 nodes and 57 edges: (a) the original node-link graph; (b) the highest level of edge clustering based on our hierarchical edge clustering algorithm; (c), (d), and (e) the intermediate graphs during the hierarchical clustering from low to high levels. ", "caption_bbox": [73, 495, 775, 534]}, {"image_id": 6, "file_name": "153_06.png", "page": 7, "dpi": 300, "bbox": [168, 88, 684, 955], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Results of hierarchical edge clustering on an airline flight route map with 83 nodes and 187 edges: (a) the original node-link graph; (b) the edge clustering result. (Data source of the background map: http://www.airchina.com.cn/ ) ", "caption_bbox": [73, 967, 775, 993]}], "154": [{"image_id": 0, "file_name": "154_00.png", "page": 2, "dpi": 300, "bbox": [120, 601, 360, 774], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Four traditional acculturation strategies (shaded) defined by the migrant\u2019s affinity to her original culture and to the host culture [3]. ", "caption_bbox": [73, 793, 408, 818]}, {"image_id": 1, "file_name": "154_01.png", "page": 3, "dpi": 300, "bbox": [75, 75, 775, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Personal networks of 79 Argentinian migrants to Spain. The four nodes of each network correspond to the four classes defined in Sect. 3.1 (also see Fig. 3). Node size reflects class size, darkness of a node reflects average connectivity within the class, width and darkness of a tie between nodes reflects average connectivity between the two classes (compare Sect. 3.2 and Fig. 4). ", "caption_bbox": [73, 347, 775, 386]}, {"image_id": 2, "file_name": "154_02.png", "page": 3, "dpi": 300, "bbox": [466, 614, 759, 706], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Left: Definition and labeling of specific actor classes, as- suming that the respondent migrated from Argentina to Spain. Right: A fixed layout (coordinates) for these classes. ", "caption_bbox": [440, 728, 775, 767]}, {"image_id": 3, "file_name": "154_03.png", "page": 4, "dpi": 300, "bbox": [455, 79, 758, 165], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Illustration for the visualization of class size and tie weight.", "caption_bbox": [440, 181, 775, 193]}, {"image_id": 4, "file_name": "154_04.png", "page": 4, "dpi": 300, "bbox": [467, 478, 715, 544], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Three selected instances from Fig. 2 that show large differ- ences in the adjacency structure between classes. ", "caption_bbox": [440, 560, 775, 585]}, {"image_id": 5, "file_name": "154_05.png", "page": 5, "dpi": 300, "bbox": [85, 76, 380, 141], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Arithmetic mean (right) of the two networks on the lefthand side of the equation. Note that both, the class sizes as well as the tie weights are averages of the corresponding values in the summands. The image on the righthand side does not visualize the variability (compare Sect. 4.2). ", "caption_bbox": [73, 154, 408, 219]}, {"image_id": 6, "file_name": "154_06.png", "page": 6, "dpi": 300, "bbox": [83, 477, 399, 592], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visual representation of mean and deviation of intra-class weights, inter-class weights,                          p and class sizes for two classes C1 (left) and C2 (right). (Let c2 = \u00b5|C2 | denote the square root of the mean size of C2 and c\u00b1                       p                  2 =    \u00b5|C2 | \u00b1 \u03c3 |C2 | respectively.). Instead of mean and standard deviation, any other measure for average and variability (e. g., median and upper/lower quartiles) could be taken. ", "caption_bbox": [73, 607, 408, 687]}, {"image_id": 7, "file_name": "154_07.png", "page": 6, "dpi": 300, "bbox": [83, 76, 394, 180], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Traditional box plot (right) of a sample of a one-dimensional random variable Y . Alternatively, box plots could visualize any other measure for average and variability, e. g.,the median (instead of mean) and upper/lower quartiles (instead of \u00b5(y) \u00b1 \u03c3 (y)). ", "caption_bbox": [73, 198, 408, 250]}, {"image_id": 8, "file_name": "154_08.png", "page": 7, "dpi": 300, "bbox": [76, 418, 771, 622], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Average networks of migrants with the same year of entry in the host country. The integer Y denotes the years of residence in the host country, the integer N denotes the number of individuals in the respective sub-sample (we only shown networks with N \u2265 5). ", "caption_bbox": [73, 637, 775, 662]}, {"image_id": 9, "file_name": "154_09.png", "page": 7, "dpi": 300, "bbox": [73, 72, 777, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Average networks of migrants with the same country of origin and host country. The network diagram in the upper right position is to remind the positions of the different classes (compare Fig. 3). Upper row are migrants to Spain, lower row are migrants to the USA. The country of origin is encoded as follows: SEN for Senegal/Gambia, DOM for the Dominican Republic, MOR for Morocco, ARG for Argentina, COL for Colombia, PUE for Puerto Rico, HAI for Haiti, and CUB for Cuba,. The integer N denotes the number of individuals in the respective sub-sample. ", "caption_bbox": [73, 345, 775, 397]}, {"image_id": 10, "file_name": "154_10.png", "page": 8, "dpi": 300, "bbox": [84, 81, 760, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Average networks of migrants (respondents) with the same skin color. The labels in the middle row denote the skin color of the respondent (the color of these labels is used to encode the skin color in the network images), the integer N denotes the number of respondents in the respective sub-sample. In the top row the four classes have been subdivided (as in a pie chart) each into four segments proportional to the relative sizes of sub-classes. The networks in the bottom row show the average adjacency structure of the 16 sub-classes. For simplicity we visualize only the mean and not the deviation in these images. ", "caption_bbox": [73, 370, 775, 435]}], "155": [{"image_id": 0, "file_name": "155_00.png", "page": 2, "dpi": 300, "bbox": [94, 520, 390, 616], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: According to Ware et al. [21], the crossing on the right is less confusing than that on the left. ", "caption_bbox": [73, 634, 408, 659]}, {"image_id": 1, "file_name": "155_01.png", "page": 4, "dpi": 300, "bbox": [453, 460, 763, 762], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration of the trend relationship between time and angle", "caption_bbox": [440, 793, 775, 805]}, {"image_id": 2, "file_name": "155_02.png", "page": 4, "dpi": 300, "bbox": [454, 76, 765, 257], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Means of response time (sec.) (crossing angle=0 means no crossings) ", "caption_bbox": [440, 287, 775, 312]}], "156": [{"image_id": 0, "file_name": "156_00.png", "page": 1, "dpi": 300, "bbox": [449, 369, 768, 663], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The vitamin B6 metabolism in different species: yeast (Sac- charomyces cerevisiae - upper left), silibacter bacterium (upper right), staphylococcus bacterium (lower left) and streptomyces bacterium (lower right). The drawings can be produced using one of the algo- rithms described in this paper. ", "caption_bbox": [440, 680, 775, 745]}, {"image_id": 1, "file_name": "156_01.png", "page": 1, "dpi": 300, "bbox": [468, 192, 748, 307], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Conserved coregulated protein cluster between yeast and fly, as visualized in [32]. ", "caption_bbox": [440, 321, 775, 347]}, {"image_id": 2, "file_name": "156_02.png", "page": 4, "dpi": 300, "bbox": [444, 73, 773, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A simultaneously planar simultaneous graph (shown in the bottom right) with three basic graphs. In the drawings that realize SCM+ , the adjacent edges (A,B) and (A,C) have multiple crossings. ", "caption_bbox": [440, 267, 775, 306]}, {"image_id": 3, "file_name": "156_03.png", "page": 4, "dpi": 300, "bbox": [77, 161, 406, 859], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Two simultaneously planar basic graphs (top) where one pair of edges crosses at least twice in an optimal drawing of their simultaneous graph (bottom). In this drawing the edges e and f cross twice. ", "caption_bbox": [73, 874, 408, 926]}, {"image_id": 4, "file_name": "156_04.png", "page": 5, "dpi": 300, "bbox": [76, 74, 408, 364], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A simultaneously planar simultaneous graph (shown in the lowest picture) with n + 1 basic graphs. Edge (u0 ,v0 ) is involved in 2n \u2212 1 crossings. The pictures show the case n = 3. ", "caption_bbox": [73, 378, 408, 417]}, {"image_id": 5, "file_name": "156_05.png", "page": 5, "dpi": 300, "bbox": [472, 74, 745, 172], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: In general, a vertex with degree two cannot be shrinked by the traditional reduction techniques, cf. text. Solid edges are in G1 , dashed edges in G2 . All edges except for e and f are also in G3 . ", "caption_bbox": [440, 189, 775, 229]}, {"image_id": 6, "file_name": "156_06.png", "page": 7, "dpi": 300, "bbox": [459, 78, 749, 446], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (Heuristic) The figure shows the computed simultaneous crossing number (scr), the number of proper (prop) and phantom (phan) crossings and the cumulative crossing count (ccc) for differ- ent values of \u03c0 . The underlying graph G has 33 nodes and 70 edges. The results were computed heuristically. For each value \u03c0 , the values were averaged over 10 simultaneous graphs generated from G. ", "caption_bbox": [440, 464, 775, 542]}, {"image_id": 7, "file_name": "156_07.png", "page": 7, "dpi": 300, "bbox": [88, 74, 379, 434], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (Exact) The figure shows the computed simultaneous cross- ing number (scr), the number of proper (prop) and phantom (phan) crossings and the cumulative crossing count (ccc) for different values of \u03c0 . The underlying graph has 10 nodes and 23 edges. The re- sults were computed using the exact Branch-and-Cut algorithm. For each value \u03c0 , the values were averaged over 5 simultaneous graphs generated from G. ", "caption_bbox": [73, 451, 409, 542]}], "157": [{"image_id": 0, "file_name": "157_00.png", "page": 2, "dpi": 300, "bbox": [221, 289, 634, 468], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Two images generated using different surface representations and rendering techniques (a) Using the standard Gouraud shading technique (b) Using the proposed technique ", "caption_bbox": [73, 492, 774, 521]}, {"image_id": 1, "file_name": "157_01.png", "page": 2, "dpi": 300, "bbox": [98, 74, 723, 202], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The examples show that a combination of simple tones and empty space can effectively illustrate the shapes of the objects. [8]", "caption_bbox": [90, 242, 757, 258]}, {"image_id": 2, "file_name": "157_02.png", "page": 3, "dpi": 300, "bbox": [464, 81, 749, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Hipip images to show the effect of different shading power (a) power=1.0; (b) power=2.0 ", "caption_bbox": [440, 244, 775, 273]}, {"image_id": 3, "file_name": "157_03.png", "page": 3, "dpi": 300, "bbox": [492, 305, 749, 450], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Delta wing images to show the adaptive change of point density when the user zooms in or out ", "caption_bbox": [440, 474, 775, 503]}, {"image_id": 4, "file_name": "157_04.png", "page": 4, "dpi": 300, "bbox": [113, 104, 735, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Hipip images to show the effect of different shading threshold (a) threshold=0.3; (b) threshold=0.6; (c) threshold=0.9", "caption_bbox": [116, 335, 730, 351]}, {"image_id": 5, "file_name": "157_05.png", "page": 5, "dpi": 300, "bbox": [237, 116, 621, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Brain examples to show that the image generated by approximate isosurface geometry is similar to that by exact isosurface geometry (a) approximate isosurface geometry (b) exact isosurface geometry ", "caption_bbox": [73, 335, 774, 364]}, {"image_id": 6, "file_name": "157_06.png", "page": 6, "dpi": 300, "bbox": [443, 261, 773, 495], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The effect of shading threshold on the message size(in bytes) using delta wing and small UNC brain datasets ", "caption_bbox": [440, 509, 775, 538]}, {"image_id": 7, "file_name": "157_07.png", "page": 7, "dpi": 300, "bbox": [117, 113, 728, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 4: This table shows the message size(in bytes) when the iso- surface of the big UNC brain rotated with different incremental de- gree. The slower it rotated, the more the frame coherence it had. ", "caption_bbox": [440, 475, 775, 517]}, {"image_id": 8, "file_name": "157_08.png", "page": 7, "dpi": 300, "bbox": [77, 380, 407, 613], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 5: This table shows the message size (in bytes) when the iso- surface of the small UNC brain rotated with different incremental de- gree. The slower it rotated, the more the frame coherence it had. ", "caption_bbox": [440, 635, 775, 677]}], "158": [{"image_id": 0, "file_name": "158_00.png", "page": 1, "dpi": 300, "bbox": [100, 121, 748, 405], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example Setup I: Combination of a CTA (Computed Tomography Angiography) dataset and a related MRI (Magnetic Resonance Imaging) dataset of a human head. The MRI dataset provides the skin and brain tissue. It is vertically cut and the two halves are moved away from each other to get insight to the inner structures. The CTA dataset contains the skull and the vessels which are rendered with different transfer functions. Images (a-c) show three stages of an interactive multi-volume visualization session and image (d) represents the render graph which corresponds to the final configuration in (c). ", "caption_bbox": [73, 418, 775, 483]}, {"image_id": 1, "file_name": "158_01.png", "page": 3, "dpi": 300, "bbox": [97, 75, 386, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The abstract render graph structure represents a scene of two volumes with different rendering styles applied. ", "caption_bbox": [73, 325, 408, 351]}, {"image_id": 2, "file_name": "158_02.png", "page": 3, "dpi": 300, "bbox": [472, 76, 743, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The resulting image of the applied render graph given in Figure 2 to the dual-volume scene. ", "caption_bbox": [440, 325, 775, 351]}, {"image_id": 3, "file_name": "158_03.png", "page": 4, "dpi": 300, "bbox": [448, 74, 768, 200], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The two-pass shader generation algorithm. In the first pass the required variables are determined and saved in the variable state. In the second pass the shader programs are assembled from prede- fined code parts. ", "caption_bbox": [440, 214, 775, 266]}, {"image_id": 4, "file_name": "158_04.png", "page": 5, "dpi": 300, "bbox": [440, 75, 776, 174], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Three types of multi-volume slice accumulation on the ex- ample of two overlapping proxy slices: Merge (left), Separate (mid- dle), and Intersect (right). Each different colored region is processed by an individual shader. The gray square illustrates the intersection layer of the multi-volume slice. ", "caption_bbox": [440, 188, 775, 253]}, {"image_id": 5, "file_name": "158_05.png", "page": 6, "dpi": 300, "bbox": [89, 74, 394, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A screen shot of the multi-volume visualization tool, show- ing the Setup I. ", "caption_bbox": [73, 311, 408, 337]}, {"image_id": 6, "file_name": "158_06.png", "page": 7, "dpi": 300, "bbox": [108, 77, 742, 435], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Example Setups II-IV and the corresponding render graphs: Setup II in image (a) shows a DVR shaded functional MRI (fMRI) dataset combined with the anatomical brain MRI data rendered as illuminated semi-transparent isosurface and a single 2D slice of the whole head as context information, Setup III in image (b) shows the combination of an illuminated DVR shaded MRI head with a ghosting method applied to see the inside. The interior brain is rendered as illuminated isosurface with a 3D LIC computation applied, to emphasize the curvature. For Setup IV in image (c) the upper half of the head is cut away, to lay open the brain, which is segmented and colored due to a functional brain atlas. ", "caption_bbox": [73, 448, 775, 513]}], "159": [{"image_id": 0, "file_name": "159_00.png", "page": 2, "dpi": 300, "bbox": [476, 635, 750, 878], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Trilinearly interpolated scalar signal (in black) along a cast ray approximated by the midpoint rule (in red). ", "caption_bbox": [440, 893, 775, 919]}, {"image_id": 1, "file_name": "159_01.png", "page": 3, "dpi": 300, "bbox": [477, 339, 741, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparison between a trilinearly interpolated signal (black curve) and its 1st order approximation (red segment) after composi- tion with the extinction component \u03c4 (s) of a random transfer function (blue diagram on top left). The two resulting curves are depicted on the right with their respective colors. ", "caption_bbox": [440, 549, 775, 614]}, {"image_id": 2, "file_name": "159_02.png", "page": 3, "dpi": 300, "bbox": [111, 391, 379, 635], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Trilinearly interpolated scalar signal (in black) along a cast ray approximated by the trapezoid rule (in red). ", "caption_bbox": [73, 650, 408, 676]}, {"image_id": 3, "file_name": "159_03.png", "page": 4, "dpi": 300, "bbox": [109, 443, 381, 691], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Trilinearly interpolated scalar signal (in black) along a cast ray approximated by Simpson\u2019s rule (in red). ", "caption_bbox": [73, 708, 408, 734]}, {"image_id": 4, "file_name": "159_04.png", "page": 5, "dpi": 300, "bbox": [117, 79, 735, 728], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Trilinear signals (in black) obtained from cast rays in the Neghip (top row) and the Silicium (bottom row) datasets. The red curves illustrate the 1st order approximations (left column) and the 2nd order approximations (right columns) with constant sampling length of the ray. ", "caption_bbox": [73, 746, 775, 772]}, {"image_id": 5, "file_name": "159_05.png", "page": 6, "dpi": 300, "bbox": [443, 643, 750, 714], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Pre-integration table computation times for the CPU and the GPU approaches (in seconds). ", "caption_bbox": [440, 725, 775, 751]}, {"image_id": 6, "file_name": "159_06.png", "page": 8, "dpi": 300, "bbox": [49, 1038, 740, 1094], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Bucky Ball 643 dataset rendered at different integration orders and different sampling rates", "caption_bbox": [179, 962, 669, 976]}, {"image_id": 7, "file_name": "159_07.png", "page": 8, "dpi": 300, "bbox": [73, 681, 777, 916], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Fuel 643 dataset rendered at different integration orders and different sampling rates", "caption_bbox": [194, 603, 654, 617]}, {"image_id": 8, "file_name": "159_08.png", "page": 8, "dpi": 300, "bbox": [73, 403, 777, 557], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Neghip 643 dataset rendered at different integration orders and different sampling rates", "caption_bbox": [187, 325, 661, 339]}], "160": [{"image_id": 0, "file_name": "160_00.png", "page": 1, "dpi": 300, "bbox": [442, 639, 750, 862], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Sample volume renderings of data set 1. The left column shows two views of one data component. The right column shows two different AMR level ranges for a different component, with the top image showing levels 0 through 1, the bottom image showing just level 1. ", "caption_bbox": [440, 575, 775, 640]}, {"image_id": 1, "file_name": "160_01.png", "page": 2, "dpi": 300, "bbox": [442, 125, 750, 348], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Sample renderings from data set 2. In clockwise direction from the top left corner are AMR levels 0 through 4, 2 through 4, 3 through 4, and 4. ", "caption_bbox": [440, 87, 775, 126]}, {"image_id": 2, "file_name": "160_02.png", "page": 4, "dpi": 300, "bbox": [95, 165, 354, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Data set 2 volume block bounding wireframes. Each vertex corresponds to a grid-centered position on the boundary. The wire- frames demonstrate the curvature and non-uniform cell sizes of the curvilinear space. Level 0 has 8 distinct blocks, level 1 has 24 distinct blocks. ", "caption_bbox": [73, 87, 408, 152]}, {"image_id": 3, "file_name": "160_03.png", "page": 4, "dpi": 300, "bbox": [452, 167, 745, 386], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Data set 1 volume block bounding wireframes. Each vertex corresponds to a grid-centered position on the boundary. The left column shows AMR levels 0 and 1, while the right column shows AMR level 1. The wireframes demonstrate the curvature and non- uniform cell sizes of the curvilinear space. Level 0 has 8 distinct blocks, level 1 has 24 distinct blocks. ", "caption_bbox": [440, 87, 775, 165]}, {"image_id": 4, "file_name": "160_04.png", "page": 6, "dpi": 300, "bbox": [73, 125, 790, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Set 1 blocks", "caption_bbox": [555, 371, 659, 384]}, {"image_id": 5, "file_name": "160_05.png", "page": 7, "dpi": 300, "bbox": [444, 619, 740, 919], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 4: Set 2 rendering times for different minimum step lengths and viewport resolutions. ", "caption_bbox": [73, 711, 408, 737]}, {"image_id": 6, "file_name": "160_06.png", "page": 7, "dpi": 300, "bbox": [444, 276, 740, 576], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Data set 2 running times", "caption_bbox": [522, 603, 692, 616]}, {"image_id": 7, "file_name": "160_07.png", "page": 8, "dpi": 300, "bbox": [75, 112, 757, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The positional error(the difference between the original mesh position and the mesh point found with equation 1) is proportional to the point darkness in these images. From left to right, the images are of set 1 levels 0 to 1, set 1 level 1, set 2 levels 0 to 4, set 2 levels 3 to 4. ", "caption_bbox": [73, 87, 775, 113]}], "161": [{"image_id": 0, "file_name": "161_00.png", "page": 2, "dpi": 300, "bbox": [89, 370, 394, 561], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Two materials with different distributions touching each other. ", "caption_bbox": [73, 575, 408, 601]}, {"image_id": 1, "file_name": "161_01.png", "page": 2, "dpi": 300, "bbox": [73, 80, 410, 228], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Left: The neighbor voxels for different radii of a voxel v. Right: A moment curve in 3D space as a function of radius r. The gray lines are the projections of the curve into the r = 0 plane and the \u03c3 = 0 plane. ", "caption_bbox": [73, 246, 408, 300]}, {"image_id": 2, "file_name": "161_02.png", "page": 2, "dpi": 300, "bbox": [464, 73, 752, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The standard deviation of the voxels in Figure 2 as a func- tion of increasing radius. ", "caption_bbox": [440, 265, 775, 291]}, {"image_id": 3, "file_name": "161_03.png", "page": 2, "dpi": 300, "bbox": [439, 368, 777, 581], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The mean values of the voxels in Figure 2 as a function of increasing radius. ", "caption_bbox": [440, 596, 775, 622]}, {"image_id": 4, "file_name": "161_04.png", "page": 3, "dpi": 300, "bbox": [439, 78, 777, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: To the left \u03bc and to the right \u03c3 for voxels with increasing radii are depicted. All cylinders have a \u03bc = 0.5 and an increasing \u03c3 = {0%, 2%, 4%, 6%, 8%, 20%} from left to right. ", "caption_bbox": [440, 259, 775, 302]}, {"image_id": 5, "file_name": "161_05.png", "page": 3, "dpi": 300, "bbox": [457, 427, 757, 689], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Moment curves, projections and r = 1 intersections for cyl2 and cyl20 in Figure 5. ", "caption_bbox": [440, 707, 775, 736]}, {"image_id": 6, "file_name": "161_06.png", "page": 4, "dpi": 300, "bbox": [440, 744, 777, 842], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Top row shows volume rendering with cylinder cyl8 classi- fied. The bottom row shows the dilation steps for the cylinder. ", "caption_bbox": [440, 860, 775, 886]}, {"image_id": 7, "file_name": "161_07.png", "page": 4, "dpi": 300, "bbox": [73, 104, 411, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Moment curves for voxels along a line from the inside to the outside of cyl8 . The green curves and point represent a voxel on the boundary of the material. ", "caption_bbox": [73, 398, 408, 437]}, {"image_id": 8, "file_name": "161_08.png", "page": 4, "dpi": 300, "bbox": [140, 468, 344, 667], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The curve intersections at r = 16 as red dots and an ana- lytically plotted (\u03bc\u03ba , \u03c3\u03ba ) path overlaid to show correspondence. ", "caption_bbox": [73, 682, 408, 712]}, {"image_id": 9, "file_name": "161_09.png", "page": 5, "dpi": 300, "bbox": [73, 78, 777, 617], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: (a) The moment curve space of the cylinder test data with a blue brush rectangle and the corresponding classification below. (b) Derivative curves from the moment curves. (c) The derivative scatterplot of the moment curves intersecting the plane r = 16. (d) The curve space of the test dataset with stabilized curves shown in blue. A derivative brush as defined in c) selects all stabilized curves. The result is a classification of all material interiors, material borders, and background. (e) A color transfer function on stabilized moment curves identifies materials of different variances and their borders. ", "caption_bbox": [73, 631, 775, 696]}, {"image_id": 10, "file_name": "161_10.png", "page": 6, "dpi": 300, "bbox": [447, 164, 770, 347], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Two classified and dilated regions in a human CT dataset.", "caption_bbox": [440, 369, 775, 382]}, {"image_id": 11, "file_name": "161_11.png", "page": 6, "dpi": 300, "bbox": [73, 74, 411, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: (a A 2D projection of the 3D moment curve space with identified stable regions in blue. (b Only stabilized curves are shown with a zoom-in on the boundaries. ", "caption_bbox": [73, 267, 408, 306]}, {"image_id": 12, "file_name": "161_12.png", "page": 7, "dpi": 300, "bbox": [73, 77, 777, 463], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Moment curve steps a)-f) for classifying regions of a human CT dataset. Results show in e) two coronal slices before and after classification and one classified axial slice. ", "caption_bbox": [73, 478, 775, 504]}, {"image_id": 13, "file_name": "161_13.png", "page": 8, "dpi": 300, "bbox": [73, 74, 777, 566], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Comparison of (a) 2D transfer function, (b) LH histogram and (c) moment curve classification. Renderings to the right in (c) are semitransparent. Unclassified and classified moment curve slice pairs are also shown. ", "caption_bbox": [73, 580, 775, 606]}], "162": [{"image_id": 0, "file_name": "162_00.png", "page": 3, "dpi": 300, "bbox": [114, 350, 366, 480], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The relation between the normalized gradient direction gt and the viewing direction v. ", "caption_bbox": [73, 494, 407, 520]}, {"image_id": 1, "file_name": "162_01.png", "page": 3, "dpi": 300, "bbox": [87, 74, 763, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The figure shows viewpoint selection results of the hydrogen atom around the Y axis based on the shape view descriptor. (a) the deformed viewing circle. The radius of each viewpoint is proportional to normalized viewpoint quality and the color mapping from blue to red corresponds to viewpoint quality from low to high. (b) the rendered image from the optimal viewpoint. (c) the corresponding intensity image from the optimal viewpoint. (d) the rendered image from the worst viewpoint for comparison. ", "caption_bbox": [73, 272, 775, 324]}, {"image_id": 2, "file_name": "162_02.png", "page": 4, "dpi": 300, "bbox": [89, 74, 761, 218], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Effects of the Gaussian filter and the bilateral filter with different parameters on the engine dataset. The detail is highlighted through the lighting. The intensity values is normalized in the range [0,1]. (a) the original volume. (b) the filtered result using the Gaussian filter with \u03c3 = 2. (c) the filtered result using the Bilateral filter with \u03c3s = 2 and \u03c3r = 0.1. (d) the filtered result using the Bilateral filter with \u03c3s = 2 and \u03c3r = 0.2. (e) the filtered result using the Bilateral filter with \u03c3s = 4 and \u03c3r = 0.2. ", "caption_bbox": [73, 237, 775, 290]}, {"image_id": 3, "file_name": "162_03.png", "page": 5, "dpi": 300, "bbox": [87, 74, 763, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The figure shows the viewpoint selection results of a synthesis cube data with the random details on the -Z face based on the hybrid view descriptor. The viewing sphere is deformed similar to the deformed circle in Figure 2. The radius of each viewpoint is proportional to normalized viewpoint quality and the color mapping from blue to red corresponds to viewpoint quality from low to high. (a) the deformed viewing sphere of the shape view descriptor. (b) the deformed viewing sphere of the detail view descriptor. (c) the deformed viewing sphere of the combined view descriptor with \u03b1 = 0.5. (d) the rendered image from the optimal viewpoint of the combined view descriptor with \u03b1 = 0.5. ", "caption_bbox": [73, 272, 775, 338]}, {"image_id": 4, "file_name": "162_04.png", "page": 5, "dpi": 300, "bbox": [84, 362, 399, 532], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The figure shows the viewpoint selection results of a syn- thesis cube data with the random details on the -Z face around the X axis based on the detail view descriptor. (a) the deformed viewing circle. (b) the rendered image from the optimal viewpoint. ", "caption_bbox": [73, 551, 408, 603]}, {"image_id": 5, "file_name": "162_05.png", "page": 6, "dpi": 300, "bbox": [84, 575, 399, 745], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The figure shows the deformed viewing circles of a shock- wave dataset around the X axis for the comparison of the opacity view descriptor and the shape view descriptor. The shape view de- scriptor is more effective in the estimation of the structural informa- tion. (a) the deformed viewing circle of the opacity view descriptor. (b) the deformed viewing circle of the shape view descriptor. ", "caption_bbox": [73, 763, 408, 841]}, {"image_id": 6, "file_name": "162_06.png", "page": 6, "dpi": 300, "bbox": [87, 325, 763, 506], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The figure shows the viewpoint selection results of the daisy pollen grain dataset based on the detail view descriptor. (a) the original volume. (b) the shape volume. (c) the deformed viewing sphere of the detail view descriptor. (d) the rendered image from the optimal viewpoint. ", "caption_bbox": [73, 524, 775, 550]}, {"image_id": 7, "file_name": "162_07.png", "page": 6, "dpi": 300, "bbox": [87, 74, 763, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The figure shows the viewpoint selection results of the tooth and vortex datasets based on the shape view descriptor. (a) the rendered image of the tooth dataset from the optimal viewpoint. (b) the rendered image of the tooth dataset from the worst viewpoint. (c) the rendered image of the vortex dataset from the optimal viewpoint. (d) the rendered image of the vortex dataset from the worst viewpoint. ", "caption_bbox": [73, 272, 775, 311]}, {"image_id": 8, "file_name": "162_08.png", "page": 7, "dpi": 300, "bbox": [87, 243, 763, 424], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The figure shows the viewpoint selection results of the shockwave and the daisy pollen grain datasets based on the hybrid view descriptor. The parameter \u03b1 is 0.8. (a) the deformed viewing sphere of the shockwave dataset. (b) the rendered image of the shockwave dataset from the optimal viewpoint. (c) the deformed viewing sphere of the daisy pollen grain dataset. (d) the rendered image of the daisy pollen grain dataset from the optimal viewpoint. ", "caption_bbox": [73, 442, 775, 494]}, {"image_id": 9, "file_name": "162_09.png", "page": 7, "dpi": 300, "bbox": [84, 74, 766, 197], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The figure shows the viewpoint selection results of the shockwave dataset based on the hybrid view descriptor with different \u03b1 settings.", "caption_bbox": [73, 216, 775, 229]}], "163": [{"image_id": 0, "file_name": "163_00.png", "page": 2, "dpi": 300, "bbox": [126, 74, 721, 503], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Contextual picking overview: (a) A knowledge base provides a library of ray profiles of anatomical structures together with an XML description of available contextual profiles. (b) An initialization step is performed during data set loading. Meta information is extracted to automatically select contextual profiles from the knowledge base. (c) For a picking on the volume rendered image, the current ray profile is analyzed to detect anatomical structures which are represented by the selected contextual profiles. If a good match is given, then this can be utilized for instance to highlight an interest point (e.g., the center of a vertebra) in the slice view. ", "caption_bbox": [73, 510, 775, 575]}, {"image_id": 1, "file_name": "163_01.png", "page": 3, "dpi": 300, "bbox": [440, 340, 777, 697], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The generation of a ray-profile sample for a contrast- enhanced vessel is initiated by picking on the structure in the 3D view. A ray profile is displayed which shows the intensity and the gradient magnitude values along the viewing ray. From a selected subset of this ray profile, which represents the picked vessel, a sam- ple is generated and stored in the ray-profile library. ", "caption_bbox": [440, 716, 775, 794]}, {"image_id": 2, "file_name": "163_02.png", "page": 4, "dpi": 300, "bbox": [440, 73, 777, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Three samples of the aorta (left) with varying extent and intensity range are collected from the ray-profile library. These sam- ples are utilized to construct a representative mean ray profile (right). ", "caption_bbox": [440, 280, 775, 319]}, {"image_id": 3, "file_name": "163_03.png", "page": 5, "dpi": 300, "bbox": [440, 279, 777, 406], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The mean ray profile of the aorta (middle) is non-uniformly scaled between a minimal (left) and a maximal range (right) to match the corresponding structure in the current ray profile. ", "caption_bbox": [440, 425, 775, 464]}, {"image_id": 4, "file_name": "163_04.png", "page": 6, "dpi": 300, "bbox": [439, 372, 777, 856], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Contextual picking on a thoracic-abdominal CT data set. The 3D position which is returned by the contextual profile with the best response is used to provide meaningful MPR views of the picked aorta (a) and the picked vertebra (b). ", "caption_bbox": [440, 879, 776, 931]}, {"image_id": 5, "file_name": "163_05.png", "page": 7, "dpi": 300, "bbox": [73, 747, 411, 862], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Contextual picking of the airway (left). The identified 3D position is used to provide a meaningful MPR view (right). ", "caption_bbox": [73, 880, 408, 905]}, {"image_id": 6, "file_name": "163_06.png", "page": 7, "dpi": 300, "bbox": [73, 74, 777, 232], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Continuous trace path along the aorta (left). This might lead to unintended responses for the vertebra if the contextual profiles of the aorta and the vertebra are selected (top-right [1-4]). The automatic temporary deactivation of the contextual vertebra profile during the tracing leads to a continuous capturing of the aorta (bottom-right [1*-4*]). ", "caption_bbox": [73, 251, 775, 290]}, {"image_id": 7, "file_name": "163_07.png", "page": 8, "dpi": 300, "bbox": [73, 81, 777, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Labeling of lumbar vertebrae. (a) A single picking on each of the four lumbar vertebrae is performed for their labeling. (b) The result from another viewpoint when the first-hit position is taken for label placement. (c) The result for the same viewpoint when the contextual picking result is taken for label placement. (d) The exact labeling positions of L1 with just the first-hit approach. (e) The exact labeling positions of L1 with the contextual picking approach. ", "caption_bbox": [73, 392, 775, 444]}], "164": [{"image_id": 0, "file_name": "164_00.png", "page": 2, "dpi": 300, "bbox": [80, 75, 788, 381], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visibility histogram for two datasets. (a) The visibility histogram (purple plot) applied to a CT foot dataset reveals that the opacity transfer function defined by the user (red line strip) is not effective at highlighting the interval of interest (bone). This is due to flesh tissue occluding underneath layers. (b) The user then manipulates the opacity of the skin and flesh intervals until the bone tissue has enough visibility. The VH provides immediate feedback that helps the user converge to a solution. (c) For a tooth dataset, rendering of different isosurfaces becomes a tedious approach. Similar to the case before, certain values occlude most of the important intervals (see the peak in the visibility histogram). Rather than letting the user manipulate each interval, we run an algorithm that automatically searches along the parameter space until the visibility of the surfaces of interest is maximized. The result is seen in (d). Notice how the most occluding intervals are made transparent. ", "caption_bbox": [73, 394, 775, 485]}, {"image_id": 1, "file_name": "164_01.png", "page": 3, "dpi": 300, "bbox": [85, 77, 407, 222], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Computation of visibility histograms. Given a viewpoint, the total opacity of a given sample, computed as the product of the orig- inal opacity and the transfer function and the accumulated opacity, is added to the corresponding bin in the histogram. ", "caption_bbox": [73, 243, 409, 295]}, {"image_id": 2, "file_name": "164_02.png", "page": 3, "dpi": 300, "bbox": [452, 77, 765, 501], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Occlusion Signatures of two different datasets. (a) The sig- nature on the histogram reveals the presence of a strong occluder. A little opacity in the interval of the occluder has a dramatic effect in the visibility of the hidden features. (b) The signature of this histogram reveals that no interval in the scalar field is a strong occluder. ", "caption_bbox": [440, 514, 775, 579]}, {"image_id": 3, "file_name": "164_03.png", "page": 4, "dpi": 300, "bbox": [444, 78, 754, 158], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Effect of sampling resolution. As the resolution of the view- dependent slices decreases, the frequencies of the interval on the right are scaled and biased, misrepresenting the actual visibility of the sample values, measured as the visibility that would be obtained at the Nyquist frequency (1/512 in this example). ", "caption_bbox": [440, 181, 775, 246]}, {"image_id": 4, "file_name": "164_04.png", "page": 4, "dpi": 300, "bbox": [81, 80, 402, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Evaluation of GPU-based histogram algorithms. Timing comparison between gather (red) and scatter algorithm (green) in seconds (log scale) vs. size of view-dependent volume. Note that scatter algorithm is faster for sampling rates less than 1/512. ", "caption_bbox": [73, 335, 408, 387]}, {"image_id": 5, "file_name": "164_05.png", "page": 5, "dpi": 300, "bbox": [456, 78, 750, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Convergence of different algorithms for transfer function op- timization. We plot energy vs. number of iterations. Conjugate gradi- ent reaches a good solution in less than 10 iterations while steepest descent requires up to 5 times the number of iterations. ", "caption_bbox": [440, 310, 775, 362]}, {"image_id": 6, "file_name": "164_06.png", "page": 6, "dpi": 300, "bbox": [73, 86, 786, 418], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Three results of automatic classification of a CT foot dataset, depending on the optimization weights. (a) Giving more weight to user satisfaction does not deviate much from the original user specification, but results in little visibility of important tissue (bone). (b) Uniform weighting achieves a balance between user satisfaction and visibility. Now bone tissue is visible, while skin and flesh tissue are still represented, although with little opacity. (c) Finally, giving more weight to visibility allows the system to decrease the opacity of occluding tissue. ", "caption_bbox": [73, 431, 775, 483]}, {"image_id": 7, "file_name": "164_07.png", "page": 7, "dpi": 300, "bbox": [79, 82, 771, 370], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Classification of vortex data. (a) The user sets the opacity function using a pre-defined collection of Gaussian bells equally distributed along the data domain. We notice that important isosurfaces (green to orange area) become occluded by the isosurfaces coded in blue. (b) The automatically generated transfer function exhibits a falloff in opacity for the unimportant isosurfaces so that visibility is attained for the important intervals. The resulting image shows the inner features while still providing context. (c) The user now shifts the importance to the interval between blue and green isosurfaces. The outer layers in blue become more transparent, while the isosurfaces in green become visible. ", "caption_bbox": [73, 382, 775, 447]}, {"image_id": 8, "file_name": "164_08.png", "page": 8, "dpi": 300, "bbox": [123, 73, 727, 863], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: VDTF of the entropy of a supernova simulation. Highest entropy is red, the lowest blue. (a) The initial transfer function attempts to depict a series of isosurfaces whose importance (opacity) increases linearly. We can see that most of the important surfaces are occluded by the blue surface. (b) After optimization, the occluding surfaces are given low opacity, resulting in better visibility of the inner layers. The red layers are still difficult to observe, given that the user considers all of these intervals as important. (c) The user then reduces the expected opacity of the green and orange layers in an attempt to improve visibility. Rather than manually finding a good trade off, the user lets the system perform the search automatically. The resulting image now provides more visibility to the layers of interest (white and red). (d) Since VDTF are view-dependent, the user now selects a different viewpoint. The system lets the user explore the transfer function space. Increasing the opacity of unimportant layers (blue and green) is now possible since it does not affect much the visibility of the red layer, completely visible from this vantage point. ", "caption_bbox": [73, 876, 775, 994]}], "165": [{"image_id": 0, "file_name": "165_00.png", "page": 1, "dpi": 300, "bbox": [73, 86, 777, 399], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Different representations of signal transduction in biological cells: microscopic image from an experiment obtained with confocal laser scanning microscopy; microscope-like image generated with one of our visualization techniques; geometric representation emphasizing single proteins and the structure of the cell; closeup of the highlighted region showing the crowded environment in a simulated cell (from left to right). ", "caption_bbox": [73, 410, 775, 449]}, {"image_id": 1, "file_name": "165_01.png", "page": 3, "dpi": 300, "bbox": [73, 73, 777, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A signaling molecule (orange) and its trajectory (red) between obstacles (purple) and the cytoskeleton (rose and light blue) of a cell. The utilization of depth cues and depth of field emphasizes molecule and trajectory: (a) without depth of field and depth cues; (b) applied color gradient on the cytoskeleton; (c) applied depth of field; (d) desaturation and color gradient as depth cue; (e) combined depth cues and depth of field. ", "caption_bbox": [73, 272, 775, 324]}, {"image_id": 2, "file_name": "165_02.png", "page": 3, "dpi": 300, "bbox": [549, 362, 664, 442], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Reactions (gray) between molecules are illustrated by ar- rows. Reactants (green) enter the reaction and products (red) leave it . ", "caption_bbox": [440, 468, 775, 507]}, {"image_id": 3, "file_name": "165_03.png", "page": 4, "dpi": 300, "bbox": [439, 80, 777, 336], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Difference between diffusion (left) and motorized transport along the cytoskeleton (right) towards the nucleus (gray). Diffusion leads to random-walk tracks while the transported molecules follow the direction of the cytoskeleton cylinders on straight paths. In the second row the cytoskeleton is included to show the alignment of tracks and cytoskeleton (closeup). Some diffusive paths seem to go through the cytoskeleton solely because only every thousandth po- sition is visualized and connected by a straight line. Additionally, the lower half of the cell was cut away and the edges of the cytoskeleton are emphasized for better distinction in the lower left image. ", "caption_bbox": [440, 346, 775, 477]}, {"image_id": 4, "file_name": "165_04.png", "page": 4, "dpi": 300, "bbox": [90, 84, 401, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The MAPK-pathway: MAPK is activated by the receptor (reaction r1 ). The activated form MAPKp then has to transport the information to the nucleus but is attacked by phosphatases (r2 ). The phosphatases relax back into the active form immediately (r3 ) ", "caption_bbox": [73, 289, 408, 342]}, {"image_id": 5, "file_name": "165_05.png", "page": 5, "dpi": 300, "bbox": [73, 80, 773, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Generated microscopic images showing the protein concentration difference between diffusion only (a) and additional motor transport along the cytoskeleton (b), as well as the respective radial concentration profiles calculated from the particle positions (c). ", "caption_bbox": [73, 292, 775, 317]}, {"image_id": 6, "file_name": "165_06.png", "page": 5, "dpi": 300, "bbox": [73, 338, 777, 526], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Drug diffusion into the tumor and binding to the tumor cells: (a) 5 min after injection; (b) 30 min after injection; (c) transection 30 min after injection; (d) radial concentration profile 30 min after injection. ", "caption_bbox": [73, 531, 775, 556]}, {"image_id": 7, "file_name": "165_07.png", "page": 7, "dpi": 300, "bbox": [73, 80, 777, 323], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Illustration of the difference in size between a tumor (1.2 mm), cells (20 \u00b5m, rose) and drug molecules (20 nm, yellow while diffusing and red if bound to a cell) visualized by zooming in. The drug molecules are up-scaled by a factor of 15. The magnification in (c) shows rendering artifacts due to precision issues on the GPU. ", "caption_bbox": [73, 342, 775, 381]}], "166": [{"image_id": 0, "file_name": "166_00.png", "page": 4, "dpi": 300, "bbox": [74, 629, 410, 815], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A slice of the temperature self-correlation field normal to the z axis. The reference location is at (140\u25e6 W, 0\u25e6 , 0m). Blue and yellow are for negative and positive linear correlations, respectively (white for no linear correlation). Continents, oceans, longitudes, and latitudes are labeled. ", "caption_bbox": [73, 824, 408, 889]}, {"image_id": 1, "file_name": "166_01.png", "page": 5, "dpi": 300, "bbox": [81, 74, 769, 634], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: First and second rows: k-means clustering the TACs (a)-(c) and the ICs (d)-(f) of the 1200 time steps climate temperature data set. Left to right: three clusters of temporal curves with increasing temporal activity are shown. The corresponding rendering at the first time step (indicated by the time lines in their temporal curves) are also displayed. Each cluster is highlighted with high saturated colors while the rest of data are rendered with low saturated colors for the context. Centroids of clusters are displayed in black on top of the temporal curves. Third row: the segmentation result corresponding to the 2D region selected over 105 time steps. The first time steps of temperature and salinity variables are shown in (g) and (i), respectively. Six clusters denoted by different colors are shown in (h) and (j), respectively. ", "caption_bbox": [73, 641, 775, 719]}, {"image_id": 2, "file_name": "166_02.png", "page": 6, "dpi": 300, "bbox": [194, 73, 657, 625], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Volume and slice rendering of the self-correlation map. The first 120 time steps of the climate data set are used. Left column: temperature variable. Right column: salinity variable. The reference location (140\u25e6 W, 0\u25e6 , 0m) is indicated with a cross sign. ", "caption_bbox": [73, 632, 775, 658]}, {"image_id": 3, "file_name": "166_03.png", "page": 7, "dpi": 300, "bbox": [81, 73, 769, 625], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Volume and slice rendering of the cross-correlation map with temperature and salinity variables. The first 120 time steps of the climate data set are used. Left column: cross-correlation of salinity values with temperature value at (140\u25e6 W, 0\u25e6 , 0m). Middle column: cross-correlation of temperature values with salinity value at (140\u25e6 W, 0\u25e6 , 0m). Right column: cross-correlation of temperature and salinity values at the same locations, which correspond to the diagonal of the cross-correlation matrix. ", "caption_bbox": [73, 632, 775, 684]}, {"image_id": 4, "file_name": "166_04.png", "page": 8, "dpi": 300, "bbox": [160, 74, 690, 599], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The CCA result with the sea surface slice of the temperature and salinity data over 310 time steps. The first two leading CCA patterns (i.e., the first and second columns of matrices A1r\u00d7d and A2r\u00d7d ) in Equation 7 are displayed. The displayed CCA patterns help scientists detect a La Nin\u0303a event. ", "caption_bbox": [73, 605, 775, 644]}], "167": [{"image_id": 0, "file_name": "167_00.png", "page": 2, "dpi": 300, "bbox": [118, 80, 732, 224], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Traditional way of HARDI glyph visualization. The glyphs\u2019 surface is getting smoother as the order of tessellation of the icosahedron is increased from order 2 (a) to order 7 (d). Changes of the maxima can be observed as the glyphs\u2019 surface gets smoother. ", "caption_bbox": [73, 243, 775, 268]}, {"image_id": 1, "file_name": "167_01.png", "page": 4, "dpi": 300, "bbox": [467, 89, 748, 364], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of our ray-casting algorithm.", "caption_bbox": [485, 393, 725, 405]}, {"image_id": 2, "file_name": "167_02.png", "page": 5, "dpi": 300, "bbox": [456, 74, 761, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Close-up of our GPU glyphs showing a detail of a synthetic phantom dataset of two crossing fiber bundles under an angle of 90 \u25e6 ", "caption_bbox": [440, 332, 775, 357]}, {"image_id": 3, "file_name": "167_03.png", "page": 7, "dpi": 300, "bbox": [99, 175, 751, 481], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Rendering performance of the classical geometry-based glyph-rendering method with varying order of tessellation.", "caption_bbox": [122, 892, 726, 904]}], "168": [{"image_id": 0, "file_name": "168_00.png", "page": 1, "dpi": 300, "bbox": [447, 381, 784, 560], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) DTI integral curves methods show the continuous struc- tures such as the white matter \ufb01ber tracts well. However, there are integration error hidden in the integral curves and the tensor details are partially lost. (b) Glyphs methods show individual tensors well. However, they do not present the continuous structures and connec- tivity information well. And they su\ufb00er from cluttering if placed on a regular sample grid. ", "caption_bbox": [440, 573, 775, 664]}, {"image_id": 1, "file_name": "168_01.png", "page": 3, "dpi": 300, "bbox": [88, 763, 420, 864], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visualizing eight di\ufb00usion tensors along an integral curve with (a) glyphs, (b) streamballs, and (c) merging ellipsoids (R=1.0). ", "caption_bbox": [73, 877, 408, 902]}, {"image_id": 2, "file_name": "168_02.png", "page": 3, "dpi": 300, "bbox": [453, 245, 778, 483], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visualizing eight di\ufb00usion tensors with di\ufb00erent iso-values: (a) 0.01, (b) 0.25, (c) 0.51, (d) 0.75, (e) 0.85, (f) 0.95. The trun- cation radius R is 1.0. ", "caption_bbox": [440, 496, 775, 534]}, {"image_id": 3, "file_name": "168_03.png", "page": 3, "dpi": 300, "bbox": [454, 719, 782, 771], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The results with di\ufb00erent truncation radii: (a) 0.3, (b) 0.5, (c) 1.0. In all cases, the iso-value is 0.5. ", "caption_bbox": [440, 784, 775, 809]}, {"image_id": 4, "file_name": "168_04.png", "page": 4, "dpi": 300, "bbox": [81, 518, 417, 909], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The merging ellipsoids method was applied to the DTI data of a normal subject. (a) The red box indicates the horizontal view of the region-of-interest on the fractional anisotropy map of the brain. (b) The merging ellipsoids capture the connectivity information as well as the tensor details. (c) Sagittal view of the merging ellipsoids. (d) Coronal view of the merging ellipsoids. ", "caption_bbox": [73, 922, 408, 1000]}, {"image_id": 5, "file_name": "168_05.png", "page": 4, "dpi": 300, "bbox": [447, 211, 784, 607], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Comparison of the integral curves method, the simple el- lipsoids glyph method, and the merging ellipsoids method in a corpus callosum region of the brain. (a) The red box indicates the horizon- tal view of the region-of-interest in the brain. The dimension of the region is 17mm \u00d7 17mm \u00d7 17mm. (b) The integral curves show the connectivity information but lack the tensor details. These curves also accumulate integration error. (c) Ellipsoid glyphs placed on the integral curves reveal more details in the individual tensors but reduce the connectivity information. (d) The merging ellipsoids capture the connectivity information as well as the tensor details. ", "caption_bbox": [440, 620, 775, 750]}, {"image_id": 6, "file_name": "168_06.png", "page": 5, "dpi": 300, "bbox": [447, 73, 782, 461], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The comparison of the three visualization methods in an- other region-of-interest close to the forceps major. (a) The region- of-interest. (b) The integral curves method. (c) The simple ellipsoid glyph method. (d) The merging ellipsoids method. ", "caption_bbox": [440, 474, 775, 526]}, {"image_id": 7, "file_name": "168_07.png", "page": 5, "dpi": 300, "bbox": [95, 75, 417, 431], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The iso-value parameter was adjusted interactively by users to produce a continuous set of merging ellipsoids models that provide information with di\ufb00erent emphases on the connectivity information and the tensor details. (a), (b), (c), and (d) were produced by the iso-values set to 0.90, 0.80, 0.60, and 0.40. The region-of-interest is the same as in Figure 6. ", "caption_bbox": [73, 444, 408, 522]}, {"image_id": 8, "file_name": "168_08.png", "page": 6, "dpi": 300, "bbox": [77, 73, 411, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: This picture shows the di\ufb00erence in tensors along an in- tegral curve. The blue arrow points to the region where the tensors are more anisotropic and well aligned while the red arrow points to the region with more isotropy and uncertainty. ", "caption_bbox": [73, 403, 408, 455]}], "169": [{"image_id": 0, "file_name": "169_00.png", "page": 1, "dpi": 300, "bbox": [424, 86, 779, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Approaches used to develop algorithms for graph visual- ization ", "caption_bbox": [440, 409, 775, 434]}, {"image_id": 1, "file_name": "169_01.png", "page": 2, "dpi": 300, "bbox": [123, 78, 361, 255], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of geodesic-path tendency. Note that the dashed line is not part of the graph. To find the path between nodes 1 and 2, if search always starts from node 1, people tend to follow the path 1-7-5-6 first, then the path 1-3-5-6, and finally the path 1-3-4-2. ", "caption_bbox": [73, 272, 408, 324]}, {"image_id": 2, "file_name": "169_02.png", "page": 2, "dpi": 300, "bbox": [122, 343, 359, 419], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Path continuity suggests that the path from node a to node b is easier to detect than that from a to c. ", "caption_bbox": [73, 438, 408, 463]}, {"image_id": 3, "file_name": "169_03.png", "page": 2, "dpi": 300, "bbox": [455, 426, 766, 630], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Stimuli examples in Pilot 1", "caption_bbox": [518, 652, 696, 664]}, {"image_id": 4, "file_name": "169_04.png", "page": 3, "dpi": 300, "bbox": [107, 76, 380, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Stimuli examples in Pilot 2", "caption_bbox": [152, 409, 330, 421]}, {"image_id": 5, "file_name": "169_05.png", "page": 6, "dpi": 300, "bbox": [453, 329, 765, 528], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Means of median times (sec.) for complex and simple graphs ", "caption_bbox": [440, 558, 775, 583]}, {"image_id": 6, "file_name": "169_06.png", "page": 6, "dpi": 300, "bbox": [453, 78, 766, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Means of median times (sec.)", "caption_bbox": [510, 297, 705, 309]}, {"image_id": 7, "file_name": "169_07.png", "page": 7, "dpi": 300, "bbox": [461, 379, 758, 571], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 6: Means of time (sec.) and error rates (%) for simple graphs and the results of ANOVA with repeated measures ", "caption_bbox": [440, 712, 775, 736]}, {"image_id": 8, "file_name": "169_08.png", "page": 7, "dpi": 300, "bbox": [77, 381, 410, 570], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Means of error rates (%) for complex and simple graphs", "caption_bbox": [446, 602, 768, 614]}], "170": [{"image_id": 0, "file_name": "170_00.png", "page": 3, "dpi": 300, "bbox": [86, 346, 747, 552], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Applying post processing algorithms to the layout of Figure 1(a). (a) LSM. (b) The Delaunay triangulation based PGM. (c) Relative neighborhood graph based PGM. ", "caption_bbox": [69, 565, 771, 591]}, {"image_id": 1, "file_name": "170_01.png", "page": 3, "dpi": 300, "bbox": [99, 74, 742, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Applying a spring-electrical algorithm with different repulsive force models on qh882 with |V | = 882 and E| = 1533. (a) With the standard force model (2). (b) With the alternative force model (3) (p = 1.8). (c) With the alternative force model (3) (p = 4). ", "caption_bbox": [69, 274, 771, 300]}, {"image_id": 2, "file_name": "170_02.png", "page": 5, "dpi": 300, "bbox": [155, 96, 694, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Comparing the CPU time (in seconds) for the baseline al- gorithm SFDP, post processing algorithms LSM and the Delaunay triangulation based PGM, as well as the FM3 algorithm. ", "caption_bbox": [438, 396, 773, 435]}, {"image_id": 3, "file_name": "170_03.png", "page": 6, "dpi": 300, "bbox": [220, 136, 678, 316], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Applying the Delaunay triangulation based PGM algorithms to graph dwt 1005 with |V | = 1005 and |E| = 3808. Left: the Delaunay triangulation which contains many long edges. Right: the Delaunay triangulation based PGM fail to preserve the symmetry. ", "caption_bbox": [74, 339, 776, 365]}, {"image_id": 4, "file_name": "170_04.png", "page": 6, "dpi": 300, "bbox": [143, 424, 739, 603], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Applying post processing algorithms to graph dwt 1005 with |V | = 1005 and |E| = 3808. Left: layout by SFDP. Middle: after applying LSM. Right: after applying relative neighborhood based PGM. ", "caption_bbox": [74, 648, 776, 674]}, {"image_id": 5, "file_name": "170_05.png", "page": 7, "dpi": 300, "bbox": [104, 96, 785, 416], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Spring-electrical algorithms on the USA.ncol graph with |V | = 44954 and |E| = 44953. (a) Layout by SFDP. (b) Layout by FM3 .", "caption_bbox": [94, 429, 757, 443]}, {"image_id": 6, "file_name": "170_06.png", "page": 8, "dpi": 300, "bbox": [267, 587, 566, 904], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Result of LGL on USA.ncol graph.", "caption_bbox": [304, 920, 527, 933]}, {"image_id": 7, "file_name": "170_07.png", "page": 8, "dpi": 300, "bbox": [98, 126, 735, 446], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Applying post processing algorithms to the layout in Figure 6(a). (a) LSM. (b) the Delaunay triangulation based PGM.", "caption_bbox": [104, 459, 728, 472]}], "171": [{"image_id": 0, "file_name": "171_00.png", "page": 3, "dpi": 300, "bbox": [96, 278, 391, 458], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Hierarchical structure for the presented technique. Catego- rized nodes are clustered based on both connectivity and categories. Non-categorized nodes are clustered based on connectivity. ", "caption_bbox": [73, 477, 408, 516]}, {"image_id": 1, "file_name": "171_01.png", "page": 3, "dpi": 300, "bbox": [492, 121, 734, 236], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of space-filling hierarchy layout.", "caption_bbox": [479, 253, 736, 265]}, {"image_id": 2, "file_name": "171_02.png", "page": 3, "dpi": 300, "bbox": [448, 609, 769, 852], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Processing flow of the hybrid layout technique.", "caption_bbox": [469, 870, 746, 882]}, {"image_id": 3, "file_name": "171_03.png", "page": 5, "dpi": 300, "bbox": [94, 278, 389, 440], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Drawing style of our implementation. It distinguishes cat- egorized and non-categorized nodes by the colors of nodes and the thickness/transparency of links. ", "caption_bbox": [73, 459, 408, 498]}, {"image_id": 4, "file_name": "171_04.png", "page": 5, "dpi": 300, "bbox": [84, 796, 381, 911], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Local modification of clusters to closely place the clusters belonging to the selected category. ", "caption_bbox": [73, 930, 408, 956]}, {"image_id": 5, "file_name": "171_05.png", "page": 5, "dpi": 300, "bbox": [443, 594, 773, 771], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Result(1). Zooming in the categorized nodes. (left) Nodes connected by links or painted in the same colors properly get closer, indicated as [A], [B], and [C]. Almost isolated two sets of nodes are properly separated, indicated as [D]. (right) Rectangular regions of the clusters. No nodes or clusters are cluttered. ", "caption_bbox": [440, 790, 776, 855]}, {"image_id": 6, "file_name": "171_06.png", "page": 6, "dpi": 300, "bbox": [95, 77, 389, 458], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Evaluation of our hybrid method with other methods.", "caption_bbox": [458, 304, 757, 316]}, {"image_id": 7, "file_name": "171_07.png", "page": 7, "dpi": 300, "bbox": [443, 77, 773, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Result(3). (left) Highlighting links connecting nodes that belong to the specific category, without layout modification. (right) Highlighting links connecting nodes that belong to the specific cat- egory, with layout modification. The layout modification is useful to zoom in the specific category. ", "caption_bbox": [440, 278, 775, 343]}, {"image_id": 8, "file_name": "171_08.png", "page": 7, "dpi": 300, "bbox": [77, 79, 406, 623], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Result(2). (upper left) Original layout. (upper right) Non- categorized nodes get closer to centers of the clusters. It helps to understand inter-cluster connections. (lower) Non-categorized nodes are distorted and get closer to categorized nodes, to realize focus and context. It helps to understand which clusters of non-categorized nodes are tightly connected to specific categorized nodes. ", "caption_bbox": [73, 642, 408, 720]}, {"image_id": 9, "file_name": "171_09.png", "page": 8, "dpi": 300, "bbox": [139, 76, 343, 581], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Visualization of an active biological network. In consul- tation with a bioinformatics scientist, we found our layout helps find hub genes indicated as [A], and important genes that belong to many categories indicated as [B]. It also helps to find clusters successfully isolated indicated as [C], and sets of clusters belong to completely common categories but separated, indicated as [D] and [D\u2019], [E] and [E\u2019], and [F] and [F\u2019]. ", "caption_bbox": [73, 598, 409, 689]}], "172": [{"image_id": 0, "file_name": "172_00.png", "page": 2, "dpi": 300, "bbox": [79, 387, 406, 484], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Edge conservation and connectivity conservation are re- quired to preserve paths in hierarchy cuts. (a) Edge conservation ensures that edges exist between metanodes of a hierarchy cut if and only if there exists one or more edges between descendants of the metanodes. (b) Connectivity conservation ensures that paths ex- ist through metanodes. If the red dashed edge did not exist, there would not be a path from the bold metaedge on the left through to the bold metaedge on the right. ", "caption_bbox": [73, 502, 408, 607]}, {"image_id": 1, "file_name": "172_01.png", "page": 2, "dpi": 300, "bbox": [85, 74, 398, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Result of one TugGraph operation, with hierarchy view above and graph view below. (a) A cut node of the hierarchy is se- lected, in this case, the highlighted node in light blue as shown. (b) The result of the TugGraph operation on this node. All the nodes in red consist of leaves or proximal components of the light blue node. ", "caption_bbox": [73, 305, 408, 370]}, {"image_id": 2, "file_name": "172_02.png", "page": 4, "dpi": 300, "bbox": [109, 74, 741, 506], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: All steps of the TugGraph algorithm with hierarchy above and graph below. (a) The input to the algorithm with the node the user has clicked on outlined in red. (b) The same selection is shown, but with the full graph visible to the leaves. Dashed lines are used for the parts of the graph hierarchy below the hierarchy cut. (c) Elements of the source set S are outlined in red. (d) Each element of the proximal set P is outlined in blue. The edges that were used to create the proximal set are highlighted in blue as well. (e) The proximal cut set C is outlined in yellow. The hierarchy edges used to compute the proximal cut set are in blue in the hierarchy view. (f) The hierarchy is destroyed below each proximal cut element. (g) The proximal components are computed. These components are outlined in red in the figure. (h) The final hierarchy is presented. ", "caption_bbox": [73, 524, 775, 602]}, {"image_id": 3, "file_name": "172_03.png", "page": 5, "dpi": 300, "bbox": [79, 73, 405, 165], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Summary of asymptotic complexity of TugGraph stages. The sets S is and P are the source and proximal sets. The sets DS and DP are the sum of the degrees of all nodes in the S and P sets respectively. The sets MS and MP consist of the sets of metanodes that exist above S and P to the elements of C. ", "caption_bbox": [73, 176, 408, 241]}, {"image_id": 4, "file_name": "172_04.png", "page": 6, "dpi": 300, "bbox": [151, 77, 699, 458], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Browsing paths between Vancouver and Columbus: (a) Grouse, (b) initial GrouseFlocks decomposition, (c) GrouseFlocks coarsening, and (d)-(e) TugGraph. In Grouse, metanodes of the hierarchy are coloured using the type of topological feature they contain. (b) In GrouseFlocks and TugGraph, Vancouver and Columbus are coloured in saturated purple while the large component in desaturated purple is the remaining airports. (c) The coarsened metanodes are brown, and the ones containing airports one hop from Vancouver are outlined in red. (d) The saturated tan Van One Hop contains airports one hop from Vancouver. (e) Van One Hop is outlined in red, and Van Two Hops contains airports two hops from Vancouver. Van Two Hops is in saturated blue. ", "caption_bbox": [73, 475, 775, 553]}, {"image_id": 5, "file_name": "172_05.png", "page": 7, "dpi": 300, "bbox": [73, 169, 774, 843], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Exploration of the Net05 dataset using: (a) LGL, (b) SPF, (c) initial GrouseFlocks decomposition, (d) GrouseFlocks coarsening, and (e)-(j) TugGraph. In the LGL and SPF drawings, UBC servers and those four hops away are highlighted red. GrouseFlocks shows a good initial decomposition but is unable to go further since the attribute information on this dataset is minimal. TugGraph, however, shows how UBC connects to the Internet. ", "caption_bbox": [73, 861, 775, 913]}, {"image_id": 6, "file_name": "172_06.png", "page": 8, "dpi": 300, "bbox": [148, 78, 336, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Bacon number trends in Actors. Bacon Number 1 con- tains all actors with a Bacon number of one. The saturated blue node to its right and Bacon Number 2 contain actors with a Bacon num- ber of 2. We see that actors with Bacon numbers of one or two tend to act with each other as their components are connected. ", "caption_bbox": [73, 312, 408, 377]}], "173": [{"image_id": 0, "file_name": "173_00.png", "page": 2, "dpi": 300, "bbox": [446, 471, 757, 595], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) Cluttered Treemap: displaying all 5 levels of NBA 2003 data set. (b) Basic map which renders only first 4 levels. (c) Infor- mation at level 5 is shown through rectangles standing perpendicular to the basic map. For a better understanding of our technique and related discussions that follow, the supplementary video may turn out to be useful. ", "caption_bbox": [440, 625, 775, 703]}, {"image_id": 1, "file_name": "173_01.png", "page": 3, "dpi": 300, "bbox": [479, 624, 739, 758], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Elevation map imparts a Front-back(Up-Down) Relation be- tween base rectangles in non-tilted(tilted) map. ", "caption_bbox": [440, 777, 775, 802]}, {"image_id": 2, "file_name": "173_02.png", "page": 3, "dpi": 300, "bbox": [480, 390, 737, 528], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Top-Bottom Relation between base rectangles in Basic Map changes to Front-Back Relation in Tilted View. ", "caption_bbox": [440, 546, 775, 571]}, {"image_id": 3, "file_name": "173_03.png", "page": 3, "dpi": 300, "bbox": [99, 325, 387, 515], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Problem of Occlusion", "caption_bbox": [163, 551, 317, 563]}, {"image_id": 4, "file_name": "173_04.png", "page": 3, "dpi": 300, "bbox": [113, 76, 365, 194], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Perceiving hierarchy: Left. The entire tree. Levels to be displayed in basic map are in shaded box. Middle. The basic map. Rectangles correspond to nodes at deepest displayed level, eg.- A, G, F. Right. The lifted map that stands atop rectangle labeled A displays subtree rooted at A. ", "caption_bbox": [73, 222, 408, 287]}, {"image_id": 5, "file_name": "173_05.png", "page": 4, "dpi": 300, "bbox": [98, 132, 752, 906], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Sequence of diagrams explaining two cases of adaptation algorithm. To clearly show the elevation values at every stage, the diagrams are drawn in such a way that they look tilted at 0\u25e6 . In the actual application, they would appear as tilted at some angle. ", "caption_bbox": [73, 924, 775, 949]}, {"image_id": 6, "file_name": "173_06.png", "page": 5, "dpi": 300, "bbox": [174, 404, 309, 519], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: All Front neighbors of B determine if B can be lowered.", "caption_bbox": [82, 534, 399, 546]}, {"image_id": 7, "file_name": "173_07.png", "page": 5, "dpi": 300, "bbox": [443, 178, 746, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) Occlusion free treemap with multiple lifted maps and elevated base rectangles. (b) Distorted Basic map: obtained by tilting the figure at left back to zero degree. (c) Distortion at full tilt: 90\u25e6 rotated view of figure at far left. ", "caption_bbox": [440, 335, 775, 387]}, {"image_id": 8, "file_name": "173_08.png", "page": 5, "dpi": 300, "bbox": [500, 736, 716, 874], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Contraction of a sample base rectangle A. The basic map rotates around z = 0. ", "caption_bbox": [440, 891, 775, 916]}, {"image_id": 9, "file_name": "173_09.png", "page": 6, "dpi": 300, "bbox": [204, 77, 646, 192], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: (a) Basic view with some randomly selected lifted maps. (b)-(d) As the angle of tilt gradually goes down to 0\u25e6 , the heights of the lifted maps proportionally reduce so that basic view suffers no distortion. The sequence will produce a basic view same as in Fig. 1(b). ", "caption_bbox": [73, 209, 775, 237]}, {"image_id": 10, "file_name": "173_10.png", "page": 6, "dpi": 300, "bbox": [202, 267, 648, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: (a)-(c) Base rectangles contract to bring all lifted maps to same image plane as angle of tilt approaches 90\u25e6 . (d) At 90\u25e6 tilted view, the view is similar to that of a 2D treemap with details exposed. ", "caption_bbox": [73, 401, 775, 429]}, {"image_id": 11, "file_name": "173_11.png", "page": 6, "dpi": 300, "bbox": [95, 783, 379, 898], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Left. The basic map is tilted at \u03b81 such that h1 = k \u2217 \u03b81 < w. Hence no zoom achieved. Right. The basic map is tilted at \u03b82 such that h2 = k \u2217 \u03b82 > w. A gain equal to h2 /w on area for rendering lifted map is obtained. ", "caption_bbox": [73, 934, 408, 986]}, {"image_id": 12, "file_name": "173_12.png", "page": 6, "dpi": 300, "bbox": [458, 638, 750, 690], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: If a base rectangle is made to slide forward as angle of tilt increases, its associated lifted map gradually expands, even if its height stays constant over change of angle, as is the case in the diagrams. The black thick line represents axis of rotation of the entire map. The blue line which denotes extended top edge of rectangle A gradually moves forward. ", "caption_bbox": [440, 733, 775, 811]}, {"image_id": 13, "file_name": "173_13.png", "page": 7, "dpi": 300, "bbox": [467, 487, 747, 786], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: (a) Normal Treemap: The manually placed frame encloses the Atlantic Division. (b) Basic View up to 3 levels show four Divi- sions. (c) The entire lifted map represents Atlantic Division. ", "caption_bbox": [440, 805, 775, 844]}, {"image_id": 14, "file_name": "173_14.png", "page": 7, "dpi": 300, "bbox": [98, 801, 389, 917], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Importance of support walls: Left. Treemap rendered without support walls. Middle. Image after adding support walls. The leftmost lifted map is occluded by support walls. Right. Sidewise rotation used as a tool to visualize the occluded lifted map. ", "caption_bbox": [73, 934, 408, 986]}, {"image_id": 15, "file_name": "173_15.png", "page": 8, "dpi": 300, "bbox": [108, 101, 375, 437], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Selection of levels for Basic View: In (a) and (b), the rectangles enclosed in the black frame belong to Boston Celtics. In (c), the lifted map itself corresponds to Boston Celtics. ", "caption_bbox": [73, 456, 408, 495]}, {"image_id": 16, "file_name": "173_16.png", "page": 8, "dpi": 300, "bbox": [479, 97, 745, 190], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 17: View for comparison: Left. Lifted maps corresponding to Miami Heat (front) and New Orleans Hornet (back). Right. Full tilted view: Only two regions to be compared are displayed on the background of support walls. ", "caption_bbox": [440, 212, 775, 264]}], "174": [{"image_id": 0, "file_name": "174_00.png", "page": 2, "dpi": 300, "bbox": [91, 77, 701, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1. Model of the process of testing symbol contrast", "caption_bbox": [282, 227, 566, 241]}, {"image_id": 1, "file_name": "174_01.png", "page": 4, "dpi": 300, "bbox": [96, 79, 778, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2. Some examples of configurations shown to participants for the three different tasks", "caption_bbox": [194, 304, 653, 318]}, {"image_id": 2, "file_name": "174_02.png", "page": 4, "dpi": 300, "bbox": [460, 374, 774, 536], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3. Symbols used, arranged by size and shape (rotational", "caption_bbox": [448, 537, 766, 551]}, {"image_id": 3, "file_name": "174_03.png", "page": 5, "dpi": 300, "bbox": [74, 440, 395, 758], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. Stimulus matrix: each cell represents a testing plot with  one symbol type indicated by the row and the other type by the               column (excluding the diagonal cells) ", "caption_bbox": [80, 763, 402, 805]}, {"image_id": 4, "file_name": "174_04.png", "page": 6, "dpi": 300, "bbox": [424, 165, 799, 640], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6. 3D MDS Results. (a) rotations of polygons (b) rotations of         asterisks (c) rotations of all symbols simultaneously ", "caption_bbox": [440, 639, 774, 667]}, {"image_id": 5, "file_name": "174_05.png", "page": 6, "dpi": 300, "bbox": [424, 674, 781, 860], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7. Optimal superposition of size scale for different shapes:                    (a) polygons, (b) asterisks. ", "caption_bbox": [445, 859, 770, 887]}, {"image_id": 6, "file_name": "174_06.png", "page": 7, "dpi": 300, "bbox": [439, 529, 763, 777], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "  Figure 10. Average size contrast of each shape (red), average polygon contrast and average asterisk contrast of each size (blue),     and average between-family contrast of each size (yellow) ", "caption_bbox": [444, 776, 773, 818]}, {"image_id": 7, "file_name": "174_07.png", "page": 7, "dpi": 300, "bbox": [457, 165, 759, 412], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9. 2D MDS results for symbols per size", "caption_bbox": [491, 411, 723, 425]}, {"image_id": 8, "file_name": "174_08.png", "page": 7, "dpi": 300, "bbox": [65, 165, 409, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8. Perceptual distances between symbols for different size                         steps and families ", "caption_bbox": [78, 336, 404, 364]}], "175": [{"image_id": 0, "file_name": "175_00.png", "page": 2, "dpi": 300, "bbox": [459, 611, 779, 868], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The node ordering is a level order traversal through a BFS spanning tree. The root node\u2019s order is set to 0, and the bottom right node at the last level (level m ) is set to V \u2212 1 where V is the total number of nodes in the graph. ", "caption_bbox": [440, 896, 776, 952]}, {"image_id": 1, "file_name": "175_01.png", "page": 2, "dpi": 300, "bbox": [469, 73, 731, 198], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Two identical graphs with alternative layouts can appear very different. ", "caption_bbox": [440, 213, 775, 241]}, {"image_id": 2, "file_name": "175_02.png", "page": 3, "dpi": 300, "bbox": [88, 596, 393, 726], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A graph and one of its BFS spanning trees. (a) A random graph. (b) One of the BFS spanning trees rooted at node a. The number next to the node indicates its order. The solid black line represents the tree edge and the dashed blue line corresponds to the non-tree edge. ", "caption_bbox": [73, 732, 409, 802]}, {"image_id": 3, "file_name": "175_03.png", "page": 3, "dpi": 300, "bbox": [468, 851, 778, 935], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The procedure to find all peripheral nodes in a graph.", "caption_bbox": [439, 937, 749, 951]}, {"image_id": 4, "file_name": "175_04.png", "page": 4, "dpi": 300, "bbox": [111, 108, 387, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Two adjacency matrices for the graph in Figure 3. Nodes are ordered by following CM ordering. If we ignore node labels, these two matrices are the same. (a) The ordering starts with node d. (b) The ordering starts with node a. ", "caption_bbox": [73, 258, 409, 314]}, {"image_id": 5, "file_name": "175_05.png", "page": 4, "dpi": 300, "bbox": [460, 73, 769, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Four different situations between nodes u and v. The graphs shown here are all subgraphs in some larger graph structure. The blue triangle represents an arbitrary substructure. (a) Nodes u and v are pseudo-indistinguishable. (b) The order between nodes u and v can be determined by the order between nodes a and b. (c) The order between nodes u and v is determined by the degree sum of those nodes connected to nodes u and v separately. (d) Node u should be placed ahead of node v because node g\u2019s parent node c is ordered before node h\u2019s parent b. ", "caption_bbox": [439, 367, 775, 492]}, {"image_id": 6, "file_name": "175_06.png", "page": 5, "dpi": 300, "bbox": [73, 503, 405, 675], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Two adjacency matrices from two different orderings. The visualization of both matrices are very similar, the only difference being edge (x, j) highlighted in red. The gray grid background is for ease of visual tracking for columns and rows. The global penalty for the left matrix is 41, while the global penalty of the right matrix is 40. ", "caption_bbox": [73, 691, 409, 761]}, {"image_id": 7, "file_name": "175_07.png", "page": 5, "dpi": 300, "bbox": [452, 340, 755, 669], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Two different orderings of the same graph having exactly the same visual representations for their adjacency matrix. On the left are two BFS spanning tree orderings with their corresponding adjacency matrices shown on the right (note that this is an unreal situation as the starting node a is not a peripheral node). ", "caption_bbox": [440, 674, 776, 744]}, {"image_id": 8, "file_name": "175_08.png", "page": 6, "dpi": 300, "bbox": [86, 652, 378, 773], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: (a): A cubic symmetric graph of size 8. (b) and (c) are two of its BFS spanning trees rooted at node a. ", "caption_bbox": [73, 779, 408, 807]}, {"image_id": 9, "file_name": "175_09.png", "page": 7, "dpi": 300, "bbox": [460, 110, 769, 558], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: An example of how canonical visual matrix changes corresponding to graph structure changes. We use the same circular layout for all three node-link graphs in (a), (b), and (c). Patterns are highlighted in both displays by using colored boxes or red cells. Their correspondences are indicated by both colors and arrows. (a) The original graph that has three clear patterns. (b) Several new edges have been added between those original clusters. (c) The graph changes even more, both representation changes dramatically. The red color in the matrix highlight two patterns, a high degree node (node 2) and a cluster formed by node 10, 11, 12,13, 6 and 21. ", "caption_bbox": [440, 564, 776, 717]}, {"image_id": 10, "file_name": "175_10.png", "page": 7, "dpi": 300, "bbox": [157, 448, 339, 628], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Several computation factors our procedure applying to the IMDB dataset. The column \u201cRunning time\u201d shows both the total running time and also the time used for finding the candidate starting nodes (in parentheses). ", "caption_bbox": [73, 729, 409, 785]}], "176": [{"image_id": 0, "file_name": "176_00.png", "page": 1, "dpi": 300, "bbox": [424, 86, 739, 481], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Point-based visualization of the DMOZ classification hi- erarchy. It contains 754403 nodes of which are 576818 leaves. (dmoz.org snapshot from 03-SEP-2008) ", "caption_bbox": [440, 489, 775, 532]}, {"image_id": 1, "file_name": "176_01.png", "page": 2, "dpi": 300, "bbox": [468, 239, 749, 545], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "                                      \u221a Figure 3: Four recursion steps of the  5-sampling method. ", "caption_bbox": [459, 548, 757, 574]}, {"image_id": 2, "file_name": "176_02.png", "page": 2, "dpi": 300, "bbox": [124, 808, 359, 959], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A point-based                   \u221a     rendering of a surface with undersampling effects (left) and 5-sampling results (right) \u2013 taken from [16] ", "caption_bbox": [73, 967, 408, 998]}, {"image_id": 3, "file_name": "176_03.png", "page": 3, "dpi": 300, "bbox": [118, 74, 365, 344], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Layout adjustment with 8 (c+d) instead of 4 (a+b) chil- dren positioned around the root node. ", "caption_bbox": [73, 356, 408, 385]}, {"image_id": 4, "file_name": "176_04.png", "page": 3, "dpi": 300, "bbox": [471, 74, 746, 348], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Improving readability by encoding the hierarchy levels on the z-axis in a 3D representation of the tree from Fig. 1. ", "caption_bbox": [440, 356, 775, 385]}, {"image_id": 5, "file_name": "176_05.png", "page": 4, "dpi": 300, "bbox": [121, 74, 729, 519], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Different filtering techniques (a-d), subsequent zooming (e-h), and rotation (i-l) of subtrees reveal more details.", "caption_bbox": [122, 529, 727, 544]}, {"image_id": 6, "file_name": "176_06.png", "page": 5, "dpi": 300, "bbox": [454, 793, 762, 890], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) The Balloon Drawings [11] or Bubble Tree Draw- ings [6] are explicit techniques by design. (b) Yet, if instead of the nodes their bounding circles are used, it becomes a circu- lar Treemap technique. (c) The Space-Optimized Tree Visualiza- tion [12] has been published as an explicit technique as well. (d) The derived version uses the underlying polygonal space-division in a Treemap-manner to yield an equivalent implicit layout. ", "caption_bbox": [440, 900, 775, 998]}, {"image_id": 7, "file_name": "176_07.png", "page": 5, "dpi": 300, "bbox": [120, 74, 363, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: This GraphSplat shows areas of high density in Fig. 1. The nodes within the DMOZ hierarchy that correspond to the ar- eas of high density have been sought out and used to annotate the GraphSplat with the font sizes reflecting the hierarchy levels. It can be seen that most of the dense spots correspond to regional subtrees. ", "caption_bbox": [73, 324, 408, 394]}, {"image_id": 8, "file_name": "176_08.png", "page": 6, "dpi": 300, "bbox": [439, 760, 777, 960], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The Ink-Paper-Ratios and overplotted%-values for the 3 trees from Table 1. ", "caption_bbox": [440, 969, 775, 998]}, {"image_id": 9, "file_name": "176_09.png", "page": 6, "dpi": 300, "bbox": [106, 540, 377, 643], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The five categories of space-filling techniques and what they are constrained by. ", "caption_bbox": [73, 652, 408, 681]}, {"image_id": 10, "file_name": "176_10.png", "page": 7, "dpi": 300, "bbox": [134, 74, 716, 366], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The Space-Optimized layout and the RINGS layout with their respective GraphSplats showing test case B and the DMOZ hierarchy from Fig. 1. The dotted circle in the GraphSplat of (b) illustrates the circular area in which the RINGS-representation is laid out, accounting for the wasted space at the bottom of the quadratic screen space. ", "caption_bbox": [73, 377, 775, 420]}, {"image_id": 11, "file_name": "176_11.png", "page": 8, "dpi": 300, "bbox": [104, 500, 380, 649], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Two other possible arrangements for space-filling, point- based layouts. ", "caption_bbox": [73, 659, 408, 688]}, {"image_id": 12, "file_name": "176_12.png", "page": 8, "dpi": 300, "bbox": [74, 74, 777, 203], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: The point-based layouts of the test cases and their respective GraphSplats.", "caption_bbox": [211, 213, 637, 228]}], "177": [{"image_id": 0, "file_name": "177_00.png", "page": 2, "dpi": 300, "bbox": [448, 74, 768, 257], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An example of the SPT tree for time interval [0, 5]. In the time tree T , each internal node labeled [t1 ,t2 ] covers the time span [t1 ,t2 ], and each leaf labeled [t] corresponds to time step t. The search path P on T for query (\u03b5s , \u03b5t ,t \u2032 ) with t \u2032 = 1 is P = (A, B,C, D), and P\u2032 with t \u2032 = 2 is P\u2032 = (A, B, E). At run-time, only T and the octree skeleton S are kept in main memory. We also show a breadth cut on S; any node and its ancestor cannot both exist in a valid cut. ", "caption_bbox": [440, 272, 775, 364]}, {"image_id": 1, "file_name": "177_01.png", "page": 6, "dpi": 300, "bbox": [70, 73, 414, 207], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Preprocessing time comparison with in-core approaches. \u201cNo VM\u201d means not enough virtual memory. ", "caption_bbox": [440, 496, 775, 522]}, {"image_id": 2, "file_name": "177_02.png", "page": 8, "dpi": 300, "bbox": [127, 74, 722, 527], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Representative volume rendering results. The datasets from left to right (and time step): Turb2-30 (1), Jets2 (50), TComb (1), TComb (105). Top row: exact images, by SPT (or TSP) tree with no errors (\u03b5s = \u03b5t = 0), which is the same as out-of-core bricking on original input. Middle row: by our SPT tree; bottom row: by the TSP tree. The error bounds (\u03b5s , \u03b5t ) for these two rows (from left to right): (0.0001, 0.000002), (0.00002, 0.0000002), and (0.001, 0.000001) (same for both time steps of the same dataset TComb). TSP resulted in more artifacts than our SPT. ", "caption_bbox": [73, 542, 775, 594]}], "178": [{"image_id": 0, "file_name": "178_00.png", "page": 1, "dpi": 300, "bbox": [472, 467, 744, 739], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A typical real-world particle dataset from the field of molecular dynamics, containing a mixture of ethanol and heptaflu- oropropane, 1,000,000 molecules altogether, represented by GPU- based compound glyphs. ", "caption_bbox": [440, 753, 775, 805]}, {"image_id": 1, "file_name": "178_01.png", "page": 3, "dpi": 300, "bbox": [74, 73, 409, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Explanation of the different uploading mechanisms used in the first tests. ", "caption_bbox": [440, 360, 775, 385]}, {"image_id": 2, "file_name": "178_02.png", "page": 4, "dpi": 300, "bbox": [439, 74, 774, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Upload performance for 4M short-quantized points. Only 1 fragment is rasterized per vertex. ", "caption_bbox": [440, 324, 775, 349]}, {"image_id": 3, "file_name": "178_03.png", "page": 4, "dpi": 300, "bbox": [73, 75, 407, 516], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Upload performance for 1M 1-pixel points (top) and 1M touching spheres (bottom) on a regular 3D grid covering 80% of the viewport. This diagram uses logarithmic scale for better depiction, since the data values vary by orders of magnitude. Positions are de- fined using 3D float vectors. View port size is 5122 . Since our focus lies on the data upload, we accept the overdraw due to our large par- ticle counts. See table 1 for a description of the shown methods. VBO dynamic mapping means that the buffer is locked and then memcpy\u2019d into. The last two measurements compare dynamic mapping includ- ing one color per vertex. For the first a high number of copy oper- ations is needed (and as such is slower as dynamic mapping only), while the second makes use of a pre-interleaved client-side array of positions and colors, which is consistently faster even than dynamic mapping only for points, but slower for spheres. ", "caption_bbox": [73, 532, 408, 715]}, {"image_id": 4, "file_name": "178_04.png", "page": 4, "dpi": 300, "bbox": [441, 688, 773, 919], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Rendering performance for 500K raycast 2:1 cylinders in a 5122 viewport with varying bounding geometry. The geometry-shader constructed quad is only available for GeForce 8 cards and newer. ", "caption_bbox": [440, 935, 775, 974]}, {"image_id": 5, "file_name": "178_05.png", "page": 5, "dpi": 300, "bbox": [75, 495, 407, 728], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Rendering performance for 500K raycast dipoles (com- plex glyph consisting of two spheres and one cylinder, raycast in one shader; see [17]) in a 5122 viewport. The \u2018normal\u2019 benchmarks em- ploy directly uploaded parameters per primitive, while the others get them from a texture. Also the glyphs are scaled to only 10% of their size to show texture access cost with less dependency on the high fragment shader load. ", "caption_bbox": [73, 743, 408, 834]}, {"image_id": 6, "file_name": "178_06.png", "page": 6, "dpi": 300, "bbox": [88, 73, 396, 189], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Explanation of the different uploading mechanisms in addi- tion to the ones described in table 1. ", "caption_bbox": [440, 354, 775, 379]}, {"image_id": 7, "file_name": "178_07.png", "page": 7, "dpi": 300, "bbox": [73, 76, 407, 507], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Performance for two compound glyph datasets (top: 100,000 Molecules; bottom: 1,000,000 Molecules). This diagram uses logarithmic scale for better depiction, since the data values vary by orders of magnitude. See table 2 for descriptions on the different uploading methods. ", "caption_bbox": [73, 522, 408, 587]}], "179": [{"image_id": 0, "file_name": "179_00.png", "page": 2, "dpi": 300, "bbox": [73, 408, 410, 573], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview on process levels in stochastic simulation.", "caption_bbox": [89, 589, 392, 601]}, {"image_id": 1, "file_name": "179_01.png", "page": 3, "dpi": 300, "bbox": [439, 73, 777, 470], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Experiment View. The multi-run simulation data and the experiment description are shown in icons that are positioned ac- cording to the 2D-layout of the model structure. The color scale for icons is shown left, the color scale for edges is shown at the bottom. ", "caption_bbox": [440, 484, 775, 536]}, {"image_id": 2, "file_name": "179_02.png", "page": 4, "dpi": 300, "bbox": [201, 271, 283, 376], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Design of the node icon. The label allows to identify the model component. An overview on the multi-run simulation data is given by the value range over time. From the background color, the subrange of the global color scale can be identified (see Figure 2). ", "caption_bbox": [73, 391, 408, 443]}, {"image_id": 3, "file_name": "179_03.png", "page": 4, "dpi": 300, "bbox": [73, 708, 410, 846], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: General design for the icons of event types. The size of the arrows excluding the arrowhead encodes the reaction rate, the color encodes the average number of event occurrences for multiple runs. ", "caption_bbox": [73, 865, 408, 904]}, {"image_id": 4, "file_name": "179_04.png", "page": 5, "dpi": 300, "bbox": [73, 144, 410, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Steps to create the segmented color scale from the value ranges of the data. The possibly overlapping value ranges in the data (1) are split into sequential intervals (2). These intervals are merged until a predefined number of intervals remains (3), which can be mapped to the segments of the predefined color scale (4). ", "caption_bbox": [73, 317, 408, 382]}, {"image_id": 5, "file_name": "179_05.png", "page": 6, "dpi": 300, "bbox": [73, 74, 411, 404], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualization design for the comparison of experiments. For every experiment, one Experiment View is shown. The screen shot includes the object-based distortion based on a region of interest. ", "caption_bbox": [73, 419, 408, 458]}, {"image_id": 6, "file_name": "179_06.png", "page": 8, "dpi": 300, "bbox": [73, 74, 777, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visualization design for the detailed exploration of one experiment. The Experiment View (top left) is coordinated with the Multi-Run View (top right) for the selection of one run from all runs, the Node View (bottom left) for the detailed analysis of single-run data linked to nodes, and the Edge View (bottom right) that shows the single-run data connected to edges. The data of the icons highlighted by a shadow are shown in the Node and Edge Views. The icon highlighted by green borders is the node shown in the Multi-Run View. ", "caption_bbox": [73, 548, 775, 600]}], "180": [], "181": [{"image_id": 0, "file_name": "181_00.png", "page": 2, "dpi": 300, "bbox": [98, 83, 383, 368], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: HiMap visualization of a group of IBM smallblue users. Edges are bundled together geometrically. ", "caption_bbox": [73, 371, 409, 398]}, {"image_id": 1, "file_name": "181_01.png", "page": 3, "dpi": 300, "bbox": [138, 73, 343, 347], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: HiMap visualization pipeline.", "caption_bbox": [146, 351, 335, 365]}, {"image_id": 2, "file_name": "181_02.png", "page": 3, "dpi": 300, "bbox": [454, 73, 759, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: HiMap visualization of an online social network within a university department. Edges between clusters are bundled together by hierarchy. The portrait of the selected people is shown as tooltip and the nodes/edges induced from him are highlighted. Here the induced clusters/edges of its parent cluster are also highlighted to assist the comprehension of hierarchical edge bundling. ", "caption_bbox": [440, 381, 775, 460]}, {"image_id": 3, "file_name": "181_03.png", "page": 7, "dpi": 300, "bbox": [83, 289, 767, 427], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Drill-in animation in HiMap, the circular blue frame in the leftmost figure indicates the focused cluster.", "caption_bbox": [151, 427, 693, 441]}, {"image_id": 4, "file_name": "181_04.png", "page": 7, "dpi": 300, "bbox": [113, 79, 737, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "                                                                                                         0 Figure 4: Zooming operation in HiMap: (a) Initial view, the blue frame shows the zoom-in window \u0393 ; (b) After geometric zoom-in, the items are only signified; (c) After semantic zoom-in, more items are visualized adaptively; (d) After drilling in the cluster in the left of sub-figure (a). ", "caption_bbox": [73, 252, 775, 282]}, {"image_id": 5, "file_name": "181_05.png", "page": 8, "dpi": 300, "bbox": [124, 807, 368, 980], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Cluster overlap probability with different layout algorithms.", "caption_bbox": [75, 981, 407, 995]}, {"image_id": 6, "file_name": "181_06.png", "page": 8, "dpi": 300, "bbox": [124, 592, 371, 767], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Coverage performance of summarization algorithms.", "caption_bbox": [87, 768, 394, 782]}, {"image_id": 7, "file_name": "181_07.png", "page": 8, "dpi": 300, "bbox": [124, 377, 365, 555], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Average visual density of graph views during the navigation.", "caption_bbox": [73, 556, 409, 570]}, {"image_id": 8, "file_name": "181_08.png", "page": 8, "dpi": 300, "bbox": [78, 82, 403, 343], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: HiMap visualization of DBLP dataset.", "caption_bbox": [125, 344, 357, 358]}], "182": [{"image_id": 0, "file_name": "182_00.png", "page": 2, "dpi": 300, "bbox": [180, 73, 777, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Smooth interpolation of element metrics over an area-of-interest", "caption_bbox": [236, 261, 611, 274]}, {"image_id": 1, "file_name": "182_01.png", "page": 3, "dpi": 300, "bbox": [114, 74, 366, 221], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The proposed set of textures. Gray value denotes opacity", "caption_bbox": [73, 234, 408, 247]}, {"image_id": 2, "file_name": "182_02.png", "page": 3, "dpi": 300, "bbox": [115, 666, 367, 978], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Diagram showing three areas of interest with metrics", "caption_bbox": [81, 985, 400, 998]}, {"image_id": 3, "file_name": "182_03.png", "page": 3, "dpi": 300, "bbox": [484, 673, 731, 887], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Enhanced areas using shading (compare with Fig. 3)", "caption_bbox": [448, 896, 766, 909]}, {"image_id": 4, "file_name": "182_04.png", "page": 5, "dpi": 300, "bbox": [183, 76, 667, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: JPEG decoder architecture. Icons show the memory usage metric \u00b5mem over five tasks. Areas show the tasks. The metric legend shows the placement of metric icons within each component. Although this figure is quite large, it is hard to correlate metric values and areas ", "caption_bbox": [73, 367, 775, 395]}, {"image_id": 5, "file_name": "182_05.png", "page": 5, "dpi": 300, "bbox": [81, 406, 776, 627], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: JPEG decoder architecture. Left: 5 tasks with memory usage metric. Right: a sixth task and a second metric is added (CPU usage)", "caption_bbox": [73, 642, 775, 655]}, {"image_id": 6, "file_name": "182_06.png", "page": 6, "dpi": 300, "bbox": [141, 291, 706, 628], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Large UML class diagram with 7 areas and over 50 classes. Metrics show the participation of classes in two aspects", "caption_bbox": [106, 644, 742, 657]}, {"image_id": 7, "file_name": "182_07.png", "page": 6, "dpi": 300, "bbox": [73, 73, 778, 255], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: JPEG decoder architecture. Left: shaded AOIs. Right: Adding shading to textured AOIs (compare with Fig. 6 right)", "caption_bbox": [109, 270, 740, 283]}, {"image_id": 8, "file_name": "182_08.png", "page": 7, "dpi": 300, "bbox": [117, 525, 367, 834], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Complex intersection of three overlapping areas", "caption_bbox": [90, 849, 391, 862]}, {"image_id": 9, "file_name": "182_09.png", "page": 7, "dpi": 300, "bbox": [140, 74, 708, 414], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Visualization of the UML diagram in Fig. 8, now with area shading and half-transparent elements", "caption_bbox": [153, 429, 695, 442]}, {"image_id": 10, "file_name": "182_10.png", "page": 8, "dpi": 300, "bbox": [148, 73, 699, 453], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: UML class diagram with two areas, class-level participation metrics, and method-level lines-of-code metrics", "caption_bbox": [123, 462, 726, 475]}], "183": [{"image_id": 0, "file_name": "183_00.png", "page": 2, "dpi": 300, "bbox": [87, 798, 382, 930], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2. Name-tag shaped beam-scan sensor module", "caption_bbox": [104, 940, 383, 954]}, {"image_id": 1, "file_name": "183_01.png", "page": 2, "dpi": 300, "bbox": [129, 583, 345, 730], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1. Concept of Business Microscope", "caption_bbox": [134, 754, 352, 768]}, {"image_id": 2, "file_name": "183_02.png", "page": 2, "dpi": 300, "bbox": [481, 724, 716, 973], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3. System configuration", "caption_bbox": [529, 983, 689, 997]}, {"image_id": 3, "file_name": "183_03.png", "page": 3, "dpi": 300, "bbox": [104, 616, 348, 945], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. (a) Traditional social network visualization.", "caption_bbox": [110, 957, 375, 971]}, {"image_id": 4, "file_name": "183_04.png", "page": 3, "dpi": 300, "bbox": [440, 579, 742, 757], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5. Three cases of grouping", "caption_bbox": [521, 763, 697, 777]}, {"image_id": 5, "file_name": "183_05.png", "page": 3, "dpi": 300, "bbox": [449, 798, 776, 937], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6. Example of data matrix IR (i,j).", "caption_bbox": [507, 943, 713, 957]}, {"image_id": 6, "file_name": "183_06.png", "page": 4, "dpi": 300, "bbox": [97, 89, 755, 590], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7. Algorithm for generating dendrogram", "caption_bbox": [307, 610, 545, 624]}, {"image_id": 7, "file_name": "183_07.png", "page": 5, "dpi": 300, "bbox": [93, 567, 398, 668], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8. Algorithm to prune dendrogram", "caption_bbox": [138, 685, 348, 699]}, {"image_id": 8, "file_name": "183_08.png", "page": 6, "dpi": 300, "bbox": [78, 535, 396, 759], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10. Examples of arranging \u201cActivity level\u201d and \u201cOrder\u201d axis.", "caption_bbox": [80, 758, 406, 772]}, {"image_id": 9, "file_name": "183_09.png", "page": 6, "dpi": 300, "bbox": [451, 292, 784, 664], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11. Examples of organization topographic maps with data", "caption_bbox": [449, 671, 769, 685]}, {"image_id": 10, "file_name": "183_10.png", "page": 6, "dpi": 300, "bbox": [103, 79, 386, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9. Mapping concept of an organization topographic map", "caption_bbox": [84, 201, 402, 215]}, {"image_id": 11, "file_name": "183_11.png", "page": 8, "dpi": 300, "bbox": [92, 107, 748, 953], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12. Organization topographic maps with data from 172 people", "caption_bbox": [255, 958, 597, 972]}], "184": [{"image_id": 0, "file_name": "184_00.png", "page": 2, "dpi": 300, "bbox": [100, 74, 750, 245], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Feature tracking approaches. Unlike traditional approaches, our approach utilizes coherency between time steps in the extraction process. ", "caption_bbox": [73, 263, 775, 289]}, {"image_id": 1, "file_name": "184_01.png", "page": 3, "dpi": 300, "bbox": [89, 74, 394, 178], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The three predictive methods. Direct prediction depends only on the previous time step, linear on the previous two, and quadratic on the previous three. ", "caption_bbox": [73, 192, 408, 231]}, {"image_id": 2, "file_name": "184_02.png", "page": 4, "dpi": 300, "bbox": [108, 74, 742, 374], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Coherent extraction. First, the feature in the previous time steps is used to predict the feature\u2019s region in the current timestep. However, the predicted region of the feature is not the correct region. In order to actually extract the correct region, some parts of it must be grown into (indicated by red voxels), and some parts of the predicted region must be shrunk away (indicated by blue voxels). By proceeding in this manner the coherent part of the feature (purple voxels) is captured in the overlap between the prediction and the actual region, and does not need to be reevaluated. ", "caption_bbox": [73, 388, 775, 453]}, {"image_id": 3, "file_name": "184_03.png", "page": 5, "dpi": 300, "bbox": [79, 74, 394, 243], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The two data sets used in this study. In both data sets, the features of interest are the regions of high vorticity, which correspond to vortices. As can be seen, direct volume renderings of this data can be busy and confusing, which makes them ideal for feature extraction approaches. ", "caption_bbox": [73, 261, 408, 326]}, {"image_id": 4, "file_name": "184_04.png", "page": 5, "dpi": 300, "bbox": [468, 74, 749, 391], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The turbulent vortex dataset: All vortices in the dataset extracted and tracked through time with event handling. Several time steps are shown and the features are highlighted with different colors. The extracted surfaces take an average of 31,698 voxels per time step, which is 1.5% the size of the original data. ", "caption_bbox": [440, 409, 775, 474]}, {"image_id": 5, "file_name": "184_05.png", "page": 6, "dpi": 300, "bbox": [84, 652, 399, 807], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The combustion vorticity dataset, time step 64: Since the our technique is based on segmentation, volume rendering can use this segmentation information to clearly present the features while maintaining context. ", "caption_bbox": [73, 825, 408, 877]}, {"image_id": 6, "file_name": "184_06.png", "page": 6, "dpi": 300, "bbox": [98, 74, 752, 457], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The combustion vorticity dataset: One vortex, highlighted in red, has been interactively extracted and tracked through the data. Traditional correspondence approaches would have to extract and correlate all features, even if user is only interested in one feature. ", "caption_bbox": [73, 475, 775, 501]}, {"image_id": 7, "file_name": "184_07.png", "page": 7, "dpi": 300, "bbox": [76, 75, 761, 316], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Timing tests. Each algorithm was run on several different features in each data set.", "caption_bbox": [197, 334, 652, 347]}], "185": [{"image_id": 0, "file_name": "185_00.png", "page": 1, "dpi": 300, "bbox": [408, 86, 751, 486], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overlay of primal (black) and dual (blue) streamlines.", "caption_bbox": [453, 501, 761, 513]}, {"image_id": 1, "file_name": "185_01.png", "page": 2, "dpi": 300, "bbox": [446, 74, 770, 173], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Outline of algorithm behavior. Left: largest segment be- longs to blue set (arrow), a new streamline for the black set will be started at its midpoint. Middle: new streamline has been inserted (shown as dotted line). Now, black set contains the largest segment (arrow), whose midpoint will again serve as seed point for the next streamline. Right: result of next streamline insertion. Newly inserted streamline is drawn dotted. ", "caption_bbox": [440, 187, 775, 278]}, {"image_id": 2, "file_name": "185_02.png", "page": 3, "dpi": 300, "bbox": [408, 316, 801, 1094], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Effects of different initializations. Left: P empty, Right: P initialized with topology of the vector field. The latter option provides clearly visible separatrices and guarantees conservation of percepti- bility of topological structure at low densities. ", "caption_bbox": [440, 231, 775, 283]}, {"image_id": 3, "file_name": "185_03.png", "page": 3, "dpi": 300, "bbox": [99, 73, 384, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Initial set of dual streamlines, i.e. dual topology shown as dotted lines. The vector field is shown via LIC. Although the ini- tial density distribution is non-uniform, a good starting coverage is achieved and uniformity of primal streamlines is not affected. ", "caption_bbox": [73, 372, 408, 424]}, {"image_id": 4, "file_name": "185_04.png", "page": 4, "dpi": 300, "bbox": [123, 80, 727, 949], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison of streamline placement techniques with decreasing densities. Separation distance from left to right: 0.84%, 1.68%, 3.36% of domain width. Pictures on the first two rows were provided by the authors of [3]. ", "caption_bbox": [73, 967, 775, 992]}, {"image_id": 5, "file_name": "185_05.png", "page": 5, "dpi": 300, "bbox": [487, 704, 730, 946], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Overlay of wall shear stress streamlines and color-coded pressure distribution on a cerebral aneurysm. Critical points are high- lighted by small spheres. ", "caption_bbox": [440, 961, 775, 1000]}, {"image_id": 6, "file_name": "185_06.png", "page": 5, "dpi": 300, "bbox": [477, 337, 740, 611], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparison to feature-based technique by Verma et al. Separation distances: top 2%, bottom 3.5% of domain width. Poisson-distributed seeds employed by Verma et al. introduce signif- icant discontinuities, whereas Dual Seeding results in long continu- ous streamlines, while still capturing topological features. ", "caption_bbox": [440, 629, 775, 694]}, {"image_id": 7, "file_name": "185_07.png", "page": 5, "dpi": 300, "bbox": [165, 73, 685, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Swirling jet entering fluid at rest. Depicted is a planar slice of a 3D velocity field. Separation distance is 0.5% (left) and 1.5% (right) of domain width. Areas of turbulent and laminar flow are well distinguishable at both densities. ", "caption_bbox": [73, 285, 775, 310]}, {"image_id": 8, "file_name": "185_08.png", "page": 6, "dpi": 300, "bbox": [101, 593, 749, 911], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Streamlines of the wall shear stress on a ship propeller. Left: Pressure side, Right: Suction side. Flow separation can be observed at the tip of the blades at the suction side. ", "caption_bbox": [73, 926, 775, 951]}, {"image_id": 9, "file_name": "185_09.png", "page": 6, "dpi": 300, "bbox": [178, 122, 673, 433], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparison of experimental flow and CFD results of a cerebral aneurysm. Particle traces of the near wall flow are shown in the background [6], the wall-shear-stress vector field of a roughly aligned CFD model is depicted with red streamlines. The comparison shows a good agreement of the fields. ", "caption_bbox": [73, 447, 775, 486]}, {"image_id": 10, "file_name": "185_10.png", "page": 7, "dpi": 300, "bbox": [408, 1038, 801, 1094], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Seeding templates proposed by Verma et al.", "caption_bbox": [471, 988, 744, 1000]}, {"image_id": 11, "file_name": "185_11.png", "page": 7, "dpi": 300, "bbox": [439, 588, 777, 969], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Comparison at low streamline density. Our streamline termination algorithm is less strict, allowing streamlines to gather at critical points, which improves their perceptibility. ", "caption_bbox": [440, 518, 775, 557]}, {"image_id": 12, "file_name": "185_12.png", "page": 7, "dpi": 300, "bbox": [458, 339, 759, 500], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Running times in relation to streamline density, which is the inverse of the separation distance. Dual Seeding exhibits a more moderate growth than the methods proposed in [15] and [21]. ", "caption_bbox": [440, 285, 775, 324]}], "186": [{"image_id": 0, "file_name": "186_00.png", "page": 3, "dpi": 300, "bbox": [455, 74, 761, 321], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: DTW between two synthesized data sequences. The two data sequences are normalized Gaussian functions with different means and variances. The warping is plotted as a red line in the lower right subfigure. The distance table is drawn as an image. ", "caption_bbox": [440, 335, 775, 387]}, {"image_id": 1, "file_name": "186_01.png", "page": 4, "dpi": 300, "bbox": [81, 74, 419, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visualization of the TAC-based distance field of a synthe- sized data set. This data set is a Gausian kernel moving over time. (a): the centers of the Gaussian kernels. (b): the isosurface. (c) and (d): DVR images where the opacities are decided according to Equation 3 with the drop-off parameter p of 8 and 16, respectively. (e) and (f): DVR images with discrete and continuous, respectively, color textures. ", "caption_bbox": [73, 324, 408, 416]}, {"image_id": 2, "file_name": "186_02.png", "page": 4, "dpi": 300, "bbox": [447, 74, 786, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Creating motion trail via DVR. (a), (b) and (c): repeated patterns in different frequencies via discrete color map. (d), (e) and (f): repeated patterns in different frequencies via continuous color map. ", "caption_bbox": [440, 324, 775, 376]}, {"image_id": 3, "file_name": "186_03.png", "page": 5, "dpi": 300, "bbox": [456, 74, 761, 419], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualization of the magnitude field of the data set TeraShake 2.1. (a): the mean TACs from three clusters. The se- lected feature TAC is plotted in blue. The values of the three TACs are normalized to match that of the selected feature TAC. (b): the joint histogram. (c): a DVR image. The parameter p in Equation 3 is 8. The basin is plotted as the grey patches. ", "caption_bbox": [440, 431, 775, 509]}, {"image_id": 4, "file_name": "186_04.png", "page": 5, "dpi": 300, "bbox": [81, 74, 402, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The memory layout of the dynamic programming tables on CUDA. (a): The layout without interleaving. (b): The layout with interleaving, where the memory requests to the (i, j)-th elements can be reduced to one request to a coalesced memory space. ", "caption_bbox": [73, 312, 408, 364]}, {"image_id": 5, "file_name": "186_05.png", "page": 6, "dpi": 300, "bbox": [456, 74, 761, 638], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visualization of the ionization front instability simulation. (a): the mean TACs of all clusters (red) and the feature TAC (blue). (b): the joint histogram of the respective TAC-based distance field. (c): a DVR image with continuous color map. (d): a DVR image with contour volumes. The parameter p in Equation 3 is 8 in both (c) and (d). ", "caption_bbox": [440, 650, 775, 728]}, {"image_id": 6, "file_name": "186_06.png", "page": 6, "dpi": 300, "bbox": [89, 74, 394, 421], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualization of the z components in the data set TeraShake 2.1. (a): the mean TACs from three clusters. The selected feature TAC is plotted in blue. (b): the joint histogram. (c): a DVR image. The parameter p in Equation 3 is 8. The basin is plotted as the grey patches. ", "caption_bbox": [73, 433, 408, 498]}, {"image_id": 7, "file_name": "186_07.png", "page": 7, "dpi": 300, "bbox": [464, 74, 752, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The joint histograms under the same TAC in different scale. The test data set is the magnitude field of the data set TeraShake 2.1. The feature TAC is the blue curve in Figure 5 (a). ", "caption_bbox": [440, 321, 775, 360]}, {"image_id": 8, "file_name": "186_08.png", "page": 7, "dpi": 300, "bbox": [81, 74, 403, 243], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visualization of the ionization front instability simulation. Compared to Figure 7, the subfigures here were rendered along a viewing direction parallel to the x axis, thus providing better cue about the symmetricity of the turbulence structure. (a): the DVR image. The saturation parameter in Equation 3 is 8. (b): the enlarged image of subfigure (a). ", "caption_bbox": [73, 256, 408, 334]}], "187": [{"image_id": 0, "file_name": "187_00.png", "page": 3, "dpi": 300, "bbox": [154, 80, 337, 492], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) A graph G and a set of three clusters C = {V1 ,V2 ,V3 }. (b) The graph of clusters H(G, C ); cluster vertices are drawn bigger than the others. ", "caption_bbox": [73, 511, 408, 536]}, {"image_id": 1, "file_name": "187_01.png", "page": 4, "dpi": 300, "bbox": [451, 374, 765, 688], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A view of the graph of clusters, where all clusters are collapsed. Bigger vertices represent clusters. The different scale of color for each vertex is used to reflect its core number: Darker colors correspond to higher core numbers. ", "caption_bbox": [440, 704, 775, 754]}, {"image_id": 2, "file_name": "187_02.png", "page": 4, "dpi": 300, "bbox": [139, 191, 339, 560], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) A graph G where the vertices are labeled with their core num- bers. The closed darker region indicates the 5-core of G; each of the two closed lighter regions indicates a 4-core component of G (their union is the 4-core of G). (b) The (planar) graph of clusters obtained by collapsing the 4-core com- ponent. Notice that the graph of clusters is not planar if we collapse the 5-core; this implies that the (planar, 4-core component)-clustering of G depicted in the figure is a main planar core-clustering of G. ", "caption_bbox": [73, 579, 408, 666]}, {"image_id": 3, "file_name": "187_03.png", "page": 5, "dpi": 300, "bbox": [84, 76, 399, 363], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A new drawing of the graph where one cluster is expanded; the graph induced by the cluster is drawn with a circular layout algorithm. ", "caption_bbox": [73, 377, 408, 402]}, {"image_id": 4, "file_name": "187_04.png", "page": 5, "dpi": 300, "bbox": [449, 76, 766, 417], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A view of the graph where two clusters are expanded and drawn with different algorithms (force-directed to the left and orthogonal to the right). ", "caption_bbox": [440, 432, 775, 457]}, {"image_id": 5, "file_name": "187_05.png", "page": 6, "dpi": 300, "bbox": [449, 287, 767, 573], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A drawing of the graph of clusters for the query \u201corthogonal AND (drawing OR embedding)\u201d. ", "caption_bbox": [440, 587, 775, 612]}, {"image_id": 6, "file_name": "187_06.png", "page": 7, "dpi": 300, "bbox": [141, 565, 343, 916], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Focusing on the largest community with no cluster.", "caption_bbox": [108, 934, 374, 947]}, {"image_id": 7, "file_name": "187_07.png", "page": 7, "dpi": 300, "bbox": [109, 76, 743, 507], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Expanding the clusters of the two largest communities.", "caption_bbox": [282, 524, 565, 537]}, {"image_id": 8, "file_name": "187_08.png", "page": 8, "dpi": 300, "bbox": [131, 74, 352, 488], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Redrawing the bigger core component with a force-directed algo- rithm helps in further detecting sub-communities. ", "caption_bbox": [73, 502, 408, 527]}], "188": [{"image_id": 0, "file_name": "188_00.png", "page": 2, "dpi": 300, "bbox": [73, 74, 777, 450], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A map of books related to \u201c1984\u201d from Amazon.com", "caption_bbox": [271, 466, 577, 478]}, {"image_id": 1, "file_name": "188_01.png", "page": 3, "dpi": 300, "bbox": [93, 74, 390, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Voronoi diagram of vertices and corners of bounding box; (b) better construction of outer boundaries through placement of random points; (c) Voronoi diagram of vertices and points inserted around the bounding boxes of the labels; (d) the final map. ", "caption_bbox": [73, 366, 408, 418]}, {"image_id": 2, "file_name": "188_02.png", "page": 4, "dpi": 300, "bbox": [444, 149, 772, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Applying coloring schemes for the country graph corre- sponding to the map in Fig. 6. Left: SPECTRAL. There are two edges of color difference 1. Right: SPECTRAL+GREEDY, the small- est color difference along any edges is now 4. Node labels are the color index given to the node, and edge label are the absolute differ- ence of the node color index. Nodes are positioned at the center of the polygons in Fig. 6. ", "caption_bbox": [440, 311, 775, 402]}, {"image_id": 3, "file_name": "188_03.png", "page": 4, "dpi": 300, "bbox": [84, 560, 397, 651], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3:     Coloring schemes RANDOM, SPECTRAL, and SPECTRAL+GREEDY. Each node is colored by the color index shown as the node label. Edge labels are the absolute difference of the endpoint labels. ", "caption_bbox": [73, 657, 408, 709]}, {"image_id": 4, "file_name": "188_04.png", "page": 5, "dpi": 300, "bbox": [506, 423, 711, 682], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Map without outer artificial points.", "caption_bbox": [500, 697, 714, 709]}, {"image_id": 5, "file_name": "188_05.png", "page": 5, "dpi": 300, "bbox": [94, 640, 389, 899], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Map without interior artificial points.", "caption_bbox": [129, 909, 352, 921]}, {"image_id": 6, "file_name": "188_06.png", "page": 5, "dpi": 300, "bbox": [94, 353, 389, 610], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Collaboration graph drawn by GMap.", "caption_bbox": [126, 619, 355, 631]}, {"image_id": 7, "file_name": "188_07.png", "page": 5, "dpi": 300, "bbox": [94, 70, 389, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Graph Drawing author collaboration, 1994-2004.", "caption_bbox": [96, 332, 385, 344]}, {"image_id": 8, "file_name": "188_08.png", "page": 6, "dpi": 300, "bbox": [98, 73, 753, 678], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Two of the central clusters in BookLand.", "caption_bbox": [300, 694, 545, 706]}, {"image_id": 9, "file_name": "188_09.png", "page": 7, "dpi": 300, "bbox": [461, 73, 756, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Author collaboration graph for the GD conference, 1994- 2004, using the defragmentation algorithm. ", "caption_bbox": [440, 365, 775, 390]}], "189": [{"image_id": 0, "file_name": "189_00.png", "page": 3, "dpi": 300, "bbox": [456, 77, 778, 636], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) Schematic illustration of the visual paradigm for G pag and Gusr . (b) Schematic illustration of the visual paradigm for Gvis [Ci ,C j ]. ", "caption_bbox": [440, 654, 775, 680]}, {"image_id": 1, "file_name": "189_01.png", "page": 5, "dpi": 300, "bbox": [73, 295, 410, 397], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of Step 2 of the drawing algorithm.", "caption_bbox": [119, 412, 362, 425]}, {"image_id": 2, "file_name": "189_02.png", "page": 7, "dpi": 300, "bbox": [130, 77, 715, 988], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) Drawings D pag (to the left) and Dusr (to the right) on April 1. (b) The effect of hiding edge (Series A, International Cups).", "caption_bbox": [138, 1006, 709, 1019]}, {"image_id": 3, "file_name": "189_03.png", "page": 8, "dpi": 300, "bbox": [105, 90, 739, 988], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Exploring graph Gvis [(Series A, International Cups)]. It is possible to see that the few pages in which the two concepts appear simultaneously are highly accessed. The dark color represents concept Series A, while the light color represents concept International Cup. (b) The effect of hiding edge (Series A, School). The logical connection between the two concepts Series A and School is not reliable. ", "caption_bbox": [73, 1006, 775, 1043]}], "190": [{"image_id": 0, "file_name": "190_00.png", "page": 1, "dpi": 300, "bbox": [424, 86, 757, 515], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An example for labeling a server motherboard.", "caption_bbox": [469, 528, 745, 540]}, {"image_id": 1, "file_name": "190_01.png", "page": 2, "dpi": 300, "bbox": [84, 249, 397, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: The time complexity of the problems for the boundary la- beling subject to the constraints where the locations of ports of each labels are fixed; the labels along the same side are of uniform (max- imum) size. ", "caption_bbox": [440, 302, 775, 354]}, {"image_id": 2, "file_name": "190_02.png", "page": 2, "dpi": 300, "bbox": [74, 386, 421, 482], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration of boundary labeling with hyperleaders and dummy labels. ", "caption_bbox": [73, 498, 408, 523]}, {"image_id": 3, "file_name": "190_03.png", "page": 4, "dpi": 300, "bbox": [75, 397, 414, 530], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The outputs of an example for each step in Algorithm 1.", "caption_bbox": [80, 549, 401, 561]}, {"image_id": 4, "file_name": "190_04.png", "page": 4, "dpi": 300, "bbox": [75, 709, 424, 854], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The outputs of an example for each step in Algorithm 2.", "caption_bbox": [80, 873, 401, 885]}, {"image_id": 5, "file_name": "190_05.png", "page": 4, "dpi": 300, "bbox": [81, 76, 400, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Illustration of routing hyperleaders.", "caption_bbox": [131, 368, 350, 380]}, {"image_id": 6, "file_name": "190_06.png", "page": 6, "dpi": 300, "bbox": [174, 191, 308, 282], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Configuration C(p), which partitions all the sites in the map into four subsets A1 \u2013 A4 according to the location of site p. ", "caption_bbox": [73, 299, 408, 326]}, {"image_id": 7, "file_name": "190_07.png", "page": 7, "dpi": 300, "bbox": [493, 74, 723, 331], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Experimental result for labeling a server motherboard.", "caption_bbox": [451, 347, 764, 359]}, {"image_id": 8, "file_name": "190_08.png", "page": 8, "dpi": 300, "bbox": [77, 308, 772, 732], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Comparison between our experimental results and the optimal solutions for labeling a four-side type-opo-hyperleader map where n = 12 and m = 4, under three different combinations of (\u03bb1 , \u03bb2 ). ", "caption_bbox": [73, 744, 775, 771]}, {"image_id": 9, "file_name": "190_09.png", "page": 8, "dpi": 300, "bbox": [78, 82, 773, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: (a) Statistics of energy costs of our experimental results compared with the optimal solutions. (b) Chart of time vs. number of sites. (c) Chart of energy costs vs. number of stages. ", "caption_bbox": [73, 247, 775, 272]}, {"image_id": 10, "file_name": "190_10.png", "page": 8, "dpi": 300, "bbox": [104, 805, 743, 964], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Comparison of our experimental results under different numbers of sites ((\u03bb1 , \u03bb2 ) = (0.5,0.5)).", "caption_bbox": [169, 975, 679, 992]}], "191": [{"image_id": 0, "file_name": "191_00.png", "page": 2, "dpi": 300, "bbox": [74, 74, 410, 495], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) Overview of the two possible usage scenarios. In the first scenario, a user has a set of static input images and in the second, the input images are generated from volume data. Then, multi-layer alpha extraction is performed, followed by interactive ex- ploration. This process can be repeated. (b) Overall process of the storage and distribution of explorable images. The compact image- based representation of a volume is stored and distributed for future exploration. Multi-layer alpha extraction allows to generate layers for synthesizing new images. Users can influence the layer extraction process and to interactively modify the properties of each layer. ", "caption_bbox": [73, 509, 408, 640]}, {"image_id": 1, "file_name": "191_01.png", "page": 5, "dpi": 300, "bbox": [90, 74, 763, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Spatial consistency priors. (a) Input images on the left allow us to decompose a rendering of a turbulent flow (vorticity). (b) With the extracted layer, we can synthesize a new image of a single feature (green layer). However, with the lack of complete information, some artifacts appear where occluding layers used to be present. (c) Spatial consistency helps alleviate these problems. Compare to the ground-truth image, obtained by re-rendering the individual layer (d). ", "caption_bbox": [73, 275, 775, 327]}, {"image_id": 2, "file_name": "191_02.png", "page": 5, "dpi": 300, "bbox": [448, 341, 768, 624], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Colorization example. An explorable image with 7 layers is recomposed from 4 input images. The colors of all features are modified. The data set is a turbulent flow (vorticity) simulation. ", "caption_bbox": [440, 639, 775, 678]}, {"image_id": 3, "file_name": "191_03.png", "page": 6, "dpi": 300, "bbox": [82, 324, 402, 607], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The radial feathered alpha mask is applied to 3 outer layers (purple, cyan, green) to reveal the inner feature (purple). Insets pro- vide a close up view of one of the areas where the partially occluded structure is revealed. The extraction of all 7 layers is performed using only 3 input images. ", "caption_bbox": [73, 622, 408, 687]}, {"image_id": 4, "file_name": "191_04.png", "page": 6, "dpi": 300, "bbox": [83, 74, 767, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison between the features extracted using our technique (bottom) and the ground-truth, individually volume rendered features (top). The extraction is accurate, except for the structures occluded by opaque features. ", "caption_bbox": [73, 284, 775, 309]}, {"image_id": 5, "file_name": "191_05.png", "page": 6, "dpi": 300, "bbox": [448, 324, 769, 607], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A triangular volumetric cutaway is applied to multiple outer layers of the supernova (entropy) data set. The extraction of 7 layers is performed using only 3 input images. The opacity of the outer layers (blue, cyan, purple, green) is decreased to reveal the inner features (yellow, orange, red). The insets show one of the areas where the finer details of the partially occluded inner structures are revealed with the use of a volumetric cutaway. ", "caption_bbox": [440, 622, 775, 713]}, {"image_id": 6, "file_name": "191_06.png", "page": 7, "dpi": 300, "bbox": [484, 579, 733, 765], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Average error per pixel for explorable images created with a different number of input images. The average error per pixel values are computed from difference images in Figure 8(c) and (d). ", "caption_bbox": [440, 781, 775, 820]}, {"image_id": 7, "file_name": "191_07.png", "page": 7, "dpi": 300, "bbox": [443, 74, 777, 417], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Examples of explorable images created with a different number of input images. There are 7 layers and 4 input images (same setup as in Figure 3). The optimization is performed with 4, 3, 2, and 1 input images (from left to right). (a) Synthesized im- ages, where layer extraction is performed with a different number of images. The error between the synthesized images in (a) and the original rendering is shown in (b). (c) Synthesized images with 3 out of 7 layers fully removed. The error between the synthesized images in (c) and ground truth is shown in (d). Note that the difference mag- nitude is amplified (increased by a factor of 2), for clarity. ", "caption_bbox": [440, 432, 775, 563]}, {"image_id": 8, "file_name": "191_08.png", "page": 7, "dpi": 300, "bbox": [82, 74, 402, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Volumetric cutaways are applied to several layers at a time, simulating cutting planes. Cutaway alpha masks are applied to the outer layers of a lifted flame (mixfrac) data set to reveal hidden struc- tures. The first cutaway is applied to the 2 outermost layers (purple, pink) and the second cutaway is applied to the next 2 layers (red, orange), revealing the partially occluded inner layer (yellow). ", "caption_bbox": [73, 372, 408, 450]}, {"image_id": 9, "file_name": "191_09.png", "page": 8, "dpi": 300, "bbox": [74, 75, 410, 221], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Example of layer extraction from existing input images, with no volume data available. Decomposition is done using 2 in- put images (left). In the first synthesized image, the skin layer is completely removed. In the second synthesized image, a volumetric cutaway is applied to the bone layer to reveal a feature hidden inside. ", "caption_bbox": [73, 235, 408, 300]}], "192": [{"image_id": 0, "file_name": "192_00.png", "page": 1, "dpi": 300, "bbox": [78, 86, 752, 437], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A CT scan of a mouse (360 \u00d7 270 \u00d7 550 voxels) rendered with the proposed illumination model. The closeups on the right show, that semi-transparent, diffuse as well as specular materials are captured realistically. ", "caption_bbox": [73, 448, 775, 474]}, {"image_id": 1, "file_name": "192_01.png", "page": 4, "dpi": 300, "bbox": [94, 77, 394, 279], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": " Figure 2: Light is propagated through the volume slice by slice start-  ing at the cube face F0 being closest to the light source located in ~xl . ", "caption_bbox": [72, 293, 408, 333]}, {"image_id": 2, "file_name": "192_02.png", "page": 5, "dpi": 300, "bbox": [114, 750, 374, 942], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: To avoid popping artifacts, when the main propagation axis dir~max is changed, we employ a blending between the two principal light directions given by F0 and F1 . ", "caption_bbox": [73, 961, 408, 1001]}, {"image_id": 3, "file_name": "192_03.png", "page": 6, "dpi": 300, "bbox": [84, 79, 765, 414], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The generated illumination volume (a) can be used to achieve different rendering effects: rendering with the attenuated light intensity         ~ ) (b), with the scattering chromaticity c(~x, \u03c9 li (~x, \u03c9                                               ~ ) (c) and with full shading as defined by our illumination model (d). ", "caption_bbox": [73, 426, 775, 452]}, {"image_id": 4, "file_name": "192_04.png", "page": 6, "dpi": 300, "bbox": [88, 477, 383, 641], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison of an MRT scan of a human head (256 \u00d7 256 \u00d7 256 voxels) rendered with gradient-based Phong illumination (left) and with our technique (right). The scattering contribution results in a more realistic appearance of the skin, while the shadowing supports the spatial comprehension. ", "caption_bbox": [73, 655, 408, 720]}, {"image_id": 5, "file_name": "192_05.png", "page": 7, "dpi": 300, "bbox": [506, 73, 711, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Performance of our technique with and without light volume regeneration as compared to local Phong illumination. ", "caption_bbox": [440, 834, 775, 859]}, {"image_id": 6, "file_name": "192_06.png", "page": 7, "dpi": 300, "bbox": [88, 760, 396, 920], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A 3D US scan of a human heart (148 \u00d7 203 \u00d7 149 voxels) rendered with gradient-based Phong illumination (left) and with our technique (right). Due to the low signal to noise ratio, spatial com- prehension is difficult when using gradient-based shading. Instead, when using our technique, structures emerge. ", "caption_bbox": [73, 935, 408, 1000]}, {"image_id": 7, "file_name": "192_07.png", "page": 8, "dpi": 300, "bbox": [79, 75, 402, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The results of the conducted depth comparison test. The plots on the left show the average time needed and the accuracy of depth decisions, while the scatter plot shows all images plotted based on their average time and accuracy. As it can be seen, images generated with our technique form a cluster towards more quick and accurate depth decisions. ", "caption_bbox": [73, 295, 408, 373]}], "193": [{"image_id": 0, "file_name": "193_00.png", "page": 2, "dpi": 300, "bbox": [467, 78, 760, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1 (a) A portion of an abdominal CT volume with complex anatomical structures. (b) Conventional meshing approach to model the shape of a single organ for deformation. (c) Global, uniform image-warping can generate visual artifacts on the local fine structure of the volume. (d) Our volume proxy mesh encodes the local geometry and physical behavior of the volume for interactive direct volume manipulation. ", "caption_bbox": [438, 347, 775, 438]}, {"image_id": 1, "file_name": "193_01.png", "page": 3, "dpi": 300, "bbox": [136, 80, 724, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2 Configuration of the direct volume manipulation and the geometry-encoding process. (a) Rendered volume and vertices placed in a regular configuration for low-frequency sampling of global structures. (b) Physically fixed volume area and newly created vertices with a fixed condition, (c) A manipulation target and the corresponding geometry encoded to the mesh. (d) Interaction area directly manipulated by the user. The positions of the vertices in this area are used as constraints in the deformation models. ", "caption_bbox": [74, 340, 774, 393]}, {"image_id": 2, "file_name": "193_02.png", "page": 4, "dpi": 300, "bbox": [73, 830, 408, 956], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3 Direct sketching of incision on rendered breast data. The adaptive proxy geometry supports the discontinuous geometry and deformation of the incision. ", "caption_bbox": [73, 955, 408, 995]}, {"image_id": 3, "file_name": "193_03.png", "page": 5, "dpi": 300, "bbox": [130, 81, 731, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1. Details on test data with computation time for both deformation and rendering. ", "caption_bbox": [439, 967, 776, 995]}, {"image_id": 4, "file_name": "193_04.png", "page": 6, "dpi": 300, "bbox": [467, 79, 745, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6 Volume lighting for a deformed engine. (a) Initial state. The light source is placed above the volume. (b)(c) The shade and shadow correctly change as the volume structure is deformed. (d) deformation without shadow or shade update for comparison. ", "caption_bbox": [441, 323, 773, 376]}, {"image_id": 5, "file_name": "193_05.png", "page": 6, "dpi": 300, "bbox": [105, 79, 395, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5 Volume deformation of sphere data when heterogeneous elasticity is set on the rendered image. (a) Initial state, (b)(c) direct, heterogeneous deformation, and (d) homogeneous deformation without adapting the proxy geometry to the volume for comparison. ", "caption_bbox": [77, 323, 409, 376]}, {"image_id": 6, "file_name": "193_06.png", "page": 7, "dpi": 300, "bbox": [100, 79, 750, 363], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8 Medical application for preoperative planning in a laparoscopic kidney surgery: (a) Initial volume data. (b) Local deformation of the kidney. (c) Volume selection of the kidney artery. (d) The artery is selectively softened and deformed easily. ", "caption_bbox": [421, 367, 765, 420]}], "194": [{"image_id": 0, "file_name": "194_00.png", "page": 1, "dpi": 300, "bbox": [448, 176, 770, 633], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Representing a motion capture data with di\ufb00erent ap- proaches. (a) The motion map approach clusters and shows key frames in a 2D grid map [19]; (b) The action synopsis technique illustrates a motion data with a 3D proximity-preserving curve as- sociated with detected key poses [1]; (c) The motion belts represen- tation focuses on the selection of key frames [23]; (d) The motion overview approach produces a video clip for e\ufb00ective summary and depiction [2]; (e) The motion track proposed in this paper embeds a motion sequence in a 2D reference space that is built from the motion database. Selected key frames from the database are shown as reference points. ", "caption_bbox": [440, 647, 775, 799]}, {"image_id": 1, "file_name": "194_01.png", "page": 2, "dpi": 300, "bbox": [109, 80, 742, 418], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The conceptual overview of our approach.", "caption_bbox": [292, 439, 557, 452]}, {"image_id": 2, "file_name": "194_02.png", "page": 3, "dpi": 300, "bbox": [452, 78, 766, 403], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The SOM of a walking motion sequence.", "caption_bbox": [479, 424, 735, 437]}, {"image_id": 3, "file_name": "194_03.png", "page": 3, "dpi": 300, "bbox": [149, 479, 334, 737], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A joint-based skeleton model.", "caption_bbox": [140, 752, 342, 765]}, {"image_id": 4, "file_name": "194_04.png", "page": 4, "dpi": 300, "bbox": [79, 74, 400, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Applying LLE to the key frames shown in Figure 4.", "caption_bbox": [87, 367, 394, 380]}, {"image_id": 5, "file_name": "194_05.png", "page": 4, "dpi": 300, "bbox": [449, 218, 777, 551], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Results for a walking motion sequence shown in Figure 7 with di\ufb00erent weighting schemes. (a) Nearest neighboring; (b) The inverse distance weighting with Equation 2, where the parameter p = 8; (c) The inverse distance weighting with Equation 3, where the parameter p = 2; (d) The inverse distance weighting with Equa- tion 4, where the parameter p = 2. ", "caption_bbox": [440, 565, 775, 649]}, {"image_id": 6, "file_name": "194_06.png", "page": 4, "dpi": 300, "bbox": [446, 680, 770, 748], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A short walking motion sequence.", "caption_bbox": [496, 763, 718, 776]}, {"image_id": 7, "file_name": "194_07.png", "page": 5, "dpi": 300, "bbox": [451, 76, 763, 236], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Results for three motion sequences: jumping (red), marching (blue), and walking (purple). ", "caption_bbox": [440, 249, 775, 276]}, {"image_id": 8, "file_name": "194_08.png", "page": 5, "dpi": 300, "bbox": [79, 151, 400, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The frames computed with SOM and the original frames.", "caption_bbox": [73, 289, 408, 302]}, {"image_id": 9, "file_name": "194_09.png", "page": 5, "dpi": 300, "bbox": [79, 501, 404, 708], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The final motion track with speed and frame sequence.", "caption_bbox": [78, 722, 403, 735]}, {"image_id": 10, "file_name": "194_10.png", "page": 5, "dpi": 300, "bbox": [451, 726, 764, 957], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Results for four motion sequences which are from dif- ferent persons. ", "caption_bbox": [440, 971, 775, 998]}, {"image_id": 11, "file_name": "194_11.png", "page": 6, "dpi": 300, "bbox": [84, 546, 398, 970], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Motion tracks for Marching, running and walking.", "caption_bbox": [85, 985, 397, 998]}, {"image_id": 12, "file_name": "194_12.png", "page": 7, "dpi": 300, "bbox": [447, 155, 771, 878], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Results for a set of walking motion sequences. (a) Mo- tion tracks from two persons; (b) Motion tracks from ten persons. ", "caption_bbox": [440, 893, 775, 920]}, {"image_id": 13, "file_name": "194_13.png", "page": 8, "dpi": 300, "bbox": [454, 117, 764, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Using MDS for low-dimensional embedding may lead to overlapped motion tracks. In contrast, Figure 10 demonstrates the advantage of using LLE. ", "caption_bbox": [440, 355, 775, 396]}, {"image_id": 14, "file_name": "194_14.png", "page": 8, "dpi": 300, "bbox": [83, 95, 404, 551], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Two walking sequences from two persons.", "caption_bbox": [106, 567, 375, 580]}, {"image_id": 15, "file_name": "194_15.png", "page": 8, "dpi": 300, "bbox": [83, 636, 401, 937], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Two walking sequences (bottom) from one person, and their motion track representations (top). ", "caption_bbox": [73, 949, 408, 976]}, {"image_id": 16, "file_name": "194_16.png", "page": 8, "dpi": 300, "bbox": [448, 498, 768, 901], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 17: Five jumping motion tracks from one person, with the original motion sequences of the blue one and the red one shown at bottom. ", "caption_bbox": [440, 913, 775, 954]}], "195": [{"image_id": 0, "file_name": "195_00.png", "page": 2, "dpi": 300, "bbox": [456, 74, 761, 552], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) A shadowgraph photograph of an AK-47 (Courtesy of G.S. Settles). (b) A schlieren photograph of a gunshot with a color filter applied (reproduced from [14] with permission). ", "caption_bbox": [440, 566, 775, 605]}, {"image_id": 1, "file_name": "195_01.png", "page": 2, "dpi": 300, "bbox": [81, 318, 397, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: 2D illustration of the shadowgraph optical setup.", "caption_bbox": [97, 445, 381, 458]}, {"image_id": 2, "file_name": "195_02.png", "page": 2, "dpi": 300, "bbox": [81, 491, 400, 610], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: 2D illustration of the schlieren optical setup.", "caption_bbox": [109, 630, 371, 643]}, {"image_id": 3, "file_name": "195_03.png", "page": 3, "dpi": 300, "bbox": [156, 86, 696, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Illustration of the rendering pipeline.", "caption_bbox": [312, 342, 537, 355]}, {"image_id": 4, "file_name": "195_04.png", "page": 3, "dpi": 300, "bbox": [190, 381, 293, 484], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A typical color filter used in schlieren optical setups.", "caption_bbox": [90, 500, 392, 513]}, {"image_id": 5, "file_name": "195_05.png", "page": 3, "dpi": 300, "bbox": [441, 380, 776, 879], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A heptane dataset rendered using refractive indices cal- culated from temperature and pressure with (a) a knife-edge cutoff, (c) color filter, and (e) a circular cutoff. (b) A simulated combustion dataset rendered using a schlieren knife-edge cutoff to enhance the flow, (d) as a shadowgraph image and (f) using a complemented cir- cular cutoff. ", "caption_bbox": [440, 893, 775, 971]}, {"image_id": 6, "file_name": "195_06.png", "page": 4, "dpi": 300, "bbox": [163, 74, 318, 227], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: An illustration of a traversal through the octree. P1 and P2 are two rays traversing through the flow. P1 is in a homogeneous region of the data and in a cell of the octree texture that will report a level number of 1 allowing P1 to skip to the edge of that level. P2 , on the other hand, is at the lowest level of the acceleration structure and will only traverse to the next voxel. ", "caption_bbox": [73, 241, 408, 319]}, {"image_id": 7, "file_name": "195_07.png", "page": 5, "dpi": 300, "bbox": [441, 360, 774, 560], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Results of a coal fire with 5 iterations of progressive refine- ment per frame on a Geforce GTX 280 card at 512x512 resolution. ", "caption_bbox": [440, 591, 775, 617]}, {"image_id": 8, "file_name": "195_08.png", "page": 5, "dpi": 300, "bbox": [442, 76, 773, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Results of a combustion dataset of dimensions 480x720x100 seen in figure 6 rendered with 10 iterations of progres- sive refinement per frame using cone filtering on a Geforce GTX 280 card at 512x512 resolution. ", "caption_bbox": [440, 293, 775, 345]}, {"image_id": 9, "file_name": "195_09.png", "page": 7, "dpi": 300, "bbox": [472, 83, 744, 950], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Comparison of volume rendering (a) with a line of sight schlieren approximation (b) with our method (c). ", "caption_bbox": [440, 964, 775, 990]}, {"image_id": 10, "file_name": "195_10.png", "page": 8, "dpi": 300, "bbox": [444, 266, 772, 754], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Comparison of unfiltered film plane with 1, 10, and 100 samples per pixel (a, c ,e) and the corresponding images of the film plane filtered with a cone filter of maximum width 6 in (b, d, f). ", "caption_bbox": [440, 768, 775, 807]}, {"image_id": 11, "file_name": "195_11.png", "page": 8, "dpi": 300, "bbox": [106, 225, 378, 794], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Comparison of the line of sight technique [18] (a,b, repro- duced with permission) and our method using a shadowgraph (c) a knife-edge cutoff (d), and a color filter (e). ", "caption_bbox": [73, 808, 408, 847]}], "196": [{"image_id": 0, "file_name": "196_00.png", "page": 4, "dpi": 300, "bbox": [445, 73, 771, 182], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Patterns formed in the double gyre flow with a sinusoidal reaction source. From left to right: t = 0, t = 38dt, t = 128dt. ", "caption_bbox": [440, 197, 775, 222]}, {"image_id": 1, "file_name": "196_01.png", "page": 5, "dpi": 300, "bbox": [100, 284, 384, 424], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Dense patterns formed in a time periodic flow with reaction without decay (left), and with \u03bb = 1 (right). ", "caption_bbox": [73, 455, 408, 480]}, {"image_id": 2, "file_name": "196_02.png", "page": 5, "dpi": 300, "bbox": [100, 74, 384, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Spot patterns formed in the rotational flow for two different frequencies and decay rates. ", "caption_bbox": [73, 244, 408, 269]}, {"image_id": 3, "file_name": "196_03.png", "page": 6, "dpi": 300, "bbox": [73, 73, 408, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Double gyre flow: Reaction with FTLE (a), FSM (b), strad- dling (c) and the functional source (d). Left:t = 100dt (for the steady case), right:t = 300dt ", "caption_bbox": [73, 309, 408, 348]}, {"image_id": 4, "file_name": "196_04.png", "page": 7, "dpi": 300, "bbox": [93, 255, 390, 869], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Turbulent flow: Reaction with straddling (1st row) and functional sources with horizontal velocity (2nd row), distance (3rd row), and regularized tangent function (4th row). From left to right: t = 50dt, t = 350dt. ", "caption_bbox": [73, 892, 408, 943]}, {"image_id": 5, "file_name": "196_05.png", "page": 7, "dpi": 300, "bbox": [456, 491, 760, 641], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Turbulent flow: Reaction with functional sources with horizontal velocity (left) and distance (right). Simulation started at t = 200dt and run for 150 steps. ", "caption_bbox": [440, 672, 775, 711]}, {"image_id": 6, "file_name": "196_06.png", "page": 7, "dpi": 300, "bbox": [74, 73, 776, 202], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Karman vortex streets: Reaction with two different functional sources", "caption_bbox": [231, 217, 617, 229]}, {"image_id": 7, "file_name": "196_07.png", "page": 7, "dpi": 300, "bbox": [456, 255, 760, 405], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Turbulent flow: Reaction with straddling at t = 350dt. Left: start time= 300dt, running time= 50 steps. Right: start time= 200dt, running time= 150 steps. ", "caption_bbox": [440, 436, 775, 475]}, {"image_id": 8, "file_name": "196_08.png", "page": 8, "dpi": 300, "bbox": [88, 640, 396, 795], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Flow scales: Reaction with a sinusoidal source in a flow with two different scales of fluctuations on the left and right halves of the grid. From left to right: t = 25dt, t = 120dt. ", "caption_bbox": [73, 810, 408, 849]}, {"image_id": 9, "file_name": "196_09.png", "page": 8, "dpi": 300, "bbox": [88, 74, 396, 547], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Turbulent flow: Reaction with a sinusoidal source and with decay: \u03bb = 1.5 (top), \u03bb = 0.5 (middle). Bottom: Reaction with a sinusoidal source (with a power based on velocity magnitude) and with decay. From left to right: t = 50dt, t = 350dt. ", "caption_bbox": [73, 570, 408, 622]}], "197": [{"image_id": 0, "file_name": "197_00.png", "page": 2, "dpi": 300, "bbox": [441, 75, 775, 397], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The sketch-based vector field visualization process. The user can use sketching to find field lines (left branch) or field-line clusters (right branch) of interest. ", "caption_bbox": [440, 416, 775, 455]}, {"image_id": 1, "file_name": "197_01.png", "page": 3, "dpi": 300, "bbox": [506, 74, 711, 185], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Examples of the sign on curvature. In (a), the first four points (from left to right) have the positive sign while the rest three points have the negative sign. In (b), all points have the positive sign. ", "caption_bbox": [440, 204, 775, 243]}, {"image_id": 2, "file_name": "197_02.png", "page": 4, "dpi": 300, "bbox": [139, 74, 344, 179], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Sampling points on two different curves yields the same feature vector since in (a), the corner is not sampled. Taking into ac- count the accumulated curvature can capture the difference between the two curves. ", "caption_bbox": [73, 198, 408, 250]}, {"image_id": 3, "file_name": "197_03.png", "page": 5, "dpi": 300, "bbox": [84, 94, 763, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a)-(c) show streamlines traced in the hurricane, plume, and computer room data sets, respectively. The velocity magnitudes are mapped to the streamline colors. For the hurricane and computer room data sets, the scalar fields are also volume rendered to provide the context information. ", "caption_bbox": [73, 285, 775, 324]}, {"image_id": 4, "file_name": "197_04.png", "page": 6, "dpi": 300, "bbox": [89, 73, 394, 626], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) The user sketches an ellipse pattern and the matching streamlines are displayed. (b) The user sketches a circular pattern and the most similar five templates are displayed from top to bottom. The user then picks the one on the top and the selected cluster is displayed. In the figure, the velocity magnitudes are mapped to the streamline colors. ", "caption_bbox": [73, 642, 408, 720]}, {"image_id": 5, "file_name": "197_05.png", "page": 6, "dpi": 300, "bbox": [456, 73, 761, 563], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) The user sketches a spiral pattern and the matching streamlines are displayed. (b) The user sketches a long-tail pattern and the most similar five templates are displayed from top to bottom. The user then picks the one on the top and the selected cluster is displayed. In the figure, the velocity magnitudes are mapped to the streamline colors. ", "caption_bbox": [440, 579, 775, 657]}, {"image_id": 6, "file_name": "197_06.png", "page": 7, "dpi": 300, "bbox": [82, 350, 790, 523], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Examples showing the sketching of similar streamlines with different tolerance. More similar streamlines are orange and less similar ones are blue. The corresponding patterns sketched for (a)-(c) are the circular, curly, and spiral patterns, respectively. ", "caption_bbox": [73, 540, 775, 566]}, {"image_id": 7, "file_name": "197_07.png", "page": 7, "dpi": 300, "bbox": [82, 97, 790, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Examples showing the sketching of similar streamlines with different scales. large-scale streamlines are orange and small-scale ones are blue. The corresponding patterns sketched for (a)-(c) are the circular, curly, and long-tail patterns, respectively. ", "caption_bbox": [73, 286, 775, 312]}, {"image_id": 8, "file_name": "197_08.png", "page": 8, "dpi": 300, "bbox": [82, 98, 778, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: (a)-(c) show the simultaneous display of multiple clusters derived from the sketch-based clustering. Each cluster is illustrated with a different color. A selective subset of streamlines is displayed for each cluster. Compared with the corresponding images in Figure 4, this visualization shows a much clearer picture of the flow patterns. ", "caption_bbox": [73, 286, 775, 325]}], "198": [{"image_id": 0, "file_name": "198_00.png", "page": 2, "dpi": 300, "bbox": [80, 76, 770, 436], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: System overview. The top center of the figure presents a significance trend chart viewer which shows a significance curve extracted from a collection of documents with different time stamps. The x-axis encodes the time and the y-axis encodes the significance of the word clouds. The green curve in the chart represents the measured significance of the word clouds at different time steps. Five word clouds ((a)-(e) in the figure) are created using our algorithm for five selected time points where high significance values are observed. ", "caption_bbox": [73, 451, 775, 504]}, {"image_id": 1, "file_name": "198_01.png", "page": 5, "dpi": 300, "bbox": [100, 76, 751, 210], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Pipeline for creating a semantic and stable word cloud layout: (a) Extracting an initial set of words from all the documents with different time stamps; (b) Placing the extracted words on the 2D plane using multidimensional scaling; (c) Filtering out unrelated words for a specified time slot; (d) Triangulating the remaining words; (d) Optimizing the layout by a force-directed algorithm. ", "caption_bbox": [73, 225, 775, 264]}, {"image_id": 2, "file_name": "198_02.png", "page": 5, "dpi": 300, "bbox": [441, 289, 775, 405], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) Two separated words exert a spring force on the con- nected edge. (b) Two overlapped words exert a repulsive force on the connected edge. ", "caption_bbox": [440, 420, 776, 459]}, {"image_id": 3, "file_name": "198_03.png", "page": 6, "dpi": 300, "bbox": [85, 74, 396, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) The attractive force between edge e (drawn in red) and word a (drawn in red) is zero if the mesh is planar. (b) The attractive force becomes effective if a is flipped to the other side of e. ", "caption_bbox": [73, 213, 409, 253]}, {"image_id": 4, "file_name": "198_04.png", "page": 6, "dpi": 300, "bbox": [444, 76, 772, 473], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Word cloud layouts and their corresponding meshes gen- erated in the process of our adapted force-directed algorithm. ", "caption_bbox": [440, 488, 775, 514]}, {"image_id": 5, "file_name": "198_05.png", "page": 7, "dpi": 300, "bbox": [78, 537, 399, 924], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Two word cloud layouts (a) and (b) generated by the impor- tance criterion and the co-occurrence criterion, respectively. ", "caption_bbox": [73, 942, 409, 968]}], "199": [{"image_id": 0, "file_name": "199_00.png", "page": 1, "dpi": 300, "bbox": [90, 144, 765, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) Because intuitive spatial scatter plot visualizations are limited to, at most, three dimensions, we cannot look into a high dimensional data set by simply visualizing its point cloud or, e.g., its density distribution. (b) However, the topology of a point cloud, described, e.g., by means of the contour tree, can be calculated in arbitrary dimension. (c) Instead of the data itself, we visualize its topological landscape [36], having the same topology as the given input data set. ", "caption_bbox": [73, 412, 775, 464]}, {"image_id": 1, "file_name": "199_01.png", "page": 3, "dpi": 300, "bbox": [450, 75, 767, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) A contour tree. (b) Its branch decomposition. (c) The topological landscape having the same contour tree. Colors have been used to mark which parts of the landscape correspond to which contour tree branches. ", "caption_bbox": [440, 241, 775, 293]}, {"image_id": 2, "file_name": "199_02.png", "page": 4, "dpi": 300, "bbox": [101, 235, 378, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) Without an additional low density sample in between two distant points, two dense regions would be identified as one by the join tree computation. The missing saddles are added by sampling the density function not only on the original points but also on the mid-points of edges. (b) Because the triangles xyz and xcz share the angle \u03b1 , the distance of the mid-point c to point z can be computed directly from the distances between x, y, z using the law of cosines. ", "caption_bbox": [73, 395, 408, 486]}, {"image_id": 3, "file_name": "199_03.png", "page": 5, "dpi": 300, "bbox": [87, 78, 401, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) For a given height value, a sequential or random choice of a triangle using uniform probabilities results in accumulation arti- facts. Therefore, we use probabilities proportional to the amount of intersection of each triangle with the contour of that height. (b) Points in the span space represent min-max height values of triangles. Only the points in R = [gmin, \u03b5 ] \u00d7 [\u03b5 , gmax] are related to triangles that share a given height value \u03b5 . ", "caption_bbox": [73, 286, 408, 373]}, {"image_id": 4, "file_name": "199_04.png", "page": 6, "dpi": 300, "bbox": [82, 74, 769, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) The synthetic example data set (the colored borders are just for better visual identification) consisting of some colored clus- ters afflicted with noise. (b) The Gabriel graph with the color-coded density distribution (dark=dense) and the critical points of the join-tree (red=maximum, green=saddle, blue=minimum). (c) The resulting topological landscape, after pruning and rebalancing using a threshold of 10% of the maximum density. ", "caption_bbox": [73, 290, 775, 342]}, {"image_id": 5, "file_name": "199_05.png", "page": 6, "dpi": 300, "bbox": [447, 368, 769, 684], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a)-(b) The projection of the data points (without noise) onto the first two principal components coarsely reveals the cluster- ing structure of the data set. (c) The Topological Landscape clearly shows 24 separated hills which correspond to the dense regions. The extremely sparse noise comprises a ring at the height of low density, thus indicating that all noise points are each on their own. ", "caption_bbox": [440, 703, 775, 781]}, {"image_id": 6, "file_name": "199_06.png", "page": 7, "dpi": 300, "bbox": [76, 79, 774, 190], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The user reads the landscape in order to determine the correct filter radius: (a) Starting with an obviously too big filter radius, we see a single hill, harboring rings of different height and color; (b) Reducing the filter radius, the first hills start to occur, representing the local maxima in the density distribution; (c) A further reduction of the filter radius leads to more hills, while some points from different clusters are still mixed on some hills and other points are still considered as being noise; (d) Finally, all the data points are separated on their corresponding hills; a further reduction would result in new local maxima inside the clusters, i.e. additional, smaller hills harboring a few points which could be pruned from the branch decomposition due to low persistence. ", "caption_bbox": [73, 209, 775, 287]}], "200": [{"image_id": 0, "file_name": "200_00.png", "page": 2, "dpi": 300, "bbox": [440, 588, 772, 819], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1. S-shaped curves in literature with reflectance measure.", "caption_bbox": [438, 818, 761, 832]}, {"image_id": 1, "file_name": "200_01.png", "page": 3, "dpi": 300, "bbox": [441, 638, 775, 705], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2. Model of lightness discrimination in visual analytic tasks: li,  lj are two different luminance levels; function G models the  lightness perception; function H models the lightness discrimination ", "caption_bbox": [438, 704, 778, 746]}, {"image_id": 2, "file_name": "200_02.png", "page": 4, "dpi": 300, "bbox": [470, 208, 740, 422], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3. Empirical mapping curve between the lightness control", "caption_bbox": [438, 421, 775, 435]}, {"image_id": 3, "file_name": "200_03.png", "page": 4, "dpi": 300, "bbox": [428, 736, 799, 985], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. Examples of the plots used in different tasks.", "caption_bbox": [438, 984, 710, 998]}, {"image_id": 4, "file_name": "200_04.png", "page": 5, "dpi": 300, "bbox": [446, 708, 770, 874], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5. Curve fitting with 3D MDS results: the distance between li", "caption_bbox": [438, 873, 775, 888]}, {"image_id": 5, "file_name": "200_05.png", "page": 6, "dpi": 300, "bbox": [439, 412, 773, 536], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6. Plots of relationship between the perceived lightness", "caption_bbox": [438, 535, 775, 549]}, {"image_id": 6, "file_name": "200_06.png", "page": 7, "dpi": 300, "bbox": [439, 779, 772, 887], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9. Estimates of shared b and d in different tasks with their", "caption_bbox": [438, 886, 775, 900]}, {"image_id": 7, "file_name": "200_07.png", "page": 7, "dpi": 300, "bbox": [465, 108, 750, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7. The plot of function G in different proposed forms.", "caption_bbox": [438, 308, 735, 322]}, {"image_id": 8, "file_name": "200_08.png", "page": 7, "dpi": 300, "bbox": [439, 331, 777, 582], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8. Sequences of outlined circles and unframed spots", "caption_bbox": [438, 581, 775, 595]}], "201": [{"image_id": 0, "file_name": "201_00.png", "page": 3, "dpi": 300, "bbox": [439, 74, 777, 422], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Attractive and (b)repulsive operators. Point (xc ,yc ), (xL ,yL ) and (xR ,yR ), together with slopec , slopeL and slopeR , deter- mine the curve Cm,n,n+1 corresponding to line segment lm,(n,n+1) . ", "caption_bbox": [440, 421, 775, 464]}, {"image_id": 1, "file_name": "201_01.png", "page": 3, "dpi": 300, "bbox": [72, 74, 411, 544], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview of interactive local operation in parallel coordi- nates. (a) Flowchart of visual exploration with local operators in par- allel coordinates; (b) repulsive and attractive operators in the parallel coordinate plot region together with the corresponding cluster graph region. ", "caption_bbox": [73, 543, 408, 608]}, {"image_id": 2, "file_name": "201_02.png", "page": 4, "dpi": 300, "bbox": [454, 102, 763, 905], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Operator interaction. (a) A segment of parallel coordinate plot under exploration; (b)-(e) user interaction with attractive opera- tors; (f)-(i) user interaction with repulsive operators. [FS = 1.0, \u03b2 = 1.2] ", "caption_bbox": [440, 932, 775, 972]}, {"image_id": 3, "file_name": "201_03.png", "page": 5, "dpi": 300, "bbox": [73, 74, 411, 200], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Hierarchical Clustering. The left part of the interface is the parallel coordinate plot. The right part of the interface is the cluster graph showing relationship between clusters defined by the user. ", "caption_bbox": [73, 228, 408, 267]}, {"image_id": 4, "file_name": "201_04.png", "page": 5, "dpi": 300, "bbox": [439, 74, 778, 405], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) Before optimization; (b) after 4 iterations of optimization with \u03b3 = 2.0. ", "caption_bbox": [440, 418, 775, 445]}, {"image_id": 5, "file_name": "201_05.png", "page": 6, "dpi": 300, "bbox": [73, 279, 411, 622], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) Illustrative drawing style; (b) traditional non-illustrative drawing style. ", "caption_bbox": [73, 648, 408, 674]}, {"image_id": 6, "file_name": "201_06.png", "page": 6, "dpi": 300, "bbox": [439, 74, 777, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Collaborative visualization with a multi-touch display. Two users are exploring a high dimensional dataset with our interactive local operators and the accompanying cluster graph. ", "caption_bbox": [440, 284, 775, 323]}, {"image_id": 7, "file_name": "201_07.png", "page": 6, "dpi": 300, "bbox": [76, 74, 407, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Two neighboring parallel coordinate sessions with (a) dis- continuous and (b) continuous colors for subgroup color encoding. ", "caption_bbox": [73, 239, 408, 265]}, {"image_id": 8, "file_name": "201_08.png", "page": 7, "dpi": 300, "bbox": [73, 85, 412, 896], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Visual exploration of a synthesized dataset with 7736 five- dimensional items. All 4 clusters are revealed by our methods. (a) Direct visualization; (b)-(e) clusters are detected one by one; (f) clus- tering by hierarchical parallel coordinates; (g) visual clustering; (g) is courtesy of Zhou et al. [25]. ", "caption_bbox": [73, 922, 408, 987]}, {"image_id": 9, "file_name": "201_09.png", "page": 7, "dpi": 300, "bbox": [444, 80, 775, 419], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Performance of user defined clustering operations. Syn stands for synthesized data set, and RS stands for the remote sens- ing data set. ", "caption_bbox": [440, 655, 775, 694]}], "202": [{"image_id": 0, "file_name": "202_00.png", "page": 2, "dpi": 300, "bbox": [439, 74, 777, 232], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of the system.", "caption_bbox": [522, 252, 689, 265]}, {"image_id": 1, "file_name": "202_01.png", "page": 2, "dpi": 300, "bbox": [81, 74, 419, 190], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Existing visualization techniques to reveal periodical pat- tern in time series. (a): 2D spiral layout, which introduces distortion and inconsistent orientation of the patterns. (b): 3D spiral layout, which causes occlusion among the patterns. (c): Linear wrapping, which can cut through the patterns at the boundaries of the display window. ", "caption_bbox": [73, 202, 408, 280]}, {"image_id": 2, "file_name": "202_02.png", "page": 3, "dpi": 300, "bbox": [78, 75, 400, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Movement trace. By collecting the pixel intensity along the red line on the video frame over time, an image with a apparent periodic pattern over time can be seen. ", "caption_bbox": [73, 279, 408, 318]}, {"image_id": 3, "file_name": "202_03.png", "page": 3, "dpi": 300, "bbox": [73, 333, 411, 639], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Sampling of the periodical movement in a video. (a): Sam- pling along a line with apparent periodical change. (b): Sampling along the same line in (a) with opposite direction. (c): Sampling along a line with less periodical change. ", "caption_bbox": [73, 651, 408, 703]}, {"image_id": 4, "file_name": "202_04.png", "page": 4, "dpi": 300, "bbox": [81, 74, 401, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Periodic cycle segmentation. (a): Segmentation of a signal by using one threshold. The exhale and inhale phases are colored in red and green, respectively. (b): Segmentation of a noisy signal by using one threshold, which can create multiple short and false phases. (c) and (d): Segmentation of a noisy signal by using two thresholds. In the first step, as shown in (c), the time steps are larger than the threshold e or smaller than the threshold i are marked as red and green, respectively. In the second step, as shown in (c), each phase is extended. ", "caption_bbox": [73, 326, 408, 444]}, {"image_id": 5, "file_name": "202_05.png", "page": 4, "dpi": 300, "bbox": [440, 74, 771, 201], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Layout of CycleStacks. Given a signal with three periodic cycles as an example, three cycles bricks are stacked. The left side of the exhale phase bricks of all cycle bricks are aligned to the red vertical line. ", "caption_bbox": [440, 217, 775, 269]}, {"image_id": 6, "file_name": "202_06.png", "page": 5, "dpi": 300, "bbox": [447, 74, 769, 435], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Test videos. (a): Video A, which is a subregion contained in ultrasound video in (c). (b): Video B, which is a subregion contained in ultrasound video in (d). ", "caption_bbox": [440, 448, 775, 487]}, {"image_id": 7, "file_name": "202_07.png", "page": 5, "dpi": 300, "bbox": [73, 74, 408, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Texture mapping from a movement trace image to Cy- cleStacks. A periodic cycle in time steps t0 . . .t1 is linearly mapped from the texture coordinate to a cycle brick with w \u00d7 h pixels where the screen coordinate of the lower-left corner is (l, b). ", "caption_bbox": [73, 249, 408, 301]}, {"image_id": 8, "file_name": "202_08.png", "page": 6, "dpi": 300, "bbox": [91, 73, 759, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: User Study Result for Opposite Events", "caption_bbox": [491, 488, 724, 501]}, {"image_id": 9, "file_name": "202_09.png", "page": 6, "dpi": 300, "bbox": [106, 337, 378, 757], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Relevant portions of the CycleStack plots for Video A. (a): 3 cycle bricks with synchronous movement traces and respiration sig- nals. (b): the cycle bricks from time step 1971 to 2776, displaying synchronous cycles (end at time steps 2304 and 2409) and opposite cycles (from time step 2430 to 2776). ", "caption_bbox": [73, 770, 408, 835]}, {"image_id": 10, "file_name": "202_10.png", "page": 7, "dpi": 300, "bbox": [441, 75, 776, 124], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: A failure case of our two-threshold cycle segmentation algorithm. The thresholds e and i are plotted as the two blue dashed lines. This cycle brick actually contains two periodic cycles, while the first one is not segmented since the signal value during first cycle does not exceed the threshold e. ", "caption_bbox": [440, 141, 775, 206]}], "203": [{"image_id": 0, "file_name": "203_00.png", "page": 4, "dpi": 300, "bbox": [143, 76, 708, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Comparative visualization of the distribution of the halos for the simulation results at z = 0. Each halo is represented by a dot. It is immediately obvious from these images that Enzo has fewer halos throughout the simulation volume and that therefore our Hypothesis 1 is false. The black circles mark the position of Halo 3. The formation history of Halo 3 will be discussed in detail in our second case study. ", "caption_bbox": [73, 311, 775, 350]}, {"image_id": 1, "file_name": "203_01.png", "page": 5, "dpi": 300, "bbox": [179, 74, 669, 466], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: First three columns: comparative qualitative visualization of the distribution of the halos in different mass ranges (light to extra-heavy from top to bottom) at a single time step z = 0. Throughout the paper we present results from GADGET-2 in red, from MC2 in green, and from Enzo in blue. A light halo contains 10-40 particles, a medium halo contains 41-300 particles, a heavy halo contains 301-2500 and an extra-heavy halo contains more than 2500 particles. Fourth column: comparative quantitative visualization of the number of halos in different mass ranges. In addition, information about the time evolution of the number of halos is shown. While the qualitative approach contains spatial information, the quantitative plots have extra temporal information. The combination of both allow the assessment of the validity of hypothesis 2a and 2b. ", "caption_bbox": [73, 484, 775, 562]}, {"image_id": 2, "file_name": "203_02.png", "page": 6, "dpi": 300, "bbox": [153, 73, 697, 865], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparative qualitative visualization: Four different time snapshots of the formation of Halo 3 at z = 5, 3, 2 and z = 1. The spheres represent halos in four different mass bins (light, medium, heavy, extra-heavy), the size of the spheres is scaled with respect to the mass bin the halo belongs to. The intensity of color contains information about the density environment in which the halos live: three intensity levels are used to reflect three density levels: low, medium, and high, and the darker the color, the higher the density. Particles which do not belong to any halo are shown as yellow dots. At the final time step, not shown here, all particles and halos will belong to the final Halo 3. As in the previous case study, red is reserved for GADGET-2, green for MC2 , and blue for Enzo. The region we are investigating is approximately 5 Mpc wide. ", "caption_bbox": [73, 879, 775, 957]}, {"image_id": 3, "file_name": "203_03.png", "page": 7, "dpi": 300, "bbox": [457, 76, 759, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparative quantitative visualization: Comparison of dif- ferent halo sizes (top to bottom: light to extra-heavy halos) and of halo counts in different density regions (left to right: low to high den- sity region). Each panel shows the time evolution of the halo count in a specific mass bin and a specific density region. As in the previous case study, Enzo loses light halos. This time we have the additional information, that most light halos are lost in lower density regions. At the final time step, only one extra-heavy halo will remain, which has absorbed all lighter halos from earlier times. This explains why the panels in the first three rows all end up at zero at z = 0 and the last panel in the bottom right corner ends up at one. ", "caption_bbox": [440, 396, 775, 540]}], "204": [{"image_id": 0, "file_name": "204_00.png", "page": 3, "dpi": 300, "bbox": [123, 73, 361, 344], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An overview of our pipeline. All preprocessing is performed in the horizon-extraction phase, followed by visualization and interac- tion for assembling correct horizons. The horizon extraction is further described in Figure 2 and Figure 4. ", "caption_bbox": [73, 358, 408, 410]}, {"image_id": 1, "file_name": "204_01.png", "page": 4, "dpi": 300, "bbox": [125, 74, 738, 296], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The process of growing from one specific seedpoint (yellow point). The green borders show the growing frontier and the red regions show the previous frontier of the blue triangulation. The triangulation is then subdivided. ", "caption_bbox": [73, 313, 775, 339]}, {"image_id": 2, "file_name": "204_02.png", "page": 4, "dpi": 300, "bbox": [506, 364, 711, 608], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The distance transform. One grown and subdivided sur- face mesh is shown in 3D at the top intersecting a slice of the seis- mic data. The colors represent surfaces at the lowest level in the pruned hierarchy. The bottom image shows a slice through the re- sulting distance transform with white representing distance zero and darker colors representing higher distances. ", "caption_bbox": [440, 622, 775, 700]}, {"image_id": 3, "file_name": "204_03.png", "page": 4, "dpi": 300, "bbox": [74, 583, 410, 722], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Increasing levels of a surface hierarchy made from one grown surface. The top-left image shows the initial one-triangle sur- faces. Each successive image shows the resulting merging after four merge levels in the binary hierarchy tree. One triangle is magnified in white at the top image and its successive higher level surfaces are shown delineated with alternating white and black borders. ", "caption_bbox": [73, 737, 408, 815]}, {"image_id": 4, "file_name": "204_04.png", "page": 6, "dpi": 300, "bbox": [459, 79, 757, 554], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Selecting a leaf-surface (a) and navigating stepwise up in the hierarchy (b-f) until an erroneous surface is shown (f). ", "caption_bbox": [440, 575, 775, 601]}, {"image_id": 5, "file_name": "204_05.png", "page": 7, "dpi": 300, "bbox": [109, 74, 740, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A comparison of gradient (left) and gradient-free shading (middle). In the right image, the two left images are interleaved and one can see how 3D and depth perception is improved and high frequency noise reduced in the gradient-free method. ", "caption_bbox": [73, 326, 775, 352]}, {"image_id": 6, "file_name": "204_06.png", "page": 8, "dpi": 300, "bbox": [119, 100, 739, 966], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The steps of interpreting two horizons, filling out holes (a-c). Creating a new horizon (d-e). Top horizon semitransparent in (f) and emissive in (g). Bottom horizon emissive in (h). Both horizons emissive in (i). Opaque volume with different roaming boxes in (j) and (k). ", "caption_bbox": [73, 1014, 775, 1040]}], "205": [{"image_id": 0, "file_name": "205_00.png", "page": 1, "dpi": 300, "bbox": [424, 86, 769, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) The blue marks indicate the locations of over 446 TSMIP stations that recorded the Chi-Chi earthquake; the red cross indicates the location of epicenter. It is so far the most thoroughly recorded earthquake ever. (b) Snapshots of acceleration wave-field map at UTC 17:47:50. Surface fitting with biharmonic operator in 2D is used to complete the unsampled areas on the map. ", "caption_bbox": [440, 482, 775, 560]}, {"image_id": 1, "file_name": "205_01.png", "page": 2, "dpi": 300, "bbox": [78, 572, 407, 831], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Three sample acceleration traces (East-West PGA of 439 gal, North-South PGA of 302 gal, and vertical PGA of 171 gal) from TSMIP TCU078 station, the closest to the epicenter (8 km), show larger acceleration amplitudes recorded during the Chi-Chi earth- quake mainshock. ", "caption_bbox": [73, 849, 408, 914]}, {"image_id": 2, "file_name": "205_02.png", "page": 4, "dpi": 300, "bbox": [74, 592, 404, 845], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Volume rendering of ground-motion wave-filed volume data of 446 stations. When first examined, the energetic area (with red- dish color tones) can be clearly identified, providing a good indication of the epicenter location. ", "caption_bbox": [73, 867, 408, 919]}, {"image_id": 3, "file_name": "205_03.png", "page": 4, "dpi": 300, "bbox": [444, 83, 773, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Orthographic views of volume rendering (front-view, top- view, and side-view). The temporal information is interpreted and presented spatially by treating time information as the third axis. The largest damage occurred at UTC 17:47:27.7 when the maximum ac- celeration was recorded. ", "caption_bbox": [440, 314, 775, 379]}, {"image_id": 4, "file_name": "205_04.png", "page": 5, "dpi": 300, "bbox": [479, 386, 761, 639], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The three-channel color scheme uses red, green, and blue to represent the vertical, north-south, and east-west channel respec- tively. The red represents that the voxel is dominated by the vertical component, i.e., the vertical acceleration is larger than the horizontal acceleration. The green and blue represent that the voxel is domi- nated by the north-south acceleration and the east-west acceleration respectively. Visualization of red dominant voxels shows a finding that vertical acceleration appears in the early stage of the earth- quake. As can be observed, the vertical ground acceleration can amplify the horizontal ground acceleration. ", "caption_bbox": [440, 657, 775, 788]}, {"image_id": 5, "file_name": "205_05.png", "page": 5, "dpi": 300, "bbox": [89, 74, 757, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Screen shots of intensity levels in volume rendering of the Chi-Chi data. (a) The blue, cyan, green, yellow, and red colors are used to represent category 3 to category 7 bubbles respectively. (b) and (c) The opacity of the bubbles is changed to show each individual intensity level. ", "caption_bbox": [73, 332, 775, 357]}, {"image_id": 6, "file_name": "205_06.png", "page": 6, "dpi": 300, "bbox": [111, 75, 394, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Low energy regions are faded out to highlight large energy regions in the second color scheme. This shows that the amplitude of the horizontal motions is dependent on the earthquake intensity. In large energy regions, the horizontal motions dominant. ", "caption_bbox": [73, 346, 408, 398]}, {"image_id": 7, "file_name": "205_07.png", "page": 6, "dpi": 300, "bbox": [443, 78, 773, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The visualization system has a slicing tool to go through layers and each layer of the volume data is a static ground-motion map. Two layers sliced at 17:47:45 and 17:48:15. ", "caption_bbox": [440, 322, 775, 361]}, {"image_id": 8, "file_name": "205_08.png", "page": 6, "dpi": 300, "bbox": [77, 422, 408, 646], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Volume rendering of the central regions of the volume data. Cut away feature allows user to focus on the regions of interests. ", "caption_bbox": [73, 664, 408, 689]}, {"image_id": 9, "file_name": "205_09.png", "page": 7, "dpi": 300, "bbox": [447, 390, 769, 624], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Volume rendering of the first half of the Chi-Chi earth- quake volume data. The red bubble-shape regions indicate the loca- tions and durations of major energy releases. ", "caption_bbox": [440, 642, 775, 681]}, {"image_id": 10, "file_name": "205_10.png", "page": 7, "dpi": 300, "bbox": [173, 89, 676, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Volume rendering is augmented with the PGA occurring times of 446 stations connected by a 3D minimum spanning tree. It provides insights into understanding how seismic waves propagate from epicenter. Another finding is that the distribution of these spheres is consistent with the trend of bubble formation. ", "caption_bbox": [73, 323, 775, 362]}], "206": [{"image_id": 0, "file_name": "206_00.png", "page": 1, "dpi": 300, "bbox": [92, 86, 758, 543], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Screenshot of Caleydo with open Bucket view, a parallel coordinates view, a heat map and some meta-information. The Bucket concept is an integral part of Caleydo and allows us to place views for pathway and gene expression analysis in a 2.5D setup. Relations between views are shown by means of visual links. ", "caption_bbox": [73, 557, 775, 596]}, {"image_id": 1, "file_name": "206_01.png", "page": 3, "dpi": 300, "bbox": [439, 176, 777, 385], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Hierarchical heat map showing 851 genes in three levels. Both experiments and genes have been clustered hierarchically, and dendrograms are shown in both dimensions. The desired level of granularity of groupings can be adjusted by dragging the cut-off line of the dendrogram. In the case of hierarchical clustering algorithms, the groupings are determined by the cut-off value\u2019s position whereas partitional clusterers assign them automatically. ", "caption_bbox": [440, 400, 775, 491]}, {"image_id": 2, "file_name": "206_02.png", "page": 4, "dpi": 300, "bbox": [439, 74, 777, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The Bucket when zoomed in, showing a 2D arrangement of focus and context views. ", "caption_bbox": [440, 276, 775, 301]}, {"image_id": 3, "file_name": "206_03.png", "page": 5, "dpi": 300, "bbox": [78, 73, 772, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Illustration of a gene-expression-centric analysis. (a) After filtering out inconspicuous genes and running a clustering algorithm, the pathologist finds a cluster in the heat map which has strongly diverging expression patterns for the different conditions. He checks for pathways containing the genes in the group, and in fact, several metabolic pathways contain four or more genes of the cluster. By clicking the pathways they are loaded into the Bucket for exploration (b). There he finds that the different pathways are heavily connected. Looking more closely at one pathway and its genes (c), he finds that the genes of the gene family CYP show the differential expression pattern. After checking PubMed and Entrez Gene with the integrated browser he learns that this family is a known catalyst for many reactions in the drug metabolism. ", "caption_bbox": [73, 281, 775, 359]}, {"image_id": 4, "file_name": "206_04.png", "page": 6, "dpi": 300, "bbox": [73, 73, 411, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The four different setups for the user study.", "caption_bbox": [111, 297, 370, 309]}, {"image_id": 5, "file_name": "206_05.png", "page": 7, "dpi": 300, "bbox": [73, 74, 778, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Questionnaire results comparing the four different tested conditions for eleven areas of interest, comparing the four different setups of the first two tasks (N=11). ", "caption_bbox": [73, 277, 775, 302]}], "207": [{"image_id": 0, "file_name": "207_00.png", "page": 1, "dpi": 300, "bbox": [440, 296, 798, 589], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: WikipediaViz visualizations revealing the history profile of a Wikipedia article. ", "caption_bbox": [440, 605, 775, 630]}, {"image_id": 1, "file_name": "207_01.png", "page": 4, "dpi": 300, "bbox": [165, 76, 688, 187], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Interactive visualization of authors\u2019 contribution sizes: treemap (a) and pie chart (b) & (c).", "caption_bbox": [182, 202, 666, 214]}, {"image_id": 2, "file_name": "207_02.png", "page": 5, "dpi": 300, "bbox": [161, 76, 690, 193], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Plot graph of contributions lengths across time.", "caption_bbox": [284, 210, 563, 222]}, {"image_id": 3, "file_name": "207_03.png", "page": 5, "dpi": 300, "bbox": [440, 247, 798, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Internal links meter (Underlinked, Fair, Overlinked).", "caption_bbox": [458, 355, 757, 367]}, {"image_id": 4, "file_name": "207_04.png", "page": 6, "dpi": 300, "bbox": [76, 73, 427, 320], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Examples of article profiles: stub (a), good start (b) and mature (c) & (d). ", "caption_bbox": [73, 337, 408, 362]}, {"image_id": 5, "file_name": "207_05.png", "page": 7, "dpi": 300, "bbox": [132, 77, 717, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) Precision of the answer and (b) Performance, Time by Technique and Quality.", "caption_bbox": [202, 341, 646, 353]}], "208": [{"image_id": 0, "file_name": "208_00.png", "page": 1, "dpi": 300, "bbox": [424, 86, 794, 432], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Our prototype interface. At left is an eye diagram which shows a signal wrapped around in time as many overlapping traces. At right is a parallel coordinates view of attributes of the traces. Along the top is a time-line of the entire signal. In the top right corner are two pseudo-spectra of the highlighted and selected traces. High- lighted and selected traces are shown in red and yellow, respec- tively, in all views. Immediately above the eye diagram, the label \u201cbits: ***11001\u201d indicates that the currently selected traces have the bit prefix 11001 in common. ", "caption_bbox": [440, 446, 775, 564]}, {"image_id": 1, "file_name": "208_01.png", "page": 2, "dpi": 300, "bbox": [82, 73, 402, 568], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Screenshots from the GUI for a commercial oscilloscope. The oscilloscope\u2019s GUI is operated with a mouse. Top: an eye di- agram with a rhombus-shaped \u201cmask\u201d defined by the user. Traces that intersect the rhombus are classified as anomalies, in this case because they transition too late or too early. Bottom: the eye diagram is unfolded, and the user may jump forward or backward with buttons in the lower right to view each of the hundreds of anomalies within its local temporal context. ", "caption_bbox": [73, 583, 408, 688]}, {"image_id": 2, "file_name": "208_02.png", "page": 4, "dpi": 300, "bbox": [73, 238, 777, 807], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Steps in opening a drawer, sub-drawer, and sub-sub-drawer, to drill down into the data.", "caption_bbox": [187, 822, 660, 835]}, {"image_id": 3, "file_name": "208_03.png", "page": 5, "dpi": 300, "bbox": [73, 74, 427, 690], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A: the user selects a few traces, and enters drawer mode. The arrow-shaped cursor indicates the user may begin opening the drawer. B-D: the user opens the drawer by dragging down and to the left. As the spacing between traces increases, the view automat- ically zooms out. E-F: if the user drags out at a nearly horizontal or vertical angle, the drawer snaps to be axis-aligned, to align traces and facilitate comparison. In these cases, the user has also opened the drawer fully, with traces now tiling the space available and no further dragging open is allowed. G-H: same as E-F, except now non-uniform automatic zooming is performed. Traces are scaled in- dependently in x and y to make full use of the space available as the drawer is opened. ", "caption_bbox": [73, 704, 408, 861]}, {"image_id": 4, "file_name": "208_04.png", "page": 5, "dpi": 300, "bbox": [439, 74, 794, 409], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Upper left: the radial menu available prior to opening a drawer (or sub-drawer). The user may select circle or line tools to se- lect traces, clear the selection, enter temporal brush (T-brush) mode, or enter drawer (open) mode. Upper right: the radial menu available when a (sub-)drawer is opened. Dragging toward an attribute causes traces in the drawer to be sorted by that attribute. Lower left: drag- ging radially past an attribute opens a submenu of groupings for that attribute, within which the user drags tangentially. Lower right: here, the user has selected 4 groupings by overshoot (over). ", "caption_bbox": [440, 423, 775, 541]}, {"image_id": 5, "file_name": "208_05.png", "page": 6, "dpi": 300, "bbox": [439, 73, 794, 509], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Upper left: brushing with the circle tool reveals interesting patterns within the eye diagram, but it is difficult to perceive the evo- lution over time without switching attention frequently between the time-line (not shown) and the eye diagram while brushing. Upper right: selecting all traces and opening a drawer, the user can scan along the drawer and see the profile for any snapshot in time, making the evolution over time more evident. Bottom: the drawer snapped to a horizontal angle. It becomes clear that the signal evolves from a sawtooth to a square shape (from left to right, respectively). ", "caption_bbox": [440, 524, 775, 642]}, {"image_id": 6, "file_name": "208_06.png", "page": 6, "dpi": 300, "bbox": [73, 73, 427, 673], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A: brushing with the circle tool, the user notices an anomaly in the lower right corner: some traces appear to rise and fall rapidly without transitioning to 1. B: one way to select only the anomalous traces is to draw three lines and select the intersection of traces crossing all lines. Above the eye diagram, we see the bit prefix 100 is common to all the selected traces. C-H: an alternative approach to drill-down to the anomalous traces. C: all traces are selected and opened in a drawer. D: the user scans along the drawer to see the profile of individual traces. E: the profile extended in time. F: the user groups by 3-bit prefixes (resulting in 8 groups). G: traces with the anomaly on the right clock edge are visible only in the group 100, which contains only anomalous traces. H: the group\u2019s profile extended in time. ", "caption_bbox": [73, 688, 408, 858]}, {"image_id": 7, "file_name": "208_07.png", "page": 7, "dpi": 300, "bbox": [73, 248, 427, 463], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The user draws a few lines (in orange) through anomalies to select the union of traces crossing the lines. The time-line shows tick marks corresponding to the selected traces. These tick marks appear to be periodic (except for a few gaps); the periodicity is con- firmed by the single yellow spike appearing in the pseudo-spectrum in the upper-right corner. ", "caption_bbox": [73, 477, 408, 555]}, {"image_id": 8, "file_name": "208_08.png", "page": 7, "dpi": 300, "bbox": [439, 73, 794, 243], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Left: the user has selected the temporal brush mode. In this mode, yellow and red no longer indicate highlighting or selection. The trace closest to the cursor is shown in white, whose continuation into the past is shown in red, and in the future is shown in yellow. Moving the cursor around updates the display of the trace and its continuation Right: The user may also click down and drag to the right or left to increase or decrease, respectively, how far into the past and future they \u201csee\u201d. In this case, the user drags right, revealing longer continuations in time. ", "caption_bbox": [440, 258, 775, 376]}], "209": [{"image_id": 0, "file_name": "209_00.png", "page": 1, "dpi": 300, "bbox": [424, 86, 777, 375], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The stack zooming technique for line graphs. The analyst has focused on a period of radical changes in the main timeline (top). ", "caption_bbox": [440, 389, 775, 414]}, {"image_id": 1, "file_name": "209_01.png", "page": 2, "dpi": 300, "bbox": [73, 74, 777, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Stack zooming in a stock market dataset using TraXplorer. The horizon graph segments are arranged in a stack hierarchy that was built during visual exploration. The exploration and presentation interface of the tool is also visible on the right side of the image. ", "caption_bbox": [73, 386, 775, 411]}, {"image_id": 2, "file_name": "209_02.png", "page": 3, "dpi": 300, "bbox": [79, 74, 771, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Stack zooming in the Hongkong stock market index dataset. Transitions between views are animated, and the space-filling layout algorithm ensures that the whole space is used optimally. ", "caption_bbox": [73, 270, 775, 295]}, {"image_id": 3, "file_name": "209_03.png", "page": 3, "dpi": 300, "bbox": [73, 665, 411, 721], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Two time-series datasets visualized as line graphs.", "caption_bbox": [92, 736, 389, 748]}, {"image_id": 4, "file_name": "209_04.png", "page": 4, "dpi": 300, "bbox": [73, 160, 411, 320], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: General layout mechanism for stack zooming. Color-coded zoom areas and corresponding colored frames show parent-child re- lationships, and visual arrows make the relations explicit. ", "caption_bbox": [73, 334, 408, 373]}, {"image_id": 5, "file_name": "209_05.png", "page": 5, "dpi": 300, "bbox": [106, 316, 378, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Communication-minded workflow for TraXplorer.", "caption_bbox": [99, 408, 383, 420]}, {"image_id": 6, "file_name": "209_06.png", "page": 5, "dpi": 300, "bbox": [73, 80, 776, 224], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Layout and temporal view of merge operations for strips during temporal overlap. (a) Two strips, A and B, at time positions T 1 and T 2, respectively, and both of interval width W are approaching. (b) Temporal overlap between A and B, causing the layouts to merge into a single strip. To maintain the same combined layout size on the visual space, all temporal overlap is added to the beginning of the combined interval. (c) B has now passed A and there is no longer a temporal overlap, so the strips are separate and with correct temporal order in layout space. ", "caption_bbox": [73, 239, 775, 291]}, {"image_id": 7, "file_name": "209_07.png", "page": 6, "dpi": 300, "bbox": [439, 348, 778, 567], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The 1987 and 1997 crashes (UK pink, Hong Kong blue).", "caption_bbox": [445, 583, 769, 595]}, {"image_id": 8, "file_name": "209_08.png", "page": 6, "dpi": 300, "bbox": [439, 73, 778, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: UK (FTSE100, pink) and Hong Kong (HNKNGI, blue/purple) values for the period October 1987 to December 1997. ", "caption_bbox": [440, 307, 775, 332]}, {"image_id": 9, "file_name": "209_09.png", "page": 7, "dpi": 300, "bbox": [73, 335, 411, 556], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Buildup and aftermath of the 1997 Asian crash.", "caption_bbox": [97, 571, 384, 583]}, {"image_id": 10, "file_name": "209_10.png", "page": 7, "dpi": 300, "bbox": [439, 73, 778, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Stack zooming in vertical layout for a multi-scale document (mockup screenshot, not implemented in this paper). ", "caption_bbox": [440, 373, 775, 398]}, {"image_id": 11, "file_name": "209_11.png", "page": 7, "dpi": 300, "bbox": [73, 73, 411, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Buildup and aftermath of the Black Monday crash.", "caption_bbox": [91, 308, 391, 320]}], "21": [{"image_id": 0, "file_name": "21_00.png", "page": 2, "dpi": 300, "bbox": [154, 828, 346, 1022], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1. Simple Query Specification", "caption_bbox": [129, 1042, 353, 1056]}, {"image_id": 1, "file_name": "21_01.png", "page": 3, "dpi": 300, "bbox": [72, 84, 409, 219], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2. Demonstration of relationship coding", "caption_bbox": [99, 231, 382, 245]}, {"image_id": 2, "file_name": "21_02.png", "page": 4, "dpi": 300, "bbox": [81, 494, 407, 686], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3. Neighbourhood Zoning of Icons", "caption_bbox": [115, 707, 366, 721]}, {"image_id": 3, "file_name": "21_03.png", "page": 4, "dpi": 300, "bbox": [425, 389, 717, 651], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. The formation of collection sets", "caption_bbox": [460, 697, 708, 711]}, {"image_id": 4, "file_name": "21_04.png", "page": 5, "dpi": 300, "bbox": [78, 78, 413, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5. The three interaction views", "caption_bbox": [129, 353, 353, 367]}, {"image_id": 5, "file_name": "21_05.png", "page": 5, "dpi": 300, "bbox": [430, 258, 762, 516], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6. Transitions through the Icon View             abstraction layers ", "caption_bbox": [451, 529, 717, 559]}, {"image_id": 6, "file_name": "21_06.png", "page": 6, "dpi": 300, "bbox": [80, 591, 415, 875], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8. Example Transformation of the Ontology               Model of an Aircraft ", "caption_bbox": [86, 892, 394, 922]}, {"image_id": 7, "file_name": "21_07.png", "page": 6, "dpi": 300, "bbox": [78, 100, 411, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7. Aircraft Ontology with Identified                 Categories ", "caption_bbox": [111, 347, 371, 377]}, {"image_id": 8, "file_name": "21_08.png", "page": 7, "dpi": 300, "bbox": [412, 348, 771, 644], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9. The Bubbleworld GUI", "caption_bbox": [496, 651, 672, 664]}, {"image_id": 9, "file_name": "21_09.png", "page": 8, "dpi": 300, "bbox": [428, 235, 743, 473], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11. Comparisons of Average Times by Query Type", "caption_bbox": [427, 489, 741, 502]}, {"image_id": 10, "file_name": "21_10.png", "page": 8, "dpi": 300, "bbox": [86, 670, 398, 916], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10. Comparison of Average Times by Question", "caption_bbox": [94, 936, 387, 949]}, {"image_id": 11, "file_name": "21_11.png", "page": 9, "dpi": 300, "bbox": [426, 155, 738, 382], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13. Comparison of Accuracy by Question Type", "caption_bbox": [437, 389, 730, 402]}, {"image_id": 12, "file_name": "21_12.png", "page": 9, "dpi": 300, "bbox": [86, 734, 398, 978], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12. Comparison of Accuracy by Question Number", "caption_bbox": [85, 993, 396, 1006]}], "210": [{"image_id": 0, "file_name": "210_00.png", "page": 2, "dpi": 300, "bbox": [80, 75, 770, 416], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Modeling the (density, density gradient magnitude) 2D histogram with the GMM for the Feet dataset. (a) The automatically generated Gaussian transfer functions, the corresponding volume rendering, and volume renderings associated with each mixture component. (b) The result obtained by scaling the red and plum Gaussian transfer functions and adjusting their maximum opacities, in which the relationship between the toes and ankles is clearly shown. ", "caption_bbox": [73, 430, 775, 469]}, {"image_id": 1, "file_name": "210_01.png", "page": 3, "dpi": 300, "bbox": [458, 303, 785, 631], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Using the greedy EM algorithm to classify the Engine data with different number of mixture components: (a) 3; (b) 4. In (b), the main body and wheel parts are classified. ", "caption_bbox": [440, 642, 775, 681]}, {"image_id": 2, "file_name": "210_02.png", "page": 4, "dpi": 300, "bbox": [81, 78, 771, 167], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visualizing the Carp dataset (256 \u00d7 256 \u00d7 512) with 3 ETFs by (a) analytic integration at the object sample distance 0.6; (b) numerical integration at the object sample distance 0.3; (c) numerical integration at the object sample distance 0.6. Their performances are 23fps, 13fps, 38fps, respectively. ", "caption_bbox": [73, 178, 775, 205]}, {"image_id": 3, "file_name": "210_03.png", "page": 5, "dpi": 300, "bbox": [83, 74, 400, 419], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The pipeline of our approach.", "caption_bbox": [135, 431, 347, 447]}, {"image_id": 4, "file_name": "210_04.png", "page": 5, "dpi": 300, "bbox": [447, 74, 764, 376], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Manipulating the red ETF shown in Fig. 1 (a). (a) Recoloring. (b) Translating the recolored ETF in (a) 0.21 along the x-axis and -0.15 along the y -axis. (c) Scaling the recolored ETF in (a) 0.38 along both the major and minor axes. (d) Rotating the recolored ETF in (a) 45 degrees counter-clockwise. ", "caption_bbox": [440, 387, 775, 439]}, {"image_id": 5, "file_name": "210_05.png", "page": 5, "dpi": 300, "bbox": [462, 457, 785, 778], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Subdividing an ETF into two smaller ones. (a) An ETF and the rendering result. (b) The recolored and subdivided two ETFs and associated results, where the joints are differentiated from other structures. ", "caption_bbox": [440, 788, 775, 827]}, {"image_id": 6, "file_name": "210_06.png", "page": 6, "dpi": 300, "bbox": [85, 74, 750, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Progressive exploration of the Teeth (256 \u00d7 256 \u00d7 161) dataset using the (density, density gradient magnitude) histogram. (a) The automatically generated ETFs and rendering results. (b) Distracting regions are removed when the dark red ETF is deleted, yielding clearer visualization of the pulp and the dentin. (c) The user moves, scales and rotates the blue ETF to discover the pulp. (d) The user scales and subdivides the dark red ETF, and scales the green ETF. All structures are clearly shown. ", "caption_bbox": [73, 395, 775, 447]}, {"image_id": 7, "file_name": "210_07.png", "page": 7, "dpi": 300, "bbox": [90, 74, 760, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Exploring the Horseshoe Vortex dataset using the (the second invariant of the velocity gradient, its gradient magnitude) feature space. The automatically generated 3 ETFs (top left) produces a result (middle) that shows some noise in the the vortex region. By moving the plum ETF and scaling three ETFs (bottom left), the two layered vortex tubes are clearly shown (right). ", "caption_bbox": [73, 353, 775, 392]}, {"image_id": 8, "file_name": "210_08.png", "page": 8, "dpi": 300, "bbox": [90, 75, 759, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Exploring the Turbulent dataset in the (vorticity, pressure) feature space. The result (middle) with the automatically generated 4 ETFs (top left) does not clearly show the vortex tubes. By performing a sequence of operations, namely, removing the cyan and chartreuse ETFs, scaling the other two ETFs and recoloring them, the kinking and tangling vortex tubes are clearly shown with a large contrast. ", "caption_bbox": [73, 354, 775, 393]}], "211": [{"image_id": 0, "file_name": "211_00.png", "page": 2, "dpi": 300, "bbox": [439, 805, 777, 956], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Slice through the synthetic data (a) and the frequency dis- tribution of the data values (b). ", "caption_bbox": [440, 974, 775, 1000]}, {"image_id": 1, "file_name": "211_01.png", "page": 2, "dpi": 300, "bbox": [448, 402, 769, 538], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Statistical transfer-function workflow.", "caption_bbox": [493, 553, 721, 566]}, {"image_id": 2, "file_name": "211_02.png", "page": 3, "dpi": 300, "bbox": [143, 522, 341, 602], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The standard deviation and mean for the sphere and the outer hull. ", "caption_bbox": [73, 617, 408, 643]}, {"image_id": 3, "file_name": "211_03.png", "page": 3, "dpi": 300, "bbox": [463, 74, 754, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Calculation loop for the extraction of the statistical proper- ties. ", "caption_bbox": [440, 288, 775, 314]}, {"image_id": 4, "file_name": "211_04.png", "page": 4, "dpi": 300, "bbox": [470, 569, 747, 754], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Statistical properties (\u03bc and \u03c3 ) of the synthetic data for three different confidence levels \u03c9 = {0.1%, 5.0%, 30.0%}. The brighter a point is, the higher is its value. ", "caption_bbox": [440, 766, 775, 807]}, {"image_id": 5, "file_name": "211_05.png", "page": 5, "dpi": 300, "bbox": [442, 337, 774, 474], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Line and dot representation in the statistical transfer- function space of the synthetic data. ", "caption_bbox": [440, 492, 775, 518]}, {"image_id": 6, "file_name": "211_06.png", "page": 5, "dpi": 300, "bbox": [98, 450, 385, 574], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Schematic representation of the statistical transfer-function space. On the left side the properties of a sample point are shown as a line segment. On the right side a transfer-function region in the new space can be seen. ", "caption_bbox": [73, 589, 408, 641]}, {"image_id": 7, "file_name": "211_07.png", "page": 6, "dpi": 300, "bbox": [106, 170, 378, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Time measurement for the estimation of statistical properties for different data sets. ", "caption_bbox": [440, 459, 775, 485]}, {"image_id": 8, "file_name": "211_08.png", "page": 6, "dpi": 300, "bbox": [449, 74, 769, 211], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Termination level of the calculation loop for different data sets and confidence levels \u03c9 . ", "caption_bbox": [440, 228, 775, 255]}, {"image_id": 9, "file_name": "211_09.png", "page": 7, "dpi": 300, "bbox": [460, 400, 757, 522], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Detection of a brain tumor. For the extraction of the statis- tical properties \u03c9 was set to 0.1%. ", "caption_bbox": [440, 536, 775, 563]}, {"image_id": 10, "file_name": "211_10.png", "page": 7, "dpi": 300, "bbox": [470, 75, 746, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Detection of different fluids in a CT scan of a backpack.", "caption_bbox": [445, 351, 771, 364]}, {"image_id": 11, "file_name": "211_11.png", "page": 7, "dpi": 300, "bbox": [73, 80, 411, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Classification results of the materials in the synthetic data set with different methods. ", "caption_bbox": [73, 256, 408, 282]}, {"image_id": 12, "file_name": "211_12.png", "page": 8, "dpi": 300, "bbox": [81, 75, 768, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Comparison of the statistical transfer-function space with the 1D and 2D transfer function space as well as the LH histogram-space. The task for the generation of the results was to classify the brain in the different spaces. ", "caption_bbox": [73, 258, 775, 284]}], "212": [{"image_id": 0, "file_name": "212_00.png", "page": 2, "dpi": 300, "bbox": [474, 76, 742, 282], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Workflow of our approach.", "caption_bbox": [515, 303, 700, 316]}, {"image_id": 1, "file_name": "212_01.png", "page": 3, "dpi": 300, "bbox": [98, 73, 386, 214], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Typical cases for the three shape classes. The arrows illustrate the distance of each surface voxel (blue) to the skeleton segment (red) . For the longitudinal shape a gap in the skeleton is displayed. The surface shape is shown along with its bounding box. ", "caption_bbox": [73, 228, 408, 283]}, {"image_id": 2, "file_name": "212_02.png", "page": 4, "dpi": 300, "bbox": [531, 74, 686, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Close-up of curve-skeleton in an angiography data set prior to normalization. Pre-segmentation errors can lead to gaps in the skeleton, as well as missing skeletons for entire parts of the volume. The skeleton segments are shown with alternating colors. ", "caption_bbox": [440, 214, 775, 269]}, {"image_id": 3, "file_name": "212_03.png", "page": 5, "dpi": 300, "bbox": [120, 83, 363, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparison of the curve-skeleton of an aneurysm blob before (a) and after (b) the splitting operation. Without splitting the left green segment ranges from the blob deep into the left vessel preventing a proper classification of the blob. ", "caption_bbox": [73, 227, 408, 282]}, {"image_id": 4, "file_name": "212_04.png", "page": 5, "dpi": 300, "bbox": [77, 298, 387, 438], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Blob merging demonstrated on one lung of the NCAT phantom [23]. (a) shows the curve-skeleton after normalization, (b) the corresponding skeleton regions, (c) the regions after fusion. ", "caption_bbox": [73, 466, 408, 507]}, {"image_id": 5, "file_name": "212_05.png", "page": 6, "dpi": 300, "bbox": [170, 74, 311, 198], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Statistics for the data sets presented in the results section. Given are the data set resolution, the times for computation of the curve-skeleton and for the classification (in seconds). ", "caption_bbox": [73, 332, 408, 373]}, {"image_id": 6, "file_name": "212_06.png", "page": 7, "dpi": 300, "bbox": [88, 77, 767, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Classification workflow for the angiography data set shown in Figure 8(b). Subfigure (a) displays the normalized curve-skeleton, while (b) and (c) present the skeleton regions before and after merging along with the corresponding shape distributions. ", "caption_bbox": [73, 312, 775, 339]}, {"image_id": 7, "file_name": "212_07.png", "page": 8, "dpi": 300, "bbox": [110, 672, 763, 930], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Shape-classified CT scan of a mouse lying on a bed. (a) was rendered with a conventional 1D transfer function. In (b) the bones/vessels are rendered semi-transparently, while the heart and the bed have been colored independently. The blobby structures (red) have been selected in the user interface. (c) shows a further refined classification where the blobby features outside the heart have been selected in the user interface in order to assign the same optical properties that have been chosen for the bones/vessels. ", "caption_bbox": [73, 945, 775, 1000]}, {"image_id": 8, "file_name": "212_08.png", "page": 8, "dpi": 300, "bbox": [129, 392, 719, 607], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Application of the proposed classification technique to a CT scan of a mouse heart. (b) and (c) show renderings of the classification result from two perspectives along with the corresponding shape distribution. The red-labeled heart structures correspond to the shapes selected in the user interface. The rendering in (a) was generated with a conventional 1D transfer function. ", "caption_bbox": [73, 621, 775, 662]}, {"image_id": 9, "file_name": "212_09.png", "page": 8, "dpi": 300, "bbox": [121, 78, 733, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Shape-classified volume renderings of two angiography data sets, each containing an aneurysm. The thumbnails show renderings generated with a conventional 1D transfer function, for comparison. ", "caption_bbox": [73, 352, 775, 379]}], "213": [{"image_id": 0, "file_name": "213_00.png", "page": 2, "dpi": 300, "bbox": [75, 74, 409, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: User interface for our system: (a) Region for adjusting pa- rameters for DVR; (b) Region for presenting the DVRI; (c) Region for providing effectiveness feedback; (d) Region for specifying the trans- fer function. ", "caption_bbox": [73, 292, 408, 344]}, {"image_id": 1, "file_name": "213_01.png", "page": 2, "dpi": 300, "bbox": [442, 76, 794, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Three features in purple, blue, and green are composited with opacity 0.5, 0.5, and 1. The purple feature cannot be distin- guished from the blue feature after composition. ", "caption_bbox": [440, 204, 775, 243]}, {"image_id": 2, "file_name": "213_02.png", "page": 3, "dpi": 300, "bbox": [125, 77, 725, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Three DVRIs with varying distinguishability values. The computed effectiveness values for (a), (b), and (c) were 0.17 and 0.43, and 0.85, respectively. ", "caption_bbox": [73, 282, 775, 308]}, {"image_id": 3, "file_name": "213_03.png", "page": 4, "dpi": 300, "bbox": [84, 75, 766, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The measured edge consistency values for (a), (b), and (d) are 0.95, 0.7, and 0.3, respectively; (c) and (e) highlight the false edges of (b) and (d), respectively, using red strokes. ", "caption_bbox": [73, 335, 775, 361]}, {"image_id": 4, "file_name": "213_04.png", "page": 5, "dpi": 300, "bbox": [112, 75, 739, 494], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a)-(d) Four DVRIs with varying contour clarity (0.47, 0.56, 0.14, and 0.92, respectively); (e) A histogram built by the clarity measure to estimate the isosurfaces presented in (a). ", "caption_bbox": [73, 510, 775, 536]}, {"image_id": 5, "file_name": "213_05.png", "page": 6, "dpi": 300, "bbox": [174, 75, 675, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A DVRI and its depth image and overly segmented image where some depth incoherence exists.", "caption_bbox": [161, 310, 683, 323]}, {"image_id": 6, "file_name": "213_06.png", "page": 7, "dpi": 300, "bbox": [440, 75, 780, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Effectiveness graphs for a typical visualization. : upper graph shows the effectiveness values for each DVRI and the bottom graph is the corresponding accumulated effectiveness graph. Color encodes the measure types. ", "caption_bbox": [440, 263, 775, 315]}, {"image_id": 7, "file_name": "213_07.png", "page": 7, "dpi": 300, "bbox": [79, 81, 403, 208], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Average ratings of the understanding and usefulness of the measures. ", "caption_bbox": [73, 229, 408, 255]}], "214": [{"image_id": 0, "file_name": "214_00.png", "page": 2, "dpi": 300, "bbox": [508, 728, 709, 843], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A small FAN represented by the interface of VISFAN.", "caption_bbox": [469, 861, 745, 874]}, {"image_id": 1, "file_name": "214_01.png", "page": 3, "dpi": 300, "bbox": [440, 82, 775, 511], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Interface that allows the analyst to begin a new investigation. (b) The initial network obtained from the seed entity Amato Paolo with maximum graph theoretic distance two. ", "caption_bbox": [440, 529, 775, 566]}, {"image_id": 2, "file_name": "214_02.png", "page": 4, "dpi": 300, "bbox": [89, 74, 393, 734], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) Layout of a new network obtained by that of Fig. 2(b), by a bottom-up exploration of nodes labeled Fabio De Santis and Claudia Fontana. (b) The same network, where some clusters have been defined; each cluster is represented as a rectangular region in the new drawing. (c) A different layout of the clustered network where a cluster has been collapsed (the filled node) and another has been resized. ", "caption_bbox": [73, 752, 408, 827]}, {"image_id": 3, "file_name": "214_03.png", "page": 5, "dpi": 300, "bbox": [459, 75, 760, 466], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) A Graph G where the nodes are labeled with their core-numbers. The closed regions colored with different gray scales denote the k-core com- ponents, and each region is labeled with a different letter. (b) The inclusion tree of the cluster hierarchy defined by our algorithm on graph G. (c) A Graph G representing a FAN with five transaction-node (black nodes). (d) The graph G\u2032 obtained from G by applying a transformation on the transaction-nodes. (e) The clusters obtained for G\u2032 by using our clustering algorithm; each closed region represents a different cluster. (f) The final clusters obtained for G. ", "caption_bbox": [440, 485, 775, 584]}, {"image_id": 4, "file_name": "214_04.png", "page": 5, "dpi": 300, "bbox": [73, 75, 410, 487], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) A FAN and the degree centrality values of its nodes shown as bars. (b) Table that compares all node centrality indices available in the system. ", "caption_bbox": [73, 506, 408, 531]}, {"image_id": 5, "file_name": "214_05.png", "page": 6, "dpi": 300, "bbox": [467, 80, 737, 176], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Schematic illustration that shows how a cluster is moved when some nodes hit its boundary. (a) Two nodes that hit the boundary of a cluster from the inside; the arrows represent the corresponding forces exerted by two nodes on the cluster region. (b) The resultant force depicted as a dashed arrow; (c) The movement of the cluster region. The intensity of the resultant is decreased to simulate the inertia of the cluster region. ", "caption_bbox": [440, 194, 775, 268]}, {"image_id": 6, "file_name": "214_06.png", "page": 8, "dpi": 300, "bbox": [94, 554, 758, 917], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The FAN of Fig. 7, after the execution of our clustering algorithm. Some elements have been hidden to diminish the visual complexity of the diagram.", "caption_bbox": [82, 933, 766, 946]}, {"image_id": 7, "file_name": "214_07.png", "page": 8, "dpi": 300, "bbox": [89, 130, 757, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A FAN containing fraudulent patterns. The network consists of 104 elements and 163 connections.", "caption_bbox": [189, 425, 659, 438]}], "215": [{"image_id": 0, "file_name": "215_00.png", "page": 1, "dpi": 300, "bbox": [95, 86, 760, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: All directed-edge representations used in our initial (a to j), follow-up (b, k, l), and current study (b, l, m, n, o). (a) standard arrow \u2013 S, (b) tapered \u2013 T, (c) dark-to-light \u2013 DL (a.k.a intensity \u2013 I), (d) light-to-dark \u2013 LD, (e) green-to-red \u2013 GR, (f) curvature \u2013 C, (g) tapered-intensity \u2013 TI, (h) tapered-curvature \u2013 TC, (i) intensity-curvature \u2013 IC, (j) tapered-intensity-curvature \u2013 TIC, (k) biased curvature \u2013 Cb , (l) animated \u2013 A, (m) animated compressed \u2013 Ac , (n) glyph \u2013 G, and (o) glyph compressed \u2013 Gc . ", "caption_bbox": [73, 429, 775, 482]}, {"image_id": 1, "file_name": "215_01.png", "page": 3, "dpi": 300, "bbox": [472, 744, 741, 988], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Graph densities used in the current study: (a) sparse (70 nodes), (b) medium-density (140 nodes), and (c) dense (280 nodes). ", "caption_bbox": [440, 988, 775, 1013]}, {"image_id": 2, "file_name": "215_02.png", "page": 5, "dpi": 300, "bbox": [73, 74, 411, 378], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Average completion time (y-axis) and average correctness (x-axis) per representation. The best and worst techniques would be situated in the bottom-right and top-left corners, respectively. ", "caption_bbox": [440, 874, 775, 913]}, {"image_id": 3, "file_name": "215_03.png", "page": 5, "dpi": 300, "bbox": [456, 687, 757, 871], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Statistically significant results of pairwise comparisons for edge representations based on error (better technique on the left). ", "caption_bbox": [440, 984, 775, 1009]}, {"image_id": 4, "file_name": "215_04.png", "page": 6, "dpi": 300, "bbox": [104, 75, 372, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Significant differences for cross comparisons according to trial error for all five edge types. ", "caption_bbox": [440, 441, 775, 466]}, {"image_id": 5, "file_name": "215_05.png", "page": 6, "dpi": 300, "bbox": [458, 74, 755, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Average correctness per representation by edge length.", "caption_bbox": [446, 254, 768, 266]}, {"image_id": 6, "file_name": "215_06.png", "page": 7, "dpi": 300, "bbox": [92, 81, 389, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Number of participants preferring each representation.", "caption_bbox": [83, 235, 399, 247]}], "216": [{"image_id": 0, "file_name": "216_00.png", "page": 3, "dpi": 300, "bbox": [73, 525, 416, 564], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of the ink minimization process. The dotted line pass through the centroids of S and T . ", "caption_bbox": [73, 578, 408, 604]}, {"image_id": 1, "file_name": "216_01.png", "page": 3, "dpi": 300, "bbox": [164, 78, 669, 374], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: How multilevel agglomerative bundling works: (a) Original edges. Ink = 35.82. (b) Constructing an edge proximity graph (k = 3). (c) After one level of agglomerative bundling. Ink = 19.31. (d) Constructing a coarsened proximity graph. (e) After multilevel agglomerative bundling. Ink = 12.00. We call the tree-like branching portions of the bundles at their endpoints the fan-in and fan-out. (f) After recursive application of bundling. Ink = 10.94. (g) Rendered using splines. (h) With turning angle <= 40o and spline rendering. Ink = 15.24. ", "caption_bbox": [73, 387, 775, 440]}, {"image_id": 2, "file_name": "216_02.png", "page": 3, "dpi": 300, "bbox": [81, 645, 414, 681], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Left: edges with far away end points. Middle: bundling results in a large turning angle. Right: limiting the turning angle. ", "caption_bbox": [73, 695, 408, 721]}, {"image_id": 3, "file_name": "216_03.png", "page": 4, "dpi": 300, "bbox": [92, 73, 392, 467], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Graph airlines (b) Bundled without recursion (c) With recursion. ", "caption_bbox": [73, 481, 408, 507]}, {"image_id": 4, "file_name": "216_04.png", "page": 7, "dpi": 300, "bbox": [73, 55, 786, 528], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: ixpas graph (|E| = 149661) before and after edge bundling", "caption_bbox": [259, 543, 590, 556]}], "217": [{"image_id": 0, "file_name": "217_00.png", "page": 1, "dpi": 300, "bbox": [424, 86, 753, 531], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The dynamic short-message communication network cen- tral to a mobile phone spammer. ", "caption_bbox": [440, 540, 775, 567]}, {"image_id": 1, "file_name": "217_01.png", "page": 3, "dpi": 300, "bbox": [88, 73, 393, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A example of the dynamic ego network compression step. The dynamic network encompasses three time slots t0 , t1 and t2 . The network is compressed based on the focus node set \u2126 = {A}, highlighted in red. In the generated graph, blue edges indicate time- independent edges and green edges indicate time-dependent edges where the label tells the timeslot attached to each edge. ", "caption_bbox": [73, 290, 409, 369]}, {"image_id": 2, "file_name": "217_02.png", "page": 3, "dpi": 300, "bbox": [459, 82, 753, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Dynamic network visualization in 1.5D: the sketch view.", "caption_bbox": [446, 329, 766, 343]}, {"image_id": 3, "file_name": "217_03.png", "page": 5, "dpi": 300, "bbox": [445, 73, 774, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Event-based network visualization with only time- independent edges: (a) Without bundling; (b) After bundling. ", "caption_bbox": [440, 259, 775, 286]}, {"image_id": 4, "file_name": "217_04.png", "page": 5, "dpi": 300, "bbox": [85, 74, 399, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: 1.5D Network Visualization with different timelines: (a) Slot- ted by month; (b) By day; (c) By minute. ", "caption_bbox": [73, 195, 409, 222]}, {"image_id": 5, "file_name": "217_05.png", "page": 5, "dpi": 300, "bbox": [85, 248, 394, 406], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Consecutive views during egocentric graph navigation in Infovis co-author network: (a) Network central to Prof. Jark van Wijk with Dr. Frank van Ham moused over; (b) Switch to the network central to Dr. Frank van Ham by clicking the node. ", "caption_bbox": [73, 414, 409, 467]}, {"image_id": 6, "file_name": "217_06.png", "page": 6, "dpi": 300, "bbox": [76, 96, 720, 601], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: 1.5D dynamic network visualization in communications scenario: (a) A typical spammer behavior slotted by month; (b) Slotted by minute; (c) A typical non-spammer behavior slotted by day; (d) Slotted by hour. ", "caption_bbox": [73, 609, 775, 636]}, {"image_id": 7, "file_name": "217_07.png", "page": 7, "dpi": 300, "bbox": [119, 75, 363, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Infovis co-authorship network 1995\u223c2009. The node rep- resenting \u201dProf. Stasko\u201d is highlighted, with only ego edges drawn. ", "caption_bbox": [73, 336, 408, 363]}, {"image_id": 8, "file_name": "217_08.png", "page": 8, "dpi": 300, "bbox": [80, 75, 777, 523], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Infovis co-authorship network: (a) Year 1995\u223c1999 highlighted; (b) Year 2000\u223c2004 highlighted; (c) Year 2005\u223c2009 highlighted; (d) Two periods highlighted, slotted by 5-year; (e) \u201dProf. Munzner\u201d ego network; (f) \u201dDr. Wong\u201d ego network ", "caption_bbox": [73, 526, 775, 553]}], "218": [{"image_id": 0, "file_name": "218_00.png", "page": 1, "dpi": 300, "bbox": [73, 120, 778, 348], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Interactive zooming towards SF Bay, where at first all the traffic from the Bay Area is aggregated, to a view where we can separate traffic from the three major airports, and even the distribution of traffic in each airports\u2018 cardinal direction. This interaction is enabled by automatically updating the bandwidth of the KDE when the viewport changes. ", "caption_bbox": [73, 363, 775, 402]}, {"image_id": 1, "file_name": "218_01.png", "page": 2, "dpi": 300, "bbox": [78, 74, 406, 168], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A kernel density estimation of petal width in the Iris dataset [13] and two corresponding histograms, one with 9 bins and the other with 10 bins. ", "caption_bbox": [73, 196, 408, 235]}, {"image_id": 2, "file_name": "218_02.png", "page": 3, "dpi": 300, "bbox": [73, 74, 411, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: 2D KDE for the Iris dataset [13] with increasing bandwidth.", "caption_bbox": [73, 292, 408, 304]}, {"image_id": 3, "file_name": "218_03.png", "page": 3, "dpi": 300, "bbox": [448, 74, 769, 205], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visualizing over 165 000 monetary contributions to the Obama campaign. Interesting areas with negative aggregates, i.e., locations where the returned amount exceeds that of the contributed, are shown as blue. ", "caption_bbox": [440, 219, 775, 271]}, {"image_id": 4, "file_name": "218_04.png", "page": 4, "dpi": 300, "bbox": [439, 74, 765, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A line kernel density reconstruction of four samples, or three edges. Each edge is weighted by one, e.g., one second, and thus the integral of this entire figure is three. The time density at the top edge is greater than the diagonals, since this distance is smaller, and its weight is the same. ", "caption_bbox": [440, 313, 775, 378]}, {"image_id": 5, "file_name": "218_05.png", "page": 4, "dpi": 300, "bbox": [73, 74, 411, 162], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Gaussian kernels with a bandwidth of 0.05 and their com- bined integral (orange). Left 10 kernels and their sum, and right 15 kernels and their sum. These figures represents the super-sampling approach, whereas Eq. 8 calculates the sum directly. ", "caption_bbox": [73, 177, 408, 229]}, {"image_id": 6, "file_name": "218_06.png", "page": 4, "dpi": 300, "bbox": [440, 394, 776, 488], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Reconstructing two connected samples in time, on left, super-sampling by filling the space with additional samples, and on right, by drawing a continuous rectangle and two end-caps. Both techniques produce the same result, but our line kernel density esti- mate does so with a significant efficiency increase. ", "caption_bbox": [440, 503, 775, 568]}, {"image_id": 7, "file_name": "218_07.png", "page": 5, "dpi": 300, "bbox": [445, 74, 772, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A side by side comparison: an overpopulated scatterplot with semi-transparent points (left) vs. our visualization with line KDE (right). Compared, the bottom of these two gives a clear overview of where time is distributed with regards to hook-load and depth. The dark blue areas to the left indicate non-productive time. ", "caption_bbox": [440, 235, 775, 300]}, {"image_id": 8, "file_name": "218_08.png", "page": 6, "dpi": 300, "bbox": [73, 329, 777, 498], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Three line kernel density estimates, showing the distribution of time over depth in a drilling hole (wellbore) and hook-load, the weight of the entire drill string. The leftmost image is a detailed view, with a small kernel, showing the curve with varying tons on the hook, used e.g., to calculate friction. The user then zooms out, and goes to an overview mode with a large kernel, on right, and selects an overwhelming time density, integrates and finds that over an hour was nonproductive at this depth. ", "caption_bbox": [73, 513, 775, 565]}, {"image_id": 9, "file_name": "218_09.png", "page": 6, "dpi": 300, "bbox": [73, 74, 778, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Two KDE-based visualizations using the same bandwidth and data, of ship traffic off the coast in western Norway. The left image shows the position samples as point kernels, and the right image shows the same data using our line reconstruction kernels. ", "caption_bbox": [73, 289, 775, 314]}, {"image_id": 10, "file_name": "218_10.png", "page": 7, "dpi": 300, "bbox": [439, 420, 789, 637], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Error introduced by using a truncated Gaussian.", "caption_bbox": [468, 761, 747, 773]}, {"image_id": 11, "file_name": "218_11.png", "page": 7, "dpi": 300, "bbox": [73, 74, 777, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Run times (in seconds) for evaluating grids of different sizes, for three different implementations of kernel density estimation, all using same dataset, kernel and bandwidth. KDE-plot GPU is our proposed technique. ", "caption_bbox": [440, 650, 775, 702]}], "219": [{"image_id": 0, "file_name": "219_00.png", "page": 1, "dpi": 300, "bbox": [73, 86, 777, 556], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Interface of Triple Perspective Visual Trajectory Analytics (TripVista) visualizing traffic trajectory data at a road intersection. (a) Spatial traffic view showing geometrical trajectory information; (b) Temporal views of ThemeRiver and scatterplots; (c) Parallel coordinates plot showing multiple properties of the multi-dimensional data; (d) Time sliders for two-level time range selection; (e) Control panel for system parameter settings and data classification. ", "caption_bbox": [73, 570, 775, 622]}, {"image_id": 1, "file_name": "219_01.png", "page": 3, "dpi": 300, "bbox": [96, 80, 387, 316], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Design Philosophy of Triple Perspective Visual Trajectory Analytics (TripVista). Spatial, temporal and multi-dimensional per- spectives are closely linked and respectively represented by different metaphors. ", "caption_bbox": [73, 333, 408, 385]}, {"image_id": 2, "file_name": "219_02.png", "page": 4, "dpi": 300, "bbox": [74, 73, 411, 193], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Traffic View: (a) The map of the road intersection where the data is collected. The arrows on the map indicate the permitted traffic directions and the traffic light configurations; (b) Traffic view - colored according to object types; (c) Traffic view - colored according to speed variation. ", "caption_bbox": [73, 206, 408, 271]}, {"image_id": 3, "file_name": "219_03.png", "page": 4, "dpi": 300, "bbox": [446, 81, 773, 438], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Algorithm Illustration for glyph embedding in ThemeRiver: (a) Original ThemeRiver; (b) Possible glyph positions determined by Fast Hierarchical Importance Sampling; (c) Each river is subdivided and the same type of glyphs are located in the same subriver; (d) Resulting ThemeRiver with embedded glyphs. ", "caption_bbox": [440, 451, 775, 516]}, {"image_id": 4, "file_name": "219_04.png", "page": 5, "dpi": 300, "bbox": [441, 160, 781, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Investigation of U-turn Patterns (a) Select the U-turn trajec- tories with ring sliders; (b) Select the U-turn trajectories using direc- tional brush; (c) Replay the scene (U-turn patterns in red). ", "caption_bbox": [440, 304, 775, 343]}, {"image_id": 5, "file_name": "219_05.png", "page": 5, "dpi": 300, "bbox": [441, 736, 782, 910], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Regular Traffic Patterns (a) Group the concerned trajec- tories according to their exits; (b) Selected trajectory groups have different volumes as shown in the ThemeRiver. ", "caption_bbox": [440, 923, 775, 962]}, {"image_id": 6, "file_name": "219_06.png", "page": 6, "dpi": 300, "bbox": [442, 345, 779, 786], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Dangerous Events Discovered in Dense Trajectories: (a) Selection of the trajectories with larger angle change values in the parallel coordinates; (b) Trajectories with larger angle changes in the traffic view; (c) One interesting trajectory identified in the traffic view; (d) A dangerous event: the cyclist narrowly escaped being hit by a car; (e) Other violation behaviors in groups. ", "caption_bbox": [440, 799, 775, 877]}, {"image_id": 7, "file_name": "219_07.png", "page": 6, "dpi": 300, "bbox": [74, 412, 409, 596], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Traffic Violations (a) Wrong-way offenders; (b) Illegal turn- ing pattern. ", "caption_bbox": [73, 609, 408, 635]}, {"image_id": 8, "file_name": "219_08.png", "page": 7, "dpi": 300, "bbox": [88, 746, 401, 851], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Several cases discovered by our prototype of relative mo- tion detection algorithm, in which moving bicycles (purple) and cars (cyan) appeared very close. However, when speed is considered, none of them is as dangerous as the case in Section 5.3. It is notice- able that in the last case, the bicycle is inside the car. This impossible scene results from the inaccuracies in the data. ", "caption_bbox": [73, 866, 408, 944]}], "22": [], "220": [{"image_id": 0, "file_name": "220_00.png", "page": 2, "dpi": 300, "bbox": [439, 76, 777, 375], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Algorithmic pipeline to create a base map from a canonical map. (1) Canonical map is created with all crawled artists, by embed- ding them using MDS and smaller-sized label fonts. (2) From each pair of daily-crawled files that are D days apart, 250 artists with the highest playcount increase are extracted. (3) Position data of the hot artists are extracted from the canonical map. (4) All label font sizes are set to the average size. (5) Overlap removal is applied, and the resulting layout is used as a base map. ", "caption_bbox": [440, 390, 775, 494]}, {"image_id": 1, "file_name": "220_01.png", "page": 3, "dpi": 300, "bbox": [144, 78, 705, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Map of 18,000 artists (b) Map of 18,000 artists using adjusted edge lengths", "caption_bbox": [230, 367, 616, 379]}, {"image_id": 2, "file_name": "220_02.png", "page": 4, "dpi": 300, "bbox": [108, 59, 740, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The top 250 artists: showing artist popularity through font sizes, while also displaying similarity using the geographic map metaphor.", "caption_bbox": [116, 346, 729, 358]}, {"image_id": 3, "file_name": "220_03.png", "page": 5, "dpi": 300, "bbox": [167, 54, 683, 429], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Overview of Implementation", "caption_bbox": [338, 444, 507, 456]}, {"image_id": 4, "file_name": "220_04.png", "page": 5, "dpi": 300, "bbox": [111, 485, 739, 689], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) Highlighting in blue areas where artists are about to disappear: Bon Jovi, Deep Purple, Elvis, Simon & Garfunkel, CCR, and Eric Clapton. (b) Highlighting in yellow the areas where new artists are about to appear. (c) An image after the appearing/increasing phase showing newcomers: Bruce Springsteen, Neil Young, The Kinks, and The Beach Boys. ", "caption_bbox": [73, 701, 775, 738]}, {"image_id": 5, "file_name": "220_05.png", "page": 6, "dpi": 300, "bbox": [81, 59, 766, 356], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A snapshot of trend visualization of last.fm. On the heat-map, darkness of the color indicates the degree of increase in short-term popularity while font sizes of artists correspond to long-term popularity. Labels of artists who are out of the top 250 are hidden and colored white. Clusters based on similarity are represented with black boundary lines as well as label colors, which are mapped with country names shown on the top of the map. The date label located on the top-left corner indicates the timestamp of the heat-map displayed, and the progress bar on the bottom-left shows the position of the map in the entire animation. ", "caption_bbox": [73, 390, 775, 439]}, {"image_id": 6, "file_name": "220_06.png", "page": 7, "dpi": 300, "bbox": [177, 51, 671, 933], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A sequence of animation frames between two consecutive base heat-maps including blue and yellow highlights.", "caption_bbox": [161, 953, 688, 965]}], "221": [{"image_id": 0, "file_name": "221_00.png", "page": 1, "dpi": 300, "bbox": [73, 119, 778, 399], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A density map of vessel traffic in front of Rotterdam during a single day. The density map is a combination of four density fields each covering a quarter of the day. The following manually defined color map is used: night is dark blue, morning is bright yellow, afternoon is dark yellow, and evening is bright blue. Furthermore, the saturation of the color represents the density field contribution and the hue is given by the period with the highest density. To discriminate daylight patterns from nighttime, the night and evening use half the kernel radius of the other periods. This figure shows that the main routes are the most used during daylight, while in the night deviations from these routes occur. ", "caption_bbox": [73, 413, 775, 478]}, {"image_id": 1, "file_name": "221_01.png", "page": 2, "dpi": 300, "bbox": [125, 75, 724, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The rendering pipeline of vessel density maps by Willems et al. [28]. From left to right, trajectories are smoothed with a large and a small kernel resulting in two density fields. In the rendering, the large kernel density field is used for color mapping and the aggregated density fields are used for the illumination. In the final density map, the color image and the gray-scale image with the illumination are multiplied. ", "caption_bbox": [73, 262, 775, 301]}, {"image_id": 2, "file_name": "221_02.png", "page": 3, "dpi": 300, "bbox": [125, 81, 724, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The architecture of our framework to generate density maps. From left to right, the trajectory data is split with various filters resulting in a number of subsets for which we compute a density field with the given weight wi and kernel radius ri . From here there are two routes. We may aggregate the density fields in a single density field via the solid lines. Then the single density field is rendered to an image with a color map ci and visualized together with its illumination in a density map. The other route, also via the dashed lines, first renders the density fields using a color map ci and then composes them and applies the illumination of the aggregate density field resulting in a density map. ", "caption_bbox": [73, 313, 775, 379]}, {"image_id": 3, "file_name": "221_03.png", "page": 3, "dpi": 300, "bbox": [510, 619, 703, 726], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Interactive bar chart to set a density parameter for subsets.", "caption_bbox": [440, 741, 775, 754]}, {"image_id": 4, "file_name": "221_04.png", "page": 4, "dpi": 300, "bbox": [81, 747, 403, 960], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Image composition: (A) Single-field, (B) multi-field, (C) opacity-blend, (D) max-blend, and (E) block. ", "caption_bbox": [73, 974, 408, 1000]}, {"image_id": 5, "file_name": "221_05.png", "page": 4, "dpi": 300, "bbox": [81, 187, 380, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Density aggregation: (A) Weighted addition, (B) absolute difference, and (C) anomaly detection. ", "caption_bbox": [73, 308, 408, 334]}, {"image_id": 6, "file_name": "221_06.png", "page": 4, "dpi": 300, "bbox": [446, 530, 775, 748], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Distribution maps from pairs of vessel attributes.", "caption_bbox": [465, 766, 750, 779]}, {"image_id": 7, "file_name": "221_07.png", "page": 5, "dpi": 300, "bbox": [72, 74, 777, 197], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The pipeline for computing density fields on a GPU: (A) The trajectory segment p0 p1 given in geographic coordinates. (B) The segment mapped to map coordinates using the cylindrical equal-area projection and its OBB v1 v2 v3 v4 at distance r. (C) The fragments inside OBB. (D) The density field computed for each fragment in OBB. This density field is then added to already computed densities of other segments. ", "caption_bbox": [73, 216, 775, 255]}, {"image_id": 8, "file_name": "221_08.png", "page": 6, "dpi": 300, "bbox": [439, 333, 776, 636], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: A vessel sailing between Amsterdam and Scheveningen is marked as anomalous, since normally no vessels sail in this area. ", "caption_bbox": [440, 650, 775, 676]}, {"image_id": 9, "file_name": "221_09.png", "page": 6, "dpi": 300, "bbox": [72, 544, 411, 830], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: An aggregation of four density maps each covering six hours of a day using addition as density aggregation. ", "caption_bbox": [73, 844, 408, 870]}, {"image_id": 10, "file_name": "221_10.png", "page": 7, "dpi": 300, "bbox": [76, 74, 774, 665], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Classifying behavior of slow moving vessels in front of Rotterdam harbor during one week. In (A) a vessel density map [28] is shown and in (C) slow moving areas are isolated using the DM in (B) and anchor zones are marked with an anchor. After defining different types of slow moving vessels with the DM in (D) we can figure out what happened in the zoomed in areas (E...I), which correspond with the numbers in (C). ", "caption_bbox": [73, 679, 775, 718]}, {"image_id": 11, "file_name": "221_11.png", "page": 8, "dpi": 300, "bbox": [73, 74, 411, 348], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: A risk map with various vessel types: large cargo vessels (blue), large tankers (purple), small passenger ships (pink), small high speed craft (orange), and other type of small ships (green). ", "caption_bbox": [73, 362, 408, 401]}], "222": [{"image_id": 0, "file_name": "222_00.png", "page": 3, "dpi": 300, "bbox": [81, 74, 774, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The main visual components of GTdiff include a temporal view (top portion of the left screenshot), a difference view (bottom portion of the left screenshot) and a geospatial view (right screenshot). The data shown is from the cod fisheries off the coast of Newfoundland, Canada. The data is filtered to a 25-year timeframe, divided into 5-year temporal bins. The yellow-blue colour encoding represents the data in the temporal bins; the sizes of the spheres are proportional to the mass of the catch at each location; the red-green colour encoding represents the changes in the difference graphs. ", "caption_bbox": [73, 410, 775, 475]}, {"image_id": 1, "file_name": "222_01.png", "page": 4, "dpi": 300, "bbox": [476, 73, 741, 612], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Examples of the spatial binning and associated colour en- coding of the differences employed in GTdiff. Note that the numbers listed within the figures represents the raw data at the associated locations. ", "caption_bbox": [440, 630, 775, 682]}, {"image_id": 2, "file_name": "222_02.png", "page": 4, "dpi": 300, "bbox": [106, 73, 378, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The difference view provides a visual comparison of every pair of temporal bins, arranged in an inverted pyramid. ", "caption_bbox": [73, 374, 408, 399]}, {"image_id": 3, "file_name": "222_03.png", "page": 5, "dpi": 300, "bbox": [98, 73, 386, 640], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Adjusting the resolution for the spatial binning results in dif- ference graphs that range from coarse-grained to fine-grained com- parisons of the data. ", "caption_bbox": [73, 655, 408, 694]}, {"image_id": 4, "file_name": "222_04.png", "page": 6, "dpi": 300, "bbox": [447, 73, 769, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A view of the cod fisheries data over a five-year timeframe. The catch data in each of the years is shown in the temporal bins across the top. The expansion of the fisheries can be identified by the green regions in the difference graphs; the subsequent depletion of stocks can be identified by the red regions. ", "caption_bbox": [440, 561, 775, 626]}, {"image_id": 5, "file_name": "222_05.png", "page": 7, "dpi": 300, "bbox": [98, 75, 386, 941], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The important difference graphs discovered in the case study, shown in detail within the geospatial view. ", "caption_bbox": [73, 973, 408, 998]}], "223": [{"image_id": 0, "file_name": "223_00.png", "page": 3, "dpi": 300, "bbox": [73, 73, 423, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: STREAMIT system overview.", "caption_bbox": [143, 314, 335, 327]}, {"image_id": 1, "file_name": "223_01.png", "page": 5, "dpi": 300, "bbox": [76, 73, 774, 470], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: STREAMIT interface. The left part is the visualization view of text streams, and the right part includes keyword table, document tables and parameter controls. ", "caption_bbox": [73, 479, 775, 505]}, {"image_id": 2, "file_name": "223_02.png", "page": 6, "dpi": 300, "bbox": [101, 77, 752, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Barack Obama news. (A) Aug. 13, 2010, 136 news articles; (B) after increasing importance of \u201cInternational Relations\u201d; (C) Sep. 18, 2010, 230 news articles. Keyword colors: \u201cPolitics\u201d - green, \u201cInternational Relations\u201d - red, \u201cTerrorism\u201d - yellow, and \u201cDefense and Military\u201d - blue. ", "caption_bbox": [73, 309, 775, 335]}, {"image_id": 3, "file_name": "223_03.png", "page": 7, "dpi": 300, "bbox": [86, 86, 768, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Performance optimization obtained by employing similarity grids on a data set of 7100 documents ", "caption_bbox": [440, 502, 775, 528]}], "224": [{"image_id": 0, "file_name": "224_00.png", "page": 1, "dpi": 300, "bbox": [75, 86, 777, 507], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The textual Web interface versus the W ORD G RAPH visualization of the N ETSPEAK writing assistant.", "caption_bbox": [156, 523, 691, 535]}, {"image_id": 1, "file_name": "224_01.png", "page": 3, "dpi": 300, "bbox": [443, 78, 774, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The W ORD G RAPH offers several filter operations: (1) Hov- ering the mouse above a node highlights all n-gram paths passing through the node. (2) Selecting a node deemphasizes all paths of n-grams that do not contain the selected word. Multi-selection is sup- ported. (3) The subgraph filter hides elements that do not belong to selected paths. ", "caption_bbox": [440, 338, 775, 416]}, {"image_id": 2, "file_name": "224_02.png", "page": 3, "dpi": 300, "bbox": [77, 87, 403, 478], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The query ? waiting * ~response combines one word and three wildcards; the search results are shown. The W ORD - G RAPH visualizes n-grams as paths through the graph, merging mul- tiple occurrences of a word within a column. Every path can be drawn individually (split path view, middle) or shared subpaths can be merged (condensed path view, bottom). The latter view increases the result capacity (i.e. a path for is waiting for a reply is there although this 5-gram is not part of the result set.) ", "caption_bbox": [73, 498, 408, 602]}, {"image_id": 3, "file_name": "224_03.png", "page": 3, "dpi": 300, "bbox": [444, 435, 773, 639], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Query expansion: by clicking on the wildcard icon next to the word answer, a set of queries is generated for all n-grams whose paths pass through this word\u2019s node, complemented by the respective wildcard. The n-grams retrieved with these queries are integrated into W ORD G RAPH which results in a new column. ", "caption_bbox": [440, 658, 775, 723]}, {"image_id": 4, "file_name": "224_04.png", "page": 4, "dpi": 300, "bbox": [448, 478, 765, 659], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Arranging words in a column according to their frequency: The center spread ordering (top) and the top spread ordering or- dering (bottom). The relative occurrence frequency of a word in a column is mapped to its font size, color and brightness. ", "caption_bbox": [440, 684, 775, 736]}, {"image_id": 5, "file_name": "224_05.png", "page": 4, "dpi": 300, "bbox": [445, 76, 773, 396], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Column layout and word placement in a column. Maximal word spreading (top). Grid-based word placement of all columns (bottom). ", "caption_bbox": [440, 418, 775, 457]}, {"image_id": 6, "file_name": "224_06.png", "page": 4, "dpi": 300, "bbox": [73, 73, 411, 296], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Navigation: The overview bar at the bottom of the screen shows the columns of W ORD G RAPH. Selecting a column (collapsed or not) moves that column into the center using an animated transi- tion. Also, the whole graph can be moved horizontally while columns are collapsed and expanded as necessary. ", "caption_bbox": [73, 310, 408, 375]}, {"image_id": 7, "file_name": "224_07.png", "page": 5, "dpi": 300, "bbox": [117, 323, 373, 640], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Possibilities for edge drawing. The edge ports are marked as small dots. (1) Condensed path view: all paths between two words are drawn as a single edge and the incoming and outgoing edges are connected by a line passing below the word to improve readability. (2) Split path view: each path is drawn independently. Crossings occur in the background of the words. (3) Split path view: each path is drawn independently. Crossings occur behind the words. ", "caption_bbox": [73, 661, 408, 752]}, {"image_id": 8, "file_name": "224_08.png", "page": 6, "dpi": 300, "bbox": [442, 73, 775, 519], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Macro-averaged recall (top) and micro-averaged recall (bottom) over quantiles. The additional axes indicate how much of a postlist is evaluated and the required processing time. ", "caption_bbox": [440, 535, 775, 574]}, {"image_id": 9, "file_name": "224_09.png", "page": 7, "dpi": 300, "bbox": [439, 204, 777, 558], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Word choice with N ETSPEAK\u2019s Web interface (excerpt).", "caption_bbox": [445, 578, 769, 590]}, {"image_id": 10, "file_name": "224_10.png", "page": 8, "dpi": 300, "bbox": [73, 74, 411, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Word choice with the N ETSPEAK W ORD G RAPH.", "caption_bbox": [96, 280, 385, 292]}], "225": [{"image_id": 0, "file_name": "225_00.png", "page": 1, "dpi": 300, "bbox": [424, 86, 779, 474], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Color-coded sets of visual links connect individual user selections across protected and shared application windows. ", "caption_bbox": [440, 489, 775, 514]}, {"image_id": 1, "file_name": "225_01.png", "page": 3, "dpi": 300, "bbox": [476, 633, 741, 868], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Collaborative information linking infrastructure: Application 1 reports a user selection and delivers the corresponding bounding rectangles of occurrences within the application. The management application consults the multi-pointer plug-in to determine the iden- tity of the user triggering the selection and forwards the selection string to all applications accessible for this user (Application 3). After all applications have reported the bounding rectangles of selection occurrences, they are sent to the rendering plug-in of the window manager. ", "caption_bbox": [440, 882, 775, 999]}, {"image_id": 2, "file_name": "225_02.png", "page": 4, "dpi": 300, "bbox": [124, 76, 724, 367], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Screenshot of a shared workspace: color-coded sets of visual links connect text selected in two protected browser windows with matching occurrences in a shared overview chart. ", "caption_bbox": [73, 383, 775, 408]}, {"image_id": 3, "file_name": "225_03.png", "page": 6, "dpi": 300, "bbox": [74, 219, 409, 390], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Screenshot of the shared display in the experiment.", "caption_bbox": [88, 405, 389, 417]}, {"image_id": 4, "file_name": "225_04.png", "page": 6, "dpi": 300, "bbox": [444, 162, 774, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Recorded activities for each group sorted by work styles and frequency of information linking: mixed-focus collaboration, indi- vidual task-solving, tight collaboration, and a single interacting per- son (view coupling [27]) were observed work styles. The overall num- ber of selections for information linking, and selections from text edi- tor and bookmark list, respectively, are listed. ", "caption_bbox": [440, 328, 775, 406]}], "226": [{"image_id": 0, "file_name": "226_00.png", "page": 1, "dpi": 300, "bbox": [137, 85, 725, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1. Example display and experimental setup used in our construction task (Experiment 3). When a visual representation must be related", "caption_bbox": [75, 344, 774, 358]}, {"image_id": 1, "file_name": "226_01.png", "page": 3, "dpi": 300, "bbox": [442, 622, 780, 796], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2. Spatial judgment task. Animation (left) and EV (right).", "caption_bbox": [450, 801, 764, 815]}, {"image_id": 2, "file_name": "226_02.png", "page": 4, "dpi": 300, "bbox": [88, 774, 358, 951], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3. Success rate for each presentation condition. Error bars", "caption_bbox": [77, 957, 404, 971]}, {"image_id": 3, "file_name": "226_03.png", "page": 4, "dpi": 300, "bbox": [459, 76, 736, 236], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. Success rate for each group condition and difficulty", "caption_bbox": [457, 241, 757, 255]}, {"image_id": 4, "file_name": "226_04.png", "page": 4, "dpi": 300, "bbox": [492, 640, 736, 880], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6. Elapsed time for each group and difficulty condition. Error", "caption_bbox": [442, 889, 773, 903]}, {"image_id": 5, "file_name": "226_05.png", "page": 4, "dpi": 300, "bbox": [458, 436, 687, 616], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5. Elapsed time for each group and presentation condition.", "caption_bbox": [445, 624, 769, 638]}, {"image_id": 6, "file_name": "226_06.png", "page": 5, "dpi": 300, "bbox": [461, 734, 747, 949], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8. Success rate for the number of people and presentation", "caption_bbox": [446, 956, 769, 970]}, {"image_id": 7, "file_name": "226_07.png", "page": 5, "dpi": 300, "bbox": [111, 607, 386, 845], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7. Contrast task. Animation is shown at the top, EV at the", "caption_bbox": [80, 851, 401, 865]}, {"image_id": 8, "file_name": "226_08.png", "page": 6, "dpi": 300, "bbox": [454, 680, 728, 880], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11. Elapsed Time for each group and presentation condition.", "caption_bbox": [440, 885, 774, 899]}, {"image_id": 9, "file_name": "226_09.png", "page": 6, "dpi": 300, "bbox": [76, 724, 408, 917], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10. Example model and display for Experiment 3. Left: EV,", "caption_bbox": [79, 936, 403, 950]}, {"image_id": 10, "file_name": "226_10.png", "page": 6, "dpi": 300, "bbox": [90, 90, 363, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9. Elapsed time for each group and presentation condition.", "caption_bbox": [79, 310, 403, 324]}], "227": [{"image_id": 0, "file_name": "227_00.png", "page": 2, "dpi": 300, "bbox": [79, 75, 773, 207], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) and (b) illustrate the relations of entropies HX , HY , mutual information MXY , conditional entropies HX|Y , HY |X , and transfer entropy TY \u2192X using the Venn diagram. (c) illustrates the simplified calculation of TY \u2192X where each step considers one more term in Equation 3 and the red number indicates how many times each portion gets counted. (d) shows a generalization of transfer entropy to three variables. ", "caption_bbox": [73, 213, 775, 252]}, {"image_id": 1, "file_name": "227_01.png", "page": 3, "dpi": 300, "bbox": [439, 74, 777, 191], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The mapping of transfer entropies to two vertices (corre- sponding to variables Vi and Vj ) and the edge in our circular graph. ", "caption_bbox": [440, 195, 775, 222]}, {"image_id": 2, "file_name": "227_02.png", "page": 5, "dpi": 300, "bbox": [83, 81, 776, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Using circular graph to show information transfer. (a) hurricane, (b) ionization, (c) and (d) combustion. (a)-(c) show transfer entropy while (d) shows relative transfer entropy. Each graph shows the influence among all pairs of variables at the selected time step. Our graphs can answer questions such as which variable has the most total outgoing and incoming influence (find the largest circle), which variable\u2019s total outgoing influence is more than its total incoming influence and by how much (read green and orange portions of the circles), and for a pair of variables, which variable influences the other more and by how much (compare edge color and width difference at both ends). ", "caption_bbox": [73, 263, 775, 328]}, {"image_id": 3, "file_name": "227_03.png", "page": 5, "dpi": 300, "bbox": [79, 344, 771, 516], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visualization of information transfer on selected time steps of the hurricane data set. The QI and WS pair is shown. Regions that preserve original colors and opacities indicate a higher amount of influence. Comparisons of normal rendering and modulated rendering are given in the first and last images. Strong influence regions are around the hurricane\u2019s eye. ", "caption_bbox": [73, 515, 775, 554]}, {"image_id": 4, "file_name": "227_04.png", "page": 6, "dpi": 300, "bbox": [90, 327, 760, 557], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualization of information transfer on selected time steps for all 30 groups of the combustion particle data set. The YOH and T pair is shown and time steps are 80, 150, 220, 290, and 290 from left to right. The rightmost image shows the smoke representation while the rest show the ellipse representation. The influences between YOH and T are nearly equal in early time steps. After that, different groups of particles exhibit different inter-influence relations. ", "caption_bbox": [73, 556, 775, 608]}, {"image_id": 5, "file_name": "227_05.png", "page": 6, "dpi": 300, "bbox": [80, 75, 767, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualization of information transfer on selected time steps of the ionization front instability data set. The He+ and H2 pair is shown. Strong influence regions are around the plane on the front moving upward. ", "caption_bbox": [73, 287, 775, 313]}, {"image_id": 6, "file_name": "227_06.png", "page": 7, "dpi": 300, "bbox": [79, 278, 777, 514], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: The average timing for calculating transfer entropies for a pair of variables per time step. The output is joint histograms and transfer entropy values. The timing consists of reading and writing data (I/O), computing joint histograms (JH), and calculating transfer entropies (TE). ", "caption_bbox": [73, 762, 408, 827]}, {"image_id": 7, "file_name": "227_07.png", "page": 7, "dpi": 300, "bbox": [79, 79, 773, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Side-by-side comparison of the three particle groups at three selected time steps: 70 (top-left), 170 (bottom-left), and 270 (right). The magnitudes of influence and their relations can be read from the sizes of the two metaballs. ", "caption_bbox": [73, 513, 775, 539]}, {"image_id": 8, "file_name": "227_08.png", "page": 8, "dpi": 300, "bbox": [79, 75, 407, 420], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Parameter changes on information transfer results. Top row, left to right: QI and WS with block sizes of 50\u00d750\u00d720, 20\u00d720\u00d7 20, and 10 \u00d7 10 \u00d7 20, respectively. Bottom row, left to right: YOH and YCH2O with histogram bin sizes of 128, 256, and 512, respectively. Although more refined/accurate results can be seen with a smaller block size/a larger bin size, the overall influence pattern is similar. ", "caption_bbox": [73, 419, 408, 497]}], "228": [{"image_id": 0, "file_name": "228_00.png", "page": 2, "dpi": 300, "bbox": [80, 74, 403, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) shows the time series curves representing correlation between temperature and mixture fraction, which are two key param- eters in the combustion simulation of a turbulent lifted autoignitive ethylene/air jet flame. There is a great deal of clutter and it is hard to perceive detailed correlation patterns. (b) shows the corresponding particle trajectories in the physical space, with volume rendering of the hydroperoxy field. ", "caption_bbox": [73, 267, 408, 358]}, {"image_id": 1, "file_name": "228_01.png", "page": 4, "dpi": 300, "bbox": [88, 73, 762, 379], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: This figure shows the ten different groups of time series curves generated by the automatic model-based clustering algorithm. The result provides an initial partition of the curve with much less clutter, which can facilitate the user to adjust the clustering parameters and refine the clustering process with domain knowledge. ", "caption_bbox": [73, 396, 775, 435]}, {"image_id": 2, "file_name": "228_02.png", "page": 5, "dpi": 300, "bbox": [80, 74, 403, 602], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: This figure shows six groups of curves, which are selected by the user as cluster prototypes for the re-clustering process. Com- paring to those in Figure 2 (a), (d), (e), (h) and (i), the outlier curves (in gray) in (a), (b), (c), (d) and (e) are rejected using our mouse- based picking tool. ", "caption_bbox": [73, 619, 408, 684]}, {"image_id": 3, "file_name": "228_03.png", "page": 6, "dpi": 300, "bbox": [98, 74, 752, 615], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: In this figure, (a1), (b1), (c1), (d1), (e1) and (f1) show the clustering results based on the user specified cluster prototypes; the light blue dots, calculated with the mean vector of component Gaussian models, represent the average trends of clusters. (a2), (b2), (c2), (d2), (e2) and (f2) show the particle trajectories in the physical space corresponding to (a1), (b1), (c1), (d1), (e1) and (f1) respectively. We can see that particles with distinct patterns of time series curves traverse differently in the physical space. ", "caption_bbox": [73, 632, 775, 684]}, {"image_id": 4, "file_name": "228_04.png", "page": 7, "dpi": 300, "bbox": [79, 75, 405, 534], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a1), (b1) and (c1) show the temporal correlation curves corresponding to those in Figure 4 (c1), (e1) and (f1) respectively, and the 3D time series curves are clustered into two groups (ren- dered in yellow and blue); in (a2), (b2) and (c2), the particles with the yellow or blue trajectories belong to the clusters of the same color in (a1), (b1) and (c1) ", "caption_bbox": [73, 550, 408, 628]}], "229": [{"image_id": 0, "file_name": "229_00.png", "page": 2, "dpi": 300, "bbox": [461, 74, 760, 174], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of the MEP-framebuffer. A MEP-framebuffer consists of two buffers Hmax and Zmax that, for a given viewpoint, store the maximal entropies for all pixels and the corresponding depths of the voxels with maximal entropy. ", "caption_bbox": [440, 191, 775, 243]}, {"image_id": 1, "file_name": "229_01.png", "page": 2, "dpi": 300, "bbox": [88, 74, 394, 165], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Entropy and complexity in flow fields. (a): A vector field with homogeneous flow and the polar histogram of the vector orien- tations. (b): A more complex flow field with its polar histogram. The entropies are measured from histograms of 16 bins, and thus the range is [0, log2 (16)]. The entropies for (a) and (b) are 0.38 and 3.73, respectively. ", "caption_bbox": [73, 178, 408, 256]}, {"image_id": 2, "file_name": "229_02.png", "page": 3, "dpi": 300, "bbox": [90, 74, 397, 187], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: View-dependent streamline evaluation for Tornado. (a): The initial set of streamlines where the blue and red ones have neg- ative and positive scores, respectively. (b): The streamlines with pos- itive scores. (c): The streamlines with negative scores. ", "caption_bbox": [73, 199, 408, 251]}, {"image_id": 3, "file_name": "229_03.png", "page": 3, "dpi": 300, "bbox": [464, 74, 752, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Placing streamlines using entropy density. (a): Original set of streamlines. (b): The MEP framebuffer. (c): The expected streamline density for each screen tile, which is equal to the average entropy in the corresponding tile in the MEP framebuffer. (d): Stream- line density after streamline placement. (e): The placed streamlines. Red streamlines have nonnegative scores, while blue have negative scores. ", "caption_bbox": [440, 357, 775, 448]}, {"image_id": 4, "file_name": "229_04.png", "page": 4, "dpi": 300, "bbox": [460, 76, 764, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Streamline placement using reverted order. Streamlines with lowest scores are placed first and thus important regions are occluded. Line widths are 1 in (a) to 4 in (d). ", "caption_bbox": [440, 274, 775, 313]}, {"image_id": 5, "file_name": "229_05.png", "page": 4, "dpi": 300, "bbox": [90, 88, 395, 471], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Streamline placement using different line widths. Line width changes from 1 in (a) to 4 in (d). Number of generated streamlines is 181, 85, 59 and 52, respectively. Meanwhile, streamline selection with even density. (e): 87 streamlines with width w = 6. (f) 59 stream- lines with width w = 10. The resolution of all images is 192\u00d7384 pixels and 16 \u00d7 16 tiles were used. ", "caption_bbox": [73, 484, 408, 563]}, {"image_id": 6, "file_name": "229_06.png", "page": 5, "dpi": 300, "bbox": [89, 74, 354, 211], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Streamline evaluation from a poor viewpoint for Plume. (a): The MEP framebuffer. (b): Streamlines with positive scores. Since regions of high-complexity are self-occluded, the flow in the complex regions cannot be effectively represented even after removing low- scoring streamlines. ", "caption_bbox": [73, 226, 408, 291]}, {"image_id": 7, "file_name": "229_07.png", "page": 6, "dpi": 300, "bbox": [85, 74, 772, 612], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Viewpoint selection for Tornado. The figures from left to right, respectively, represent scores for the corresponding viewpoints, the vector field, the obtained MEP framebuffer, and the result from our view-dependent streamline placement algorithm. In the leftmost column, the center of the sphere\u2019s projection encodes the score for the corresponding viewpoint. Scores are mapped from blue (low) to red (high). Figures in the top two rows show two poor viewpoints. The top row shows one of the low scoring views. The tornado is viewed from one of the sides and thus the circular pattern of the flow field is not revealed. The middle row represents another low scoring view. The tornado is viewed from the top and thus the depth cue of the flow is not revealed. Bottom row: one of the good viewpoints. ", "caption_bbox": [73, 625, 775, 703]}, {"image_id": 8, "file_name": "229_08.png", "page": 7, "dpi": 300, "bbox": [439, 83, 777, 444], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Comparison between our method (a) and the algorithm by Xu et al. [22] (b). In both cases 131 streamlines are used. Image (a) has size of 512 \u00d7 256 pixels and uses 64 \u00d7 64 tiles. Streamline width is width = 4. ", "caption_bbox": [440, 456, 775, 508]}, {"image_id": 9, "file_name": "229_09.png", "page": 7, "dpi": 300, "bbox": [93, 74, 391, 631], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Test datasets and performance (milliseconds) under differ-", "caption_bbox": [73, 792, 408, 805]}], "23": [{"image_id": 0, "file_name": "23_00.png", "page": 2, "dpi": 300, "bbox": [432, 484, 688, 648], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2. User Interaction Phases", "caption_bbox": [491, 653, 678, 668]}, {"image_id": 1, "file_name": "23_01.png", "page": 2, "dpi": 300, "bbox": [49, 289, 408, 623], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1. Gulfs of Execution and Evaluation", "caption_bbox": [116, 643, 365, 658]}, {"image_id": 2, "file_name": "23_02.png", "page": 3, "dpi": 300, "bbox": [249, 621, 371, 1006], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": " Figure 3.", "caption_bbox": [251, 589, 303, 604]}, {"image_id": 3, "file_name": "23_03.png", "page": 3, "dpi": 300, "bbox": [424, 277, 732, 511], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. Data Dimensions", "caption_bbox": [508, 533, 660, 548]}, {"image_id": 4, "file_name": "23_04.png", "page": 4, "dpi": 300, "bbox": [419, 337, 763, 400], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7. Segmented Interactivity Continuum", "caption_bbox": [457, 300, 712, 315]}, {"image_id": 5, "file_name": "23_05.png", "page": 4, "dpi": 300, "bbox": [120, 146, 326, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5. Task Dimensions", "caption_bbox": [164, 296, 316, 311]}, {"image_id": 6, "file_name": "23_06.png", "page": 5, "dpi": 300, "bbox": [423, 80, 750, 500], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10. Contextual Dimensions", "caption_bbox": [487, 517, 680, 532]}, {"image_id": 7, "file_name": "23_07.png", "page": 5, "dpi": 300, "bbox": [78, 109, 386, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8. Data & Interaction Matrix", "caption_bbox": [140, 328, 341, 343]}, {"image_id": 8, "file_name": "23_08.png", "page": 6, "dpi": 300, "bbox": [425, 438, 691, 597], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12. Output Dimensions", "caption_bbox": [498, 607, 669, 622]}, {"image_id": 9, "file_name": "23_09.png", "page": 7, "dpi": 300, "bbox": [81, 96, 401, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13. Static and Dynamic Display Interaction", "caption_bbox": [99, 304, 381, 319]}, {"image_id": 10, "file_name": "23_10.png", "page": 8, "dpi": 300, "bbox": [99, 96, 729, 829], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14. Taxonomic Framework", "caption_bbox": [316, 857, 509, 872]}], "230": [], "231": [{"image_id": 0, "file_name": "231_00.png", "page": 3, "dpi": 300, "bbox": [102, 82, 380, 243], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example field (2): (a) critical points and illuminated stream lines of vavg from section 3.2. Sources are displayed by red ellip- soids, sinks by blue elipsoids, repelling saddles by red cylinders, and attracting saddles by blue cylinders (b) sink (blue) and source (red) distributions of \u03c1v , represented as volume rendering, including inflow and outflow regions that are interpreted as sources and sinks ", "caption_bbox": [73, 256, 409, 334]}, {"image_id": 1, "file_name": "231_01.png", "page": 4, "dpi": 300, "bbox": [464, 73, 753, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Example field (2): volume renderings of corresponding co- ordinates (top, left) of the sink distributions; (top, right) of the outflow distributions; (bottom, left) of the source distributions; (bottom, right) of the inflow distributions ", "caption_bbox": [440, 333, 775, 385]}, {"image_id": 2, "file_name": "231_02.png", "page": 5, "dpi": 300, "bbox": [92, 74, 384, 216], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Example field (2): (a) uncertain saddle connectors (b) uncertain saddle connectors uncertain saddle and boundary switch connectors ", "caption_bbox": [73, 228, 408, 267]}, {"image_id": 3, "file_name": "231_03.png", "page": 5, "dpi": 300, "bbox": [459, 74, 745, 216], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Example field (2): (a) visualization of the complete topol- ogy with saddle connectors (b) inflow, ouflow regions and boundary switch connectors added to the visualization ", "caption_bbox": [440, 228, 775, 267]}, {"image_id": 4, "file_name": "231_04.png", "page": 6, "dpi": 300, "bbox": [471, 74, 747, 613], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: DNS simulation: (a) topology of the turbulent flow phe- nomenon example, described by an uncertain vector field (b) critical points and illuminated stream lines of the turbulent flow phenomenon example ", "caption_bbox": [440, 625, 775, 677]}, {"image_id": 5, "file_name": "231_05.png", "page": 7, "dpi": 300, "bbox": [444, 698, 764, 892], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Flow in the Pacific Ocean: topology of the uncertain vector field (north left) ", "caption_bbox": [440, 937, 775, 963]}, {"image_id": 6, "file_name": "231_06.png", "page": 7, "dpi": 300, "bbox": [459, 137, 759, 563], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Flow in the Pacific Ocean: topology of the uncertain vector field (north top) ", "caption_bbox": [440, 583, 775, 609]}, {"image_id": 7, "file_name": "231_07.png", "page": 8, "dpi": 300, "bbox": [146, 91, 337, 344], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Flow in the Pacific Ocean: critical points and illuminated stream lines of the average vector field ", "caption_bbox": [73, 379, 408, 405]}], "232": [{"image_id": 0, "file_name": "232_00.png", "page": 3, "dpi": 300, "bbox": [488, 67, 725, 173], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The original prism (left) unfolded into a single slice (right).", "caption_bbox": [442, 180, 773, 193]}, {"image_id": 1, "file_name": "232_01.png", "page": 3, "dpi": 300, "bbox": [96, 621, 383, 959], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Linked-view interaction diagram. The different views of the system are coupled to each other, triggering actions upon interaction, and updating the other views accordingly. ", "caption_bbox": [73, 967, 408, 1006]}, {"image_id": 2, "file_name": "232_02.png", "page": 4, "dpi": 300, "bbox": [80, 58, 767, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Our framework for interactive seismic interpretation using piecewise global energy minimization. The 3D view in (a) shows the volume alongside well positions, and a complete horizon surface. In the main interpretation view (b), the unfolded sides of a prism are shown overlaid with well logs. The slice views (c) and (d) show inline and crossline slices, respectively, (e) the timeslice view with the well positions. A horizon covering the complete volume was traced by adding prism vertices on the corners of the volume. The amplitude at the horizon vertices is plotted on the horizon using a cool to warm colormap. ", "caption_bbox": [73, 342, 775, 407]}, {"image_id": 3, "file_name": "232_03.png", "page": 5, "dpi": 300, "bbox": [80, 811, 401, 976], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Correspondence between picture elements and items in the primal and dual graph. ", "caption_bbox": [73, 984, 408, 1010]}, {"image_id": 4, "file_name": "232_04.png", "page": 6, "dpi": 300, "bbox": [88, 62, 758, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Tracing pipeline.", "caption_bbox": [359, 365, 488, 378]}, {"image_id": 5, "file_name": "232_05.png", "page": 8, "dpi": 300, "bbox": [75, 74, 405, 404], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Three horizon patches computed using our algorithm. (a), (b) and (c) show the distance in pixels from a manual trace of the same horizon. (d), (e) and (f) show detailed slice view cutouts of the surface indicated by the green boxes in (a), (b) and (c). Manual traces are in cyan, traces computed with our method in magenta. (d) shows a region of the first horizon, with > 2 pixel difference, where the manual trace is clearly better than the automatic trace, manual and automatic traces in (e) are very similar. (f) shows a part of the horizon with > 4 pixel difference. Here, the automatic trace is closer to the actual ridgeline. ", "caption_bbox": [73, 407, 408, 538]}], "233": [{"image_id": 0, "file_name": "233_00.png", "page": 1, "dpi": 300, "bbox": [82, 86, 777, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Showing all points of a large and time-dependent data set at once usually results in expensive (non-interactive) rendering, high storage requirement, and heavy occlusion. LCCVD allows to drastically reduce the amount of points very quickly using a GPU-friendly algorithm which preserves the basic structure of the data set. ", "caption_bbox": [73, 368, 775, 407]}, {"image_id": 1, "file_name": "233_01.png", "page": 3, "dpi": 300, "bbox": [76, 74, 774, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Two-dimensional point dataset represented by sites using LCCVD. Sites are depicted by black circles while points are shown as colored dots. Different colors depict that points belong to different sites. ", "caption_bbox": [73, 367, 775, 392]}, {"image_id": 2, "file_name": "233_02.png", "page": 3, "dpi": 300, "bbox": [75, 836, 409, 980], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Computation steps and control flow of LCCVD.", "caption_bbox": [100, 997, 377, 1009]}, {"image_id": 3, "file_name": "233_03.png", "page": 4, "dpi": 300, "bbox": [73, 73, 410, 248], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Overview on the LCCVD parallel point exchange. Selected connections between the three steps are indicated by dashed lines. ", "caption_bbox": [73, 263, 408, 288]}, {"image_id": 4, "file_name": "233_04.png", "page": 6, "dpi": 300, "bbox": [73, 642, 406, 916], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Laser ablation from a block of solid aluminum. (a) Extract- ing path lines using the full data set. (b) Reduced version for a single time step. (c) Extracting path lines from the reduced version. In (c) the structure of the molecule movement as well as the amount of molecules being expelled from the block is visualized more clearly. ", "caption_bbox": [73, 934, 408, 999]}, {"image_id": 5, "file_name": "233_05.png", "page": 6, "dpi": 300, "bbox": [73, 86, 408, 471], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Arnold-Beltrami-Childress flow. (a) Data set represented by a set of sites over numerous time steps. (b) Full data set for a single time step t = 90. (c) Reduced version for t = 90 sites which represents m = 512 points on average. It fully preserves the basic structure and allows better insight into the data set, e.g. the point density at the left is much lower than in the middle or on the right. (d) Reduced version based on random sampling exhibits an irregular structure that does not preserve densities and results in the loss of smaller features (e.g. thin structures on the bottom left and top right indicated by arrows). ", "caption_bbox": [73, 489, 408, 620]}, {"image_id": 6, "file_name": "233_06.png", "page": 7, "dpi": 300, "bbox": [73, 74, 778, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Performance of LCCVD for different data sets, loose con- straints l and no cmin relaxation. The top rows depicts the best (mean- ing largest) quality results in bold while the other results are given as the difference to this reference value. The bottom rows give the com- putation times in seconds. Additionally, quality results for random sampling are provided for comparison. ", "caption_bbox": [440, 912, 775, 990]}, {"image_id": 7, "file_name": "233_07.png", "page": 8, "dpi": 300, "bbox": [74, 74, 410, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Collision of methane and ethane. (a, b) Very loose or no capacity constraints lead to points that are highly overrepresented by sites which gives the false impression of a substantial amount of particles in the outer regions. (c, d) A loose constraint of l = 0.2 yields a much more genuine result. ", "caption_bbox": [73, 333, 408, 398]}], "234": [{"image_id": 0, "file_name": "234_00.png", "page": 3, "dpi": 300, "bbox": [439, 743, 780, 806], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The gray rectangle represents a treatment plan along a time-axis containing diverse clinical actions. These clinical actions are represented by diamonds. The peak of the diamond indicates the exact point in time when the actions was applied while the body of the diamond ensures the visibility of the action. In case an action is carried out over a time span, the temporal bounds are indicated by whiskers. Clinical actions that were applied to the patient but are not part of the treatment plan are laid out below the plan body. ", "caption_bbox": [440, 821, 775, 925]}, {"image_id": 1, "file_name": "234_01.png", "page": 3, "dpi": 300, "bbox": [73, 73, 778, 400], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: UI of the CareCruiser prototype. The logical view (a) communicates the logical structure of treatment plan execution by means of a flowchart-like representation [3]. The lower left part (b) displays a tree graph to visualize the hierarchical structure of treatment plans and sub-plans; the time-oriented view (c) focuses on the temporal-qualities of applied treatment plans, clinical actions, and patient parameters. We extended the time-oriented view with step-wise interactive means to explore the effects of applied treatment plans on the patient\u2019s condition. This screenshot shows one treatment plan that has been applied on three different patients (aligned vertically for comparison). The charts and treatment plans are colored according to the color scheme of the parameter values\u2019 distance to the intended value. Selecting ranges with big distance to the intended value with the range slider draws attention to critical cases and brings out the differences between the conditions of the three patients. ", "caption_bbox": [73, 414, 775, 518]}, {"image_id": 2, "file_name": "234_02.png", "page": 5, "dpi": 300, "bbox": [439, 74, 780, 171], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Selecting only extreme drops of the parameter chart with the range slider makes the coloring of minimal drops and rises of the chart disappear. ", "caption_bbox": [440, 186, 775, 225]}, {"image_id": 3, "file_name": "234_03.png", "page": 6, "dpi": 300, "bbox": [73, 74, 777, 410], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Highlighting the progress of parameter values from the initial value toward the intended value, results in getting an immediate idea of success or failure of the applied treatments. The overall success of executing the selected treatment plan at a given point in time is determined by the minimum of the success value for stabilizing the patient\u2019s tcpSO2 and the success value for stabilizing the patient\u2019s PCO2 . The low success values for stabilizing the patient\u2019s tcpSO2 lead to a low overall success for the selected treatment plan. ", "caption_bbox": [73, 424, 775, 477]}, {"image_id": 4, "file_name": "234_04.png", "page": 7, "dpi": 300, "bbox": [73, 812, 413, 894], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Collapsed patient facets. We have aligned a given treat- ment plan that has been applied to four different patients. When highlighting the parameter values\u2019 progress from the initial value and filtering for parameter values within the intended range (blue) one can still tell that the treatment plan succeeded in stabilizing the val- ues of the first and third patient while failed for the second and fourth patient. ", "caption_bbox": [73, 909, 408, 1000]}, {"image_id": 5, "file_name": "234_05.png", "page": 7, "dpi": 300, "bbox": [73, 73, 414, 435], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Revealing the delayed drop of the patient\u2019s tcpSO2 when applying the clinical action \u2018reduce the FiO2 when tcpSO2 rises above 92%\u2019. All applications of this action were aligned vertically along the black line; the negative slopes of tcpSO2 were highlighted. Dragging the focus window over the time span after applying the action reveals a vertical turquoise pattern (drops of the tcpSO2 curve) with some delay to the application of the action. ", "caption_bbox": [73, 449, 408, 540]}], "235": [{"image_id": 0, "file_name": "235_00.png", "page": 1, "dpi": 300, "bbox": [80, 86, 427, 497], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 1. (a) NNG draws neurons using tracing lines", "caption_bbox": [142, 496, 387, 510]}, {"image_id": 1, "file_name": "235_01.png", "page": 2, "dpi": 300, "bbox": [443, 636, 760, 974], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 2. NNG architecture overview", "caption_bbox": [526, 981, 695, 995]}, {"image_id": 2, "file_name": "235_02.png", "page": 3, "dpi": 300, "bbox": [430, 78, 778, 604], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 3. 3D Neuron Image Database", "caption_bbox": [474, 619, 648, 633]}, {"image_id": 3, "file_name": "235_03.png", "page": 4, "dpi": 300, "bbox": [69, 443, 395, 611], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 4. Render of the terminals of dTdc2 in point clouds. The two central bands from the fan-shaped body are easily seen. ", "caption_bbox": [69, 610, 385, 637]}, {"image_id": 4, "file_name": "235_04.png", "page": 4, "dpi": 300, "bbox": [440, 387, 591, 523], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 6. Query UI", "caption_bbox": [474, 522, 554, 536]}, {"image_id": 5, "file_name": "235_05.png", "page": 4, "dpi": 300, "bbox": [69, 648, 396, 858], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 5. Terminal Density Map. The sphere size represents the density at the location, click the sphere to query neurons ", "caption_bbox": [69, 857, 385, 884]}, {"image_id": 6, "file_name": "235_06.png", "page": 5, "dpi": 300, "bbox": [443, 78, 764, 656], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 8.", "caption_bbox": [580, 655, 613, 669]}, {"image_id": 7, "file_name": "235_07.png", "page": 5, "dpi": 300, "bbox": [83, 76, 405, 678], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 7.", "caption_bbox": [181, 677, 214, 691]}, {"image_id": 8, "file_name": "235_08.png", "page": 6, "dpi": 300, "bbox": [75, 78, 765, 542], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 9. The sequences for the Innervation query operation.", "caption_bbox": [278, 541, 566, 555]}, {"image_id": 9, "file_name": "235_09.png", "page": 8, "dpi": 300, "bbox": [73, 75, 777, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 10. Many long range commissural tr   actsmaybef    oundbet  weenmedul   l                                                                              aswi ththe\u201c  across\u201dsearch( 9(a)) on two sides of the Droso brain.Thedor  salmostonemaybesel        ect edbyr  estri                                                        cti                                                          ngt he\u201c acr                                                                    oss\u201dboxandt    henneur   onsconnect edthr oughi tsterminalsmay be f and selectively visualized in the viewer (9(b)). Blue cubes represent the connection sites of the commissural neuron with other neurons. ", "caption_bbox": [80, 337, 746, 377]}], "236": [{"image_id": 0, "file_name": "236_00.png", "page": 2, "dpi": 300, "bbox": [73, 239, 410, 474], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Our sampling scheme consists of (1) selecting important samples from the volume, (2) choosing sample pairs for distance matrix computation, and (3) approximating volume-based correlation with sample-based correlation. The three images on the right are the sample selection and correlation classification results on a synthe- sized time-varying data set. ", "caption_bbox": [73, 477, 408, 555]}, {"image_id": 1, "file_name": "236_01.png", "page": 2, "dpi": 300, "bbox": [73, 74, 777, 183], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The major steps of our sampling-based correlation classification. Domain knowledge about important regions is utilized for sample selection. A succinct visualization is achieved through data classification based on correlation distance. ", "caption_bbox": [73, 188, 775, 214]}, {"image_id": 2, "file_name": "236_02.png", "page": 2, "dpi": 300, "bbox": [456, 240, 761, 646], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Sample selection and ordering for the climate data set. (a) the probability functions used for latitude and depth are plat (a Gaussian function) and pdep (an exponential function), respectively. The probability assigned to a voxel is plat \u00d7 pdep . (b) the 1D Hilbert curve traversal order for 2,000 selected samples (long edges across oceans are because continents are not sampled). We order 3D sam- ples along the two axes of the distance matrix so that spatially close 3D samples are likewise close along the 1D axis. ", "caption_bbox": [440, 647, 775, 752]}, {"image_id": 3, "file_name": "236_03.png", "page": 4, "dpi": 300, "bbox": [79, 76, 775, 232], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Iterative update of the distance map. The radius of a disk ri j for the sample pair (i, j) is proportional to their distance D(i, j). This solution allows us to select more sample pairs from regions closer to dissimilar pairs and less from regions closer to similar pairs. After distance calculation, we use the Delauney triangulation to interpolate the distance values for all the sample pairs. ", "caption_bbox": [73, 236, 775, 275]}, {"image_id": 4, "file_name": "236_04.png", "page": 4, "dpi": 300, "bbox": [79, 291, 772, 476], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) to (d) show the distance map with increasing numbers of sample pairs selected. The map is 2, 0002 and there are 2,001,000 pairs in total. As more sample pairs are selected, new pairs would be more likely selected from regions closer to dissimilar pairs. The distance calculation is based on the entire temperature self-correlation volumes given a pair of reference locations. To generate the distance map, we first apply the Delaunay triangulation to the selected sample pairs, then interpolate the distance values within each triangle. ", "caption_bbox": [73, 478, 775, 532]}, {"image_id": 5, "file_name": "236_05.png", "page": 5, "dpi": 300, "bbox": [82, 74, 768, 413], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Timing and error comparison for the combustion and climate data sets with different numbers of samples selected. (a) and (b) are based on the computation of mixture fraction self-correlation, and (c) and (d) are base on the computation of salinity self-correlation. The \u201cground-truth\u201d references in error comparison for (a)-(d) are 10,000, 4,000, 2,000, and 4,000 sample voxels, respectively. Furthermore, (a) uses volume-based calculation while (b)-(d) use sample-based calculation as the reference. ", "caption_bbox": [73, 420, 775, 472]}, {"image_id": 6, "file_name": "236_06.png", "page": 6, "dpi": 300, "bbox": [103, 74, 747, 382], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Clustering of the sample voxels of the climate data set based on the correlation distance. All use five clusters. Notice that for correlation classification, the salinity self-correlation is more sensitive to the number of time steps chosen than the temperature and salinity cross-correlation. ", "caption_bbox": [73, 384, 775, 410]}, {"image_id": 7, "file_name": "236_07.png", "page": 7, "dpi": 300, "bbox": [138, 74, 712, 454], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Clustering of the sample voxels based on the correlation distance. The temperature self-correlation is computed over 100 time steps. Four reference locations near the equator are highlighted in the spatial view. Their corresponding correlation volumes are displayed. A is on 100\u25e6 W, B is on 140\u25e6 W, C is on 150\u25e6 E, and D is on 120\u25e6 E. A and B are drawn from the same cluster, while C and D are drawn from different clusters. We can observe that the correlation volumes of A and B are similar, while the correlation volumes of C and D are dissimilar. ", "caption_bbox": [73, 460, 775, 512]}, {"image_id": 8, "file_name": "236_08.png", "page": 8, "dpi": 300, "bbox": [456, 74, 761, 480], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Clustering of the sample voxels of the combustion data set based on the correlation distance for the mixture fraction self- correlation. All use 11 clusters. (a) shows our \u201cground truth\u201d with 10,000 samples on a 2D slice. (b) shows the clustering of a subset of 1,000 samples. (c) shows the classification result with 4,000 samples of the 3D volume. ", "caption_bbox": [440, 481, 775, 559]}, {"image_id": 9, "file_name": "236_09.png", "page": 8, "dpi": 300, "bbox": [89, 75, 394, 498], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Sample selection and ordering for a slice of the combustion data set. (a) voxels closer to the main flame structure (denoted by the two red dashed sidelines) are more important and are thus more likely to be sampled than voxels farther away. (b) shows the 1D Z- curve traversal order for 1,000 selected samples. ", "caption_bbox": [73, 500, 408, 565]}], "237": [{"image_id": 0, "file_name": "237_00.png", "page": 1, "dpi": 300, "bbox": [76, 86, 778, 407], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Volume visualization of multivariate data (Hurricane Isabel) with our proposed interface of transfer function design. (a) Multidimensional scaling plots are embedded in the parallel coordinates to facilitate feature selection without context switching. (b) Corresponding rendering result with the TF specified in (a). ", "caption_bbox": [73, 420, 775, 459]}, {"image_id": 1, "file_name": "237_01.png", "page": 2, "dpi": 300, "bbox": [442, 612, 774, 832], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Algorithm overview of the proposed TF design system for multivariate volume data sets. A multivariate volumetric data set is first preprocessed with level-of-detail representation before rendered in the PCP and MDS plots. Users interact with the plots and classify features of the volume data. TFs then can be constructed based on the user clustering results. Further interaction can also be performed on the rendered images, and fed back to the TF design. ", "caption_bbox": [440, 850, 776, 941]}, {"image_id": 2, "file_name": "237_02.png", "page": 3, "dpi": 300, "bbox": [448, 76, 768, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: User interactions on direct volume rendering view. The green colored TF component is highlighted after a sketch on the ren- dering view. ", "caption_bbox": [440, 265, 775, 304]}, {"image_id": 3, "file_name": "237_03.png", "page": 3, "dpi": 300, "bbox": [81, 534, 419, 741], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Smooth linkages between the continuous PCP and the MDS plots: (a) the linkage of the whole domain; (b) the local shape of the linkage when a small set of samples is shown. ", "caption_bbox": [73, 754, 408, 793]}, {"image_id": 4, "file_name": "237_04.png", "page": 4, "dpi": 300, "bbox": [459, 74, 758, 192], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Result comparisons with linear and logarithmic tone- mapping: (a) pseudo color and the colormap on [0, 1]; (b) linear; (c) logarithmic. ", "caption_bbox": [440, 204, 775, 243]}, {"image_id": 5, "file_name": "237_05.png", "page": 4, "dpi": 300, "bbox": [81, 259, 402, 471], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The comparisons of the adaptive PCP rendering at different error level: (a) 5%, (c) 10%, (e) 15%. The error images of (c) to (a), (e) to (a) are shown in (d) and (f) respectively, with pseudo colormap (b). ", "caption_bbox": [73, 484, 408, 536]}, {"image_id": 6, "file_name": "237_06.png", "page": 5, "dpi": 300, "bbox": [439, 75, 776, 210], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Two methods of user selection on projection plot: (a) the lasso tool, circling a group of points explicitly; (b) the magic wand tool, clicking on a seed position, and the selection is made by automatic diffusion based on the point cloud distribution as the corresponding height map shown in (c). ", "caption_bbox": [440, 226, 775, 291]}, {"image_id": 7, "file_name": "237_07.png", "page": 5, "dpi": 300, "bbox": [73, 215, 410, 385], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Rotation correction for the Pivot MDS results. The weight- ings modify the distance metric of the MDS, thus adjusting the MDS layout. The weighting of dimension \u201cTemperature\u201d is set to 30% in (a), and then it rises to 35% in (b) and (d), 40% in (c) and (e). MDS layout is flipped randomly with traditional methods as shown in (b) and (c). Sequence (a), (d), (e) keeps coherence with our rotation correction algorithm. ", "caption_bbox": [73, 401, 408, 492]}, {"image_id": 8, "file_name": "237_08.png", "page": 6, "dpi": 300, "bbox": [73, 696, 411, 811], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Different MDS layouts of Isabel data embedded in the PCP. The impact of each dimension is indicated by the small round widget at the bottom of each layout. ", "caption_bbox": [73, 825, 408, 864]}, {"image_id": 9, "file_name": "237_09.png", "page": 6, "dpi": 300, "bbox": [447, 84, 769, 403], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Atmospheric data visualization results with decomposed TFs in Figure 1(a). Each color represent a specific feature cluster. ", "caption_bbox": [440, 416, 775, 442]}, {"image_id": 10, "file_name": "237_10.png", "page": 7, "dpi": 300, "bbox": [81, 600, 419, 961], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Multifield Data: (a) the volume rendering result; (b) the corresponding TF. ", "caption_bbox": [73, 974, 408, 1000]}, {"image_id": 11, "file_name": "237_11.png", "page": 7, "dpi": 300, "bbox": [81, 74, 418, 412], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Combustion simulation data (4 dimensions): (a) the vol- ume rendering result; (b) the corresponding TF. ", "caption_bbox": [73, 424, 408, 450]}], "238": [{"image_id": 0, "file_name": "238_00.png", "page": 1, "dpi": 300, "bbox": [181, 86, 671, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Three subsequent screenshots as made during the usage of our image-based volume navigation metaphor. Without changing the navigation mode, the user is able to inspect the data set in a behavior similar to a trackball and can also fly through internal structures when a collision detection is present. To support the spatial-awareness, appropriate thumbnails are displayed. ", "caption_bbox": [73, 362, 775, 401]}, {"image_id": 1, "file_name": "238_01.png", "page": 4, "dpi": 300, "bbox": [137, 73, 347, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The workflow of our navigation system, integrated into a volume rendering system. The same raycaster is executed twice, one rendering is displayed on the canvas while the other is analyzed to map the users input to camera movement. ", "caption_bbox": [73, 392, 408, 444]}, {"image_id": 2, "file_name": "238_02.png", "page": 4, "dpi": 300, "bbox": [148, 824, 336, 947], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Spherical entry-exit points outside and inside the proxy geometry. The entry points for raycasting from inside the proxy ge- ometry are constant because the rays start at the camera position. ", "caption_bbox": [73, 961, 408, 1000]}, {"image_id": 3, "file_name": "238_03.png", "page": 4, "dpi": 300, "bbox": [440, 800, 777, 934], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: We distinguish between three basic camera movements when dragging the mouse: Rotating, Strafing and Panning. By ana- lyzing the depth image we dynamically decide which movement the user wants to perform. ", "caption_bbox": [440, 948, 775, 1000]}, {"image_id": 4, "file_name": "238_04.png", "page": 5, "dpi": 300, "bbox": [439, 868, 777, 960], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Based on saliency and the overall occlusion our technique overlays a rear preview and an overview map, respectively. ", "caption_bbox": [440, 975, 775, 1000]}, {"image_id": 5, "file_name": "238_05.png", "page": 5, "dpi": 300, "bbox": [139, 825, 344, 960], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Expected camera movement for two simple cases: Rotating (a) and Panning (b). ", "caption_bbox": [73, 975, 408, 1000]}, {"image_id": 6, "file_name": "238_06.png", "page": 5, "dpi": 300, "bbox": [490, 76, 726, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Strafing as combination of rotating and panning, with (a) and without (b) distance adjustment. ", "caption_bbox": [440, 234, 775, 259]}, {"image_id": 7, "file_name": "238_07.png", "page": 6, "dpi": 300, "bbox": [439, 73, 778, 172], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The results of the questionnaire of the conducted user study, which we have evaluated on a seven point Likert scale. Ques- tions 6-12 (red) are about specific aspects of our technique and the participants were asked if they percieved these as useful or good solutions to the problem. ", "caption_bbox": [440, 186, 775, 251]}, {"image_id": 8, "file_name": "238_08.png", "page": 6, "dpi": 300, "bbox": [106, 817, 377, 936], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The previews are generated from the spherical image (left) without performing additional raycasting passes. The bottom preview (right) is reconstructed from the lower part of the spherical image without distortions. ", "caption_bbox": [73, 951, 408, 1003]}], "239": [{"image_id": 0, "file_name": "239_00.png", "page": 1, "dpi": 300, "bbox": [81, 85, 769, 424], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: 2048x2048x1920 Richtmyer Meshkov instability CFD simulation, rendered at full data resolution (without LOD) into a 2048x768 frame buffer at 5.7 fps on a dual 4-core 2.67 GHz Intel Core i7 (X5550) workstation with 32 GB RAM, outperforming an out-of-core renderer on a NVIDIA 285GTX GPU by 80x. ", "caption_bbox": [73, 427, 775, 448]}, {"image_id": 1, "file_name": "239_01.png", "page": 2, "dpi": 300, "bbox": [440, 74, 772, 351], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of our system and algorithm pipeline.", "caption_bbox": [496, 350, 716, 360]}, {"image_id": 2, "file_name": "239_02.png", "page": 3, "dpi": 300, "bbox": [74, 67, 406, 155], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Coherent BVH traversal of interior nodes. Left: the first active ray (or SSE packlet) in a packet is speculatively tested against a child node bounding box. Cen- ter: if this test fails, an interval arithmetic frustum test tests whether we can discard the entire packet. Right: only then must we test all rays (packlets) against the node. By incrementing the \u201cfirst active\u201d ray for this level of the traversal stack, we can avoid redundant intersection tests. ", "caption_bbox": [73, 156, 408, 221]}, {"image_id": 3, "file_name": "239_03.png", "page": 4, "dpi": 300, "bbox": [121, 58, 359, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The implicit BVH can be heuristically pruned using the preintegrated transfer function, resulting in a smaller subtree. Similarly, it can detect constant subvolumes and perform less expensive DVR integration. ", "caption_bbox": [73, 215, 408, 247]}, {"image_id": 4, "file_name": "239_04.png", "page": 5, "dpi": 300, "bbox": [77, 58, 770, 448], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Small and moderate-size data benchmarked with various CPU and GPU volume renderers. Results with our CPU method using the BVH are in bold. Lighting (unlit (u), diffuse (d), or Phong (p)) is indicated next to the dataset name. ", "caption_bbox": [73, 447, 775, 468]}, {"image_id": 5, "file_name": "239_05.png", "page": 6, "dpi": 300, "bbox": [73, 898, 407, 979], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Sampling rate. Left to right, with differential sampling steps of rda=2\u22128 , 2\u22127 , 2\u22126 , and 2\u22125 , rendering at 6.2, 10.0, 11.1, and 15.8 fps, respectively (2k3 Richtmyer- Meshkov at 5122 on the 8-Core i7). 2\u22127 is qualitatively comparable to the Nyquist rate (>2 samples per voxel). ", "caption_bbox": [73, 978, 408, 1024]}, {"image_id": 6, "file_name": "239_06.png", "page": 6, "dpi": 300, "bbox": [75, 59, 776, 444], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: CPU time profile for individual algorithmic stages of the naive (gcc) and hand- tuned (sse) methods, rendering the heptane scene from Figure 5. ", "caption_bbox": [440, 1006, 775, 1027]}], "24": [{"image_id": 0, "file_name": "24_00.png", "page": 3, "dpi": 300, "bbox": [112, 822, 761, 884], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1. Class diagram prior to application of visualization techniques.", "caption_bbox": [245, 889, 645, 902]}, {"image_id": 1, "file_name": "24_01.png", "page": 3, "dpi": 300, "bbox": [125, 918, 726, 984], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2. Class diagram following application of focus + context techniques.", "caption_bbox": [234, 991, 655, 1004]}, {"image_id": 2, "file_name": "24_02.png", "page": 4, "dpi": 300, "bbox": [479, 507, 713, 652], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5. Class diagram with focus + context applied.", "caption_bbox": [438, 667, 734, 680]}, {"image_id": 3, "file_name": "24_03.png", "page": 4, "dpi": 300, "bbox": [458, 197, 715, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. Initial class diagram.", "caption_bbox": [501, 351, 672, 364]}, {"image_id": 4, "file_name": "24_04.png", "page": 5, "dpi": 300, "bbox": [126, 294, 401, 421], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6. Class diagram after phase 1 of layout                    algorithm. ", "caption_bbox": [132, 443, 395, 471]}], "240": [{"image_id": 0, "file_name": "240_00.png", "page": 1, "dpi": 300, "bbox": [73, 86, 777, 411], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) 3D visualization of a CT data set. (b) Automatically detected cervical vessels visualized with size-based color-coding (thick vessels in red, thin ones in blue). (c) Vessel lumen of the whole vasculature with halos (red) and context (Maximum Intensity Projection), rendered by the proposed Centerline Reformation technique. (d) Automatically detected vessels (blue). (e) Vessels filtered according to length and thickness in order to select specific vessels (orange). (f) Carotis delineated with halos (red) and embedded into a context (Maximum Intensity Projection). ", "caption_bbox": [73, 416, 775, 468]}, {"image_id": 1, "file_name": "240_01.png", "page": 2, "dpi": 300, "bbox": [510, 826, 706, 944], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Comparison between CPR using parallel scanlines (left) and normal vectors (center) as lines-of-interest. The proposed CR technique spreads wavefronts from the centerline outwards (right). ", "caption_bbox": [440, 961, 775, 1000]}, {"image_id": 2, "file_name": "240_02.png", "page": 3, "dpi": 300, "bbox": [458, 76, 760, 528], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Workflow of the vessel-detection pipeline illustrated on an artificial data set. The arrows on the right side indicate the auto- matically processed parts of the pipeline. In the preprocessing step the data set is converted to the desired representation and vessels might be initially enhanced using a windowing function. During scale- space analysis, the Gaussian and Hessian filters followed by HT are applied for each scale in parallel (three scales are illustrated here). After combining all scales, the vessel centerlines are detected by skeletonization and finally converted into a graph representation. ", "caption_bbox": [440, 548, 775, 665]}, {"image_id": 3, "file_name": "240_03.png", "page": 4, "dpi": 300, "bbox": [91, 77, 393, 496], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Workflow of CR. The vasculature is projected into the im- age space. Then the lumen is rendered and optionally enveloped by halos to enhance depth perception. The final image is composed by adding a context visualization if desired. ", "caption_bbox": [73, 516, 408, 568]}, {"image_id": 4, "file_name": "240_04.png", "page": 5, "dpi": 300, "bbox": [441, 812, 776, 945], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Illustration of pixels spreading to their neighbors using 4-neighborhood and Manhattan metric. The numbers indicate the vessel-radius and interpolated pixels are outlined in yellow. ", "caption_bbox": [440, 961, 775, 1000]}, {"image_id": 5, "file_name": "240_05.png", "page": 5, "dpi": 300, "bbox": [80, 74, 403, 164], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison when using the arc-length parametrization or depth buffering for visibility. Since grey value gradients are stored in the data, they should be clearly reflected in the lumen visualiza- tion. Artifacts (highlighted with yellow circles) occur in (a) because pixels are never changed and in (b) since too many pixels are falsely overwritten. (c) shows the result of our proposed method. ", "caption_bbox": [73, 167, 408, 245]}, {"image_id": 6, "file_name": "240_06.png", "page": 5, "dpi": 300, "bbox": [86, 858, 392, 944], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Distances dgraph between two points along the projected vessel graph G2D , which consists of two disconnected graphs (high- lighted in green and orange). ", "caption_bbox": [73, 960, 408, 1000]}, {"image_id": 7, "file_name": "240_07.png", "page": 6, "dpi": 300, "bbox": [157, 713, 325, 775], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Configuration of the vessel-detection pipeline for several pro- cessed data sets. Timings are given for a whole run. ", "caption_bbox": [440, 780, 775, 805]}, {"image_id": 8, "file_name": "240_08.png", "page": 7, "dpi": 300, "bbox": [441, 232, 776, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Evaluation of CR with 34 questions. A positive score favours CR, whereas a negative one CPR or mpCPR. The bullets show the average and the error indicators the deviation. ", "caption_bbox": [440, 317, 775, 356]}, {"image_id": 9, "file_name": "240_09.png", "page": 7, "dpi": 300, "bbox": [439, 73, 776, 185], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Pulmonary data set with an embolism highlighted with yellow circles. The lumen is rendered with mpCPR (a) and CR (b). ", "caption_bbox": [440, 190, 775, 215]}, {"image_id": 10, "file_name": "240_10.png", "page": 7, "dpi": 300, "bbox": [73, 645, 409, 791], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Comparison between mpCPR (a) and CR (b) presented on several artificial helices. ", "caption_bbox": [73, 796, 408, 821]}, {"image_id": 11, "file_name": "240_11.png", "page": 7, "dpi": 300, "bbox": [73, 360, 411, 571], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Data set with a bypass when the aorta splits into left and right (occluded, shown as dashed line) femoral arteries. The red lines indicate the direction of the blood flow. (a) mpCPR cannot visualize the bypass properly. (b) CR clearly delineates it. ", "caption_bbox": [73, 577, 408, 629]}, {"image_id": 12, "file_name": "240_12.png", "page": 7, "dpi": 300, "bbox": [73, 73, 411, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparison between mpCPR (a) and CR (b) of the aorta splitting into femoral arteries left and right. The discontinuities (white arrows) result from the fact that the distance dgraph is used to deter- mine whether a pixel is interpolated during spreading. However, they occur only in the surrounding parts and do not affect the lumen itself. The bright calcification (yellow arrow) is correctly shown by CR, be- cause the depth of this region is obtained by wavefronts and not by horizontal lines-of-interest as in mpCPR. ", "caption_bbox": [73, 241, 408, 345]}], "241": [{"image_id": 0, "file_name": "241_00.png", "page": 2, "dpi": 300, "bbox": [456, 73, 761, 179], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Left: Two time steps of a 2D VOF simulation with possible topology change. The interface lies in the region with a volume frac- tion between 0 and 1. Right: Four reconstructed interfaces for the highlighted cell with f = 0.5. One fluid is shown in blue, the other in white. All four extracted interfaces are exact with respect to recon- structed fluid volumes. An infinite number of other representations exist that reconstruct fluid volumes correctly, leaving the true inter- face shape and topology unknown. ", "caption_bbox": [440, 194, 775, 298]}, {"image_id": 1, "file_name": "241_01.png", "page": 3, "dpi": 300, "bbox": [84, 521, 411, 921], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of two consecutive 2D material interfaces. The three points A, B,C are representatives of stable, detaching, and at- taching flow particles. A remains on the interface and can be used for parametrization. B detaches from the interface, whereas C attaches to the interface in the second time step. ", "caption_bbox": [73, 935, 408, 1000]}, {"image_id": 2, "file_name": "241_02.png", "page": 4, "dpi": 300, "bbox": [493, 136, 725, 487], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Left column: Images of flattened material interface mesh before advection (top) and after advection without and with seam treatment. Parametrization texture is shown in the background. Large triangles across parameter space indicate invalid seam treat- ment. Right column: Material interface mesh before advection (top) and after advection without and with seam treatment. Close ups of parametrization seams reveal artifacts if discontinuities are not re- spected during the parametrization process. ", "caption_bbox": [440, 501, 775, 605]}, {"image_id": 3, "file_name": "241_03.png", "page": 5, "dpi": 300, "bbox": [89, 74, 394, 168], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Left: A triangle (black) stretches incorrectly over a large re- gion of parameter space, as it crosses the periodic boundary (blue). From left to right: Edge bisection with point-location in parameter space finds intersections between triangle edges and parametriza- tion seams that allow retriangulation of the mesh (gray polygons). ", "caption_bbox": [73, 183, 408, 248]}, {"image_id": 4, "file_name": "241_04.png", "page": 5, "dpi": 300, "bbox": [73, 434, 411, 508], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Each edge of a triangle may be cut by a parametrization seam. Splitting and reparametrization of the new triangles is straight- forward for the one and two cuts cases (examples of seam locations shown in blue). In the three-cut case shown on the right, we compute parameter values of the third vertex of the middle triangle by using known parameter values of the remaining two vertices together with angle informations in the triangle. ", "caption_bbox": [73, 522, 408, 613]}, {"image_id": 5, "file_name": "241_05.png", "page": 7, "dpi": 300, "bbox": [115, 75, 737, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) Visualization of three time steps per column for all simulations. From left to right: Dam-break simulation with volume-rendered instability density in the last frame. Fluid-drop simulation before, immediately before and shortly after impact with the domain boundary drawn without instabilities. Rayleigh-Taylor Instability with density based instability visualization. A close-up of several Rayleigh-Taylor fingers reveals stable (consistent texturing), detachment (red detachment particles), and attachment (no parameterization) behavior. (b) Full resolution and parametrization transfer with low resolution time surface. The contrast-enhanced difference image shows changes in approximation accuracy. ", "caption_bbox": [73, 407, 775, 472]}, {"image_id": 6, "file_name": "241_06.png", "page": 7, "dpi": 300, "bbox": [441, 497, 776, 616], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: This image shows the flattened interface meshes in the foreground of a parametrization texture for three different time steps. Detachment causes topology changes in the parameter space of in- dividual interfaces. Parameter space seams are treated correctly by the proposed method. ", "caption_bbox": [440, 630, 775, 695]}, {"image_id": 7, "file_name": "241_07.png", "page": 7, "dpi": 300, "bbox": [74, 497, 410, 738], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) Visualization of the fluid-drop interface after impact, (b) with density-based visualization and (c) splatting. (d) shows a later time step with instability splatting, demonstrating the spreading of detachment situations over large regions of the data set. ", "caption_bbox": [73, 752, 408, 804]}, {"image_id": 8, "file_name": "241_08.png", "page": 8, "dpi": 300, "bbox": [73, 73, 410, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Total run-times in minutes for surface advection, stability classification, and instability advection. Medium and low detail com- putations include time for surface simplification. ", "caption_bbox": [73, 385, 408, 424]}], "242": [{"image_id": 0, "file_name": "242_00.png", "page": 1, "dpi": 300, "bbox": [163, 120, 686, 445], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Ray-casting based visualization of eight proteins represented by the solvent excluded surfaces (SES). Surfaces are defined by implicit functions computed locally and without performing any precomputation steps. The proteins contain 3023 (a), 2872 (b), 2820 (c), 3346 (d), 12530 (e), 12555 (f), 1718 (g) and 14744 (h). Small discontinuities are caused by the precision parameter that accepts a close vicinity of the 0 iso-level of the implicit function. ", "caption_bbox": [73, 464, 775, 516]}, {"image_id": 1, "file_name": "242_01.png", "page": 2, "dpi": 300, "bbox": [75, 471, 408, 662], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An example of a molecular surface. The solvent excluded surface (union of full circles and their toroidal interconnections) is formed by rolling a ball (blue circle) on van der Waals spheres while the center lies on the boundary of solvent accessible surface (union of dashed circles). The SES representation depicts a single residual sequence of proteinase 3 (Pr3) peptide containing 360 atoms. The SES surface can be be described by three types of patches, the con- vex spherical one (green), the concave spherical one (blue) and the toroidal one (red). ", "caption_bbox": [73, 686, 409, 804]}, {"image_id": 2, "file_name": "242_02.png", "page": 4, "dpi": 300, "bbox": [123, 149, 360, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Forming the point set Sp . a) Out of all the points, the set Sp contains those which belong to the area of influence of the point p (full circles). b) The point p lies above the R distance from the atom c2 , but it might still participate in forming the final iso-surface. ", "caption_bbox": [73, 277, 408, 330]}, {"image_id": 3, "file_name": "242_03.png", "page": 4, "dpi": 300, "bbox": [491, 474, 723, 667], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A 2D version of the toroidal implicit function with rendered iso-levels. The function returns correct distance values from the sur- face up to R distance from the surface (arrows). ", "caption_bbox": [440, 685, 775, 724]}, {"image_id": 4, "file_name": "242_04.png", "page": 5, "dpi": 300, "bbox": [440, 73, 775, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Forming the toroidal patch for two atoms. a) The toroidal patch (red) lies only in the area marked by the blue triangle. b) In order to determine that the given point p belongs to this area, we per- form (1) projection of B p to iso-surfaces g1 (p1 ) = 0 and g2 (p2 ) = 0 and (2) evaluation of both functions for opposite points. c) In a case that the point p lies inside the toroidal section, we retrieve the intersection point x1\u22122 of g1 and g2 using the fact that the vector (x1\u22122 \u2212 p) lies in the plane perpendicular to both gradients \u2207g1 (p) and \u2207g2 (p). d) The visualization of the toroidal patch. The atoms are close enough to get the continuous iso-surface. e) Self-intersection can occur when the solvent is thicker than the height of the actual toroidal section. f) The visualization of the self-intersected toroidal patch. ", "caption_bbox": [440, 406, 775, 563]}, {"image_id": 5, "file_name": "242_05.png", "page": 6, "dpi": 300, "bbox": [440, 460, 777, 558], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparison of the SES visual quality when having set the parameter kmax = 5 (left), kmax = 10 (middle) and kmax = 15 (right). Note that there are only negligible improvements between the last two. ", "caption_bbox": [440, 572, 775, 611]}, {"image_id": 6, "file_name": "242_06.png", "page": 6, "dpi": 300, "bbox": [73, 145, 409, 401], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The formation of the spherical triangle patch. a) Evaluation of the predicate B1\u22122 . The point x1\u22122 , representing the intersection of g1 and g2 , must lie inside the area of influence of g3 . Therefore the area (the blue ellipse) for x1\u22122 estimation is extended to all the points that fulfil g1 (p) \u2265 \u2212R \u2227 g2 (p) \u2265 \u2212R. b) Once the intersection point x1\u22122 is computed, it is evaluated against the third extended function g3 (x1\u22122 ) \u2265 0 (Eq. 14). c) When using the original predicates artifacts can appear caused by the fact that the intersection point xi\u2212 j lies too far away from the point ck . d) The example of the corrected predicate B , where the cracks disappeared. e) The self-intersection issue is solved implicitly using the property of the point x1\u22122\u22123 . f) An example of the SES, defined by (18), composed of 12 atoms. ", "caption_bbox": [73, 416, 408, 573]}, {"image_id": 7, "file_name": "242_07.png", "page": 7, "dpi": 300, "bbox": [139, 148, 344, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Ray-casting a simplified scene. We perform steps of the size of fSES , in order not to skip the existing iso-surface. ", "caption_bbox": [73, 306, 408, 333]}], "243": [{"image_id": 0, "file_name": "243_00.png", "page": 1, "dpi": 300, "bbox": [73, 86, 778, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Molecular dynamics simulation of 2 million molecules forming a liquid layer of argon in vacuum, which gets ripped apart by its vapor pressure. The time steps shown are 5, 15, and 30 (from left to right). The lower row shows na\u0131\u0308ve ray casting of spheres for the individual molecules. The upper row shows the same rendering enhanced with our object-space ambient occlusion. Especially the break-up of the structure in time steps 5 and 15 is clearly visible. ", "caption_bbox": [73, 419, 775, 471]}, {"image_id": 1, "file_name": "243_01.png", "page": 2, "dpi": 300, "bbox": [439, 74, 777, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A maltoporin protein (PDB-ID: 1AF6, 10 000 atoms); Left: our object space ambient occlusion method; Right: depth darken- ing [16]; Depth darkening emphasizes the three channels but is not able to extract the more shallow structures on top of the protein, un- like our technique. ", "caption_bbox": [440, 237, 775, 302]}, {"image_id": 2, "file_name": "243_02.png", "page": 3, "dpi": 300, "bbox": [439, 74, 776, 206], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Zoomed in view into a small test data set. Left: the na\u0131\u0308ve rendering. Since the spheres are overlapping in this test data set the depth structure is not visible. Especially for the marked sphere it is not obvious how much this sphere intersects with the row of three spheres in front. Middle: the ambient occlusion factors based on the neighborhood. Right: the final image using Phong shading and ambient occlusion. The position of the marked sphere is now clearly behind all other spheres. ", "caption_bbox": [440, 217, 775, 321]}, {"image_id": 3, "file_name": "243_03.png", "page": 5, "dpi": 300, "bbox": [83, 74, 774, 210], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Zoomed in view of the exp2mill data set rendered with different density volume resolutions: (from left to right) 4 \u00d7 32 \u00d7 4, 8 \u00d7 64 \u00d7 8, 16 \u00d7 128 \u00d7 16 (optimal setting, which is used in all other figures showing this data set), 32 \u00d7 256 \u00d7 32, and 64 \u00d7 512 \u00d7 64. Smaller caves, like in the upper bulk, are not captured by too coarse volumes, while with volumes with a too high resolution have too few atoms contributing to a density cell, rendering the argumentation of low frequencies in section 3 invalid and resulting in visual clutter. ", "caption_bbox": [73, 221, 775, 273]}, {"image_id": 4, "file_name": "243_04.png", "page": 7, "dpi": 300, "bbox": [73, 74, 762, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison between local lighting (a, e), ray tracing (b, f), screen-space ambient occlusion (c, g), and our object-space ambient occlusion method (d, h); The ray traced images were created by Tachyon [24] as ground truth. For the screen-space ambient occlusion we implemented the method presented by Kajalin [13]. As observable, our object-space ambient occlusion technique creates comparable results to the ray tracing while maintaining interactive frame rates. ", "caption_bbox": [73, 438, 775, 490]}, {"image_id": 5, "file_name": "243_05.png", "page": 7, "dpi": 300, "bbox": [79, 521, 406, 705], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The nickel-aluminum data set (NiAl) exposes visual arti- facts with our method. While the overall structure is clearly empha- sized (as shown in the zoomed-in views on the left), the flat planes formed by the crystal lattice are not aligned with our density volume, which results in visual artifacts. The right zoomed-in view shows the artifacts (we increased the density volume influence to make the ar- tifacts better perceivable). ", "caption_bbox": [73, 721, 408, 812]}, {"image_id": 6, "file_name": "243_06.png", "page": 8, "dpi": 300, "bbox": [76, 74, 411, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A laser ablation data set of 11.8 million particles enhanced with our object space ambient occlusion technique. The shape of the crater\u2019s brim is not emphasized because we only use short-range neighborhood information to determine the occlusion factors. ", "caption_bbox": [73, 314, 408, 366]}], "244": [{"image_id": 0, "file_name": "244_00.png", "page": 2, "dpi": 300, "bbox": [507, 663, 710, 803], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An illustation of the 2D volume transfer function in Fluo- Render. The colored arrows indicate the possible adjustments for the parameters, which are: falloff, offset, gradient magnitude thresh- old, low scalar intensity threshold and high scalar intensity threshold. All parameters are adjusted with sliders as shown in Figure 10. ", "caption_bbox": [440, 820, 775, 885]}, {"image_id": 1, "file_name": "244_01.png", "page": 3, "dpi": 300, "bbox": [92, 76, 392, 208], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Results from pre-quantized (A) and on the fly (B) evaluation of the transfer function. The two results are generated with the same transfer function settings. The pre-quantized transfer function clips many details in the low intensity regions, which are preserved with on the fly evaluation of the transfer function. The dataset shows tectal neurons of a 5-day-post-fertilization (5dpf) zebrafish. ", "caption_bbox": [73, 224, 408, 302]}, {"image_id": 2, "file_name": "244_02.png", "page": 3, "dpi": 300, "bbox": [458, 458, 760, 717], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The volume transfer function falloff and the 2D rendering gamma work well together. The confocal dataset shows three chan- nels of a 5dpf zebrafish embryo: eye muscles (red), neurons (green), and nuclei (blue). A: The initial rendering without any adjustment. B: The result when the falloff is increased. The rendering does not be- come brighter as many users may expect. The attached plots show the change of one ray profile after the falloff is increased. Though the adjustment is monotonic and increases all values along the ray pro- file, the blended output becomes darker due to quick accumulation of low intensity values. C: The result when the gamma is increased. The rendering result is brightened, but noise becomes prominent in the regions indicated by yellow arrowheads. D: The satisfactory re- sult achieved by decreasing falloff and increasing gamma. Neuron fibers are visualized clearly with less noise (in the same regions indi- cated in C). ", "caption_bbox": [440, 732, 775, 928]}, {"image_id": 3, "file_name": "244_03.png", "page": 4, "dpi": 300, "bbox": [111, 363, 373, 469], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The mapping of the user-adjustable parameter L and the scaling factor f (L), in linear scale (left) and logarithmic scale (right) plots. ", "caption_bbox": [73, 487, 408, 526]}, {"image_id": 4, "file_name": "244_04.png", "page": 4, "dpi": 300, "bbox": [439, 150, 778, 359], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The scale-space equalization process. The example dataset has three channels of stained muscles, neurons and nuclei of the zebrafish head. ", "caption_bbox": [440, 375, 775, 414]}, {"image_id": 5, "file_name": "244_05.png", "page": 5, "dpi": 300, "bbox": [458, 76, 759, 158], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Using a colormap as the volume transfer function and 2D color mapping of the MIP. All results have the same colormap, as shown on the right. A: The colormap is used as the volume transfer function. B: The colormap is applied to the MIP rendering output. C: The MIP rendering is overlaid with a shading layer (shading overlay is discussed in Section 4.4). The dataset shows a 5 dpf zebrafish eye. ", "caption_bbox": [440, 174, 775, 265]}, {"image_id": 6, "file_name": "244_06.png", "page": 5, "dpi": 300, "bbox": [76, 260, 411, 387], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A confocal dataset of a 5dpf zebrafish embryo has three channels: eye muscles (red), neurons (green), and nuclei (blue). A: The channels are combined with 3D compositing. The muscle and neuron channels are barely seen. Yellow arrowheads indicate the boundary of the brain, which is on the right side of the eye when visualized as in the figure. B: The channels are composited with 2D addition. Highlight details are over-saturated, due to the addi- tive compositing. C: The channels are composited with 2D layering. Details of the muscle and neuron channels are visualized, but the spatial order of the two is incorrect. D: The muscle channel and the neuron channel are grouped and combined with 3D compositing, which renders their spatial relationship correctly; the nuclei channel is in a separate group. The two groups are composited with 2D lay- ering. The nuclei channel is a context layer, showing the boundary between the brain and the eye. ", "caption_bbox": [73, 403, 408, 599]}, {"image_id": 7, "file_name": "244_07.png", "page": 6, "dpi": 300, "bbox": [90, 516, 392, 614], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A comparison of DVR (A), MIDA (B), and shading overlay on MIP (C). They all use the same colormap shown on the right. The dataset is the mushroom body (MB) of an adult Drosophila, stained with nsyb::GFP. This fluorescent protein specifically binds to presy- naptic regions of neurons. Thus higher signal intensity indicates higher density of synapses of the mushroom body. By using MIP with 2D overlays, we can clearly see the head of \u03b1/\u03b10 lobe has higher presynaptic density than its neck, which can be similarly observed for \u03b2/\u03b20 lobe. ", "caption_bbox": [73, 629, 408, 746]}, {"image_id": 8, "file_name": "244_08.png", "page": 6, "dpi": 300, "bbox": [112, 76, 370, 222], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A shading pass (A) is composited with the result of a 2D color-mapped MIP pass (B). The result (C) has the advantages of both MIP and DVR. The dataset has three confocal channels, includ- ing stained muscles, neurons, and nuclei. ", "caption_bbox": [73, 236, 408, 288]}, {"image_id": 9, "file_name": "244_09.png", "page": 6, "dpi": 300, "bbox": [474, 333, 743, 495], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: FluoRender user interface. A: Toolbar; B: List of loaded datasets; C: Tone-mapping adjustment; D: Tree layout of current ac- tive datasets; E: Movie export settings; F: Render viewport; G: Clip- ping plane controls; H: Volume data property settings. ", "caption_bbox": [440, 510, 775, 562]}, {"image_id": 10, "file_name": "244_10.png", "page": 7, "dpi": 300, "bbox": [459, 374, 759, 704], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Case study 2. A 4D dataset is visualized without (A) and with (B) shadow effect. The lower part of the figure compares the results with scale-space equalization off/on. The histogram of output pixel brightness is displayed under each image. ", "caption_bbox": [440, 721, 775, 773]}, {"image_id": 11, "file_name": "244_11.png", "page": 7, "dpi": 300, "bbox": [91, 225, 392, 472], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Case study 1. A1 and A2 : dorsal and lateral views of a zebrafish head dataset, rendered without any enhancement; B1 and B2 : the same dataset rendered from the same view directions, with enhancements applied; C1 and C2 : groups and different render modes can create clear visualizations when derived channels are presented. ", "caption_bbox": [73, 489, 408, 567]}, {"image_id": 12, "file_name": "244_12.png", "page": 8, "dpi": 300, "bbox": [75, 463, 408, 586], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Speed comparison. We test all speeds on the same PC with Intel Core i7 3.2GHz, 12GB memory, single 7200 RPM SATA disk, nVIDIA GTX280 and Microsoft Windows XP 64bit. The dataset is a two channel 4D confocal dataset with 210 frames, which occu- pies 3.43GB on disk. Volocity is 64bit at version 5.1.0. Imaris is 64bit at version 6.3.0. FluoRender is 64bit at version 2.9.0 ", "caption_bbox": [73, 602, 408, 680]}], "245": [{"image_id": 0, "file_name": "245_00.png", "page": 1, "dpi": 300, "bbox": [140, 120, 733, 450], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization of the uncertainty in two diffusion shapes. (a) Two fibers crossing at 60 degrees with relative weight of 0.6:0.4 and SNR of 10. (b) Two fibers crossing at 90 degrees with equal weight and SNR of 20 (with much less uncertainty). ", "caption_bbox": [73, 454, 775, 479]}, {"image_id": 1, "file_name": "245_01.png", "page": 3, "dpi": 300, "bbox": [76, 80, 405, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: 25 noisy diffusion shapes at the crossing of two fibers at 60\u25e6 and relative weights 0.7 : 0.3. The SNR is 10 and b-value is 2000 s/mm2 . The original, noiseless diffusion shape is shown below. ", "caption_bbox": [73, 265, 408, 304]}, {"image_id": 2, "file_name": "245_02.png", "page": 3, "dpi": 300, "bbox": [450, 657, 767, 947], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: SIP function of diffusion shapes with b = 1000 and SNR of 5 illustrated with colormaps highlighting 4 (upper left), 5 (upper right), 6 (lower left), or 8 (lower right) layers. ", "caption_bbox": [440, 961, 775, 1000]}, {"image_id": 3, "file_name": "245_03.png", "page": 4, "dpi": 300, "bbox": [74, 437, 411, 527], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: SIP functions for different ODF representations: Left to right: ellipsoids (DTI), super quadratic (DTI), fourth-order homoge- neous polynomial (HARDI). All use the same data with SNR of 20, b- value = 3000, two crossing fibers at 75\u25e6 and relative weights 0.6 : 0.4. ", "caption_bbox": [73, 535, 408, 587]}, {"image_id": 4, "file_name": "245_04.png", "page": 5, "dpi": 300, "bbox": [96, 75, 754, 690], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: SIP functions of diffusion shapes for two fibers crossing at 30 (left), 60 (middle), and 90 (right) degrees. In (a), (b), and (c) the fibers have equal weight, and in (d), (e), and (f) they have relative weights of 0.7 and 0.3. Six levels of noise (SNR = {5, 10, 20, 30, 40, 50} from right to left) each with 8 different b-values (= {1, 2, 3, 4, 5, 6, 7, 8} \u00d7 1000s/mm2 from top to bottom) were used in each subfigure. ", "caption_bbox": [73, 703, 775, 742]}, {"image_id": 5, "file_name": "245_05.png", "page": 6, "dpi": 300, "bbox": [455, 240, 762, 448], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Plots of certain volume ratio as a function of b-value (top) and SNR (bottom). All experiments on synthetic example of two fibers crossing at 60\u25e6 with equal relative weights and an SNR of 10 (top) or b-value of 3000 (bottom). ", "caption_bbox": [440, 453, 775, 505]}, {"image_id": 6, "file_name": "245_06.png", "page": 6, "dpi": 300, "bbox": [74, 77, 777, 161], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Different visualizations of diffusion uncertainty in a single glyph. Left to right: the single best-fit diffusion shape; two-standard deviation of top principal component in either direction superimposed; local variation color-mapped onto the 50% iso-level of diffusion shape; and SIP function of diffusion shapes with iso-levels at 25%, 50%, 75%, and 95%. The colormap for the left two images signifies ODF values, not uncertainty. ", "caption_bbox": [73, 175, 775, 214]}, {"image_id": 7, "file_name": "245_07.png", "page": 6, "dpi": 300, "bbox": [107, 240, 378, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Distribution of cumulative variation explained by up to the first 10 principal components for cases shown in Figure 5. ", "caption_bbox": [73, 410, 408, 435]}, {"image_id": 8, "file_name": "245_08.png", "page": 7, "dpi": 300, "bbox": [125, 75, 722, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The certain volume ratio for two fiber crossing at 30 (left hand side), 60 (middle), and 90 (right hand side) degrees. Two groups of fiber weights are shown: 0.5 and 0.5 (top row) and 0.7 and 0.3 (bottom row). Six levels of noise with the SNR0 of 50,40,30,20,10, and 5 were applied. ", "caption_bbox": [73, 346, 775, 373]}, {"image_id": 9, "file_name": "245_09.png", "page": 8, "dpi": 300, "bbox": [101, 78, 743, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Left: 7 by 4 region of interest from the white matter. Right three columns: human data with a b-value of 1000, 2000, and 3000 s/mm2. Each column shows 28 diffusion shapes as a single triangular mesh (top) and a SIP function using 1000 instantiations of each diffusion shape. ", "caption_bbox": [73, 361, 775, 386]}], "246": [{"image_id": 0, "file_name": "246_00.png", "page": 1, "dpi": 300, "bbox": [89, 86, 759, 323], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Cutaway image from a flow visualization. (a) Features of interest are colored orange. (b) The algorithm determines the positions of the cutting objects in order to reveal as much of the features as possible. (c) The resulting cutaway. ", "caption_bbox": [73, 330, 775, 355]}, {"image_id": 1, "file_name": "246_01.png", "page": 2, "dpi": 300, "bbox": [448, 74, 769, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Computer assisted creation of cutaway illustrations. The user knows which features are relevant and can understand a ren- dering of the data. To place the cutaway geometry optimally in the illustration, an optimization algorithm based on a MC method inter- acts with the rendering system. ", "caption_bbox": [440, 315, 775, 380]}, {"image_id": 2, "file_name": "246_02.png", "page": 3, "dpi": 300, "bbox": [74, 74, 411, 201], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Three primitives used to produce cutaways: (a) cuboid, (b) cylinder, and (c) sphere. Unlike in the real results, primitives are rendered here in order to get an impression of how the method works. ", "caption_bbox": [73, 208, 408, 247]}, {"image_id": 3, "file_name": "246_03.png", "page": 3, "dpi": 300, "bbox": [448, 274, 769, 463], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Composition of the objective function images. From the viewpoint of the user, the objective function images are produced by coloring the data according to the importance. Objective function im- ages resulting from the dataset defined in Section 3.1 are displayed on the right side. (a) Without cutaway. Most of the important parts (green) are occluded while unwanted parts are visible (red). (b) Af- ter subtraction of a cutaway primitive, the important regions become visible and the unwanted regions vanish. ", "caption_bbox": [440, 471, 775, 575]}, {"image_id": 4, "file_name": "246_04.png", "page": 5, "dpi": 300, "bbox": [440, 450, 776, 586], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Piston gas engine dataset. (a) Orange parts are selected by the user. (b) Making the unwanted parts transparent makes the important parts visible whereas (c) a cutaway provides more informa- tion about spatial structure. In this example, a cuboid and a sphere are used to produce the cutaway shape. ", "caption_bbox": [440, 594, 775, 659]}, {"image_id": 5, "file_name": "246_05.png", "page": 5, "dpi": 300, "bbox": [473, 73, 744, 160], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Integration in the rendering framework. The renderer pro- cesses the usual inputs (geometry or volume data and colors) plus a list of primitives to be clipped. The optimization process takes an image as input and measures its quality. Then, a new placement of the cut objects is proposed and transmitted to the renderer which produces a new image. ", "caption_bbox": [440, 167, 775, 245]}, {"image_id": 6, "file_name": "246_06.png", "page": 6, "dpi": 300, "bbox": [439, 690, 777, 816], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Evaluation results, normalized with respect to the refer- ence run. (a) The objective function approaches the value obtained by the reference run. (b) The convergence measurement shows that the global optimum is reached consistently. (c) SA performs magni- tudes better than searching the best position in the whole configura- tion space. Each data point is produced by taking the mean of 50 samples. The mean time for the samples with Smax = 550 is 158s, compared to 3388s for the reference run. For all plots, the error bars denote the borders of the 95% confidence interval. ", "caption_bbox": [440, 823, 775, 940]}, {"image_id": 7, "file_name": "246_07.png", "page": 6, "dpi": 300, "bbox": [442, 73, 776, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Volumetric dataset. (a) Direct volume rendering. (b) Exam- ple of a spherical cut-away. (c-d) Even a rough DOI with the highest values inside the brain leads to the clean cutaway in (d), which max- imizes the brain cross-section. ", "caption_bbox": [440, 234, 775, 286]}, {"image_id": 8, "file_name": "246_08.png", "page": 6, "dpi": 300, "bbox": [74, 73, 392, 512], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: LES cylinder flow. (a) The user selects regions with differ- ent physical properties. (b) The data contains the selected features (orange) but they are occluded by other parts of the isosurface. (c) Parts of the data are removed by the cutaway in order to reveal the selected regions. In the right image, the cutting lines are highlighted blue. (d) The resulting cutaway. ", "caption_bbox": [73, 520, 408, 598]}, {"image_id": 9, "file_name": "246_09.png", "page": 7, "dpi": 300, "bbox": [446, 310, 771, 671], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: (a) An instance of PLANAR-3SAT. (b) An instance of CUT- POINTS. The array A is used as a drawing board to draw one closed loop per variable and one clause gadget per clause. (c) Part of a variable loop. There are only two ways to cover all negative cells in the loop with a minimal number of boxes, such that no box includes a background cell. The square element containing the two orange cells is used to swap the layout of the boxes along the loop to ac- count for negations. (d) A clause gadget for the expression A OR B OR D. In this example, A is false and B and D are true. Only loops with the correct box layout can extend one of their boxes to collect the additional black cell in the middle. ", "caption_bbox": [440, 678, 775, 822]}], "247": [{"image_id": 0, "file_name": "247_00.png", "page": 1, "dpi": 300, "bbox": [105, 119, 751, 476], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization results of a mouse intestine microvilli data set with lens of DICVR (Differential Interference Contrast Volume Rendering) and PCVR (Phase-Contrast Volume Rendering) in the context of DVR (Direct Volume Rendering). While both methods can enhance the structure details of the noisy data, DICVR is able to clearly depict the small micro-filament structures in each microvillus. ", "caption_bbox": [73, 480, 775, 519]}, {"image_id": 1, "file_name": "247_01.png", "page": 2, "dpi": 300, "bbox": [451, 74, 765, 184], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The illustration of light interfence. Red and blue curves are two coherent waves respectively, and the black curve is the interfer- ence results. (a) constructive interference; (b) destructive interfer- ence. ", "caption_bbox": [440, 186, 775, 238]}, {"image_id": 2, "file_name": "247_02.png", "page": 3, "dpi": 300, "bbox": [439, 74, 777, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The configuration of interference microscopes: (a) Phase- contrast microscpe; (b) Transmitted and inverted de Se\u0301narmont Dif- ferential Interference Contrast (DIC) Microscope. Image courtesy from Nikon MicroscopyU, http://www.microscopyu.com ", "caption_bbox": [440, 264, 775, 316]}, {"image_id": 3, "file_name": "247_03.png", "page": 3, "dpi": 300, "bbox": [448, 322, 769, 420], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Phase-contrast microcope image: (a) microscopy image of crystals of strontium chloride with standard bright- field; (b) image obtained by phase-contrast microscopy.  Im- age courtesy from Microscopy Primer (http://www.microscopy- uk.org.uk/primer/special.htm). ", "caption_bbox": [440, 422, 775, 487]}, {"image_id": 4, "file_name": "247_04.png", "page": 4, "dpi": 300, "bbox": [73, 75, 410, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The pipline of interference microscopy volume illustration. The OPD map and differential OPD map can be generated with GPU- based raycasting. The PCVR and DICVR results are achieved by modulating DVR images with OPD map and differential OPD map respectively. ", "caption_bbox": [73, 271, 408, 336]}, {"image_id": 5, "file_name": "247_05.png", "page": 4, "dpi": 300, "bbox": [81, 340, 402, 650], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The simplified physical model for phase-contrast mi- croscopy in PCVR (a) and DICVR (b). ", "caption_bbox": [73, 652, 408, 678]}, {"image_id": 6, "file_name": "247_06.png", "page": 5, "dpi": 300, "bbox": [453, 230, 771, 410], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The visualization result of Hepatitis B Virus (HBV) [1] Cryo- EM data with focus+context lenses. ", "caption_bbox": [440, 413, 775, 439]}, {"image_id": 7, "file_name": "247_07.png", "page": 5, "dpi": 300, "bbox": [447, 73, 768, 206], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Linked view of the specimen slicer", "caption_bbox": [497, 213, 714, 226]}, {"image_id": 8, "file_name": "247_08.png", "page": 6, "dpi": 300, "bbox": [85, 73, 399, 419], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: PCVR with multiple wavelength modulated: (a) DVR image; (b) The actual crystal structure of the data; (b) PCVR with unique wavelength; (c) PCVR with multiple different wavelengths. The yellow points in (c) are control points defining different wavelengths. ", "caption_bbox": [73, 421, 408, 473]}, {"image_id": 9, "file_name": "247_09.png", "page": 7, "dpi": 300, "bbox": [98, 423, 752, 623], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Visualization results for electron tomogram of neuron synapse data with different methods. Structures of microtubules are much easier to be identified with methods we proposed: (a) DVR. The features are severely submerged with the surroundings; (b) PCVR. The contrast of the image is enhanced. The outlines of inner features appear; (c) DICVR. The contrast of the image is enhanced by introducing emboss effects that are brought by DICVR. Inner structures are clearly visualized. ", "caption_bbox": [73, 629, 775, 681]}, {"image_id": 10, "file_name": "247_10.png", "page": 7, "dpi": 300, "bbox": [97, 74, 752, 387], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The interference microscopy volume rendering of rATCpnbeta data with PCVR (a) and DICVR (b) in different wavelengths and phase. The DVR image is shown in Fig. 9(a). ", "caption_bbox": [73, 393, 775, 419]}], "248": [{"image_id": 0, "file_name": "248_00.png", "page": 1, "dpi": 300, "bbox": [73, 119, 778, 468], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Stream lines (127k triangles) of a mixing pipe and a scalar volume (1800 \u00d7 121 \u00d7 121 resolution), of which the front half was removed by a clipping plane. The images were rendered with a) Phong volume shading with on-the-fly gradient estimation and Phong surface shading and b) the presented combined surface and volumetric occlusion shading method. ", "caption_bbox": [73, 469, 776, 510]}, {"image_id": 1, "file_name": "248_01.png", "page": 2, "dpi": 300, "bbox": [444, 73, 772, 402], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The various occlusion effects between the volume and geometry, where each image introduces additional interactions, begin- ning with the occlusion of a) the volume , b) the geometry, c) between the geometry and the volume and d) between the volume and the geometry. ", "caption_bbox": [440, 417, 777, 482]}, {"image_id": 2, "file_name": "248_02.png", "page": 3, "dpi": 300, "bbox": [73, 360, 410, 805], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The extensions to the original DOS method are denoted in orange: additional data structures (G-buffer, partial occlusion buffer) and additional processing steps (computing the G-buffer, updating the partial occlusion buffer, computing surface shading and determining the vicinity occlusion term) ", "caption_bbox": [73, 811, 409, 876]}, {"image_id": 3, "file_name": "248_03.png", "page": 4, "dpi": 300, "bbox": [484, 81, 728, 257], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Illustration of the basic geometric setup for updating the par- tial occlusion buffer of a geometric surface at a view space distance zsurface which is situated between slices slicen\u22121 (at view space dis- tance zslice ) and slicen , separated by the slice distance d. The partial occlusion of the surfaces is approximated by interpolating between volumetric_occlusionn\u22121 and volumetric_occlusionn based on z\u2206 . ", "caption_bbox": [440, 279, 777, 360]}, {"image_id": 4, "file_name": "248_04.png", "page": 5, "dpi": 300, "bbox": [121, 79, 358, 255], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Illustration of the basic geometric setup for computing the vicinity occlusion term of a geometric surface at the view space dis- tance zsurface . ", "caption_bbox": [73, 279, 411, 319]}, {"image_id": 5, "file_name": "248_05.png", "page": 5, "dpi": 300, "bbox": [444, 74, 772, 581], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Left column: DTI fiber tracts were rendered where the transfer function was set to render all voxels as transparent in order to emphasize the occlusion effects on the geometric structures. a) shows the volumetric occlusion term, c) shows the vicinity occlusion term and e) shows the combined occlusion term. The right column shows the combined occlusion term for various values of \u03b8 . ", "caption_bbox": [440, 595, 776, 673]}, {"image_id": 6, "file_name": "248_06.png", "page": 7, "dpi": 300, "bbox": [85, 73, 765, 413], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Performance for various rendering methods and data sets, measured in FPS on an NVIDIA GeForce GTX 580 GPU.", "caption_bbox": [118, 482, 730, 495]}, {"image_id": 7, "file_name": "248_07.png", "page": 8, "dpi": 300, "bbox": [85, 73, 765, 507], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: An astrophysical data set was used to compute magnetic field lines (7.9M triangles) with Phong surface shading and a scalar volume (256 \u00d7 512 \u00d7 512 resolution) showing the magnitude of the magnetic field, rendered with a) Phong volume shading with on-the-fly gradient estimation and Phong surface shading, and b) combined directional occlusion shading and Phong surface shading. ", "caption_bbox": [73, 521, 775, 560]}], "249": [{"image_id": 0, "file_name": "249_00.png", "page": 2, "dpi": 300, "bbox": [62, 87, 770, 390], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Volume rendering of a 2-channel fluid dynamics data set consisting of vorticity magnitude and normalized helicity. The trans- fer function (shown in the lower-right corner) is chosen to visualize surfaces of medium vorticity (yellow) and high-vorticity regions (red and blue). In the latter, normalized helicity is considered as a secondary variable to color strong vortical regions by direction of rotation. Multidimensional peak finding lets us quickly and accurately render multi-criteria vortex features without explicit mesh extraction. ", "caption_bbox": [73, 402, 775, 457]}, {"image_id": 1, "file_name": "249_01.png", "page": 3, "dpi": 300, "bbox": [141, 75, 710, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Classification of multivariate data, and locating peaks between segments. (a) - a straight ray ~R(t) in world space; (b) - the curved path of ~R(t) in transfer function domain, f(t) = ( f (~R(t)), g(~R(t))); (c) - transfer function profile along the ray, \u03c1 \u25e6 f(t). ", "caption_bbox": [73, 217, 775, 250]}, {"image_id": 2, "file_name": "249_02.png", "page": 3, "dpi": 300, "bbox": [131, 820, 354, 955], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: In 2D transfer function space, peaks along the image of the ray are in general not the same as peak points of \u03c1. ", "caption_bbox": [73, 972, 408, 999]}, {"image_id": 3, "file_name": "249_03.png", "page": 4, "dpi": 300, "bbox": [88, 89, 396, 470], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Parameterizations for sampling in transfer space \u03c1( f , g).", "caption_bbox": [73, 476, 408, 490]}, {"image_id": 4, "file_name": "249_04.png", "page": 4, "dpi": 300, "bbox": [449, 89, 761, 433], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Scanline sampling approaches.", "caption_bbox": [503, 439, 711, 452]}, {"image_id": 5, "file_name": "249_05.png", "page": 5, "dpi": 300, "bbox": [79, 79, 769, 398], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison of various classification techniques on a close view forward (\u039b+ ) and backward (\u039b\u2212 ) FTLE fields of a combustion dataset, classified using a sharp separable Gaussian 2D transfer function, evaluated analytically (sampled at a discretized resolution of 10242 in (d)). Rendering of frames (a-g) run at 33, 1.2, 35, 22, 32, 18 and 10 fps, respectively. ", "caption_bbox": [73, 397, 775, 443]}, {"image_id": 6, "file_name": "249_06.png", "page": 6, "dpi": 300, "bbox": [76, 75, 771, 397], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Classification of matter density ( f 1 ) and dark matter density ( f 2 ) in an Enzo computational astrophysics dataset [22]. The transfer function highlights ridges in the joint histogram to illustrate where one matter quantity is high relative to the other. We use a 10242 transfer function and render at 1024 \u00d7 768. Frames (a-g) run at 8.5, 1.2, 12.8, 10.6, 7.6, 12.5 and 8.4 fps, respectively. ", "caption_bbox": [73, 399, 775, 442]}, {"image_id": 7, "file_name": "249_07.png", "page": 7, "dpi": 300, "bbox": [73, 73, 409, 575], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: 2D classifications of value and inverse gradient magni- tude, without (left) and with (right) peak finding. From top left to bottom right, these render at 8.0, 7.1, 5.3, 4.0, 12.3 and 9.8 fps, respectively, using scanline DDA sampling. ", "caption_bbox": [73, 578, 408, 633]}, {"image_id": 8, "file_name": "249_08.png", "page": 8, "dpi": 300, "bbox": [73, 73, 777, 438], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Visualization of 4-channel combustion simulation data [13] using a 4D transfer function modeled by analytically convolving two 2D transfer function textures \u03bd and \u00b5. Postclassified renderings are on the left and peak finding renderings are on the right. The top row shows a transfer function with peaks, purple and pink isolines. The bottom row shows results with the low-frequency components of the same function. With \u2206t = 0.5 for the postclassified examples and \u2206 = 1, \u2206s = 2 for peak finding with chordal ray marching, these frames render at 0.8, 0.75, 1.6 and 1.6 fps, respectively at 1200 \u00d7 600. ", "caption_bbox": [73, 439, 775, 507]}], "25": [], "250": [{"image_id": 0, "file_name": "250_00.png", "page": 1, "dpi": 300, "bbox": [100, 86, 749, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Flow swirling around a straight line. Two APAP surfaces are seeded near the core line at different distances.", "caption_bbox": [134, 296, 710, 308]}, {"image_id": 1, "file_name": "250_01.png", "page": 3, "dpi": 300, "bbox": [151, 76, 321, 197], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Quantities required for the local discrete error at an edge ` = {i, j}: vertex positions xi , x j , normalized flow vectors v\u0303i , v\u0303 j evalu- ated at these locations as well as in the midpoint (v\u0303` ), and the Jaco- bian J\u0303` of v\u0303 at the midpoint of the edge. ", "caption_bbox": [73, 212, 408, 265]}, {"image_id": 2, "file_name": "250_02.png", "page": 3, "dpi": 300, "bbox": [439, 264, 777, 522], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Surface growing. The position of the offset vertex xnew is computed from the discrete boundary curve and its unit tangent n and normal n vectors (left). The boundary polygon and the offset points form a triangle strip (red) which is included in the triangulation. ", "caption_bbox": [440, 182, 775, 234]}, {"image_id": 3, "file_name": "250_03.png", "page": 4, "dpi": 300, "bbox": [107, 74, 377, 151], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Surface growing. We consider the conservative vector field v(x) = \u2207x, the critical point 0 is marked. In this case the APAP surface is a spherical isosurface. We start with disk as seed surface (left) which evolves to part of a sphere (center) as APAP surface. After surface growing the mesh covers the whole sphere. (b) Two APAP surfaces in a conservative linear field with a saddle. ", "caption_bbox": [73, 166, 408, 244]}, {"image_id": 4, "file_name": "250_04.png", "page": 4, "dpi": 300, "bbox": [511, 74, 707, 194], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: APAP surfaces in a conservative flow [29]. The LIC image of the underlying 2D vector field reveals the sink and saddle. ", "caption_bbox": [440, 209, 775, 234]}, {"image_id": 5, "file_name": "250_05.png", "page": 4, "dpi": 300, "bbox": [549, 249, 669, 366], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Five APAP surfaces combined with illuminated streamlines visualize the focus saddle flow. ", "caption_bbox": [440, 380, 775, 405]}, {"image_id": 6, "file_name": "250_06.png", "page": 6, "dpi": 300, "bbox": [139, 260, 344, 343], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) APAP surface near critical point in front of square cylin- der. 473 streamlines are seeded at the vertices resulting in an even distribution. (b) Four APAP surfaces on the benzene flow combined with illuminated streamlines. ", "caption_bbox": [73, 357, 408, 409]}, {"image_id": 7, "file_name": "250_07.png", "page": 6, "dpi": 300, "bbox": [160, 74, 690, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Simulated flow around a square cylinder. We show one time step of the simulation and combine APAP surfaces with a LIC image on a central plane. ", "caption_bbox": [73, 209, 775, 234]}, {"image_id": 8, "file_name": "250_08.png", "page": 7, "dpi": 300, "bbox": [230, 241, 620, 411], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Six APAP surfaces at time-step 50 (left) and 78 (right) indicating the focus saddle-like structure of decaying magnetic Borromean rings.", "caption_bbox": [73, 425, 775, 437]}, {"image_id": 9, "file_name": "250_09.png", "page": 7, "dpi": 300, "bbox": [206, 74, 644, 197], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Two views of flow around a wing visualized by five APAP surfaces combined with streamlines. The red arrow shows the main direction.", "caption_bbox": [73, 214, 775, 226]}, {"image_id": 10, "file_name": "250_10.png", "page": 8, "dpi": 300, "bbox": [111, 73, 373, 162], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Timings for meshes with n vertices. We measured time to setup and factor AT A, to solve the linear system, to smooth, refine (all triangles), and to grow one layer. Timings are given in millisec- onds. ", "caption_bbox": [73, 382, 408, 434]}], "251": [{"image_id": 0, "file_name": "251_00.png", "page": 2, "dpi": 300, "bbox": [447, 74, 763, 152], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The Access Dependency Graph (ADG). (a): An illustrative flow field divided into four blocks. The flows are aligned to the grey curves with the direction from bottom left to top right. (b): The ADG of one hop. (c): The ADG of two hops. (d): The merge of (b) and (c). ", "caption_bbox": [440, 162, 775, 217]}, {"image_id": 1, "file_name": "251_01.png", "page": 2, "dpi": 300, "bbox": [106, 74, 374, 127], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: System Overview.", "caption_bbox": [172, 139, 310, 155]}, {"image_id": 2, "file_name": "251_02.png", "page": 4, "dpi": 300, "bbox": [464, 73, 752, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The 2D layout of a slice from Isabel. (a): Streamlines show- ing the flow field, which exists one source on the right side and two sinks at the left corners. (b)-(e): The layouts generated by using the multi-hop graphs of G1 , G\u22173 , G\u22175 , and G\u221710 . The color of each end point of the line segments reflects the layout order of the related block. (f): Colormap of the layout order (from the bottom color to the top color) ", "caption_bbox": [440, 289, 775, 370]}, {"image_id": 3, "file_name": "251_03.png", "page": 5, "dpi": 300, "bbox": [115, 75, 369, 194], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Out-of-core visualization system.", "caption_bbox": [136, 209, 346, 225]}, {"image_id": 4, "file_name": "251_04.png", "page": 5, "dpi": 300, "bbox": [114, 239, 366, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Block prefetching. The blocks are firstly loaded into a tem- porary buffer and then separately copied into the memory pool. ", "caption_bbox": [73, 347, 408, 376]}, {"image_id": 5, "file_name": "251_05.png", "page": 5, "dpi": 300, "bbox": [449, 75, 764, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Layout validation. (a): Layout costs of EMR(L, G\u221710 ) in Equa- tion 4 with different prefetch sizes. (b): Averaged miss ratio of single particle tracing. (c): A close view of (b). The curves are for H-curve (. . . ), the optimized layout for G\u22171 , ('), G\u22172 ((), G\u22173 (+), G\u22175 (\u2666), and G\u221710 (*). ", "caption_bbox": [440, 324, 775, 393]}, {"image_id": 6, "file_name": "251_06.png", "page": 6, "dpi": 300, "bbox": [449, 644, 774, 798], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The block loading time (color bars) and wall time (white bars) of uneven seeding. The bars in each group from left to right represent the result for Hilbert-curve layout and our layouts optimized for G1 , G\u22173 and G\u22175 . ", "caption_bbox": [440, 812, 775, 868]}, {"image_id": 7, "file_name": "251_07.png", "page": 6, "dpi": 300, "bbox": [449, 546, 774, 643], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The number of missed blocks (color bars) and the total number of loaded blocks (white bars) for uneven seeding. Note that the box counts are plotted in logarithm scale. The bars in each group from left to right represent the result from Hilbert-curve layout and our layouts optimized for G1 , G\u22173 and G\u22175 . ", "caption_bbox": [440, 456, 775, 525]}, {"image_id": 8, "file_name": "251_08.png", "page": 7, "dpi": 300, "bbox": [82, 426, 408, 677], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The block loading time (color bars) and wall time (white bars) of uniform seeding. The bars in each group from left to right represent the result for Hilbert-curve layout and our layouts optimized for G1 , G\u22173 and G\u22175 . ", "caption_bbox": [73, 691, 408, 747]}, {"image_id": 9, "file_name": "251_09.png", "page": 7, "dpi": 300, "bbox": [82, 74, 408, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The number of missed blocks (color bars) and the total number of loaded blocks (white bars) for uniform seeding. Note that the box counts are plotted in logarithm scale. The bars in each group from left to right represent the result from Hilbert-curve layout and our layouts optimized for G1 , G\u22173 and G\u22175 . ", "caption_bbox": [73, 340, 408, 409]}], "252": [{"image_id": 0, "file_name": "252_00.png", "page": 2, "dpi": 300, "bbox": [73, 73, 772, 174], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Two consecutive frames during the zooming in operation. Randomly generating the noise in the image space [15] causes popping of color as shown in (a), especially around singularities. Our method generates consistent streamline rendering result (b). Please see the accompany video for a better illustration. ", "caption_bbox": [73, 206, 775, 245]}, {"image_id": 1, "file_name": "252_01.png", "page": 2, "dpi": 300, "bbox": [79, 503, 405, 656], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The image on the right column shows the region in the red rectangle on the left image by moving the camera closer to the surface. Our method utilizes a set of correlated noise textures in a mipmap texture pyramid, and makes the results share similar color distribution in different scales (upper row). Using uncorrelated multi- resolution noise textures (lower row) cannot achieve such consis- tency. ", "caption_bbox": [73, 674, 408, 765]}, {"image_id": 2, "file_name": "252_02.png", "page": 3, "dpi": 300, "bbox": [81, 417, 402, 884], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The pipeline of our approach.", "caption_bbox": [144, 900, 337, 912]}, {"image_id": 3, "file_name": "252_03.png", "page": 4, "dpi": 300, "bbox": [91, 83, 391, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) A LIC result for the Moai model. When the model is zoomed in, the result (b) with the noise texture used in (a) presents color blur, while the result (c) with a noise texture selected from the pre-computed texture pyramid presents pleasing effect. ", "caption_bbox": [73, 392, 408, 444]}, {"image_id": 4, "file_name": "252_04.png", "page": 4, "dpi": 300, "bbox": [443, 74, 772, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: From left to right, the image shows a small portion of the texture image in the pyramid in the order of resolution gradually de- creasing. The first row shows automatic-generated noise mipmap. As resolution decreases, the maps become blurred. The second row shows the customized maps without the scaling operation in Equa- tion 2. It can be seen that the noise maps have color blocks. The maps in the last row are generated using our algorithm (Equation 3). ", "caption_bbox": [440, 341, 775, 432]}, {"image_id": 5, "file_name": "252_05.png", "page": 5, "dpi": 300, "bbox": [467, 451, 747, 653], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Result comparison on the elephant model without (a) and with streamline contrast enhancement (b). This modulation leads to a balance between the details and contrast. ", "caption_bbox": [440, 666, 775, 705]}, {"image_id": 6, "file_name": "252_06.png", "page": 5, "dpi": 300, "bbox": [73, 221, 401, 508], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: From left to right, the model is zoomed out. The first row shows the results at different resolutions with the automatic- generated mipmap. The results become blurred when the model is zoomed out (from left to right). The second row shows the results by employing Equation 2, where big color blocks appear when the model is zoomed in (from right to left). The last row presents the best quality with Equation 3. ", "caption_bbox": [73, 528, 408, 619]}, {"image_id": 7, "file_name": "252_07.png", "page": 5, "dpi": 300, "bbox": [465, 221, 748, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Results with different resolutions. The triangles are mapped onto the noise texture with a higher resolution noise tex- ture in the pyramid for (a), and thus the streamlines are thinner than those in (b). ", "caption_bbox": [440, 384, 775, 436]}, {"image_id": 8, "file_name": "252_08.png", "page": 5, "dpi": 300, "bbox": [71, 73, 773, 162], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The sequence of the mipmap texture images (from 16 \u00d7 16 to 2048 \u00d7 2048). The arrows point to the relatively dark regions.", "caption_bbox": [103, 182, 745, 195]}, {"image_id": 9, "file_name": "252_09.png", "page": 6, "dpi": 300, "bbox": [99, 669, 386, 931], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Result for a complex CAD model. To locate and check the singularities on the model, consistent LIC visualization is very helpful for such tasks. ", "caption_bbox": [73, 947, 408, 986]}, {"image_id": 10, "file_name": "252_10.png", "page": 6, "dpi": 300, "bbox": [464, 74, 752, 642], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Visualization of a vector field on the boundary geometry of a cooling jacket. ", "caption_bbox": [440, 670, 775, 695]}, {"image_id": 11, "file_name": "252_11.png", "page": 6, "dpi": 300, "bbox": [97, 75, 383, 197], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The streamline length on the fertility model used in (b) is longer than that of (a). ", "caption_bbox": [73, 210, 408, 235]}, {"image_id": 12, "file_name": "252_12.png", "page": 7, "dpi": 300, "bbox": [469, 419, 750, 683], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Result for a complicated Buddha model. The complex wrinkles still cause some popping although our silhouette treatment has dramatically reduced such artifacts. ", "caption_bbox": [440, 700, 775, 739]}, {"image_id": 13, "file_name": "252_13.png", "page": 7, "dpi": 300, "bbox": [81, 401, 403, 584], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Our method is simple enough to easily integrate with other LIC technique. (a) shows the result of applying our method to visualize rotational symmetry field [17]. Compared with (b) which uses a set of uncorrelated images in the texture pyramid, our method achieves better color consistency in different scales. ", "caption_bbox": [73, 598, 408, 663]}, {"image_id": 14, "file_name": "252_14.png", "page": 7, "dpi": 300, "bbox": [90, 87, 759, 245], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Performance measurement for the bunny model in two dif- ferent resolutions (the time unit is milliseconds). ", "caption_bbox": [440, 374, 775, 399]}], "253": [{"image_id": 0, "file_name": "253_00.png", "page": 1, "dpi": 300, "bbox": [73, 119, 778, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: This image shows spiral fields visualized at different frequencies with our method (A & D) and LIC (B & C) for comparison.", "caption_bbox": [100, 373, 748, 385]}, {"image_id": 1, "file_name": "253_01.png", "page": 3, "dpi": 300, "bbox": [162, 320, 338, 513], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The main steps of the proposed flow visualization method.", "caption_bbox": [74, 540, 408, 552]}, {"image_id": 2, "file_name": "253_02.png", "page": 3, "dpi": 300, "bbox": [439, 161, 778, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Streamlines traced from pixels A and B, though not the same, sweep the same region in the texture, while streamline traced from C sweeps a completely different region. ", "caption_bbox": [440, 312, 775, 351]}, {"image_id": 3, "file_name": "253_03.png", "page": 3, "dpi": 300, "bbox": [439, 529, 777, 659], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The relative streamline thickness di j for pixel centres Ai and A j is measured as the average height of the pictured polygon. ", "caption_bbox": [440, 674, 775, 700]}, {"image_id": 4, "file_name": "253_04.png", "page": 4, "dpi": 300, "bbox": [73, 74, 411, 243], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: On the left, the set of all pixels with relative thickness to the green point less than a pixel size, underlaid by the LIC image of the same field is shown. The right depicts a distance field computed for the spiral field from a single green point. Outside a local neighborhood, the field is increasingly distorted. Please note that the actual method uses a much smaller neighborhood, with a radius about the size of one pixel. ", "caption_bbox": [73, 257, 410, 348]}, {"image_id": 5, "file_name": "253_05.png", "page": 4, "dpi": 300, "bbox": [439, 471, 777, 809], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Image of a drain field consisting of 64 wave blocks with different phases on each block. Again, please note, actual neighbor- hoods used in our approach are much smaller and this image uses large regions only for illustration purposes. ", "caption_bbox": [440, 824, 777, 876]}, {"image_id": 6, "file_name": "253_06.png", "page": 6, "dpi": 300, "bbox": [439, 517, 778, 744], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The top vortex from the previous figure represented with higher frequency (\u03d5 = 17 , L = 1400). Note a better representation of the swirling behavior. The red line segments show the actual streamlines. ", "caption_bbox": [440, 759, 778, 798]}, {"image_id": 7, "file_name": "253_07.png", "page": 6, "dpi": 300, "bbox": [73, 339, 411, 509], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: On the left, an amplitude image on one of the early iterations is shown. On the right, another early iteration with the corresponding amplitude map overlay (6% threshold) is depicted. The image reveals that streamline branching points as well as boundaries are regions of low amplitude, which can be interpreted as a relative visualization certainty. ", "caption_bbox": [73, 523, 408, 601]}, {"image_id": 8, "file_name": "253_08.png", "page": 6, "dpi": 300, "bbox": [439, 73, 777, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Variation in frequency in the image obtained with a large                                                                  1 integration length (1024 pixels) and the base frequency of 20      . The red line segments show the actual streamlines. Note that discrepancy between the real streamlines and the image lines around the branch- ing points. Also note, that regions of high frequency are better aligned with streamlines than low-frequent regions. ", "caption_bbox": [439, 423, 777, 501]}, {"image_id": 9, "file_name": "253_09.png", "page": 6, "dpi": 300, "bbox": [73, 73, 411, 243], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The left image shows an intermediate result after about 0,5 seconds while the right image depicts the fully converged solution after roughly 20 seconds on our target machine. It is evident that the early version of the image is a close approximation of the final result. ", "caption_bbox": [73, 257, 410, 309]}, {"image_id": 10, "file_name": "253_10.png", "page": 7, "dpi": 300, "bbox": [439, 74, 777, 243], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Post-processed versions of images generated with our method. On the left, the output was converted to vector graphics, and on the right, it was smoothed by a LIC. ", "caption_bbox": [440, 257, 776, 296]}, {"image_id": 11, "file_name": "253_11.png", "page": 8, "dpi": 300, "bbox": [73, 74, 777, 216], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "                                                                                        1 Figure 11: A flow around a cylinder, visualized with our technique using L = 30 and \u03d5 = 3 (left) compared to the enhanced two-fold LIC with a short kernel (middle) and a long kernel (right). ", "caption_bbox": [73, 229, 775, 256]}], "254": [{"image_id": 0, "file_name": "254_00.png", "page": 3, "dpi": 300, "bbox": [489, 245, 727, 364], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Creating a new vector field w by mapping the domain of v by \u03b1. ", "caption_bbox": [440, 378, 775, 404]}, {"image_id": 1, "file_name": "254_01.png", "page": 3, "dpi": 300, "bbox": [82, 80, 756, 185], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Conceptual representation of three different FTLE computation schemes: C-FTLE, R-FTLE, and L-FTLE (from left to right).", "caption_bbox": [99, 208, 748, 220]}, {"image_id": 2, "file_name": "254_02.png", "page": 4, "dpi": 300, "bbox": [77, 75, 406, 186], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Steps to create a deformed ground truth field, where all path lines end up at their originating position. In the ideal case the FTLE value of every point equates to zero. ", "caption_bbox": [73, 202, 408, 241]}, {"image_id": 3, "file_name": "254_03.png", "page": 4, "dpi": 300, "bbox": [440, 502, 776, 689], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The top image shows path lines of the original field in the x, \u03c4 plane and the bottom plot for the mirrored and deformed field. Note that path lines of the latter field are non-symmetric and guaran- teed to end up at their original position in the x, y plane. ", "caption_bbox": [440, 703, 775, 755]}, {"image_id": 4, "file_name": "254_04.png", "page": 5, "dpi": 300, "bbox": [74, 73, 409, 203], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Sine ridge: Path line plot and resulting FTLE fields. The last two images show the effect of increasing the integration time and convergence towards the sine ridge structure (from left to right: \u03c4 = 0.1, 0.5, 1.0). ", "caption_bbox": [73, 218, 408, 270]}, {"image_id": 5, "file_name": "254_05.png", "page": 5, "dpi": 300, "bbox": [76, 553, 407, 772], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Spiral focus: Influence of the parameter p0 (Upper row: path line plot, Bottom row: resulting FTLE field for p0 = 4, 8, 12). ", "caption_bbox": [73, 787, 408, 814]}, {"image_id": 6, "file_name": "254_06.png", "page": 6, "dpi": 300, "bbox": [74, 673, 411, 904], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Double gyre deformed: Plots for the field error in local color scale. The top picture shows the resulting field error in depen- dence of resolution H and integration time TAU. ", "caption_bbox": [73, 920, 408, 959]}, {"image_id": 7, "file_name": "254_07.png", "page": 6, "dpi": 300, "bbox": [439, 512, 777, 620], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Double gyre deformed: Influence of the reseeding sam- pling distance HSAMP and reseeding trigger distance EPS2 on the resulting field errors. ", "caption_bbox": [440, 634, 775, 673]}, {"image_id": 8, "file_name": "254_08.png", "page": 6, "dpi": 300, "bbox": [73, 74, 778, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Ridge extraction samples for C-FTLE on the sine ridge (top) and spiral focus (bottom) test field. Yellow ridges have been extracted from the ground truth (GT) fields at the highest resolution available. The leftmost image shows the ridge error plots of Figure 10 and 12. ", "caption_bbox": [73, 375, 775, 400]}, {"image_id": 9, "file_name": "254_09.png", "page": 7, "dpi": 300, "bbox": [440, 443, 777, 612], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Spiral focus: Resolution H plotted against TAU, color coding the resulting ridge error. Especially L-FTLE performs worse than in the sine ridge example in figure 10. ", "caption_bbox": [440, 626, 775, 665]}, {"image_id": 10, "file_name": "254_10.png", "page": 7, "dpi": 300, "bbox": [73, 442, 411, 684], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Sine ridge: H plotted against TAU, while color encodes the resulting ridge error for analytic and discrete field evaluation. C- FTLE performs better on lower resolutions, while the main character- istic is similar for all methods. ", "caption_bbox": [73, 698, 408, 750]}, {"image_id": 11, "file_name": "254_11.png", "page": 8, "dpi": 300, "bbox": [73, 73, 777, 193], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Double gyre deformed: FTLE field error plots for TAU = 10, H = 0.01 and P0 = 10. Note that the field error has a clear peak at the original ridge location, thus largest FTLE approximation deviations occur close to regions of high separation. ", "caption_bbox": [73, 208, 775, 233]}], "255": [{"image_id": 0, "file_name": "255_00.png", "page": 4, "dpi": 300, "bbox": [97, 76, 378, 179], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) path lines meeting the analytic condition defined in Sec. 4.2 and (b) their seeding positions. The color coding gives the temporal evolution of the path line (from yellow to red). ", "caption_bbox": [73, 197, 409, 235]}, {"image_id": 1, "file_name": "255_01.png", "page": 4, "dpi": 300, "bbox": [139, 249, 344, 367], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Scatter plot of the start-end distance (horizontal) and path line length (vertical). Red points represent path lines starting in or in the vicinity of the middle pipe. For further discussion see Sec. 4.2. ", "caption_bbox": [73, 382, 409, 420]}, {"image_id": 2, "file_name": "255_02.png", "page": 5, "dpi": 300, "bbox": [113, 74, 737, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Investigation of some of the clusters in Fig. 2. The top row shows the actual selections, while the bottom row gives the associated path lines in their 3D context (color coding according to temporal evolution from yellow to red). For the discussion of the figures, we refer to the main text (Sec. 4.2). ", "caption_bbox": [73, 338, 775, 362]}, {"image_id": 3, "file_name": "255_03.png", "page": 5, "dpi": 300, "bbox": [139, 388, 344, 505], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Scatter plot of the maximum velocity (horizontal) and the mean velocity along the path line (vertical). As in Fig. 2, red points represent path lines starting in or in the vicinity of the middle pipe. For further discussion see the main text in Sec. 4.2. ", "caption_bbox": [73, 520, 409, 571]}, {"image_id": 4, "file_name": "255_04.png", "page": 5, "dpi": 300, "bbox": [506, 388, 711, 505], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Scatter plot of the maximum curvature (horizontal) and the maximum torsion along the path line (vertical). As in Fig. 2 and 4, red points represent path lines starting in or in the vicinity of the middle pipe. For further discussion see the main text in Sec. 4.2. ", "caption_bbox": [440, 520, 775, 571]}, {"image_id": 5, "file_name": "255_05.png", "page": 6, "dpi": 300, "bbox": [509, 704, 707, 819], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Close-up of the seeding positions of the path lines in Fig. 8 compared to the seeding points of the reference path lines. We see that the difference between those two sets is hardly detectable. ", "caption_bbox": [440, 835, 775, 873]}, {"image_id": 6, "file_name": "255_06.png", "page": 6, "dpi": 300, "bbox": [143, 704, 341, 930], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The upper branch in the inv2 line plot together with the respective path lines (together with the previous described selection, see Sec.4.2). ", "caption_bbox": [73, 945, 408, 969]}, {"image_id": 7, "file_name": "255_07.png", "page": 6, "dpi": 300, "bbox": [123, 396, 699, 636], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Intermediate steps of the interactive flow analysis based on the attribute set proposed in this paper. The time line is left to right, top to bottom. Regular selections are marked in orange, not-selections in pink. The final result can be found in Fig. 8. A detailed description of the analysis steps is given in Sec.4.2. ", "caption_bbox": [73, 655, 775, 679]}, {"image_id": 8, "file_name": "255_08.png", "page": 6, "dpi": 300, "bbox": [120, 74, 731, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) The visually detectable \"abnormality\" in the scatter plot is selected. The path lines show the targeted behavior, but not all of them can be detected (cf. inset). (b) and (c) Due to the lack of visual clues, different thresholds are assessed, not showing the desired effect. For further discussion we refer to the main text (Sec. 4.2). For all three figures: Color coding of the path lines according to their temporal evolution (from yellow to red). ", "caption_bbox": [73, 344, 777, 382]}, {"image_id": 9, "file_name": "255_09.png", "page": 7, "dpi": 300, "bbox": [510, 388, 698, 493], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Top view on the path lines depicted in Fig. 11. The color coding is according to the attribute inv3, blue being low and red being high values. ", "caption_bbox": [440, 516, 775, 540]}, {"image_id": 10, "file_name": "255_10.png", "page": 7, "dpi": 300, "bbox": [143, 381, 341, 595], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Final result of the interactive flow analysis based on the her proposed feature set. We are able to identify the recirculation area in front of the of the obstacle described by Pobitzer et al. [23] ", "caption_bbox": [73, 622, 409, 660]}, {"image_id": 11, "file_name": "255_11.png", "page": 7, "dpi": 300, "bbox": [123, 74, 727, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Intermediate steps of the interactive flow analysis based on the attribute set proposed in this paper. The time line is top to bottom, left to right. The final result can be found in Fig. 11 and Fig. 12. A detailed description of the analysis steps is given in Sec.4.3. ", "caption_bbox": [73, 331, 775, 355]}], "256": [{"image_id": 0, "file_name": "256_00.png", "page": 1, "dpi": 300, "bbox": [81, 86, 769, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Aneurysm in the descending aorta. (a) Pathlines crossing the displayed ROI (white arrow) at t = 100ms. (b) Further subdivision into pathlines entering the brachiocephalic artery (yellow), the left carotid artery (light blue), and the left subclavian artery (blue). (c) Gray lines represent particles residing in the aneurysm for more than 150ms. Color-coded lines pass the aneurysm in less than 150ms. (d) Streamlines (at t = 180ms) with mean velocity greater than 80 cm    are directed at the aneurysm wall (white arrow). ", "caption_bbox": [73, 426, 775, 478]}, {"image_id": 1, "file_name": "256_01.png", "page": 5, "dpi": 300, "bbox": [74, 74, 409, 178], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Result of vortex predicate in the aorta aneurysm dataset based on \u03bb2 (left) and based on a dilated vortex core line (right). Color mapping shows mean velocity of a line. ", "caption_bbox": [73, 192, 408, 231]}, {"image_id": 2, "file_name": "256_02.png", "page": 6, "dpi": 300, "bbox": [82, 74, 768, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Healthy aorta (a,b). (a) Yellow isosurface represents the union of all streamlines running through the vortex in the ascending aorta. Yellow lines are a subset running also through the vortex in the descending aorta. The color-coded streamlines through the arch vortex are outside this isosurface and, thus, do not interact with the ascending vortex. (b) Characteristic set of streamlines starting at the ROI (white arrow) and running through vortex in the descending aorta reveal retrograde vortical flow in late systole. Distorted aorta dataset (c,d). Pathlines representing particles which are at some point faster than 130 cms                                                                    . (c) Velocity color mapping reveals these areas of fast flow. (d) Time color mapping shows at what time during the cardiac cycle the velocity was high. Note also the left-handed swirl developing further downstream of the bent in late systole. ", "caption_bbox": [73, 317, 775, 408]}, {"image_id": 3, "file_name": "256_03.png", "page": 7, "dpi": 300, "bbox": [80, 74, 770, 189], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Vortex in the proximal descending aorta of the 4D MRI of the distorted aorta. Pathlines run through the evolving vortex at t = 102ms. The dark line represents the vortex core line at t = 102ms, the light blue line (leftmost image) represents the core at t = 347ms. The remaining images show the course of the pathlines from seeding time until (from left right) 140ms, 200ms,300ms, 350ms ,500ms, 600ms, 700ms. ", "caption_bbox": [73, 203, 775, 242]}], "257": [{"image_id": 0, "file_name": "257_00.png", "page": 1, "dpi": 300, "bbox": [424, 86, 760, 548], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The four rendering styles studied, left to right: (a) OpenGL- style rendering without texture (LI), (b) LI with texture (LI+T), (c) global illumination rendering without texture (GI), and (d) global illu- mination rendering with texture (GI+T). Our study included conditions based on these four rendering styles shown both with and without motion. The sphere can be a proxy for a tumor in one of the tasks. The scene is also one of the small datasets used in the study. ", "caption_bbox": [440, 566, 776, 657]}, {"image_id": 1, "file_name": "257_01.png", "page": 4, "dpi": 300, "bbox": [90, 75, 760, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The three tasks studied and the UI used. (a) Depth-judgement task: participants were asked to report which of the two tubes was closer to their viewpoint. The answer here is green. The dataset rotates automatically when motion is present. (b) Visual-tracing task: participants were asked to trace a tube and mark its endpoint. When motion was enabled, participants could rotate the dataset using the arrow keys on the keyboard. (c) Contact-judgment task: participants were asked to judge the relationship between the blue sphere and its surrounding tubes. There are three possible answers: no penetration, tangential penetration and full penetration. The answer here is (3), full penetration. (d) User interface for cue choice. This display was shown after each task to ask about the cues used in answering the task questions. This is a multiple-choice question. ", "caption_bbox": [73, 269, 775, 360]}, {"image_id": 2, "file_name": "257_02.png", "page": 5, "dpi": 300, "bbox": [454, 74, 762, 367], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Summary of the F and p values for the main effects on task completion time. \u201c*\u201d indicates the significant main effects. ", "caption_bbox": [440, 441, 775, 467]}, {"image_id": 3, "file_name": "257_03.png", "page": 6, "dpi": 300, "bbox": [454, 73, 762, 367], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Contact-judgment task: effect of illumination model, mo- tion, texture, and scene complexity on task performance. (a) and (b) Motion and scene complexity had a significant impact on task completion time and error rate. (c) Combined effect: GI+M+T led to relatively longer task completion time. (d) Combined effect: GI+M+T led to the lowest error rate. ", "caption_bbox": [440, 399, 775, 477]}, {"image_id": 4, "file_name": "257_04.png", "page": 6, "dpi": 300, "bbox": [88, 73, 396, 525], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visual-tracing task: effect of illumination model, motion, texture, and scene complexity on task performance. (a) Motion, tex- ture, and scene complexity had a significant impact on time. (b) Illu- mination model, model and scene complexity had a significant impact on error rate. (c) Combined effect: GI+M+T was in different groups from LI, GI, LI+T, and GI+T accordingly. (d) Combined effect: LI+M led to the lowest error rate. (e) Only scene complexity was significant. (f) GI+M+T led to the most accurate answers. ", "caption_bbox": [73, 557, 408, 662]}], "258": [{"image_id": 0, "file_name": "258_00.png", "page": 3, "dpi": 300, "bbox": [248, 73, 603, 628], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Interfaces for both phases of the experiment. (a) Memorization phase. Participants play the video and click on \u201cnext sequence\u201d when they believe that they have memorized the graph. (b) Recall Phase. A question in the upper right corner asks if the graph was present in the memorization block. Participants are presented with two possible answers \u201cyes\u201d and \u201cno\u201d. They select the appropriate radio button and click \u201csubmit answer\u201d to respond. In both cases, Threads2 is shown. ", "caption_bbox": [73, 646, 775, 698]}, {"image_id": 1, "file_name": "258_01.png", "page": 4, "dpi": 300, "bbox": [72, 155, 821, 868], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The three levels of mental map preservation used in this experiment on the van de Bunt data set. The \u201cWithout mental map preservation\u201d level does not attempt to preserve the mental map at all. The medium level has inter-timeslice edges set to 60, and the high level has inter-timeslice edges set to 400 with nodes pinned to their average positions. ", "caption_bbox": [73, 878, 775, 917]}, {"image_id": 2, "file_name": "258_02.png", "page": 6, "dpi": 300, "bbox": [93, 73, 757, 414], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Response time and error rate divided by data set. No significant difference was found in either response time or error rate for any of the data sets individually. ", "caption_bbox": [73, 424, 775, 450]}, {"image_id": 3, "file_name": "258_03.png", "page": 6, "dpi": 300, "bbox": [74, 478, 409, 613], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Response time and error rate for high, medium, and no mental map preservation over all data sets. We found no significant difference in terms of response time (p = 0.19) or error rate (p = 0.27) in this data. ", "caption_bbox": [73, 631, 409, 683]}, {"image_id": 4, "file_name": "258_04.png", "page": 7, "dpi": 300, "bbox": [75, 304, 409, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Results of our ranked survey data. Lines between bars indicate where significance was found. (a) Question 1: We found that no node movement was significantly easier than short movement and large movement. (b) Question 2: We found certain groups of nodes (subgraphs) and constant node position significantly more important than large node movement. ", "caption_bbox": [73, 448, 408, 526]}, {"image_id": 5, "file_name": "258_05.png", "page": 7, "dpi": 300, "bbox": [222, 73, 628, 228], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Table of preference data. The top part of the table compares the three mental map preservation conditions while the bottom part compares the importance of certain layout features. We found that no movement in node position was significantly preferred to large movement and small movement. We also found that subgraphs and constant position were significantly more important than large node movement. ", "caption_bbox": [73, 238, 775, 277]}], "259": [{"image_id": 0, "file_name": "259_00.png", "page": 4, "dpi": 300, "bbox": [74, 284, 393, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Implementation of the Kamada-Kawai force model.", "caption_bbox": [92, 384, 389, 396]}, {"image_id": 1, "file_name": "259_01.png", "page": 5, "dpi": 300, "bbox": [444, 511, 770, 697], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Optimization of scalar potentials for the 3elt graph.", "caption_bbox": [460, 704, 756, 716]}, {"image_id": 2, "file_name": "259_02.png", "page": 5, "dpi": 300, "bbox": [78, 511, 404, 699], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Times for numerical optimization.", "caption_bbox": [136, 707, 348, 719]}, {"image_id": 3, "file_name": "259_03.png", "page": 5, "dpi": 300, "bbox": [78, 74, 404, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Total execution times.", "caption_bbox": [164, 269, 319, 281]}, {"image_id": 4, "file_name": "259_04.png", "page": 5, "dpi": 300, "bbox": [444, 74, 771, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Average final scalar potentials.", "caption_bbox": [508, 269, 707, 281]}, {"image_id": 5, "file_name": "259_05.png", "page": 5, "dpi": 300, "bbox": [78, 292, 404, 480], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Times for computing graph-theoretic distances.", "caption_bbox": [102, 488, 381, 500]}, {"image_id": 6, "file_name": "259_06.png", "page": 5, "dpi": 300, "bbox": [444, 292, 771, 480], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Minimum final scalar potentials.", "caption_bbox": [506, 488, 710, 500]}, {"image_id": 7, "file_name": "259_07.png", "page": 6, "dpi": 300, "bbox": [109, 77, 741, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The sierpinski 04 graph drawn by (a) L-BFGS/KK, (b) L-BFGS/HC, (c) L-BFGS/Eades, (d) L-BFGS/FR, (e) neato/KK, (f) neato/major, (g) fdp, and (h) sfdp. ", "caption_bbox": [73, 434, 775, 460]}, {"image_id": 8, "file_name": "259_08.png", "page": 7, "dpi": 300, "bbox": [99, 77, 751, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The rna graph drawn by (a) L-BFGS/KK, (b) L-BFGS/HC, (c) L-BFGS/Eades, (d) L-BFGS/FR, (e) neato/KK, (f) neato/major, (g) fdp, and (h) sfdp. ", "caption_bbox": [73, 411, 775, 437]}, {"image_id": 9, "file_name": "259_09.png", "page": 8, "dpi": 300, "bbox": [114, 90, 736, 414], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The sierpinski 06 graph drawn by (a) L-BFGS/KK, (b) L-BFGS/HC, (c) L-BFGS/Eades, (d) L-BFGS/FR, (e) neato/KK, (f) neato/major, (g) fdp, and (h) sfdp. ", "caption_bbox": [73, 441, 775, 467]}, {"image_id": 10, "file_name": "259_10.png", "page": 8, "dpi": 300, "bbox": [93, 508, 770, 947], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Graphs drawn by L-BFGS/KK and sfdp: (a)(b) flower 005, (c)(d) 3elt, (e)(f) uk, (g)(h) add32, (i)(j) sierpinski 08, and (k)(l) crack.", "caption_bbox": [87, 973, 761, 985]}], "26": [{"image_id": 0, "file_name": "26_00.png", "page": 1, "dpi": 300, "bbox": [439, 456, 739, 594], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A psychological framework for data visu- alization. Based on Lee and Vickers (1998, Figure 1). ", "caption_bbox": [427, 631, 749, 673]}, {"image_id": 1, "file_name": "26_01.png", "page": 4, "dpi": 300, "bbox": [441, 471, 737, 686], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The faces visualization of the animals data set. ", "caption_bbox": [427, 441, 749, 469]}, {"image_id": 2, "file_name": "26_02.png", "page": 5, "dpi": 300, "bbox": [87, 421, 404, 738], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The distinctive spatial visualization of the animals data set. ", "caption_bbox": [83, 388, 405, 416]}, {"image_id": 3, "file_name": "26_03.png", "page": 5, "dpi": 300, "bbox": [97, 119, 393, 331], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The stars visualization of the animals data set. ", "caption_bbox": [83, 86, 405, 114]}, {"image_id": 4, "file_name": "26_04.png", "page": 5, "dpi": 300, "bbox": [432, 119, 748, 436], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The common spatial visualization of the animals data set. ", "caption_bbox": [427, 86, 749, 114]}, {"image_id": 5, "file_name": "26_05.png", "page": 6, "dpi": 300, "bbox": [431, 413, 749, 667], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Mean con\ufb01dence across the four visu- alization types (Fa=\u2018face glyph\u2019, St=\u2018star glyph\u2019, Di=\u2018distinctive spatial\u2019, Co=\u2018common spatial\u2019). ", "caption_bbox": [427, 684, 749, 726]}, {"image_id": 6, "file_name": "26_06.png", "page": 6, "dpi": 300, "bbox": [431, 76, 749, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Mean accuracy across the four visu- alization types (Fa=\u2018face glyph\u2019, St=\u2018star glyph\u2019, Di=\u2018distinctive spatial\u2019, Co=\u2018common spatial\u2019). ", "caption_bbox": [427, 341, 749, 383]}, {"image_id": 7, "file_name": "26_07.png", "page": 7, "dpi": 300, "bbox": [86, 76, 405, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Mean response time across the four vi- sualization types (Fa=\u2018face glyph\u2019, St=\u2018star glyph\u2019, Di=\u2018distinctive spatial\u2019, Co=\u2018common spatial\u2019). ", "caption_bbox": [83, 343, 405, 385]}], "260": [{"image_id": 0, "file_name": "260_00.png", "page": 4, "dpi": 300, "bbox": [460, 345, 757, 611], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Drawings by (a) PivotMDS, (b) PivotMDS(1), (c) Maxent and (d) sfdp, on the 1138 bus graph ", "caption_bbox": [440, 611, 775, 635]}, {"image_id": 1, "file_name": "260_01.png", "page": 7, "dpi": 300, "bbox": [113, 69, 371, 421], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Drawings by (a) FSM, (b) PivotMDS (c) PivotMDS(1), (d) Pivot- MDS(2), (e) Maxent and (f) Maxent(2) on the lp ship04l graph. ", "caption_bbox": [73, 420, 408, 444]}, {"image_id": 2, "file_name": "260_02.png", "page": 7, "dpi": 300, "bbox": [460, 62, 757, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Original graph (a), and drawings by (b) PivotMDS, (c) PivotMDS(1), (d) PivotMDS(2), (e) Maxent and (f) Maxent(2) on the commanche graph. ", "caption_bbox": [440, 341, 775, 365]}], "261": [{"image_id": 0, "file_name": "261_00.png", "page": 2, "dpi": 300, "bbox": [80, 75, 403, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Original unbundled graph of 2263 trust relations between 50 nodes in a wireless network. The grey grids in the background shows wireless connectivity between the nodes, while the colored lines are their trust relations established upon packet transmission along the wireless links. The lower color gradient bar is used to encode the low-to-high trust level. ", "caption_bbox": [73, 440, 408, 518]}, {"image_id": 1, "file_name": "261_01.png", "page": 3, "dpi": 300, "bbox": [75, 76, 784, 210], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Processing pipeline of SideKnot. Edges are colored for illustration purpose only.", "caption_bbox": [204, 229, 644, 241]}, {"image_id": 2, "file_name": "261_02.png", "page": 3, "dpi": 300, "bbox": [79, 267, 404, 387], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The clustering algorithm.", "caption_bbox": [155, 402, 326, 414]}, {"image_id": 3, "file_name": "261_03.png", "page": 3, "dpi": 300, "bbox": [456, 267, 760, 504], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Spline-controlled edge bundling process. Up: an edge (in bold) is connecting nodes N1 and N2 ; this edge belongs to the red clusters for node N1 and N2 , respectively; we find control points C1 and C2 along the average direction of both clusters. Down: a spline (in bold) is generated with control points C1 and C2 . ", "caption_bbox": [440, 518, 775, 584]}, {"image_id": 4, "file_name": "261_04.png", "page": 4, "dpi": 300, "bbox": [471, 74, 745, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Illustration of the edge dispersing process. A spline is broken into N line segments P0 P1 ...PN . User defines EdgeLens center E and its radius of influence r. All line segments with distance to E less than r are dispersed by adding control point C. ", "caption_bbox": [440, 290, 775, 342]}, {"image_id": 5, "file_name": "261_05.png", "page": 5, "dpi": 300, "bbox": [79, 74, 403, 410], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Integration with EdgeLens [25]. (a)Part of the bundled result of the U.S. airline graph. A node is blocked by a bundle of edges. (b) Edges dispersed from a user-defined point (green dot). ", "caption_bbox": [73, 426, 408, 465]}, {"image_id": 6, "file_name": "261_06.png", "page": 6, "dpi": 300, "bbox": [73, 562, 777, 906], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Edge bundling for U.S. airline route graph. (a) Original graph with 235 nodes and 2101 edges. (b) Bundled with GBEB [5]. (c) Bundled with FDEB [13]. (d) Bundled with our method. Our visualization shows a number of middle-western cities (e.g. HDN, EGE, DEN, COS and more) have more routes to the east than to the west, suggesting their stronger connections with the eastern part of U.S. ", "caption_bbox": [73, 922, 775, 961]}, {"image_id": 7, "file_name": "261_07.png", "page": 6, "dpi": 300, "bbox": [73, 112, 777, 447], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Bundled result for trust graph (Figure 1). (a) Bundled result. (b) Node B is selected by user and its trust relations get highlighted.", "caption_bbox": [86, 463, 762, 475]}, {"image_id": 8, "file_name": "261_08.png", "page": 8, "dpi": 300, "bbox": [79, 76, 772, 492], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: World airline route graph collected by openflights.org [1]. (a) Original graph with 6630 nodes and 58278 edges. (b) Bundled with our method. (c-d) Zoom in near New York and Amsterdam with routes connecting JFK and AMS highlighted, respectively. ", "caption_bbox": [73, 507, 775, 533]}], "262": [{"image_id": 0, "file_name": "262_00.png", "page": 2, "dpi": 300, "bbox": [137, 74, 712, 355], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview for constructing event databases from blog posts in blog archive by using dependency analysis", "caption_bbox": [142, 360, 703, 372]}, {"image_id": 1, "file_name": "262_01.png", "page": 3, "dpi": 300, "bbox": [121, 74, 362, 205], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Dependency structure for Japanese sentence: \u201cA 13-year- old girl newly caught swine flu (Aratani 13-sai-no shoujo-ga shingata- influenza-ni kansensita)\u201d. Dependency relations with a thick line form an event ", "caption_bbox": [73, 212, 408, 264]}, {"image_id": 2, "file_name": "262_02.png", "page": 3, "dpi": 300, "bbox": [121, 280, 362, 373], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Dependency structure for Japanese sentence: \u201cA child died of swine flu in California (California-de jidou-ga shingata-influenza-de shibou-sita)\u201d ", "caption_bbox": [73, 381, 408, 420]}, {"image_id": 3, "file_name": "262_03.png", "page": 4, "dpi": 300, "bbox": [463, 73, 754, 327], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualizing set of events by using tree on TimeSlice, which indicates both original in Japanese and translated words in English ", "caption_bbox": [440, 332, 775, 358]}, {"image_id": 4, "file_name": "262_04.png", "page": 4, "dpi": 300, "bbox": [74, 74, 411, 537], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Multiple TimeSlices for comparing events in different months and for comparing events on different topics ", "caption_bbox": [73, 542, 408, 568]}, {"image_id": 5, "file_name": "262_05.png", "page": 4, "dpi": 300, "bbox": [441, 380, 775, 563], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualization of detailed information on selected event", "caption_bbox": [451, 570, 764, 582]}, {"image_id": 6, "file_name": "262_06.png", "page": 5, "dpi": 300, "bbox": [439, 77, 766, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Parallel view", "caption_bbox": [552, 355, 663, 367]}, {"image_id": 7, "file_name": "262_07.png", "page": 6, "dpi": 300, "bbox": [103, 74, 379, 443], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison of temporal changes in frequency between events on different topics by using multiple TimeFluxes ", "caption_bbox": [73, 448, 408, 474]}, {"image_id": 8, "file_name": "262_08.png", "page": 7, "dpi": 300, "bbox": [182, 74, 667, 454], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Visualizing changes in trends on St. Valentine\u2019s Day in Japan", "caption_bbox": [250, 459, 599, 471]}], "264": [{"image_id": 0, "file_name": "264_00.png", "page": 1, "dpi": 300, "bbox": [73, 111, 778, 513], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The ScatterBlogs workbench showing spatiotemporal term usage anomalies extracted from geolocated Twitter messages. Some of the visible anomalies correspond to power outage events during hurricane Irene on August 27, 2011. ", "caption_bbox": [73, 528, 775, 553]}, {"image_id": 1, "file_name": "264_01.png", "page": 4, "dpi": 300, "bbox": [75, 78, 403, 348], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Three activities to generate an overview of anomalies: 1) Message terms are extracted and transformed to term artifacts. 2) Microblog Quantization of term artifacts generates spatiotemporal clusters. 3) Clusters selected by the decision strategy are considered as anomalies and represented as term map overlay for exploration. ", "caption_bbox": [73, 371, 408, 436]}, {"image_id": 2, "file_name": "264_02.png", "page": 7, "dpi": 300, "bbox": [73, 73, 778, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: From left to right: The first image shows the map overview showing the earthquake on 23 August 2011. Additionally, the temporal distribution of the term \u2018earthquake\u2019 is depicted in our time-slider tool at a minute-by-minute resolution. The second view depicts all earthquake tags shown within the first minute after the event is mentioned in Twitter. It gives a rough impression of the shock\u2019s epicenter, which was actually located 63 miles northwest of Richmond. The third image depicts the usage of our lens-tool while searching for reported damage at buildings. ", "caption_bbox": [73, 277, 775, 329]}], "265": [{"image_id": 0, "file_name": "265_00.png", "page": 2, "dpi": 300, "bbox": [87, 79, 776, 605], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualizing multiple maps requires both layout stability and color stability. (a): mtDNA similarity visualized as a graph. (b): mtDNA similarity visualized as a map. (c): NRY DNA similarity map which is difficult to compare with (b) as the node layout is computed independently. (d): NRY DNA similarity map, computed to optimize node layout stability with regard to (b), which makes is possible to compare nodes, while clusters are still hard to compare. (e): NRY DNA similarity map with optimal node layout and color assignments, which makes it easy to compare with (b); e.g., it is clear that two clusters in the top left of (b) are now merged. ", "caption_bbox": [73, 611, 775, 660]}, {"image_id": 1, "file_name": "265_01.png", "page": 3, "dpi": 300, "bbox": [448, 75, 775, 530], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: World trade maps: (a) clustering of countries based on total im- port/export values between countries; (b) clustering of countries based on total import/export fractions; (c) same clustering as (b), but with color stability. ", "caption_bbox": [440, 535, 775, 572]}, {"image_id": 2, "file_name": "265_02.png", "page": 4, "dpi": 300, "bbox": [127, 74, 356, 364], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A map of Europe and Africa from a poster for the Woermann-Linie. Note that the colors of countries in Europe match the colors of the colonies in Africa: Mozambique and Portugal, Germany and Namibia, France and Sene- gal, Belgium and Congo, etc. ", "caption_bbox": [73, 371, 408, 420]}, {"image_id": 3, "file_name": "265_03.png", "page": 5, "dpi": 300, "bbox": [466, 73, 736, 126], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The affine transformation pipeline. X t denotes the layout at time t. This layout is transformed to fit the previous frame X\u0304 t\u22121 as close as possible to give the current frame X\u0304 t , and the frames are what the user sees. ", "caption_bbox": [440, 134, 775, 171]}, {"image_id": 4, "file_name": "265_04.png", "page": 6, "dpi": 300, "bbox": [468, 74, 754, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Trajectories of randomly selected nodes with three different lay- out stability methods. (Top) independent layout with average distance traveled 21.41; (Middle) layout initialized with positions from the previous frame with average distance traveled 13.19; (Bottom) initialized positions and Procrustes transformation, with average distance traveled 8.43. ", "caption_bbox": [440, 367, 775, 429]}, {"image_id": 5, "file_name": "265_05.png", "page": 7, "dpi": 300, "bbox": [81, 74, 774, 942], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A sequence of maps obtained by combining mtDNA and NRY DNA similarity metrics. Note that in both sequences the clusters match well and the colors of the clusters also match well. The sequence in the left and right employ different node stabilization: (Left) sequence obtained without affine transformation; (Right) a sequence obtained with affine transformation. Note that although both this Figure and Figure 1 are part of the same animation, this Figure is the result of quite different weight values from that of Figure 1, thus the figures do not look similar. ", "caption_bbox": [73, 958, 775, 1007]}, {"image_id": 6, "file_name": "265_06.png", "page": 8, "dpi": 300, "bbox": [73, 63, 413, 566], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A sequence of GD collaboration graphs: 2000, 2001 and 2002.", "caption_bbox": [81, 583, 400, 595]}], "266": [{"image_id": 0, "file_name": "266_00.png", "page": 2, "dpi": 300, "bbox": [80, 81, 420, 557], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: ppe can provide additional insight into the data, such as outliers (a) or trends (b,c). This information is usually hidden by clut\u00ad ter (d), but can be made visible by using an appropriate strategy for hierarchy-building like clustering (a), wavelet transform (b), or recur\u00ad sive interval subdivision (c). Due to the strongly decreased number of displayed primitives (in  %), early refinement stages are especially well-suited to convey data properties covered within the fully detailed display. This also reduces resource consumption. ", "caption_bbox": [73, 583, 409, 691]}, {"image_id": 1, "file_name": "266_01.png", "page": 3, "dpi": 300, "bbox": [68, 81, 423, 216], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Recursive interval subdivision of the values of a selected dimension is based on incremental splits of a given interval in two new intervals. This approach successively reduces the value range leading to efficient and low-complexity forms of data compression founded on li-coding. ", "caption_bbox": [73, 226, 409, 295]}, {"image_id": 2, "file_name": "266_02.png", "page": 3, "dpi": 300, "bbox": [438, 68, 795, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration of an LOD hierarchy for PPC constructed by RISD: Inner nodes of the hierarchy represent aggregations associ\u00ad ated with the corresponding data interval. All nodes of a hierarchy level contribute to the visual appearance of the presentation at the particular level (center). The presentation gains accuracy with each incremental refinement stage. Only incremental data (li) are needed to encode these changes efficiently. ", "caption_bbox": [440, 319, 776, 411]}, {"image_id": 3, "file_name": "266_03.png", "page": 4, "dpi": 300, "bbox": [76, 71, 777, 352], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visual representation of the LOD hierarchies resulting from RISD by lines (a) and polygons (b), from a wavelet transform by lines (c), and hierarchical clustering by polygons (d). The individual previews represent the refinement stages 1, 3, 6, 9, 11, and 14 (from left to right). The strongly different representations and refinements of an identical data set can be used to convey different properties of the data. Refinement to the highest LOD leads to the traditional PC plot for all approaches. ", "caption_bbox": [73, 364, 776, 420]}, {"image_id": 4, "file_name": "266_04.png", "page": 4, "dpi": 300, "bbox": [446, 833, 787, 960], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Ordering dependent on pre-defined or current interests: Different traversals of the LaD hierarchy lead to different previews. ", "caption_bbox": [440, 971, 775, 1001]}, {"image_id": 5, "file_name": "266_05.png", "page": 5, "dpi": 300, "bbox": [438, 826, 781, 957], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: PPC applied to quickly adapt the presentation to the screen estate available on the respective viewing device. ", "caption_bbox": [440, 971, 775, 1001]}, {"image_id": 6, "file_name": "266_06.png", "page": 5, "dpi": 300, "bbox": [69, 589, 421, 753], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Dimension-ot-interest retinement prioritizing important di\u00ad mensions. In this example importance decreases from the left to the right axis. Dimensions may also be prioritized interactively. ", "caption_bbox": [73, 765, 408, 809]}, {"image_id": 7, "file_name": "266_07.png", "page": 5, "dpi": 300, "bbox": [78, 84, 777, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Cluster-of-interest refinement to prioritize and refine on a cluster basis. Red poly gons represent clusters selected for refinement in the next preview, orange polygons clusters that are currently refined. Interesting clusters can be pre-defined or interactively selected. ", "caption_bbox": [73, 269, 775, 296]}, {"image_id": 8, "file_name": "266_08.png", "page": 6, "dpi": 300, "bbox": [435, 729, 789, 914], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Data volume (blue bars) associated with the different re\u00ad finement stages using R ISD for no, constraint range coding, and L\u00ad coding. The computing power (red line) needed to decode and dis\u00ad play L-coded data shows the correlation with data volume and the low complexity of the processes. ", "caption_bbox": [439, 935, 775, 1001]}, {"image_id": 9, "file_name": "266_09.png", "page": 6, "dpi": 300, "bbox": [435, 70, 788, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Time needed to calculate and L-code the LOD hierarchy for data sets of different volumes using the discussed scalability ap\u00ad proaches. ", "caption_bbox": [440, 274, 775, 313]}, {"image_id": 10, "file_name": "266_10.png", "page": 7, "dpi": 300, "bbox": [458, 269, 762, 469], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The number of refinement levels required to detect a pat\u00ad tern (left) indicates that the majority of users (encoded by point size) achieved the task by previews only. The median of the stated levels (yellow reference lines) is significantly different to the number of all available levels (black reference lines). There was also a large pref\u00ad erence for PPC with reg ard to assistance and acceptance (right). We interpret this as an indication for an improved user experience. ", "caption_bbox": [439, 484, 775, 576]}], "267": [{"image_id": 0, "file_name": "267_00.png", "page": 1, "dpi": 300, "bbox": [72, 85, 776, 364], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 1: Storyboarding and storytelling with the Sales dataset. (a) Original dimension network display laid out by data correlations, along with automatically computed optimal route. (b) Linked parallel coordinate display [17] with axis order determined by the route in (a). (c) The user zooms into the network (blue rectangle in (a)) and manually specifies a route that seems to best capture the story \u2013 the strategic model of win- ning the most customers (see Section 5 for more detail), (d) Linked parallel coordinate display with updated axes ordering according to the route of (c). ", "caption_bbox": [68, 374, 775, 442]}, {"image_id": 1, "file_name": "267_01.png", "page": 3, "dpi": 300, "bbox": [73, 85, 404, 171], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 2: The network generation pipeline.", "caption_bbox": [139, 180, 336, 192]}, {"image_id": 2, "file_name": "267_02.png", "page": 3, "dpi": 300, "bbox": [434, 86, 773, 205], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 3: Dimension layout in the Cars dataset via a mass-spring mod- el. Higher color saturation on edges represents high correlation val- ues. Green represents positive correlation, while red represents negative. (a) Layout with absolute correlation strength; (b) layout with positive correlation; (c) layout with negative correlation prefer- ence. ", "caption_bbox": [433, 214, 773, 296]}, {"image_id": 3, "file_name": "267_03.png", "page": 4, "dpi": 300, "bbox": [91, 83, 754, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) A tour of the Cars dataset. In the network display, the dimension ordering is given as a series of directed edges color-coded by correlation value. (b) Parallel Coordinate display. The dimension triples (Horsepower, Cylinder, and Weight) and (Year, MPG, and Origin) are put next to each other in the parallel coordinate display because they are strongly correlated with each other. These strong positive cor- relations can be seen on the network display also. (c) Correlation display colors the outlines of line bundles (see [17]) in terms of their corre- lation strength (less saturation maps to lower correlation). We can also discern negative correlations by the characteristic bow-tie shapes. ", "caption_bbox": [75, 239, 768, 307]}, {"image_id": 4, "file_name": "267_04.png", "page": 5, "dpi": 300, "bbox": [74, 85, 766, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 5: User interaction and constraint imposition for the Cars dataset. (a) Network Display with Year being filtered out by multi-scale zooming. (b) The route is edited to avoid unrelated dimensions Year and Origin. (c) Routing with a cyclical constraint. Dimension Horsepower is visited more than once, which makes it adjacent to 4 dimensions (MPG, Weight, Cylinders, and Acceleration). The corresponding parallel coordinate display is shown in (d), where we can see that Horsepower has been duplicated. ", "caption_bbox": [73, 242, 771, 296]}, {"image_id": 5, "file_name": "267_05.png", "page": 5, "dpi": 300, "bbox": [75, 757, 407, 894], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 6: Zooming out in the Network Display of a 25-dimensional syn- thetic dataset. Representative dimensions (F, P, S) are displayed by double lines in the parallel coordinates display (a) and double circles in the network display (b). Also, the number of dimensions hidden by each representative dimension is given by the small number in the upper left corner of its vertex in the network display. ", "caption_bbox": [74, 903, 419, 985]}, {"image_id": 6, "file_name": "267_06.png", "page": 6, "dpi": 300, "bbox": [74, 82, 772, 228], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 7: The effect of dimension bracketing, using the global seawater oxygen-18 dataset. (a), (b) Parallel coordinate and network display of the original dataset with undefined values in dimension depth, temp, salinity and d180. (c), (d) After filtering out the undefined values and bracket- ing the dimensions. We can now see a strong positive correlation between salinity and d18O (green arrow in (d)), while in the original, unfil- tered dataset with undefined values, d18O is incorrectly shown not to be strongly correlated with any other dimensions (green arrow in (b)). ", "caption_bbox": [74, 236, 775, 290]}, {"image_id": 7, "file_name": "267_07.png", "page": 7, "dpi": 300, "bbox": [70, 80, 765, 390], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 8: Comparison of our automatic dimension ordering algorithm with other methods. (a) Original ordering. (b) The clutter-based ordering of Peng et al. [18] is unable to put the proper dimension order to show sub-clusters. (c) Ankerst\u2019s method [1] can capture the two subspaces, but the other un-related dimensions are split into two parts. Figures 8b and 8c are generated by xmdvTool [26]. (d) Ferdosi\u2019s subspace-based dimension ordering [8], which is able to capture the structure of the dataset (2 cluster subspace highlighted in red rectangle and 3 cluster sub- space highlighted in blue rectangle). (e) Our method: the result is quite similar to (d). ", "caption_bbox": [69, 399, 770, 467]}], "268": [{"image_id": 0, "file_name": "268_00.png", "page": 1, "dpi": 300, "bbox": [91, 144, 760, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: One circular parameterization of the memory behavior of bubble sort (box (a)) morphing into another (box (b)), highlighting both their similarities and differences, and giving two views of the recurrent nature of the program. ", "caption_bbox": [73, 360, 775, 386]}, {"image_id": 1, "file_name": "268_01.png", "page": 3, "dpi": 300, "bbox": [485, 87, 736, 206], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The circular structure on the left has high persistence while the one on the right is considered topological noise [10]. ", "caption_bbox": [440, 213, 775, 239]}, {"image_id": 2, "file_name": "268_02.png", "page": 3, "dpi": 300, "bbox": [103, 75, 381, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Algorithm pipeline: (a)-(c) data points to nested family of simplicial complexes; (d) detection of signi\ufb01cant cohomology class and its transformation into a circle-valued function; (e) color map encoding. ", "caption_bbox": [73, 299, 408, 352]}, {"image_id": 3, "file_name": "268_03.png", "page": 3, "dpi": 300, "bbox": [476, 809, 743, 942], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A point cloud X is sampled from a genus-4 surface. We construct four circle-valued coordinate functions that correspond to its signi\ufb01cant circular structures, visualized by color map transfer functions. ", "caption_bbox": [440, 950, 776, 1003]}, {"image_id": 4, "file_name": "268_04.png", "page": 4, "dpi": 300, "bbox": [101, 78, 381, 190], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Available visualization options for parameterized data. (a) The parameterization is placed in a circular structure. (b) Time is applied to the radius. (c-d): The data points are correlated back to source code using a color map. ", "caption_bbox": [439, 220, 775, 273]}, {"image_id": 5, "file_name": "268_05.png", "page": 4, "dpi": 300, "bbox": [442, 74, 776, 202], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Details of the data used in our experiments.", "caption_bbox": [479, 987, 736, 1000]}, {"image_id": 6, "file_name": "268_06.png", "page": 5, "dpi": 300, "bbox": [441, 75, 773, 176], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The block and loop structure of blocked matrix multiplication.", "caption_bbox": [440, 184, 778, 197]}, {"image_id": 7, "file_name": "268_07.png", "page": 6, "dpi": 300, "bbox": [107, 73, 741, 552], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Various recurrent runtime structures within a bubble sort of \ufb01ve numbers ordered (a-b) ascendingly, (c-d) descendingly, and (e-f) randomly. (g-h) Versions of (b-c) in which a bare array has been used in place of STL vectors, eliminating many overhead memory accesses associated with the STL. ", "caption_bbox": [73, 557, 776, 597]}, {"image_id": 8, "file_name": "268_08.png", "page": 7, "dpi": 300, "bbox": [88, 343, 394, 941], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Various recurrent runtime structures within matrix multipli- cation algorithms. (a-c) Standard matrix multiplication. (d-f) Blocked matrix multiplication. Top: source code for standard implementation. Bottom: source code for blocked implementation. ", "caption_bbox": [73, 948, 411, 1001]}, {"image_id": 9, "file_name": "268_09.png", "page": 7, "dpi": 300, "bbox": [456, 73, 760, 381], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Interpolating mass and momentum in MPM. (a) Interpola- tion operation for a single particle. (b) A dual view of (a), expanding a non-interpolation action into the circular structures. ", "caption_bbox": [440, 385, 777, 425]}, {"image_id": 10, "file_name": "268_10.png", "page": 8, "dpi": 300, "bbox": [89, 74, 394, 321], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Analyzing the MPM trace at a larger scale. (a) 1000 consecutive trace records (no sampling). (b) 1000 trace records produced by sampling 1 of every 10 records from a segment of 10000 consecutive trace records. (c) A dual view of (b) showing recurrences later in the trace. ", "caption_bbox": [73, 321, 408, 387]}], "269": [{"image_id": 0, "file_name": "269_00.png", "page": 1, "dpi": 300, "bbox": [73, 86, 777, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Four different visual composition operators (from the left): juxtaposition, superimposition, overloading, and nesting.", "caption_bbox": [120, 242, 729, 254]}, {"image_id": 1, "file_name": "269_01.png", "page": 2, "dpi": 300, "bbox": [439, 74, 777, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: ComVis [24] (Juxtaposed Views). Meteorology data.", "caption_bbox": [454, 287, 761, 299]}, {"image_id": 2, "file_name": "269_02.png", "page": 2, "dpi": 300, "bbox": [440, 315, 776, 497], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Improvise [39] (Juxtaposed Views). Juxtaposed views are used to explore the simulated ion trajectory in a cubic ion trap. ", "caption_bbox": [440, 511, 775, 536]}, {"image_id": 3, "file_name": "269_03.png", "page": 3, "dpi": 300, "bbox": [443, 75, 777, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: VisLink [11] (Integrated Views). Radial and force-directed graphs on separate visualization planes linked with visual edges. ", "caption_bbox": [440, 287, 775, 312]}, {"image_id": 4, "file_name": "269_04.png", "page": 3, "dpi": 300, "bbox": [73, 491, 411, 774], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Semantic Substrates [34] (Integrated Views). Network visualization of a dataset of court cases using semantic substrates. ", "caption_bbox": [73, 789, 408, 814]}, {"image_id": 5, "file_name": "269_05.png", "page": 4, "dpi": 300, "bbox": [439, 598, 778, 946], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Links on treemaps [14] (Overloaded Views). The tool identifies a tree structure in a graph and visualizes it using a treemap. ", "caption_bbox": [440, 960, 775, 985]}, {"image_id": 6, "file_name": "269_06.png", "page": 4, "dpi": 300, "bbox": [439, 379, 778, 532], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: SPPC [45] (Overloaded Views). This tool overloads points into the region bounded by two axes in the parallel coordinate plot. ", "caption_bbox": [440, 547, 775, 572]}, {"image_id": 7, "file_name": "269_07.png", "page": 4, "dpi": 300, "bbox": [73, 337, 411, 560], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: GeoSpace [22] (Superimposed Views). A crime data layer superimposed on a geographical map of the Cambridge, MA area. ", "caption_bbox": [73, 574, 408, 599]}, {"image_id": 8, "file_name": "269_08.png", "page": 4, "dpi": 300, "bbox": [76, 86, 409, 276], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Mapgets [38] (Superimposed Views). Presentation stack, with superimposed layers for rivers, borders, and labels, in Mapgets. ", "caption_bbox": [73, 296, 408, 321]}, {"image_id": 9, "file_name": "269_09.png", "page": 5, "dpi": 300, "bbox": [73, 317, 411, 572], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: ZAME [13] (Nested Views). Visual exploration of a protein-protein interaction dataset in ZAME. ", "caption_bbox": [73, 587, 408, 612]}, {"image_id": 10, "file_name": "269_10.png", "page": 5, "dpi": 300, "bbox": [439, 275, 793, 420], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: NodeTrix [17] (Nested Views). This example shows a visualization of the InfoVis co-authorship network. ", "caption_bbox": [440, 436, 775, 461]}, {"image_id": 11, "file_name": "269_11.png", "page": 7, "dpi": 300, "bbox": [89, 371, 761, 494], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Example of composing a scatterplot and bar graph using different methods.", "caption_bbox": [212, 512, 636, 524]}], "27": [], "270": [], "271": [], "272": [{"image_id": 0, "file_name": "272_00.png", "page": 1, "dpi": 300, "bbox": [424, 86, 778, 428], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization of a vector field from a simulation of coseis- mic displacements [38] (Sec. 5.2). The image (a) shows the result of our automatically generated visualization including a rough rep- resentation of the context as background and the strongly expressed features on top. Those occur mostly along the fault moving from top to down. The image (c) shows the detailed hybrid visualiza- tion technique developed by Chen et al. [4] consisting of hyper- streamlines and elliptical glyphs. Image (b) is the sketch drawn by domain experts on basis of (c) and motivated our work. ", "caption_bbox": [440, 440, 775, 564]}, {"image_id": 1, "file_name": "272_01.png", "page": 3, "dpi": 300, "bbox": [536, 80, 683, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Critical points of a scalar function. The size of the spheres is determined by homological persistence. There are 38000 critical points contained in the dataset, but homological persistence classi- fies most of them as unimportant. ", "caption_bbox": [440, 211, 775, 266]}, {"image_id": 2, "file_name": "272_02.png", "page": 3, "dpi": 300, "bbox": [469, 295, 747, 432], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Simplified schematic illustration of the persistence con- cept. In both images M1 , M2 are the maxima of a 1-D scalar func- tion. In (a) M2 has a relatively low, whereas in (b) M2 has a high persistence value. Filtering by homological persistence would in- duce that for the function in (a) only at M1 an icon would be drawn and the final depiction naturally cleaned up. In contrast, in (b) at both extrema, M1 and M2 an icon would be placed. However, we are convinced that although this might induce clutter both extrema are of such high importance that each of them has to be displayed. ", "caption_bbox": [440, 444, 775, 568]}, {"image_id": 3, "file_name": "272_03.png", "page": 4, "dpi": 300, "bbox": [104, 113, 379, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Top: Background icons for different deformation modes: positive, and negative isotropic scale, shear, counterclockwise rota- tion, and clockwise rotation. Bottom: Respective extrema icons. ", "caption_bbox": [73, 244, 408, 285]}, {"image_id": 4, "file_name": "272_04.png", "page": 4, "dpi": 300, "bbox": [475, 75, 742, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Earthquake data set (Sec. 5.2) a) Height field of shear scalar field. b) All extrema of scalar field displayed as spheres scaled by their persistence value. c) Persistence filtered extrema. ", "caption_bbox": [440, 324, 775, 365]}, {"image_id": 5, "file_name": "272_05.png", "page": 4, "dpi": 300, "bbox": [486, 391, 726, 476], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) Isocontour errors as defined by [35].", "caption_bbox": [481, 489, 733, 502]}, {"image_id": 6, "file_name": "272_06.png", "page": 5, "dpi": 300, "bbox": [531, 73, 686, 165], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Placement of icons along medial axis of a cluster. The light gray polyline indicates the boundary of the cluster, the dark gray lines depict information by the segment Voronoi diagram (me- dial axis and distances to the boundary). ", "caption_bbox": [440, 181, 775, 236]}, {"image_id": 7, "file_name": "272_07.png", "page": 6, "dpi": 300, "bbox": [442, 509, 753, 632], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Cylinder data set \u2013 (a) Close-up: background visu- alization of shear basins (transparency of shear icons adjusted to strength, orientation to major eigenvector) for a more detailed in- spection. The background visualization reveals properties of the shear which could not be deduced from the LIC visualization only. (b) Extrema (spheres with size adjusted to persistence value) and basins of shear scalar field. The gray rectangle denotes the close-up area in (a). ", "caption_bbox": [440, 645, 775, 755]}, {"image_id": 8, "file_name": "272_08.png", "page": 6, "dpi": 300, "bbox": [73, 73, 411, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Cylinder data set \u2013 Information about shear and vortic- ity made visible in the sketch-like representation (in combination with the vector field visualization method LIC as context informa- tion). The extrema of the scalar fields show the locations of highest strengths. If the size of extrema is below the fixed threshold they are rendered as colored dots. The background visualization depicts the dominant components according to the classification: regions of dominant rotation are distinguished against those of dominant shear. Regions with low tensor magnitude are illustrated by arrows. ", "caption_bbox": [73, 337, 408, 461]}, {"image_id": 9, "file_name": "272_09.png", "page": 6, "dpi": 300, "bbox": [447, 73, 775, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Cylinder data set \u2013 (a) Same data set as in Fig. 8 but with change of reference frame. Result shows the independence of the information given by the scalar fields from the chosen frame of ref- erence. (b) Schematic depiction of the vector field clustering pro- cess with respect to magnitude of derivative (resulting clusters ran- domly color coded). White denotes regions with magnitude m > \u03c4, which are excluded from the clustering. (c) Close-up: schematic il- lustration of size adaption of the reference ellipse for position error. ", "caption_bbox": [440, 271, 775, 381]}, {"image_id": 10, "file_name": "272_10.png", "page": 7, "dpi": 300, "bbox": [481, 504, 736, 757], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Climate data set \u2013 Close-ups of Fig. 11 (top row) com- bined with vector visualization. (a) Isotropic scaling extremum at location where the stream fronts converge from two sides which might indicate an up- or down-stream. (b) Shear extremum where the flow follows to opposing directions. (c+d) The depicted scalar quantities are independent of the chosen frame of reference. In con- trast to the extremum in (d) the rotation extremum in (c) is not in a location which the vector visualization would suggest. ", "caption_bbox": [440, 771, 775, 881]}, {"image_id": 11, "file_name": "272_11.png", "page": 7, "dpi": 300, "bbox": [456, 74, 761, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Climate data set \u2013 Time dependent simulation of wind. Top and bottom image display two consecutive time steps. Due to the high feature density the visualization is extremely simplified \u2013 only the most persistent extrema are displayed. Additionally the arrow icons of the vector clustering, contours of the continents, and sparsely seeded streamlines can be seen. ", "caption_bbox": [440, 399, 775, 481]}], "273": [{"image_id": 0, "file_name": "273_00.png", "page": 2, "dpi": 300, "bbox": [463, 74, 748, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Limitation of the 1D histogram representation.", "caption_bbox": [471, 296, 744, 309]}, {"image_id": 1, "file_name": "273_01.png", "page": 2, "dpi": 300, "bbox": [89, 263, 394, 420], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The major steps for our distribution-based flow analysis framework ", "caption_bbox": [73, 435, 408, 461]}, {"image_id": 2, "file_name": "273_02.png", "page": 2, "dpi": 300, "bbox": [111, 74, 371, 172], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Limitation of point-based metric computation. (a) A stream- line (color coded by curvature) with high range of curvature along the length. (b) The curvature values ordered along the length. (c) The zoomed in view of the point with highest curvature. ", "caption_bbox": [73, 191, 408, 243]}, {"image_id": 3, "file_name": "273_03.png", "page": 3, "dpi": 300, "bbox": [659, 368, 776, 488], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A segmenta- tion result where seg- ments are shown by col- ors. ", "caption_bbox": [656, 504, 775, 556]}, {"image_id": 4, "file_name": "273_04.png", "page": 3, "dpi": 300, "bbox": [87, 73, 392, 171], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a): The selected streamline color coded by curvature. (b): The curvature values ordered along the streamline. (c): The 2D his- togram representation for this streamline, color represents frequency. ", "caption_bbox": [73, 190, 408, 229]}, {"image_id": 5, "file_name": "273_05.png", "page": 3, "dpi": 300, "bbox": [453, 73, 764, 136], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: From left to right, the 2D histogram for the streamline in Figure 3(a) and (b) ", "caption_bbox": [440, 152, 775, 178]}, {"image_id": 6, "file_name": "273_06.png", "page": 4, "dpi": 300, "bbox": [89, 74, 395, 243], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Comparison of different distance measurement functions", "caption_bbox": [447, 300, 769, 313]}, {"image_id": 7, "file_name": "273_07.png", "page": 4, "dpi": 300, "bbox": [447, 79, 786, 215], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Visualization of the data sets Tornado, Hurricane Isabel, Solar Plume and Ocean. The number of testing streamlines are 1000, 2000, 2000, and 4800, respectively. ", "caption_bbox": [440, 233, 775, 272]}, {"image_id": 8, "file_name": "273_08.png", "page": 4, "dpi": 300, "bbox": [89, 318, 388, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Three 1D histograms A, B and C for three different stream- lines. H(A)=(0.1 0.8 0 0 0 0 0.1); H(B)=(0.8 0.1 0 0 0 0 0.1); H(C)=(0.1 0.2 0 0 0 0 0.7). ", "caption_bbox": [73, 397, 408, 436]}, {"image_id": 9, "file_name": "273_09.png", "page": 5, "dpi": 300, "bbox": [441, 73, 775, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Four query results for Isabel data and Plume data. (a),(c),(e) and (g) show the four target streamlines. (b),(d),(f) and (h) show the query results for (a),(c),(e) and (g) respectively. In the results, streamlines are colored from red to yellow where red means more similar and the target streamline is in blue. ", "caption_bbox": [440, 337, 775, 402]}, {"image_id": 10, "file_name": "273_10.png", "page": 6, "dpi": 300, "bbox": [107, 359, 376, 626], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: (a): The target streamline with a highly swirling part in the end. (b): The top 500 similar streamlines based on our distribution method. Five big swirling areas highlighted by black squares and one small swirling area highlighted by a green square are extracted. (c),(d) and (e) show the top 500 similar streamlines based on the hausdorff, mean of closest point and edit distance. ", "caption_bbox": [73, 644, 408, 722]}, {"image_id": 11, "file_name": "273_11.png", "page": 6, "dpi": 300, "bbox": [142, 76, 708, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Effectiveness of our streamline query. The top left corner shows the target streamline which indicates an vortex. By querying similar streamlines, lots of vortices are found in the Ocean data set. ", "caption_bbox": [73, 309, 775, 335]}, {"image_id": 12, "file_name": "273_12.png", "page": 7, "dpi": 300, "bbox": [466, 257, 750, 510], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Hierarchical streamline clustering results for Plume data set based on the combination of curvature and torsion. The balance parameter w = 0.7. The whole set of streamlines are cut into different parts based on their shape difference. ", "caption_bbox": [440, 528, 775, 580]}, {"image_id": 13, "file_name": "273_13.png", "page": 7, "dpi": 300, "bbox": [91, 74, 393, 165], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Timings for Streamline Query", "caption_bbox": [147, 648, 335, 661]}, {"image_id": 14, "file_name": "273_14.png", "page": 7, "dpi": 300, "bbox": [439, 74, 777, 171], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Hierarchical streamline clustering results for Tornado data set based on the magnitude of curl. The balance parameter w = 0.0. The whole set of streamlines are cut into four parts with different swirling intensity. ", "caption_bbox": [440, 189, 775, 241]}, {"image_id": 15, "file_name": "273_15.png", "page": 7, "dpi": 300, "bbox": [89, 251, 394, 407], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 4: Timings for Hierarchical Streamline Clustering", "caption_bbox": [106, 803, 375, 816]}], "274": [{"image_id": 0, "file_name": "274_00.png", "page": 1, "dpi": 300, "bbox": [130, 86, 720, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Linear neighborhoods computed in originally linear fields (source, center, saddle and shear) that have been multiplied with a 2D Gaussian kernel. The result is non-linear. The shape of the of the linear neighborhoods reflects the circular kernel causing the non-linearity. ", "caption_bbox": [73, 290, 775, 316]}, {"image_id": 1, "file_name": "274_01.png", "page": 3, "dpi": 300, "bbox": [204, 75, 276, 146], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Linear approximation of a quadratic function in quadrilateral cells, where the light gray area represents the ALN. Red lines show the actually extracted boundary, by using the marching-cubes-based approach. Small structures arising from the quadratic function will be discarded and approximated by these borders. ", "caption_bbox": [73, 149, 408, 214]}, {"image_id": 2, "file_name": "274_02.png", "page": 4, "dpi": 300, "bbox": [135, 133, 347, 209], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Black arrows represent vectors at the seed positions of ALNs and red arrows the vectors still accepted according to Eq. (3). Image (a) illustrates the possible magnitude differences between two parallel vectors as given by Eq. (5). Image (b) illustrates the possible angle differences between two vectors of the same length as given by Eq. (6). ", "caption_bbox": [73, 215, 408, 293]}, {"image_id": 3, "file_name": "274_03.png", "page": 4, "dpi": 300, "bbox": [110, 785, 373, 958], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Plot of Eq. (6) illustrating the possible angular deviation \u03b1 for a given CL . Original and approximated vector have the same constant length. ", "caption_bbox": [73, 961, 408, 1000]}, {"image_id": 4, "file_name": "274_04.png", "page": 4, "dpi": 300, "bbox": [482, 595, 732, 784], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Direct volume rendering of the ALAE field at level two of the delta wing dataset. Its triangular shape is well perceptible. The areas with the largest ALAE, lie exactly behind the tail of the wing, can be clearly identified as the vortex breakdown bubbles. ", "caption_bbox": [440, 790, 775, 842]}, {"image_id": 5, "file_name": "274_05.png", "page": 5, "dpi": 300, "bbox": [471, 517, 742, 605], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Left: Three ALNs seeded at the singularities of a data set containing two co-rotating Oseen vortices (resolution 500 \u00d7 500). Center and right: Color coding according to ALAE fields at approx- imation levels of four and eight, respectively. The relation of four, re- spectively eight, edge lengths to the grid size is indicated by the small red scales in the lower left corner of the ALAE fields. Red colored re- gions indicate non-linear flow behavior. The color map indicates that the ALAE values range from 0 (white) to 0.05 (dark red). ", "caption_bbox": [440, 608, 775, 713]}, {"image_id": 6, "file_name": "274_06.png", "page": 5, "dpi": 300, "bbox": [471, 77, 742, 162], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A synthetic two-dimensional vector field created by the mul- tiplication of a Gauss kernel with a linear vector field, which contains a center point in its origin. There is a non-linear change in the flow behavior caused by the Gaussian kernel. This can be found by Algo- rithm (1). Its size depends on the chosen error threshold CL . These images show the ALNs for CL = 0.2, 0.4, and 0.8, respectively. ", "caption_bbox": [440, 169, 775, 248]}, {"image_id": 7, "file_name": "274_07.png", "page": 5, "dpi": 300, "bbox": [118, 76, 367, 216], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Front view of the ICE train with comparison of streamlines in an ALN next to the ICE. The ALN is shown in light gray. Red streamlines represent the linearly approximated vector field for CL = 0.2 and blue streamlines the original vector field. The low error is achieved in the ALN, only. The swirling behavior of the approximated streamlines are well perceivable. ", "caption_bbox": [73, 219, 408, 297]}, {"image_id": 8, "file_name": "274_08.png", "page": 6, "dpi": 300, "bbox": [472, 295, 743, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Top view of an ICE train for comparison between vortex core regions [8] illustrated by a \u03bb2 = \u221210\u22129 isosurface in blue and a region with high non-linearity ALAE shown                                         \u221a     in red. The ALAE field was computed with parameters CL = 0.0075 and n = 2. A region of high ALAE lies exactly between the two main vortices that are present on the lee side of the ICE train. High ALAE can also be observed where the flow separates from the top border of the train. The small structures in the middle of the train result from a small turbulence caused by the connector between the train and its first docked wagon. ", "caption_bbox": [440, 372, 776, 503]}, {"image_id": 9, "file_name": "274_09.png", "page": 6, "dpi": 300, "bbox": [93, 313, 331, 442], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Affine linear neighborhoods at the singularities of the right vortex bubble formed behind the delta wing. Streamlines show the helical structure of the flow along the vortex core. This behavior re- mains stable until the flow enters the vortex bubble which is bounded by the vector field singularities (red spheres). The two gray surfaces depict the affine linear neighborhoods rooted at the singularities for CL = 0.1. ", "caption_bbox": [72, 444, 408, 536]}, {"image_id": 10, "file_name": "274_10.png", "page": 6, "dpi": 300, "bbox": [113, 74, 366, 204], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Depiction of the right primary vortex on the delta wing dataset as a composition of ALNs (CL = 0.1) seeded equidistantly along the vortex core line. At this low error threshold, a composi- tion of similar areas can be used to describe the shape of the vortex. Furthermore, one can very nicely perceive that the ALNs towards the vortex breakdown bubble shrink and twist because the flow behavior becomes more and more nonlinear (compare Fig. 11). ", "caption_bbox": [73, 206, 408, 297]}, {"image_id": 11, "file_name": "274_11.png", "page": 7, "dpi": 300, "bbox": [451, 651, 745, 760], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: The same dataset as Fig. 13 compared                                           \u221a      \u221aat level four.                                                               \u221a Here, the isosurface is shown for CL values of 0.025, 0.05, and 0.1. In agreement with the observations made in Fig. (13), structures indi- cating regions that are only coarsely approximable by linear fields are vanishing with increasing error bound. ", "caption_bbox": [440, 761, 775, 826]}, {"image_id": 12, "file_name": "274_12.png", "page": 7, "dpi": 300, "bbox": [85, 571, 378, 679], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Comparison of ALAE in the turbine data set. The gray surface       \u221a depicts the boundary of the draft tube. ALAE is shown using CL = 0.1 isosurfaces at approximation levels two, four and six. The high ALAE values near the tube surface are probably caused by the shear in the boundary layer. With increasing level of approximation, more and more regions, which are only coarsely approximable by linear fields, arise at locations corresponding to vortices. ", "caption_bbox": [72, 681, 408, 772]}], "275": [{"image_id": 0, "file_name": "275_00.png", "page": 2, "dpi": 300, "bbox": [440, 74, 776, 150], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Deformation principle. An initial surface mesh (\u2022) is iter- atively deformed by conceptually aligning each triangle individually to the flow and reconstructing the mesh (\u2022) from these transformed gradients until the iteration converges to a flow aligned mesh (\u2022). ", "caption_bbox": [440, 156, 775, 208]}, {"image_id": 1, "file_name": "275_01.png", "page": 4, "dpi": 300, "bbox": [73, 74, 411, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Parametrization types. Iso-contours (\u2022) of flow tangential surfaces are used to integrate larger exact stream surfaces (\u2022) (left). Orthogonally aligned surfaces (\u2022) can be parametrized using different angular rotations (middle) or using circular geodesics-based distance fields (right). ", "caption_bbox": [73, 192, 408, 257]}, {"image_id": 2, "file_name": "275_02.png", "page": 4, "dpi": 300, "bbox": [440, 75, 777, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Stream surface parametrizations. The exact unnormalized time line/stream line parametrization obtained by front line-based stream surface integrators (top) exhibits more distortion than our least-squares tangential parametrization (bottom). ", "caption_bbox": [440, 248, 775, 300]}, {"image_id": 3, "file_name": "275_03.png", "page": 5, "dpi": 300, "bbox": [440, 75, 776, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Seeding at the T URBINE. Top: a tangential surface is interactively placed into the inflow area of the flow (I). It is then grown orthogonally to the flow (II) and an iso-contour of a tangen- tial parametrization yields a non-straight seed curve (III) for the in- tegration of the final stream surface (top right). Bottom: onto an in- teractively placed orthogonal surface (I) a orthogonal seed curve is manually \u201cdrawn\u201d (II) and used for stream surface integration. ", "caption_bbox": [440, 314, 775, 405]}, {"image_id": 4, "file_name": "275_04.png", "page": 6, "dpi": 300, "bbox": [439, 386, 772, 472], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Flux convergence in interactive session. The graph shows the normalized flux fn of each deformation iteration in an interac- tive session for tangentially (\u2022) and orthogonally (\u2022) aligned surfaces. Translations, rotations as well as growing operations were performed by the user, which result in quickly optimized \u201cflux spikes\u201d. ", "caption_bbox": [440, 480, 775, 545]}, {"image_id": 5, "file_name": "275_05.png", "page": 6, "dpi": 300, "bbox": [73, 74, 773, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Interactive seeding results. The surfaces orthogonal surfaces (\u2022) are positioned interactively by the user. Then stream surfaces and stream lines (\u2022) are seeded from these orthogonal surfaces and integrated tangentially to the flow. Both orthogonal (S TALLING 2D, C YLINDER, and S TEP) as well as circular parametrizations (B UBBLE C HAMBER, cutaway view) were used to extract flow orthogonal seed curves. ", "caption_bbox": [73, 342, 775, 381]}, {"image_id": 6, "file_name": "275_06.png", "page": 7, "dpi": 300, "bbox": [74, 264, 411, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: APAP comparison. Starting from a converged APAP [32, Figure 10] surface (left) our deformation converges to an even better aligned orthogonal surface (right). The color scale captures normal- ized f j \u2208 [0.75, 1]. The highlighted fixation artifact at the center vertex is also removed by our deformation. ", "caption_bbox": [73, 389, 408, 454]}, {"image_id": 7, "file_name": "275_07.png", "page": 8, "dpi": 300, "bbox": [77, 75, 777, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: LIC-like visualization results. Precomputed textures of anisotropic noise and flow-aligned arrows (bottom right) are mapped to the tangentially parametrized stream surfaces (S TEP, T URBINE, D ELTAW ING) and two path surfaces (U NSTEADY C YLINDER). Resulting LIC-like and illustrative structures are flow-aligned everywhere except at locally masked regions (e. g., at the vortex of the D ELTAW ING). ", "caption_bbox": [73, 342, 775, 381]}], "276": [{"image_id": 0, "file_name": "276_00.png", "page": 2, "dpi": 300, "bbox": [114, 74, 369, 193], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Illustration of L-node signature with a 2D space partitioning example. (a) the signature of the streamline is an ordered sequence (12, 10, 9, 6, 5, 2, 1). (b) the signature of the streamline cluster is an unordered set (1, 2, 3, 5, 6, 9, 10, 11, 12). ", "caption_bbox": [73, 195, 408, 247]}, {"image_id": 1, "file_name": "276_01.png", "page": 3, "dpi": 300, "bbox": [85, 75, 764, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) the initial layout is produced using the force-directed graph layout algorithm. The size of each node in the graph is proportional to the number of children within. (b) the triangle mesh produced from the initial node positions. (c) the adjusted layout after two nodes are selected and expanded for detail examination. (d) the underlying triangle mesh is used to maintain the topology of the graph during layout adjustment. ", "caption_bbox": [73, 252, 775, 291]}, {"image_id": 2, "file_name": "276_02.png", "page": 4, "dpi": 300, "bbox": [84, 75, 401, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A L-node is expanded in the computer room data set and one of its child node is shown in purple. The corresponding child and parent streamline clusters are shown in gold and white, respectively. ", "caption_bbox": [73, 231, 408, 270]}, {"image_id": 3, "file_name": "276_03.png", "page": 4, "dpi": 300, "bbox": [454, 73, 768, 228], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Filtering L-R edges by weight in the FlowGraph highlights eleven R-nodes (shown in blue) that have strong connection with the L-node of interest (shown in purple) in the hurricane data set. ", "caption_bbox": [440, 231, 775, 270]}, {"image_id": 4, "file_name": "276_04.png", "page": 5, "dpi": 300, "bbox": [86, 76, 765, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) and (b) show path comparison for three streamline clusters shown in red, blue and cyan, respectively of the two swirls data set. Observe that the two swirls are well separated in the graph view as indicated by the green dashed lines. Three R-nodes shared by the blue and cyan L-nodes are highlighted with double boundaries. (c) and (d) show path comparison for two streamline clusters of the solar plume data set. ", "caption_bbox": [73, 252, 775, 291]}, {"image_id": 5, "file_name": "276_05.png", "page": 5, "dpi": 300, "bbox": [452, 317, 768, 472], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The detail path of a child L-node (shown in purple) of the tornado data set and the corresponding streamline cluster. ", "caption_bbox": [440, 475, 775, 501]}, {"image_id": 6, "file_name": "276_06.png", "page": 7, "dpi": 300, "bbox": [85, 73, 765, 397], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Exploring the five critical points data set. First row: three R-nodes are selected (shown in blue, red and brown) which correspond to the spatial regions each containing one critical point. Second row: filtering R-nodes based on the R-R edge weight identifies an important R-node. The streamlines passing through the parent R-node (shown in black) and two child R-nodes (shown in blue and red) are displayed. ", "caption_bbox": [73, 400, 775, 439]}, {"image_id": 7, "file_name": "276_07.png", "page": 7, "dpi": 300, "bbox": [88, 454, 765, 632], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Exploration of the supernova data set using the FlowGraph. (a) and (b) show the path comparison of two streamline clusters (shown in black and magenta) in both views. Their shared spatial regions are also highlighted. (c) and (d) show the snapshot of path animation of a single streamline over spatial regions with different levels of detail. Green, red and blue squares (graph view) and spheres (streamline view) indicate the starting, ending and current animation points, respectively. ", "caption_bbox": [73, 633, 775, 685]}, {"image_id": 8, "file_name": "276_08.png", "page": 8, "dpi": 300, "bbox": [85, 76, 765, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Exploring the interesting flow pattern in the car flow data set. (a) and (b) show four important R-nodes (shown in red, green, blue and brown) and eight L-nodes that have strong connection to the R-nodes of interest. From these eight L-nodes, (c) and (d) show further selection of three L-nodes (one at the next level of the hierarchy) to capture the main flow structure passing through the car. ", "caption_bbox": [73, 252, 775, 291]}], "277": [{"image_id": 0, "file_name": "277_00.png", "page": 2, "dpi": 300, "bbox": [73, 74, 418, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Radial examples for the different layout requirements LR1-LR3 and their interplay. ", "caption_bbox": [73, 397, 408, 424]}, {"image_id": 1, "file_name": "277_01.png", "page": 2, "dpi": 300, "bbox": [441, 842, 772, 918], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Scaling on different stages of an inclusion-type layout. (a) scales down the dark parent rectangle first and then subdivides it, while (b) performs the subdivision first and scales each of the three resulting rectangles afterwards. This yields different results, with (a) emphasizing the sibling relation much more than (b) does. ", "caption_bbox": [440, 930, 775, 998]}, {"image_id": 2, "file_name": "277_02.png", "page": 4, "dpi": 300, "bbox": [73, 74, 778, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Schema of our tree layout pipeline for realizing (a) top-down layouts and (b) bottom-up layouts. The stages colored dark gray are those that can be configured through operators. The light gray stages are constant as the direction of traversal is fixed depending on whether the layout is top-down or bottom-up. The variables s denote geometric shapes, the variables n denote nodes of the tree. The index p marks parent shapes/nodes, the index c marks child shapes/nodes. Changes made at the individual stages to the current level Ld are highlighted in red. Modifications are denoted with a prime symbol, copies are denoted with a hat symbol. Blue indicates a mere renaming of the variables without any change to them, which is done so that each iteration through the layout process starts with a level Ld . ", "caption_bbox": [73, 294, 775, 378]}, {"image_id": 3, "file_name": "277_03.png", "page": 6, "dpi": 300, "bbox": [73, 73, 777, 939], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An example for the step-wise creation of a space-filling tree drawing (a)-(d) and a node-link tree drawing (e)-(h). The black layout operators are those that were added from one step to the next to yield the change in appearance. The gray shapes in the background of the node-link layouts in (e)-(h) are not part of the drawings, but only overlaid to illustrate the internally performed subdivision. ", "caption_bbox": [73, 952, 775, 993]}], "278": [{"image_id": 0, "file_name": "278_00.png", "page": 2, "dpi": 300, "bbox": [156, 94, 693, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Even distribution of the graph over the drawing area.", "caption_bbox": [271, 312, 576, 324]}, {"image_id": 1, "file_name": "278_01.png", "page": 3, "dpi": 300, "bbox": [168, 91, 684, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Email network from a large European research institution.", "caption_bbox": [258, 373, 589, 385]}, {"image_id": 2, "file_name": "278_02.png", "page": 5, "dpi": 300, "bbox": [73, 173, 778, 632], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparison of FlexGD with force-directed models.", "caption_bbox": [276, 649, 573, 661]}, {"image_id": 3, "file_name": "278_03.png", "page": 6, "dpi": 300, "bbox": [73, 73, 779, 506], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparison of FlexGD with HDE and ACE.", "caption_bbox": [293, 523, 554, 535]}, {"image_id": 4, "file_name": "278_04.png", "page": 7, "dpi": 300, "bbox": [165, 92, 685, 373], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Sample Layouts of the FlexGD model.", "caption_bbox": [306, 386, 542, 398]}, {"image_id": 5, "file_name": "278_05.png", "page": 8, "dpi": 300, "bbox": [122, 99, 726, 950], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: FlexGD Layouts of sample graphs taken from the University of Florida Sparse Matrix Collection. The graph size, abstraction constant and CPU time in seconds are given in the caption. Zooming on the layouts reveals more details. ", "caption_bbox": [73, 964, 775, 989]}], "279": [{"image_id": 0, "file_name": "279_00.png", "page": 1, "dpi": 300, "bbox": [503, 385, 718, 604], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An example of edge concentration [35]", "caption_bbox": [471, 615, 744, 629]}, {"image_id": 1, "file_name": "279_01.png", "page": 2, "dpi": 300, "bbox": [87, 73, 404, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Example of confluent drawing [17].", "caption_bbox": [114, 275, 367, 289]}, {"image_id": 2, "file_name": "279_02.png", "page": 2, "dpi": 300, "bbox": [441, 73, 775, 255], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Graph visualization model", "caption_bbox": [504, 265, 710, 279]}, {"image_id": 3, "file_name": "279_03.png", "page": 3, "dpi": 300, "bbox": [121, 73, 734, 375], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An example graph using force-directed edge bundling", "caption_bbox": [245, 387, 602, 401]}, {"image_id": 4, "file_name": "279_04.png", "page": 4, "dpi": 300, "bbox": [448, 74, 768, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Interaction groups between Health researchers in the EuroSiS dataset ", "caption_bbox": [440, 236, 775, 264]}, {"image_id": 5, "file_name": "279_05.png", "page": 7, "dpi": 300, "bbox": [85, 76, 772, 237], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualization of US airline network using edge bundling", "caption_bbox": [239, 249, 609, 263]}], "28": [{"image_id": 0, "file_name": "28_00.png", "page": 1, "dpi": 300, "bbox": [413, 781, 757, 926], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2. A Java program to swap the contents of two                      variables. ", "caption_bbox": [423, 925, 746, 955]}, {"image_id": 1, "file_name": "28_01.png", "page": 2, "dpi": 300, "bbox": [432, 511, 738, 719], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. Performance Balance of Groups.", "caption_bbox": [456, 734, 713, 749]}, {"image_id": 2, "file_name": "28_02.png", "page": 2, "dpi": 300, "bbox": [71, 278, 413, 754], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3. Trace of Swap.java", "caption_bbox": [152, 765, 329, 780]}, {"image_id": 3, "file_name": "28_03.png", "page": 3, "dpi": 300, "bbox": [79, 599, 405, 844], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5. Presentation of Questions.", "caption_bbox": [132, 868, 350, 883]}, {"image_id": 4, "file_name": "28_04.png", "page": 3, "dpi": 300, "bbox": [425, 830, 750, 1017], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6. Average response time for each question.", "caption_bbox": [421, 1027, 726, 1042]}, {"image_id": 5, "file_name": "28_05.png", "page": 4, "dpi": 300, "bbox": [425, 773, 750, 969], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9. Percentage of students with each mark.", "caption_bbox": [436, 975, 731, 990]}, {"image_id": 6, "file_name": "28_06.png", "page": 4, "dpi": 300, "bbox": [424, 161, 740, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8. Percentage of students with correct response                   for each question. ", "caption_bbox": [421, 351, 746, 382]}, {"image_id": 7, "file_name": "28_07.png", "page": 4, "dpi": 300, "bbox": [81, 522, 407, 711], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7. Average response time for correct answer to                    each question. ", "caption_bbox": [78, 717, 402, 748]}, {"image_id": 8, "file_name": "28_08.png", "page": 5, "dpi": 300, "bbox": [81, 804, 395, 1021], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12. Difference plot for correctness over T.", "caption_bbox": [93, 1027, 388, 1042]}, {"image_id": 9, "file_name": "28_09.png", "page": 5, "dpi": 300, "bbox": [424, 819, 730, 1021], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14. Efficiency difference.", "caption_bbox": [486, 1027, 681, 1042]}, {"image_id": 10, "file_name": "28_10.png", "page": 5, "dpi": 300, "bbox": [424, 412, 750, 601], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13. Efficiency.", "caption_bbox": [518, 607, 650, 622]}, {"image_id": 11, "file_name": "28_11.png", "page": 5, "dpi": 300, "bbox": [81, 565, 396, 754], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11. Percentage of students with each mark for             questions on taught material. ", "caption_bbox": [81, 760, 401, 790]}, {"image_id": 12, "file_name": "28_12.png", "page": 5, "dpi": 300, "bbox": [81, 81, 400, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10. Difference plot for correctness.", "caption_bbox": [114, 296, 367, 311]}, {"image_id": 13, "file_name": "28_13.png", "page": 6, "dpi": 300, "bbox": [81, 121, 402, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15. Efficiency difference over T.", "caption_bbox": [122, 336, 359, 351]}], "280": [{"image_id": 0, "file_name": "280_00.png", "page": 1, "dpi": 300, "bbox": [80, 120, 771, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Financial transaction data of 249 transactions between 181 accounts visualized as directed straight links connecting vertices and hence representing relations between objects. The blue curves represent edge-edge relations, thereby connecting pairs of transactions that vary in amount drastically, although assigned the same set of keywords. Left: Loops attached to transactions represent temporal patterns (emphasized by the green arrows), i.e., reoccurring transactions of diverging amounts between the same accounts. Right: Selection of four transactions whose amounts vary from many other transactions that have the same keywords. ", "caption_bbox": [73, 411, 775, 476]}, {"image_id": 1, "file_name": "280_01.png", "page": 2, "dpi": 300, "bbox": [115, 76, 735, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visualization of VVRs and EERs of the graph from Figure 1 using separate linked views. (a) Node-link diagram of directed VVRs using clockwise curved links; each VVR is assigned a different color (hue). (b) Node-link diagram of EERs; nodes represent VVRs of (a) and are therefore colored in the same fashion. The strength of dissimilarity is mapped to the color and width of the links. ", "caption_bbox": [73, 280, 775, 319]}, {"image_id": 2, "file_name": "280_02.png", "page": 3, "dpi": 300, "bbox": [512, 80, 693, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Definition of the control points for a Be\u0301zier curve, repre- senting the relation between two undirected VVRs, ve(vi1 , vi2 ) and ve(vi3 , vi4 ). P0 and P3 are chosen as the closest docking points of the two VVRs; P1 and P2 are positioned on the normal of those docking points. ", "caption_bbox": [440, 204, 775, 269]}, {"image_id": 3, "file_name": "280_03.png", "page": 3, "dpi": 300, "bbox": [101, 76, 381, 204], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Design of edge shapes for directed and undirected graphs. While VVRs are represented as straight shapes, EERs are visualized using cubic Be\u0301zier curves. (a) Undirected VVRs are represented as tight straight shapes. The positioning of docking points allows for optimizing the layout of the Be\u0301zier curves. (b) The direction of VVRs is indicated by the clockwise curvature as well as arrows. Hence, the positioning of docking points for EERs is restricted. ", "caption_bbox": [73, 222, 408, 313]}, {"image_id": 4, "file_name": "280_04.png", "page": 5, "dpi": 300, "bbox": [77, 77, 771, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Correlation analysis of the Eissing model describing apoptosis induction. Positive correlations (red) and negative correlations (blue) between (a) parameters and (b) fluxes with Pearson correlation (|\u03c1| > 0.5) are illustrated. (a) In particular, parameter pairs of reversible reactions, such as (k3 ,k4 ), show strong positive correlations. In contrast, parameter pairs associated to alternative reaction paths, such as (k7 ,k8 ), are anti-correlated. As the number of reversible reactions exceeds the number of alternative reaction paths, predominantly positive correlations occur. (b) Pair-wise flux correlations (dis-)appear at particular points in time. Therefore, only correlations for the currently selected point in time are emphasized, whereas all others are faded to the background by decreasing their opacity to maintain an overview of all points in time. The strong change of correlation structure between t = 175 min and t = 180 min clarifies that the system undergoes a sudden transition of fluxes. ", "caption_bbox": [73, 252, 775, 343]}, {"image_id": 5, "file_name": "280_05.png", "page": 7, "dpi": 300, "bbox": [84, 76, 766, 469], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Financial transaction data of 249 transactions between 181 accounts visualized as directed straight edges connecting vertices (see also Figure 1). The red Be\u0301zier curves connecting two transactions indicate that these are particularly similar, i.e., that they are assigned the same keywords and about the same amount was transferred close in time. The graph contains 297 similarities of w+ \u2265 0.8, where EERs of four different keywords out of 29 keywords that show an interesting behavior are highlighted by slightly fading out all other EERs (see further examples within supplemental material). These include the words: \u201cFinancial Service\u201d (a), \u201cRaw Materials\u201d (b), \u201cTransportation\u201d (c), and \u201cElectronics\u201d (d). Loops attached to transactions represent temporal patterns, i.e., reoccurring transactions of similar amounts between the same accounts. ", "caption_bbox": [73, 487, 775, 565]}], "281": [{"image_id": 0, "file_name": "281_00.png", "page": 2, "dpi": 300, "bbox": [107, 75, 742, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The layout of a flexibility plot and the CheY data set as shown in [4]. (a) Flexibility plot layout where each axis is ordered by the residue sequence occuring in the three-dimensional protein space. At each index is the flexibility measure of residue R after RP is perturbed. (b) A color-coded flexibility plot based on the layout in (a) and containing 128 rows and 128 columns. One plot encodes the response resulting from a single set of model parameters. In each column, blue indicates rigid areas and red indicates flexible areas. (c) The entire data set consists of 75 plots, each one representing a single parameter combination. The subtle and faint patterns are difficult for analysts to investigate. ", "caption_bbox": [73, 324, 775, 389]}, {"image_id": 1, "file_name": "281_01.png", "page": 4, "dpi": 300, "bbox": [148, 72, 702, 454], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Control panel with input boxes for changing the length and width of grid cells and the size of the bounding window. (b) The grid divides the data set into subspaces that can be selected by clicking. (c) Subspace plots occupying the same location across the data set as the selected subspace in (b). Subspaces may vary in both the location of flexible areas and their degree of flexibility. The selected subspace becomes the target plot and is highlighted. (d) Enlarged view of the selected subspace. An individual residue has been selected and highlighted. (e) The flexibility value of the current residue sorted across the data set. Clicking on a residue square changes the target plot. (f) A clipboard holds plots containing subspaces of interest. ", "caption_bbox": [73, 469, 775, 547]}, {"image_id": 2, "file_name": "281_02.png", "page": 5, "dpi": 300, "bbox": [151, 72, 697, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) Histogram view sorted by bin-by-bin distance. The number of bins is user-defined and colored according to average flexibility of its members. (b) The trim tool allows the elimination of bins for more targeted comparison. (c) The original data items after the red bins are eliminated by the trim tool. (d) Trim tool after bin removal. (e) - (f) Perceptual similarity between two histograms may not ensure that encoded flexibility meanings are preserved. ", "caption_bbox": [73, 380, 775, 432]}, {"image_id": 3, "file_name": "281_03.png", "page": 5, "dpi": 300, "bbox": [151, 437, 699, 679], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Histograms show a subspace where flexibility has a wider range (beginning of the sort at top left) and a narrow range (end of the sort).", "caption_bbox": [73, 694, 775, 707]}, {"image_id": 4, "file_name": "281_04.png", "page": 6, "dpi": 300, "bbox": [98, 73, 747, 378], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Scanning provides contextual information for the chosen subspace. (a) Sorted bubbles in each row trace the similarity between the subspace plot visualized on the far left and the corresponding area in the other plots. Detailed information is available for a bubble with a mouse- over. (b) The original subspace (dark box) and the current location of the sliding window (dotted box). (c) The starting and stopping positions of a horizontal scan. (d) The snapshot view for two subspaces being scanned in (a). ", "caption_bbox": [73, 394, 775, 446]}, {"image_id": 5, "file_name": "281_05.png", "page": 6, "dpi": 300, "bbox": [156, 466, 325, 543], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Window selecting an area of interest allows greater free- dom when choosing subspaces. ", "caption_bbox": [73, 563, 408, 589]}, {"image_id": 6, "file_name": "281_06.png", "page": 8, "dpi": 300, "bbox": [144, 74, 707, 503], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A series of transitions displaying residue column similarity for investigating local, native torsion energy. Changes in movement for selected items are marked with a green circle and tail. Transitions include (a) 0.6 to 0.7 kcal/mol, (b) 0.7 to 0.8 kcal/mol, (c) 0.8 to 0.9 kcal/mol, and (d) 0.9 to 1.0 kcal/mol. The greatest change within the highlighted items occurs for residues 72, 74, and 79 in (b) and for residues 72 and 74 in (c). ", "caption_bbox": [73, 519, 775, 571]}], "282": [{"image_id": 0, "file_name": "282_00.png", "page": 1, "dpi": 300, "bbox": [89, 86, 758, 438], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A selected time step of an ocean forecasting ensemble computed for the Gulf of Mexico is visualized via the mean surface of the ensemble (center). For a more detailed inspection of the entire distribution of the surfaces comprising the ensemble, we provide two linked views. The \ufb01rst linked view (left) shows a histogram of depth positions of the surfaces at a selected spatial position and time step. The second linked view (right) is a time-series view that depicts a glyph for each time step at the selected position. The horizontal line corresponds to a chosen critical sea level, where each glyph\u2019s color depicts the risk corresponding to how much of the distribution is above that critical level. ", "caption_bbox": [73, 448, 775, 514]}, {"image_id": 1, "file_name": "282_01.png", "page": 2, "dpi": 300, "bbox": [85, 73, 400, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2:   The Gulf of Mexico Simulation Area covered by the presented dataset. The colors denote water depth in meters [11]. ", "caption_bbox": [73, 316, 408, 342]}, {"image_id": 2, "file_name": "282_02.png", "page": 3, "dpi": 300, "bbox": [75, 73, 773, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Application Overview. Our application for exploration of ocean forecast ensembles consists of four main views. The simulated ocean surface, or a derived version, like the mean surface for a time step, can be shown in 3D or 2D ( a and b ). The histogram view ( c ) shows the complete distribution of the ensemble at a selected position, while the time-series view ( d ) shows the distribution and the resulting operational risk at a selected position for multiple time steps. ", "caption_bbox": [73, 365, 775, 418]}, {"image_id": 3, "file_name": "282_03.png", "page": 4, "dpi": 300, "bbox": [78, 74, 406, 209], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: 3D View Detail. a shows iso contours of the mean sur- faces for all time steps blended over the current surface. The area of interest is rendered with full opacity, while the context is preserved by rendering the remaining parts semi-transparently. b shows a vol- ume rendering of the pdf at a user-selected position. The surface is color-mapped with the variance. The large spread in areas of high variance is clearly visible in the volume rendering. ", "caption_bbox": [73, 218, 408, 310]}, {"image_id": 4, "file_name": "282_04.png", "page": 4, "dpi": 300, "bbox": [440, 74, 777, 209], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The Time-Series View in detail. The y axis corresponds to the sea level, the x axis to time. Each glyph shows the distribution of the selected position for one time step. Glyphs are colored us- ing the associated risk, i.e., the fraction of the distribution above the selected critical sea level. Each time step corresponds to a unique color, as indicated by the vertical lines, which is also used for render- ing the iso contours of multiple time steps (Figure 4 a ). ", "caption_bbox": [440, 221, 775, 313]}, {"image_id": 5, "file_name": "282_05.png", "page": 5, "dpi": 300, "bbox": [88, 74, 758, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Pipeline Overview. The pipeline is divided into two major blocks: The statistical analysis part at the top, and the rendering part shown at the bottom. Both parts are entirely GPU-based, and all data (middle) are shared by both parts in GPU memory. ", "caption_bbox": [73, 305, 775, 331]}, {"image_id": 6, "file_name": "282_06.png", "page": 7, "dpi": 300, "bbox": [80, 576, 401, 929], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Spatial Exploration for placement planning consists of four main steps: De\ufb01nition of the area of interest based for example on reservoir reachability (a), general overview (b), time series analy- sis (c) and detailed analysis for veri\ufb01cation (d). ", "caption_bbox": [73, 935, 408, 988]}], "283": [{"image_id": 0, "file_name": "283_00.png", "page": 3, "dpi": 300, "bbox": [144, 438, 338, 557], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Each of the yellow vertices is a Gateway to the vertex set {A}. That is, every maximal path leaving a yellow vertex contains A. ", "caption_bbox": [73, 571, 408, 596]}, {"image_id": 1, "file_name": "283_01.png", "page": 4, "dpi": 300, "bbox": [153, 74, 696, 204], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Execution of the FindGateways algorithm. (L) An interesting simulation state has been identified, and we would like to determine the set of vertices that inevitably lead to this state. A vertex H representing this state is given as input to the algorithm. (C) After a few iterations, vertices E and G have been added to the set of Gateways (shown in green) and vertices K and L have been processed and labeled. Yellow vertices are now in the queue to be processed. (R) Upon completion of the algorithm, the set of Gateways has been iteratively grown as large as possible and the final set of Gateways (shown in green) is returned. ", "caption_bbox": [73, 225, 775, 290]}, {"image_id": 2, "file_name": "283_02.png", "page": 4, "dpi": 300, "bbox": [511, 491, 708, 617], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Vertex G is a Gateway to each of the yellow vertices, or Terminals. That is, every maximal path leaving G contains each of the yellow vertices. ", "caption_bbox": [440, 635, 775, 674]}, {"image_id": 3, "file_name": "283_03.png", "page": 5, "dpi": 300, "bbox": [153, 76, 695, 205], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Execution of the FindTerminals algorithm. (L) A simulation state that closely resembles a real-world interaction has been identified, and we would like to determine any inevitable future events. A vertex A representing this state is given as input to the algorithm. (C) To minimize computation, we begin by pruning parts of the graph. We accomplish this by selecting a random maximal path, knowing that only vertices that appear along this path can meet inevitability criteria. Vertices along this path (shown in yellow) are now in the queue to be processed. (R) After the execution of the algorithm, the final set of Terminals representing inevitable future states is returned. ", "caption_bbox": [73, 226, 775, 291]}, {"image_id": 4, "file_name": "283_04.png", "page": 6, "dpi": 300, "bbox": [180, 74, 675, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (L) Visualization of an ATG generated from 100 runs of an agent-based simulation of political hierarchies. The two yellow vertices represent an interesting feature: a highly stable vertex pair (note the high degree of revisitation). In red are the results of the FindGateways algorithm. (R) A simplified graph showing only the input vertices V 0 in yellow, the set of Gateway vertices to this set in red, and critical decision points and alternatives in green. By extracting and examining this subgraph, the analyst is able to determine that in this case there many independent paths representing distinct sequences of events leading into the yellow vertices. ", "caption_bbox": [73, 344, 775, 409]}, {"image_id": 5, "file_name": "283_05.png", "page": 7, "dpi": 300, "bbox": [182, 79, 669, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (L) Visualization of an ATG generated from 100 runs of an agent-based simulation of political hierarchies. The yellow vertex represents a simulation state similar to the current political climate. In red are the results of the FindTerminals algorithm. (R) A simplified graph showing only the input vertex in yellow and the set of Terminal vertices in red. By extracting and examining this subgraph, the analyst is able to see clearly that in this case there is is only one pathway predicted by the simulation once the yellow vertex has been reached. ", "caption_bbox": [73, 359, 775, 411]}, {"image_id": 6, "file_name": "283_06.png", "page": 8, "dpi": 300, "bbox": [143, 74, 706, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Examples of interesting structures seen in the ATG generated from an agent-based simulation of political violence in Thailand. (L) A tightly interconnected group of \u201chub\u201d vertices. In this view, repeated edges have been represented using edge weight, vertex indegree is mapped to vertex size, and the vertex is labeled with the dominant identity in the configuration the vertex encodes. (C) A stable vertex, highlighted in yellow. The majority of the edges incident to this vertex are self-loops, suggesting that the simulation often remains in this same configuration state over a period of several timesteps. (R) A stable pairing, highlighted in yellow. Note that the majority of the edges incident to this pair are shared, suggesting that the simulation often bounces between these same two configuration states over a period of several timesteps. ", "caption_bbox": [73, 276, 775, 354]}], "284": [{"image_id": 0, "file_name": "284_00.png", "page": 2, "dpi": 300, "bbox": [105, 73, 378, 355], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Stimuli for traditional (top), orthogonal (center), and radial layout (bottom): (a) Heat maps are time-aggregated region-based representations hiding intermediate steps in the data. (b) Gaze plots are trajectory-based diagrams with visual clutter. ", "caption_bbox": [73, 368, 408, 420]}, {"image_id": 1, "file_name": "284_01.png", "page": 4, "dpi": 300, "bbox": [107, 73, 743, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Color-coded time-varying distances to selected POIs for nearest marked nodes, root node, and solution node.", "caption_bbox": [131, 326, 716, 338]}, {"image_id": 2, "file_name": "284_02.png", "page": 5, "dpi": 300, "bbox": [94, 74, 756, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Tree diagrams with time series plots showing the relative number of participants that visited specific regions in a displayed stimulus: (a) traditional diagram (31 as the maximal number of fixations), (b) orthogonal diagram (29), and (c) radial tree diagram (26). ", "caption_bbox": [73, 242, 775, 267]}, {"image_id": 3, "file_name": "284_03.png", "page": 6, "dpi": 300, "bbox": [109, 73, 740, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Gaze trajectories split into five equally sized time intervals of 200 relative units each (from left to right). Three layouts are shown: (top row) traditional, (center row) orthogonal, and (bottom row) radial. ", "caption_bbox": [73, 397, 775, 422]}, {"image_id": 4, "file_name": "284_04.png", "page": 7, "dpi": 300, "bbox": [79, 73, 414, 766], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Relative number of participants\u2019 eye moves between re- gions of interest in displayed stimuli proportionally mapped to link thicknesses: source region, target region, and directions of eye movement over time in 100 unit steps. Time starts at the top row. Layouts: (a) traditional, (b) orthogonal, and (c) radial. ", "caption_bbox": [73, 779, 408, 844]}], "285": [{"image_id": 0, "file_name": "285_00.png", "page": 1, "dpi": 300, "bbox": [115, 86, 789, 401], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Time Step 11 of the Limited Area Meso-Scale Prediction System (LAMPS) data set [20]. On the left, U and V vector components. The circular structure apparently shows rotational movement in the simulation. On the right, pressure, temperature and specific humidity, with staircase structure showing complex pressure / humidity interactions around regions of higher temperature. ", "caption_bbox": [73, 454, 775, 495]}, {"image_id": 1, "file_name": "285_01.png", "page": 3, "dpi": 300, "bbox": [109, 351, 731, 886], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The variation in level sets of a bivariate function can be expressed as a 2-manifold. Here, the function f1 is a distance field, and the function f2 is a height field. If we take an isosurface of f1 then compute the Reeb graph of f2 restricted to that surface, we get the sequence shown on the right. If we take an isosurface of f2 then compute the Reeb graph of f1 restricted to that surface, we get the sequence displayed along the top. Note that the Jacobi Set of this example are a subset of the edges of the manifold projected back into the domain of f . ", "caption_bbox": [73, 906, 775, 961]}, {"image_id": 2, "file_name": "285_02.png", "page": 3, "dpi": 300, "bbox": [116, 77, 738, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The contour trees for two small data sets. Each contour contracts to a single point. Forks in the tree correspond to saddles, leaves correspond to extrema. ", "caption_bbox": [73, 304, 775, 331]}, {"image_id": 3, "file_name": "285_03.png", "page": 5, "dpi": 300, "bbox": [125, 73, 723, 924], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The Joint Function is divided into Joint Contour Slabs by intersecting the slabs with respect to each individual function. The Joint Contour Graph is then constructed as the dual graph of the Joint Contour Slabs. Finally, the Joint Contour Net is constructed by contracting adjacent nodes in the Joint Contour Graph with matching values. Note that the same contraction can be used to compute individual contour trees either from the Joint Contour Net or directly from the individual Contour Graphs. ", "caption_bbox": [73, 963, 775, 1018]}, {"image_id": 4, "file_name": "285_04.png", "page": 7, "dpi": 300, "bbox": [201, 88, 644, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Dataset Statistics", "caption_bbox": [175, 779, 306, 792]}], "286": [{"image_id": 0, "file_name": "286_00.png", "page": 4, "dpi": 300, "bbox": [440, 73, 744, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Pseudo-code summarizing SOMMOS.", "caption_bbox": [487, 423, 724, 436]}, {"image_id": 1, "file_name": "286_01.png", "page": 4, "dpi": 300, "bbox": [99, 73, 385, 127], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Demonstrating the proposed radius formulation (Eq. 1) by depicting a specific solution from the TAM example (Section 7) com- pared to the common radial bar charts formulae (\u2019sqrt\u2019, \u2019linear\u2019). ", "caption_bbox": [73, 142, 409, 181]}, {"image_id": 2, "file_name": "286_02.png", "page": 6, "dpi": 300, "bbox": [164, 488, 685, 919], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A five-objective Transportation Asset Management problem. Focusing on the yellow cluster, which aims at maximizing air quality, the decision maker can clearly identify that she can maximize both air quality and congestion reduction. She can compromise a bit on congestion reduction to gain higher economic growth. Unfortunately, there is no option for a decent compromise with cyclist/pedestrian trails without hindering the air quality. Note that both the glyph fill color and the order of the objectives contribute to the decision maker\u2019s ability to understand the above insights. ", "caption_bbox": [73, 934, 775, 999]}, {"image_id": 3, "file_name": "286_03.png", "page": 6, "dpi": 300, "bbox": [156, 75, 692, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A screen-shot of the Self-Organizing Maps for Multi-Objective Pareto Frontiers (SOMMOS) as part of the PPM system. The decision maker decides she would like to gain in revenue at least $60M , so she filtered out the solutions with low revenue. She then adds a solution to the basket (outlined in + signs) that she sees as a good compromise between all the objectives. Given that she does not want to compromise too much on risk but still would like to increase her revenue, she examines another solution within the cluster that maximizes revenue. She notices that by compromising on 0.5 in risk she can maximize her revenue and still have a decent cost reduction. She can now either add that solution to the basket and compare the two more rigorously or continue exploring other options. ", "caption_bbox": [73, 400, 775, 479]}, {"image_id": 4, "file_name": "286_04.png", "page": 7, "dpi": 300, "bbox": [499, 76, 718, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A RadViz application [8] of the transportation asset man- agement problem. The colored points demonstrate a drawback of RadViz, as it does not support the adjacency requirement. Specifi- cally, non-similar solutions can be placed close to each other. ", "caption_bbox": [440, 294, 775, 346]}], "287": [{"image_id": 0, "file_name": "287_00.png", "page": 3, "dpi": 300, "bbox": [472, 302, 742, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An illustration of determining significant bins. Given a clus- ter (Fi ) and the number of its data points per bin (Eib , in decreasing order), the set of significant bins is the smallest group of bins that can represent Fi \u2019s presence above a given percentage threshold (t). ", "caption_bbox": [440, 363, 775, 416]}, {"image_id": 1, "file_name": "287_01.png", "page": 4, "dpi": 300, "bbox": [149, 75, 708, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Statistics views based on CO3 metrics. Various examples of utilizing CO3 metrics in visualization and analysis. The utility of the visualizations in the subfigures (along with corresponding labels) are discussed in Sections 4.2, 4.3, and 4.4. (Year 2003, 5 km bin size) ", "caption_bbox": [73, 241, 775, 267]}, {"image_id": 2, "file_name": "287_02.png", "page": 4, "dpi": 300, "bbox": [78, 695, 402, 761], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Clusters in quadrants A, B and C (left to right) in Figure 2(b).", "caption_bbox": [73, 769, 408, 782]}, {"image_id": 3, "file_name": "287_03.png", "page": 5, "dpi": 300, "bbox": [106, 190, 378, 483], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (Top) A snapshot of CO3 Inspector showing the spatiotem- poral view, graph view, and statistics view; (bottom) Spatiotemporal view adapted for the power grid application. ", "caption_bbox": [73, 487, 408, 526]}, {"image_id": 4, "file_name": "287_04.png", "page": 6, "dpi": 300, "bbox": [448, 261, 769, 548], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: An example feature group in the MODIS data. The se- lection starts from the example feature of salt flats and white sands. After a series of navigation and selection refinement steps, users are able to discover such a feature group. These phenostates reside in some large irrigated lands in dry areas. (Year 2000, 15km bin size) ", "caption_bbox": [440, 558, 775, 623]}, {"image_id": 5, "file_name": "287_05.png", "page": 6, "dpi": 300, "bbox": [96, 74, 384, 225], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A highly continuous and concentrated feature in the MODIS data that captures areas of salt plains and white sands - The Bon- neville Salt Flats (1), White Sands National Monument (2), and other salt flats (3) are highlighted. (Year 2000, 15km bin size) ", "caption_bbox": [73, 230, 408, 282]}, {"image_id": 6, "file_name": "287_06.png", "page": 6, "dpi": 300, "bbox": [81, 647, 397, 827], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An example from the FNET data showing a highly concen- trated and continuous feature, with an exceptionally low frequency but a large phase angle shift. Temporal histogram (a) shows this fea- ture is exclusive to a small window of time after the \u201cStorm Period\u201d. (1s bin size) ", "caption_bbox": [73, 836, 408, 901]}, {"image_id": 7, "file_name": "287_07.png", "page": 7, "dpi": 300, "bbox": [471, 74, 743, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: We expand the graph in Figure 8(b) and refine the selec- tion to two individual parts that initially appeared together. The area showed on the top row is almost totally correlated to the Central Cal- ifornia Valley. (Year 2003, 5km bin size) ", "caption_bbox": [440, 360, 775, 412]}, {"image_id": 8, "file_name": "287_08.png", "page": 7, "dpi": 300, "bbox": [101, 74, 373, 352], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: An example feature group in the MODIS data. The spa- tial distribution a the feature group containing areas in the Southern Great Plains and the outline of the Central California Valley (Year 2003, (a, b) 5km bin size, (c, d) 20km bin size). ", "caption_bbox": [73, 355, 408, 407]}, {"image_id": 9, "file_name": "287_09.png", "page": 8, "dpi": 300, "bbox": [447, 74, 763, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Traditional parallel coordinates plots of example feature groups (rendered with the other features in the same attribute space in different colors): (a, b) Figure 7, (c) Figure 10(a), (d) Figure 10(b). The features that selected using CO3 Inspector are colored in red. The features selected by specifying variable ranges (c and d) are plotted in bluish color. The rest are colored in orange. ", "caption_bbox": [440, 307, 775, 385]}, {"image_id": 10, "file_name": "287_10.png", "page": 8, "dpi": 300, "bbox": [79, 74, 394, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Two example feature groups in the FNET data; both oc- curred in a \u201cStorm Period\u201d. Both are inherently correlated in terms of co-occurrence, but contain highly contrasting distribution patterns. (1s bin size) ", "caption_bbox": [73, 374, 408, 426]}], "288": [{"image_id": 0, "file_name": "288_00.png", "page": 2, "dpi": 300, "bbox": [442, 74, 775, 187], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: H \u2032 is the histogram after logarithm and normalization of the original histogram of the earthquake data set. H is the new histogram which results from multiplying H \u2032 by the opacity value. Blue and red arrows indicate the breakpoints determined by the original histogram and H, respectively. ", "caption_bbox": [440, 188, 775, 255]}, {"image_id": 1, "file_name": "288_01.png", "page": 3, "dpi": 300, "bbox": [90, 76, 393, 176], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Comparing SAX symbol splitting using our algorithm (a) and the original algorithm [12] (b). Red indicates which symbol to split and blue indicates the largest value range. ", "caption_bbox": [73, 177, 408, 216]}, {"image_id": 2, "file_name": "288_02.png", "page": 3, "dpi": 300, "bbox": [508, 75, 707, 164], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An illustration of an iSAX index. Internal nodes and terminal nodes are denoted with [ ] and { }, respectively. ", "caption_bbox": [440, 170, 775, 204]}, {"image_id": 3, "file_name": "288_03.png", "page": 4, "dpi": 300, "bbox": [81, 74, 769, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) and (b) show the comparison of iTrees of the argon bubble data set generated using the original algorithm [12, 18] and our algorithm with new schemes for breakpoint identification and symbol splitting. Three main clusters are highlighted in the volume at time step 160. ", "caption_bbox": [73, 270, 775, 296]}, {"image_id": 4, "file_name": "288_04.png", "page": 6, "dpi": 300, "bbox": [81, 335, 768, 468], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Exploring the supernova (entropy) data set using the SAX view. (a) shows the overall density pattern of SAX words with a particular SAX word highlighted. (b) shows the zoom-in into the first time interval where user selections are highlighted in green. (c) SAX filtering shows the SAX words that are within a distance of 1.0 to the selected green regions. ", "caption_bbox": [73, 470, 775, 509]}, {"image_id": 5, "file_name": "288_05.png", "page": 6, "dpi": 300, "bbox": [81, 73, 766, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) level-of-detail exploration of the iTree of the combustion data set. We mark four nodes (1) to (4) at four different levels of detail in the iTree. The four images to the right show the corresponding clusters highlighted in the volume at the first time step. (b) exploring the supernova (entropy) data set using the iTree and volume views. We show the iTree with the corresponding nodes highlighted according to SAX filtering. (1) shows the full volume rendering at time step 1295. (2) to (4) show the corresponding volumetric region and the tracking results at three selected time steps: 1295, 1323 and 1353. ", "caption_bbox": [73, 256, 775, 321]}, {"image_id": 6, "file_name": "288_06.png", "page": 7, "dpi": 300, "bbox": [80, 394, 795, 548], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Searching the iTree of the hurricane data set. (a) a block at (x, y, z,t) = (91, 31, 20, 48) is selected using three slices along the x, y and z axes, respectively. (b) and (c) show the exact search results with \u03b4 = 0.000711. (d) and (e) are the results at other two selective time steps for the exact search with the same threshold. ", "caption_bbox": [73, 549, 775, 588]}, {"image_id": 7, "file_name": "288_07.png", "page": 7, "dpi": 300, "bbox": [80, 75, 804, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Querying the earthquake data set. (a) a group of blocks at time step 90 are selected by bounding two slices along each of the x, y and z axes, respectively. (c) the initial SAX view of the group of blocks. (d) the F+C visualization with three clusters highlighted and the orange cluster selected. (b) and (e) to (h) are the query results where the SAX words are within a distance of 4.0 to the selected cluster at every SAX symbol. ", "caption_bbox": [73, 339, 775, 378]}], "289": [{"image_id": 0, "file_name": "289_00.png", "page": 1, "dpi": 300, "bbox": [95, 86, 755, 428], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) Systolic blood flow in the right ventricular outflow tract (i.e., right ventricle (RV), pulmonary trunk (PA), right (RPA) and left pulmonary arteries (LPA)) of a healthy heart. The fastest blood (maximal velocity \u2265 80 cm       s ) flows from the ventricle into the left and right pulmonary artery. (b) Our illustrative visualization depicts this balanced behavior comprehensively with a diverging arrow. (c) Blood flow in an aorta with a large aneurysm in the proximal descending part. The line bundle shows the flow through the vortex in the descending aorta (arrow). (d) The representatives of the previous line bundle show clearly how two other vortices are involved in this flow as well (arrows). ", "caption_bbox": [73, 447, 775, 512]}, {"image_id": 1, "file_name": "289_01.png", "page": 2, "dpi": 300, "bbox": [79, 77, 422, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustrations showing blood flow through the heart as observed in studies with 4D MRI measurements. Abbreviations: Ao, aorta; LA, left atrium; LV, left ventricle; PA, pulmonary artery; RA, right atrium; RV, right ventricle. Reprinted by permission from Macmillan Publishers Ltd: Nature 404: Kilner et al. [13], c 2000. ", "caption_bbox": [73, 290, 408, 355]}, {"image_id": 2, "file_name": "289_02.png", "page": 4, "dpi": 300, "bbox": [79, 80, 771, 232], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Finding representatives of a line bundle (shown by means of the flow in the right ventricular outflow tract after repair of TOF). (a) The voxel representation of a line bundle\u2019s characteristic set and (b) the original line bundle to be represented. (c) Topologically correct skeleton and (d) representatives determined based on it (already neglecting lines with a low impact). (e) Skeleton of the smoothed characteristic set and added vortex core lines (red). (f) The reduced number of lines. ", "caption_bbox": [73, 251, 775, 303]}, {"image_id": 3, "file_name": "289_03.png", "page": 5, "dpi": 300, "bbox": [448, 73, 768, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Tube-like structure depicting a vortex region. The hatching resembles vortical flow. Shown together with a yellow streamtape. ", "caption_bbox": [440, 282, 775, 308]}, {"image_id": 4, "file_name": "289_04.png", "page": 5, "dpi": 300, "bbox": [82, 73, 402, 453], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Fusion of streamtape segments (cross-sectional view). (a) Situation for two streamtapes. Tapes are arranged next to each other along the averaged binormal. (b) The ordering of three streamtapes depends on the scalar products between di and the average binor- mal. ", "caption_bbox": [73, 471, 408, 536]}, {"image_id": 5, "file_name": "289_05.png", "page": 6, "dpi": 300, "bbox": [82, 74, 768, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Blood flow in the right ventricular outflow tract of the pathological heart dataset. (a) The blood ejected from the right ventricle (maximal velocity \u2265 165 cm                 s flows into the left pulmonary artery. (b) The representatives show nicely the pathological flow situation in the left pulmonary artery with turbulent flow. A different viewing direction is chosen for a better overview. The subfigure shows that the tape ordering is not consistent in this case (arrow). (c) Blood flow towards the right pulmonary artery shows vortical behavior in the bulges of the pulmonary trunk. (d) The abstract depiction shows this vortical behavior more comprehensible. Abbreviations: RV, right ventricle; RA, right atrium; PA, pulmonary artery; LPA, left PA; RPA, right PA; Ao, aorta. ", "caption_bbox": [73, 321, 775, 399]}, {"image_id": 6, "file_name": "289_06.png", "page": 7, "dpi": 300, "bbox": [82, 74, 768, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Blood flow in the left atrium of a healthy heart during systole and diastole. (a) Streamline bundle showing blood flowing from left atrium to left ventricle with a maximal velocity \u2265 100 cms . (b) This flow behavior is represented by three streamlines depicting the different sources of the blood. (c) With closed valves, a large centered vortex evolves in the left atrium. (d) The vortical flow is represented by a single streamline. Abbreviations see Fig. 6. ", "caption_bbox": [73, 321, 775, 373]}], "29": [{"image_id": 0, "file_name": "29_00.png", "page": 3, "dpi": 300, "bbox": [156, 808, 643, 987], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Sample Scan History over regions.", "caption_bbox": [280, 1002, 544, 1019]}, {"image_id": 1, "file_name": "29_01.png", "page": 3, "dpi": 300, "bbox": [161, 415, 631, 529], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Smear Instantaneous Coverage into Swaths.", "caption_bbox": [252, 382, 573, 399]}, {"image_id": 2, "file_name": "29_02.png", "page": 3, "dpi": 300, "bbox": [174, 577, 516, 794], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Sample Scan History at a point.", "caption_bbox": [289, 548, 536, 565]}, {"image_id": 3, "file_name": "29_03.png", "page": 4, "dpi": 300, "bbox": [161, 752, 660, 933], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Scan History analysis through Latency.", "caption_bbox": [266, 947, 559, 964]}, {"image_id": 4, "file_name": "29_04.png", "page": 4, "dpi": 300, "bbox": [160, 589, 637, 748], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Framework for generating Scan Histories.", "caption_bbox": [257, 555, 567, 572]}, {"image_id": 5, "file_name": "29_05.png", "page": 5, "dpi": 300, "bbox": [202, 77, 624, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Latency Mapping Example.", "caption_bbox": [300, 378, 525, 395]}], "290": [{"image_id": 0, "file_name": "290_00.png", "page": 2, "dpi": 300, "bbox": [79, 77, 404, 189], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Volume of fluid method with PLIC interface reconstruc- tion. (a) Exemplary distribution of the f -field. (b) PLIC reconstruction (gray) of the interface based on normals n\u03b3 . (c) Time integrals \u03c6 x (blue) of f -fluxes over time step \u03b4 t in x-direction. ", "caption_bbox": [73, 202, 411, 254]}, {"image_id": 1, "file_name": "290_01.png", "page": 3, "dpi": 300, "bbox": [81, 75, 402, 164], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overall pipeline of our framework with respect to data (blue), computation (orange), and results (green). ", "caption_bbox": [73, 179, 410, 205]}, {"image_id": 2, "file_name": "290_02.png", "page": 4, "dpi": 300, "bbox": [79, 74, 408, 191], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) PLIC as isosurface extraction problem in f\u02dc1 . First-order approximation f\u02dc1 exhibits planar isosurfaces (dashed lines) perpen- dicular to \u2207 f (xc ) (red), and so does PLIC by construction (green). Hence, instead of adjusting \u03c4 such that the volume \u00b5 (P\u03c4 ) of the en- closed polyhedron P\u03c4 equals fc , one can adjust isolevel \u03c3 accord- ingly. (b) and (c) Discretization (gray nodes) of f\u02dck within a simulation cell (bold grid). (b) An isosurface (gray polygon) representing the PLIC polyhedron P (green) is obtained by setting all boundary nodes (red) of the supersampling grid to -FLT MAX. (c) Cells are split at \u201creversely advected\u201d cell face to generate flux volume (blue), f\u02dck is in- terpolated at the new (gray) nodes. Nodes below the face are set to ", "caption_bbox": [72, 205, 411, 351]}, {"image_id": 3, "file_name": "290_03.png", "page": 5, "dpi": 300, "bbox": [77, 75, 777, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Our measures applied to the Sphere dataset (top row, rendered with backface culling to make discontinuity gaps better visible), and to a small part of a ligament (bottom row, without backface culling) in the last time step of Figure 8. Columns: Traditional isosurface (a), minimum discontinuity \u03b4min (b), maximum discontinuity \u03b4max on PLIC (c) and on second-order patches (d), bound B (Eq. 4) on approximation error with respect to f (e), second-order PLIC patches colored with surface curvature \u03bamax (f), and cell-wise maximum \u03ba\u0302max of (f) colored on the PLIC patches (g). The radius of the sphere according to our PLIC reconstruction is 0.0505 m (initialized as 0.05 m), hence the curvature should be ideally 20 m\u22121 . While (b), (c), and (d) account for the displacement of the patches along \u2207 f (x), (e), (f), and (g) take into account only partial derivatives of f and are hence not directly dependent on the displacement. ", "caption_bbox": [73, 274, 775, 365]}, {"image_id": 4, "file_name": "290_04.png", "page": 6, "dpi": 300, "bbox": [107, 75, 740, 182], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Zalesak dataset at time step 25 (time 0.0375 s) and simula- tion grid 322 \u00d716 (a), 642 \u00d732 (b), and 1282 \u00d764 (c), visualized by PLIC patches. The coloring by B (left halves) and c \u00b7 B (right halves) con- veys approximation problems regarding the f -field, including aliasing. The gray box depicts the region analyzed in Figure 5, however for the onset of the simulation. ", "caption_bbox": [439, 469, 777, 547]}, {"image_id": 5, "file_name": "290_05.png", "page": 6, "dpi": 300, "bbox": [458, 352, 766, 455], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Timings (in seconds) for the datasets from Figure 8 (C1: 323 , C2: 643 , C3: 1283 ) and from Figure 9 (M), QUAD: second-order surface, Flux: flux volumes. Total exectution time in brackets. ", "caption_bbox": [73, 859, 410, 898]}, {"image_id": 6, "file_name": "290_06.png", "page": 7, "dpi": 300, "bbox": [470, 330, 750, 454], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Freezing Drop 2D dataset stacked in space-time (time axis downward). View along time visualizes the growth of the crystal (upper right in (a)). The PLIC patch size (bottom of (a)) is smaller at the dendrites. Although, the crystal growth is faster in these ar- eas. Discontinuities \u03b4max are smaller at the dendrites (bottom of (b)), providing a possible explanation. Another unexpected result are two parallel PLIC patches per axis at initialization (upper left in (b)). ", "caption_bbox": [439, 468, 777, 559]}, {"image_id": 7, "file_name": "290_07.png", "page": 7, "dpi": 300, "bbox": [107, 74, 762, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Colliding Drops dataset. Visualization by PLIC patches with \u03ba\u0302max (left halves) and \u03ba\u0302max \u00b7 c (right halves), for same time step at resolution 323 (a), 643 (b), 1283 (c). \u03ba\u0302max \u00b7 c provides good estimate of approximation quality. Top: Time evolution by PLIC colored with \u03ba\u0302max . ", "caption_bbox": [73, 279, 775, 306]}, {"image_id": 8, "file_name": "290_08.png", "page": 8, "dpi": 300, "bbox": [120, 195, 757, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Merging Drops dataset. PLIC patches colored by discontinuity \u03b4max (a), by curvature \u03bamax on second-order surface reconstruction (b), and a closeup thereof visualized using surface reconstruction and flux volumes based on first-order (PLIC) approximation (c), and second-order approximation (d). As shown in (d), disconnection should occur due to larger flux volume in the lower region. In (c) PLIC suppresses the breakup. ", "caption_bbox": [73, 354, 777, 393]}, {"image_id": 9, "file_name": "290_09.png", "page": 8, "dpi": 300, "bbox": [106, 75, 760, 150], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Time sequence of Merging Drops dataset. Visualization by PLIC patches colored by \u03b4max , in frame of reference moving with the drops.", "caption_bbox": [73, 165, 777, 179]}], "291": [{"image_id": 0, "file_name": "291_00.png", "page": 2, "dpi": 300, "bbox": [85, 73, 764, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Hybrid wind tunnel system.", "caption_bbox": [333, 290, 515, 302]}, {"image_id": 1, "file_name": "291_01.png", "page": 3, "dpi": 300, "bbox": [456, 74, 761, 180], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Classification of 2D critical points.", "caption_bbox": [500, 193, 714, 205]}, {"image_id": 2, "file_name": "291_02.png", "page": 3, "dpi": 300, "bbox": [456, 222, 760, 452], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Critical points and ridge/ravine lines of a 2D sample dataset. ", "caption_bbox": [440, 469, 775, 495]}, {"image_id": 3, "file_name": "291_03.png", "page": 4, "dpi": 300, "bbox": [507, 73, 710, 224], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Design of a topologically-accentuated color map.", "caption_bbox": [463, 244, 751, 256]}, {"image_id": 4, "file_name": "291_04.png", "page": 7, "dpi": 300, "bbox": [81, 91, 772, 942], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visual tracking of vortical regions represented as ridge cycles (Re \u2248 1,000). Note that the region enclosed by the purple lines at each time step traces a specifically-selected vortex. ", "caption_bbox": [73, 954, 775, 982]}, {"image_id": 5, "file_name": "291_05.png", "page": 8, "dpi": 300, "bbox": [213, 87, 638, 934], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Juxtaposition results where the computationally-visualized images are superimposed synchronously onto the corresponding physically- visualized ones. ", "caption_bbox": [73, 963, 775, 989]}], "292": [{"image_id": 0, "file_name": "292_00.png", "page": 1, "dpi": 300, "bbox": [136, 86, 718, 516], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Our system is composed of many linked views. Structural MRI data is presented in a 3D visualization (top left) whose transfer function is manipulated using 2D widgets (bottom right). Users may select individual EEG sensors (yellow sphere) in the 3D visualization to explore its raw signal (bottom left) and time-frequency representation (middle right). The user also interacts with the time-frequency query area (top right) to generate spectral queries. The time-frequency display and query area are colormapped using an interactive widget (middle left). Combined with the settings in the parameter dialog, the query is issued and relevant sensors are colored blue according to their correlation with the query. ", "caption_bbox": [73, 530, 775, 595]}, {"image_id": 1, "file_name": "292_01.png", "page": 2, "dpi": 300, "bbox": [494, 80, 722, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Brain activity related to working memory is generated in more than just one part of the brain. Almost every part of the brain exhibits various patterns of activation spanning the temporal cortex (green), the parietal cortex (blue), the frontal cortex (light red) and the prefrontal cortex (dark red). ", "caption_bbox": [440, 345, 775, 410]}, {"image_id": 2, "file_name": "292_02.png", "page": 3, "dpi": 300, "bbox": [130, 80, 356, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Our system supports two primary functions: exploring EEG data and extracting neural circuits. Users interact with the system primarily to extract and visualize neural circuits. To achieve the best results, users iteratively refine time-frequency queries and set filter parameters for the results. Here, yellow ovals represent steps that users have direct control over. ", "caption_bbox": [73, 382, 408, 460]}, {"image_id": 3, "file_name": "292_03.png", "page": 3, "dpi": 300, "bbox": [453, 80, 764, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Creating a time-frequency query. The user interacts pri- marily with a 2D time-frequency plane in which a circular brush (blue outline) controls the scalar field being painted. When paint strokes overlap, their respective values are either additave or subtractive, al- lowing scientists to gradually change the time-frequency query being constructed. The time and frequency coordinates along with their supports of the kernel are displayed during interaction to ensure the user knows exactly how the query is being manipulated. ", "caption_bbox": [440, 291, 775, 395]}, {"image_id": 4, "file_name": "292_04.png", "page": 4, "dpi": 300, "bbox": [73, 74, 410, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Finding the similarity between an input query and a sen- sor\u2019s time-frequency data begins with computing the correlation im- age through convolution. A filter mask is then formed using the user- controlled sensitivity and lag parameters. This mask is then multi- plied with the correlation image. The maximum value of this filtered image represents the filtered similarity between the input query and sensor data. ", "caption_bbox": [73, 355, 408, 446]}, {"image_id": 5, "file_name": "292_05.png", "page": 4, "dpi": 300, "bbox": [472, 72, 744, 201], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Large collections of time-frequency planes may be pro- jected to a plane to reduce the overall dimensionality of the dataset. Here, IsoMap has been used to position individual planes while at- tempting to conserve the relative differences between the various data points. ", "caption_bbox": [440, 217, 775, 282]}, {"image_id": 6, "file_name": "292_06.png", "page": 5, "dpi": 300, "bbox": [160, 78, 685, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Using a data driven query to extract a neural circuit results in an overall high correlation because the query exists exactly in the data. However, carefully constructed user generated queries may yield similar results. Here, the differences between data driven and user generated queries are explored. On the left is the result of a user-generated query (top inset), while the rendering on the right is driven by a time-frequency image from the EEG collection (bottom inset). ", "caption_bbox": [73, 326, 775, 378]}, {"image_id": 7, "file_name": "292_07.png", "page": 6, "dpi": 300, "bbox": [163, 75, 686, 368], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Our system helps provide evidence supporting the hypothesis that the application of rTMS enhances the performance of working memory. Using the query pictured above, we extracted a working memory circuit before stimulation with rTMS (left) and then after (right). Although the circuit extracted is similar in both cases, the overall similarity measure is markedly different. The expected spectral evolution is more evident after stimulation. ", "caption_bbox": [73, 389, 775, 441]}, {"image_id": 8, "file_name": "292_08.png", "page": 7, "dpi": 300, "bbox": [470, 76, 746, 227], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Volumetric datasets have high correlation between adja- cent slices, giving rise to features that exist in all three dimensions of the volume. Here, a synthetic dataset composed of three concentric spheres (a) is shown. By re-ordering slices in this symmetric volume using a correlation measure with the mid-volume plane as the query image (b), the symmetry is exploited to form a different volumetric dataset with high correlation between slices. ", "caption_bbox": [440, 248, 775, 339]}], "293": [{"image_id": 0, "file_name": "293_00.png", "page": 2, "dpi": 300, "bbox": [446, 73, 771, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Screenshots of our system during the three phases as de- scribed in Section 3.1. The planning phase (Section 3.2 in the top left, recording phase (Section 3.3) on the right, and the placement phase (Section 3.4) on the lower left. ", "caption_bbox": [440, 258, 775, 310]}, {"image_id": 1, "file_name": "293_01.png", "page": 2, "dpi": 300, "bbox": [74, 73, 409, 187], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The MER discharge pattern changes depending on the functional region of the brain. The level of background activity and single-cell activity varies when entering or leaving specific regions and can be used to identify these region [3, 14]. ", "caption_bbox": [73, 199, 408, 251]}, {"image_id": 2, "file_name": "293_02.png", "page": 3, "dpi": 300, "bbox": [145, 76, 706, 218], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The workflow of the proposed DBS intervention system can be divided into three phases: planning, recording and placement. To support each of these phases, we employ dedicated views that are arranged in a multiple view setup as shows in Figure 3. External components interacting with our visualization system are shown for each phase. ", "caption_bbox": [73, 226, 775, 265]}, {"image_id": 3, "file_name": "293_03.png", "page": 4, "dpi": 300, "bbox": [97, 780, 386, 933], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Two x-ray images are created to calibrate the patient\u2019s po- sition in the operating room using the perspective distortion of the reference plates. Subsequent x-ray images are used to verify the electrodes position inside the head and estimate the uncertainty of the segmentation. ", "caption_bbox": [73, 945, 408, 1010]}, {"image_id": 4, "file_name": "293_04.png", "page": 4, "dpi": 300, "bbox": [480, 74, 736, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: In the recording phase the contextual view additionally shows the intra-operatively acquired x-ray scans. It further renders the electrode while it is being advanced towards the target. The beads behind the electrodes represent the results of the MER sig- nal analysis. ", "caption_bbox": [440, 336, 775, 401]}, {"image_id": 5, "file_name": "293_05.png", "page": 5, "dpi": 300, "bbox": [89, 802, 395, 924], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The MER signal in the time domain is shown using an oscillograph-like representation in which time is on the horizontal axis and the electric potential difference on the vertical. The visual per- ception of the signal is enhanced by de-emphasizing the background noise and guiding the attention to the more important spikes. The signal of the currently selected electrodes is highlighted. ", "caption_bbox": [73, 932, 408, 1010]}, {"image_id": 6, "file_name": "293_06.png", "page": 5, "dpi": 300, "bbox": [439, 74, 779, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Combining the spatial orientation and layout of the record- ing electrodes with the temporal signal relieves the surgeon of the burden to keep this association in mind. To enhance the perception of the spikes, only the values above a certain threshold are shown in this view so that they are visible pre-attentively. The inset shows the result for one electrode without thresholding. ", "caption_bbox": [440, 219, 775, 297]}, {"image_id": 7, "file_name": "293_07.png", "page": 6, "dpi": 300, "bbox": [445, 74, 771, 259], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The placement guide gives a quantitative overview of mea- sured data for potential target regions. The top figure is a combina- tion of all data values, where as the lower figures present detailed information by showing either all values or pairwise combinations. These combinations enable the surgeon to gain further insight into the measurements in certain situations, for example, when a mea- surement proves unreliable during the procedure. ", "caption_bbox": [440, 266, 775, 357]}, {"image_id": 8, "file_name": "293_08.png", "page": 6, "dpi": 300, "bbox": [76, 74, 408, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The target closeup visualization shows the potential tar- get regions (speech tests=blue, movement tests=purple). The spa- tial context provided by the MRI signal is color coded using the red- green MER region mapping. The stimulation electrode changes its color when it is entering the intersection of the potential target area. This view gives qualitative access to all uncertainty data fused with structural data in one glance. ", "caption_bbox": [73, 296, 408, 387]}], "294": [{"image_id": 0, "file_name": "294_00.png", "page": 2, "dpi": 300, "bbox": [491, 74, 726, 200], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The preprocessing phase transforms the volume data into metadata using the transformation pipeline in equation (2). This re- quires O(N) working set complexity, for a volume with N elements. In the interactive phase, queries for distribution range queries are evaluated by reading parts of the metadata on demand into the trans- formation pipeline in equation (3). The working set complexity for this phase depends primarily on the result query size rather than the size of the input volume. ", "caption_bbox": [440, 210, 775, 320]}, {"image_id": 1, "file_name": "294_01.png", "page": 3, "dpi": 300, "bbox": [492, 219, 730, 399], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: In this example, a 1D integral distribution volume (Xi (s)) is discretized into 8 span distributions (Yk,i ) as described in equation (9). The span distribution at index 6, for example, is computed by subtracting Xi (5) from Xi (7). ", "caption_bbox": [440, 414, 775, 471]}, {"image_id": 2, "file_name": "294_02.png", "page": 4, "dpi": 300, "bbox": [492, 74, 730, 206], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Distribution range queries are executed by evaluating the integral distirbution of each corner of the range using equation (10), then combining them using equation (8). In this example, the range query is evaluated using 4 span distributions, subtracting the span distributions (Y2,i and Y3,i ) that contribute to the Xi (4) integral dis- tribution, and adding the span distributions (Y4,i and Y6,i ) that con- tribute to the Xi (7) integral distribution. ", "caption_bbox": [440, 224, 775, 322]}, {"image_id": 3, "file_name": "294_03.png", "page": 4, "dpi": 300, "bbox": [519, 334, 698, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The Z-order space-filling curve maps a d-dimensional integer coordinate to a 1-dimensional integer coordinate. In this example, a 3D coordinate with 4 bits per component is mapped to a a single 1D coordinate with 12 bits. ", "caption_bbox": [440, 404, 775, 459]}, {"image_id": 4, "file_name": "294_04.png", "page": 5, "dpi": 300, "bbox": [469, 73, 748, 194], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Both the size of the levels, and the number of span dis- tributions in the levels, exponentially decreases as the level number increases. The ratio between the size of the span distributions and the number of span distributions enables modeling of the entropy per span distribution. ", "caption_bbox": [440, 207, 775, 276]}, {"image_id": 5, "file_name": "294_05.png", "page": 5, "dpi": 300, "bbox": [469, 521, 747, 627], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The relationship between the error bound and the stored size for varying numbers of levels skipped ", "caption_bbox": [440, 640, 775, 667]}, {"image_id": 6, "file_name": "294_06.png", "page": 6, "dpi": 300, "bbox": [469, 633, 755, 779], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Out-of-core data, query time transient response, randomly positioned and sized queries, 64MiB source data ", "caption_bbox": [440, 791, 775, 818]}, {"image_id": 7, "file_name": "294_07.png", "page": 6, "dpi": 300, "bbox": [469, 79, 760, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison of metadata sizes from applying lossless compression with span distributions versus lossy compression with span distributions versus no compression with integral histograms ", "caption_bbox": [440, 207, 775, 248]}, {"image_id": 8, "file_name": "294_08.png", "page": 6, "dpi": 300, "bbox": [102, 265, 389, 411], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Out-of-core data, query time, randomly positioned and sized queries, 2016MiB source data ", "caption_bbox": [73, 424, 408, 451]}, {"image_id": 9, "file_name": "294_09.png", "page": 7, "dpi": 300, "bbox": [447, 582, 773, 726], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Interactive transfer function design for large-scale time-varying volume data, using interactive 4D distribution range queries, as discussed in \u00a74.2. The user moves a region of interest in the left pane on a projection of the volume. The distribution of the region of interest is then used to generate transfer functions in the right pane, using the same technique as Martin et al.[23] ", "caption_bbox": [440, 726, 775, 808]}, {"image_id": 10, "file_name": "294_10.png", "page": 7, "dpi": 300, "bbox": [119, 523, 367, 634], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Approximate sum aggregation of 3D volumes for Ho\u0308vmoller diagrams as discussed in \u00a74.1. The horizontal axis is longitude and the vertical axis is time. The tolerance provides a bound on how far the approximate sums may be from the true sums. The dataset is from a simulation produced by the Pacific North- west National Laboratory to examine the Madden-Julian Oscilla- tion [12]. ", "caption_bbox": [73, 633, 408, 729]}], "295": [{"image_id": 0, "file_name": "295_00.png", "page": 1, "dpi": 300, "bbox": [424, 86, 774, 613], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Flame Dataset (a) Original Rendering (b) with occlusion shading. We see that having ambient occlusion does not improve ordinal depth perception in this type of images. (c) shows the bonsai dataset with well defined surfaces. We can see that applying direc- tional occlusion shading (d) helps with depth perception in this case. property to another. This can be further broken down into relative and ordinal. \u201cRelative descriptions relate one perceived geomet- ric property to another (e.g., point a is twice as far away as point b). Ordinal descriptions are a special case of relative measure in which the sign, but not the magnitude, of the relations is all that is represented.\u201d [29]. ", "caption_bbox": [440, 612, 776, 767]}, {"image_id": 1, "file_name": "295_01.png", "page": 3, "dpi": 300, "bbox": [73, 537, 407, 929], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Lens Setup, (b) Circle of Confusion", "caption_bbox": [122, 930, 360, 943]}, {"image_id": 2, "file_name": "295_02.png", "page": 3, "dpi": 300, "bbox": [439, 75, 774, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Geometric setup of the DVR implementation of DoF(image courtesy of Mathias Schott [26]) ", "caption_bbox": [440, 238, 776, 264]}, {"image_id": 3, "file_name": "295_03.png", "page": 3, "dpi": 300, "bbox": [439, 413, 774, 593], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Backpack displayed within Psychopy. The features to choose from have been circled. (b) Side view of the same dataset (focus plane shown as dashed line) not shown in the experiment. We can see that the features are quite far apart. ", "caption_bbox": [440, 593, 776, 646]}, {"image_id": 4, "file_name": "295_04.png", "page": 4, "dpi": 300, "bbox": [73, 75, 777, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 4: Images description", "caption_bbox": [539, 243, 676, 256]}, {"image_id": 5, "file_name": "295_05.png", "page": 5, "dpi": 300, "bbox": [440, 75, 773, 503], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) Average correctness for the different conditions (with static images) of the experiment with standard error. (b) Average response time for the different datasets and conditions (with static images) of the experiment with standard error. ", "caption_bbox": [440, 504, 776, 556]}, {"image_id": 6, "file_name": "295_06.png", "page": 6, "dpi": 300, "bbox": [439, 74, 773, 453], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) Average correctness for the different datasets, including static and dynamic (b) Mean response time taken for the different datasets and conditions. Note: the 0 value for the flame dataset for Perspective DoF Back indicates that all answers were wrong. ", "caption_bbox": [440, 452, 776, 504]}, {"image_id": 7, "file_name": "295_07.png", "page": 7, "dpi": 300, "bbox": [440, 347, 773, 531], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Average correctness for the different datasets. The datasets from left to right shows the ordering in which the videos were shown to the participants. ", "caption_bbox": [440, 530, 776, 569]}, {"image_id": 8, "file_name": "295_08.png", "page": 7, "dpi": 300, "bbox": [439, 220, 774, 334], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Average correctness for the different datasets.", "caption_bbox": [470, 333, 745, 346]}, {"image_id": 9, "file_name": "295_09.png", "page": 7, "dpi": 300, "bbox": [73, 75, 777, 192], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Tracking examples: (a) flame, (b) backpack, (c) aneurism, (d) bonsai & (e) Richtmyer-Meshkov instability where the white and black dots represent gaze for all the users. ", "caption_bbox": [73, 193, 776, 219]}], "296": [{"image_id": 0, "file_name": "296_00.png", "page": 1, "dpi": 300, "bbox": [87, 86, 762, 407], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The user interface and the work flow of the system implementing our proposed method. Four closely linked views are shown and labeled, namely: (1) multi-panel view, (2) volume rendering view, (3) projection view and (4) high-dimensional transfer function view. Three stages: (A) data probing, (B) qualitative analysis and (C) optional feature refinement comprise our work flow. With the proposed method and user interface, domain users are able to explore and extract meaningful features in highly complex multivariate dataset, e.g. the 3D seismic survey shown above. ", "caption_bbox": [73, 418, 775, 487]}, {"image_id": 1, "file_name": "296_01.png", "page": 3, "dpi": 300, "bbox": [185, 556, 298, 608], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Generating a PCP from a joint histogram.", "caption_bbox": [110, 619, 371, 632]}, {"image_id": 2, "file_name": "296_02.png", "page": 3, "dpi": 300, "bbox": [506, 524, 711, 667], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The user draws on a salt dome (stroke shown in light blue) over the fifth attribute in the panel view resulting in the dark blue region of selection. ", "caption_bbox": [440, 678, 775, 719]}, {"image_id": 3, "file_name": "296_03.png", "page": 4, "dpi": 300, "bbox": [116, 74, 367, 154], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: User selected sample points (shown in green) over a joint histogram. TF widget generated from the samples as (a) convex hull and (b) KDE. In (c): a point cloud (left) and its KDE result color coded with a \u2019jet\u2019 color map. ", "caption_bbox": [73, 172, 408, 227]}, {"image_id": 4, "file_name": "296_04.png", "page": 5, "dpi": 300, "bbox": [503, 73, 714, 159], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Feature refinement tools: (a) 3D brush, (b) 3D lasso and (c) 2D brush. ", "caption_bbox": [440, 177, 775, 204]}, {"image_id": 5, "file_name": "296_05.png", "page": 6, "dpi": 300, "bbox": [484, 612, 732, 842], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The extracted features shown in (a) the top view and (b) the bottom view. Seen in (c) is the corresponding projection view with automated Gaussian TFs that produce the classification result. ", "caption_bbox": [440, 860, 775, 901]}, {"image_id": 6, "file_name": "296_06.png", "page": 6, "dpi": 300, "bbox": [139, 647, 344, 836], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The HDTF editor. Note that the first attribute, seismic amplitude, is locked. ", "caption_bbox": [73, 847, 408, 874]}, {"image_id": 7, "file_name": "296_07.png", "page": 7, "dpi": 300, "bbox": [472, 440, 744, 809], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Refined features shown in the middle column with the user\u2019s selection of regions of interest shown in the left column, and their TFs shown to the right. Note that the color of the refined features are independent of their TF colors. ", "caption_bbox": [440, 826, 775, 881]}, {"image_id": 8, "file_name": "296_08.png", "page": 7, "dpi": 300, "bbox": [173, 577, 311, 762], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Extracted geological features: a shallow channel com- plex in red, a salt dome shown in yellow, a deeper channel shown in purple and the largest fault in green. ", "caption_bbox": [73, 778, 408, 819]}], "297": [{"image_id": 0, "file_name": "297_00.png", "page": 1, "dpi": 300, "bbox": [75, 86, 774, 534], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A CT scan of a hand explored and visualized using our Local WYSIWYG Volume Visualization System. (a) The initial rendering of the raw data; (b) the dense outer part of the volume removed with eraser tool; (c) the vessels are painted with different colors; (d) the bones and the skin are painted with colors; (e) the rendering style of a metacarpal is transferred from another bone by sketching; (f) the brightness of the bones in the previous operations are adjusted by painting; (g) the vessels are selected and moved to create a ghost view with annotations. ", "caption_bbox": [73, 534, 775, 586]}, {"image_id": 1, "file_name": "297_01.png", "page": 3, "dpi": 300, "bbox": [440, 74, 776, 666], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The system pipeline with both data pre-processing and run-time algorithms. ", "caption_bbox": [440, 670, 775, 696]}, {"image_id": 2, "file_name": "297_02.png", "page": 4, "dpi": 300, "bbox": [73, 74, 411, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Three different operation scopes: painting scope is (a) lo- cal; (b) group; and (c) global. ", "caption_bbox": [73, 480, 408, 506]}, {"image_id": 3, "file_name": "297_03.png", "page": 4, "dpi": 300, "bbox": [445, 77, 772, 397], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Drilling down and rolling up. In \u2780, a selected region is extracted for drilling down; in \u2781, the focused region is painted with a different color; in \u2782, the focused region is restored to the original view by rolling up. ", "caption_bbox": [440, 402, 775, 454]}, {"image_id": 4, "file_name": "297_04.png", "page": 4, "dpi": 300, "bbox": [76, 347, 408, 475], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: The user interaction tool set of the proposed Local WYSI- WYG Volume Visualization system. ", "caption_bbox": [440, 917, 775, 943]}, {"image_id": 5, "file_name": "297_05.png", "page": 5, "dpi": 300, "bbox": [439, 74, 776, 172], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Stroke types: (a) painting strokes (invisible); (b) ordi- nary strokes; (c) functional strokes; (d) hybrid strokes. In (d), the smoothed strokes (in dashed lines) are derived from hybrid strokes. ", "caption_bbox": [440, 173, 775, 212]}, {"image_id": 6, "file_name": "297_06.png", "page": 6, "dpi": 300, "bbox": [440, 190, 775, 514], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The rendering results for the CT chest data with a ghost view of the lungs. A global eraser operation is applied first to remove the outer part. Then the colors of different structures in the volume are changed with a colorization tool. To reveal detailed features of the lungs, a ghost view is created in the last stage. ", "caption_bbox": [440, 513, 775, 578]}, {"image_id": 7, "file_name": "297_07.png", "page": 7, "dpi": 300, "bbox": [87, 76, 391, 193], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Comparison to previous work which supports 2D interaction on volume rendered images. The plus means that the method is ca- pable of applying a certain kind of functions, while minus means that it does not apply. Plus in brackets indicates that the corresponding technique has the potential to support the certain function. ", "caption_bbox": [440, 211, 775, 276]}], "298": [{"image_id": 0, "file_name": "298_00.png", "page": 1, "dpi": 300, "bbox": [108, 86, 742, 451], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A summary graph (middle) constructed from four graphs of molecules; colors indicate which input graphs contain a given feature with gray indicating the feature is common to all graphs. ", "caption_bbox": [73, 462, 775, 489]}, {"image_id": 1, "file_name": "298_01.png", "page": 3, "dpi": 300, "bbox": [73, 77, 775, 215], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A comparison of graph-matching algorithms run on a pair of graphs (a); mismatched nodes and edges in (b) and (c) are highlighted. A node-only matching (b) errs because it cannot differentiate between similar pairs of nodes (e.g., the Bob/Robert nodes). A matching that considers neighborhoods improves the result (c), but can still have issues when neighborhoods are similar (e.g., the Cynthia/Cindy nodes). Similarity Flooding takes global structure into account, leading to an even better result (d). ", "caption_bbox": [73, 218, 775, 273]}, {"image_id": 2, "file_name": "298_02.png", "page": 4, "dpi": 300, "bbox": [441, 76, 779, 387], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A summary of eight graphs representing visualization workflows generated by different students for a specific homework problem. A single student\u2019s work is highlighted in the context of the summary allowing it to be compared with the others as a whole. ", "caption_bbox": [440, 399, 775, 454]}, {"image_id": 3, "file_name": "298_03.png", "page": 5, "dpi": 300, "bbox": [117, 77, 734, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A piece of a molecular summary graph that shows how users can leverage edit operations to transform one summary into another via two break operations, (a) to (b), followed by two join operations, (b) to (c). ", "caption_bbox": [73, 240, 775, 267]}, {"image_id": 4, "file_name": "298_04.png", "page": 6, "dpi": 300, "bbox": [86, 77, 764, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A summary graph of enzyme relation graphs from the citric acid cycle for eight organisms. Showing all colors (a) can be distracting. A user can interactively investigate a particular relationship, like that between E. coli and the castor bean, by either highlighting specific differences in the context of the summary (b) or hiding nodes and edges that do not exist in a selected subset (c). ", "caption_bbox": [73, 348, 775, 389]}, {"image_id": 5, "file_name": "298_05.png", "page": 6, "dpi": 300, "bbox": [100, 794, 382, 972], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The interface allows users to control summarization, ad- just the color threshold, and toggle the display of individual graphs. ", "caption_bbox": [73, 972, 408, 999]}, {"image_id": 6, "file_name": "298_06.png", "page": 7, "dpi": 300, "bbox": [74, 79, 776, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: One of the questions in the user study asked participants to modify a given summary (left) constructed using the same graphs as in Figure 1 to create an informative visualization. Two results, (middle) and (right), show how user preferences vary. ", "caption_bbox": [73, 295, 775, 322]}], "299": [{"image_id": 0, "file_name": "299_00.png", "page": 3, "dpi": 300, "bbox": [103, 810, 374, 901], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A query graph (the subgraph in box) overlaid on the local graph shown in Fig 1. The query graph contains three nodes (high- lighted with yellow circles), two meta edges, and one query edge (represented in yellow dashed line). This query is to find Jim\u2019s friends who share the same zodiac with himself. The query is constructed on the GUI by adding the query edge, and then assigning the type zodiac to the edge. The system automatically detects nodes in the query, and highlights them. ", "caption_bbox": [73, 905, 408, 1010]}, {"image_id": 1, "file_name": "299_01.png", "page": 3, "dpi": 300, "bbox": [98, 133, 383, 231], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A view of the local graph in GraphCharter with two entity nodes [Jim and Karen in circles], one literal node [Columbia Col- lege Chicago in rectangle], and two meta nodes [person(117) and zodiac(12) in octagons]. Nodes and edges are color-encoded with their type information. ", "caption_bbox": [73, 231, 408, 296]}, {"image_id": 2, "file_name": "299_02.png", "page": 3, "dpi": 300, "bbox": [457, 542, 759, 769], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Usage scenarios for query", "caption_bbox": [518, 770, 697, 783]}, {"image_id": 3, "file_name": "299_03.png", "page": 4, "dpi": 300, "bbox": [73, 74, 777, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Query results presentation: the result panels are semi-transparent to allow users to see the graph layout with query results. They support \u201cRefine\u201d to further filter results in the list, and \u201cSort\u201d to sort all results based on the values in the current panel. The numbers under the text box, e.g. 25(1)/25(1), means that there are 25 tuples/rows in the result, and 1 distinct value for this particular variable. The pair after the slash is the numbers from the original query result, while the pair before the slash is when the refining conditions are applied. ", "caption_bbox": [73, 249, 775, 301]}, {"image_id": 4, "file_name": "299_04.png", "page": 5, "dpi": 300, "bbox": [77, 74, 773, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Interactions for graph browsing: the floating panels are \u201cattached\u201d to the node and can be opened and closed on-demand. They support interactions such as \u201cFind\u201d to look up data in the graph, and \u201cRefine\u201d to further filter the results in the list. The numbers 117/117 in (d) means how many entries/rows are in the result panel. The number after the slash is calculated from the original query result, and the other number is after applying the refinement. The left column in the summary panel shows the property name with the property ID, e.g. /p//education. ", "caption_bbox": [73, 242, 775, 294]}, {"image_id": 5, "file_name": "299_05.png", "page": 5, "dpi": 300, "bbox": [466, 609, 751, 694], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A few Academy Award categories and George Clooney", "caption_bbox": [448, 693, 767, 706]}, {"image_id": 6, "file_name": "299_06.png", "page": 6, "dpi": 300, "bbox": [439, 350, 780, 763], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Query for the categories of Academy Awards that Steven Soderbergh\u2019s movies have been nominated for ", "caption_bbox": [440, 765, 775, 791]}, {"image_id": 7, "file_name": "299_07.png", "page": 6, "dpi": 300, "bbox": [73, 233, 414, 545], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Best Leading Actor and Best Supporting Actor nominees who has been nominated for other Academy Award categories, using two disjoint edges to exclude the best actor awards. ", "caption_bbox": [73, 547, 409, 586]}, {"image_id": 8, "file_name": "299_08.png", "page": 6, "dpi": 300, "bbox": [133, 779, 348, 956], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Summarized information of Matt Damon", "caption_bbox": [118, 955, 363, 968]}, {"image_id": 9, "file_name": "299_09.png", "page": 6, "dpi": 300, "bbox": [464, 73, 749, 192], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Query for the directors of Matt Damon\u2019s movies", "caption_bbox": [464, 191, 751, 204]}, {"image_id": 10, "file_name": "299_10.png", "page": 6, "dpi": 300, "bbox": [110, 73, 374, 204], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: George Clooney\u2019s nominations for Academy Awards", "caption_bbox": [89, 203, 393, 216]}, {"image_id": 11, "file_name": "299_11.png", "page": 7, "dpi": 300, "bbox": [439, 627, 780, 800], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: An exemplar local graph after 16 tasks in the user study", "caption_bbox": [443, 799, 771, 812]}, {"image_id": 12, "file_name": "299_12.png", "page": 7, "dpi": 300, "bbox": [80, 74, 400, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Auto-expansion on Steven Soderbergh\u2019s movies", "caption_bbox": [95, 230, 386, 243]}], "30": [{"image_id": 0, "file_name": "30_00.png", "page": 3, "dpi": 300, "bbox": [92, 53, 741, 391], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A worm-view visualisation showing the movements for the 391 largest fund managers over a 12 month period. ", "caption_bbox": [83, 404, 749, 432]}, {"image_id": 1, "file_name": "30_01.png", "page": 4, "dpi": 300, "bbox": [92, 72, 741, 404], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A zoomed view of the highlighted portion of Figure 1. 8 months are shown.", "caption_bbox": [155, 417, 676, 431]}, {"image_id": 2, "file_name": "30_02.png", "page": 4, "dpi": 300, "bbox": [94, 501, 741, 977], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A 3D area chart showing the fluctuations in share price in a particular portfolio over 12 months. Each of the columns is a different stock, the depth axis is time (most recent at the front) and the vertical (labelled axis) shows share price in GBP (British Pounds Stirling). ", "caption_bbox": [83, 1009, 749, 1051]}, {"image_id": 3, "file_name": "30_03.png", "page": 5, "dpi": 300, "bbox": [93, 74, 741, 502], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A 3D area chart showing the changing count of shares in the portfolio over 12 months. The axes are as in Figure 3 except the vertical axis which shows count of shares ", "caption_bbox": [83, 534, 749, 562]}, {"image_id": 4, "file_name": "30_04.png", "page": 5, "dpi": 300, "bbox": [86, 689, 402, 900], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: This chart shows the net effect on the total value of a portfolio of the share price fluctu- ations, shown in Figure 3, and the fund manager\u2019s re-weighting, shown in Figure 4. ", "caption_bbox": [83, 932, 405, 988]}, {"image_id": 5, "file_name": "30_05.png", "page": 6, "dpi": 300, "bbox": [103, 62, 383, 367], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The stratified graph from 8 viewed from above. ", "caption_bbox": [83, 388, 405, 416]}, {"image_id": 6, "file_name": "30_06.png", "page": 7, "dpi": 300, "bbox": [109, 60, 737, 472], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A stratified graph representing the movements in the portfolio shown in figures 3, 4 and 5, laid out using a basic force-directed algorithm. The thresholds are \u03c4e = \u00b15% and \u03c4v = \u00a35, 000. ", "caption_bbox": [83, 489, 749, 518]}, {"image_id": 7, "file_name": "30_07.png", "page": 8, "dpi": 300, "bbox": [106, 295, 727, 820], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The stratified graph from 6 arranged using the Sugiyama algorithm.", "caption_bbox": [178, 833, 654, 847]}, {"image_id": 8, "file_name": "30_08.png", "page": 9, "dpi": 300, "bbox": [112, 785, 717, 953], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The stratified graph from 8 viewed from the side to better show the strata.", "caption_bbox": [157, 983, 675, 997]}, {"image_id": 9, "file_name": "30_09.png", "page": 9, "dpi": 300, "bbox": [109, 130, 722, 558], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Another stratified graph showing the movements in the portfolio from Figure 7 in lower detail. In this figure fewer edges are visible since \u03c4e \u00b1 has been raised to 8%. ", "caption_bbox": [83, 578, 749, 607]}], "300": [{"image_id": 0, "file_name": "300_00.png", "page": 4, "dpi": 300, "bbox": [51, 68, 801, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Streaming visualization for 6-days US airline flight dataset (Sec. 3.2)", "caption_bbox": [231, 359, 614, 371]}, {"image_id": 1, "file_name": "300_01.png", "page": 4, "dpi": 300, "bbox": [98, 393, 379, 664], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Interpolation for graph sequence visualization", "caption_bbox": [103, 677, 375, 689]}, {"image_id": 2, "file_name": "300_02.png", "page": 6, "dpi": 300, "bbox": [41, 74, 812, 312], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Sequence-based visualization for clones in Firefox (8 frames). Top row: HEB bundling. Bottom row: KDEEB bundling (Sec. 4.2)", "caption_bbox": [87, 330, 758, 342]}, {"image_id": 3, "file_name": "300_03.png", "page": 6, "dpi": 300, "bbox": [41, 357, 812, 601], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Sequence animation \u2013 Wicket call graphs (8 frames around release 1.4.18). Top: SBEB bundling. Bottom: KDEEB bundling (Sec. 4.2)", "caption_bbox": [71, 619, 775, 631]}, {"image_id": 4, "file_name": "300_04.png", "page": 7, "dpi": 300, "bbox": [137, 74, 708, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Streaming visualization of graph sequence (3 frames around revision 1.5.0, Wicket software dataset)", "caption_bbox": [153, 435, 693, 447]}], "301": [{"image_id": 0, "file_name": "301_00.png", "page": 1, "dpi": 300, "bbox": [111, 86, 746, 470], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Massive Sequence Views as part of a multiple coordinated view application applied to real-world dynamic network data; a financial transaction data set containing 302 accounts and 997 transactions. Each ordering provides a unique view on temporal and structural aspects of the data: the Combined criteria (j) and Minimize standard deviation (h) views reveal several strong communities. The Activity view (e) clearly shows nodes only active at the beginning and others only at the end. Outliers are emphasized by the Minimize edge length view (f). More detail on the different reordered views is given in Section 5. ", "caption_bbox": [73, 484, 775, 549]}, {"image_id": 1, "file_name": "301_01.png", "page": 2, "dpi": 300, "bbox": [79, 76, 764, 174], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Different visualizations of dynamic network data. Note that there are no overlapping edges in the minimal edge length ordering (e).", "caption_bbox": [81, 186, 768, 199]}, {"image_id": 2, "file_name": "301_02.png", "page": 3, "dpi": 300, "bbox": [447, 150, 771, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Gestalt principles applied to MSV.", "caption_bbox": [499, 119, 716, 132]}, {"image_id": 3, "file_name": "301_03.png", "page": 3, "dpi": 300, "bbox": [441, 386, 777, 477], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Temporal and structural properties of a dynamic network in the context of the MSV. ", "caption_bbox": [440, 347, 775, 373]}, {"image_id": 4, "file_name": "301_04.png", "page": 3, "dpi": 300, "bbox": [441, 478, 777, 665], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Different color encodings for the MSV edges.", "caption_bbox": [472, 680, 743, 693]}, {"image_id": 5, "file_name": "301_05.png", "page": 5, "dpi": 300, "bbox": [456, 79, 751, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Blocks E(a, b) and E(c, d) with vertical overlap Cv , horizontal overlap Ch , total overlap C, and padding parameter P. ", "caption_bbox": [440, 213, 775, 240]}, {"image_id": 6, "file_name": "301_06.png", "page": 6, "dpi": 300, "bbox": [79, 896, 771, 970], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Standard deviation of edge length \u00b5 is minimized, next the block overlap is minimized with constraint to stay within an 1 + \u03b5 fraction of \u00b5 . Edges are colored according to size of edge sets (same colormap as in Figure 5(c)). ", "caption_bbox": [73, 974, 775, 1000]}, {"image_id": 7, "file_name": "301_07.png", "page": 6, "dpi": 300, "bbox": [440, 76, 775, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Minimization of block overlap (top), standard deviation (bot- tom) and combined criteria (middle) for synthetic data sets. Edges are colored according to edge set size. ", "caption_bbox": [440, 292, 775, 331]}, {"image_id": 8, "file_name": "301_08.png", "page": 7, "dpi": 300, "bbox": [73, 74, 778, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Enron email data set, 151 nodes and 21374 edges horizontally positioned based on transaction time.", "caption_bbox": [153, 273, 696, 286]}], "302": [{"image_id": 0, "file_name": "302_00.png", "page": 1, "dpi": 300, "bbox": [76, 86, 774, 344], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The states mapped onto the stars of the US Flag using the minimum L1 -distance matching under translation. The two white stars are reserved for Alaska and Hawaii. ", "caption_bbox": [73, 358, 775, 384]}, {"image_id": 1, "file_name": "302_01.png", "page": 2, "dpi": 300, "bbox": [81, 74, 403, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Election results from the Netherlands in a grid map.", "caption_bbox": [90, 309, 391, 321]}, {"image_id": 2, "file_name": "302_02.png", "page": 4, "dpi": 300, "bbox": [121, 74, 363, 190], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: We can improve a matching between A (grey) and B (white) indicated by the dashed lines by x-aligning the point sets (the dotted lines). ", "caption_bbox": [73, 206, 408, 245]}, {"image_id": 3, "file_name": "302_03.png", "page": 4, "dpi": 300, "bbox": [450, 74, 766, 176], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) The areas in the plane corresponding to each direc- tion. (b) The directional relation between a1 and a2 is not preserved, (a1 , a2 ) is an x-inversion. ", "caption_bbox": [440, 191, 775, 231]}, {"image_id": 4, "file_name": "302_04.png", "page": 6, "dpi": 300, "bbox": [73, 74, 777, 419], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: United States.", "caption_bbox": [367, 597, 481, 609]}, {"image_id": 5, "file_name": "302_05.png", "page": 7, "dpi": 300, "bbox": [95, 74, 755, 523], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: France.", "caption_bbox": [383, 700, 464, 712]}, {"image_id": 6, "file_name": "302_06.png", "page": 8, "dpi": 300, "bbox": [123, 74, 727, 183], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: London boroughs.", "caption_bbox": [357, 346, 490, 358]}], "303": [{"image_id": 0, "file_name": "303_00.png", "page": 1, "dpi": 300, "bbox": [107, 86, 743, 413], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Side-by-side comparison between an ordinary perspective view (left) and its optimally distorted version with our approach (right). Note that we can successfully avoid the occlusions of important route to the destination (drawn in orange) while accentuating the 3D appearance of the landmark buildings. (Kikuna, Yokohama, Japan.) ", "caption_bbox": [73, 429, 775, 468]}, {"image_id": 1, "file_name": "303_01.png", "page": 2, "dpi": 300, "bbox": [84, 74, 399, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An example of a hand-drawn illustrative map of Tokyo, Japan (courtesy of WORKS-PRESS CO., LTD.). ", "caption_bbox": [73, 266, 408, 292]}, {"image_id": 2, "file_name": "303_02.png", "page": 2, "dpi": 300, "bbox": [451, 74, 766, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Five design criteria.", "caption_bbox": [535, 279, 680, 292]}, {"image_id": 3, "file_name": "303_03.png", "page": 3, "dpi": 300, "bbox": [454, 225, 762, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Relative position constraint. (a) Neighbor edges that sur- round the vertex v. (b) The vertex v and its neighbor edge pq. ", "caption_bbox": [440, 370, 775, 396]}, {"image_id": 4, "file_name": "303_04.png", "page": 3, "dpi": 300, "bbox": [506, 74, 711, 172], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Fixed orientation constraint. The orientation of the edge pq is fixed while its scale ratio changes. ", "caption_bbox": [440, 187, 775, 213]}, {"image_id": 5, "file_name": "303_05.png", "page": 4, "dpi": 300, "bbox": [454, 74, 762, 204], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Occlusion avoidance constraints. (a) A constraint of the first type on a building vertex v and a road edge pq. (b) A constraint of the second type on a road vertex v and a building edge pq. ", "caption_bbox": [440, 216, 775, 255]}, {"image_id": 6, "file_name": "303_06.png", "page": 5, "dpi": 300, "bbox": [444, 74, 772, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Perspective views of a 3D urban model optimized based on (a) orthographic projection and (b) perspective projection. (Kuga- hara, Tokyo, Japan.) ", "caption_bbox": [440, 226, 775, 265]}, {"image_id": 7, "file_name": "303_07.png", "page": 7, "dpi": 300, "bbox": [165, 791, 682, 985], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Additional space for annotating roads has been introduced into a 3D urban map. An ordinary perspective image (left) and its optimized version (right). Note that we set Wr = 50 in this case. (Endo-machi, Kawasaki, Japan.) ", "caption_bbox": [73, 992, 775, 1019]}, {"image_id": 8, "file_name": "303_08.png", "page": 7, "dpi": 300, "bbox": [165, 551, 682, 745], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: An optimized layout of a 3D urban map while landmark buildings are emphasized. An ordinary perspective image (left) and its optimized version (right). (Okurayama, Yokohama, Japan.) ", "caption_bbox": [73, 752, 775, 778]}, {"image_id": 9, "file_name": "303_09.png", "page": 7, "dpi": 300, "bbox": [165, 312, 682, 506], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: An optimized layout of a 3D urban map where all the routes are selected as landmarks. An ordinary perspective image (left) and its optimized version (right). (Nishi-Kamata, Tokyo, Japan.) ", "caption_bbox": [73, 513, 775, 539]}, {"image_id": 10, "file_name": "303_10.png", "page": 7, "dpi": 300, "bbox": [165, 73, 682, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A complicated 3D urban environment where a sharply curved route is disoccluded. An ordinary perspective image (left) and its optimized version (right). (Suwazaka, Yokohama, Japan.) ", "caption_bbox": [73, 273, 775, 299]}, {"image_id": 11, "file_name": "303_11.png", "page": 8, "dpi": 300, "bbox": [76, 307, 404, 448], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Comparisons between eye-gaze distributions between the (a) ordinary perspective view and (b) its optimized layout where a landmark route is disoccluded. The image opacity is reduced ac- cording to the length of the eye-gaze fixation time. (Matsubacho, Chiba, Japan.) ", "caption_bbox": [73, 453, 408, 518]}, {"image_id": 12, "file_name": "303_12.png", "page": 8, "dpi": 300, "bbox": [100, 74, 746, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Optimized 3D urban layouts with different weight assignments. (a) An ordinary perspective image. Disoccluding the landmark route when (b) Wd = 1,Wh = 1,Wo = 50 and (c) Wd = 1,Wh = 200,Wo = 50. The angle of elevation is 20 degrees in this case. (Asada, Kawasaki, Japan.) ", "caption_bbox": [73, 256, 775, 283]}], "304": [{"image_id": 0, "file_name": "304_00.png", "page": 1, "dpi": 300, "bbox": [110, 186, 742, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Left: Multiple entity selection showing parts that failed along with wiper and window components. Middle: Exploring issues in the front of the vehicle. Right: A potential usage scenario for building maintenance. ", "caption_bbox": [73, 319, 775, 344]}, {"image_id": 1, "file_name": "304_01.png", "page": 2, "dpi": 300, "bbox": [80, 76, 393, 210], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A subset of the component keywords hierarchy. Words in square brackets are synonyms. ", "caption_bbox": [73, 221, 408, 246]}, {"image_id": 2, "file_name": "304_02.png", "page": 3, "dpi": 300, "bbox": [82, 76, 766, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The Descriptive NPR visualization in use. The lens widget is used to solicit more details in the front portion of the vehicle. The time frame is set to include the first four months of the year 2000. The document panel at right shows some texts matching the filter query. ", "caption_bbox": [73, 357, 775, 382]}, {"image_id": 3, "file_name": "304_03.png", "page": 3, "dpi": 300, "bbox": [450, 387, 770, 530], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Design options using hues and lighting effects. Clockwise from top-left: Single-hue, solid colour; multi-hue, solid colour; multi- hue, simulated lighting (used); single-hue, simulated lighting. ", "caption_bbox": [440, 540, 775, 578]}, {"image_id": 4, "file_name": "304_04.png", "page": 4, "dpi": 300, "bbox": [76, 76, 403, 184], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Lens Widget. Left: No depth plane specified. Right: Active depth plane cutting into the model. The engine and part of the radiator are in front of the plane, thus rendered as outlines. ", "caption_bbox": [73, 193, 408, 231]}, {"image_id": 5, "file_name": "304_05.png", "page": 5, "dpi": 300, "bbox": [78, 75, 404, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Heatmap widgets for several entities. Left to right: Component-max, Global-max and Month-max perspectives. ", "caption_bbox": [73, 239, 408, 264]}, {"image_id": 6, "file_name": "304_06.png", "page": 6, "dpi": 300, "bbox": [73, 290, 410, 367], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Aggregation mode. Left: disabled. Right: enabled.", "caption_bbox": [90, 377, 391, 389]}, {"image_id": 7, "file_name": "304_07.png", "page": 6, "dpi": 300, "bbox": [439, 74, 777, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A participant using the lens to examine the vehicle.", "caption_bbox": [455, 300, 759, 312]}, {"image_id": 8, "file_name": "304_08.png", "page": 6, "dpi": 300, "bbox": [86, 76, 378, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: In the comparison view, the component outline indicates whether vehicle one (pink) or vehicle two (green) had a higher rate of failure. ", "caption_bbox": [73, 239, 408, 277]}, {"image_id": 9, "file_name": "304_09.png", "page": 7, "dpi": 300, "bbox": [439, 76, 774, 177], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Widget usage for the task of comparing two vehicles.", "caption_bbox": [448, 188, 766, 200]}], "305": [{"image_id": 0, "file_name": "305_00.png", "page": 1, "dpi": 300, "bbox": [87, 86, 753, 558], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The results of the 2004 US presidential election. In red states the majority of the vote was for the republican (G. W. Bush) and in blue states the majority was for the democrat (J. Kerry). Note that the circular-arc cartogram makes it easy to see that most blue states are densly populated (cloud shapes), while the red states are more rural. Exceptions such as Oregon (blue but not densly populated) and North Carolina (red but dense) stand out. ", "caption_bbox": [73, 571, 776, 626]}, {"image_id": 1, "file_name": "305_01.png", "page": 3, "dpi": 300, "bbox": [462, 435, 749, 545], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A planar rectilinear drawing of a P LANAR M ONOTONE 3-S AT instance. ", "caption_bbox": [440, 556, 775, 583]}, {"image_id": 2, "file_name": "305_02.png", "page": 3, "dpi": 300, "bbox": [440, 780, 777, 872], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The three possibilities to realize a circular-arc triangle with area 0. ", "caption_bbox": [439, 884, 775, 911]}, {"image_id": 3, "file_name": "305_03.png", "page": 4, "dpi": 300, "bbox": [96, 250, 387, 778], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Variable gadget. The central decision rectangle is shown in purple, connector rectangles in green, 0-area triangles in blue and the remaining rectangles in brown. ", "caption_bbox": [73, 790, 408, 831]}, {"image_id": 4, "file_name": "305_04.png", "page": 5, "dpi": 300, "bbox": [107, 74, 377, 637], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Cross-shaped clause gadget with three literal gadgets.", "caption_bbox": [81, 650, 399, 663]}, {"image_id": 5, "file_name": "305_05.png", "page": 6, "dpi": 300, "bbox": [73, 573, 410, 947], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Cartogram of the population in Italy; the first number indi- cates the success rate, the second number the relative cartographic error. ", "caption_bbox": [73, 958, 410, 999]}, {"image_id": 6, "file_name": "305_06.png", "page": 6, "dpi": 300, "bbox": [440, 74, 777, 447], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Cartogram of the agricultural use area in Italy; the first number indicates the success rate, the second number the relative cartographic error. ", "caption_bbox": [440, 458, 775, 499]}, {"image_id": 7, "file_name": "305_07.png", "page": 6, "dpi": 300, "bbox": [73, 74, 411, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The straight skeleton of two adjacent polygons and the maximally realizable circular-arcs within the safe bending limits of each edge. ", "caption_bbox": [73, 292, 408, 333]}, {"image_id": 8, "file_name": "305_08.png", "page": 7, "dpi": 300, "bbox": [73, 271, 410, 642], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Cartogram of the population in the Netherlands.", "caption_bbox": [96, 652, 386, 665]}, {"image_id": 9, "file_name": "305_09.png", "page": 7, "dpi": 300, "bbox": [439, 74, 777, 495], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Cartogram of the length of the main roads in Europe.", "caption_bbox": [446, 506, 768, 519]}], "306": [], "307": [{"image_id": 0, "file_name": "307_00.png", "page": 1, "dpi": 300, "bbox": [445, 481, 758, 651], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Pairwise comparison for two brain datasets. From left to right: (a) the 3D \ufb01ber models; (b) 2D embedded points from our ap- proach; (c) the kernel density estimation maps based on (b) using the Rainbow color map; (d) the contoured KDE maps (12 levels) based on (c). ", "caption_bbox": [434, 666, 756, 730]}, {"image_id": 1, "file_name": "307_01.png", "page": 2, "dpi": 300, "bbox": [438, 351, 756, 570], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Results for six \ufb01ber models from different \ufb01ber tracking parameters. ", "caption_bbox": [435, 585, 757, 611]}, {"image_id": 2, "file_name": "307_02.png", "page": 2, "dpi": 300, "bbox": [93, 366, 411, 754], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The pipeline of our method. The input is a set of \ufb01ber models, and the output is a set of 2D signature maps. ", "caption_bbox": [90, 767, 412, 793]}], "308": [{"image_id": 0, "file_name": "308_00.png", "page": 1, "dpi": 300, "bbox": [424, 60, 737, 435], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example of visualization by scatterplots. X-axis denotes time, Y-axis denotes item code(ex.750 = \u201dgasoline\u201d), and color de- notes fraud types. It shows the distribution of frauds on Saturday. ", "caption_bbox": [434, 448, 756, 487]}, {"image_id": 1, "file_name": "308_01.png", "page": 2, "dpi": 300, "bbox": [507, 310, 684, 573], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (Upper)Illustration of the space we recorded the movie. (Lower)Clustering results of the all trajectories. ", "caption_bbox": [434, 586, 756, 612]}, {"image_id": 2, "file_name": "308_02.png", "page": 2, "dpi": 300, "bbox": [462, 650, 729, 781], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: ThemeRiver-like representation of the population on Fri- days. It decreased on December 31 and February 11 because these days were holidays, and on March 18 because the day was in the next week of the big earthquake in the east part of Japan. ", "caption_bbox": [434, 793, 756, 844]}, {"image_id": 3, "file_name": "308_03.png", "page": 2, "dpi": 300, "bbox": [120, 99, 382, 336], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Example of visualization by scatterplot-like histogram. X- axis denotes time, Y-axis denotes shop ID, and color denotes fraud types. ", "caption_bbox": [90, 350, 412, 389]}], "309": [{"image_id": 0, "file_name": "309_00.png", "page": 1, "dpi": 300, "bbox": [435, 317, 760, 515], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 1 Exploration of the requirements from our society and", "caption_bbox": [447, 516, 758, 529]}, {"image_id": 1, "file_name": "309_01.png", "page": 2, "dpi": 300, "bbox": [90, 380, 427, 1094], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 2 shows a cognitive structure developed using the EGM. The upper and lower elements represent what are obtained in the ladder-up and ladder-down process, respectively. ", "caption_bbox": [90, 319, 412, 360]}], "31": [], "311": [], "312": [{"image_id": 0, "file_name": "312_00.png", "page": 1, "dpi": 300, "bbox": [411, 60, 759, 967], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization result of SST (Sea Surface Temperature)", "caption_bbox": [441, 975, 748, 987]}, {"image_id": 1, "file_name": "312_01.png", "page": 2, "dpi": 300, "bbox": [84, 432, 761, 934], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Visualization result of the ocean currents and (b)", "caption_bbox": [98, 945, 393, 957]}], "313": [{"image_id": 0, "file_name": "313_00.png", "page": 2, "dpi": 300, "bbox": [436, 99, 758, 421], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Real Time 3D Volume Rendering of CT scans of bone affected by multiple myeloma ", "caption_bbox": [435, 434, 757, 460]}, {"image_id": 1, "file_name": "313_01.png", "page": 3, "dpi": 300, "bbox": [435, 314, 760, 457], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The typical display from Neighbourhood Scoreboards", "caption_bbox": [446, 470, 744, 483]}, {"image_id": 2, "file_name": "313_02.png", "page": 3, "dpi": 300, "bbox": [89, 100, 414, 344], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Interactive visualisations of bacteria using a touchless in- terface, projected on to a 3m hemispherical Dome at CSIRO ", "caption_bbox": [89, 357, 411, 383]}, {"image_id": 3, "file_name": "313_03.png", "page": 3, "dpi": 300, "bbox": [435, 100, 750, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Images from Human Genome Art by Humans with Gen- omes ", "caption_bbox": [435, 277, 757, 303]}, {"image_id": 4, "file_name": "313_04.png", "page": 4, "dpi": 300, "bbox": [89, 99, 411, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The InterANTARCTICA installation with three-screen video and interactive table ", "caption_bbox": [90, 354, 412, 380]}, {"image_id": 5, "file_name": "313_05.png", "page": 4, "dpi": 300, "bbox": [436, 99, 758, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The visualisation projected under the TUI objects int Reefs on the Edge ", "caption_bbox": [434, 328, 756, 354]}], "314": [{"image_id": 0, "file_name": "314_00.png", "page": 1, "dpi": 300, "bbox": [90, 60, 763, 546], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An illustration of the proposed Weibo visual analytic system. The components are (a) Dynamic Web Portal, (b) Retweet Tree View, used in both web-based interface and the expert analytic system, (c) Global Events Timeline, (d) Events Map, (e) High Dimensional Filters. (a) and (b) are used in the web-based interface. (b), (c), (d) and (e) are used in the expert analytic system. In this example, we\u2019re using the expert analytic system to inspect an event. Tweets with keyword \u201cWuMao\u201d are colored orange and tweets with higher information are colored brown. ", "caption_bbox": [90, 559, 764, 610]}, {"image_id": 1, "file_name": "314_01.png", "page": 2, "dpi": 300, "bbox": [438, 99, 752, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Three layout methods for the retweet tree view. (1) Tree layout, (2) Circular layout, (3) Sail layout. (4) Curves layout. ", "caption_bbox": [434, 340, 756, 366]}, {"image_id": 2, "file_name": "314_02.png", "page": 3, "dpi": 300, "bbox": [435, 749, 758, 907], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Left: Work\ufb02ow statistics of users. Each action is repre- sented by a node, the curves represent the interaction process, for example, we \ufb01nd a lot of users proceeded as \u201cinitialize, pan/zoom, circular layout, select keyword\u201d. Right: Transition graph between ac- tions, treating it as a markov process. ", "caption_bbox": [435, 920, 757, 984]}, {"image_id": 3, "file_name": "314_03.png", "page": 3, "dpi": 300, "bbox": [90, 709, 414, 828], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The global events timeline view. By hovering on one shar- ing label, the snapshot of that sharing pops up. ", "caption_bbox": [90, 843, 412, 869]}, {"image_id": 4, "file_name": "314_04.png", "page": 4, "dpi": 300, "bbox": [89, 97, 765, 211], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Illustration of results. (1) False aircraft news. (2) Robot accounts. (3) Snowing in Beijing. (4) \u201cStudent ask for interview of TV Star\u201d", "caption_bbox": [98, 224, 753, 237]}], "315": [{"image_id": 0, "file_name": "315_00.png", "page": 1, "dpi": 300, "bbox": [424, 1022, 766, 1094], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Video visualization diagram.", "caption_bbox": [528, 989, 711, 1001]}, {"image_id": 1, "file_name": "315_01.png", "page": 2, "dpi": 300, "bbox": [445, 207, 747, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Video structure rendering.", "caption_bbox": [533, 349, 706, 361]}, {"image_id": 2, "file_name": "315_02.png", "page": 2, "dpi": 300, "bbox": [503, 709, 739, 872], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Temporal structure expression.", "caption_bbox": [521, 885, 718, 897]}, {"image_id": 3, "file_name": "315_03.png", "page": 3, "dpi": 300, "bbox": [445, 767, 769, 970], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7 shows the rendering process of region E in Figure 6.", "caption_bbox": [454, 754, 757, 766]}, {"image_id": 4, "file_name": "315_04.png", "page": 3, "dpi": 300, "bbox": [424, 1027, 740, 1094], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Video visualization rendering process.", "caption_bbox": [504, 977, 734, 989]}, {"image_id": 5, "file_name": "315_05.png", "page": 3, "dpi": 300, "bbox": [462, 534, 743, 671], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Video visualization tool interface(Region A:", "caption_bbox": [491, 679, 747, 691]}, {"image_id": 6, "file_name": "315_06.png", "page": 3, "dpi": 300, "bbox": [459, 98, 765, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Test results of three video key frame extraction", "caption_bbox": [483, 352, 755, 364]}, {"image_id": 7, "file_name": "315_07.png", "page": 3, "dpi": 300, "bbox": [110, 672, 410, 951], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Performance comparisons of three video shot", "caption_bbox": [141, 958, 407, 970]}, {"image_id": 8, "file_name": "315_08.png", "page": 4, "dpi": 300, "bbox": [82, 854, 406, 947], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Video Visualization Methods", "caption_bbox": [172, 954, 360, 966]}, {"image_id": 9, "file_name": "315_09.png", "page": 4, "dpi": 300, "bbox": [79, 374, 413, 479], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Interaction Design", "caption_bbox": [182, 486, 321, 498]}, {"image_id": 10, "file_name": "315_10.png", "page": 4, "dpi": 300, "bbox": [152, 99, 348, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2. User Experience Statistics", "caption_bbox": [535, 99, 706, 111]}], "316": [{"image_id": 0, "file_name": "316_00.png", "page": 1, "dpi": 300, "bbox": [90, 60, 767, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An example of EmailMap. The blue color \ufb02ow depicts the event evolution in email archives of a time period, and the color tracks reveal the interaction between the email owner and his/her contacts. Notice that the names are blurred due to the privacy issue. ", "caption_bbox": [90, 407, 764, 433]}, {"image_id": 1, "file_name": "316_01.png", "page": 2, "dpi": 300, "bbox": [482, 99, 711, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The contacts are represented as curved tracks. When two tracks intersect, the participating node is encoded by concentric rings with their corresponding color keys. ", "caption_bbox": [434, 253, 756, 292]}, {"image_id": 2, "file_name": "316_02.png", "page": 2, "dpi": 300, "bbox": [89, 99, 412, 205], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An example of event \ufb02ow, which consists of three visual elements: branch, email, and thread. ", "caption_bbox": [90, 219, 412, 245]}, {"image_id": 3, "file_name": "316_03.png", "page": 3, "dpi": 300, "bbox": [446, 99, 746, 191], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The results of optimizing the energy function \u03a9 with and without the weight wv c . Notice that the thickness of each branch in- dicates the value of wv c . (a) The input tree structure. (b) The result with wv c . (c) The result without wv c . ", "caption_bbox": [434, 201, 756, 257]}, {"image_id": 4, "file_name": "316_04.png", "page": 4, "dpi": 300, "bbox": [105, 99, 398, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The visualization of EmailMap project.", "caption_bbox": [136, 261, 363, 274]}], "317": [{"image_id": 0, "file_name": "317_00.png", "page": 1, "dpi": 300, "bbox": [89, 177, 766, 548], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Traf\ufb01c incidents highlighted using the Traf\ufb01c Origins approach. When an incident occurs, its location is marked by an expanding circle that reveals traf\ufb01c conditions in the immediate vicinity. ", "caption_bbox": [90, 561, 764, 587]}, {"image_id": 1, "file_name": "317_01.png", "page": 2, "dpi": 300, "bbox": [96, 99, 762, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Figure showing the sequence of events used to draw attention to road incidents. At time t \u2212 2, the road network remains occluded. At t \u2212 1, an expanding circle uncovers the underlying congestion free road network. At time interval t the road incident occurs and causes congestion in its immediate vicinity. The circle remain open until time t + 1 (just after the road incident ends) and closes at t + 2. This allows users to see the before and after effects of the road incident. ", "caption_bbox": [90, 276, 764, 328]}, {"image_id": 2, "file_name": "317_02.png", "page": 3, "dpi": 300, "bbox": [89, 100, 766, 482], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: User interface for the Traf\ufb01c Origins road speed + traf\ufb01c incident visualization", "caption_bbox": [221, 495, 630, 508]}], "318": [{"image_id": 0, "file_name": "318_00.png", "page": 1, "dpi": 300, "bbox": [98, 60, 761, 438], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The award-winning building design by Eva Hagen, part of which we used as a testbed for state-of-the-art BPS tools (marked in green).", "caption_bbox": [90, 450, 764, 463]}, {"image_id": 1, "file_name": "318_01.png", "page": 3, "dpi": 300, "bbox": [106, 489, 398, 706], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A combined visualization example (created with IES-VE): Isosurfaces for air temperature (gridded surfaces), cutting planes with color-coded vector glyphs for air \ufb02ow and contour lines for wind speed, and tracked particles. ", "caption_bbox": [90, 719, 412, 770]}, {"image_id": 2, "file_name": "318_02.png", "page": 4, "dpi": 300, "bbox": [122, 170, 382, 363], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Isosurfaces for air temperature (created with IES-VE).", "caption_bbox": [101, 376, 401, 389]}], "319": [{"image_id": 0, "file_name": "319_00.png", "page": 3, "dpi": 300, "bbox": [79, 181, 412, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: System overview with the main views plus a settings panel. The two spatial views show the distribution of a variable on a 2-D plane (a) and the 3D flow field using streamlines in a 3-D view (b). A linked view of the correlation (f) and a scatter plot view (e) are also shown. The slice surface is specified in the Slice Plane Setting Window (c) and the data are selected in the Data Selection Window(d). ", "caption_bbox": [86, 337, 412, 430]}], "32": [{"image_id": 0, "file_name": "32_00.png", "page": 3, "dpi": 300, "bbox": [84, 54, 751, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Angle in the visualisation pipeline", "caption_bbox": [277, 393, 554, 411]}, {"image_id": 1, "file_name": "32_01.png", "page": 4, "dpi": 300, "bbox": [83, 52, 359, 158], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Sets of mappings used in this paper", "caption_bbox": [451, 710, 724, 725]}, {"image_id": 2, "file_name": "32_02.png", "page": 4, "dpi": 300, "bbox": [428, 280, 693, 553], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Post-filter mappings", "caption_bbox": [154, 1064, 333, 1079]}, {"image_id": 3, "file_name": "32_03.png", "page": 6, "dpi": 300, "bbox": [82, 896, 752, 1030], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Separable class", "caption_bbox": [339, 1055, 493, 1070]}, {"image_id": 4, "file_name": "32_04.png", "page": 6, "dpi": 300, "bbox": [82, 615, 751, 799], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Perfect cohesion (6 properties, 6 methods)", "caption_bbox": [256, 825, 575, 840]}, {"image_id": 5, "file_name": "32_05.png", "page": 6, "dpi": 300, "bbox": [82, 348, 752, 521], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Multiple use participation", "caption_bbox": [306, 546, 526, 561]}, {"image_id": 6, "file_name": "32_06.png", "page": 6, "dpi": 300, "bbox": [82, 76, 752, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Low class cohesion", "caption_bbox": [328, 278, 504, 293]}, {"image_id": 7, "file_name": "32_07.png", "page": 7, "dpi": 300, "bbox": [82, 172, 751, 935], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A \u201creal\u201d class with 7 properties and 26 methods", "caption_bbox": [238, 960, 594, 975]}, {"image_id": 8, "file_name": "32_08.png", "page": 8, "dpi": 300, "bbox": [98, 78, 391, 1029], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The VT CAVE", "caption_bbox": [166, 1054, 321, 1069]}], "320": [{"image_id": 0, "file_name": "320_00.png", "page": 1, "dpi": 300, "bbox": [91, 60, 765, 424], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Our visual analysis application allows expert users to extract and analyze cavities and binding sites in protein simulation data.   1 3D                                                                                                            visualization (molecular surface and cartoon representation); 2 sequence diagram; two line plots for 3 cavity diameter (x-axis: cavity length, y-axis: diameter) and  4 cavity area (x-axis: time, y-axis: area);                                                                      5 relational graph showing the evolution of the cavities (splits and merges). ", "caption_bbox": [91, 431, 762, 472]}, {"image_id": 1, "file_name": "320_01.png", "page": 2, "dpi": 300, "bbox": [490, 98, 701, 224], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Semi-transparent molecular surface of a lipase (PDB-ID: 4FKB) colored by binding site information combined with Stick model. ", "caption_bbox": [434, 233, 755, 259]}, {"image_id": 2, "file_name": "320_02.png", "page": 3, "dpi": 300, "bbox": [94, 100, 765, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A lectin protein (PDB-ID: 2BT9) with a channel and three pockets analyzed and rendered using P OCASA [35] (a) and our application (b). (c) A line graph showing the permeability (diameter) of the channel. The marker signals that the channel has an exit. (d) Close-up of the extracted channel as wireframe rendering. The orange cycles represent the starting edges for the centerline extraction. ", "caption_bbox": [91, 248, 762, 287]}, {"image_id": 3, "file_name": "320_03.png", "page": 4, "dpi": 300, "bbox": [91, 99, 414, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Left: The green contour halo gives an impression of the shape of the selected pocket hidden by the molecular surface (PDB- ID: 1OGZ). Right: A coupling protein (PDB-ID: 1GKI) with a branch- ing channel (green: centerline, white dots: exits). ", "caption_bbox": [91, 248, 412, 299]}], "321": [{"image_id": 0, "file_name": "321_00.png", "page": 1, "dpi": 300, "bbox": [97, 60, 744, 551], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Nodal pressure representation of a water distribution system.", "caption_bbox": [245, 571, 568, 582]}, {"image_id": 1, "file_name": "321_01.png", "page": 2, "dpi": 300, "bbox": [181, 684, 659, 967], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Original network (A); after aggregating the edges (B); after schematizing the network (C).", "caption_bbox": [197, 975, 646, 986]}, {"image_id": 2, "file_name": "321_02.png", "page": 3, "dpi": 300, "bbox": [442, 193, 755, 296], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Multiple values of a nodal pressure variable are", "caption_bbox": [446, 328, 758, 339]}, {"image_id": 3, "file_name": "321_03.png", "page": 4, "dpi": 300, "bbox": [437, 303, 756, 537], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Existing techniques used in water distribution systems (A);", "caption_bbox": [446, 549, 758, 560]}, {"image_id": 4, "file_name": "321_04.png", "page": 4, "dpi": 300, "bbox": [107, 162, 388, 245], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Reliability example (A); vulnerability example (B);", "caption_bbox": [100, 269, 412, 280]}], "322": [{"image_id": 0, "file_name": "322_00.png", "page": 1, "dpi": 300, "bbox": [141, 60, 714, 477], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Our semiabstract multimodal visualization of 3D volume rendered data with additional isosurface context and an embedded 2D EIT movie. Left: Standard volume rendered CT data with a transfer function calculated from the grayscale. Many surrounding structures have the same grayscale value as the lung which leads to cluttering. Middle: Our multimodal visualization with enhanced volume rendering, isosurfaces and the embedded EIT movie. Right: The visualized thorax clipped with a sphere volume to remove cluttering. ", "caption_bbox": [90, 487, 764, 540]}, {"image_id": 1, "file_name": "322_01.png", "page": 2, "dpi": 300, "bbox": [120, 100, 750, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Different types of data used for the presented visualization. a) Histogram of CT data b) Segmentation of the CT data, c) one image of the 2D EIT movie. ", "caption_bbox": [90, 345, 764, 372]}, {"image_id": 2, "file_name": "322_02.png", "page": 3, "dpi": 300, "bbox": [117, 544, 386, 804], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visualization work\ufb02ow: a) CT data slices b) isosurface boundaries computed from the CT segmentation (c) 2D EIT movie d) volume rendering with grayscale transfer function e) volume rendering with grayscale and segmentation transfer function f) our combined visualization with volume rendering and boundary sur- faces. ", "caption_bbox": [90, 822, 412, 902]}, {"image_id": 3, "file_name": "322_03.png", "page": 4, "dpi": 300, "bbox": [140, 95, 715, 443], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Our multimodal visualization applied to medical datasets from a pig before a) and after b) a lung injury.", "caption_bbox": [154, 454, 699, 467]}], "323": [{"image_id": 0, "file_name": "323_00.png", "page": 1, "dpi": 300, "bbox": [144, 60, 711, 389], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Taxonomy of fault tolerance methods according to Egwutuoha et al. [7] extended with speci\ufb01c methods for distributed visualization. Gray dotted paths are well-known methods in high performance computing while bold elements are speci\ufb01c to (distributed) visualization. ", "caption_bbox": [90, 397, 764, 423]}, {"image_id": 1, "file_name": "323_01.png", "page": 4, "dpi": 300, "bbox": [89, 100, 767, 161], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Examples for different fault tolerance strategies. The fault region of a \ufb02ow visualization was rendered in a lower resolution and then upsampled to mask the failure timely while desaturation signals the approximate nature of the reconstruction to users (Figure 3(b)). Failures in large coherent regions can be alleviated with mosaic rendering so overall structures can still be perceived without any masking (compare Figure 3(c) and 3(d)). Please consult the electronic version for a magni\ufb01ed view. ", "caption_bbox": [90, 171, 764, 222]}], "324": [{"image_id": 0, "file_name": "324_00.png", "page": 1, "dpi": 300, "bbox": [424, 60, 718, 356], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Parallel POD compression. (a) Transforming a 3D data in one time step into a vector. (b) Binary-load distributed algorithm. ", "caption_bbox": [434, 368, 756, 394]}, {"image_id": 1, "file_name": "324_01.png", "page": 2, "dpi": 300, "bbox": [112, 100, 392, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Transforming the two cases of non-power-of-two into power-of-two. (a) The number of processors is power-of-two, while the number of time steps is not power-of-two (PPT-TNPT). (b) Neither the number of time steps nor processors is power-of-two (NNPT). (c) and (d) are the transformed BPT from (a) and (b), respectively. In the case of (b), 2 processors are enough to compress the dataset. ", "caption_bbox": [90, 312, 412, 389]}, {"image_id": 2, "file_name": "324_02.png", "page": 2, "dpi": 300, "bbox": [489, 100, 711, 312], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An example of 2-3-4 combination. 3-4 mode is selected to resolve this NNPT case. 4 processors are used to transform it into BPT from the second layer. The gray arrows show the process to decompose the data of P0 9 . ", "caption_bbox": [434, 331, 756, 383]}, {"image_id": 3, "file_name": "324_03.png", "page": 3, "dpi": 300, "bbox": [170, 98, 334, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An example of binary tree for decomposing the data in time step P0 9 of Figure 3. ", "caption_bbox": [90, 209, 412, 236]}, {"image_id": 4, "file_name": "324_04.png", "page": 4, "dpi": 300, "bbox": [101, 241, 403, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The compression time (s) of parallel 8000 processors.", "caption_bbox": [98, 364, 399, 377]}, {"image_id": 5, "file_name": "324_05.png", "page": 4, "dpi": 300, "bbox": [457, 100, 734, 331], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The result of compressing the large-scale time-varying dataset of the \ufb02ow simulation around a car. (a) is the visualization results by volume rendering of the magnitude of velocity. (b) is the compression ratio, where the color corresponding the errors in (c) and (d). (c) and (d) are the error and the standard deviation of error using 8000 processors on the K computer. ", "caption_bbox": [434, 343, 756, 420]}], "325": [{"image_id": 0, "file_name": "325_00.png", "page": 2, "dpi": 300, "bbox": [483, 99, 724, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A FTLE like image of 3D \ufb02ow \ufb01eld for the New River Inlet, Onslow, North Carolina using a Euclidean distance measure. The dominant ridgeline demarcates the slack tide interface between the river and the ocean. ", "caption_bbox": [434, 359, 756, 410]}, {"image_id": 1, "file_name": "325_01.png", "page": 2, "dpi": 300, "bbox": [131, 99, 372, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A traditional FTLE image of an instaneous 3D \ufb02ow \ufb01eld for the New River Inlet, Onslow, North Carolina. The dominant ridgeline demarcates the slack tide interface between the river and the ocean. ", "caption_bbox": [89, 359, 411, 398]}, {"image_id": 2, "file_name": "325_02.png", "page": 3, "dpi": 300, "bbox": [482, 442, 722, 684], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An image of the seed points colored by the Euclidean dis- tance a particle would travel from the seed point using an instanta- neous \ufb02ow \ufb01eld. The red regions represent particles that have travel the furthest over a \ufb01nite time period. Whereas the blue regions rep- resent particles that have travel the least. ", "caption_bbox": [435, 704, 757, 768]}, {"image_id": 3, "file_name": "325_03.png", "page": 3, "dpi": 300, "bbox": [130, 439, 370, 681], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An image of the seed points colored by the arc length of the streamline originating at the seed. The red regions represent par- ticles that have travel the furthest over a \ufb01nite time period. Whereas the blue regions represent particles that have travel the least. ", "caption_bbox": [89, 700, 411, 751]}, {"image_id": 4, "file_name": "325_04.png", "page": 3, "dpi": 300, "bbox": [130, 98, 369, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A series of 3D streamlines for the \ufb02ow \ufb01eld from the New River Inlet, Onslow, North Carolina. The streamlines are colored via the arc length (blue: short distances, red: long distances) and show a series of eddies. None of which are more dominant than another. ", "caption_bbox": [89, 357, 411, 408]}, {"image_id": 5, "file_name": "325_05.png", "page": 3, "dpi": 300, "bbox": [481, 98, 721, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A series of 3D streamlines for the \ufb02ow \ufb01eld from the New River Inlet, Onslow, North Carolina. The streamlines are col- ored based on the Euclidean distance a particle would travel from its initial starting location (blue: short distances, red: long distances). ", "caption_bbox": [434, 358, 756, 409]}, {"image_id": 6, "file_name": "325_06.png", "page": 4, "dpi": 300, "bbox": [484, 456, 726, 698], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: A time varying LE image using a Euclidean distance measure. Similar structures as well as other structures can be seen when compared to the traditional FTLE in Figure 8. ", "caption_bbox": [435, 711, 757, 750]}, {"image_id": 7, "file_name": "325_07.png", "page": 4, "dpi": 300, "bbox": [132, 448, 374, 692], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A traditional time varying FTLE image of 3D \ufb02ow \ufb01eld. The dominant ridgeline demarcates the interface between the river and the ocean. ", "caption_bbox": [90, 711, 412, 750]}, {"image_id": 8, "file_name": "325_08.png", "page": 4, "dpi": 300, "bbox": [484, 98, 726, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: An image of the seed points colored by the Euclidean dis- tance a particle would travel from the seed point using a time varying \ufb02ow \ufb01eld. The red regions represent particles that have travel the fur- thest over a \ufb01nite time period. Whereas the blue regions represent particles that have travel the least. ", "caption_bbox": [434, 359, 756, 423]}, {"image_id": 9, "file_name": "325_09.png", "page": 4, "dpi": 300, "bbox": [132, 98, 374, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: An image of the seed points colored by the arc length of the pathline originating at the seed. The red regions represent particles that have travel the furthest over a \ufb01nite time period. Whereas the blue regions represent particles that have travel the least. ", "caption_bbox": [90, 359, 412, 410]}], "326": [{"image_id": 0, "file_name": "326_00.png", "page": 2, "dpi": 300, "bbox": [101, 743, 402, 943], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Cumulative distribution function as the opacity value between the front point and the particle on the ray segment. ", "caption_bbox": [97, 952, 411, 977]}, {"image_id": 1, "file_name": "326_01.png", "page": 3, "dpi": 300, "bbox": [85, 459, 413, 611], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Rendering results with the previous techniques. The depth is evaluated at (a) the front, (b) middle, and (c) back points. ", "caption_bbox": [94, 402, 408, 427]}, {"image_id": 2, "file_name": "326_02.png", "page": 3, "dpi": 300, "bbox": [101, 277, 419, 381], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Rendering results for two tetrahedral cells with our proposed technique. The red and blue color maps are applied for each cell. ", "caption_bbox": [94, 214, 408, 252]}, {"image_id": 3, "file_name": "326_03.png", "page": 4, "dpi": 300, "bbox": [97, 342, 758, 618], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison of our results with those of the previous techniques. These panels show the fused visualization results of the velocity magnitude (blue) and the pressure (red) with and without cell edges generated by (a) our proposed technique and the previous techniques with the depth at the (b) front, (c) middle, and (d) back points of the ray segment for each cell. The rendering times with 100 ensembles are shown for each technique. ", "caption_bbox": [94, 631, 759, 683]}, {"image_id": 4, "file_name": "326_04.png", "page": 4, "dpi": 300, "bbox": [165, 99, 716, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Rendering results of the Tank dataset with the cell edges. (a) The distribution of the velocity magnitude calculated with 516 tetrahedral cells, (b) the distribution of the pressure calculated with 9,827 tetrahedral cells, and (c) the fused visualization result of (a) and (b). ", "caption_bbox": [94, 291, 762, 316]}], "327": [{"image_id": 0, "file_name": "327_00.png", "page": 3, "dpi": 300, "bbox": [471, 643, 723, 751], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Left: Funeboko \ufb02oat for the Gion Festival in Kyoto, Japan (photo). Right: laser-scanned 3D point data (166.9 M points). ", "caption_bbox": [435, 763, 757, 789]}, {"image_id": 1, "file_name": "327_01.png", "page": 3, "dpi": 300, "bbox": [439, 99, 755, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Left: transparent visualization of the laser-scanned data of a campus building using our scheme. The standard surface opacity is \u03b1 = 0.2, the image resolution is 10242 , the image-quality parame- ter is LR = 1000, and the number of proliferated particles is 154.5M (k = 8.09). Right: fused visualization of the laser-scanned data with visual assistants, which are the concentric spheres centered at the weighted center of the laser-scanned 3D points. ", "caption_bbox": [435, 270, 757, 359]}, {"image_id": 2, "file_name": "327_02.png", "page": 4, "dpi": 300, "bbox": [94, 496, 410, 654], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Left: transparent visualization of laser-scanned data (166.9 M points) of the festival \ufb02oat, assigning different opacities to different member components by tuning proliferation ratios. Right: a zoomed- in view, where particle cross section s is adaptively tuned. ", "caption_bbox": [90, 667, 412, 718]}, {"image_id": 3, "file_name": "327_03.png", "page": 4, "dpi": 300, "bbox": [439, 99, 755, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Left: fused visualization of laser-scanned data (gray) and a visual-assistant polygon mesh (red) constructed using modeling soft- ware . Right: fusion with a high-resolution photo image of a tapestry. The standard surface opacity of the photo image is \u03b1 = 0.3, which corresponds to 14.6M particles. ", "caption_bbox": [435, 276, 757, 340]}, {"image_id": 4, "file_name": "327_04.png", "page": 4, "dpi": 300, "bbox": [133, 152, 371, 228], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Left: the rendering artifact for overlapping boundary sur- faces (depth peeling). Right: prevention of the artifact by averaging the surface colors (stochastic point-based rendering). ", "caption_bbox": [90, 241, 412, 280]}], "328": [{"image_id": 0, "file_name": "328_00.png", "page": 1, "dpi": 300, "bbox": [89, 60, 766, 400], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A collection of 16,598 transfer functions on CT head data collected from 20 users during the design process are integrated in one transfer function map in (a). Three key points on the map are selected in (a), and the corresponding volume rendered results and transfer functions are shown in (b). ", "caption_bbox": [90, 400, 764, 439]}, {"image_id": 1, "file_name": "328_01.png", "page": 2, "dpi": 300, "bbox": [434, 97, 759, 378], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Transfer function map navigation with two interpolation schemes: (a) linear interpolation; (b) transfer function map interpo- lation. The position of the intermediate transfer functions are shown as trajectories in (a) and (b). ", "caption_bbox": [435, 377, 757, 428]}, {"image_id": 2, "file_name": "328_02.png", "page": 3, "dpi": 300, "bbox": [92, 97, 763, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The pipeline of the system. First, transfer functions are collected from users, then transfer function maps are generated using MDS layouts and density maps. The map navigation and recommendation system are provided to users for further exploration of the volume data. ", "caption_bbox": [90, 212, 764, 238]}, {"image_id": 3, "file_name": "328_03.png", "page": 3, "dpi": 300, "bbox": [442, 251, 766, 508], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Two transfer function design tools provided for users. (a) The traditional control points-based 1D transfer function design inter- face. The black curve indicates the histogram of the feature. Users can use control points to control the de\ufb01ne the intended opacity val- ues and colors, and other blank areas are smoothed and interpo- lated according to the control points. (b) WYSIWYG volume visual- ization [7]. Users can use different painting tools to sketch on the image, in order to change the appearance of features, without direct accessing the transfer functions. ", "caption_bbox": [434, 507, 756, 621]}, {"image_id": 4, "file_name": "328_04.png", "page": 3, "dpi": 300, "bbox": [89, 255, 410, 511], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visual recommendation for user operation: (a) the current status 0 of the user operation and the recommended rendering re- sults 1, 2, and 3; (b) the corresponding transfer function map and the local triangle mesh. ", "caption_bbox": [90, 510, 412, 561]}, {"image_id": 5, "file_name": "328_05.png", "page": 4, "dpi": 300, "bbox": [89, 329, 410, 501], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparison between expert users (a) and novice users (b). ", "caption_bbox": [90, 500, 412, 526]}, {"image_id": 6, "file_name": "328_06.png", "page": 4, "dpi": 300, "bbox": [434, 99, 757, 427], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: User trajectories in the transfer function map: (a) and (b): trajectories on a color-invariant map; (c) and (d): trajectories on a transfer function map which accounts all metrics ", "caption_bbox": [435, 426, 757, 465]}, {"image_id": 7, "file_name": "328_07.png", "page": 4, "dpi": 300, "bbox": [89, 101, 410, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Transfer function map comparison between two provided design tools on CT head data: (a) traditional curve-based transfer function; (b) WYSIWYG transfer function design. The density map in both \ufb01gures are identical for reference. ", "caption_bbox": [89, 269, 411, 320]}], "329": [{"image_id": 0, "file_name": "329_00.png", "page": 1, "dpi": 300, "bbox": [439, 595, 750, 710], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2 Main processing steps and data flow", "caption_bbox": [504, 719, 688, 730]}, {"image_id": 1, "file_name": "329_01.png", "page": 2, "dpi": 300, "bbox": [92, 746, 749, 948], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: the main view of the visual detection of anomalies system", "caption_bbox": [290, 947, 563, 958]}, {"image_id": 2, "file_name": "329_02.png", "page": 4, "dpi": 300, "bbox": [84, 100, 756, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Case study: Anomalies detection and DNS behavior feature analysis", "caption_bbox": [263, 319, 577, 330]}], "33": [{"image_id": 0, "file_name": "33_00.png", "page": 1, "dpi": 300, "bbox": [514, 472, 649, 596], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An example of direct interaction with large-display. ", "caption_bbox": [447, 620, 725, 651]}, {"image_id": 1, "file_name": "33_01.png", "page": 1, "dpi": 300, "bbox": [515, 281, 650, 397], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A schematic representation of existing large-display interactive system. ", "caption_bbox": [442, 414, 724, 444]}, {"image_id": 2, "file_name": "33_02.png", "page": 3, "dpi": 300, "bbox": [149, 89, 699, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) Initial state where the black arrow represents the position of the invisible laser beam, and is not currently selecting the object. (b) To select the object, the user moves their laser beam towards the object. However, due to latency, the system is not yet aware of these changes, and so keeps the original beam position, illustrated with a dotted arrow. (c) As the pointer moves inside the object, the system detects the crossing of the boundary by the laser beam. (d) The system reacts to this crossing and highlights the object, while the laser beam of the pointer stops at the centre of the object. ", "caption_bbox": [132, 248, 693, 342]}, {"image_id": 3, "file_name": "33_03.png", "page": 4, "dpi": 300, "bbox": [201, 86, 652, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Initial state of an object. (b) To select the object, a circling gesture is used. (c) The final state of the object after selecting. ", "caption_bbox": [135, 195, 692, 225]}, {"image_id": 4, "file_name": "33_04.png", "page": 4, "dpi": 300, "bbox": [125, 918, 351, 1066], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Infrared laser tracking device Smart-Nav.", "caption_bbox": [91, 1074, 383, 1088]}, {"image_id": 5, "file_name": "33_05.png", "page": 4, "dpi": 300, "bbox": [441, 896, 715, 1023], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) A screen shot illustrating the initial state of a rectangle and a textbox. (b) The rectangle is being selected. (c) The textbox is being selected. ", "caption_bbox": [439, 1040, 728, 1087]}, {"image_id": 6, "file_name": "33_06.png", "page": 5, "dpi": 300, "bbox": [125, 632, 315, 957], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) The bounding box of an object is divided into four \u201cgesture boxes\u201d. (b) To select the object, all four boxes must be in the path of the gesture. (c) To make it easier to perform gestures, an external box is implemented, allowing users to go outside the boundary of the object. (d) A successful selection of the object. ", "caption_bbox": [88, 975, 388, 1086]}, {"image_id": 7, "file_name": "33_07.png", "page": 6, "dpi": 300, "bbox": [112, 669, 367, 852], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: An infrared laser pointer enclosed in a mouse case. ", "caption_bbox": [96, 865, 373, 896]}], "330": [{"image_id": 0, "file_name": "330_00.png", "page": 1, "dpi": 300, "bbox": [89, 60, 766, 605], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The overview of web-based visualization tool for analyzing the network and system anomalies in standard log \ufb01les.", "caption_bbox": [125, 616, 727, 629]}, {"image_id": 1, "file_name": "330_01.png", "page": 2, "dpi": 300, "bbox": [434, 99, 774, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Attributes of server machines are summed by time slices. In the stacked area charts, each of the attributes (log record counts, \ufb01rst-seen-total-bytes, and \ufb01rst-seen-packet-count) is plotted with a unique color. ", "caption_bbox": [434, 304, 756, 357]}, {"image_id": 2, "file_name": "330_02.png", "page": 3, "dpi": 300, "bbox": [434, 100, 774, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Rectangles in the Treemap represent the record counts grouped by time unit from the server machines with unique col- ors. The rectangle of the server \u2018web03\u2019 from 9 to 12am dominates on April 3rd. In addition, servers \u2018web02\u2019 and \u2018web02l\u2019 are also noticeable. ", "caption_bbox": [434, 305, 756, 371]}, {"image_id": 3, "file_name": "330_03.png", "page": 3, "dpi": 300, "bbox": [80, 100, 414, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A Gantt chart showing the connection status of servers (y-axis) by the timeline (x-axis). Colors indicate the severity of events (similar to syslog levels). It is obvious that server \u2018web03\u2019 has abnormality. To pin down the exact start and end times, one can click the upper left buttons to zoom along x-axis of time units. ", "caption_bbox": [90, 304, 412, 371]}, {"image_id": 4, "file_name": "330_04.png", "page": 4, "dpi": 300, "bbox": [435, 99, 776, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Examine and correlate events by selecting anomalous nodes in a network graph. ", "caption_bbox": [435, 304, 757, 331]}], "331": [{"image_id": 0, "file_name": "331_00.png", "page": 1, "dpi": 300, "bbox": [465, 652, 731, 822], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Bigraph and Hasse diagram for example formal context.", "caption_bbox": [436, 834, 754, 847]}, {"image_id": 1, "file_name": "331_01.png", "page": 3, "dpi": 300, "bbox": [93, 151, 410, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Example formal context and a precursor to the corre- sponding Hasse diagram showing the hierarchical decomposition identi\ufb01ed by C ARVE. ", "caption_bbox": [89, 340, 411, 380]}, {"image_id": 2, "file_name": "331_02.png", "page": 3, "dpi": 300, "bbox": [466, 99, 726, 237], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Modi\ufb01ed Hasse diagram with discovered sub-lattices within inclusion layout containers. ", "caption_bbox": [434, 246, 756, 273]}, {"image_id": 3, "file_name": "331_03.png", "page": 4, "dpi": 300, "bbox": [435, 454, 759, 640], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Prototype interface applied to the InfoVis 2004 biblio- graphic data set [20]. The user has selected and zoomed to a \ufb01rst- generation sub-context containing 42 concepts. ", "caption_bbox": [435, 663, 757, 703]}, {"image_id": 4, "file_name": "331_04.png", "page": 4, "dpi": 300, "bbox": [98, 98, 403, 225], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Hasse diagram with and without recursive partitioning.", "caption_bbox": [95, 237, 407, 250]}], "332": [{"image_id": 0, "file_name": "332_00.png", "page": 1, "dpi": 300, "bbox": [424, 60, 767, 550], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The \ufb01gure shows a part of a biological network with the focus region. Nodes, whose center is within the focus region are labeled by their name, if available. The arrangement of the labels is done according to the Radial approach. ", "caption_bbox": [434, 559, 756, 612]}, {"image_id": 1, "file_name": "332_01.png", "page": 2, "dpi": 300, "bbox": [192, 100, 311, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: This \ufb01gure shows a time series of expression data in BiNA (NCBI: GEO GDS 39), which was produced for a comprehensive identi\ufb01cation of cell cycle-regulated genes [16]. The expression graphics are stacked on the left side of the focus region. The labels have all the same size and are easily comparable for the user. ", "caption_bbox": [89, 256, 412, 322]}, {"image_id": 2, "file_name": "332_02.png", "page": 3, "dpi": 300, "bbox": [437, 99, 763, 404], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: This \ufb01gure shows the result of the Force Directed ap- proach. The conditions are the same as in Figure 1. Note the different distribution of the nodes in the bottom left corner, while labels at the right top corner maintain the same position, as there is no in\ufb02uence by other labels. ", "caption_bbox": [435, 410, 759, 477]}, {"image_id": 3, "file_name": "332_03.png", "page": 4, "dpi": 300, "bbox": [92, 99, 410, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: These two \ufb01gures show the effect that occurs if the focus region approaches the borders of the visible region for the Cake- Cutting approach. On the left, we shows the assignment of labels around the focus region, as there is no border in\ufb02uence. To maintain the right \ufb01gure, the view was shifted to the left to show the same labels with in\ufb02uence of the border. The labels are shifted such that no border crossings occur. ", "caption_bbox": [89, 275, 413, 368]}], "333": [{"image_id": 0, "file_name": "333_00.png", "page": 2, "dpi": 300, "bbox": [523, 99, 665, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Different types of Edges. The one of the bottom is used in our approach ", "caption_bbox": [434, 241, 756, 268]}, {"image_id": 1, "file_name": "333_01.png", "page": 2, "dpi": 300, "bbox": [92, 99, 411, 170], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Content based versus personalized linking", "caption_bbox": [125, 183, 376, 196]}, {"image_id": 2, "file_name": "333_02.png", "page": 4, "dpi": 300, "bbox": [498, 486, 695, 651], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Personalized visualization for user 2", "caption_bbox": [484, 661, 707, 674]}, {"image_id": 3, "file_name": "333_03.png", "page": 4, "dpi": 300, "bbox": [93, 367, 412, 470], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Clusters in Different Approaches", "caption_bbox": [150, 500, 352, 513]}, {"image_id": 4, "file_name": "333_04.png", "page": 4, "dpi": 300, "bbox": [498, 293, 695, 459], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Personalized visualization for user 1", "caption_bbox": [484, 468, 707, 481]}, {"image_id": 5, "file_name": "333_05.png", "page": 4, "dpi": 300, "bbox": [93, 233, 412, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Personalized Clustering of Web Graph", "caption_bbox": [135, 481, 369, 494]}, {"image_id": 6, "file_name": "333_06.png", "page": 4, "dpi": 300, "bbox": [93, 99, 412, 203], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Content based Clustering of Web Graph", "caption_bbox": [131, 348, 372, 361]}, {"image_id": 7, "file_name": "333_07.png", "page": 4, "dpi": 300, "bbox": [499, 99, 695, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Original web graph of a university web site", "caption_bbox": [468, 275, 724, 288]}], "334": [{"image_id": 0, "file_name": "334_00.png", "page": 2, "dpi": 300, "bbox": [93, 99, 413, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The original graph, showing two types of relations between the graph nodes: (a) the structural relations, and (b) the adjacency relations. ", "caption_bbox": [92, 325, 413, 364]}, {"image_id": 1, "file_name": "334_01.png", "page": 2, "dpi": 300, "bbox": [94, 377, 413, 608], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The compound graph representation of the graph pre- sented in Figure 1. ", "caption_bbox": [92, 622, 413, 648]}, {"image_id": 2, "file_name": "334_02.png", "page": 3, "dpi": 300, "bbox": [104, 98, 754, 372], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The highest level of details of an CFT model without ex- panding any node. ", "caption_bbox": [434, 371, 755, 397]}, {"image_id": 3, "file_name": "334_03.png", "page": 4, "dpi": 300, "bbox": [436, 99, 755, 416], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: An illustration of the graph representation after expanding three compound nodes. The color saturation is used to show the parent-child relationships between the components and their sub- components and the failure relations are visualized using explicit edges between the graph nodes. ", "caption_bbox": [434, 429, 755, 493]}, {"image_id": 4, "file_name": "334_04.png", "page": 4, "dpi": 300, "bbox": [93, 99, 413, 389], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The process of expanding the required nodes using the CluE algorithm. The abstract view is shown at the top left side of the \ufb01gure with smaller size, while the expanded view is shown at the center of the \ufb01gure. ", "caption_bbox": [91, 401, 412, 452]}], "335": [{"image_id": 0, "file_name": "335_00.png", "page": 2, "dpi": 300, "bbox": [448, 99, 766, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Two exploration views to perform data exploration and a lock view to con\ufb01gure the brushing and dig techniques. ", "caption_bbox": [435, 375, 764, 400]}, {"image_id": 1, "file_name": "335_01.png", "page": 3, "dpi": 300, "bbox": [82, 99, 413, 510], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Brush, dig, and lock tools. Locked items are not affected by brush and dig. We used transfer functions to make air voxels transparent and standard gradient shading. We see that the head is surrounded by a large amount of uninteresting noise (yellow). ", "caption_bbox": [83, 522, 412, 572]}, {"image_id": 2, "file_name": "335_02.png", "page": 3, "dpi": 300, "bbox": [454, 519, 742, 676], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Opening a human head DVR to expose the skull structure.", "caption_bbox": [444, 684, 754, 697]}, {"image_id": 3, "file_name": "335_03.png", "page": 4, "dpi": 300, "bbox": [86, 99, 408, 587], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Exposing the top part of the brain structure in a 3D scan.", "caption_bbox": [96, 594, 399, 607]}, {"image_id": 4, "file_name": "335_04.png", "page": 5, "dpi": 300, "bbox": [84, 98, 753, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Finding intensity outliers with isolated ranges in an astronomical data cube.", "caption_bbox": [228, 292, 614, 305]}, {"image_id": 5, "file_name": "335_05.png", "page": 5, "dpi": 300, "bbox": [84, 311, 709, 510], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Locating constant-intensity line outliers in an astronomical data cube.", "caption_bbox": [242, 511, 601, 524]}, {"image_id": 6, "file_name": "335_06.png", "page": 6, "dpi": 300, "bbox": [111, 99, 727, 276], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Dead pixel isolation. Warping between an image (left) and its hue-saturation plot (right) allows \ufb01nding a few outlier pixels (marked red).", "caption_bbox": [95, 281, 749, 294]}, {"image_id": 7, "file_name": "335_07.png", "page": 6, "dpi": 300, "bbox": [79, 311, 412, 845], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Skin tumor segmentation scenario.", "caption_bbox": [141, 855, 339, 868]}, {"image_id": 8, "file_name": "335_08.png", "page": 7, "dpi": 300, "bbox": [84, 99, 758, 506], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Removing a complex area from a color image using a combination of brushing, animation, and linked scatterplots.", "caption_bbox": [141, 511, 702, 524]}], "336": [{"image_id": 0, "file_name": "336_00.png", "page": 1, "dpi": 300, "bbox": [105, 161, 748, 656], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Manipulating feature space for categorizing images. Global manipulation allows us to edit the closeness between image categories on the screen space as shown at the top right, while local manipulation controls the distances between images within each category as depicted at the bottom right. Here, different background colors are assigned to image categories where images in each category are tied with edges of the same color. ", "caption_bbox": [93, 669, 761, 720]}, {"image_id": 1, "file_name": "336_01.png", "page": 2, "dpi": 300, "bbox": [438, 98, 753, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of the proposed approach.", "caption_bbox": [486, 264, 703, 277]}, {"image_id": 2, "file_name": "336_02.png", "page": 3, "dpi": 300, "bbox": [481, 99, 707, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Bilevel feature space representation and its associated two- layered graph. ", "caption_bbox": [434, 280, 753, 306]}, {"image_id": 3, "file_name": "336_03.png", "page": 4, "dpi": 300, "bbox": [108, 99, 398, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Histogram representations of images.", "caption_bbox": [141, 253, 363, 266]}, {"image_id": 4, "file_name": "336_04.png", "page": 5, "dpi": 300, "bbox": [102, 100, 752, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Local and global operations for manipulating feature space.", "caption_bbox": [265, 273, 587, 286]}, {"image_id": 5, "file_name": "336_05.png", "page": 5, "dpi": 300, "bbox": [456, 310, 748, 470], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Updating the distance between the nodes in the two- layered graph when manipulating the feature space. (a) local ma- nipulation. (b) Global manipulation. ", "caption_bbox": [435, 495, 754, 533]}, {"image_id": 6, "file_name": "336_06.png", "page": 6, "dpi": 300, "bbox": [118, 99, 738, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Local manipulation of the feature space: (a) Original layout of images where tomato images are selected. (b) Local manipulation permits us to increase the closeness of the selected two images. ", "caption_bbox": [93, 371, 761, 397]}, {"image_id": 7, "file_name": "336_07.png", "page": 7, "dpi": 300, "bbox": [118, 100, 738, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Global manipulation of the feature space: (a) Original layout of the images where tomato and CD images are selected. (b) Global manipulation helps us merge the two different image categories and further collect images including round objects around the merged category. ", "caption_bbox": [93, 372, 761, 398]}, {"image_id": 8, "file_name": "336_08.png", "page": 8, "dpi": 300, "bbox": [117, 100, 738, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: An example of unexpected rearrangement of the images. (a) Two images (a cat in the night and a cat in the washbowl) are selected. (b) Bringing the two images close to each other incurs a drastic change in the layout of other images. ", "caption_bbox": [93, 351, 761, 377]}], "337": [{"image_id": 0, "file_name": "337_00.png", "page": 3, "dpi": 300, "bbox": [434, 656, 760, 706], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Summary of the \ufb02ow of RBF projection technique. Con- trol points selection and calculation of positions are the \ufb01rst steps, followed by determination of \u03bb \u2019s and application of function s(x) to position the remaining instances. ", "caption_bbox": [435, 718, 757, 769]}, {"image_id": 1, "file_name": "337_01.png", "page": 3, "dpi": 300, "bbox": [122, 514, 383, 759], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Radial Basis Function interpolation with \ufb01ve data samples X = {0, 1, 3, 4, 5} and function values Y = {0, 2, 5, 3, 1}. The data sam- ples are represented as colored points. The blue curve is the function obtained with RBF interpolating between the data samples. Below                                                                  2 the graph, the Gaussian radial basis functions \u03c6 (r) = e\u2212(\u03b5r) are rep- resented, where r is the distance between a point and the data sam- ple, with \u03b5 2 = 0.5. The colors of the curves make the correspondence to the data samples. ", "caption_bbox": [90, 771, 412, 875]}, {"image_id": 2, "file_name": "337_02.png", "page": 4, "dpi": 300, "bbox": [121, 364, 382, 574], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Gaussian, multiquadrics and inverse multiquadrics func- tions in one dimension. In this example all of the functions have \u03b5 = 1. ", "caption_bbox": [90, 586, 412, 626]}, {"image_id": 3, "file_name": "337_03.png", "page": 4, "dpi": 300, "bbox": [434, 99, 759, 614], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Boxplots with a comparison of projection quality (stress) us- ing Norm (Pekalska), Multiquadrics and Gaussian kernels, for three data sets (Pima, WDBC and Wine Quality); (a) 10 and (b) 100 ran- domly selected control points. Each experiment was executed 100 times, with a different set of control points for each execution. ", "caption_bbox": [435, 627, 757, 691]}, {"image_id": 4, "file_name": "337_04.png", "page": 6, "dpi": 300, "bbox": [468, 100, 727, 755], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Impact of control points\u2019 selection with ROLS in projection stress, for three data sets. In ROLS results, #FCP indicates the av- erage number of control points selected in the experiment. ", "caption_bbox": [434, 767, 756, 806]}, {"image_id": 5, "file_name": "337_05.png", "page": 7, "dpi": 300, "bbox": [437, 98, 762, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Example of control points manipulation with the Ionosphere data set, with the goal of unveiling samples close to a pivot. Through the manipulation of control points the user is able to examine a sub- set of the data (b) observed to be cluttered in the original projection (a). The color represents the distance value of the sample to a pivot, black being the most similar and light green the most dissimilar. ", "caption_bbox": [435, 305, 757, 382]}, {"image_id": 6, "file_name": "337_06.png", "page": 7, "dpi": 300, "bbox": [121, 98, 359, 592], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Stress and time comparison for RBF, LAMP, PLMP, Pekalska and Fastmap. ", "caption_bbox": [90, 605, 412, 631]}, {"image_id": 7, "file_name": "337_07.png", "page": 8, "dpi": 300, "bbox": [157, 100, 699, 336], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Example of control points selection through ROLS in the Mammals data set (20,000 instances and 47 dimensions). This data set contains four well-de\ufb01ned clusters, indicated by the different colors in the projection. Figures on the bottom present only the control points used to produce the projection, depicted on the top. ", "caption_bbox": [90, 349, 764, 388]}, {"image_id": 8, "file_name": "337_08.png", "page": 8, "dpi": 300, "bbox": [90, 393, 414, 545], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Example of control points manipulation with the segmenta- tion data set. (a) Control points automatically positioned and (b) \ufb01nal projection after user manipulation. ", "caption_bbox": [90, 557, 412, 596]}], "338": [{"image_id": 0, "file_name": "338_00.png", "page": 2, "dpi": 300, "bbox": [435, 278, 760, 351], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2. Overview of the proposed framework for transformation and storage of integral distribution volume. ", "caption_bbox": [435, 361, 757, 384]}, {"image_id": 1, "file_name": "338_01.png", "page": 2, "dpi": 300, "bbox": [477, 99, 717, 179], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1. Left. Traditional raw data access method of answering range distri- bution queries where compute time, i/o and communication time are functions of query size. The blocks to be loaded to answer a query (red rectangle) are shaded in blue. Right. Proposed integral distribution approach only needs to probe the 4 (8 in 3D) corners of a query region to answer it. Query response time is \ufb01xed regardless of query size. ", "caption_bbox": [435, 190, 757, 260]}, {"image_id": 2, "file_name": "338_02.png", "page": 3, "dpi": 300, "bbox": [444, 97, 752, 249], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. Transformation of a 1D integral distribution. Only the distributions of the ranges colored in gray are suf\ufb01cient to construct the distribution of any arbitrary range. ", "caption_bbox": [435, 260, 757, 294]}, {"image_id": 3, "file_name": "338_03.png", "page": 3, "dpi": 300, "bbox": [260, 422, 415, 491], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3.    Fast algorithm to de- compose a range into power-of-two length blocks. ", "caption_bbox": [260, 502, 412, 536]}, {"image_id": 4, "file_name": "338_04.png", "page": 3, "dpi": 300, "bbox": [435, 681, 759, 877], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5. Overview of the indexing algorithm, where sub-range distribu- tions, grouped based on their sizes, \ufb01nd an approximate match from a much smaller set of template distributions. ", "caption_bbox": [595, 876, 757, 934]}, {"image_id": 5, "file_name": "338_05.png", "page": 4, "dpi": 300, "bbox": [489, 100, 705, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7. (a) Schematic presentation of chosen transformations for histograms. (b) Fast shift and re\ufb02ection through peak matching and local adjustment. ", "caption_bbox": [435, 381, 757, 403]}, {"image_id": 6, "file_name": "338_06.png", "page": 4, "dpi": 300, "bbox": [146, 100, 359, 181], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6. Proposed strategy for template creation. Regions of length B at regular intervals are chosen as templates in the \ufb01rst iteration. Region length is increased and the interval is decreased in subsequent iterations. ", "caption_bbox": [90, 193, 412, 227]}, {"image_id": 7, "file_name": "338_07.png", "page": 5, "dpi": 300, "bbox": [442, 98, 756, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8. Local statistical analysis at different levels of detail. (a) Accurate and approximate reconstruction of block-wise mean \ufb01eld of Isabel pressure, (b) relative amount of memory access (in terms of sub-ranges access), (c) relative computation time, and (d) accuracy (measured by RMS error) of local statistical analysis at different levels of approximation. ", "caption_bbox": [434, 317, 756, 375]}, {"image_id": 8, "file_name": "338_08.png", "page": 6, "dpi": 300, "bbox": [99, 99, 405, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1. Size of test datasets and the storage cost of corresponding IDVs (64 bins) ", "caption_bbox": [435, 100, 757, 123]}, {"image_id": 9, "file_name": "338_09.png", "page": 6, "dpi": 300, "bbox": [97, 316, 408, 535], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10. Top. Distribution-based search for different patterns on Solar Plume dataset (using a 93 local neighborhood). A commonly occurring distribution (top left), and a sparsely present distribution (top right) used as template. Bottom. Distribution-based search for locations with stoichiometric mixture rate of 0.42 on time step 118 of the combustion dataset (using a 73 local neighborhood). ", "caption_bbox": [90, 547, 412, 606]}, {"image_id": 10, "file_name": "338_10.png", "page": 7, "dpi": 300, "bbox": [627, 597, 758, 698], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13. Performance anal- ysis of indexing of power-of- two sub-range distributions for Plume ( ), Isabel ( ), and Combustion (2). Each is par- titioned into 1024 blocks. ", "caption_bbox": [626, 711, 756, 781]}, {"image_id": 11, "file_name": "338_11.png", "page": 7, "dpi": 300, "bbox": [442, 98, 765, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2. Performance analysis of different stages of pre-processing (run on 8 processors in parallel). All times are in seconds. ", "caption_bbox": [434, 351, 756, 374]}, {"image_id": 12, "file_name": "338_12.png", "page": 7, "dpi": 300, "bbox": [133, 98, 369, 204], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12. Performance analysis of query response for different query sizes and different datasets. The y axes in logarithmic scale. The tested algorithms are raw-access (2), integral histograms ( ), and our approach ( ). ", "caption_bbox": [434, 299, 756, 333]}], "339": [{"image_id": 0, "file_name": "339_00.png", "page": 1, "dpi": 300, "bbox": [93, 187, 763, 578], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Our system for interactive visual analysis of semantically enriched movement data consists of two components: top) Geographic View - visualizing frequent destination clusters, routes, POIs (points of interest) and degree of uncertainty by varying color intensity of the icons; bottom) Temporal View - showing frequent temporal daily patterns. Most frequent patterns are shown on top. Color varies from green (frequent) to white (infrequent). Views are connected by brushing and linking. ", "caption_bbox": [94, 602, 761, 653]}, {"image_id": 1, "file_name": "339_01.png", "page": 2, "dpi": 300, "bbox": [435, 99, 756, 282], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Analysis Pipeline: a) Extract frequent destinations, b) Data enrichment using a POI Service, c) Interactive Visual Analysis of POI results and movement patterns, d) Interpretation ", "caption_bbox": [434, 295, 753, 333]}, {"image_id": 2, "file_name": "339_02.png", "page": 3, "dpi": 300, "bbox": [435, 313, 756, 468], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Popular destinations build dense clusters (red) surrounded with noise (white). Map details are blured due to privacy purposes. ", "caption_bbox": [435, 480, 754, 506]}, {"image_id": 3, "file_name": "339_03.png", "page": 4, "dpi": 300, "bbox": [93, 590, 414, 772], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Found Clusters: venues nearby (red), home (green), charg- ings (yellow). Map details are removed due to privacy purposes. ", "caption_bbox": [93, 784, 412, 810]}, {"image_id": 4, "file_name": "339_04.png", "page": 4, "dpi": 300, "bbox": [435, 100, 755, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Found venues per cluster, using a 50 meters query radius. For 607 of the 1.215 clusters venues where found. ", "caption_bbox": [435, 286, 754, 312]}, {"image_id": 5, "file_name": "339_05.png", "page": 4, "dpi": 300, "bbox": [440, 577, 749, 785], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Foursquare category tree: each level summarizes its child nodes in parent categories. Leaf nodes are high detailed venue types, such as Post Of\ufb01ce. ", "caption_bbox": [435, 798, 754, 836]}, {"image_id": 6, "file_name": "339_06.png", "page": 5, "dpi": 300, "bbox": [434, 472, 756, 693], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Area based analysis. Map snippet shows the scooter home location and frequent destinations like shops and of\ufb01ces. The area was selected using a lens magni\ufb01er. Map is hidden, due to privacy. ", "caption_bbox": [435, 705, 754, 743]}, {"image_id": 7, "file_name": "339_07.png", "page": 5, "dpi": 300, "bbox": [93, 530, 415, 595], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Found venues for a cluster in the inner city area, where venues are dense. From left to right: most likely main category, subcategory, subsubcategory with venue name. With higher detail certainty is decreasing. ", "caption_bbox": [93, 607, 412, 658]}, {"image_id": 8, "file_name": "339_08.png", "page": 5, "dpi": 300, "bbox": [434, 99, 756, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Map snippet showing clusters and found venues at cate- gory level 1. Top: Ungrouped icons may give better hints but clutter; Bottom: Aggregated icons avoid clutter. Map details are removed in the image due to privacy. ", "caption_bbox": [435, 327, 754, 378]}, {"image_id": 9, "file_name": "339_09.png", "page": 6, "dpi": 300, "bbox": [434, 485, 756, 691], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Map snippet. All users living in the \ufb01ltered suburb are selected. Routes show movements. Icons show frequently visited POIs. ", "caption_bbox": [435, 704, 754, 742]}, {"image_id": 10, "file_name": "339_10.png", "page": 6, "dpi": 300, "bbox": [136, 144, 377, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The analyst can integrate expert knowledge and change preselected categories on each level of detail. ", "caption_bbox": [93, 278, 412, 304]}, {"image_id": 11, "file_name": "339_11.png", "page": 7, "dpi": 300, "bbox": [435, 299, 757, 527], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Map snippet. An individual scooter is selected. Routes show movements. Icons visualize frequent visited POIs. Map details are removed for privacy protection. ", "caption_bbox": [435, 539, 754, 577]}, {"image_id": 12, "file_name": "339_12.png", "page": 7, "dpi": 300, "bbox": [87, 100, 757, 225], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Temporal component showing frequent temporal patterns per hour on a daily basis. It can be seen that at night times, the selected scooters are usually at home, while they are used to get to work and education at daytimes. In the early evening shopping becomes more frequent. ", "caption_bbox": [87, 238, 754, 276]}], "34": [{"image_id": 0, "file_name": "34_00.png", "page": 4, "dpi": 300, "bbox": [97, 652, 730, 1006], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: illustrating concept lattice indication previous and current occupations of survey participants in                                                 organisation Z ", "caption_bbox": [99, 1010, 726, 1043]}, {"image_id": 1, "file_name": "34_01.png", "page": 5, "dpi": 300, "bbox": [97, 460, 404, 813], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": " Figure 2: illustrating years of IT experience by      highest formal qualification achieved by             respondents in organisation Z Turning our attention to the tacit knowledge inventory results themselves we can see an example of a scenario (figure 3) Scenario 4 has been chosen in this instance along with answer 6. In response to the scenario, participants were asked to choose an ethical and realistic Likert value (Extremely Bad through to Extremely Good). Clearly the scenario given (Scenario 4) deals with IT managerial knowledge. However it is a knowledge set that is ", "caption_bbox": [96, 812, 388, 1009]}, {"image_id": 2, "file_name": "34_02.png", "page": 6, "dpi": 300, "bbox": [88, 106, 739, 457], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Sample scenario examining implicit articulable IT managerial knowledge for scenario 4, answer                                                 option 6 ", "caption_bbox": [99, 456, 727, 489]}, {"image_id": 3, "file_name": "34_03.png", "page": 6, "dpi": 300, "bbox": [101, 516, 726, 877], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Illustrating Formal Concept Analysis results for scenario 4, answer option 6 (note the disparity                                between expert choices versus non-experts) ", "caption_bbox": [102, 877, 724, 910]}, {"image_id": 4, "file_name": "34_04.png", "page": 7, "dpi": 300, "bbox": [117, 705, 710, 1037], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: illustrating FCA lattice result for scenario 8, answer option 2", "caption_bbox": [202, 1041, 622, 1058]}, {"image_id": 5, "file_name": "34_05.png", "page": 7, "dpi": 300, "bbox": [94, 125, 733, 522], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: illustrating scenario 8, answer option 2", "caption_bbox": [268, 526, 558, 543]}, {"image_id": 6, "file_name": "34_06.png", "page": 8, "dpi": 300, "bbox": [435, 559, 725, 843], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9 illustrating send the person an email or fax. Again note the direction of the edges in the                       graph. ", "caption_bbox": [438, 848, 726, 897]}, {"image_id": 7, "file_name": "34_07.png", "page": 8, "dpi": 300, "bbox": [439, 97, 727, 389], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "   Figure 8 illustrating HAVE to see and Very    important to see the person. Note again the  direction of the edges in the graph, indicated by                the break in the edge. If we examine figure 9 however, we can see a great deal of email interaction takes place, and principally from non-experts to experts. Note the individual represented in red at the top of the diagram has chosen not to present their gender and hence has been placed separately by the social ", "caption_bbox": [436, 393, 729, 558]}, {"image_id": 8, "file_name": "34_08.png", "page": 8, "dpi": 300, "bbox": [98, 262, 390, 535], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": " Figure 7 illustrating the clique among the non-                    expert group. We can note the strong HAVE to see the person directional flow from 3345 to 3337 in the diagram. Similarly non \u2013 expert employees 3334 (although 3337 noted they could get by without seeing 3334), 3337, 3344 and to some extent 3345 seem to be in demand for their services. If we examine our networks from a different point of view (Figure 8), namely the importance of certain individuals within the organization, we can build up a picture of who the more important people are. Perhaps not surprisingly figure 8 illustrates the importance of the expert sample group (namely those individuals ", "caption_bbox": [97, 540, 390, 769]}], "340": [{"image_id": 0, "file_name": "340_00.png", "page": 3, "dpi": 300, "bbox": [114, 263, 387, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: System Overview. The data module allows users to pre- process and \ufb01lter data. The visualization module supports the over- laying of temporal displays onto roads that are broadened by our extended seam carving algorithm. The interaction module provides rich user interactions to facilitate various analytical tasks. ", "caption_bbox": [90, 388, 412, 452]}, {"image_id": 1, "file_name": "340_01.png", "page": 4, "dpi": 300, "bbox": [106, 100, 744, 279], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Extended seam carving algorithm. (a) Uncontrolled seam carving on the map causes offsets, especially at the cross. (b) The optimal seam \ufb01nding direction for the rest of the map to avoid offsets among the broadening area and retargeting areas that results in (c). ", "caption_bbox": [90, 278, 764, 304]}, {"image_id": 2, "file_name": "340_02.png", "page": 4, "dpi": 300, "bbox": [437, 310, 752, 413], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparison of our algorithm with linear zooming. (a) A map with a road and a region of interest highlighted in the black rect- angle. (b) The result after broadening the road by 50 pixels. (c) The result after linearly enlarging the whole image by 300%. ", "caption_bbox": [434, 417, 756, 468]}, {"image_id": 3, "file_name": "340_03.png", "page": 4, "dpi": 300, "bbox": [438, 574, 752, 723], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Different encoding methods for time direction using road name (A), text labels, such as date and time (B), visual symbols, such as arrow (C) and color (D). ", "caption_bbox": [434, 729, 756, 768]}, {"image_id": 4, "file_name": "340_04.png", "page": 5, "dpi": 300, "bbox": [106, 101, 744, 296], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Comparison of different schemes to encode time direction.", "caption_bbox": [437, 546, 754, 559]}, {"image_id": 5, "file_name": "340_05.png", "page": 6, "dpi": 300, "bbox": [101, 322, 400, 487], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A synoptic view of the traf\ufb01c volume in the West Lake Dis- trict allows quick detection of interesting patterns and easy compari- son between multiple roads. ", "caption_bbox": [90, 490, 412, 529]}, {"image_id": 6, "file_name": "340_06.png", "page": 6, "dpi": 300, "bbox": [445, 196, 746, 404], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Time series curves representing the time consumed by taxis on each road segment of one Friday in one-way direction from location A to B. Different time saving routes could be found out at different times in a day. ", "caption_bbox": [435, 407, 757, 458]}, {"image_id": 7, "file_name": "340_07.png", "page": 7, "dpi": 300, "bbox": [97, 99, 399, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Charts show the mean response time (a) and subjective user ratings (b) for the user study with no label, a time text label, and a time axis label to indicate time direction. ", "caption_bbox": [90, 261, 412, 300]}], "341": [{"image_id": 0, "file_name": "341_00.png", "page": 1, "dpi": 300, "bbox": [436, 565, 755, 656], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Crisis Reports from Pakistan in the aftermath of the 2010", "caption_bbox": [437, 660, 755, 672]}, {"image_id": 1, "file_name": "341_01.png", "page": 3, "dpi": 300, "bbox": [91, 497, 414, 695], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Crisis Maps in action: left) Japan Quake Ushahidi Crisis", "caption_bbox": [95, 702, 408, 714]}, {"image_id": 2, "file_name": "341_02.png", "page": 4, "dpi": 300, "bbox": [104, 730, 408, 821], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Geo-Temporal Tag Visualization showing interactions on", "caption_bbox": [93, 829, 410, 841]}, {"image_id": 3, "file_name": "341_03.png", "page": 4, "dpi": 300, "bbox": [139, 209, 364, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Geo-Temporal Tag Visualization providing information on", "caption_bbox": [92, 324, 411, 336]}, {"image_id": 4, "file_name": "341_04.png", "page": 4, "dpi": 300, "bbox": [456, 235, 737, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Toolbar for filtering data. Users can either select a month", "caption_bbox": [437, 350, 755, 362]}, {"image_id": 5, "file_name": "341_05.png", "page": 5, "dpi": 300, "bbox": [436, 474, 757, 577], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (Left) SparkClouds from [10] adapted for the controlled", "caption_bbox": [442, 586, 749, 598]}, {"image_id": 6, "file_name": "341_06.png", "page": 5, "dpi": 300, "bbox": [434, 100, 775, 368], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Geo-Temporal Tag Visualization showing the crime data", "caption_bbox": [438, 375, 753, 387]}, {"image_id": 7, "file_name": "341_07.png", "page": 5, "dpi": 300, "bbox": [97, 100, 393, 389], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Geo-Temporal Tag Visualization showing the data", "caption_bbox": [101, 396, 387, 408]}, {"image_id": 8, "file_name": "341_08.png", "page": 6, "dpi": 300, "bbox": [460, 338, 733, 542], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Mean task completion time for each visualization.", "caption_bbox": [455, 550, 737, 562]}, {"image_id": 9, "file_name": "341_09.png", "page": 7, "dpi": 300, "bbox": [126, 762, 380, 966], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Mean task completion time for each group.", "caption_bbox": [124, 974, 378, 986]}, {"image_id": 10, "file_name": "341_10.png", "page": 7, "dpi": 300, "bbox": [131, 475, 375, 675], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Mean task completion time for each task type.", "caption_bbox": [116, 683, 386, 695]}, {"image_id": 11, "file_name": "341_11.png", "page": 7, "dpi": 300, "bbox": [91, 186, 415, 445], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Mean task completion time for each task.", "caption_bbox": [128, 455, 375, 467]}], "342": [{"image_id": 0, "file_name": "342_00.png", "page": 1, "dpi": 300, "bbox": [131, 60, 725, 510], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Mobile crime analytics system gives ubiquitous and context-aware analysis of law enforcement data to users.", "caption_bbox": [144, 522, 708, 535]}, {"image_id": 1, "file_name": "342_01.png", "page": 3, "dpi": 300, "bbox": [152, 99, 700, 450], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A screenshot of our mobile visual analytics law enforcement system. (left) Visualizing all CTC incidents for the city of Seattle, WA, USA on February 20, 2011. The map view (a) plots the incidents as color-coded points on a map (the legend for the points has been shown in the top-right window). The interactive time series view (b) plots the incident count over time with the estimated weighted moving average (EWMA) control chart overlaid. The bottom-left image (c) shows an overview+detail calendar view of the CTC incidents. (right) Visualizing all CTC incidents for Tippecanoe County, IN, for the month of February 2011. The county\u2019s census tracts have been overlaid on the map. The bottom right image (d) shows the interactive clock view to provide an hourly view of CTC incidents for the month selected. The interactive time slider (e) allows users to scroll through time and offers various temporal aggregation levels. ", "caption_bbox": [93, 456, 760, 548]}, {"image_id": 2, "file_name": "342_02.png", "page": 5, "dpi": 300, "bbox": [161, 99, 692, 531], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Risk profile visualizations at different times of day. The selected hour is shown by the dark green colored histogram bin, and the current time is shown as the orange colored bin. The \u00b13 window from the current selected hour are shown as the green colored histogram bins, and the rest of the histogram bins is colored as blue. ", "caption_bbox": [93, 532, 760, 571]}, {"image_id": 3, "file_name": "342_03.png", "page": 6, "dpi": 300, "bbox": [141, 100, 367, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Incidents with nearby localized high-frequency activity are highlighted in yellow to alert users of areas with suspicious criminal activity. ", "caption_bbox": [93, 254, 412, 293]}, {"image_id": 4, "file_name": "342_04.png", "page": 6, "dpi": 300, "bbox": [436, 100, 754, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Plume visualization. (left) The plume visualization dis- playing the different levels of danger zones. (right) The plume visu- alization showing census tracts colored on a sequential color scale to encode the number of people affected in each census tract, with respect to the maximum people affected in any tract. ", "caption_bbox": [435, 221, 754, 286]}], "343": [{"image_id": 0, "file_name": "343_00.png", "page": 1, "dpi": 300, "bbox": [89, 60, 767, 348], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The proposed visual analysis of covariation is performed on three levels of abstraction, demonstrated on a mouse mandible: A static overview (left) provides guidance to candidate points exhibiting non-trivial covariation patterns with the remaining shape. For a particular point p a focus visualization (center) reveals the underlying covariation pattern to p. By interactively dragging around p, details of the correlated shape variation can be investigated in a dynamic animation (right), uncovering also speci\ufb01c directional dependencies of covariation. ", "caption_bbox": [90, 360, 764, 411]}, {"image_id": 1, "file_name": "343_01.png", "page": 4, "dpi": 300, "bbox": [434, 99, 758, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview visualization of Mus dataset. Glyph size indi- cates strength of the interaction pattern T p associated with a partic- ular point (compare Fig. 8 to point B). Principal axes inform on edit directions d p with strong responses (compare Fig. 6 to point A). ", "caption_bbox": [435, 232, 757, 286]}, {"image_id": 2, "file_name": "343_02.png", "page": 5, "dpi": 300, "bbox": [442, 257, 766, 662], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: PCA eigenmodes of Mus dataset capturing 93% of the total variance. Shown are the vector\ufb01elds on a representative iso-surface decomposed into a surface orthogonal and tangential part, visualized color-coded and as vector glyphs respectively with glyphs of max. magnitude scaled to same length. (Visualization based on [42].) ", "caption_bbox": [435, 673, 757, 738]}, {"image_id": 3, "file_name": "343_03.png", "page": 5, "dpi": 300, "bbox": [123, 695, 378, 817], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Anatomical parts of the mouse mandible referred to in this work. A common subdivision [22] into 2 functional subunits is shown. ", "caption_bbox": [90, 830, 412, 856]}, {"image_id": 4, "file_name": "343_04.png", "page": 6, "dpi": 300, "bbox": [435, 99, 760, 255], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Local covariance \ufb01elds for probes at coronoid and condy- lar processes, probing points highlighted in red. A strong interaction in-between the two processes becomes apparent and shows the di- minishing impact on angular process and incisor. This \ufb01nding is in agreement with PLS analysis and results of Zelditch et al. [41]. ", "caption_bbox": [435, 267, 757, 331]}, {"image_id": 5, "file_name": "343_05.png", "page": 6, "dpi": 300, "bbox": [89, 138, 414, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Global anatomic covariance \ufb01eld [17] for Mus dataset. A lateral view is shown in the inset for comparison with Fig. 10. ", "caption_bbox": [90, 256, 412, 283]}, {"image_id": 6, "file_name": "343_06.png", "page": 6, "dpi": 300, "bbox": [435, 530, 759, 686], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Local covariance \ufb01elds for probes at incisor and angular process, probing points highlighted in red. Note that the incisor ten- sor \ufb01eld is scaled by a factor of 2.5 compared to all other \ufb01elds, at- tributed to the smaller overall interaction strength (see also Fig. 2). While the incisor probe produces a global covariation pattern, the covariation response of the angular process is locally concentrated. ", "caption_bbox": [435, 699, 757, 776]}, {"image_id": 7, "file_name": "343_07.png", "page": 6, "dpi": 300, "bbox": [91, 645, 414, 735], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Model-based editing on Mus dataset at coronoid process. Color coded from cool to warm (0                max) is the displace- ment magnitude from the template, whose silhouette is overlaid. In- set bar plots describe the \ufb01rst 5 PC coef\ufb01cients in units of standard deviations. Observe that varying the coronoid position is strongly associated with the condylar process (a), while changing its length impacts the rear of the mandible at a larger scale (b). ", "caption_bbox": [90, 748, 412, 838]}, {"image_id": 8, "file_name": "343_08.png", "page": 7, "dpi": 300, "bbox": [91, 135, 413, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Model-based editing on Mus dataset at incisor, same leg- end as in Fig. 6. Pulling the incisor in directions (a) and (b) leads to the expected elongation / foreshortening, seemingly correlated with the shape of the tips of the rear processes. Dragging the incisor orthogonally (c)-(d) keeps the front nearly rigid showing minor inter- action in the posterior part. ", "caption_bbox": [89, 321, 411, 399]}, {"image_id": 9, "file_name": "343_09.png", "page": 7, "dpi": 300, "bbox": [89, 561, 411, 682], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Close-ups of local covariance \ufb01elds for coronoid and condylar processes show their consistent interaction. While the lo- cal region close to each probe (highlighted in red) exhibits more isotropic covariation, the reaction pattern at the other process is more directed. This reveals which part of the global covariance \ufb01eld can be attributed to this particular interaction between the two processes. ", "caption_bbox": [89, 694, 411, 771]}, {"image_id": 10, "file_name": "343_10.png", "page": 8, "dpi": 300, "bbox": [89, 100, 766, 454], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: PLS analysis on Mus dataset with four different segmentations into white and red blocks as indicated in the insets, visualization design as in Fig. 4. Note the similarity of PLS1 for the rear processes which resembles the \ufb01rst mode PC1 (up to sign) of the global analysis. The variation patterns of PLS2 shows strong covariation between coronoid and condylar processes (top row) while the incisor affects more the angular process (bottom row). ", "caption_bbox": [89, 465, 763, 517]}], "344": [{"image_id": 0, "file_name": "344_00.png", "page": 1, "dpi": 300, "bbox": [107, 176, 745, 505], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Glass \ufb01ber reinforced polymer (GFRP) visualized using the FiberScout system.", "caption_bbox": [212, 520, 642, 533]}, {"image_id": 1, "file_name": "344_01.png", "page": 2, "dpi": 300, "bbox": [445, 560, 750, 959], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of the FiberScout visualization techniques.", "caption_bbox": [444, 970, 748, 983]}, {"image_id": 2, "file_name": "344_02.png", "page": 3, "dpi": 300, "bbox": [447, 756, 748, 931], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: 3D rendering of the datasets used in this paper. (A) GFRP specimen (dataset1), 15916 \ufb01bers. (B) GFRP specimen (dataset2), 21751 \ufb01bers. (C) CFRP specimen (dataset3), 22656 \ufb01bers. ", "caption_bbox": [435, 944, 757, 984]}, {"image_id": 3, "file_name": "344_03.png", "page": 5, "dpi": 300, "bbox": [91, 98, 765, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Fiber orientation distribution (FOD) in a PC plot. (A) Construction of the \ufb01ber orientations from Cartesian coordinates. (B) Global FOD (dataset1). (C) FOD of a single class (dataset1). ", "caption_bbox": [90, 310, 764, 337]}, {"image_id": 4, "file_name": "344_04.png", "page": 5, "dpi": 300, "bbox": [116, 601, 388, 931], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualization of the individual \ufb01ber orientations. (A) The spherical color map. (B) A direct volume rendering of the \ufb01bers using color-coded orientations (dataset2). ", "caption_bbox": [90, 945, 412, 985]}, {"image_id": 5, "file_name": "344_05.png", "page": 6, "dpi": 300, "bbox": [443, 564, 748, 889], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Fiber metadata visualization of dataset3 in detail. (A) Left: 3D view of the original volume data set with a red border slice. Right: Slice view of the original dataset. (B) Left: 3D view of the meta-volume overlaid on the original volume data. Right: Slice view of the semi-transparent meta-volume overlaid on the original volume data with a linear blending. ", "caption_bbox": [434, 903, 756, 983]}, {"image_id": 6, "file_name": "344_06.png", "page": 6, "dpi": 300, "bbox": [94, 421, 410, 622], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Blob visualization of dataset3. (A) 3D view of the dataset with unclassi\ufb01ed \ufb01bers in gray. (B) 3D view of the blue and orange class with labeled blobs (blue Class 1, 9403 \ufb01bers (41.50%) and (orange Class 2, 5831 \ufb01bers (25.74%)). ", "caption_bbox": [90, 636, 412, 689]}, {"image_id": 7, "file_name": "344_07.png", "page": 6, "dpi": 300, "bbox": [91, 96, 413, 351], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualization of the different \ufb01ber lengths. (A) 3D ren- dering of the \ufb01ber length distribution with the corresponding color map. (B) Fiber length distribution of dataset1 shown in Figure 6A. ", "caption_bbox": [90, 362, 412, 402]}, {"image_id": 8, "file_name": "344_08.png", "page": 7, "dpi": 300, "bbox": [439, 98, 757, 423], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Averaged results of the evaluation questionnaire.", "caption_bbox": [455, 436, 737, 449]}], "345": [{"image_id": 0, "file_name": "345_00.png", "page": 1, "dpi": 300, "bbox": [108, 60, 752, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Design of a new rib structure for a brake lever guided by tensor lines: From design concept to virtual and experimental part tests.", "caption_bbox": [102, 390, 753, 403]}, {"image_id": 1, "file_name": "345_01.png", "page": 2, "dpi": 300, "bbox": [455, 98, 743, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Common commercial brake lever from the manufacturer Avid. It has been used as a sample for our case study. (b) Reference geometry of a brake lever with the design space (red outlined), which is available for structural optimization. (c) FEM-simulation model with bolts for \ufb01xation and the area of the operating force application. ", "caption_bbox": [434, 356, 756, 420]}, {"image_id": 2, "file_name": "345_02.png", "page": 3, "dpi": 300, "bbox": [499, 99, 686, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The slope of the load-de\ufb02ection curve is an indicator for the stiffness of a technical part. It is used for the evaluation and comparison of the various brake levers designed in this case study. ", "caption_bbox": [434, 264, 756, 303]}, {"image_id": 3, "file_name": "345_03.png", "page": 4, "dpi": 300, "bbox": [434, 99, 759, 569], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Tensor visualizations of the stress tensor \ufb01eld that resulted from the simulation of a brake lever. Here, the design space was \ufb01lled with a solid with a Young\u2019s modulus multiple orders lower than the plastics one. (a) Brush-and-link framework (bottom right: region of highest shear selected in scatterplot, bottom left: Mohr diagram in which selected circles are displayed as full circles and others as half circles (see also [12]), top: tensor lines started at seed points that correspond to the selection in the scatterplot). (b) Fabric texture for the same dataset as in (a). The 3D lines do not signi\ufb01cantly vary in x-direction. Therefore, we reduced our observations to 2D slices that are parallel to the yz-plane. ", "caption_bbox": [434, 585, 756, 725]}, {"image_id": 4, "file_name": "345_04.png", "page": 5, "dpi": 300, "bbox": [474, 416, 718, 671], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: FEM-simulation results with highlighted maximum stress.", "caption_bbox": [438, 374, 753, 387]}, {"image_id": 5, "file_name": "345_05.png", "page": 5, "dpi": 300, "bbox": [475, 673, 719, 826], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Simple hand sketched lines following tensor lines used as basis for three new CAD-structures. ", "caption_bbox": [434, 842, 756, 868]}, {"image_id": 6, "file_name": "345_06.png", "page": 6, "dpi": 300, "bbox": [450, 420, 753, 554], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Resulting maximum von Mises stresses based on the FEM- simulation for the three new designs (red, green, yellow) in compari- son with the reference geometry (blue). ", "caption_bbox": [435, 569, 757, 608]}, {"image_id": 7, "file_name": "345_07.png", "page": 6, "dpi": 300, "bbox": [123, 98, 733, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: CAD models of the three rib structures designed along tensor lines and the corresponding FEM-simulation results. The maximum von Mises stresses are 126.5 MPa (1), 139.5 MPa (2), 134.4 MPa (3). ", "caption_bbox": [90, 366, 764, 392]}, {"image_id": 8, "file_name": "345_08.png", "page": 7, "dpi": 300, "bbox": [452, 337, 747, 547], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Load-de\ufb02ection curve s of the initial geometry in compar- ison with the tree tensor line driven parts. ", "caption_bbox": [434, 561, 756, 587]}, {"image_id": 9, "file_name": "345_09.png", "page": 7, "dpi": 300, "bbox": [457, 100, 750, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Test setup with \ufb01xed brake lever", "caption_bbox": [501, 308, 704, 321]}, {"image_id": 10, "file_name": "345_10.png", "page": 7, "dpi": 300, "bbox": [121, 100, 382, 542], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: 3D printed new brake lever geometries", "caption_bbox": [136, 555, 365, 568]}], "346": [{"image_id": 0, "file_name": "346_00.png", "page": 5, "dpi": 300, "bbox": [92, 100, 761, 367], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: VATT System Interface. (a) Taxi topic maps; (b) Street cloud; (c) Parallel Coordinate Plots of Streets and Trajectories; (d) Topic Routes. ", "caption_bbox": [92, 376, 759, 403]}, {"image_id": 1, "file_name": "346_01.png", "page": 5, "dpi": 300, "bbox": [93, 404, 761, 618], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Eight taxi topics shown on a Shenzhen map. Street clouds of four topics are shown in the corresponding colors.", "caption_bbox": [138, 627, 713, 640]}, {"image_id": 2, "file_name": "346_02.png", "page": 5, "dpi": 300, "bbox": [92, 646, 413, 826], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: PCP-based analysis of Topic2 streets of Fig. 2.", "caption_bbox": [116, 835, 387, 848]}, {"image_id": 3, "file_name": "346_03.png", "page": 6, "dpi": 300, "bbox": [437, 284, 761, 465], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Temporal change over one topic.", "caption_bbox": [492, 476, 696, 489]}, {"image_id": 4, "file_name": "346_04.png", "page": 6, "dpi": 300, "bbox": [93, 273, 414, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Topic routes of occupied taxis during the whole day .", "caption_bbox": [103, 369, 402, 382]}, {"image_id": 5, "file_name": "346_05.png", "page": 6, "dpi": 300, "bbox": [96, 100, 765, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Occupied and vacant taxi topics.", "caption_bbox": [325, 253, 529, 266]}, {"image_id": 6, "file_name": "346_06.png", "page": 7, "dpi": 300, "bbox": [93, 100, 762, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visualizing disappearing (brown) and emerging (orange) streets for a selected topic on maps and street clouds.", "caption_bbox": [139, 364, 714, 377]}, {"image_id": 7, "file_name": "346_07.png", "page": 8, "dpi": 300, "bbox": [88, 98, 412, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Taxi trajectories.", "caption_bbox": [184, 223, 313, 236]}], "347": [{"image_id": 0, "file_name": "347_00.png", "page": 2, "dpi": 300, "bbox": [90, 98, 413, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview of framework for visual inter-media comparison", "caption_bbox": [93, 334, 408, 346]}, {"image_id": 1, "file_name": "347_01.png", "page": 3, "dpi": 300, "bbox": [456, 100, 752, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Demonstrating on display wall (9 panels with 4k x 3k pixels)", "caption_bbox": [434, 354, 756, 366]}, {"image_id": 2, "file_name": "347_02.png", "page": 3, "dpi": 300, "bbox": [110, 100, 393, 418], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Of\ufb02ine news video indexing", "caption_bbox": [163, 423, 339, 435]}, {"image_id": 3, "file_name": "347_03.png", "page": 4, "dpi": 300, "bbox": [90, 99, 767, 549], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Overview of image clusters from blogs and TV", "caption_bbox": [295, 550, 559, 562]}, {"image_id": 4, "file_name": "347_04.png", "page": 5, "dpi": 300, "bbox": [434, 428, 766, 603], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Exploring interesting image clusters by using parallel coor- dinate view for dynamic query dialog ", "caption_bbox": [434, 610, 756, 635]}, {"image_id": 5, "file_name": "347_05.png", "page": 5, "dpi": 300, "bbox": [92, 434, 412, 677], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Two ways for arranging images from blogs and TV", "caption_bbox": [110, 685, 392, 697]}, {"image_id": 6, "file_name": "347_06.png", "page": 5, "dpi": 300, "bbox": [94, 99, 411, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualizing topics on blogs related to Great East Japan Earthquake, tsunami, nuclear power plant, and radioactivity: (a) Fukushima nuclear power plant incident, (b) photos of disaster area, (c) photo messages from Fukushima, (d) support for disaster area, (e) radioactive pollution, (f) documentary program on nuclear power pollution, (g) message from Studio Ghibli concerning anti-nuclear power and support for victims, (h) photos of tsunami, and (i) marches protesting nuclear power. ", "caption_bbox": [90, 301, 412, 401]}, {"image_id": 7, "file_name": "347_07.png", "page": 6, "dpi": 300, "bbox": [443, 99, 751, 553], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Image clusters related to Fukushima nuclear power plant incident in which images from TV lead images from blogs ", "caption_bbox": [435, 558, 757, 583]}, {"image_id": 8, "file_name": "347_08.png", "page": 7, "dpi": 300, "bbox": [438, 100, 754, 468], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Image \ufb02ows from blogs and TV having two peaks for Women\u2019s World Cup 2011 at same time ", "caption_bbox": [434, 474, 756, 499]}, {"image_id": 9, "file_name": "347_09.png", "page": 7, "dpi": 300, "bbox": [94, 100, 410, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Image cluster related to construction of nuclear power plant in which images from blogs were posted 2 days before TV ", "caption_bbox": [90, 313, 412, 338]}, {"image_id": 10, "file_name": "347_10.png", "page": 8, "dpi": 300, "bbox": [436, 99, 756, 378], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Images related to Ukiyo-e by Kuniyoshi Utagawa around 1831 ", "caption_bbox": [434, 383, 756, 408]}, {"image_id": 11, "file_name": "347_11.png", "page": 8, "dpi": 300, "bbox": [89, 99, 413, 524], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Difference among topics in neighboring countries", "caption_bbox": [109, 530, 393, 542]}], "348": [{"image_id": 0, "file_name": "348_00.png", "page": 2, "dpi": 300, "bbox": [449, 267, 741, 457], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview: (a) three curves measuring the energy at each timeslice in the \ufb02ow: ev (red), ec (blue), and er (green) (Sec. 4.4.1); (b) the \ufb02ow view of a dynamic graph with two enhanced paths (Sec. 4.4.2); (c) the graph view showing three timeslices selected from the \ufb02ow view with four nodes selected to show the splitting pattern (Sec. 5). ", "caption_bbox": [434, 463, 757, 527]}, {"image_id": 1, "file_name": "348_01.png", "page": 3, "dpi": 300, "bbox": [90, 509, 414, 566], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A line chart representation of a dynamic graph consisting of 23 nodes and 165 time points (the data of the youngest subject in Fig. 9). Nodes are represented by horizontal lines, which are sorted vertically based on the node degree at each time. ", "caption_bbox": [89, 573, 411, 624]}, {"image_id": 2, "file_name": "348_02.png", "page": 3, "dpi": 300, "bbox": [468, 333, 720, 396], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Vector generation and possible patterns: (a) vectors gener- ated by connecting all the tiles corresponding to the same vertex in temporal order; (b) a dynamic graph changing smoothly; (c) a dynamic graph changing more dramatically. ", "caption_bbox": [435, 402, 759, 453]}, {"image_id": 3, "file_name": "348_03.png", "page": 3, "dpi": 300, "bbox": [451, 465, 741, 538], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Assigning a vector to each pixel.", "caption_bbox": [496, 544, 695, 557]}, {"image_id": 4, "file_name": "348_04.png", "page": 3, "dpi": 300, "bbox": [116, 710, 395, 800], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An example of turning a dynamic graph into a tile matrix: vertices at each timeslice are sorted by their degree values. Color is used to encode the category of each vertex. ", "caption_bbox": [89, 807, 413, 846]}, {"image_id": 5, "file_name": "348_05.png", "page": 4, "dpi": 300, "bbox": [123, 98, 367, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Comparison: (a) input tile matrix; (b) LIC result; (c) LIC result with enhanced main trends; (d) our \ufb01nal result (main trend enhancement + color differentiation + alpha blending). ", "caption_bbox": [83, 310, 405, 349]}, {"image_id": 6, "file_name": "348_06.png", "page": 4, "dpi": 300, "bbox": [99, 358, 391, 441], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Rendering pipeline: (a) input tile matrix; (b) enhanced tile matrix; (c) re\ufb01ned tile matrix for individual colors; (d) LIC images for individual colors; (e) \ufb01nal result with alpha blending of all LIC images. ", "caption_bbox": [83, 447, 407, 486]}, {"image_id": 7, "file_name": "348_07.png", "page": 5, "dpi": 300, "bbox": [499, 98, 694, 160], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: An example of force settings for two links.", "caption_bbox": [474, 166, 717, 179]}, {"image_id": 8, "file_name": "348_08.png", "page": 6, "dpi": 300, "bbox": [89, 577, 414, 656], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The node-link diagram shows the behavior of two nodes of the default mode networks. While these two nodes are strongly corre- lated to each other (green links), they are also negatively correlated to the nodes of the other two regions (the gray regions). ", "caption_bbox": [90, 833, 414, 884]}, {"image_id": 9, "file_name": "348_09.png", "page": 6, "dpi": 300, "bbox": [90, 134, 414, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The degree changes of two nodes over time (highlighted as brown and orange) in two subjects: (a) similar evolution patterns in the middle-aged subject; (b)dissimilar trends in the older subject. ", "caption_bbox": [90, 660, 412, 699]}, {"image_id": 10, "file_name": "348_10.png", "page": 6, "dpi": 300, "bbox": [148, 719, 352, 827], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Number of Twitter accounts in the top 100 under each cate- gory for the bin Laden dataset and Linsanity dataset. ", "caption_bbox": [434, 898, 758, 924]}, {"image_id": 11, "file_name": "348_11.png", "page": 7, "dpi": 300, "bbox": [90, 99, 414, 495], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Flow summaries of the twitter datasets: (a) summary of bin Laden data (sorted by degree); (b) summary of bin Laden data (sorted by closeness); (c) summary of Linsanity data (sorted by degree). ", "caption_bbox": [90, 503, 412, 542]}], "349": [{"image_id": 0, "file_name": "349_00.png", "page": 1, "dpi": 300, "bbox": [214, 60, 642, 499], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Map of TVCG based on 1,343 TVCG titles in DBLP, heatmap overlay based on 34 papers by the most proli\ufb01c TVCG author. (Multi-Word Term extraction, C-Value with Unigrams ranking, Partial Match Jaccard Coef\ufb01cient similarity, Pull Lesser Terms \ufb01ltering, N = 1500.) The terms in the map are contained in 1,041 TVCG titles (78% coverage). ", "caption_bbox": [89, 505, 766, 545]}, {"image_id": 1, "file_name": "349_01.png", "page": 2, "dpi": 300, "bbox": [174, 100, 682, 375], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The main steps of the MoCS system are querying documents from DBLP, extracting terms from these titles, ranking terms by importance, calculating term similarity, further \ufb01ltering terms based on similarity, and \ufb01nally performing multidimensional scaling and clustering to produce a basemap, over which a heatmap can be overlaid. ", "caption_bbox": [90, 385, 766, 425]}, {"image_id": 2, "file_name": "349_02.png", "page": 3, "dpi": 300, "bbox": [434, 100, 759, 282], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Section of a single-word term map of 1,343 TVCG paper titles using the TF, LSA, and Pull Lesser Terms functions, with N = 1800. ", "caption_bbox": [435, 292, 757, 333]}, {"image_id": 3, "file_name": "349_03.png", "page": 3, "dpi": 300, "bbox": [88, 100, 414, 283], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Section of a multi-word term map of 1,343 TVCG paper titles using the C-Value with Unigrams, Partial Match Jaccard Coef\ufb01cient, and Pull Lesser Terms functions, with N = 1500. ", "caption_bbox": [89, 292, 411, 333]}, {"image_id": 4, "file_name": "349_04.png", "page": 5, "dpi": 300, "bbox": [453, 651, 740, 904], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A heatmap produced from 75 papers by the author who has published most frequently at NIPS, over a basemap made from 3,553 NIPS papers, using C-Value with Unigrams ranking, Partial Match Jaccard Coef\ufb01cient similarity, and Pull Lesser Terms \ufb01ltering, with N = 1100. The basemap terms are contained in 2,770 NIPS documents (78% coverage). ", "caption_bbox": [434, 914, 758, 994]}, {"image_id": 5, "file_name": "349_05.png", "page": 6, "dpi": 300, "bbox": [140, 100, 707, 575], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Conference and journal heatmaps overlaid on a map generated from 70,000 paper titles, sampled uniformly from all available DBLP papers, using C-value With Unigrams, Partial Match Jaccard Coef\ufb01cient, and Pull Lesser Terms, with N = 1500. The basemap terms are contained in 1,660,311 of 2,184,055 DBLP papers (76% coverage). ", "caption_bbox": [90, 588, 764, 628]}, {"image_id": 6, "file_name": "349_06.png", "page": 7, "dpi": 300, "bbox": [99, 100, 755, 516], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Heatmaps of six decades of papers from Journal of the ACM (JACM). Basemap is generated from multi-word terms extracted from the titles of 1,998 paper titles published in JACM, using the C-Value with Unigrams ranking, Partial Match Jaccard Coef\ufb01cient similarity, and Pull Lesser Terms \ufb01ltering functions, with N = 1400. 200 paper titles were sampled uniformly from the JACM\u2019s publications for each decade to create the heatmaps. Full resolution images are available at http://mocs.cs.arizona.edu/figures.php. The basemap terms are contained in 1,543 titles from JACM (77% coverage). ", "caption_bbox": [89, 528, 763, 594]}], "35": [], "350": [{"image_id": 0, "file_name": "350_00.png", "page": 2, "dpi": 300, "bbox": [456, 99, 691, 435], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A small example of power-graph decomposition.", "caption_bbox": [434, 451, 708, 464]}, {"image_id": 1, "file_name": "350_01.png", "page": 3, "dpi": 300, "bbox": [92, 99, 412, 160], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The optimal solution for a single module (shaded) is not in the optimal solution for two modules (dashed lines). ", "caption_bbox": [90, 172, 412, 198]}, {"image_id": 2, "file_name": "350_02.png", "page": 3, "dpi": 300, "bbox": [96, 218, 405, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The construction G  .", "caption_bbox": [178, 346, 321, 362]}, {"image_id": 3, "file_name": "350_03.png", "page": 4, "dpi": 300, "bbox": [434, 98, 759, 374], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The search space of module con\ufb01gurations for a given graph is a tree structure. Here we highlight several nodes in the very large search space of module con\ufb01gurations for the graph shown in Figure 2. A solid arrow indicates a direct child relationship in the search tree. That is, the child con\ufb01guration is obtained from a single merge operation from the parent. A dotted arrow indicates the target con\ufb01guration is reachable from the source via multiple merges. ", "caption_bbox": [434, 386, 756, 475]}, {"image_id": 4, "file_name": "350_04.png", "page": 6, "dpi": 300, "bbox": [433, 364, 767, 565], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison of running times for Beam Search with various beam sizes and Greedy Jaccard Clustering heuristic. ", "caption_bbox": [435, 571, 757, 597]}, {"image_id": 5, "file_name": "350_05.png", "page": 6, "dpi": 300, "bbox": [435, 99, 763, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparison of cost versus graph size for the various power graph decomposition heuristics. ", "caption_bbox": [435, 331, 757, 357]}, {"image_id": 6, "file_name": "350_06.png", "page": 7, "dpi": 300, "bbox": [106, 1027, 740, 1094], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Flat and power graph renderings of a graph with 10 nodes and 51 edges. It is interesting to note that the reduction in clutter from (b) to (c) is fairly obvious, however, the qualitative improvement from (c) to (d) is less dramatic. Layouts were obtained using the yEd software (http://yfiles.com) using a combination of automatic layout and manual re\ufb01nement with automatic edge routing. ", "caption_bbox": [79, 817, 753, 856]}], "351": [{"image_id": 0, "file_name": "351_00.png", "page": 1, "dpi": 300, "bbox": [424, 60, 766, 485], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The KEGG Citrate Cycle (TCA Cycle), a metabolic pathway as shown on the KEGG website. The green enzyme boxes indicate enzymes present in human. ", "caption_bbox": [435, 498, 757, 537]}, {"image_id": 1, "file_name": "351_01.png", "page": 3, "dpi": 300, "bbox": [522, 272, 671, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: If a node of an inter edge is invisible, it is redirected to the \ufb01rst visible parental group node. Redirected edges are represented using dashes. ", "caption_bbox": [434, 326, 756, 365]}, {"image_id": 2, "file_name": "351_02.png", "page": 3, "dpi": 300, "bbox": [90, 374, 414, 613], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Important characteristics of KEGG maps: A,B,C, and D show some typical layout features. E and E\u2019 refer to the multiple representation of a reaction. ", "caption_bbox": [90, 625, 412, 664]}, {"image_id": 3, "file_name": "351_03.png", "page": 4, "dpi": 300, "bbox": [542, 99, 650, 211], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Reaction 1.3.99.1 is not present in human and removing it results in a gap. This gap can be closed by moving reaction 1.3.5.1 to the left. Otherwise, our calculated layout would have up to four additional and unnecessary bends, since we route the edges orthog- onally through the center of the reaction nodes (blue dashed line). ", "caption_bbox": [434, 227, 756, 291]}, {"image_id": 4, "file_name": "351_04.png", "page": 4, "dpi": 300, "bbox": [526, 756, 676, 898], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Part of the Phenylalanine Metabolism pathway, where the reaction 2.1.3.13 has two optimal graphical reaction directions if only counting its minimum-required number of bends. By counting the minimum-required number of bends of all neighbored reactions (2.1.3.13 and 2.3.1.192), we can correctly determine a vertical direc- tion. ", "caption_bbox": [434, 915, 756, 992]}, {"image_id": 5, "file_name": "351_05.png", "page": 4, "dpi": 300, "bbox": [136, 758, 369, 933], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Showing two excerpts of Figure 2. The reaction 1.8.1.4 and their compounds are represented twice (duplication) to avoid long edges and crossings in the KEGG map. ", "caption_bbox": [90, 946, 412, 985]}, {"image_id": 6, "file_name": "351_06.png", "page": 5, "dpi": 300, "bbox": [102, 101, 750, 373], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparison of the original TCA Cycle on the left and the human-speci\ufb01c part of this pathway produced by our approach on the right.", "caption_bbox": [93, 387, 762, 400]}, {"image_id": 7, "file_name": "351_07.png", "page": 6, "dpi": 300, "bbox": [92, 728, 411, 930], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Data mapping capabilities of BiNA presented using parts of the Phenylalanine Metabolism. An example data set is mapped to the enzyme color, enzyme size, edge thickness, and edge color. ", "caption_bbox": [90, 945, 412, 984]}, {"image_id": 8, "file_name": "351_08.png", "page": 6, "dpi": 300, "bbox": [108, 101, 749, 418], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison of the original Glycerolipid Metabolism from KEGG on the left and the version of this pathway laid out and reduced to the human-speci\ufb01c part by our approach on the right. Single reactions disconnected from the rest of the pathway have been removed. ", "caption_bbox": [90, 433, 764, 459]}, {"image_id": 9, "file_name": "351_09.png", "page": 7, "dpi": 300, "bbox": [91, 100, 765, 765], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The overview map of three KEGG pathways produced with BiNA.", "caption_bbox": [247, 780, 606, 793]}], "352": [{"image_id": 0, "file_name": "352_00.png", "page": 1, "dpi": 300, "bbox": [124, 60, 728, 551], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: OnionGraph interface showing the bibliographic network in the visualization community. (a) Main OnionGraph panel visualizing the author-paper-venue heterogeneous network. Venues (right column) are expanded into single journal/conference entities; papers (central column) are expanded by their citation count groups; authors (left column) are expanded by their neighborhood attributes, i.e., the publication pro\ufb01le of low/medium/high-citation papers. The layout improves PivotGraph grid-like layout [27]. (b) Con\ufb01guration panel for OnionGraph abstraction. The current abstraction control speci\ufb01es the pro\ufb01le of the selected author node in the left column of the main panel. (c) Filter panel which is con\ufb01gured to only show authors who publish more than 10 papers, and edges which connect author-paper (\u201cauthorize\u201d type) and paper-venue (\u201cpublish\u201d type). (d) Legend panel showing the icons and colors used in the current network. (e) The selected node list which includes authors with many high-citation papers. (f) Details of \u201cKaufman, A\u201d, all the statistics (e.g., h-index) are computed within the visualization paper dataset. ", "caption_bbox": [93, 553, 760, 654]}, {"image_id": 1, "file_name": "352_01.png", "page": 3, "dpi": 300, "bbox": [442, 98, 742, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: OnionGraph structure featuring \ufb01ve hierarchies below the original network: networks by semantic aggregations (SA) on node type (heterogeneous abstraction) and node attributes, Relative Reg- ular Equivalence (RRE), Strong Structural Equivalence (SSE), and the node-level network in the \ufb01nest granularity. In each hierarchy, the network can be expanded on certain focuses (red regions) into their lower-hierarchy details (blue regions). ", "caption_bbox": [434, 342, 753, 430]}, {"image_id": 2, "file_name": "352_02.png", "page": 4, "dpi": 300, "bbox": [438, 99, 747, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: OnionGraph network partitions (undirected case). In each sub\ufb01gure, node \ufb01ll color indicates the partition index: (a) semantic aggregation, the selected attribute value is labeled on the node; (b) a regular equivalence partition; (c) the regular equivalence relative to the semantic aggregation in (a); (d) strong structural equivalence. ", "caption_bbox": [434, 250, 753, 313]}, {"image_id": 3, "file_name": "352_03.png", "page": 5, "dpi": 300, "bbox": [439, 98, 753, 176], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: OnionGraph network abstraction performance (SA).", "caption_bbox": [452, 220, 734, 233]}, {"image_id": 4, "file_name": "352_04.png", "page": 6, "dpi": 300, "bbox": [493, 99, 694, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: An OnionGraph network visualization of the author-paper- venue bibliographic network in the visualization community. Three author groups indicate different connection patterns: normal authors with co-authors and publications, special authors who only write single-authored papers, and anomalous authors without a publica- tion (potential errors in the data set). Four venue groups indicate the conferences/journals on different topics. ", "caption_bbox": [434, 285, 753, 373]}, {"image_id": 5, "file_name": "352_05.png", "page": 7, "dpi": 300, "bbox": [109, 99, 399, 439], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualization bibliographic network analysis: (a) Initial view; (b) Venues expanded; (c) Papers expanded by citation categories. ", "caption_bbox": [93, 442, 412, 468]}, {"image_id": 6, "file_name": "352_06.png", "page": 8, "dpi": 300, "bbox": [158, 100, 698, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: HUA communication network visual analytics.", "caption_bbox": [298, 246, 557, 259]}], "353": [{"image_id": 0, "file_name": "353_00.png", "page": 2, "dpi": 300, "bbox": [474, 99, 716, 182], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Mushroom data table shown in part.", "caption_bbox": [483, 184, 704, 197]}, {"image_id": 1, "file_name": "353_01.png", "page": 3, "dpi": 300, "bbox": [117, 99, 390, 259], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Using word cloud (SparkClouds) to depict categorical data feature of the mushroom data. For each dimension, the font size re\ufb02ects the number of categories and the color represents the entropy of the dimension. The graph line of each word shows the data frequency of each category. ", "caption_bbox": [94, 262, 413, 328]}, {"image_id": 2, "file_name": "353_02.png", "page": 4, "dpi": 300, "bbox": [79, 99, 775, 331], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Using joint entropy and mutual information in navigating scatter plot matrix.", "caption_bbox": [220, 335, 635, 348]}, {"image_id": 3, "file_name": "353_03.png", "page": 5, "dpi": 300, "bbox": [86, 100, 413, 652], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visualizations of the mushroom dataset with parallel sets.", "caption_bbox": [92, 661, 411, 674]}, {"image_id": 4, "file_name": "353_04.png", "page": 5, "dpi": 300, "bbox": [436, 193, 745, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualization of the mushroom data \ufb01ltered by setting an entropy threshold of 1.0 to remove low diversity dimensions. ate visualization results that promote better knowledge discovery. We modify the minimization optimization [32] to a maximization solution of the sum of mutual information with respect to all dif- ferent orders of categorical dimensions. This implementation uses Hamiltonian path algorithms and creates optimal ordering. ", "caption_bbox": [435, 329, 754, 426]}, {"image_id": 5, "file_name": "353_05.png", "page": 5, "dpi": 300, "bbox": [466, 100, 724, 173], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Sorting categories between two categorical dimensions", "caption_bbox": [439, 175, 748, 188]}, {"image_id": 6, "file_name": "353_06.png", "page": 6, "dpi": 300, "bbox": [436, 99, 746, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visualizations of the congressional voting dataset. The optimization is applied by using mutual information for dimen- sion ordering and sorting categories over axes. Classi\ufb01cation of the congressmen is the leftmost dimension where green represents Democracy and reed represents Republican. ", "caption_bbox": [434, 397, 753, 463]}, {"image_id": 7, "file_name": "353_07.png", "page": 6, "dpi": 300, "bbox": [81, 102, 417, 519], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visualizations with different ordering methods of multiple coordinates, improving the original visualization of Fig. 4(b) which uses the reading order of dimensions and the alphabetical sequence of categories on axes. ", "caption_bbox": [94, 545, 413, 598]}, {"image_id": 8, "file_name": "353_08.png", "page": 7, "dpi": 300, "bbox": [94, 99, 408, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Visualizations of the congressional voting dataset. The optimization is applied by using mutual information for dimension ordering and sorting categories over axes. The leftmost dimension is the votes of education-spending. Here, blue represents voting for nay, red represents voting for yea, and gray is for unknown. nate ordering and category sequence optimization. Without optimal category sorting on axes, mutual information based ordering (green bars) also achieved good results. These results indicate that by us- ing entropy-based measures users can identify more insights in a limited time. In contrast, the crossing based optimization (red bars) does not provide better results in T2/T3 than original visualization (blue bars). ", "caption_bbox": [93, 397, 412, 560]}, {"image_id": 9, "file_name": "353_09.png", "page": 8, "dpi": 300, "bbox": [91, 101, 764, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: User study results of the mushroom dataset. (a) Average percentage of user \ufb01ndings over ground truth on each task, attained with different visual representations. (b) Total performance of user \ufb01ndings using different visualizations. (c) Total error rate of user \ufb01ndings using different visualizations. ", "caption_bbox": [86, 245, 753, 285]}], "354": [{"image_id": 0, "file_name": "354_00.png", "page": 1, "dpi": 300, "bbox": [435, 592, 759, 705], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Graphs for computing scagnostics measures.", "caption_bbox": [466, 720, 726, 733]}, {"image_id": 1, "file_name": "354_01.png", "page": 2, "dpi": 300, "bbox": [97, 99, 405, 423], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Example scatterplots and their scagnostics measures.", "caption_bbox": [100, 437, 402, 450]}, {"image_id": 2, "file_name": "354_02.png", "page": 2, "dpi": 300, "bbox": [436, 684, 755, 794], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Three scatterplots of life expectancy of male vs. female in 1982,1983, and 1984. ", "caption_bbox": [434, 811, 756, 837]}, {"image_id": 3, "file_name": "354_03.png", "page": 2, "dpi": 300, "bbox": [104, 656, 401, 762], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: a) Monotonic distribution b) Stringy distribution c) Striated distribution. ", "caption_bbox": [90, 775, 412, 801]}, {"image_id": 4, "file_name": "354_04.png", "page": 4, "dpi": 300, "bbox": [84, 100, 757, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Schematic overview of ScagExplorer.", "caption_bbox": [308, 315, 531, 328]}, {"image_id": 5, "file_name": "354_05.png", "page": 5, "dpi": 300, "bbox": [435, 432, 758, 933], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visualizing the Breast Cancer, US employment, and Sub- way data. The leader plots in each dataset are colored and aligned by Striated, Stringy, and Outlying respectively. ", "caption_bbox": [434, 946, 756, 985]}, {"image_id": 6, "file_name": "354_06.png", "page": 5, "dpi": 300, "bbox": [93, 98, 412, 950], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualizing the leader scatterplots in the Sonar, Communi- ties, Madelon, and Arcene data. ", "caption_bbox": [90, 963, 412, 989]}, {"image_id": 7, "file_name": "354_07.png", "page": 6, "dpi": 300, "bbox": [107, 549, 398, 835], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Expanding all scatterplots of a cluster in the Libras data.", "caption_bbox": [95, 849, 406, 862]}, {"image_id": 8, "file_name": "354_08.png", "page": 6, "dpi": 300, "bbox": [436, 287, 759, 562], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Density distribution of scatterplots by each scagnostic.", "caption_bbox": [444, 575, 747, 588]}, {"image_id": 9, "file_name": "354_09.png", "page": 7, "dpi": 300, "bbox": [434, 405, 765, 516], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Three clusters in the Monte Carlo test dataset.", "caption_bbox": [460, 530, 732, 543]}, {"image_id": 10, "file_name": "354_10.png", "page": 7, "dpi": 300, "bbox": [89, 100, 413, 465], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Filtering high Monotonic scatterplots (Monotonicity \u2265 0.5) in the NRC university ranking data. ", "caption_bbox": [89, 476, 411, 503]}, {"image_id": 11, "file_name": "354_11.png", "page": 7, "dpi": 300, "bbox": [436, 100, 763, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Computation times (in hours) for large datasets where n is the number of observations and p is the number of scatterplots. ", "caption_bbox": [435, 362, 757, 388]}, {"image_id": 12, "file_name": "354_12.png", "page": 8, "dpi": 300, "bbox": [86, 98, 415, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Force-directed layout produces nine clusters in the Monte Carlo test dataset. Scatterplots are colored by their Monotonicity. ", "caption_bbox": [90, 340, 412, 366]}], "355": [{"image_id": 0, "file_name": "355_00.png", "page": 3, "dpi": 300, "bbox": [94, 505, 415, 949], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Changes in parallel-coordinates plots upon basic transfor- mations, as illustrated by a 2D ELLIPSE. ", "caption_bbox": [94, 950, 413, 976]}, {"image_id": 1, "file_name": "355_01.png", "page": 3, "dpi": 300, "bbox": [96, 99, 758, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview of the six major steps in our visualization pipeline: 1) surface construction to generate a set of grid points; 2) blue-noise surface sampling to obtain a sample point set; 3) interactive N-D transformation (rotation and projection); 4) parallel-coordinates plots with visual signatures; 5) enhanced visual signatures (e.g., emphasize high curvature areas); and 6) interactive exploration with brushing. ", "caption_bbox": [94, 289, 761, 327]}, {"image_id": 2, "file_name": "355_02.png", "page": 4, "dpi": 300, "bbox": [97, 99, 758, 203], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Example correspondences between geometrical properties and visual signatures in parallel-coordinates plots: two simple geometric models are used: a 2D ELLIPSE ((a) and (b)) and a 3D E LLIPTICAL CYLINDER ((c) and (d)). ", "caption_bbox": [93, 202, 760, 228]}, {"image_id": 3, "file_name": "355_03.png", "page": 4, "dpi": 300, "bbox": [106, 236, 746, 391], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparing different sampling approaches to generate continuous parallel-coordinates plots on the 4D K NOTTED SPHERE model. All approaches use 3000 sample points in 4D, and blue-noise sampling produces the highest-quality visualization. ", "caption_bbox": [93, 390, 760, 416]}, {"image_id": 4, "file_name": "355_04.png", "page": 5, "dpi": 300, "bbox": [96, 100, 743, 374], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Interactive parallel-coordinates visualization upon dynamic subspace rotation in N-dimensions. The three 4D geometric models used here are T ORUS, T ORUS K NOT- LIKE, and F ERMAT SURFACE (from left to right column). ", "caption_bbox": [86, 373, 753, 399]}, {"image_id": 5, "file_name": "355_05.png", "page": 5, "dpi": 300, "bbox": [434, 767, 752, 956], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Interactive parallel-coordinates visualization upon dynamic subspace rotation in N-dimensions of 6D V ERONESE model. ", "caption_bbox": [434, 955, 753, 981]}, {"image_id": 6, "file_name": "355_06.png", "page": 6, "dpi": 300, "bbox": [94, 99, 411, 259], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Using AND and OR brushing modes on the same set of brush points. We highlight related surface regions in red. ", "caption_bbox": [93, 260, 412, 287]}, {"image_id": 7, "file_name": "355_07.png", "page": 6, "dpi": 300, "bbox": [452, 99, 735, 243], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Other than mean curvature (see Figure 8), we can also choose to show min or max curvature. ", "caption_bbox": [435, 244, 754, 270]}, {"image_id": 8, "file_name": "355_08.png", "page": 7, "dpi": 300, "bbox": [97, 99, 756, 422], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Two example scenarios of depicting curvature (on the 3D projection view and the parallel-coordinates plots) and brushing the curvature feature lines in the plots. Left: P ILLOW model and Right: K LEIN 2 model. ", "caption_bbox": [93, 424, 760, 450]}], "356": [{"image_id": 0, "file_name": "356_00.png", "page": 1, "dpi": 300, "bbox": [89, 60, 763, 382], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The Cars data set shown using the classic parallel coordinates plot (PCP) on the left, and our new edge-bundling layout on the right. Our method clusters the data in each dimension, and sets these clusters in relation to each other by bundling the lines between two axes. The bundles are then rendered using polygonal strips. This generates an abstract, clutter-reduced version of the classic PCP. We provide intuitive interactions such as the shown axis-based selection, where all clusters of a chosen axis are automatically selected using a different color. In this example, this has been done for the Weight axis. The colors will merge and split at other axes, thereby revealing the relations in a data set. ", "caption_bbox": [94, 394, 761, 457]}, {"image_id": 1, "file_name": "356_01.png", "page": 2, "dpi": 300, "bbox": [424, 274, 756, 1094], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Simple example showing the Gaussian kernel density esti- mate for six observation points. A wide Gaussian kernel (left) leads to less clusters than a narrow kernel (right). ", "caption_bbox": [435, 207, 754, 245]}, {"image_id": 2, "file_name": "356_02.png", "page": 3, "dpi": 300, "bbox": [434, 100, 756, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visual layout between two data axes A and B. Edges are bundled near each data axis according to the clusters in each dimen- sion. To do so, we form a cubic B\u00e9zier spline out of three segments. ", "caption_bbox": [435, 278, 754, 316]}, {"image_id": 3, "file_name": "356_03.png", "page": 3, "dpi": 300, "bbox": [92, 100, 413, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Normalized Gaussian kernel density estimations for dif- ferent \u03c3 creating different numbers of clusters k for the Horsepower variable of the Cars data set. ", "caption_bbox": [92, 310, 411, 348]}, {"image_id": 4, "file_name": "356_04.png", "page": 3, "dpi": 300, "bbox": [435, 326, 756, 941], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison of the different PCP layouts. Shown are three dimensions from the Cars data set. ", "caption_bbox": [435, 957, 754, 983]}, {"image_id": 5, "file_name": "356_05.png", "page": 4, "dpi": 300, "bbox": [448, 99, 600, 321], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Construction of the polygonal strip be- tween a data axis and its bundling axis. This de- \ufb01nes the appearance of the clusters around each axis. ", "caption_bbox": [599, 137, 717, 225]}, {"image_id": 6, "file_name": "356_06.png", "page": 5, "dpi": 300, "bbox": [108, 338, 755, 441], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Interactive quick selection modes. Hovering with the cursor over a cluster or axis automatically highlights parts of the data set. ", "caption_bbox": [320, 284, 761, 310]}, {"image_id": 7, "file_name": "356_07.png", "page": 5, "dpi": 300, "bbox": [93, 99, 763, 218], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Arbitrary selections speci\ufb01ed in      (a) Hovering over a cluster creates a selection of all (b) Hovering over an axis automatically selects all its                                                     its observation points. This quickly reveals their     clusters with a different color. Here, we hover with other visualizations are shown coherently by                                                     distribution on other axes.                            the mouse cursor over the weight axis. Note how our polygonal strips using color blending. This                                                                                                            the colors merge in other regions, e.g., the violet way, our method can be applied in Linking &                                                                                                            color at the left. Brushing scenarios. ", "caption_bbox": [94, 219, 761, 285]}, {"image_id": 8, "file_name": "356_08.png", "page": 6, "dpi": 300, "bbox": [87, 99, 762, 284], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The results of our user study show that our bundled PCP increases the users\u2019 accuracy in complex visual data analysis tasks. The plots show error measures: lower values are better. The vertical bars denote the 95% con\ufb01dence interval. See the text for details. ", "caption_bbox": [87, 301, 754, 327]}, {"image_id": 9, "file_name": "356_09.png", "page": 7, "dpi": 300, "bbox": [434, 403, 756, 496], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: The netperf data set visualized using the edge-bundling method of McDonnell and Mueller [18]. Left: k-means clustering for k = 3. Note how the multidimensional clusters overlap on several axes. Right: When merging two clusters (red+green=orange), the edge-bundling of [18] changes the bending of the curves. ", "caption_bbox": [434, 508, 753, 571]}, {"image_id": 10, "file_name": "356_10.png", "page": 7, "dpi": 300, "bbox": [434, 99, 756, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Our method is an abstract version of the classic PCP. It retains some of its visual characteristics and adds new possibilities such as faster interactions. ", "caption_bbox": [434, 351, 753, 389]}, {"image_id": 11, "file_name": "356_11.png", "page": 7, "dpi": 300, "bbox": [92, 99, 414, 577], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The out5d data set with 16384 observation points shown without selection, with single selections, and with several selections at once. Left: classic PCP. Right: our method. ", "caption_bbox": [93, 589, 412, 627]}, {"image_id": 12, "file_name": "356_12.png", "page": 8, "dpi": 300, "bbox": [93, 99, 415, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Biomechanical data set with 116732 observation points.", "caption_bbox": [97, 327, 409, 340]}], "357": [{"image_id": 0, "file_name": "357_00.png", "page": 1, "dpi": 300, "bbox": [457, 747, 733, 923], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Topological skeleton: Sinks (and saddle-sink separatrices) are red, sources (and saddle-source separatrices) green, and saddles blue. (a) A highly rotational \ufb02ow \ufb01eld where the pointed critical points are close to Hopf-bifurcations. Numerical inac- curacies may accumulate during integration and separatrices may intersect or switch. (b)-(c) Instability of separatrices under a small perturbation: The upper right sink is not connected with the saddle on the left in (b), but is after a small perturbation in (c). ", "caption_bbox": [435, 930, 757, 1001]}, {"image_id": 1, "file_name": "357_01.png", "page": 2, "dpi": 300, "bbox": [434, 99, 758, 216], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Figure adapted from [29]. Suppose the vector \ufb01eld is continuous, where sinks are red, sources are green, and saddles are blue. From left to right: vector \ufb01elds  f , relations among components of Fr , and augmented merge trees. f contains four critical points, a sink x1 , a source x3 , and two saddles x2 and x4 . We use \u03b2 , \u03b3, \u03c9, etc. to represent components of certain sublevel sets. ", "caption_bbox": [434, 219, 756, 278]}, {"image_id": 2, "file_name": "357_02.png", "page": 3, "dpi": 300, "bbox": [435, 99, 757, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a)-(b): Illustrative examples for uncovered (a) and covered (b) boundaries of im (C). (c): A component and its image space with a few mappings highlighted. ", "caption_bbox": [434, 278, 756, 302]}, {"image_id": 3, "file_name": "357_03.png", "page": 4, "dpi": 300, "bbox": [83, 100, 752, 209], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a)-(b) Locating a cut point for the Cut operation: (a) Track the angle (a.k.a. phase) of a point in im (\u2202C) along S as we move along \u2202C counter-clockwise. (b) The corresponding phase plot (a.k.a. angle-valued function) is shown in blue. The result of phase-unwrapping is shown in red. (c)-(e) Locating an unwrap point in Unwrap operation: (c) Track the angle of a point in im (\u2202C) along S as we move along \u2202C counter-clockwise. (d) The corresponding angle-valued function (shown in blue), the result of phase-unwrapping (shown in red), and the optimal unwrap point c\u2217 corresponding to phase \u03c6 \u2217 . (e) The modi\ufb01ed boundary of im (C) (shown in purple), which becomes uncovered. ", "caption_bbox": [82, 208, 756, 258]}, {"image_id": 4, "file_name": "357_04.png", "page": 4, "dpi": 300, "bbox": [119, 268, 370, 398], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Cut operation. Left: The projection of edges that intersect during the Cut operation. Right: After Cut, the light blue region represents im (C), which no longer contains (covers) the origin and so is critical point free. ", "caption_bbox": [90, 397, 412, 432]}, {"image_id": 5, "file_name": "357_05.png", "page": 4, "dpi": 300, "bbox": [439, 631, 751, 836], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: SyntheticA. (a) The original vector \ufb01eld: sinks are red, sources are green and saddles are blue. (b) The topological skeleton: saddle-sink separatrices are red and saddle-source separatrices are green. (c)-(d) 1st level simpli\ufb01cation: before (c) and af- ter (d) Smoothing. (e)-(f) 2nd level simpli\ufb01cation: before (e) and after (f) Smoothing. ", "caption_bbox": [434, 836, 756, 883]}, {"image_id": 6, "file_name": "357_06.png", "page": 5, "dpi": 300, "bbox": [89, 771, 413, 855], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: SyntheticC. The image space is shown through the different steps: (a) origi- nal, (b) after Unwrap, (c) after Cut, and (d) \ufb01nal output after Restore. ", "caption_bbox": [89, 860, 411, 883]}, {"image_id": 7, "file_name": "357_07.png", "page": 5, "dpi": 300, "bbox": [89, 243, 413, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: SyntheticC. (a) the original vector \ufb01eld with topological skeleton. (b)-(c) Before (b) and after (c) simpli\ufb01cation by combining Unwrap, Cut and Smoothing. ", "caption_bbox": [89, 360, 411, 383]}, {"image_id": 8, "file_name": "357_08.png", "page": 5, "dpi": 300, "bbox": [94, 100, 405, 206], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: SyntheticB. (a) the original vector \ufb01eld with its topological skeleton. (a)-(b): Single level simpli\ufb01cation before (a) and after (b) by Cut and Smoothing. (c) Only applying Smoothing does not make the region a critical point free \ufb01eld. ", "caption_bbox": [89, 205, 411, 240]}, {"image_id": 9, "file_name": "357_09.png", "page": 5, "dpi": 300, "bbox": [435, 99, 759, 187], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: SyntheticC. Left: The phase plot, original version (blue), and the phase- unwrapped version (red). Right: The phase plot with optimal unwrap point (orange) and the modi\ufb01ed phase plot with boundary uncovered (purple). ", "caption_bbox": [435, 193, 757, 228]}, {"image_id": 10, "file_name": "357_10.png", "page": 6, "dpi": 300, "bbox": [109, 520, 744, 775], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: The OceanA dataset: (a) #20311; (b)-(c) #21217. (a)-(b) For each sub\ufb01gure, Top Row: Left \u2013 shows robustness values with region of interest highlighted; Right \u2013 shows the vector \ufb01eld marked by critical point types and its topological skeleton. Bottom Row: results after distance-based (left) and robustness-based simpli\ufb01cations (right). (c) A region (yellow boundary) with a nontrivial Conley index and uncovered boundary (top), where smoothing does not remove its critical points (bottom). ", "caption_bbox": [90, 775, 764, 810]}, {"image_id": 11, "file_name": "357_11.png", "page": 6, "dpi": 300, "bbox": [170, 98, 684, 482], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: (a) The OceanB dataset. (b) The OceanC dataset. For each sub\ufb01gure: Top Row: Left \u2013 shows robustness values with the region of interest highlighted (robustness values are colored from red to white, where red means low and white means high robustness); Right \u2013 shows the vector \ufb01eld marked by critical point types along with separatrices. Middle Row: the two-step hierarchical simpli\ufb01cation based on distance. Bottom Row: the two-step hierarchical simpli\ufb01cation based on robustness. ", "caption_bbox": [90, 482, 764, 517]}, {"image_id": 12, "file_name": "357_12.png", "page": 7, "dpi": 300, "bbox": [176, 511, 678, 762], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: The Combustion dataset. The bottom-up hierarchical simpli\ufb01cations (Top) from the distance-based strategy and (Bottom) from the robustness-based strategy.", "caption_bbox": [113, 763, 742, 774]}, {"image_id": 13, "file_name": "357_13.png", "page": 7, "dpi": 300, "bbox": [119, 100, 738, 470], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: The OceanD dataset. (a) A sampled time series with pairs of critical points highlighted, where white numbers indicate time stamps. (b) #21710. (c) #21715. For each sub\ufb01gure (b)-(c), Top Row: The original vector \ufb01eld (left) and with the separatrices (right). Middle Row: The simpli\ufb01cation ordering for the distance-based strategy. Bottom Row: The simpli\ufb01cation ordering for the robustness-based strategy. Orderings for distance and robustness-based methods are consistent in (b) and different in (c). ", "caption_bbox": [90, 470, 764, 505]}], "358": [{"image_id": 0, "file_name": "358_00.png", "page": 1, "dpi": 300, "bbox": [132, 60, 749, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The similarity of the underlying \ufb01eld to the counter oriented double vortex is encoded in the brightness of the circles.", "caption_bbox": [135, 371, 720, 384]}, {"image_id": 1, "file_name": "358_01.png", "page": 3, "dpi": 300, "bbox": [101, 99, 407, 477], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The \ufb01rst complex monomials interpreted as 2D vector \ufb01elds visualized with line integral convolution (LIC) [3] and a color map rep- resenting the velocity. Blue means low and red high velocity. ", "caption_bbox": [94, 493, 413, 531]}, {"image_id": 2, "file_name": "358_02.png", "page": 3, "dpi": 300, "bbox": [439, 310, 750, 599], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Normalization of the triangle from equation (6)", "caption_bbox": [463, 615, 724, 628]}, {"image_id": 3, "file_name": "358_03.png", "page": 4, "dpi": 300, "bbox": [437, 99, 755, 201], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Effect of the rotation operator R\u03b1 applied to an example vector \ufb01eld in three different ways. ", "caption_bbox": [435, 217, 754, 243]}, {"image_id": 4, "file_name": "358_04.png", "page": 6, "dpi": 300, "bbox": [434, 595, 755, 802], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Query patterns selected from Figure 6 bottom.", "caption_bbox": [462, 818, 725, 831]}, {"image_id": 5, "file_name": "358_05.png", "page": 6, "dpi": 300, "bbox": [107, 514, 400, 618], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Errors due to discretization with a resolution of 0.1 (discr.), total rotation (rot.), outer translation (tr.), outer scaling (sc.), and evenly distributed noise with SNR = 3.5 (noise). The lines connect- ing the points are for visualization purposes only. ", "caption_bbox": [93, 636, 412, 687]}, {"image_id": 6, "file_name": "358_06.png", "page": 6, "dpi": 300, "bbox": [436, 163, 753, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Line integral convolution of the dataset. The colors repre- sent the velocity of the \ufb01eld: blue is slow, red ist fast. ", "caption_bbox": [434, 360, 753, 386]}, {"image_id": 7, "file_name": "358_07.png", "page": 7, "dpi": 300, "bbox": [443, 294, 760, 481], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Similarity of the dataset to the saddle vortex combination with distortions by different signal to noise ratios. ", "caption_bbox": [434, 497, 753, 523]}, {"image_id": 8, "file_name": "358_08.png", "page": 7, "dpi": 300, "bbox": [96, 100, 759, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: For comparison, the similarity to the saddle vortex combination was laid over the LIC of the \ufb02ow \ufb01eld with removed mean \ufb02ow.", "caption_bbox": [111, 257, 741, 270]}, {"image_id": 9, "file_name": "358_09.png", "page": 7, "dpi": 300, "bbox": [95, 294, 412, 484], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Similarity of the dataset to the vortex saddle pattern.", "caption_bbox": [107, 499, 397, 512]}, {"image_id": 10, "file_name": "358_10.png", "page": 8, "dpi": 300, "bbox": [97, 99, 759, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: For comparison, the similarity to the double vortex saddle pattern was laid over the LIC of the \ufb01eld with removed mean \ufb02ow.", "caption_bbox": [114, 256, 739, 269]}], "359": [{"image_id": 0, "file_name": "359_00.png", "page": 1, "dpi": 300, "bbox": [89, 60, 766, 558], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The visualization results for Hurricane Isabel dataset. (a)(b)(c) show results at time step 0. (a) On the projection view, two groups of points are selected. Each point represents the pathline starting from a spatiotemporal point. (b) In the attribute matrix, the selected pathlines are projected in individual scatterplots in the matrix. Each selected group in (a) appears to be clustered in attribute space. (c) In the spatial view, the spatial distribution of the corresponding pathlines are visualized. (d) shows the projection view and spatial view of corresponding pathlines at time step 4, 8, 12, 16, and 20. ", "caption_bbox": [90, 558, 764, 622]}, {"image_id": 1, "file_name": "359_01.png", "page": 3, "dpi": 300, "bbox": [90, 98, 414, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The Eulerian-based (a) and Lagrangian-based (b) attribute space projection for unsteady \ufb02ow. ", "caption_bbox": [90, 360, 412, 386]}, {"image_id": 2, "file_name": "359_02.png", "page": 4, "dpi": 300, "bbox": [93, 96, 761, 227], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The logical pipeline of Lagrangian-based attribute space projection.", "caption_bbox": [243, 232, 606, 245]}, {"image_id": 3, "file_name": "359_03.png", "page": 4, "dpi": 300, "bbox": [442, 259, 766, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The out-of-sample extension to Pivot MDS for multireso- lution analysis: (a) low resolution (34,560 samples), (b) high resolu- tion, out-of-sample extension (138,240 samples), (c) high resolution, direct projection (the same number of samples as in (b)). ", "caption_bbox": [434, 364, 756, 415]}, {"image_id": 4, "file_name": "359_04.png", "page": 5, "dpi": 300, "bbox": [93, 98, 760, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The parallel system design. The scalable Pivot MDS is tightly integrated into DStep framework. The pivot pathlines and all other pathlines are traced in the pivot phase and the distance phase, respectively. The projection is done after the distance matrices are computed. ", "caption_bbox": [90, 303, 764, 329]}, {"image_id": 5, "file_name": "359_05.png", "page": 5, "dpi": 300, "bbox": [91, 333, 765, 503], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Timings tested on parallel environment with different numbers of processes. In (a), (b), and (c), three parameters related to problem size, including number of samples n, number of pivots k, and the time window size tc , are changed respectively. ", "caption_bbox": [90, 503, 764, 530]}, {"image_id": 6, "file_name": "359_06.png", "page": 6, "dpi": 300, "bbox": [439, 98, 756, 307], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The projection results of Hurricane Isabel dataset with dif- ferent distance metrics and parameters. Weights of attributes \u03c9 and tc are shown with results except (a) use distance metric in geometric space. Pseudo-color is used to visualize the difference between the projection results. ", "caption_bbox": [434, 312, 756, 376]}, {"image_id": 7, "file_name": "359_07.png", "page": 7, "dpi": 300, "bbox": [99, 427, 761, 537], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The LASP results and the spatial views for two runs from GEOS-5 ensembles at May 2000. Slight differences can be observed in projection results. By selecting two regions in projection plot, corresponding pathlines are shown in spatial views. Signi\ufb01cant divergence exists in northern hemisphere for these two runs, while they are similar in southern part. ", "caption_bbox": [89, 545, 763, 584]}, {"image_id": 8, "file_name": "359_08.png", "page": 7, "dpi": 300, "bbox": [96, 99, 765, 381], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The visualization of GEOS-5 simulation dataset with the proposed method. Two clusters are selected in the projection view, and the corresponding pathlines are shown in the spatial views. Pathlines are also mapped in the attribute matrix to show the numerical distributions of the selected features. ", "caption_bbox": [89, 383, 763, 422]}], "36": [{"image_id": 0, "file_name": "36_00.png", "page": 2, "dpi": 300, "bbox": [85, 519, 406, 670], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Data grid for discrete two-dimensional survey data before (a) and after (b) distortion which aligns coor- dinate quadrants with categories in the survey data. ", "caption_bbox": [83, 685, 405, 727]}, {"image_id": 1, "file_name": "36_01.png", "page": 3, "dpi": 300, "bbox": [86, 328, 404, 629], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Cubic Hermite-Linear Lagrange interpolation of sample values at the corners of a square element. ", "caption_bbox": [83, 657, 404, 685]}, {"image_id": 2, "file_name": "36_02.png", "page": 4, "dpi": 300, "bbox": [85, 75, 404, 196], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Graphs of the linear B-Spline filter (solid line), the quadratic B-Spline filter (dashed line) and the cubic B-Spline filter (dotted line). ", "caption_bbox": [83, 230, 405, 272]}, {"image_id": 3, "file_name": "36_03.png", "page": 4, "dpi": 300, "bbox": [85, 524, 404, 664], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Graph of the Catmull-Rom spline.", "caption_bbox": [121, 681, 367, 695]}, {"image_id": 4, "file_name": "36_04.png", "page": 4, "dpi": 300, "bbox": [427, 481, 752, 727], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: VRML file of a height field constructed from a 2D survey and viewed with the Cortona VRML viewer. ", "caption_bbox": [427, 741, 748, 769]}, {"image_id": 5, "file_name": "36_05.png", "page": 5, "dpi": 300, "bbox": [82, 524, 407, 753], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The 2D example survey data interpolated with radial basis functions. ", "caption_bbox": [83, 766, 404, 794]}, {"image_id": 6, "file_name": "36_06.png", "page": 5, "dpi": 300, "bbox": [427, 416, 752, 649], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The 2D example survey data interpolated with a bilinear B-Spline reconstruction filter. ", "caption_bbox": [427, 663, 748, 691]}, {"image_id": 7, "file_name": "36_07.png", "page": 5, "dpi": 300, "bbox": [427, 55, 752, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The 2D example survey data interpolated with a Catmull-Rom spline reconstruction filter. ", "caption_bbox": [427, 295, 748, 323]}, {"image_id": 8, "file_name": "36_08.png", "page": 6, "dpi": 300, "bbox": [82, 693, 407, 921], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The 2D example survey data interpolated with a bicubic B-Spline reconstruction filter. ", "caption_bbox": [83, 935, 404, 963]}, {"image_id": 9, "file_name": "36_09.png", "page": 6, "dpi": 300, "bbox": [427, 406, 752, 641], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The 2D example survey data interpolated with a bicubic endpoint-interpolating NURBS surface. ", "caption_bbox": [427, 655, 748, 683]}, {"image_id": 10, "file_name": "36_10.png", "page": 6, "dpi": 300, "bbox": [82, 170, 407, 395], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The 2D example survey data interpolated with a biquadratic B-Spline reconstruction filter. ", "caption_bbox": [83, 409, 404, 437]}], "360": [{"image_id": 0, "file_name": "360_00.png", "page": 2, "dpi": 300, "bbox": [442, 98, 753, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) shows the isosurfaces constructed for the \ufb01ve critical points data set. Each closed surface indicates one critical region in the \ufb02ow \ufb01eld. (b) shows the simpli\ufb01ed triangle meshes constructed from the isosurfaces in (a) where a region with small volume size (smaller than 1/1000 of the total \ufb02ow \ufb01eld volume) is \ufb01ltered out in ad- vance. (c) indicates all viewpoints generated on the simpli\ufb01ed mesh surface. Spheres indicate viewpoint positions while red and blue ar- rows indicate look-at and up directions, respectively. ", "caption_bbox": [434, 245, 753, 347]}, {"image_id": 1, "file_name": "360_01.png", "page": 2, "dpi": 300, "bbox": [99, 99, 411, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) is the entropy \ufb01eld of the \ufb01ve critical points data set. (b) shows the critical regions identi\ufb01ed from the entropy \ufb01eld. Different colors are for different regions. (c) shows skeleton lines extracted from critical regions. ", "caption_bbox": [93, 218, 412, 269]}, {"image_id": 2, "file_name": "360_02.png", "page": 3, "dpi": 300, "bbox": [99, 98, 412, 227], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) shows an offset surface of one critical region of the \ufb01ve critical points data set where color mapping indicates viewpoint quality. Each black point indicates one best viewpoint. (b) shows the B-spline curve path that connects selected viewpoints in (a). The red, green and blue arrows indicate the look-at, up and binormal directions of each viewpoint, respectively. (c) shows the \ufb01nal global B-spline curve path traversing all critical regions. ", "caption_bbox": [93, 228, 412, 316]}, {"image_id": 3, "file_name": "360_03.png", "page": 3, "dpi": 300, "bbox": [440, 98, 753, 211], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Parameter in\ufb02uence. (a) and (b) show critical regions de- tected for the ABC \ufb02ow data set with two different \u03b4e values. (c) and (d) depict the skeleton of a critical region for the tornado data set with two different \u03b4t values. (e) and (f) show the simpli\ufb01ed meshes for the electron data set with two different \u03b4s values. ", "caption_bbox": [434, 213, 753, 278]}, {"image_id": 4, "file_name": "360_04.png", "page": 4, "dpi": 300, "bbox": [441, 252, 752, 409], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparing (a) skeleton-based seeding and (b) random seeding for the \ufb01ve critical points data set. Both place 320 stream- lines. Velocity magnitude is mapped to streamline color. ", "caption_bbox": [435, 410, 754, 448]}, {"image_id": 5, "file_name": "360_05.png", "page": 5, "dpi": 300, "bbox": [434, 541, 755, 722], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: FlowTour screenshots for the tornado data set. (b) to (e) show the respective views from four different viewpoints along the tour path as marked in (a). ", "caption_bbox": [434, 725, 753, 763]}, {"image_id": 6, "file_name": "360_06.png", "page": 5, "dpi": 300, "bbox": [89, 364, 766, 491], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: FlowTour screenshots for the \ufb01ve critical points data set. The \ufb01ve critical points are two spirals (a) and (b), two saddles (c) and (d), and a source (e). (f) shows the connection between a spiral and the source. ", "caption_bbox": [97, 492, 764, 518]}, {"image_id": 7, "file_name": "360_07.png", "page": 5, "dpi": 300, "bbox": [89, 98, 767, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: FlowTour screenshots for the solar plume data set. (b) to (g) show the respective views from six different viewpoints along the tour path as marked in (a). Tube radius is decreased in (a) for all streamlines so that the view path can be perceived. ", "caption_bbox": [97, 324, 764, 350]}, {"image_id": 8, "file_name": "360_08.png", "page": 6, "dpi": 300, "bbox": [100, 287, 758, 406], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: FlowTour vs. random tour for the two swirls data set. (a) and (d) show the tour paths for FlowTour and random tour, respectively. (b) and (c) are screenshots from FlowTour, while (e) and (f) are screenshots from random tour. The corresponding two viewpoints for the two methods are marked in (a) and (d), respectively. Tube radius is decreased in (a) and (d) for all streamlines so that the view path can be perceived. ", "caption_bbox": [94, 407, 761, 445]}, {"image_id": 9, "file_name": "360_09.png", "page": 6, "dpi": 300, "bbox": [100, 99, 759, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: FlowTour vs. external tour for the supernova data set. (a) shows the bounding sphere and the selected best viewpoints for external tour. (b) and (c) are screenshots corresponding to two different viewpoints for external tour. (d) and (e) are screenshots from FlowTour. ", "caption_bbox": [94, 247, 761, 273]}, {"image_id": 10, "file_name": "360_10.png", "page": 7, "dpi": 300, "bbox": [445, 98, 756, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: (a) Average proportion of correct answers of multiple- choice questions for each data set. (b) Average proportion of critical regions identi\ufb01ed correctly for each data set. For the supernova data set, the score with the random and external paths is zero. ", "caption_bbox": [435, 271, 754, 322]}], "361": [{"image_id": 0, "file_name": "361_00.png", "page": 1, "dpi": 300, "bbox": [114, 60, 742, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Single moving objects are grouped into larger visual representations to reduce visual clutter and overlap. On the left we show individual vessels in a harbor visualized using vessel glyphs, while on the right we show them grouped and visualized using aggregated multivariate glyphs. ", "caption_bbox": [90, 364, 764, 388]}, {"image_id": 1, "file_name": "361_01.png", "page": 2, "dpi": 300, "bbox": [466, 860, 726, 944], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The areas of in\ufb02uence of subsets S and T overlap with the area of overlap \u03c9o (A) or the penetration depth \u03c9 (B). ", "caption_bbox": [434, 960, 756, 986]}, {"image_id": 2, "file_name": "361_02.png", "page": 4, "dpi": 300, "bbox": [157, 100, 698, 184], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Our subset glyph (D) is composed of a Type Pie (A) showing the distribution of object types, a heading ring (B) showing the types and number of objects moving in a select number of direction ranges, and a Stationary Disc (C) showing the proportion of stationary objects. A number of design choices for the stationary ring: A translucent disc (E), a solid disc (F), and a ring (G). ", "caption_bbox": [90, 199, 764, 236]}, {"image_id": 3, "file_name": "361_03.png", "page": 4, "dpi": 300, "bbox": [158, 250, 698, 460], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An application of our partition method in the maritime domain (A). Through interaction the user can investigate point groups: By holding the mouse over a glyph, the user can see the spatial distribution of the points in the subset, and by clicking on a glyph the user can see statistics of the vessels in the subset (B), such as the distribution of vessel types, vessel velocities or vessel states (e.g., the vessel is stationary). ", "caption_bbox": [90, 474, 764, 511]}, {"image_id": 4, "file_name": "361_04.png", "page": 5, "dpi": 300, "bbox": [128, 100, 732, 424], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: In our user study we show two red squares containing a distribution of points each for the static tests (A), and for the dynamic test we split the screen into four numbered quadrants (B). The visualizations used are Msingle (C), M part (D), and Mdens (E). ", "caption_bbox": [90, 438, 764, 464]}, {"image_id": 5, "file_name": "361_05.png", "page": 6, "dpi": 300, "bbox": [458, 332, 748, 714], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Plots of the mean correctness with a con\ufb01dence interval of 95% are shown for each visualization method for each static test separated by data set size (top) and percentage difference between the left and right hand size (bottom). ", "caption_bbox": [434, 727, 756, 777]}, {"image_id": 6, "file_name": "361_06.png", "page": 6, "dpi": 300, "bbox": [91, 99, 764, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A scatter plot of the mean response time versus the mean correctness for each visualization for tasks Ti where each point represents a single subject. Each test Ti has 9 unique con\ufb01gurations, resulting in 9 possible values for mean correctness. ", "caption_bbox": [90, 281, 764, 305]}, {"image_id": 7, "file_name": "361_07.png", "page": 7, "dpi": 300, "bbox": [89, 99, 414, 237], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The homogeneous subsets for mean correctness and re- sponse time for T1 and T2 for all combinations of n and p, and ps and p, respectively. S is Msingle , P is M part , and D is Mdens . Signi\ufb01cant results are highlighted. Our method is never signi\ufb01cantly the worst. ", "caption_bbox": [89, 245, 411, 295]}], "362": [{"image_id": 0, "file_name": "362_00.png", "page": 2, "dpi": 300, "bbox": [126, 99, 383, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Resampling a streamline traced from the cray\ufb01sh data set. The red dots are resampled points. ", "caption_bbox": [94, 230, 413, 256]}, {"image_id": 1, "file_name": "362_01.png", "page": 3, "dpi": 300, "bbox": [100, 101, 761, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Characters generated from a two-level bottom-up af\ufb01nity propagation clustering of the cray\ufb01sh data set. (a) shows the 11 high-level cluster centers, which are assigned to characters a to k in order. (b) shows the 23 members in the cluster highlighted with a box in (a), which are low-level cluster centers. (c) shows the 24 members in the cluster highlighted with a box in (b). ", "caption_bbox": [93, 219, 760, 257]}, {"image_id": 2, "file_name": "362_02.png", "page": 3, "dpi": 300, "bbox": [454, 280, 736, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Character concatenation. The blue and red lines indicate the neighborhoods of blue and red sample points, respectively. (a) characters are assigned to all sample points. r \u2212 1 sample points are shared by the neighborhoods of blue and red sample points, which produce a deterministic shape. (b) and (c) characters are assigned to every r \u2212 1 sample points. Only one point is shared by the neigh- borhoods, which produces different shapes. ", "caption_bbox": [434, 367, 753, 455]}, {"image_id": 3, "file_name": "362_03.png", "page": 4, "dpi": 300, "bbox": [103, 99, 404, 206], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Matching results using the cray\ufb01sh data set. A zoomed-in view is used to show a partial volume for clearer observation. (a) and (b) show respectively, exact match results for patterns EE and FF, where E (F) is a spiral pattern with large (small) torsion (refer to Figure 2 (a)). (c) and (d) show respectively, exact and approximate (k = 15) match results for pattern (E|F)(E|F). ", "caption_bbox": [93, 213, 412, 290]}, {"image_id": 4, "file_name": "362_04.png", "page": 5, "dpi": 300, "bbox": [441, 293, 752, 530], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Alphabet widget (a), vocabulary widget (b), and query string widget (c) with the solar plume data set. Streamline widget (d) with the computer room data set. (a) shows the alphabet visual- ization where the last character is created by the user to match either G, K or L. (b) shows the \ufb01rst page of the vocabulary widget. (c) shows a query string in the forms of text and polyline. (d) shows the user- selected query segment on the upper-left subwindow (where two red spheres are used to delimitate the blue segment as the query pat- tern), all streamlines on the lower-left subwindow, and the query re- sult on the right subwindow. ", "caption_bbox": [435, 537, 754, 663]}, {"image_id": 5, "file_name": "362_05.png", "page": 6, "dpi": 300, "bbox": [99, 417, 757, 584], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Case study for the plume data set. (a) to (d) show streamline segments matched by four automatically generated words. (e) to (h) show query results when the previously generated alphabet is used for newly traced streamlines. (e) and (f) show streamline segments matched by two words. (g) and (h) show the concatenation of the two words using | and &, respectively. ", "caption_bbox": [93, 591, 760, 631]}, {"image_id": 6, "file_name": "362_06.png", "page": 6, "dpi": 300, "bbox": [99, 100, 757, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Case study for the cray\ufb01sh data set. (a) to (d) show streamline segments matched by four automatically generated words. (e) to (h) show query results of (A|I)+(D|E|F|K)(D|E|F|K), (A|I)(A|I)+(D|E|F|K)(D|E|F|K), (A|I)???(D|E|F|K)(D|E|F|K), and (A|I)*(D|E|F|K)(D|E|F|K), respectively. ", "caption_bbox": [93, 364, 760, 405]}, {"image_id": 7, "file_name": "362_07.png", "page": 7, "dpi": 300, "bbox": [99, 100, 410, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Case study for the tornado data set. (a) shows all stream- lines. (b) shows query results for a user-selected streamline seg- ment with different settings. (c) and (d) show streamline segments matched by two automatically generated words. ", "caption_bbox": [93, 368, 412, 419]}, {"image_id": 8, "file_name": "362_08.png", "page": 7, "dpi": 300, "bbox": [456, 100, 733, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Case study for the two swirls data set. (a) shows all stream- lines. (b) shows the query result for a user-selected streamline seg- ment with the minimum number of repetition q = 1. (c) and (d) show query results for a user-selected streamline segment with q = 0 and q = 1, respectively. ", "caption_bbox": [434, 347, 753, 412]}], "363": [{"image_id": 0, "file_name": "363_00.png", "page": 2, "dpi": 300, "bbox": [478, 755, 716, 808], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The vertex-restricted operation replaces two arcs by their unique area-equivalent arc. ", "caption_bbox": [435, 822, 757, 848]}, {"image_id": 1, "file_name": "363_01.png", "page": 3, "dpi": 300, "bbox": [159, 605, 344, 687], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Solution v  lies on line L through p Signed area for a  is given in gray. Non-optimal solution is used for illustration. ", "caption_bbox": [90, 697, 412, 726]}, {"image_id": 2, "file_name": "363_02.png", "page": 3, "dpi": 300, "bbox": [453, 693, 739, 745], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A non-vertex-restricted solution (right) may more accurately re\ufb02ect shape compared to vertex-restricted solutions (middle). ", "caption_bbox": [434, 758, 756, 784]}, {"image_id": 3, "file_name": "363_03.png", "page": 3, "dpi": 300, "bbox": [452, 99, 740, 173], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A planar solution exists if vi\u22121 and vi+2 lie on different sides of L. Arcs a  and a   are a straight line at l1 and l2 respectively. ", "caption_bbox": [434, 186, 756, 213]}, {"image_id": 4, "file_name": "363_04.png", "page": 3, "dpi": 300, "bbox": [95, 99, 409, 222], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a-b) Symmetric difference \u03941 and \u03942 of the area-equivalent arc replacing ai\u22121 and ai , and ai and ai+1 , respectively. (c) Point p is located at fraction \u0394 \u0394+\u0394                         2  along the perimeter of ai . ", "caption_bbox": [90, 234, 412, 276]}, {"image_id": 5, "file_name": "363_05.png", "page": 4, "dpi": 300, "bbox": [158, 770, 698, 951], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (Top) China with \ufb02at 8-arc and 13-arc schematizations on the left and curvy 4-arc and 13-arc schematizations on the right. (Bottom) Australia with \ufb02at 6-arc and 15-arc schematizations on the left and with curvy 6-arc and 15-arc schematizations on the right. ", "caption_bbox": [90, 964, 764, 990]}, {"image_id": 6, "file_name": "363_06.png", "page": 5, "dpi": 300, "bbox": [482, 448, 710, 674], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Pop-art rendering of a curvy Italy.", "caption_bbox": [490, 688, 700, 701]}, {"image_id": 7, "file_name": "363_07.png", "page": 5, "dpi": 300, "bbox": [185, 100, 318, 160], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Vertex v is to be smoothed (bend exaggerated). Circle C contains exactly the positions where the arcs meet smoothly. ", "caption_bbox": [89, 173, 411, 199]}, {"image_id": 8, "file_name": "363_08.png", "page": 5, "dpi": 300, "bbox": [447, 100, 742, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Sketchy rendering of a \ufb02at 12-arc France using [29].", "caption_bbox": [449, 222, 740, 235]}, {"image_id": 9, "file_name": "363_09.png", "page": 5, "dpi": 300, "bbox": [101, 214, 401, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Regular 13-arc schematization of France. Smoothing a nearly smooth bend may reduce visual complexity without compro- mising on shape. Tangents are indicated. ", "caption_bbox": [89, 348, 411, 387]}, {"image_id": 10, "file_name": "363_10.png", "page": 5, "dpi": 300, "bbox": [466, 252, 722, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Stroked rendering of a regular 12-arc Vietnam.", "caption_bbox": [459, 418, 732, 431]}, {"image_id": 11, "file_name": "363_11.png", "page": 6, "dpi": 300, "bbox": [445, 99, 749, 249], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: For Task 2, users were asked to match a schematic shape to one of four alternatives, only one of which is correct. In this exam- ple the third is the correct answer. ", "caption_bbox": [435, 262, 757, 301]}, {"image_id": 12, "file_name": "363_12.png", "page": 6, "dpi": 300, "bbox": [449, 634, 745, 805], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Sample of shapes (China outline) provided in user test. Columns show curvy, regular, \ufb02at, and straight schematization. Rows show low, medium and high level of similarity. ", "caption_bbox": [435, 818, 757, 857]}, {"image_id": 13, "file_name": "363_13.png", "page": 7, "dpi": 300, "bbox": [101, 807, 411, 960], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Style preference by gender and age.", "caption_bbox": [138, 976, 363, 989]}, {"image_id": 14, "file_name": "363_14.png", "page": 7, "dpi": 300, "bbox": [98, 99, 407, 417], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Pro\ufb01les of the 303 respondents who completed all tasks.", "caption_bbox": [91, 432, 410, 445]}, {"image_id": 15, "file_name": "363_15.png", "page": 7, "dpi": 300, "bbox": [495, 99, 702, 249], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Simplicity judgement by age.", "caption_bbox": [502, 264, 690, 277]}, {"image_id": 16, "file_name": "363_16.png", "page": 7, "dpi": 300, "bbox": [449, 691, 746, 941], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 17: Accuracy (top) and response time (bottom) for recogniz- ability. For each combination of style and simpli\ufb01cation n \u2248 450. Error bars indicate 95%-con\ufb01dence intervals. ", "caption_bbox": [435, 953, 757, 992]}, {"image_id": 17, "file_name": "363_17.png", "page": 8, "dpi": 300, "bbox": [110, 772, 393, 852], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 18: 6-arc Antarctica: regular (middle) and curvy style (right). Antarctica is unsuitable for the curvy style produced by our algorithm. ", "caption_bbox": [89, 865, 411, 891]}], "364": [{"image_id": 0, "file_name": "364_00.png", "page": 1, "dpi": 300, "bbox": [160, 119, 689, 461], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Interface of TrajRank: A. spatial-temporal view: supports trajectory filtering and route segmentation; B. horizon graph view: shows the distribution of trajectories over a day; C. ranking view: provides visualization and exploration of trajectories by ranking; D. menu panel; E. part of spatial temporal view, drawing bands over road segments encoding the average (the blue ones) and variance (the gray ones) of travel time. ", "caption_bbox": [73, 465, 775, 504]}, {"image_id": 1, "file_name": "364_01.png", "page": 3, "dpi": 300, "bbox": [144, 74, 706, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The Workflow of TrajRank consists of an offline preprocessing stage and a runtime visual analysis stage.", "caption_bbox": [143, 263, 704, 276]}, {"image_id": 2, "file_name": "364_02.png", "page": 4, "dpi": 300, "bbox": [90, 659, 394, 905], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Ranking Diagrams: different settings on threshold Dmin and vertical gap. ", "caption_bbox": [73, 904, 408, 930]}, {"image_id": 3, "file_name": "364_03.png", "page": 5, "dpi": 300, "bbox": [90, 662, 394, 748], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Modified Box-plot View: (a) box-plot only; (b) distribution histogram covered. ", "caption_bbox": [73, 749, 408, 775]}, {"image_id": 4, "file_name": "364_04.png", "page": 5, "dpi": 300, "bbox": [439, 437, 777, 506], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Route Segmentation Interactions.", "caption_bbox": [501, 507, 715, 520]}, {"image_id": 5, "file_name": "364_05.png", "page": 5, "dpi": 300, "bbox": [89, 120, 394, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Occurrence Temporal Distribution View: (a) fine granu- larity, separating weekday/weekend; (b) coarse granularity, separat- ing weekday/weekend; (c) coarse granularity, weekday and weekend data merged. ", "caption_bbox": [73, 342, 408, 394]}, {"image_id": 6, "file_name": "364_06.png", "page": 5, "dpi": 300, "bbox": [472, 73, 744, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Trajectory Filtering Interactions. CPS is short for Carry Passenger Status. ", "caption_bbox": [440, 236, 775, 262]}, {"image_id": 7, "file_name": "364_07.png", "page": 6, "dpi": 300, "bbox": [90, 330, 393, 693], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Travel Behaviour over Space and Time: (a) 6 typical routes in Beijing are selected and their corresponding bands are shown in the spatial view; (b) the temporal distribution views of these 6 routes. ", "caption_bbox": [73, 694, 408, 733]}, {"image_id": 8, "file_name": "364_08.png", "page": 6, "dpi": 300, "bbox": [439, 74, 777, 406], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: TrajRank with Even Segmentation: (a) a westward route is selected on the 4th ring; (b) the horizon graph shows the temporal distribution of trajectories on that route; (c) ranking diagram shows the trajectory ranking; (d) 8 clusters with different travel behaviors are highlighted respectively. ", "caption_bbox": [440, 407, 775, 472]}, {"image_id": 9, "file_name": "364_09.png", "page": 7, "dpi": 300, "bbox": [84, 75, 767, 259], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Summary of the evaluation questions and results.", "caption_bbox": [464, 305, 750, 318]}], "365": [{"image_id": 0, "file_name": "365_00.png", "page": 5, "dpi": 300, "bbox": [82, 74, 427, 614], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Separation of US Politics Blogs into Two Parties", "caption_bbox": [75, 618, 407, 631]}, {"image_id": 1, "file_name": "365_01.png", "page": 6, "dpi": 300, "bbox": [83, 73, 421, 468], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visual Analytics of \u201cFour Universities\u201d", "caption_bbox": [102, 472, 379, 485]}, {"image_id": 2, "file_name": "365_02.png", "page": 7, "dpi": 300, "bbox": [447, 74, 788, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison of 2D and 3D visualization of the \u201cfour universities\u201d dataset (1,896 vertices and 26,183 edges). The projection factor is given the maximum value for both visualizations and no filter is applied. ", "caption_bbox": [440, 259, 775, 314]}], "366": [{"image_id": 0, "file_name": "366_00.png", "page": 1, "dpi": 300, "bbox": [87, 127, 753, 497], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 1 The interface of our system demonstrating the linked display functionality \u2013 the highlighted parts are linked with the chosen area.", "caption_bbox": [84, 496, 748, 513]}, {"image_id": 1, "file_name": "366_01.png", "page": 3, "dpi": 300, "bbox": [483, 167, 721, 403], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 3 Distance Spaced Layout Pipeline", "caption_bbox": [484, 407, 680, 424]}, {"image_id": 2, "file_name": "366_02.png", "page": 4, "dpi": 300, "bbox": [448, 771, 754, 956], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 6 The change of the data to data error.", "caption_bbox": [449, 957, 663, 974]}, {"image_id": 3, "file_name": "366_03.png", "page": 4, "dpi": 300, "bbox": [446, 144, 754, 741], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 5 The change of the data to variable error.", "caption_bbox": [451, 742, 685, 759]}, {"image_id": 4, "file_name": "366_04.png", "page": 4, "dpi": 300, "bbox": [134, 261, 396, 512], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 4 The error polygon", "caption_bbox": [151, 515, 272, 532]}, {"image_id": 5, "file_name": "366_05.png", "page": 5, "dpi": 300, "bbox": [152, 355, 339, 489], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 7 The force directed adjustment", "caption_bbox": [149, 491, 329, 508]}, {"image_id": 6, "file_name": "366_06.png", "page": 6, "dpi": 300, "bbox": [74, 735, 754, 959], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 10 The error distribution with (a) the car data (b) the campaign data (c) the bike data. Brighter red tones correspond to high value.", "caption_bbox": [73, 963, 735, 980]}, {"image_id": 7, "file_name": "366_07.png", "page": 6, "dpi": 300, "bbox": [77, 74, 770, 525], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 9 The GBC error reduction with car data (first line), campaign data (second line) and bike data (third line). The color shows the k- means clusters [9] in the high dimensional distances. The columns are GBC, DGBC, IGBC, FGBC, DIFGBC in order. ", "caption_bbox": [81, 524, 756, 554]}, {"image_id": 8, "file_name": "366_08.png", "page": 7, "dpi": 300, "bbox": [432, 717, 780, 894], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 11 Verification coloring of (a) distance and (b) error.", "caption_bbox": [434, 893, 715, 910]}, {"image_id": 9, "file_name": "366_09.png", "page": 8, "dpi": 300, "bbox": [127, 653, 352, 867], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 13 The variable-centric refinement with the bike data matrix.", "caption_bbox": [79, 871, 397, 888]}], "367": [{"image_id": 0, "file_name": "367_00.png", "page": 1, "dpi": 300, "bbox": [78, 86, 764, 484], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Screenshot of our system interface for finding correlated subspaces based on biclustering. (a) Classical parallel coordinate plot (PCP). (b) Clustered PCP. (c) Contracted PCP. (d) Block matrix diagram. (e) History tree. (f) Objective function value. ", "caption_bbox": [73, 489, 775, 515]}, {"image_id": 1, "file_name": "367_01.png", "page": 3, "dpi": 300, "bbox": [444, 74, 770, 216], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) Data matrix, and (b) schematic representation of the block model for K = 4 and L = 3. ", "caption_bbox": [440, 229, 775, 255]}, {"image_id": 2, "file_name": "367_02.png", "page": 3, "dpi": 300, "bbox": [91, 74, 392, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visual analytic framework of correlated subspace mining.", "caption_bbox": [76, 272, 405, 285]}, {"image_id": 3, "file_name": "367_03.png", "page": 3, "dpi": 300, "bbox": [539, 268, 676, 405], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A concept illustration of spherical k-means.", "caption_bbox": [476, 421, 736, 434]}, {"image_id": 4, "file_name": "367_04.png", "page": 6, "dpi": 300, "bbox": [74, 101, 777, 429], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: System screenshots for exploring subspaces in a 12-dimensional synthetic data.", "caption_bbox": [201, 447, 643, 460]}, {"image_id": 5, "file_name": "367_05.png", "page": 6, "dpi": 300, "bbox": [77, 478, 770, 946], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Experiments on the USDA national nutrient data.", "caption_bbox": [278, 959, 566, 972]}, {"image_id": 6, "file_name": "367_06.png", "page": 7, "dpi": 300, "bbox": [443, 74, 771, 347], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Analyzing blazar dataset of 1,285 samples in 17D. (a) Plot- ting original data. (b) Plotting final data clustered with 3 sample-by-2 axis clusters. (c) Plotting final data (strip-rendered view). ", "caption_bbox": [440, 360, 775, 399]}], "368": [{"image_id": 0, "file_name": "368_00.png", "page": 1, "dpi": 300, "bbox": [198, 86, 669, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Renderings of three of the scientific data sets used in the performance study. The images were generated in 43 ms on an NVIDIA Titan Black, using a ray tracer consisting entirely of data parallel primitives. ", "caption_bbox": [73, 342, 775, 369]}, {"image_id": 1, "file_name": "368_01.png", "page": 4, "dpi": 300, "bbox": [48, 1038, 427, 1094], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Pseudocode for our ray-tracing algorithm made up of data-parallel primitives. Parallel primitives are shown in the form : primitive<functor>(args) ", "caption_bbox": [73, 958, 408, 999]}, {"image_id": 2, "file_name": "368_02.png", "page": 5, "dpi": 300, "bbox": [88, 73, 377, 162], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Ray tracings of the Richtmyer-Meshkov isosurfaces used in this study, using the RM 3.2M version of the data. The left im- age represents the results of basic intersection tests (i.e., WORK- LOAD1 from Section 5.1.4) and the right image contains the pic- tures produced from the shaded pictures (i.e., WORKLOAD2). ", "caption_bbox": [73, 163, 408, 231]}], "369": [{"image_id": 0, "file_name": "369_00.png", "page": 1, "dpi": 300, "bbox": [445, 181, 737, 400], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A height function and the corresponding contour tree. The ith critical point in increasing order of function value is labeled ci . ", "caption_bbox": [440, 419, 775, 445]}, {"image_id": 1, "file_name": "369_01.png", "page": 3, "dpi": 300, "bbox": [189, 553, 294, 676], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An analytic function sampled on a structured grid and a visualization that shows multiple level sets of the function. Each level set consists of one or more connected components. ", "caption_bbox": [73, 691, 408, 730]}, {"image_id": 2, "file_name": "369_02.png", "page": 3, "dpi": 300, "bbox": [210, 74, 639, 473], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The contour tree for the analytic function shown in Figure 2. (a) Level sets at different function values (b) The contour tree tracks the evolution of connected components of the level sets. (c) The split tree tracks connected components of the super-level sets. (d) The join tree tracks connectivity of sub-level sets. ", "caption_bbox": [73, 488, 775, 527]}, {"image_id": 3, "file_name": "369_03.png", "page": 4, "dpi": 300, "bbox": [73, 79, 411, 215], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Points classified as saddles in a sub-domain. (a) The green point represents an interior saddle with two upper link components (red) and one lower link component (blue). The lower link component lies on a plane normal to one of the axes and the two upper link component on either side. (b) A point on the boundary with one upper link component (red) and one lower link component (blue) within the sub-domain. It is classified as critical because it is a minimum of the function restricted to the boundary plane. ", "caption_bbox": [73, 234, 408, 338]}, {"image_id": 4, "file_name": "369_04.png", "page": 7, "dpi": 300, "bbox": [113, 369, 383, 578], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Speedup for large datasets with increasing number of cores. D IV CT exhibits close to ideal scaling behavior. The exact speedup factors are available in Table 2. ", "caption_bbox": [73, 608, 408, 647]}], "37": [{"image_id": 0, "file_name": "37_00.png", "page": 1, "dpi": 300, "bbox": [425, 508, 729, 630], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The visualisation process.", "caption_bbox": [476, 644, 675, 660]}, {"image_id": 1, "file_name": "37_01.png", "page": 3, "dpi": 300, "bbox": [415, 252, 740, 586], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A circular vector field visualised using different visualisation icons. ", "caption_bbox": [416, 599, 736, 629]}, {"image_id": 2, "file_name": "37_02.png", "page": 4, "dpi": 300, "bbox": [70, 133, 395, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Screen shot of a program to test preattentive target identification. ", "caption_bbox": [71, 381, 392, 411]}, {"image_id": 3, "file_name": "37_03.png", "page": 4, "dpi": 300, "bbox": [419, 63, 736, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A chart of the time it took to find a red square among 1000 blue squares using different square sizes. ", "caption_bbox": [416, 370, 736, 400]}, {"image_id": 4, "file_name": "37_04.png", "page": 4, "dpi": 300, "bbox": [419, 596, 737, 849], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A chart of the time it took to find a red square among 1000 non-target squares with 1, 2, 3, 4 and 5 dif- ferent colours, respectively. ", "caption_bbox": [416, 865, 736, 909]}, {"image_id": 5, "file_name": "37_05.png", "page": 6, "dpi": 300, "bbox": [415, 59, 740, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A visualisation of the nerve fiber structure in the brain. Perception is improved by inserting familiar anatomical structures such as the eyes (green) and the ven- tricles (red). ", "caption_bbox": [416, 358, 736, 415]}], "370": [{"image_id": 0, "file_name": "370_00.png", "page": 1, "dpi": 300, "bbox": [446, 281, 719, 525], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A merge tree, and its superset, the contour tree, captures the nesting structure of level sets. For the two functions shown above (blue and red), no branch decomposition of the merge tree (below) reflects the correspondence between both maxima b to b0 and c to c0 . The extremum graph (dashed) captures proximity be- tween the extrema and can provide a more intuitive correspondence between them. ", "caption_bbox": [440, 544, 775, 640]}, {"image_id": 1, "file_name": "370_01.png", "page": 3, "dpi": 300, "bbox": [81, 296, 384, 559], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Extremum graphs provide an abstraction of scalar fields and encodes adjacency relationships between its extrema. (a) shows a 2D scalar function overlayed with its extremum graph. (b) The ex- tremum C can be simplified by a merger into extremum D, follow- ing which D becomes adjacent to A and B, after this simplification A and B appear much farther away in the graph. (c) shows a com- binatorial representation of the extremum graph. (d) Simplification of vertex C into vertex D involves contraction of edge (C,D). ", "caption_bbox": [73, 558, 408, 668]}, {"image_id": 2, "file_name": "370_02.png", "page": 4, "dpi": 300, "bbox": [84, 463, 384, 737], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Construction of the complete extremum graph. (a) Input extremum graph EG. (b) (F,G) is processed. (C,D) is processed introducing (A,D) and (B,D). Other edges associated with C are retained.(c) (C,A) is processed and (A,B) is introduced. (d)(A,E) is processed introducing (E,D). ", "caption_bbox": [73, 743, 408, 811]}, {"image_id": 3, "file_name": "370_03.png", "page": 5, "dpi": 300, "bbox": [74, 74, 377, 317], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: For \u03c1 = 0.25, the figure shows a possible map between the two complete extremum graphs. Dummy vertices are inserted into each graph to obtain a bijective map. Edges are labelled with their corresponding edge cost. The correspondence A 7\u2192 0 and C 7\u2192 2 sat- isfies the \u03c1 criterion since |C((A, C)) \u2212 C((0, 2))| = |0.35 \u2212 0.10| \u2264 0.25. The correspondence B 7\u2192 1 cannot be included since (A, B) and (0, 1) cannot be mapped within a distortion of 0.25 though (B, C) and (1, 2) satisfy the condition. Correspondences that in- volve a dummy vertex are indicated with dotted edges. The vertex distortion for this map can now be computed based on the differ- ence in the vertex attributes of the corresponding vertices. ", "caption_bbox": [73, 316, 408, 468]}, {"image_id": 4, "file_name": "370_04.png", "page": 6, "dpi": 300, "bbox": [443, 328, 778, 477], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The plot shows distances computed between consecutive time steps for a synthetic time-varying dataset. The distance plot helps in summarizing the dataset, peaks in the plot indicate frames that have a large distance with respect to the previous time step, indicating an event of importance. The peak at time step 24 occurs due to the creation of a new feature in the bottom right. ", "caption_bbox": [440, 480, 775, 562]}, {"image_id": 5, "file_name": "370_05.png", "page": 7, "dpi": 300, "bbox": [444, 74, 698, 532], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: To track features in the turbulent vortex data, we compare the complete extremum graphs of consecutive time steps. Tracked features across time steps 2, 4 and 6 are shown on the left. Low opacity values indicate higher structural distortion in the complete extremum graph. Three features are shown in isolation on the right, the violet feature undergoes a split. The green and brown features merge, the purple feature grows. ", "caption_bbox": [440, 534, 775, 630]}, {"image_id": 6, "file_name": "370_06.png", "page": 7, "dpi": 300, "bbox": [76, 305, 408, 524], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: To identify periodicity, we compare the extremum graph of each time step with all 1000 time steps of the data. The line plot above shows distances computed between time step 0 and time steps 0-1000. The time steps are indicated on the x-axis and dis- tance is indicated on the y-axis. The plot below shows distances computed with respect to time step 22, 38, 58 and 75. From both plots, a time period of 38 can be identified. ", "caption_bbox": [73, 527, 408, 623]}, {"image_id": 7, "file_name": "370_07.png", "page": 7, "dpi": 300, "bbox": [73, 73, 411, 207], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Time-step 0 (top), 38 (middle) and 75 (bottom) of the flow around a cylinder simulation. This simulation is time dependent with a time period of 75, these time steps appear similar. The vortex shedding alternates between the two sides of cylinder with a time period of 38. Time step 38 appears symmetric to time step 0 and 75. The extremum graph is overlayed in yellow. ", "caption_bbox": [73, 206, 408, 288]}], "371": [{"image_id": 0, "file_name": "371_00.png", "page": 1, "dpi": 300, "bbox": [97, 144, 754, 398], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Thermus thermophilus 70S ribosome (PDB ID: 2WDK) rendered with no Depth of Field effect (left) and using our approach focusing on near structures (center) and far away structures (right). ", "caption_bbox": [73, 413, 775, 438]}, {"image_id": 1, "file_name": "371_01.png", "page": 2, "dpi": 300, "bbox": [75, 79, 410, 225], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Comparison of our method with an image-based DoF ap- proach. (a) our coverage-based DoF. (b) image-based DoF by post- processing depth and color buffer. Even for such relatively small molecular structures the image-based approach suffer from severe artifacts that are not visible in our object-based approach. ", "caption_bbox": [73, 244, 408, 309]}, {"image_id": 2, "file_name": "371_02.png", "page": 3, "dpi": 300, "bbox": [91, 74, 393, 216], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An illustration of the thin lens model. While point F being in focus projects to a point, points A and B that are not in focus are captured as blurred circle in the image plane. This circle is known as circle of confusion (CoC) (green). A smaller aperture results in a smaller CoC (dotted blue lines). ", "caption_bbox": [73, 230, 408, 295]}, {"image_id": 3, "file_name": "371_03.png", "page": 3, "dpi": 300, "bbox": [474, 75, 742, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Diameter of the circle of confusion (CoC). When the CoC is calculated for the ratio of dfocus to d, the CoC is proportional to this ratio (red). The piecewise linear approximation of the CoC (or- ange) is used in the approach by Scheuermann and Tatarchuck [19]. Parameters: f = 35 mm, a = f /2, and dfocus = 1 m. ", "caption_bbox": [440, 259, 775, 325]}, {"image_id": 4, "file_name": "371_04.png", "page": 4, "dpi": 300, "bbox": [439, 80, 777, 392], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Reference DoF images generated by the Mitsuba ren- derer. (a) pinhole camera. (b) small aperture, f/2.5, dcoc = 5.45 mm. (c) medium aperture, f/1, dcoc = 15.79 mm. (d) large aperture, f/0.5, dcoc = 42.86 mm. The radial opacity values measured in (b)-(d) are plotted together with our approximation (bottom). rA and rCoC are atom radius and CoC disk radius respectively. Parameters: f = 50 mm, dfocus = 0.12 m, object distance d = 0.3 m, and disk diameter r = 0.1 m. ", "caption_bbox": [440, 412, 775, 516]}, {"image_id": 5, "file_name": "371_05.png", "page": 4, "dpi": 300, "bbox": [75, 78, 408, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Multi-sampling DoF as often computed in ray tracing. The DoF effect is obtained by sampling rays starting inside the open part of the aperture of the thin lens. All rays are directed toward the point in the scene which would produce a sharp image in the pixel (red dot) and intersection tests are performed. ", "caption_bbox": [73, 227, 408, 292]}, {"image_id": 6, "file_name": "371_06.png", "page": 4, "dpi": 300, "bbox": [121, 313, 371, 422], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Reference images for Phong illumination generated by the Mitsuba renderer. Sphere without (left) and with DoF effect (right). ", "caption_bbox": [73, 443, 408, 468]}, {"image_id": 7, "file_name": "371_07.png", "page": 5, "dpi": 300, "bbox": [447, 406, 770, 505], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The contribution of occluded glyphs is considered by em- ploying the opacity fall-off function. The focal distance increases from front to back (a) to (c). With larger focal distance and, thus, increas- ing CoC diameter the occluded atoms become visible (Parameters:  f = 0.28 mm, a = f/0.1). ", "caption_bbox": [440, 523, 775, 588]}, {"image_id": 8, "file_name": "371_08.png", "page": 5, "dpi": 300, "bbox": [106, 312, 401, 588], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Illustration of the opacity fall-off function. (a) the fall-off function is applied to the enlarged glyph footprint. (b) atoms rendered without DoF effect. (c) enlarged glyphs with area affected by fall-off indicated in yellow. (d) final rendering with alpha blending yielding the DoF effect. ", "caption_bbox": [73, 607, 408, 672]}, {"image_id": 9, "file_name": "371_09.png", "page": 5, "dpi": 300, "bbox": [462, 77, 759, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The glyph footprint is radially enlarged by twice the CoC radius rCoC depending on the distance to the camera and lens pa- rameters. If a view ray hits a blur disk, the respective glyph contribu- tion is calculated from a single sample. Glyphs in front of the focal plane are spread out over the atom boundaries (a). Objects in focus (b), i.e. d = dfocus , do not possess a blur disk and are treated as en- tirely opaque. Although glyphs might be occluded (c), they still can contribute to view rays due to their enlarged blur disk. ", "caption_bbox": [440, 268, 775, 372]}, {"image_id": 10, "file_name": "371_10.png", "page": 5, "dpi": 300, "bbox": [122, 80, 411, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison of DoF applied to a disk and a sphere. (a) disk (left) and sphere (right). (b) difference between disk and sphere (scaled by a factor of 10 for illustration purposes). Images have been created with the Mitsuba renderer. ", "caption_bbox": [73, 235, 408, 287]}, {"image_id": 11, "file_name": "371_11.png", "page": 6, "dpi": 300, "bbox": [73, 73, 775, 331], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Comparison of different approaches for atom shading. (a) regular Phong shading on the inner sphere. Normals extending outward from the inner sphere are used to shade the outer sphere. (b) ray intersections with the inner and the outer sphere are interpolated before shading is computed. (c) normals of the inner sphere and the outer sphere intersection are merged before shading. (d) shading computation is performed for both, inner sphere and outer sphere intersection, before being blended. (e) only intersections with the outer sphere are used. ", "caption_bbox": [73, 345, 775, 397]}, {"image_id": 12, "file_name": "371_12.png", "page": 8, "dpi": 300, "bbox": [98, 104, 752, 481], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Depth of field applied to different protein structures. (a) Human protein kinase MEK2 (PDB ID: 1S9I). (b) Half vault protein of the rat liver (PDB ID: 2ZUO, 2ZV4, 2ZV5). ", "caption_bbox": [73, 499, 775, 524]}], "372": [{"image_id": 0, "file_name": "372_00.png", "page": 1, "dpi": 300, "bbox": [73, 86, 778, 434], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Screen capture of an outer mitochondrial membrane featuring adenosine triphosphate (ATP) molecules (in green) crossing larger voltage-dependent anion channel (VDAC) proteins (in dark red). Our real-time technique lets us observe results of mesoscale particle simulation in fast-forward while showcasing perceivable moving molecules and a scene full of stochastic motion and interactions ", "caption_bbox": [73, 448, 775, 485]}, {"image_id": 1, "file_name": "372_01.png", "page": 3, "dpi": 300, "bbox": [73, 74, 777, 209], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Three consecutive frames of a MCell based simulation visualized using CellBlender. When directly visualizing the molecular positions obtained from the simulation data, it is very challenging to track the molecules in consecutive time steps (cf., red circle). ", "caption_bbox": [73, 222, 775, 247]}, {"image_id": 2, "file_name": "372_02.png", "page": 3, "dpi": 300, "bbox": [446, 556, 769, 650], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Screenshot of frame m and m + 3 of a molecular anima- tion [5]. Mind how the main reaction is forced to remain fairly sta- tionary (upper arrow), while molecules in the background move very quickly (lower arrow). ", "caption_bbox": [440, 665, 775, 715]}, {"image_id": 3, "file_name": "372_03.png", "page": 4, "dpi": 300, "bbox": [482, 214, 736, 511], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A sample movement trajectory over 12 frames: (a) the original trajectory (\u03c1 = 1) and (b) a reduced version visualized in red (\u03c1 = 0.5) which is equivalent to a displacement reduction of 50% of the distance between the current position and the next sampled point on the trajectory. ", "caption_bbox": [440, 517, 775, 579]}, {"image_id": 4, "file_name": "372_04.png", "page": 5, "dpi": 300, "bbox": [482, 75, 736, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Illustration of two lens effects. a) Visual abstraction (red trails) within the world lens (illustrated with inner radius only, with- out transition area). b) Dynamic displacement reduction based on screen-space distance. ", "caption_bbox": [440, 396, 775, 446]}, {"image_id": 5, "file_name": "372_05.png", "page": 6, "dpi": 300, "bbox": [79, 316, 404, 929], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Screen capture of our Illustrated Timelapse system which features 25000 particles reacting and diffusing smoothly at more than 50 frames per seconds. (a) Succinate thiokinase (blue) reacting with ADP (orange) inside mitochondrion (b) ATP (green) is produced from Succinate thiokinase (c) ATP about to exit the organelle via VDAC (red) (d) ATP outside mitochondrion. ", "caption_bbox": [73, 935, 408, 1010]}, {"image_id": 6, "file_name": "372_06.png", "page": 7, "dpi": 300, "bbox": [446, 203, 775, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Average z-scores per visualization condition (color-coded) for the three questions listed in Table 1. Higher values are better. ", "caption_bbox": [440, 315, 775, 340]}], "373": [{"image_id": 0, "file_name": "373_00.png", "page": 1, "dpi": 300, "bbox": [77, 86, 773, 522], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Unstructured grid volume visualization examples showing our method\u2019s advantages. The H2 O field of the Flame dataset is visualized. With our method, shadows enhance the visual perception of depth cue greatly. ", "caption_bbox": [73, 540, 775, 565]}, {"image_id": 1, "file_name": "373_01.png", "page": 4, "dpi": 300, "bbox": [84, 74, 400, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Assuming that the space in the concavities and holes is transparent, the light should be propagated across the concavities and holes. If this situation is not handled properly, the simulation result will be incorrect. (b) We add the level-0 regular grid to solve the problem. ", "caption_bbox": [73, 271, 408, 336]}, {"image_id": 2, "file_name": "373_02.png", "page": 5, "dpi": 300, "bbox": [90, 74, 760, 614], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Volume rendering of the Engine dataset with different optical models. With our lighting method, the structure of the flow around the crankshaft is much clearer, and the spatial ambiguity around the pink features is well resolved. Advanced lighting also helps better illustrate the shape and structure of the engine body. ", "caption_bbox": [73, 632, 775, 671]}, {"image_id": 3, "file_name": "373_03.png", "page": 6, "dpi": 300, "bbox": [443, 326, 773, 506], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Rendering results with different scattering coefficient \u03c3\u0303s .", "caption_bbox": [446, 524, 769, 537]}, {"image_id": 4, "file_name": "373_04.png", "page": 6, "dpi": 300, "bbox": [443, 73, 773, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Rendering results with different absorption strength \u03c3\u02dca . As \u03c3\u02dca increases, the shadows become darker. ", "caption_bbox": [440, 284, 775, 310]}, {"image_id": 5, "file_name": "373_05.png", "page": 6, "dpi": 300, "bbox": [76, 73, 407, 441], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Volume rendering of the Aircraft1 dataset. (c) and (d) are the close-up view of (a) and (b), respectively. The images show that simulating the light only on the level-0 grid cannot accurately capture the lighting effects at the fine regions of a highly adaptive grid. ", "caption_bbox": [73, 459, 408, 511]}, {"image_id": 6, "file_name": "373_06.png", "page": 7, "dpi": 300, "bbox": [82, 73, 768, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Performance measurements for the datasets in our study. The light volume calculation times are measured using a single directional light source. The resolution of the level-0 grid is 128\u00d7128\u00d7128. ", "caption_bbox": [73, 247, 775, 272]}, {"image_id": 7, "file_name": "373_07.png", "page": 8, "dpi": 300, "bbox": [441, 79, 768, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: level-1 grid calculation times for different data sizes. The calculation time increases linearly as the data size (in terms of the number of tetrahedra) increases. ", "caption_bbox": [440, 281, 775, 320]}, {"image_id": 8, "file_name": "373_08.png", "page": 8, "dpi": 300, "bbox": [77, 74, 406, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Rendering results with different level-0 grid resolutions. In images (a)\u2013(d), a synthetic non-convex grid is rendered. Since the light propagation crossing the concavities relies on the level-0 simula- tion, the lighting quality largely depends on the level-0 grid resolution in this case. On the other hand, with the Flame dataset (temperature field), where there are no concavities among the occluders, it is hard to distinguish between images (f), (g), and the ground truth image (h). Image (e) is darker than the other images, which shows that the boundary values of level-1 grid are not accurate due to coarse level-0 simulation. ", "caption_bbox": [73, 411, 408, 542]}], "374": [{"image_id": 0, "file_name": "374_00.png", "page": 1, "dpi": 300, "bbox": [116, 86, 720, 390], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A CT scan of a mummy (438 \u00d7 289 \u00d7 1700 voxels) rendered using the proposed volumetric illumination method. To enable high contrast in bright and shadowed areas, we use a light setup that consists of two warm (orange and red) point lights and two directional white lights. ", "caption_bbox": [73, 411, 775, 437]}, {"image_id": 1, "file_name": "374_01.png", "page": 3, "dpi": 300, "bbox": [455, 74, 771, 179], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Application of our technique with lighting setups used in photography. We show the setups butterfly lighting (b) and three- point lighting (c) as compared to a single point light setup (a). ", "caption_bbox": [440, 197, 775, 236]}, {"image_id": 2, "file_name": "374_02.png", "page": 4, "dpi": 300, "bbox": [440, 76, 775, 204], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: By exploiting coherence-based light propagation, we achieve a constant maximum number of propagation passes inde- pendent of the number of light sources. While in standard multi-light rendering approaches (left) all light sources and their visibility would be evaluated per sample during rendering, the coherence-based propagation (right) groups light sources into propagation groups as- sociated with the principal axis of the volume. ", "caption_bbox": [440, 220, 775, 311]}, {"image_id": 3, "file_name": "374_03.png", "page": 5, "dpi": 300, "bbox": [441, 74, 776, 257], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Rendering of a human skull (a) and associated light volume (b) with 10 light sources using our method. ", "caption_bbox": [440, 275, 775, 301]}, {"image_id": 4, "file_name": "374_04.png", "page": 5, "dpi": 300, "bbox": [441, 875, 775, 943], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: For the supported light source types (directional, point, and spotlight (from left to right), we project the light sources on the initial volume slice before we perform our coherence-based propagation. ", "caption_bbox": [440, 961, 775, 1000]}, {"image_id": 5, "file_name": "374_05.png", "page": 6, "dpi": 300, "bbox": [443, 396, 776, 561], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: When applied to complex 3D structures, the use of multi- ple light sources not only increases the level of realism, but also the contrast in lit and shadowed areas, which emphasize the structures. ", "caption_bbox": [440, 579, 775, 618]}, {"image_id": 6, "file_name": "374_06.png", "page": 6, "dpi": 300, "bbox": [78, 396, 406, 590], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Light contribution to a scene. (a) shows the illumination volume, of three spheres, under lighting from one yellow point light from the left of the volume, relative to the camera. In (b) an additional blue point light has been added, whose location is on the right side of the volume, thus there are areas to the left of the spheres where the blue light is not present, and areas to the right of the spheres where the yellow light is not present. ", "caption_bbox": [73, 608, 408, 699]}, {"image_id": 7, "file_name": "374_07.png", "page": 6, "dpi": 300, "bbox": [84, 73, 766, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Renderings of CT data set of a male\u2019s upper body. In (a) only local shading is used with the Ashikhmin-Shirley model [2]. One light has been added in (b), (c) and (d) respectively, with varying characteristics of light type, direction and color. All the three light sources from (b), (c) and (d) are then used together in (e), which is rendered with our volume illumination approach that supports multiple light sources. ", "caption_bbox": [73, 332, 775, 371]}, {"image_id": 8, "file_name": "374_08.png", "page": 7, "dpi": 300, "bbox": [494, 334, 706, 499], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Performance measurements of our coherence-based propagation compared to sequential propagation The results have been achieved for a data resolution of 2563 for read and storage. ", "caption_bbox": [440, 516, 775, 555]}, {"image_id": 9, "file_name": "374_09.png", "page": 7, "dpi": 300, "bbox": [74, 328, 409, 443], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The engine data set rendered with our approach and col- ored light setups to shift the image tone from warm (a) to cool (b). ", "caption_bbox": [73, 461, 408, 487]}], "375": [{"image_id": 0, "file_name": "375_00.png", "page": 3, "dpi": 300, "bbox": [483, 74, 733, 236], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Uncertainty in vortex detection and modeling via sigmoid curve. ", "caption_bbox": [440, 250, 775, 277]}, {"image_id": 1, "file_name": "375_01.png", "page": 3, "dpi": 300, "bbox": [73, 74, 410, 161], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A schematic view of the different stages of our system.", "caption_bbox": [78, 186, 403, 199]}, {"image_id": 2, "file_name": "375_02.png", "page": 4, "dpi": 300, "bbox": [77, 73, 406, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Change in the distribution due to entropy maximization.", "caption_bbox": [76, 226, 406, 239]}, {"image_id": 3, "file_name": "375_03.png", "page": 5, "dpi": 300, "bbox": [77, 74, 406, 161], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Incorporation of spatial proximity. (a) Certain (red) and uncertain (blue) points detected after majority voting. (b) Spatial clustering of certain points. (c) Uncertain points are classified ac- cording to their distance from their nearest certain vortex cluster. ", "caption_bbox": [73, 174, 408, 229]}, {"image_id": 4, "file_name": "375_04.png", "page": 6, "dpi": 300, "bbox": [450, 599, 767, 755], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Results for the Rearward Facing Step data set. (a) Volume rendering from our algorithm generated prediction field. (b) Isosur- face from the prediction field showing the vortical regions detected from our algorithm. ", "caption_bbox": [440, 754, 775, 809]}, {"image_id": 5, "file_name": "375_05.png", "page": 6, "dpi": 300, "bbox": [100, 85, 740, 375], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Results for different time steps of the Tapered Cylinder data set.", "caption_bbox": [239, 380, 609, 393]}, {"image_id": 6, "file_name": "375_06.png", "page": 6, "dpi": 300, "bbox": [111, 404, 740, 559], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Results for the Rearward Facing Step data set. (a) Quantitative comparison results. (b)-(d) Domain expert\u2019s labeled points in three regions of the data set. ", "caption_bbox": [73, 559, 775, 586]}, {"image_id": 7, "file_name": "375_07.png", "page": 7, "dpi": 300, "bbox": [99, 85, 739, 232], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Running time for different components of the framework.", "caption_bbox": [440, 597, 775, 610]}], "376": [{"image_id": 0, "file_name": "376_00.png", "page": 2, "dpi": 300, "bbox": [81, 73, 402, 197], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview of our system. White blocks: existing data down- sampling procedures. Color thick blocks: proposed error modeling method for uncertain pathline computation and refinement. ", "caption_bbox": [73, 212, 408, 251]}, {"image_id": 1, "file_name": "376_01.png", "page": 5, "dpi": 300, "bbox": [87, 77, 395, 176], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a): Illustration of intersection of two Gaussian distributions. (b): Illustration of our forward-backward trace intersection method. Each ellipse represents the uncertainty of the corresponding trace at a sampled time step modeled as a 2D Gaussian, where the radius is proportional to the standard deviation. ", "caption_bbox": [73, 188, 408, 253]}, {"image_id": 2, "file_name": "376_02.png", "page": 5, "dpi": 300, "bbox": [445, 77, 773, 161], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: RMSE of different interpolation methods to the ground truth. Red: linear interpolation. Green: linear interpolation with a double sampling rate. Blue: quadratic Bezier curve interpolation. ", "caption_bbox": [440, 176, 775, 215]}, {"image_id": 3, "file_name": "376_03.png", "page": 7, "dpi": 300, "bbox": [75, 417, 409, 506], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Forward and backward traces (a) and our intersected trace (b) in the Climate dataset with the sampling interval of 50 time steps. ", "caption_bbox": [73, 517, 408, 543]}, {"image_id": 4, "file_name": "376_04.png", "page": 7, "dpi": 300, "bbox": [113, 273, 371, 367], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Test on the Plume dataset with the sampling interval of 24 time steps. ", "caption_bbox": [73, 377, 408, 403]}, {"image_id": 5, "file_name": "376_05.png", "page": 7, "dpi": 300, "bbox": [126, 74, 724, 185], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Uncertain forward (a1) and backward (a2) traces from two ends of a true pathline in the Isabel dataset within the sampling interval of 12 time steps. (a3): Our pathline refinement method by intersecting the previous forward and backward traces. (b): Our forward-backward intersected trace with the sampling interval of 24 time steps. Including for the rest of the figures, the color coding on all the estimated traces represents the estimated standard deviation (blue: lower error, and red: higher error). The 1.96 standard deviation is used as the error range. ", "caption_bbox": [73, 196, 775, 248]}], "377": [{"image_id": 0, "file_name": "377_00.png", "page": 1, "dpi": 300, "bbox": [173, 56, 685, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 1. A comparison of partial layouts of 366 \u201cGerman railway stations.\u201d The labeling results are generated on canvases with a resolution of 2850 \u00d7 3800. The left side shows particle-based labeling [18]. The right side is the result of our labeling pipeline with clutter control. ", "caption_bbox": [73, 319, 787, 344]}, {"image_id": 1, "file_name": "377_01.png", "page": 3, "dpi": 300, "bbox": [123, 64, 736, 308], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 2. Cognitive process. (a) An example label layout. Each point-feature is represented by a circle with a letter. (b) and (c) The reasoning process of recognizing a label. The arrows show the reasoning direction. (d) A pair of point-feature and its associated label with different colors. ", "caption_bbox": [73, 307, 788, 332]}, {"image_id": 2, "file_name": "377_02.png", "page": 3, "dpi": 300, "bbox": [524, 338, 702, 564], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 3. Reasoning Cases. The left column shows cases of recognizing a label. The right column shows cases of recognizing a point-feature. \u201cY\u201d means the visual element can be recognized directly, while \u201cN\u201d means it cannot be recognized. The area enclosed in a red line represents the neighborhood of a visual element. ", "caption_bbox": [438, 570, 789, 635]}, {"image_id": 3, "file_name": "377_03.png", "page": 4, "dpi": 300, "bbox": [513, 72, 685, 193], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 4. Visual Connection. In (a) the two labels are visually connected. In (b), since the label\u2019s horizontal gap wh is much larger than ws , the width of a space character, they are distinguished easily. In (c), although the labels are close to each other, the visual connection is broken due to the vertical gap between the two labels. ", "caption_bbox": [425, 195, 775, 260]}, {"image_id": 4, "file_name": "377_04.png", "page": 4, "dpi": 300, "bbox": [689, 259, 779, 1094], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 5. Intersections between labels and guiding lines.", "caption_bbox": [425, 389, 690, 401]}, {"image_id": 5, "file_name": "377_05.png", "page": 5, "dpi": 300, "bbox": [437, 71, 791, 542], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 7. Possible labels conflict. The labels in (a) may overlap, but the labels in (b) will not. ", "caption_bbox": [438, 553, 788, 578]}, {"image_id": 6, "file_name": "377_06.png", "page": 5, "dpi": 300, "bbox": [158, 870, 791, 966], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 6. An example of placing a label. The area bounded by the dash we use a variable Vc \u2208 [0, 1] to control clutter. As Vc increases, the labels lines contains the possible position to place the label.            become more cluttered. The threshold of Cstm is 60Vc ; the threshold ", "caption_bbox": [73, 965, 787, 997]}, {"image_id": 7, "file_name": "377_07.png", "page": 7, "dpi": 300, "bbox": [71, 738, 427, 1094], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 10. German Railway Stations. Part of the layout results is shown.", "caption_bbox": [73, 708, 415, 720]}, {"image_id": 8, "file_name": "377_08.png", "page": 7, "dpi": 300, "bbox": [88, 479, 791, 708], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 9. Tourist Shops in Berlin. This data set contains 357 point-features. Here we only show a portion of the layout results.", "caption_bbox": [73, 449, 674, 461]}], "378": [{"image_id": 0, "file_name": "378_00.png", "page": 1, "dpi": 300, "bbox": [123, 162, 737, 461], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1. SketchInsight helps people visually explore their data, primarily by allowing them to interactively create and manipulate charts with pen and touch interaction. ", "caption_bbox": [73, 466, 774, 494]}, {"image_id": 1, "file_name": "378_01.png", "page": 3, "dpi": 300, "bbox": [86, 76, 766, 150], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2. SketchInsight supports eight simple pen gestures. (a)-(b) scribble and \u2018X\u2019 for erasure, (c)-(e) \u2018L\u2019, \u2018O\u2019, and inverted L for X/Y chart, pie chart, and map creation, and (f)-(h) bar shape, jagged line, and four dots for changing a chart type to a bar chart, line chart, and scatterplot. ", "caption_bbox": [74, 163, 774, 191]}, {"image_id": 2, "file_name": "378_02.png", "page": 4, "dpi": 300, "bbox": [99, 201, 753, 549], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3. Exploring a global energy consumption data with SketchInsight. The icons shown in the upper-left boxes of each image indicate the type of interaction, but not the location of where it is performed. ", "caption_bbox": [74, 554, 775, 582]}, {"image_id": 3, "file_name": "378_03.png", "page": 4, "dpi": 300, "bbox": [101, 612, 751, 969], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. Exploring a survey data with SketchInsight. The icons shown in the upper-left boxes of each image indicate the type of interaction, but not the location of where it is performed. ", "caption_bbox": [74, 974, 775, 1002]}, {"image_id": 4, "file_name": "378_04.png", "page": 7, "dpi": 300, "bbox": [74, 75, 415, 205], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5. Average responses to subjective satisfaction questions. Error bars represent standard deviation. ", "caption_bbox": [72, 209, 394, 237]}], "379": [{"image_id": 0, "file_name": "379_00.png", "page": 2, "dpi": 300, "bbox": [73, 74, 410, 216], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Flow chart of the MetaTracts approach for fiber bundle extraction ", "caption_bbox": [73, 227, 408, 254]}, {"image_id": 1, "file_name": "379_01.png", "page": 3, "dpi": 300, "bbox": [73, 73, 409, 144], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Data characteristics: (a) Rendering of dataset D1. (b, c) 2D slices along Z- and X-axis. (d) Zoom in of the green region marked in (c). Multiple fiber bundles cross and are indistinguish- able by visual inspection alone. ", "caption_bbox": [73, 155, 408, 210]}, {"image_id": 2, "file_name": "379_02.png", "page": 4, "dpi": 300, "bbox": [73, 73, 410, 145], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Reliable Hessians. (a) Colored according to Orientation vector mapped to RGB. (b,c) 2D slices along Z- and X axis. (d) Zoom in of the green region marked in (c). ", "caption_bbox": [73, 151, 408, 192]}, {"image_id": 3, "file_name": "379_03.png", "page": 4, "dpi": 300, "bbox": [439, 73, 776, 214], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: MetaTracts generation: (b) Generation process. (a) Zoom in of the white marked region in (b). (c) Individual cylinder. ", "caption_bbox": [440, 226, 775, 253]}, {"image_id": 4, "file_name": "379_04.png", "page": 5, "dpi": 300, "bbox": [73, 72, 410, 169], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) MetaTracts color-coded according to their mean ori- entations. (b) length distribution of individual MetaTracts for a par- ticular bundle (unit for length is grid cube edge length: 2\u00b5 m). ", "caption_bbox": [73, 180, 408, 223]}, {"image_id": 5, "file_name": "379_05.png", "page": 5, "dpi": 300, "bbox": [439, 73, 777, 355], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (b) Result of K means clustering with data points pro- jected to the top three eigenvectors as major axes. (a) MetaTracts belonging to orientation cluster 1. (c) MetaTracts belonging to ori- entation cluster 2. MetaTracts in gray (a,c) show context. (d,e) shows the result of distance based clustering on the orientation clus- ter. (f) shows the combined result. ", "caption_bbox": [440, 361, 775, 443]}, {"image_id": 6, "file_name": "379_06.png", "page": 6, "dpi": 300, "bbox": [440, 329, 777, 574], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) Voxelization of data set 1; (b) a single slice of the data set; (c) two of the extracted meshes together; (d) the meshes rendered separately. ", "caption_bbox": [440, 580, 775, 621]}, {"image_id": 7, "file_name": "379_07.png", "page": 6, "dpi": 300, "bbox": [442, 73, 777, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Applying only (a)hierarchical and (b)dimensionality re- duction followed by K-means clustering methods to MetaTracts for various numbers of clusters (distance measure is minimal directed Hausdorffs. ", "caption_bbox": [440, 265, 775, 320]}, {"image_id": 8, "file_name": "379_08.png", "page": 7, "dpi": 300, "bbox": [439, 74, 778, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The user evaluation consists of a set of queries on videos of our results, volume rendering and Hessian colormap. The ques- tionnaire tests the effectiveness of MetaTracts in visualizing \u201cgeo- metric structure\u201d and \u201cspatial context\u201d. The Likert scale goes from 1-5: strongly disagree, disagree, neutral, agree and strongly agree. ", "caption_bbox": [440, 275, 775, 344]}, {"image_id": 9, "file_name": "379_09.png", "page": 7, "dpi": 300, "bbox": [73, 74, 409, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Data set with flat thin and compact bundles. (a) shows the volume rendering and a 2D slice with one of the boundaries marked in green, (b) shows the clusters according to individual orientation. (c) shows the complete result. (d) shows the voxelization of (c). ", "caption_bbox": [73, 353, 408, 408]}, {"image_id": 10, "file_name": "379_10.png", "page": 7, "dpi": 300, "bbox": [442, 352, 777, 482], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Number of tracts and median, minimum and maximum length of individual MetaTracts in the orientation cluster Figure 6d, clustered into 10 clusters. The unit for length is the grid cube length. Clusters labeled 2,3,4,5 and 7 all have cardinality less than 10. ", "caption_bbox": [440, 489, 775, 544]}], "38": [{"image_id": 0, "file_name": "38_00.png", "page": 2, "dpi": 300, "bbox": [421, 534, 729, 897], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: InVision view with multiple overlays highlighting                different aspects of the view. ", "caption_bbox": [426, 905, 743, 935]}, {"image_id": 1, "file_name": "38_01.png", "page": 3, "dpi": 300, "bbox": [424, 78, 745, 175], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Process for building an InVision view.", "caption_bbox": [455, 188, 712, 204]}, {"image_id": 2, "file_name": "38_02.png", "page": 3, "dpi": 300, "bbox": [423, 630, 743, 762], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The Common Overlay Architecture.", "caption_bbox": [460, 776, 708, 792]}, {"image_id": 3, "file_name": "38_03.png", "page": 4, "dpi": 300, "bbox": [78, 122, 406, 409], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": " Figure 4: Example of information overlays in an InVision 3D view. The stars and pipes represent people in a research     group, the lines represent supervisory relationships. ", "caption_bbox": [81, 421, 399, 466]}, {"image_id": 4, "file_name": "38_04.png", "page": 4, "dpi": 300, "bbox": [78, 667, 406, 868], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Implementation approach: \u2018glue\u2019 synchronizes overlay and style layer stacks, while \u2018merger\u2019 maintains a                       merged layer. ", "caption_bbox": [86, 895, 395, 940]}, {"image_id": 5, "file_name": "38_05.png", "page": 5, "dpi": 300, "bbox": [480, 85, 690, 368], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The original style layer view elements aliasing     structure was found to be insufficiently flexible. ", "caption_bbox": [435, 391, 734, 421]}, {"image_id": 6, "file_name": "38_06.png", "page": 5, "dpi": 300, "bbox": [88, 212, 398, 439], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Style layer view elements aliasing structure.", "caption_bbox": [97, 462, 385, 478]}, {"image_id": 7, "file_name": "38_07.png", "page": 6, "dpi": 300, "bbox": [134, 574, 692, 1040], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: InVision with shared overlays on a 2D Clovis view and a chart view. Class size (in number of methods) is shown in              colour, classes written by a selected author are shown as stars. The overlay stack is shown top left. ", "caption_bbox": [81, 1053, 743, 1083]}], "380": [{"image_id": 0, "file_name": "380_00.png", "page": 1, "dpi": 300, "bbox": [73, 86, 777, 448], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Left: ScatterBlogs was used as a platform for the case study. Currently data from the 2013 German Flood is analyzed. The blue symbols show reported flood damages (with translation). The UI features: a) Interactive map (red dots=Tweets) b) Hierarchical time overview and filter, showing positive (green), negative (red) and neutral (blue) sentiment volumes c) Message contents d) Archive controls e) Textual and geo-search f) LDA topics, g) Exploration overlay buttons h) Interactive SVM classifier management. Right: Spatiotemporal clusters of similar messages are detected and visualized as tags on the TagMap. Cluster size is mapped to tag size, and unusual topics are highlighted by the system in yellow. Zooming into the map shows smaller subevents. (hochwasser = flood, umspannwerk = transformer station) ", "caption_bbox": [73, 463, 775, 541]}, {"image_id": 1, "file_name": "380_01.png", "page": 4, "dpi": 300, "bbox": [120, 73, 363, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The Content Lens could be used in the third task to assess the ongoing situation in Frankfurt. The three largest tags say police, encircle/empocket, and protest. The view below shows the volumes of positive (red) and negative (green) sentiment Tweets for the keyword police in a temporal overview. ", "caption_bbox": [73, 266, 410, 331]}, {"image_id": 2, "file_name": "380_02.png", "page": 5, "dpi": 300, "bbox": [497, 73, 719, 156], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Means and quartiles of ratings for the usefulness of tools. Grades could be given from 1 (very useless) to 10 (very useful). Standard errors of means are: 0.24; 0.67; 0.54; 0.58 ", "caption_bbox": [440, 171, 778, 210]}, {"image_id": 3, "file_name": "380_03.png", "page": 7, "dpi": 300, "bbox": [99, 74, 384, 450], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Means and standard errors for the 28 items of the percieved performance questionnaire. ", "caption_bbox": [73, 465, 408, 490]}], "381": [{"image_id": 0, "file_name": "381_00.png", "page": 1, "dpi": 300, "bbox": [75, 144, 776, 456], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Screenshot of CloudGazer showing the application perspective in the focus view (right) and the virtual and physical perspectives as interactive thumbnails (left). The user has selected the blocks representing \u2018mail01\u2019 and \u2018wss1 8\u2019 to inspect their relationship across the semantic perspectives. By looking at the dynamically created inlay (bottom), it becomes obvious that the virtual machine \u2018big15\u2019 has a high load even though \u2018wss1 8\u2019 has only few connections. The user concludes that another application on \u2018big15\u2019 must cause the problem. ", "caption_bbox": [73, 466, 775, 521]}, {"image_id": 1, "file_name": "381_01.png", "page": 2, "dpi": 300, "bbox": [90, 74, 393, 362], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Graph of a cloud-based network with 67 nodes. Blue, green, and red nodes encode physical components, VMs, and ap- plications respectively. Solid links denote relationships between components of the same type, such as logical groupings of VMs and applications by customer, and dashed links indicate mapping rela- tionships where one type of component is assigned to a component of a different type. ", "caption_bbox": [73, 374, 408, 470]}, {"image_id": 2, "file_name": "381_02.png", "page": 2, "dpi": 300, "bbox": [83, 646, 397, 728], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Division of the network into component-specific per- spectives. Solid lines represent direct relationships between com- ponents, while dashed lines indicate mapping relationships. The graph in (a) is split into the three perspectives shown in (b). ", "caption_bbox": [73, 740, 408, 795]}, {"image_id": 3, "file_name": "381_03.png", "page": 4, "dpi": 300, "bbox": [161, 63, 689, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Building blocks of CloudGazer. (1) Timeline for temporal navigation. (2) Semantic perspectives shown as interactive thumbnails. (3) Focus view presenting one perspective in greater detail. (4) Blocks visualizing a single component with its associated data. (5) Inlay showing relationships of selected nodes to other perspectives. ", "caption_bbox": [73, 274, 775, 315]}, {"image_id": 4, "file_name": "381_04.png", "page": 5, "dpi": 300, "bbox": [105, 283, 376, 409], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Blocks represent the status of a single component. Static blocks (left) encode component attributes using stacked bars. Each bar corresponds to one attribute. Dynamic blocks (right) visualize live streaming data using heatmaps and streamgraphs. Each row of the heatmap encodes data from different attributes over time. In the case of live streaming data, new data is pushed into the heatmap from the right. The streamgraph in the lower part of the represen- tation encodes incoming and outgoing connections. The height of the first inner layer corresponds to the number of connections with directly linked components. With each layer the distance in the hi- erarchy increases, as indicated by a decreasing brightness. ", "caption_bbox": [73, 412, 408, 563]}, {"image_id": 5, "file_name": "381_05.png", "page": 6, "dpi": 300, "bbox": [79, 76, 764, 232], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Hierarchy represented by the different layout approaches available in CloudGazer.", "caption_bbox": [190, 238, 658, 251]}, {"image_id": 6, "file_name": "381_06.png", "page": 7, "dpi": 300, "bbox": [77, 89, 770, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Server perspective with the selected server \u2018cb2\u2019 and the corresponding inlay with related VMs and applications. The two stacked bars encode the components\u2019 main memory and disk space (dark gray = used, light gray = free, white = empty space to make bars comparable across components, i.e., only present if available memory is different between components on the same hierarchy level). To reduce the connection distances between the VMs \u2018tele 1\u2019, \u2018tele 2\u2019, and \u2018tele 3\u2019, the administrator reassigns the VM \u2018tele 2\u2019 to server \u2018rsw1\u2019 via drag-and-drop. ", "caption_bbox": [73, 277, 775, 345]}], "382": [{"image_id": 0, "file_name": "382_00.png", "page": 4, "dpi": 300, "bbox": [137, 74, 706, 416], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The graphical user interface. (a) The Map View. Plan-view overlay of a transect on the LULC layer, visualizing surface temperatures. Surface temperatures are higher (dark red) on asphalt, and cooler on grass LULC. (b) The Fraction Plot, showing the LULC fractions within the surface temperature infrared radiometer\u2019s field of view. (c) The pie-chart that complements the fraction plot. (d) Classification result based on surface temperature and land use fractions in the infrared radiometer\u2019s source area. ", "caption_bbox": [73, 431, 775, 483]}, {"image_id": 1, "file_name": "382_01.png", "page": 4, "dpi": 300, "bbox": [500, 514, 721, 683], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A wall in close up view, showing a segment of a transect run included in our sample data set: surface temperature, 1 m rela- tive humidity, 1 m air temperature, 2 m relative humidity, and 2 m air temperature (from bottom to top). The lowest layer shows the LULC class of the particular route nodes; trees dark green, soil/gravel yel- low, grass light green, hardscape light grey. Note the visual pattern of association between LULC, temperature, and humidity. ", "caption_bbox": [440, 702, 775, 793]}, {"image_id": 2, "file_name": "382_02.png", "page": 5, "dpi": 300, "bbox": [464, 76, 754, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The slider can be used to interactively explore the spatial context of the data. The source area is attached to the bottom of the slider, while the fraction plot and the pie chart underneath the map display the composition of LULC fractions within the source area. The ellipsoid exemplifies the source area for air temperature mea- sured at a height of 1 m. ", "caption_bbox": [440, 283, 775, 361]}, {"image_id": 3, "file_name": "382_03.png", "page": 6, "dpi": 300, "bbox": [113, 82, 370, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The cluster interface, which is linked to the main GUI de- picted in Figure 1. In the background, the lengths of the weight vec- tors associated with the individual self-organizing map (SOM) nodes are visualized. The borders of the nodes represent each node\u2019s clus- ter membership after the k-means clustering has been applied. ", "caption_bbox": [73, 292, 408, 357]}, {"image_id": 4, "file_name": "382_04.png", "page": 7, "dpi": 300, "bbox": [144, 75, 705, 378], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A use case for our framework. In this example, we analyze the classification of a transect route into similar microenvironmental segments, based on a combined SOM and k-means clustering algorithm [37, 38] over all measured quantities. This clustering is based purely on associations between (in order of stacking from surface) surface temperature, air temperature, and relative humidity at 1 m and 2 m AGL heights. (a) displays the visualization of the clustering output. (b) shows the distribution of the cluster members along the transect route from the birds-view perspective. Note the correlations between patches of land use and cluster membership. (c) and (d) visualize the meaning of the different clusters in terms of multivariate value distribution, with (c) showing the wall from the south, (d) from the north. ", "caption_bbox": [73, 393, 775, 471]}], "383": [{"image_id": 0, "file_name": "383_00.png", "page": 1, "dpi": 300, "bbox": [127, 112, 723, 484], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A screenshot of VisMOOC. It consists of three views: the List View on the left, the Content-based View (including the video player, the seek graph and the event graph) in the middle, and the Dashboard View on the right. The Dashboard View includes the course information, the geographic distribution, the video temporal information, the video popularity, and the animation. ", "caption_bbox": [73, 499, 775, 538]}, {"image_id": 1, "file_name": "383_01.png", "page": 4, "dpi": 300, "bbox": [75, 74, 410, 164], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Comparison among three design candidates: (a) arc dia- gram; (b) scatter plots; (c) parallel coordinates. Blue color encodes the seek event happened when learners watched the video for the first time, while orange color encodes the seek event happened when learners reviewed the video. ", "caption_bbox": [73, 180, 410, 245]}, {"image_id": 2, "file_name": "383_02.png", "page": 5, "dpi": 300, "bbox": [444, 850, 776, 968], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The calendar view shows the temporal popularity for the selected video. We can see that there are two weeks with a lot of acitons. ", "caption_bbox": [440, 983, 775, 1022]}, {"image_id": 3, "file_name": "383_03.png", "page": 5, "dpi": 300, "bbox": [440, 351, 776, 499], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A world map show the distribution of learners around the world for the Course GT. We can see that the majority of learners are from the U.S, while all the learners are from more than 150 countries. ", "caption_bbox": [439, 516, 777, 555]}, {"image_id": 4, "file_name": "383_04.png", "page": 5, "dpi": 300, "bbox": [440, 74, 766, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The histogram shows the popularity of videos. The color encodes the video type and height encodes the number of learners. We can see that the popularity becomes stable after two weeks for both courses. ", "caption_bbox": [439, 283, 777, 335]}, {"image_id": 5, "file_name": "383_05.png", "page": 6, "dpi": 300, "bbox": [440, 448, 774, 568], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The Content Views for the same video shown in Figure 1 but with different time periods. a) the clickstream data from the first week when the video released; b) the clickstream data from the week when the related assignment released. ", "caption_bbox": [439, 586, 775, 638]}, {"image_id": 6, "file_name": "383_06.png", "page": 6, "dpi": 300, "bbox": [75, 840, 408, 959], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparison between the Content-based views of two videos with a in-video question. ", "caption_bbox": [73, 977, 409, 1002]}, {"image_id": 7, "file_name": "383_07.png", "page": 6, "dpi": 300, "bbox": [79, 75, 411, 221], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Event graphs show the distribution of different clickstreams in different types of videos in Course GT : a) the lecture video; b) the assignment video; c) the experiment video; d) the experiment video with an in-video question. ", "caption_bbox": [73, 237, 409, 289]}, {"image_id": 8, "file_name": "383_08.png", "page": 7, "dpi": 300, "bbox": [77, 289, 405, 498], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The Event Graphs showing the clickstream data of the same course during the same time period but for learners from differ- ent countries. a) Learners from the U.S; b) Learners from China. We can clearly see that the percentage of seek events happened in the U.S is much larger than the one in China. ", "caption_bbox": [73, 516, 410, 581]}, {"image_id": 9, "file_name": "383_09.png", "page": 7, "dpi": 300, "bbox": [75, 74, 755, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Animations show three patterns: a) pause events and play events are dominant when learners watch the videos for the first time; b) seek events are dominant when learners review the videos; c) there is a burst of events on the exam day. ", "caption_bbox": [73, 253, 775, 278]}], "384": [{"image_id": 0, "file_name": "384_00.png", "page": 1, "dpi": 300, "bbox": [118, 86, 753, 415], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Data sets used for performance tests (from left to right): the Abdominal (340 MB, 16-bit per sample), the Stag Beetle (652 MB, 16-bit per sample) and the Bat data set (1.2 GB, 8-bit per sample). They are rendered with the Warp Marching algorithm. ", "caption_bbox": [73, 436, 775, 461]}, {"image_id": 1, "file_name": "384_01.png", "page": 2, "dpi": 300, "bbox": [453, 301, 769, 431], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The distance between four samples in c and d is the same; while that between a and b is different. ", "caption_bbox": [440, 463, 775, 488]}, {"image_id": 2, "file_name": "384_02.png", "page": 2, "dpi": 300, "bbox": [98, 419, 381, 547], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Effects of different viewing directions.", "caption_bbox": [123, 578, 354, 590]}, {"image_id": 3, "file_name": "384_03.png", "page": 3, "dpi": 300, "bbox": [129, 73, 352, 206], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Different computation-to-core mapping strategies.", "caption_bbox": [95, 237, 387, 249]}, {"image_id": 4, "file_name": "384_04.png", "page": 3, "dpi": 300, "bbox": [84, 383, 411, 820], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Three general cases (A, B) and two special cases (C, D) of the iso-surface Warp Marching (the warp size is 8 in this figure). ", "caption_bbox": [73, 850, 408, 875]}, {"image_id": 5, "file_name": "384_05.png", "page": 4, "dpi": 300, "bbox": [78, 446, 398, 750], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The effect of projection method to the texture cache hit rate. The horizontal axis shows the field of view angles, and 0\u25e6 indicates an orthographic projection. ", "caption_bbox": [73, 782, 408, 821]}], "385": [{"image_id": 0, "file_name": "385_00.png", "page": 4, "dpi": 300, "bbox": [73, 105, 774, 402], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Two-sided Hausdorff distance between a low-resolution (20x20) and a high-resolution (200x200) surface. ", "caption_bbox": [73, 822, 408, 849]}], "386": [{"image_id": 0, "file_name": "386_00.png", "page": 1, "dpi": 300, "bbox": [462, 286, 766, 421], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The visualization framework based on hierarchical", "caption_bbox": [458, 430, 756, 442]}, {"image_id": 1, "file_name": "386_01.png", "page": 2, "dpi": 300, "bbox": [557, 823, 672, 912], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An approximate contour traced across MS complex cells.", "caption_bbox": [441, 919, 773, 931]}, {"image_id": 2, "file_name": "386_02.png", "page": 3, "dpi": 300, "bbox": [440, 162, 776, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Create topology-based spaghetti plots.", "caption_bbox": [484, 227, 729, 239]}, {"image_id": 3, "file_name": "386_03.png", "page": 3, "dpi": 300, "bbox": [510, 503, 720, 578], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The mapping scheme for producing a visual ribbon.", "caption_bbox": [455, 591, 760, 603]}, {"image_id": 4, "file_name": "386_04.png", "page": 3, "dpi": 300, "bbox": [170, 350, 325, 484], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Contours (blue) by Conrec [27], contour approximation", "caption_bbox": [81, 491, 401, 503]}, {"image_id": 5, "file_name": "386_05.png", "page": 3, "dpi": 300, "bbox": [445, 819, 771, 914], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Compare the topology-based spaghetti plot with usual", "caption_bbox": [449, 926, 766, 938]}, {"image_id": 6, "file_name": "386_06.png", "page": 4, "dpi": 300, "bbox": [439, 542, 771, 865], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Compare between contouring methods: contour", "caption_bbox": [464, 530, 751, 542]}, {"image_id": 7, "file_name": "386_07.png", "page": 4, "dpi": 300, "bbox": [72, 261, 411, 473], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visualize multiple variables of a hurricane data in", "caption_bbox": [94, 480, 387, 492]}, {"image_id": 8, "file_name": "386_08.png", "page": 4, "dpi": 300, "bbox": [439, 73, 777, 331], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visualize an ocean flow velocity field with multi-resolution", "caption_bbox": [441, 330, 774, 342]}], "387": [{"image_id": 0, "file_name": "387_00.png", "page": 2, "dpi": 300, "bbox": [171, 73, 682, 391], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Selection of distance maps based on 3D scans of a car trunk lid, displayed color-coded on the quota grid. The colorscale ranges from black (zero) over red to yellow. ", "caption_bbox": [73, 423, 775, 448]}, {"image_id": 1, "file_name": "387_01.png", "page": 3, "dpi": 300, "bbox": [531, 734, 686, 820], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A simple 1D example with three functions f1 , f2 and f3 and the corresponding Pareto extrema. ", "caption_bbox": [440, 848, 775, 873]}, {"image_id": 2, "file_name": "387_02.png", "page": 3, "dpi": 300, "bbox": [196, 332, 655, 520], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Image analogous to Figure 2 with different smoothing parameters (I: 20, FWHM: 3, and ND: 5). Note how the oversimplification removed most of the interesting features visible in Figure 2. ", "caption_bbox": [73, 552, 775, 577]}, {"image_id": 3, "file_name": "387_03.png", "page": 3, "dpi": 300, "bbox": [195, 73, 655, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The weighted Pareto set on the trunk lid for the six distance maps shown in Figure 1 after a Gaussian smoothing with the parameters I: 10, FWHM: 6, and ND: 5. ", "caption_bbox": [73, 293, 775, 318]}, {"image_id": 4, "file_name": "387_04.png", "page": 4, "dpi": 300, "bbox": [473, 74, 743, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Image similar to Figure 2 (smoothing parameters I: 10, FWHM: 3, ND: 3). Note how most of the Pareto extrema can be found in slopes of the trunk lid. ", "caption_bbox": [440, 378, 775, 417]}], "388": [{"image_id": 0, "file_name": "388_00.png", "page": 1, "dpi": 300, "bbox": [76, 86, 774, 569], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: SentiCompass of tweets collected during Wales vs. New Zealand rugby union match (5:40-7:10pm (UTC), 22 Nov, 2014). Individual visual features are indexed in this illustration to facilitate detailed explanations in Table 1. ", "caption_bbox": [73, 583, 775, 608]}, {"image_id": 1, "file_name": "388_01.png", "page": 3, "dpi": 300, "bbox": [440, 73, 778, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The visual metaphor of SentiCompass combining circum- plex model and perspective time tunnel representation. ", "caption_bbox": [440, 303, 775, 328]}, {"image_id": 2, "file_name": "388_02.png", "page": 4, "dpi": 300, "bbox": [84, 319, 768, 548], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: SentiCompass of 122,393 tweets collected during 2013 Australian election period. The election day is highlighted.", "caption_bbox": [121, 566, 727, 578]}, {"image_id": 3, "file_name": "388_03.png", "page": 4, "dpi": 300, "bbox": [176, 74, 676, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparing sentiments of tweets on two rugby union matches on 22 Nov, 2014 (UTC).", "caption_bbox": [190, 293, 659, 305]}], "389": [{"image_id": 0, "file_name": "389_00.png", "page": 1, "dpi": 300, "bbox": [108, 86, 742, 503], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Proposed visual design for an interactive tool to enable multilevel visual exploration of LBSN data in the                     context of land use planning. (Left: Temporal view - Right: Spatial view) ", "caption_bbox": [137, 513, 711, 540]}, {"image_id": 1, "file_name": "389_01.png", "page": 3, "dpi": 300, "bbox": [494, 352, 727, 541], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Detailed view of the third ring (yearly view) and fourth ring (time range selection) showing a ring segment corresponding                       to one month of a year. ", "caption_bbox": [443, 564, 772, 605]}, {"image_id": 2, "file_name": "389_02.png", "page": 3, "dpi": 300, "bbox": [484, 83, 739, 259], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Detailed view of a segment of the first ring (daily view) and second ring (time range selection) showing total and average     number of events included in the current time selection. ", "caption_bbox": [443, 283, 771, 324]}, {"image_id": 3, "file_name": "389_03.png", "page": 4, "dpi": 300, "bbox": [502, 372, 719, 455], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Tool bar of spatial view", "caption_bbox": [523, 478, 692, 491]}, {"image_id": 4, "file_name": "389_04.png", "page": 4, "dpi": 300, "bbox": [493, 92, 724, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Detailed view of the spatial distribution display. (Left: selection of two land use districts - Right: spatial distribution of               registered events in selected districts). ", "caption_bbox": [446, 300, 768, 341]}], "39": [{"image_id": 0, "file_name": "39_00.png", "page": 1, "dpi": 300, "bbox": [425, 627, 729, 672], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Textual representation of a DNA sequence", "caption_bbox": [421, 680, 735, 694]}, {"image_id": 1, "file_name": "39_01.png", "page": 2, "dpi": 300, "bbox": [421, 304, 741, 644], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Colour representation of a DNA sequence", "caption_bbox": [421, 651, 732, 665]}, {"image_id": 2, "file_name": "39_02.png", "page": 3, "dpi": 300, "bbox": [78, 79, 398, 418], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3:     Representing content of a DNA sequence ", "caption_bbox": [78, 425, 240, 455]}, {"image_id": 3, "file_name": "39_03.png", "page": 3, "dpi": 300, "bbox": [78, 632, 398, 971], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Separating the codons of a DNA sequence", "caption_bbox": [78, 979, 388, 993]}, {"image_id": 4, "file_name": "39_04.png", "page": 3, "dpi": 300, "bbox": [413, 258, 741, 991], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Discovering repeat patterns in a DNA sequence ", "caption_bbox": [421, 1002, 746, 1032]}, {"image_id": 5, "file_name": "39_05.png", "page": 4, "dpi": 300, "bbox": [93, 546, 413, 885], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Representing variable regions", "caption_bbox": [78, 912, 319, 926]}, {"image_id": 6, "file_name": "39_06.png", "page": 5, "dpi": 300, "bbox": [541, 210, 629, 532], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: User control window", "caption_bbox": [421, 564, 608, 578]}, {"image_id": 7, "file_name": "39_07.png", "page": 5, "dpi": 300, "bbox": [84, 79, 399, 409], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Showing the amino acid groups and their              representative colours ", "caption_bbox": [90, 841, 392, 871]}, {"image_id": 8, "file_name": "39_08.png", "page": 6, "dpi": 300, "bbox": [422, 79, 742, 697], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Overview versus detail", "caption_bbox": [421, 708, 626, 722]}], "390": [{"image_id": 0, "file_name": "390_00.png", "page": 1, "dpi": 300, "bbox": [74, 86, 778, 397], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The web-based user interface of our visual survey called Text Visualization Browser. By using the interaction panel on the left hand side, researchers can look for specific visualization techniques and filter out entries with respect to a set of categories (cf. the taxonomy given in Sect. 3). Details for a selected entry are shown by clicking on a thumbnail image in the main view. The survey contains 141 categorized visualization techniques by January 19, 2015. ", "caption_bbox": [73, 401, 775, 453]}, {"image_id": 1, "file_name": "390_01.png", "page": 2, "dpi": 300, "bbox": [74, 74, 714, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: The comparison of text visualization taxonomies. Supported categories are marked by \u2019+\u2019, partial support denoted by \u2019(+)\u2019.", "caption_bbox": [104, 390, 744, 402]}, {"image_id": 2, "file_name": "390_02.png", "page": 3, "dpi": 300, "bbox": [445, 342, 768, 470], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Details of a survey entry.", "caption_bbox": [522, 477, 692, 489]}, {"image_id": 3, "file_name": "390_03.png", "page": 4, "dpi": 300, "bbox": [127, 575, 354, 812], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Co-authorship network for current survey entries visualized in Gephi with the ForceAtlas layout. Note the big connected compo- nent on the left hand side containing 106 author nodes. ", "caption_bbox": [73, 819, 408, 858]}, {"image_id": 4, "file_name": "390_04.png", "page": 4, "dpi": 300, "bbox": [75, 66, 776, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The basic statistics for technique categories which are displayed as bar charts in the \u201cAbout\u201d dialog on demand.", "caption_bbox": [127, 345, 722, 357]}], "391": [{"image_id": 0, "file_name": "391_00.png", "page": 1, "dpi": 300, "bbox": [83, 101, 765, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1. Some experimental results of using Radviz on the iris data. (a) the best visualization result on the original four dimensions; (b) an      optimal visualization result found by partitioning a single dimension; (c) an optimal visualization result found by extending two  dimensions; (d) an over-separated visualization result is brought out by an improper dimension placement; (e) the significant overlapped           result is brought out by using binary method of VRV to encode all the dimension values after the dimension expansion. ", "caption_bbox": [84, 366, 763, 422]}, {"image_id": 1, "file_name": "391_01.png", "page": 2, "dpi": 300, "bbox": [86, 491, 758, 682], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "    Figure 2. The illustrations of the probability distribution histogram and the dimension expansion in Radviz. (a) the above is the data distribution of dimension A and B in a categorical dataset and the below is the histogram of probability distribution of dimension A; (b) the above shows the data distribution of dimension A and B in a continuous dataset and the below is the histogram of probability distribution of    dimension A; (c) the visualization of a dataset with three continuous dimensions in Radviz; (d) the better visualization in Radviz after                                extending dimension A into two dimensions and reordering the four dimensions. ", "caption_bbox": [83, 687, 765, 757]}, {"image_id": 2, "file_name": "391_02.png", "page": 3, "dpi": 300, "bbox": [161, 867, 332, 966], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. The illustration of mean shift algorithm", "caption_bbox": [125, 966, 366, 981]}, {"image_id": 3, "file_name": "391_03.png", "page": 3, "dpi": 300, "bbox": [83, 241, 405, 419], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "    Figure 3. The probability distribution histograms of four dimensions in the iris data and their segmentation results by mean                    shift (the bandwidth = 0.2). ", "caption_bbox": [84, 425, 407, 468]}, {"image_id": 4, "file_name": "391_04.png", "page": 4, "dpi": 300, "bbox": [465, 312, 738, 469], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6. Two experimental results on the ecoli data. (a) the best   visualization result on the original seven dimensions; (b) an  optimal visualization after the multiple dimension expansion. ", "caption_bbox": [445, 473, 760, 516]}, {"image_id": 5, "file_name": "391_05.png", "page": 4, "dpi": 300, "bbox": [464, 83, 742, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5. Two experimental results on the seeds data. (a) the", "caption_bbox": [461, 245, 756, 260]}], "392": [{"image_id": 0, "file_name": "392_00.png", "page": 1, "dpi": 300, "bbox": [481, 504, 736, 724], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A typical VMD [11] visualization of the alpha electron local- ization function resulting from a CPMD simulation. ", "caption_bbox": [440, 739, 775, 764]}, {"image_id": 1, "file_name": "392_01.png", "page": 4, "dpi": 300, "bbox": [119, 73, 731, 214], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Three still images taken from an ERICA of the 2HO\u2217 (aq) \u2192 H2 O + O(aq) reaction from [4] - Reproduced by permission of the PCCP Owner Societies. The yellow and green point clouds represent the positive and negative spin densities of the system near the HO*\u2019s, respectively. The red and cream spheres with tails correspond to the oxygen and hydrogen atoms, respectively. The images and SI videos are shown in perspective with a \u03c0/4 shear. A) The two HO*\u2019s prior to the reaction. B) The reaction as the hydrogen atom from one HO* is transferred to the other. C) The newly formed oxygen atom as the newly formed water molecule departs. ", "caption_bbox": [73, 226, 775, 293]}], "393": [{"image_id": 0, "file_name": "393_00.png", "page": 2, "dpi": 300, "bbox": [457, 74, 760, 191], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: RoseShapes with different petal types.", "caption_bbox": [486, 204, 728, 217]}, {"image_id": 1, "file_name": "393_01.png", "page": 2, "dpi": 300, "bbox": [75, 134, 408, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: RoseShapes with different a parameters, \u22121, \u22120.25, 0.5, 0.75 and 1 from top to bottom. ", "caption_bbox": [440, 588, 775, 616]}, {"image_id": 2, "file_name": "393_02.png", "page": 2, "dpi": 300, "bbox": [441, 416, 775, 577], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: The mapping relationship between parameters and glyph characteristics. ", "caption_bbox": [440, 748, 775, 775]}, {"image_id": 3, "file_name": "393_03.png", "page": 2, "dpi": 300, "bbox": [114, 670, 368, 784], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: RoseShapes controlled by a.", "caption_bbox": [144, 795, 337, 808]}, {"image_id": 4, "file_name": "393_04.png", "page": 3, "dpi": 300, "bbox": [75, 539, 408, 669], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Colored RoseShapes using the alpha filling algorithm.", "caption_bbox": [80, 680, 401, 693]}, {"image_id": 5, "file_name": "393_05.png", "page": 3, "dpi": 300, "bbox": [90, 316, 393, 485], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Scan line algorithm applied to RoseShapes.", "caption_bbox": [107, 496, 375, 509]}, {"image_id": 6, "file_name": "393_06.png", "page": 4, "dpi": 300, "bbox": [265, 77, 585, 460], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The U.S. education funding visualized using RoseShapes.", "caption_bbox": [254, 473, 593, 486]}], "394": [{"image_id": 0, "file_name": "394_00.png", "page": 2, "dpi": 300, "bbox": [468, 73, 748, 395], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visualizations for a matching based on the directional distance similarity measure. (a) Trajectories and a corresponding matching. (b) The delay space and a matching. ", "caption_bbox": [440, 408, 775, 449]}, {"image_id": 1, "file_name": "394_01.png", "page": 2, "dpi": 300, "bbox": [164, 73, 317, 164], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A metric space with p \u2208 T1 and q \u2208 T2", "caption_bbox": [116, 189, 364, 205]}, {"image_id": 2, "file_name": "394_02.png", "page": 3, "dpi": 300, "bbox": [88, 74, 391, 201], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) Trajectory with a zig-zag movement pattern and a straight trajectory. (b) Delay space based on the directional distance similarity measure. The strong color change corresponds to the zig- zag pattern. ", "caption_bbox": [73, 214, 408, 269]}, {"image_id": 3, "file_name": "394_03.png", "page": 3, "dpi": 300, "bbox": [439, 74, 776, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Screenshot of the tool, showing the delay space (1), the trajectory visualization (2) with an enlarged section of it (B), the distance plot (3), and the delay plot (4). Ahead/behind behavior is visualized by a glyph, shown enlarged in (A). ", "caption_bbox": [440, 382, 775, 437]}, {"image_id": 4, "file_name": "394_04.png", "page": 4, "dpi": 300, "bbox": [471, 78, 727, 435], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Detecting a loop in the Ultimate Frisbee data. (a) Match- ing based on the dynamic interaction similarity measure by Long and Nelson [8] does not highlight the loop pattern as an interac- tion event. (b) Matching based on the directional distance similarity measure detects the loop pattern as shown clearly by the blue patch. (c) The distance plot. (d) The delay plot shows a sign change at the point where the loop occurs. ", "caption_bbox": [440, 448, 775, 544]}, {"image_id": 5, "file_name": "394_05.png", "page": 4, "dpi": 300, "bbox": [73, 74, 410, 145], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: An action-reaction pattern in the distances.", "caption_bbox": [108, 170, 373, 183]}, {"image_id": 6, "file_name": "394_06.png", "page": 4, "dpi": 300, "bbox": [73, 199, 410, 391], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualization of pigeon trajectories and corresponding delay space based on the directional distance similarity measure. ", "caption_bbox": [73, 416, 408, 443]}], "395": [{"image_id": 0, "file_name": "395_00.png", "page": 2, "dpi": 300, "bbox": [439, 498, 777, 563], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Interactions on Circular Filter: different functions are in- voked by hovering on corresponding regions. Direction between fil- ters is assigned by dragging from one to another. ", "caption_bbox": [440, 578, 775, 617]}, {"image_id": 1, "file_name": "395_01.png", "page": 2, "dpi": 300, "bbox": [108, 74, 743, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: System Pipeline: the whole tool consists of four parts, from the left to the right, off-line trajectory preprocessing, interactive trajectory filter, automatic OD clusters extraction and OD pattern visual analysis. ", "caption_bbox": [73, 260, 775, 286]}, {"image_id": 2, "file_name": "395_02.png", "page": 2, "dpi": 300, "bbox": [439, 649, 777, 738], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Circular Filter Design: (a) circular filter glyph: carry pas- senger status, street name, radius and spatial filter with location con- strains are explicitly encoded. Gray without-passenger status is in- valid here. (b) six types of spatial filters (the left-top circle in glyph) with different location constrains. ", "caption_bbox": [440, 753, 775, 818]}, {"image_id": 3, "file_name": "395_03.png", "page": 3, "dpi": 300, "bbox": [87, 217, 407, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Date-time Temporal Filter: the oranges indicate those se- lected time range and the greens represent the weekends. ", "caption_bbox": [73, 265, 408, 291]}, {"image_id": 4, "file_name": "395_04.png", "page": 3, "dpi": 300, "bbox": [73, 632, 411, 775], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Overview: (a) clsuters\u2019 spatial view. (b) average trajectory distribution on weekdays. (c) average trajectory distribution at week- ends. (d) travel time and travel distance histograms. ", "caption_bbox": [73, 791, 408, 830]}, {"image_id": 5, "file_name": "395_05.png", "page": 3, "dpi": 300, "bbox": [443, 207, 774, 491], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visual Design of OD-Wheel: (a) linear and circular view displays the temporal distribution of travel flow volumes. (b) an alter- native to linear view which plots the distribution of travel time. ", "caption_bbox": [440, 508, 775, 547]}, {"image_id": 6, "file_name": "395_06.png", "page": 4, "dpi": 300, "bbox": [73, 73, 777, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Travel Time Exploration of a Central Region: region around Beijing Railway Station is selected as central region. (a) the top five O and D clusters are plotted on map and OD-Wheel visualizes the temporal dynamics of traffic flow volume and travel time. Its bidirectional traffic flows with Beijing Railway Station and Beijing West Railway Station are stacked, to compare traffic volume in opposite direction; (b) selecting the blue region in dotted box, trajectories travelling are shown; (c, d) travel routes with normal travel time and abnormal travel time are plotted respectively. ", "caption_bbox": [73, 239, 775, 304]}], "397": [{"image_id": 0, "file_name": "397_00.png", "page": 1, "dpi": 300, "bbox": [111, 86, 739, 500], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview screenshot of the MultiStory system.", "caption_bbox": [279, 512, 569, 525]}, {"image_id": 1, "file_name": "397_01.png", "page": 2, "dpi": 300, "bbox": [83, 435, 400, 625], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of the framework", "caption_bbox": [146, 636, 335, 649]}, {"image_id": 2, "file_name": "397_02.png", "page": 3, "dpi": 300, "bbox": [74, 458, 413, 753], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Task 1: A SocializeTwicePerWeek dynamic cluster (red box) with filtered most similar clusters from other relationships. Some have high similarities with the chosen cluster, while others less so despite being the most similar from that relationship. ", "caption_bbox": [73, 763, 408, 818]}, {"image_id": 3, "file_name": "397_03.png", "page": 3, "dpi": 300, "bbox": [443, 79, 776, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Task 3: Similarity calculations for (A) SocializeTwi- cePerWeek cluster #4 with a threshold of 0.17 and (B) Social- izeTwicePerWeek cluster #5 with a threshold of 0.1 , with the SocializeTwicePerWeek clusters highlighted in red. Only clusters from PoliticalDiscussant (dark green) and BlogLivejournalTwitter (light blue) exceed these specified thresholds. ", "caption_bbox": [440, 330, 775, 412]}, {"image_id": 4, "file_name": "397_04.png", "page": 3, "dpi": 300, "bbox": [446, 609, 775, 791], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Task 4: PoliticalDiscussant Storylines with residents of the same dorm section highlighted. Note that most of the time the actors keep within the same cluster both in the main relationship and in some of the alternate relationships. ", "caption_bbox": [440, 806, 775, 861]}, {"image_id": 5, "file_name": "397_05.png", "page": 4, "dpi": 300, "bbox": [104, 697, 377, 932], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Task 6: Comparison of phone communications patterns of friendship clusters with different eigenvector centralities. The clus- ter with higher eigenvector centralities not only has denser intra- cluster arcs, but also more arcs coming from other clusters. ", "caption_bbox": [73, 944, 408, 999]}, {"image_id": 6, "file_name": "397_06.png", "page": 4, "dpi": 300, "bbox": [82, 207, 411, 511], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Task 5: Causal analysis between phone correspondences and relationship changes. The highlighted participants have been corresponding with members of a different cluster before joining it. ", "caption_bbox": [73, 522, 408, 563]}, {"image_id": 7, "file_name": "397_07.png", "page": 4, "dpi": 300, "bbox": [450, 76, 765, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Task 8: Anomaly detection using visualisation (InterArc), analysis (filtering), and interaction (temporal zoom- ing). Reduced proximity records are detected by statistical filtering, and a more exact time frame is found using temporal zooming. ", "caption_bbox": [440, 356, 775, 411]}], "398": [{"image_id": 0, "file_name": "398_00.png", "page": 2, "dpi": 300, "bbox": [446, 76, 774, 231], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) the layout of Li\u22121 ; (b) the layout of Li\u2217 , which represents the ideal layout without preserving the mental map and with great aesthetic criteria; (c) the layout of Li after running our LCDE algorithm (\u03b1 = 10), which keeps a good balance between the aesthetic criteria against the mental map preservation. ", "caption_bbox": [440, 249, 775, 314]}, {"image_id": 1, "file_name": "398_01.png", "page": 2, "dpi": 300, "bbox": [469, 331, 753, 503], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Layouts of Li with different \u03b1 values: (a) \u03b1 = 0.1; (b) \u03b1 = 1.", "caption_bbox": [440, 522, 775, 535]}, {"image_id": 2, "file_name": "398_02.png", "page": 3, "dpi": 300, "bbox": [439, 89, 778, 931], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparison of the layout results of the new fraternity data [26]: (a) the results generated by our method; (b) the results generated by the online dynamic graph drawing algorithm [17] ", "caption_bbox": [440, 950, 775, 989]}, {"image_id": 3, "file_name": "398_03.png", "page": 4, "dpi": 300, "bbox": [80, 80, 764, 219], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) the collaboration graph of 2004, (b) the collaboration graph of 2005, (c) the collaboration graph of 2006, (d) the collaboration graph of 2007. Some sub-graph structures for example in red triangle and blue rectangle, are kept during the collaboration graph changing overtime. ", "caption_bbox": [73, 234, 775, 259]}], "399": [{"image_id": 0, "file_name": "399_00.png", "page": 1, "dpi": 300, "bbox": [424, 86, 777, 410], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Head Mounted Devices render a warped view with tight control for each eye. Our approach for graph visualization uses tech- niques targeted specifically for such displays. Color in all figures cor- responds to clusters. ", "caption_bbox": [440, 424, 775, 476]}, {"image_id": 1, "file_name": "399_01.png", "page": 2, "dpi": 300, "bbox": [451, 74, 765, 135], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Mapping a 2D layout to a sphere. Na\u0131\u0308ve azimuthal projec- tion distorts distances (a). Warping the space according by d = tan(d) produces even radial spacing (b). ", "caption_bbox": [440, 153, 775, 192]}, {"image_id": 2, "file_name": "399_02.png", "page": 3, "dpi": 300, "bbox": [489, 404, 727, 512], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Hierarchical edge bundling routes edges with splines that follow the clustering hierarchy. For a sphere, we compute the spline in two stages. An angular spline (in yellow) is computed with spher- ical interpolation according to control points on the surface of the sphere (red points). Then the spline is extended radially by moving the control points outward (blue) and modulating the radius of the edge samples as a 1D spline (green). ", "caption_bbox": [440, 526, 775, 617]}, {"image_id": 3, "file_name": "399_03.png", "page": 3, "dpi": 300, "bbox": [84, 73, 766, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Spherical graph layouts: 2D layouts can be mapped to the sphere with varying amounts of distortion. Preserving angles (a) is appropriate for rigid, rectangular structures, but is limited in field of view (FOV). Azimuthal mapping (b) works well for roughly circular layouts to use a full hemisphere. For full immersion (c), we use a space filling curve defined on a cubed sphere to cover the entire surface. ", "caption_bbox": [73, 340, 775, 379]}, {"image_id": 4, "file_name": "399_04.png", "page": 4, "dpi": 300, "bbox": [442, 73, 776, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: In a 2D view, the whole graph may be visible, but there is no discernable shape to the edges, making them difficult to follow. In a VR environment, only a small section of the graph is visible at a given time, but structure is more tangible. ", "caption_bbox": [440, 274, 775, 326]}, {"image_id": 5, "file_name": "399_05.png", "page": 4, "dpi": 300, "bbox": [74, 73, 409, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: When the user selects a node, it and all its neighbors were brought closer to the user, rendered with a halo effect, and labelled. Here, this is shown at an angle for illustrative purposes; in the HMD view, the nodes move straight towards the user. ", "caption_bbox": [73, 274, 408, 326]}], "40": [{"image_id": 0, "file_name": "40_00.png", "page": 4, "dpi": 300, "bbox": [483, 428, 695, 712], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An Articulated Figure Representing a Char- acter\u2019s Skeleton (Source: Jakobsen 2001). ", "caption_bbox": [427, 723, 749, 751]}, {"image_id": 1, "file_name": "40_01.png", "page": 6, "dpi": 300, "bbox": [450, 53, 729, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Movement of the Node to the Desired Posi- tion followed by the Constraint Solver Produces the Final Configuration. ", "caption_bbox": [427, 399, 749, 441]}, {"image_id": 2, "file_name": "40_02.png", "page": 6, "dpi": 300, "bbox": [450, 671, 729, 759], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: As neither nodes are fixed, the edge-length constraint is easily satisfied. ", "caption_bbox": [427, 770, 749, 798]}, {"image_id": 3, "file_name": "40_03.png", "page": 6, "dpi": 300, "bbox": [105, 472, 384, 807], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Initial Configuration Showing Desired Po- sition of End-Effector. ", "caption_bbox": [83, 818, 405, 846]}, {"image_id": 4, "file_name": "40_04.png", "page": 6, "dpi": 300, "bbox": [450, 839, 729, 927], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Both nodes are fixed. It is not possible to satisfy the edge-length constraint, as moving the nodes closer together would violate the fixed nodes constraint. ", "caption_bbox": [427, 938, 749, 994]}, {"image_id": 5, "file_name": "40_05.png", "page": 7, "dpi": 300, "bbox": [105, 579, 384, 902], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: All constraints are satisfied. This is indi- cated by edges of standard width. ", "caption_bbox": [83, 913, 405, 941]}, {"image_id": 6, "file_name": "40_06.png", "page": 7, "dpi": 300, "bbox": [450, 53, 729, 376], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Some edge-length constraints are not sat- isfied. This is indicated by edges of varying width. Thin edges are too long while thick edges are too short. While it cannot be seen here, we also high- light violated edges in red to further emphasise which edge-length constraints are not satisfied. ", "caption_bbox": [427, 387, 749, 470]}, {"image_id": 7, "file_name": "40_07.png", "page": 10, "dpi": 300, "bbox": [82, 166, 760, 915], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Dragging nodes using our dynamics-based skeletal graph interaction system. By ensuring the con- straints are satisfied it quickly produces a much better graph drawing and allows us to improve our under- standing of the graph structure. ", "caption_bbox": [83, 926, 749, 968]}], "400": [{"image_id": 0, "file_name": "400_00.png", "page": 1, "dpi": 300, "bbox": [73, 86, 773, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Clustered edge routing based on a well-separated pair decomposition and a greedy sparsification of the visibility graph on a synthetic data set. One edge cluster is highlighted in red. ", "caption_bbox": [73, 347, 775, 372]}, {"image_id": 1, "file_name": "400_01.png", "page": 3, "dpi": 300, "bbox": [439, 74, 777, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Our routing graph constructed on the TLR4 dataset [4]. The edge types are indicated: (black) visibility edge, (blue) obstacle edge, (green) internal edge. The sparsification has been computed using dilation t = 1.8. No straightening has been applied to this graph. ", "caption_bbox": [440, 377, 775, 429]}, {"image_id": 2, "file_name": "400_02.png", "page": 4, "dpi": 300, "bbox": [106, 74, 377, 160], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) Obstacles are too close. (b) Voronoi diagram within convex hull. (c) Snap Voronoi to convex hull vertices and add internal edges within each cell. ", "caption_bbox": [73, 179, 408, 218]}, {"image_id": 3, "file_name": "400_03.png", "page": 4, "dpi": 300, "bbox": [456, 428, 757, 528], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Hubs and ribbon bases.", "caption_bbox": [524, 540, 690, 552]}, {"image_id": 4, "file_name": "400_04.png", "page": 4, "dpi": 300, "bbox": [110, 863, 374, 974], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Non-merged vs. merged obstacles.", "caption_bbox": [130, 988, 352, 1000]}, {"image_id": 5, "file_name": "400_05.png", "page": 5, "dpi": 300, "bbox": [439, 820, 777, 959], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The greedy (left) and Yao (right) sparsifications.", "caption_bbox": [467, 988, 749, 1000]}, {"image_id": 6, "file_name": "400_06.png", "page": 5, "dpi": 300, "bbox": [135, 74, 348, 146], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: A comparison of the greedy and Yao sparsification methods. Results are averages over 100 random inputs. ", "caption_bbox": [440, 651, 775, 676]}, {"image_id": 7, "file_name": "400_07.png", "page": 6, "dpi": 300, "bbox": [90, 74, 760, 688], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The TLR4 graph from [4] (91 nodes, 124 links), rendered by Cerebral [4] (see inset) and by our algorithm.", "caption_bbox": [142, 703, 706, 715]}, {"image_id": 8, "file_name": "400_08.png", "page": 7, "dpi": 300, "bbox": [443, 597, 781, 943], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: (a) The ordered bundles algorithm from [23] and (b) our method with two ribbons highlighted on the US Airlines graph (235 nodes, 2101 links). ", "caption_bbox": [440, 962, 775, 1001]}, {"image_id": 9, "file_name": "400_09.png", "page": 7, "dpi": 300, "bbox": [499, 74, 718, 174], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Detail of the TLR4 graph from Fig. 8 as drawn by (a) Cerebral [4] and (b) our algorithm. ", "caption_bbox": [440, 193, 775, 218]}, {"image_id": 10, "file_name": "400_10.png", "page": 7, "dpi": 300, "bbox": [76, 74, 411, 955], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: By varying the dilation one can choose between (a,b) a more direction preserving or (c) a more schematic and abstract layout ", "caption_bbox": [73, 974, 408, 999]}, {"image_id": 11, "file_name": "400_11.png", "page": 8, "dpi": 300, "bbox": [80, 77, 408, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: The Tail graph from [23] (8 nodes, 28 links) as rendered by (a) the ordered bundles algorithm and (b) our method. In (a) the edges are drawn as bands using double lines, the single lines are part of the background image and correspond to our blue lines. ", "caption_bbox": [73, 282, 408, 334]}], "401": [{"image_id": 0, "file_name": "401_00.png", "page": 3, "dpi": 300, "bbox": [90, 76, 753, 203], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The layout generation process: (a) Use MDS to gather strong connected cluster nodes together. (b) Original Voronoi treemap represents different clusters with the size attribute. (c) Shrink each Voronoi cell to form cluster polygons and cluster gaps. (d) Arrange external nodes along cluster gaps and adapt the corner-cutting algorithm for each cluster polygon. ", "caption_bbox": [73, 205, 775, 244]}, {"image_id": 1, "file_name": "401_01.png", "page": 3, "dpi": 300, "bbox": [449, 253, 744, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Voronoi cell shrinking; (b) Boundary node encoding.", "caption_bbox": [445, 374, 765, 386]}, {"image_id": 2, "file_name": "401_02.png", "page": 4, "dpi": 300, "bbox": [450, 498, 763, 610], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Overview of our visualization process pipeline. (a) Raw graph datasets; (b) Data processing stage; (c) Layout optimization stage; (d) User interaction stage. ", "caption_bbox": [440, 611, 775, 650]}, {"image_id": 3, "file_name": "401_03.png", "page": 4, "dpi": 300, "bbox": [80, 566, 398, 754], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Four major encoding methods for community quality using curve smoothness, border stroke, color saturation, and blur. The community quality improves from left to right. ", "caption_bbox": [73, 761, 408, 800]}, {"image_id": 4, "file_name": "401_04.png", "page": 8, "dpi": 300, "bbox": [132, 558, 721, 915], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: JDK java package dependency network comprising 2379 classes (vertices). (a) Package java.lang are imported by other classes by default. (b) Classes in package java.awt sometimes import classes from java.util. In the mean time, they depend on classes in the same package to a great extent. (c) Several individual classes from java.lang and java.util with high degrees. (d) The filtered topology structure for sub-package java.nio. (e) The second level structures of sub-package java.awt. ", "caption_bbox": [73, 934, 775, 986]}, {"image_id": 5, "file_name": "401_05.png", "page": 8, "dpi": 300, "bbox": [128, 89, 713, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: This figure shows the DBLP dataset consisting of eleven conferences in the fields of Programming Language, Computer Networks, Operating System and Computer Architecture, etc. Nodes represent papers and edges represent two papers having at least one common author. ", "caption_bbox": [73, 478, 775, 517]}], "402": [{"image_id": 0, "file_name": "402_00.png", "page": 3, "dpi": 300, "bbox": [67, 156, 413, 401], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Influence of compatibility factor on bundling result.", "caption_bbox": [89, 400, 398, 413]}, {"image_id": 1, "file_name": "402_01.png", "page": 4, "dpi": 300, "bbox": [73, 64, 420, 619], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Multi-criteria bundling of an eye tracking dataset.", "caption_bbox": [95, 636, 394, 649]}, {"image_id": 2, "file_name": "402_02.png", "page": 4, "dpi": 300, "bbox": [497, 775, 710, 978], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Aircraft traffic over Paris (bundled with KDEEB). Com- pare with the ADEB directional bundling in Fig. 3 c. ", "caption_bbox": [433, 983, 775, 1010]}, {"image_id": 3, "file_name": "402_03.png", "page": 5, "dpi": 300, "bbox": [88, 66, 758, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Aircraft trails analysis. (a) Raw data. (b) Directional bundling over France. (c) Zoom-in over Paris area.", "caption_bbox": [139, 279, 708, 292]}, {"image_id": 4, "file_name": "402_04.png", "page": 6, "dpi": 300, "bbox": [73, 66, 777, 609], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Bundled eye-tracking trails of novice and expert subjects for a multitask experiment done with two priority conditions.", "caption_bbox": [103, 613, 745, 626]}, {"image_id": 5, "file_name": "402_05.png", "page": 7, "dpi": 300, "bbox": [432, 64, 780, 644], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Raw and bundled eye trails, landing scenario (Sec. 4.2.2).", "caption_bbox": [436, 659, 773, 672]}], "403": [{"image_id": 0, "file_name": "403_00.png", "page": 1, "dpi": 300, "bbox": [74, 144, 776, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Dendrogramix visualizing 6 years (2006\u20132011) of co-authorship at the IEEE InfoVis conference.", "caption_bbox": [166, 392, 682, 404]}, {"image_id": 1, "file_name": "403_01.png", "page": 2, "dpi": 300, "bbox": [462, 80, 756, 198], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Data set used for illustration purpose in Figure 3: (a) points of the plan; and (b) dendrogram of the data using Euclidean distance and single-linkage agglomerative hierarchical clustering. ", "caption_bbox": [440, 211, 775, 250]}, {"image_id": 2, "file_name": "403_02.png", "page": 3, "dpi": 300, "bbox": [80, 106, 402, 322], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: From similarity matrix to Dendrogramix: (a) graphic encod- ing of the similarity; (b) matrix reordered with an (optimal) order com- patible with a traversal of the tree of clusters; (c) graphic encoding of clusters; (d) Dendrogramix compared to (e) classic dendrogram showing the same hierarchical clustering of the same data. ", "caption_bbox": [73, 335, 408, 400]}, {"image_id": 3, "file_name": "403_03.png", "page": 3, "dpi": 300, "bbox": [485, 767, 735, 946], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Cluster detail, research groups are visible as homogeneous (dark) clusters, \u201csocial\u201d people as having many dots connecting them to other people outside their research group. ", "caption_bbox": [440, 961, 775, 1000]}, {"image_id": 4, "file_name": "403_04.png", "page": 4, "dpi": 300, "bbox": [439, 86, 777, 276], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Cluster reordering using drag-and-drop: (a) initial state, (b\u2013c) intermediate states, (d) final state with clusters swapped. ", "caption_bbox": [440, 289, 775, 314]}, {"image_id": 5, "file_name": "403_05.png", "page": 4, "dpi": 300, "bbox": [73, 86, 411, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Items: (a) highlight; and (b) pairwise comparison.", "caption_bbox": [96, 287, 386, 299]}, {"image_id": 6, "file_name": "403_06.png", "page": 4, "dpi": 300, "bbox": [73, 794, 411, 974], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Cluster (a) labeling; and (b) folding.", "caption_bbox": [130, 988, 352, 1000]}, {"image_id": 7, "file_name": "403_07.png", "page": 5, "dpi": 300, "bbox": [96, 709, 392, 971], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Selection of a partition.", "caption_bbox": [159, 988, 322, 1000]}, {"image_id": 8, "file_name": "403_08.png", "page": 5, "dpi": 300, "bbox": [73, 81, 411, 438], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Bringing two clusters side by side: (a\u2013b) crossing-based bi-selection, and (c\u2013d) bi-drag. ", "caption_bbox": [73, 450, 408, 475]}, {"image_id": 9, "file_name": "403_09.png", "page": 6, "dpi": 300, "bbox": [76, 74, 761, 611], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Collaborations between 189 researchers visualized with: (left) a classical dendrogram (CD); and (right) a Dendrogramix (DX) with insights revealed by patterns highlighted in blue (top, \u201cgrid\u201d pattern) and red (middle, \u201ccross\u201d patterns). The names of the researchers have been obfuscated and the figures rotated to better fit on the paper. ", "caption_bbox": [73, 618, 775, 657]}], "404": [{"image_id": 0, "file_name": "404_00.png", "page": 2, "dpi": 300, "bbox": [456, 801, 760, 972], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of our pathline reuse strategy.", "caption_bbox": [483, 987, 731, 1000]}, {"image_id": 1, "file_name": "404_01.png", "page": 2, "dpi": 300, "bbox": [456, 73, 759, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The pipeline of our algorithm.", "caption_bbox": [511, 308, 704, 321]}, {"image_id": 2, "file_name": "404_02.png", "page": 3, "dpi": 300, "bbox": [96, 532, 394, 724], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration of the result after the mapping process.", "caption_bbox": [93, 739, 388, 752]}, {"image_id": 3, "file_name": "404_03.png", "page": 3, "dpi": 300, "bbox": [456, 708, 761, 822], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The layout of the global memory for particles.(a) the whole memory is divided into L layers(4 in this figure); (b) each layer is divided into M \u00d7 N blocks; (c) each block contains the information of one particle. ", "caption_bbox": [440, 840, 775, 892]}, {"image_id": 4, "file_name": "404_04.png", "page": 4, "dpi": 300, "bbox": [446, 142, 787, 355], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Performance comparison in FPS with different life spans. All results are tested on PSI dataset with resolution of 512 \u00d7 512. ", "caption_bbox": [440, 380, 775, 407]}, {"image_id": 5, "file_name": "404_05.png", "page": 4, "dpi": 300, "bbox": [89, 584, 394, 889], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: PSI dataset.", "caption_bbox": [186, 904, 296, 917]}, {"image_id": 6, "file_name": "404_06.png", "page": 5, "dpi": 300, "bbox": [73, 291, 777, 467], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Wind flow dataset.", "caption_bbox": [354, 482, 494, 495]}, {"image_id": 7, "file_name": "404_07.png", "page": 5, "dpi": 300, "bbox": [73, 74, 777, 248], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Double gyre dataset.", "caption_bbox": [348, 263, 499, 276]}, {"image_id": 8, "file_name": "404_08.png", "page": 6, "dpi": 300, "bbox": [72, 770, 778, 943], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: A side-by-side comparison between our approach and GPUFLIC on PSI dataset.", "caption_bbox": [199, 958, 649, 971]}, {"image_id": 9, "file_name": "404_09.png", "page": 6, "dpi": 300, "bbox": [73, 101, 777, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Performance in average FPS.", "caption_bbox": [330, 385, 519, 398]}], "405": [{"image_id": 0, "file_name": "405_00.png", "page": 2, "dpi": 300, "bbox": [124, 311, 356, 875], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The ICE train visualized with UFLIC with the closest point embedding (Fig. 1(a)) and using Flow Charts (Fig. 1(b)). ", "caption_bbox": [73, 894, 408, 919]}, {"image_id": 1, "file_name": "405_01.png", "page": 3, "dpi": 300, "bbox": [95, 74, 752, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Figures 2(a)-2(c) are two-dimensional examples of the closest point embedding. For all figures, the cells close to the surface are colored blue, while cells far away from the surface are colored white. Figure 2(a) is an example surface, a curve embedded in a coarse grid. Figure 2(b) displays part of the fine level of the surface from 2(a), with spacing S = 1/4. An example of the closest point to the surface is shown, where the red cell is at the fine grid position, (23,14) and the projection is visualized with an arrow, and the surface location (the green point) is at (21.3,14.8). Finally, Fig. 2(c) focuses on the fine grid cell (from Fig. 2(b)), which is colored red. To determine the closest point on the surface, the surface vertex (in blue) is fetched. Then, the lines adjacent to the vertex are checked to see if there is a point on them closer to the fine grid cell than the surface vertex. In this example, there is a point (colored green) on a line adjacent to the surface vertex that is closer than the surface vertex. The point on the adjacent line is saved to the fine grid. ", "caption_bbox": [73, 312, 775, 416]}, {"image_id": 2, "file_name": "405_02.png", "page": 3, "dpi": 300, "bbox": [109, 574, 374, 779], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An example of a triangle face (in blue) projected into a co- ordinate plane and the seven different regions numbered. The green vertex is a grid vertex projected into the two-dimensional plane and is in region 3. ", "caption_bbox": [73, 793, 408, 845]}, {"image_id": 3, "file_name": "405_03.png", "page": 4, "dpi": 300, "bbox": [497, 74, 740, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: To construct the sparsely-stored refined grid, the closest point embedding is subdivided. Using the original two-dimensional closest point embedding example from Fig. 2, the fine grid is subdi- vided and two grid cells are each subdivided into eight refined grid cells, in red. ", "caption_bbox": [440, 292, 775, 357]}, {"image_id": 4, "file_name": "405_04.png", "page": 5, "dpi": 300, "bbox": [449, 89, 766, 453], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The airliner (F6) dataset visualized with UFLIC and the closest point embedding (Fig. 6(a)) and using Flow Charts in Fig. 6(b). ", "caption_bbox": [440, 472, 775, 511]}, {"image_id": 5, "file_name": "405_05.png", "page": 5, "dpi": 300, "bbox": [145, 74, 342, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Continuing with the two-dimensional fine grid example from Fig. 4, a single refined grid cell is highlighted in green, with its four neighbors (in two-dimensions) colored yellow. ", "caption_bbox": [73, 292, 408, 331]}, {"image_id": 6, "file_name": "405_06.png", "page": 6, "dpi": 300, "bbox": [78, 73, 769, 231], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: The timing results (in seconds) and dimensions for the datasets. All timing results were performed with an Intel Core i7-3770 with an Nvidia GeForce GTX-780 GPU. ", "caption_bbox": [73, 357, 775, 382]}, {"image_id": 7, "file_name": "405_07.png", "page": 7, "dpi": 300, "bbox": [155, 243, 328, 759], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Engine cylinder visualizations. Figures 8(a) and 8(b) use UFLIC with the closest point embedding and Flow Charts, respec- tively, for visualizing flow in a combustion cylinder. ", "caption_bbox": [73, 777, 408, 816]}], "406": [{"image_id": 0, "file_name": "406_00.png", "page": 3, "dpi": 300, "bbox": [73, 284, 407, 409], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Demonstration of TRS normalization for the example of the 3D characteristic function of a prism. ", "caption_bbox": [73, 425, 408, 454]}, {"image_id": 1, "file_name": "406_01.png", "page": 4, "dpi": 300, "bbox": [74, 531, 410, 630], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The first basis vector fields visualized with hedgehogs and line integral convolution (LIC) [3]. The color map represents the ve- locity. Blue means low and red high velocity. ", "caption_bbox": [73, 646, 408, 688]}, {"image_id": 2, "file_name": "406_02.png", "page": 4, "dpi": 300, "bbox": [75, 787, 411, 939], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Popular flow patterns can be easily constructed from com- binations of the basis vector fields. ", "caption_bbox": [73, 955, 408, 984]}, {"image_id": 3, "file_name": "406_03.png", "page": 5, "dpi": 300, "bbox": [74, 185, 410, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Effect of the rotation operator Ra applied to an example vector field in three different ways. ", "caption_bbox": [73, 308, 408, 337]}, {"image_id": 4, "file_name": "406_04.png", "page": 5, "dpi": 300, "bbox": [439, 79, 777, 179], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: An example flow field is normalized step by step with re- spect to the considered transformations. The color map represents the velocity. Blue means low and red high velocity. ", "caption_bbox": [440, 195, 775, 237]}, {"image_id": 5, "file_name": "406_05.png", "page": 7, "dpi": 300, "bbox": [439, 468, 777, 688], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Volume rendering of the similarity field of the delta wing data set using a vortex template. ", "caption_bbox": [440, 717, 775, 746]}, {"image_id": 6, "file_name": "406_06.png", "page": 7, "dpi": 300, "bbox": [439, 80, 778, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) Left: Volume rendering of the spheres field. The stream- lines are seeded by similarity of the moments. (b) Right: The transfer function for the volume rendering. ", "caption_bbox": [440, 409, 775, 451]}, {"image_id": 7, "file_name": "406_07.png", "page": 7, "dpi": 300, "bbox": [73, 80, 411, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: LIC images through the synthetic field. The field contains a sink (A), an oval vortex (B), a bipole (half hidden here) (C), a vortex added to a quadrupole (D), a saddle (E), a short vortex (F), and a long vortex (G). ", "caption_bbox": [73, 409, 408, 464]}, {"image_id": 8, "file_name": "406_08.png", "page": 8, "dpi": 300, "bbox": [73, 73, 411, 191], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The similarity of the von-Ka\u0301rma\u0301n street to the double vortex on its very right under orthographic projection. ", "caption_bbox": [73, 203, 408, 232]}], "407": [{"image_id": 0, "file_name": "407_00.png", "page": 1, "dpi": 300, "bbox": [460, 267, 756, 528], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Three methods are compared to reveal the feature in Hur- ricane Isabel dataset, a group of vortex-shaped streamlines, orig- inally occluded by other streamlines. (a) original rendering with the features occluded; (b) transparency method is applied (depth sorting is not applied because of its expensive computation); (c) di- rect vertex transformation is applied; (d) our deformation method is applied, which completely removes the occlusions with context information preserved. ", "caption_bbox": [440, 542, 775, 652]}, {"image_id": 1, "file_name": "407_01.png", "page": 3, "dpi": 300, "bbox": [89, 585, 394, 711], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Sketches of the two deformation models: (a) the point model and (b) the line model. The region inside the black boundary is the focus region. The region between the black and green bound- aries is the transition region. The region outside the green boundary is the context region. During deformation, the vertex moves from Porig to Pnew . In (a) O is the center of the black ellipse, while in (b) O is the intersection point between the line AB and the perpendic- ular line of AB passing through Porig . M and N are the intersection points between the line OPorig and the two boundaries. ", "caption_bbox": [73, 722, 408, 847]}, {"image_id": 2, "file_name": "407_02.png", "page": 4, "dpi": 300, "bbox": [75, 679, 392, 846], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": " Figure 3: (a) Illustration of the point model in the normalized space. ~w and ~u are the two displacement directions for the point at P.  Pl and Pr are the two vertices connected to P on this streamline.  (b) Blue dotted line: normalized displacement function g in Equa-  tion 10 when r = 0.5. Red line: a reference displacement function  F(x) = x, which gives no displacement for the entire domain. ", "caption_bbox": [73, 859, 409, 942]}, {"image_id": 3, "file_name": "407_03.png", "page": 5, "dpi": 300, "bbox": [114, 74, 369, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Deformed grids using two shape models with r = 0.5.", "caption_bbox": [81, 206, 401, 220]}, {"image_id": 4, "file_name": "407_04.png", "page": 5, "dpi": 300, "bbox": [439, 179, 776, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) The 3D lens. The blue cube denotes the 3D space. The yellow square denotes the 2D screen space. The lens has an ellipse-shaped surface on the plane of the screen. Inside the cube, there are three streamlines. (b) Placing an open blade shape lens with two fingers on a multi-touch display. ", "caption_bbox": [440, 333, 775, 402]}, {"image_id": 5, "file_name": "407_05.png", "page": 5, "dpi": 300, "bbox": [483, 568, 733, 873], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A point-model lens is applied to the streamline visual- ization in (a) to push layers apart and reveal the hidden red curled vortex in (b). A line-model lens cuts up a flow field in (c) into 2 halves and pushes them aside to expose the olive colored helix twisted vortex in (d). ", "caption_bbox": [440, 887, 775, 956]}, {"image_id": 6, "file_name": "407_06.png", "page": 6, "dpi": 300, "bbox": [440, 853, 777, 973], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Views of a bundle from different view directions.", "caption_bbox": [459, 985, 755, 998]}, {"image_id": 7, "file_name": "407_07.png", "page": 6, "dpi": 300, "bbox": [440, 367, 777, 467], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Exploring streamlines at different depths by the interac- tive 3D lens with different lens depths. ", "caption_bbox": [440, 481, 775, 508]}, {"image_id": 8, "file_name": "407_08.png", "page": 7, "dpi": 300, "bbox": [73, 398, 410, 513], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Exploring flow features at different locations. The stream- line picking cube moves bottom up from (a) to (c). ", "caption_bbox": [73, 526, 408, 553]}], "408": [{"image_id": 0, "file_name": "408_00.png", "page": 1, "dpi": 300, "bbox": [79, 86, 772, 481], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A system overview of our exhibit prototype which allows museum visitors to explore migratory marine animal trajectories over time. (a) Visitors place the cards on the table to observe animal migration patterns. This picture was taken when we conducted the formative evaluation in the museum. (b) The label around the table provides background knowledge of the data set and a legend of visualizations. (c) Placing the physical card on the table will highlight the corresponding species. Visitors can tap the buttons through holes to toggle different visual encodings. (d) The timeline shows the speed pro\ufb01le of selected species visualized with the speed encoding. ", "caption_bbox": [73, 485, 775, 552]}, {"image_id": 1, "file_name": "408_01.png", "page": 2, "dpi": 300, "bbox": [81, 64, 774, 171], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Four trajectory visual encodings used in the prototype. (a) Inactive is designed to minimize distractions, but still entice viewers. (b) Active is bright to identify selected species and follow their movement. (c) Speed uses triangles to quantify speed: Faster speeds are drawn to be larger, whereas slower speeds are smaller. (d) Sex uses patterns to isolate behaviors indicative of males or females of the selected species. ", "caption_bbox": [73, 172, 775, 212]}, {"image_id": 2, "file_name": "408_02.png", "page": 3, "dpi": 300, "bbox": [446, 74, 768, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Analysis of card placement on table in relation to our vi- sualization. The respective legends are found at the corners. The heat map shows the aggregated time of cards placed on the table at a particular x, y location. The paths show where visitors lifted and placed the card at its new location. ", "caption_bbox": [440, 259, 775, 326]}, {"image_id": 3, "file_name": "408_03.png", "page": 3, "dpi": 300, "bbox": [79, 74, 401, 185], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Speed timeline shows the average speed pro\ufb01le of each selected species, in this case, the Blue Whale. The faded banding represents the minimum and maximum within the species. Points A and B are used in an example described in Section 3.3. ", "caption_bbox": [73, 188, 408, 241]}], "409": [{"image_id": 0, "file_name": "409_00.png", "page": 3, "dpi": 300, "bbox": [462, 137, 755, 296], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Between-sample lineage dissimilarities view: The MDS plot shows the population samples similarities based on the 16-dimension vector encoding of their lineage dissimilarity distributions. It shows a core cluster (right) of similar samples surrounded by samples of strongly different lineage characteristics. This overview shows an un- expected heterogeneity of lineage dissimilarity distribution across the samples, where {CLM, PEL, MXL, PUR} on bottom left, and {STU, ITU, PJL} on top left form two distinct clusters far apart the core one, and {ASW, JPT, GIH}, and {CHB, CHS} to a lower extent, appear as outliers. ", "caption_bbox": [440, 316, 775, 448]}, {"image_id": 1, "file_name": "409_01.png", "page": 4, "dpi": 300, "bbox": [456, 73, 761, 436], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Map of within-sample kinship similarities view: each sam- ple kinship similarity matrix is displayed as a color-coded scatterplot using MDS. The color-code is identical to the one used in \ufb01gure 2 except that individuals with lineage dissimilarity greater than 5 are displayed as black dots. Color-coded links connect the dots involved in lineage dissimilarity up to 3. The scatterplots have been manu- ally, tentatively and spatially organized by visual similarity according to their number of links (more links to the left), and to their number of clusters (more clusters to the top). The most homogeneous sam- ples are in the lower right corner while the others call for a deeper quantitative analysis of their anomalous characteristics. ", "caption_bbox": [440, 450, 775, 595]}, {"image_id": 2, "file_name": "409_02.png", "page": 4, "dpi": 300, "bbox": [123, 74, 360, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Distribution of lineage dissimilarities view: the proportion of anomalous lineage dissimilarities vs [k] for k \u2208 {1, 2, 3, 4, 5} are dis- played for each sample as horizontal stacked bar graphs color-coded according to k. Bars are ordered from left to right for k = 1 . . . 5 respec- tively. The samples are ordered on the y-axis based on their cumula- tive proportion from 1 to 5. PEL, CLM, PUR and MXL, clearly appear as having a signi\ufb01cantly greater proportion of anomalous relations of value 4 (pink) than the other samples. PEL has a signig\ufb01cantly greater proportion of value 3 (mauve). The top ranked PUR, PEL, ASW, JPT, MXL, CHB, CLM and CHS and bottom ranked STU, ITU, PJL and GIH samples also appear as clusters or outliers in \ufb01gure 1. ", "caption_bbox": [73, 301, 408, 446]}], "41": [{"image_id": 0, "file_name": "41_00.png", "page": 2, "dpi": 300, "bbox": [478, 630, 699, 873], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An MVSP graph and its decomposition tree", "caption_bbox": [427, 887, 748, 903]}, {"image_id": 1, "file_name": "41_01.png", "page": 3, "dpi": 300, "bbox": [134, 54, 355, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A non MVSP graph and the decomposition tree of its transformed graph. ", "caption_bbox": [83, 374, 405, 404]}, {"image_id": 2, "file_name": "41_02.png", "page": 6, "dpi": 300, "bbox": [153, 320, 336, 683], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A set of tasks corresponding to a non MVSP graph ", "caption_bbox": [83, 696, 404, 726]}, {"image_id": 3, "file_name": "41_03.png", "page": 6, "dpi": 300, "bbox": [516, 71, 662, 336], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Result of adding arcs (6, 5) and (8, 7) to the graph shown in Figure 3 ", "caption_bbox": [427, 349, 748, 379]}, {"image_id": 4, "file_name": "41_04.png", "page": 6, "dpi": 300, "bbox": [516, 423, 663, 687], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Transitive reduction of graph shown in Fig- ure 4. ", "caption_bbox": [427, 700, 748, 730]}, {"image_id": 5, "file_name": "41_05.png", "page": 6, "dpi": 300, "bbox": [516, 771, 663, 1036], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Decomposition tree for graph shown in Fig- ure 5. ", "caption_bbox": [427, 1049, 748, 1079]}, {"image_id": 6, "file_name": "41_06.png", "page": 7, "dpi": 300, "bbox": [71, 52, 406, 442], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: An example of instructions based on the set of tasks in Figure 3 after applying our graph trans- formation to the underlying graph ", "caption_bbox": [83, 466, 405, 510]}], "410": [{"image_id": 0, "file_name": "410_00.png", "page": 1, "dpi": 300, "bbox": [73, 86, 777, 440], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The system-\ufb02ow of wall view generation. (a) we retrieved book data, including cover, title, price, score and number of reviews from amazon.com; (b) we parsed the text data; (c) we utilized the parsed data, e.g., reviews and scores, to calculate the layout; (d) after calculating, we obtain grid size in layout, then using these information to resize covers; (e) is the result. ", "caption_bbox": [73, 455, 775, 495]}, {"image_id": 1, "file_name": "410_01.png", "page": 2, "dpi": 300, "bbox": [82, 73, 396, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: In conventional online bookstore interface, the category is usually arranged as a drop-down list while containing levels of search hierarchies. It requires extra attention to navigate. ", "caption_bbox": [73, 248, 408, 288]}, {"image_id": 2, "file_name": "410_02.png", "page": 3, "dpi": 300, "bbox": [81, 74, 416, 192], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The result of our \ufb01eld study. Reasons to go physical book- stores by participants in (a) and online bookstores in (b). ", "caption_bbox": [73, 208, 408, 235]}, {"image_id": 3, "file_name": "410_03.png", "page": 3, "dpi": 300, "bbox": [470, 74, 744, 172], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: In (a), it shows the product list according to the keyword relevance (TED Talk ), we highlight the top 1 and the top 10 relevant items by red rectangles. After sorting by review number, these two high relevant items are not shown in the top list (b). ", "caption_bbox": [440, 184, 775, 237]}, {"image_id": 4, "file_name": "410_04.png", "page": 3, "dpi": 300, "bbox": [81, 236, 410, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The book covers are shown in the physical bookstores(a). The concept of our wall view (b); books of similar topics are put to- gether and a book\u2019s popularity is highlight by its representative size. ", "caption_bbox": [73, 340, 408, 380]}, {"image_id": 5, "file_name": "410_05.png", "page": 4, "dpi": 300, "bbox": [458, 73, 759, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Bookwall demo. (a) and (b) is our category map. (a) The category map is hidden as an icon; (b) When the cursor is on the icon, the category map will slide out. (c) and (d) are the dataset PhotoShop under price and score-review mode respectively. ", "caption_bbox": [440, 261, 775, 316]}, {"image_id": 6, "file_name": "410_06.png", "page": 4, "dpi": 300, "bbox": [81, 73, 408, 193], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Grid layout before adjustment (a) and after adjustment (b) in (A). The height of the container is extended till the minimum grid size generated by treemap algorithm is larger than the threshold (B). We retrieved data via Amazon Product Advertising API2 and parsed the information within the product list, including book covers, book titles, scores, prices, reviews and drop-down category list. ", "caption_bbox": [73, 204, 408, 288]}], "411": [{"image_id": 0, "file_name": "411_00.png", "page": 2, "dpi": 300, "bbox": [98, 75, 746, 279], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Examples of visualizing the bibliographic data of a researcher with 30-year academic experience using three different representations: (a) Node-link diagram, (b) Adjacency matrix, and (c) Botanical tree. ", "caption_bbox": [73, 281, 775, 308]}, {"image_id": 1, "file_name": "411_01.png", "page": 4, "dpi": 300, "bbox": [440, 529, 787, 893], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visualizing a researcher\u2019s career in \ufb01ve year intervals: (a) Node-link diagram, (b) Adjacency matrix, (c) Botanical tree. ", "caption_bbox": [440, 893, 775, 920]}, {"image_id": 2, "file_name": "411_02.png", "page": 4, "dpi": 300, "bbox": [64, 74, 792, 491], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparing 5 researchers at the same time using the three visual representations.", "caption_bbox": [197, 490, 646, 504]}], "412": [{"image_id": 0, "file_name": "412_00.png", "page": 2, "dpi": 300, "bbox": [184, 74, 688, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Work\ufb02ow. Texts and pre-trained word embeddings are input data and the sematic word cloud generation consists of four steps.", "caption_bbox": [101, 258, 769, 272]}, {"image_id": 1, "file_name": "412_01.png", "page": 3, "dpi": 300, "bbox": [84, 72, 427, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview. Our framework includes (a) the semantic word cloud view and (b) the text view. When we hover the mouse over the word \u201cbusy\u201d and \u201csashimi\u201d in (a), the contexts of \u201cbusy\u201d and \u201csashi- mi\u201d are represented in (c) and (d), respectively, with colored by the number of co-occurrence from cool to warm. ", "caption_bbox": [84, 295, 419, 362]}, {"image_id": 2, "file_name": "412_02.png", "page": 4, "dpi": 300, "bbox": [84, 261, 787, 376], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: We visualize an Italian cuisine restaurant\u2019s reviews with four different word clouds.", "caption_bbox": [211, 391, 660, 405]}, {"image_id": 3, "file_name": "412_03.png", "page": 4, "dpi": 300, "bbox": [91, 72, 783, 205], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Web reviews from three domains a) movie: Interstellar, b) restaurant: a Japanese cuisine restaurant, and c) product: a type of Bose headphone. Our method summarizes and visualizes general themes with a clustered layout. ", "caption_bbox": [84, 220, 786, 247]}], "413": [{"image_id": 0, "file_name": "413_00.png", "page": 1, "dpi": 300, "bbox": [450, 316, 756, 420], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) An aggregated dent at t. (b) The involved layers A, B, C and D contribute differently. A and B are similar to the aggregation showing a dent while C and D have an opposite trend showing a bump. ", "caption_bbox": [440, 419, 775, 472]}, {"image_id": 1, "file_name": "413_01.png", "page": 3, "dpi": 300, "bbox": [447, 134, 767, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Correlation view: in each time segment, an MDS layout shows the distribution of the time series. Closer time series re\ufb02ect more similarity. ", "caption_bbox": [440, 260, 775, 300]}, {"image_id": 2, "file_name": "413_02.png", "page": 3, "dpi": 300, "bbox": [77, 400, 410, 523], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Aggregation view: in each time segment, time series are divided into groups based on their similarity to the aggregation. ", "caption_bbox": [73, 535, 408, 562]}, {"image_id": 3, "file_name": "413_03.png", "page": 3, "dpi": 300, "bbox": [98, 69, 383, 148], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Trend view: each layer encodes the rate of value change for each time series. ", "caption_bbox": [73, 154, 408, 181]}, {"image_id": 4, "file_name": "413_04.png", "page": 4, "dpi": 300, "bbox": [75, 613, 411, 901], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualization generated by STAC for the unemployment rates of 14 industries. The original stacked graph is shown in (a), fol- lowed by (b)trend view, (c)aggregation view and (d)correlation view. ", "caption_bbox": [73, 927, 408, 967]}, {"image_id": 5, "file_name": "413_05.png", "page": 4, "dpi": 300, "bbox": [79, 75, 767, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: System work\ufb02ow: In the data preprocessing phase, we extract time series from raw data. In the data modeling phase, we conduct trend extraction, aggregation analysis and correlation analysis. In the visual exploration phase, four coordinated views are provided to support four basic analytic tasks. ", "caption_bbox": [73, 226, 775, 266]}], "414": [{"image_id": 0, "file_name": "414_00.png", "page": 4, "dpi": 300, "bbox": [73, 74, 777, 497], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization divided by x range \ufb01ltered with Neutral events (a), clustered with threshold=0 (b), divided by total number of Positive and Negative events (c), clustered with threshold=0.35 (d), and navigation bar (e) ", "caption_bbox": [73, 508, 775, 536]}], "415": [{"image_id": 0, "file_name": "415_00.png", "page": 1, "dpi": 300, "bbox": [96, 86, 754, 627], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The overview of the tool and the smartphone usage patterns of user 36598b. (a) the AllEventTime View (b) the EventLine View (c) the EventTree View (d) the EventScatterView. ", "caption_bbox": [73, 640, 775, 667]}, {"image_id": 1, "file_name": "415_01.png", "page": 3, "dpi": 300, "bbox": [446, 118, 770, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Hirachical exploration of event associations.", "caption_bbox": [476, 235, 739, 249]}, {"image_id": 2, "file_name": "415_02.png", "page": 4, "dpi": 300, "bbox": [446, 669, 771, 761], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The distributions of event sequences of two users.", "caption_bbox": [460, 776, 755, 790]}, {"image_id": 3, "file_name": "415_03.png", "page": 4, "dpi": 300, "bbox": [98, 74, 752, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The smartphone usage patterns of user 9b6955.", "caption_bbox": [280, 475, 567, 489]}], "416": [{"image_id": 0, "file_name": "416_00.png", "page": 2, "dpi": 300, "bbox": [81, 74, 778, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Three representations used in User Study I. All of them present the same driver\u2019s behavior.", "caption_bbox": [175, 261, 668, 275]}, {"image_id": 1, "file_name": "416_01.png", "page": 3, "dpi": 300, "bbox": [86, 808, 394, 963], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Two screenshots of DBW-m where the motion bars move (a) inward and (b) outward with respect to the center. (Please also see the accompanying video.) ", "caption_bbox": [73, 964, 408, 1004]}, {"image_id": 2, "file_name": "416_02.png", "page": 4, "dpi": 300, "bbox": [80, 75, 400, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: T-test results of NASA-TLX", "caption_bbox": [153, 332, 329, 346]}], "417": [{"image_id": 0, "file_name": "417_00.png", "page": 2, "dpi": 300, "bbox": [455, 841, 774, 944], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Points sampled from three von Mises-Fisher distributions on 2-dimensional spheres with different value of \u03ba . The mean di- rections are shown as arrows. ", "caption_bbox": [440, 957, 775, 998]}, {"image_id": 1, "file_name": "417_01.png", "page": 3, "dpi": 300, "bbox": [465, 370, 763, 455], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Comparison of the distance between the most likely traces and the ground truth for our method and the MC method. ", "caption_bbox": [440, 465, 775, 493]}, {"image_id": 2, "file_name": "417_02.png", "page": 3, "dpi": 300, "bbox": [465, 525, 763, 610], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparison of overall trace accuracy. For each method, distances of all sample traces to the ground truth are measured and summed by their weights. ", "caption_bbox": [440, 620, 775, 661]}, {"image_id": 3, "file_name": "417_03.png", "page": 3, "dpi": 300, "bbox": [440, 778, 775, 833], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a): Sampled streamlines computed by the MC method starting from seeding position x = 0.3, y = 0.5 in the analytical double-gyre data set. (b): Sampled streamlines computed by our method from the same seeding position in (a). (c): The most likely traces generated by both methods compared with the ground truth. ", "caption_bbox": [440, 843, 775, 912]}, {"image_id": 4, "file_name": "417_04.png", "page": 4, "dpi": 300, "bbox": [108, 771, 384, 866], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Distances between the ground truth and sample traces generated by our method and the MC method for the Isabel data set. ", "caption_bbox": [73, 876, 408, 917]}, {"image_id": 5, "file_name": "417_05.png", "page": 4, "dpi": 300, "bbox": [73, 73, 775, 228], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Streamlines generated on the Hurricane Isabel data sets. The color is used to enhance the contrast among streamlines. (a): The ground truth streamlines generated on the raw data. (b): Results produced by the Monte Carlo method on the distribution data with block size 163 . (c): Streamlines generated by our method on the same data in (b). ", "caption_bbox": [73, 239, 775, 280]}, {"image_id": 6, "file_name": "417_06.png", "page": 4, "dpi": 300, "bbox": [73, 306, 391, 411], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Overview of the performance for the proposed algorithm and the Monte Carlo method. ", "caption_bbox": [440, 679, 775, 707]}], "418": [{"image_id": 0, "file_name": "418_00.png", "page": 1, "dpi": 300, "bbox": [454, 257, 777, 615], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview of the steps involved.", "caption_bbox": [503, 629, 711, 643]}, {"image_id": 1, "file_name": "418_01.png", "page": 2, "dpi": 300, "bbox": [450, 74, 766, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Showing the variation of an isosurface from the statisti- cally signi\ufb01cant isosurface(s). (a) from median isosurface (b) from the 30% quantile(centrally located isosurfaces). The blue regions are closer to the median isosurface than the greener regions. ", "caption_bbox": [440, 226, 775, 281]}, {"image_id": 2, "file_name": "418_02.png", "page": 3, "dpi": 300, "bbox": [145, 73, 706, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Clustering the ensemble volumes based on isosurface variations. (a) scatter plot of the 2 principal components colored with the k-means ids. (b) one of the ensemble volumes being segmented to regions of high and low isosurface variation. (c) a slicer interface to view different parts of the segmented volume. ", "caption_bbox": [73, 226, 775, 267]}, {"image_id": 3, "file_name": "418_03.png", "page": 3, "dpi": 300, "bbox": [443, 294, 803, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Ensemble isosurfaces for single isovalue. (a) shows the 10 isosurfaces rendered at the same time(the central surface is color red). (b) highlights the order information in PCP for the same 10 isosurfaces. The median isosurface is from the ninth ensemble member as it has the highest band-depth value for axes e8 ", "caption_bbox": [440, 438, 775, 507]}, {"image_id": 4, "file_name": "418_04.png", "page": 4, "dpi": 300, "bbox": [76, 516, 410, 676], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Isosurface of one of the Great Lakes ensemble member (a) shows the distance of different parts of the isosurface from the median isosurface (b) shows the distance from 30% quantile. ", "caption_bbox": [73, 689, 408, 730]}, {"image_id": 5, "file_name": "418_05.png", "page": 4, "dpi": 300, "bbox": [148, 769, 334, 901], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Clustering of regions based on isosurface entropy for Great Lakes data. The segmented volume of one of the ensemble members showing regions of feature variation. ", "caption_bbox": [73, 916, 408, 957]}, {"image_id": 6, "file_name": "418_06.png", "page": 4, "dpi": 300, "bbox": [76, 74, 770, 207], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A PCP view of the band-depth(ordering) information for all temperature isovalues for The Massachusetts Bay Ensemble.", "caption_bbox": [97, 220, 751, 234]}, {"image_id": 7, "file_name": "418_07.png", "page": 4, "dpi": 300, "bbox": [73, 260, 408, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Average CPU Time performance per ensemble member", "caption_bbox": [446, 643, 768, 657]}], "419": [{"image_id": 0, "file_name": "419_00.png", "page": 1, "dpi": 300, "bbox": [73, 86, 761, 419], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization of a weather forecast ensemble from the ECMWF Prediction System [29]. This ensemble comprises wind velocity data and consists of 50 members. For one isovalue, all members are visualized as silhouettes of isosurfaces. Additionally, a mean ensemble member is rendered as a gray isosurface to enhance the visual perception of the spatial context. Color is used to cluster members by their similarity. ", "caption_bbox": [73, 432, 775, 472]}, {"image_id": 1, "file_name": "419_01.png", "page": 3, "dpi": 300, "bbox": [74, 77, 412, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visualization using different rendering techniques. a) Semi- transparent surfaces. b) 3D spaghetti plots of silhouettes. c) Shaded silhouettes. d) Shaded silhouettes with density-based removal. ", "caption_bbox": [73, 341, 408, 381]}, {"image_id": 2, "file_name": "419_02.png", "page": 4, "dpi": 300, "bbox": [74, 72, 780, 191], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Results from two ensemble data sets. a) An outlier was selected in the ECMWF data set (bottom left) to get a better understanding of its shape. b) A cutting plane allows us to analyze a feature in more detail. c) Overview of a Navier-Stokes \ufb02ow simulation comprising 56 runs. d) A cutting plane reveals the inner structures. The underlying \ufb02ow is depicted at the bottom right. ", "caption_bbox": [73, 204, 775, 244]}], "42": [{"image_id": 0, "file_name": "42_00.png", "page": 2, "dpi": 300, "bbox": [524, 694, 652, 854], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Initial configuration of skeletal chain", "caption_bbox": [452, 864, 731, 884]}, {"image_id": 1, "file_name": "42_01.png", "page": 2, "dpi": 300, "bbox": [90, 80, 391, 1039], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Successive screenshots from the sGraph                       system ", "caption_bbox": [82, 1047, 378, 1083]}, {"image_id": 2, "file_name": "42_02.png", "page": 2, "dpi": 300, "bbox": [525, 892, 652, 988], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Final configuration of skeletal chain", "caption_bbox": [455, 1063, 728, 1083]}, {"image_id": 3, "file_name": "42_03.png", "page": 3, "dpi": 300, "bbox": [119, 87, 698, 1071], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An example of the CCD algorithm executing over several iterations", "caption_bbox": [180, 1084, 638, 1104]}, {"image_id": 4, "file_name": "42_04.png", "page": 5, "dpi": 300, "bbox": [493, 320, 698, 456], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A solution is generated for the controlling                         chain algorithm on this controlling chain gives a new set of coordinates for each joint in the chain (Figure 7). Notice that there are currently two visual representations of the single joint adjoining the controlling chain to the rest of the graph. This is obviously not desired, but one may realise that this new problem may be formulated again as a goal- directed motion problem on the rest of the graph. That is, we select the common joint as a new end-effector that we desire to move into the position specified by the CCD solution of the controlling chain. Since we already have a solution for the original controlling chain, we may ignore it and deal solely with the ", "caption_bbox": [436, 489, 747, 740]}, {"image_id": 5, "file_name": "42_05.png", "page": 5, "dpi": 300, "bbox": [106, 109, 369, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": " Figure 5: An acyclic graph structure of bones and                         joints several questions that must be answered if we are to ", "caption_bbox": [78, 325, 388, 384]}, {"image_id": 6, "file_name": "42_06.png", "page": 5, "dpi": 300, "bbox": [493, 103, 708, 257], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A controlling chain is chosen", "caption_bbox": [476, 271, 706, 291]}, {"image_id": 7, "file_name": "42_07.png", "page": 6, "dpi": 300, "bbox": [494, 336, 699, 473], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: A solution is generated, yielding a      complete solution for the skeleton ", "caption_bbox": [458, 505, 725, 541]}, {"image_id": 8, "file_name": "42_08.png", "page": 6, "dpi": 300, "bbox": [135, 336, 340, 472], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "    Figure 9: A solution is generated for the new                   controlling chain brought the original end-effector into the position desired. Figure 11 illustrates the final solution for our ", "caption_bbox": [78, 501, 388, 572]}, {"image_id": 9, "file_name": "42_09.png", "page": 6, "dpi": 300, "bbox": [493, 93, 698, 236], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The last fixed joint is chosen to construct                 a controlling chain ", "caption_bbox": [437, 271, 746, 307]}, {"image_id": 10, "file_name": "42_10.png", "page": 6, "dpi": 300, "bbox": [124, 102, 340, 236], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A controlling chain is chosen from the             remainder of the graph ", "caption_bbox": [91, 271, 376, 307]}, {"image_id": 11, "file_name": "42_11.png", "page": 10, "dpi": 300, "bbox": [86, 110, 741, 558], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Graph laid out in sGraph", "caption_bbox": [303, 566, 521, 586]}, {"image_id": 12, "file_name": "42_12.png", "page": 10, "dpi": 300, "bbox": [86, 599, 741, 1031], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Graph laid out in Wilma", "caption_bbox": [306, 1039, 519, 1059]}], "420": [{"image_id": 0, "file_name": "420_00.png", "page": 2, "dpi": 300, "bbox": [77, 314, 411, 738], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Four drawing versions of a graph.", "caption_bbox": [73, 748, 290, 760]}, {"image_id": 1, "file_name": "420_01.png", "page": 3, "dpi": 300, "bbox": [463, 741, 763, 902], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Average effort data for each drawing version.", "caption_bbox": [440, 909, 714, 921]}, {"image_id": 2, "file_name": "420_02.png", "page": 3, "dpi": 300, "bbox": [456, 368, 750, 519], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Average time data (seconds) for each drawing version.", "caption_bbox": [440, 526, 761, 538]}, {"image_id": 3, "file_name": "420_03.png", "page": 4, "dpi": 300, "bbox": [466, 184, 763, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Average aesthetic preference for each drawing version.", "caption_bbox": [440, 367, 764, 379]}, {"image_id": 4, "file_name": "420_04.png", "page": 4, "dpi": 300, "bbox": [96, 458, 383, 644], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Average task preference for each drawing version.", "caption_bbox": [73, 651, 373, 663]}, {"image_id": 5, "file_name": "420_05.png", "page": 4, "dpi": 300, "bbox": [87, 140, 383, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Accuracy data for each drawing version.", "caption_bbox": [73, 299, 323, 311]}], "421": [{"image_id": 0, "file_name": "421_00.png", "page": 2, "dpi": 300, "bbox": [445, 727, 776, 775], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Encodings for student interactions, with node A and B being students, C being (vA , vB ), the response from A to B. Node saturation encodes the grade of the corresponding student, and size encodes the interaction level, w(vi , v j ). ", "caption_bbox": [440, 777, 775, 832]}, {"image_id": 1, "file_name": "421_01.png", "page": 2, "dpi": 300, "bbox": [445, 394, 772, 591], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Network View for NetworkSeer, with colored arcs delineat- ing sub-forums (e.g., A-D). Area a shows students with high contri- butions have less speci\ufb01c interests in any sub-forums. b and c shows students focusing on Study Groups and Assignments respectively. ", "caption_bbox": [440, 598, 775, 651]}, {"image_id": 2, "file_name": "421_02.png", "page": 3, "dpi": 300, "bbox": [88, 81, 774, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Filtering students with high grades (\u226585), with (a) being the Feature Statistics View, and (b) the corresponding Network View.", "caption_bbox": [94, 278, 754, 292]}, {"image_id": 3, "file_name": "421_03.png", "page": 3, "dpi": 300, "bbox": [443, 585, 775, 720], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Feature Statistics View for posts from students with high reputation. These students generally have high grades. ", "caption_bbox": [440, 724, 775, 751]}, {"image_id": 4, "file_name": "421_04.png", "page": 4, "dpi": 300, "bbox": [80, 559, 416, 683], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Student interactions in different periods: (a) Jun 14 to 28, when Study Groups is heavily used, and (b) from Jun 28 till the end. ", "caption_bbox": [73, 691, 408, 718]}, {"image_id": 5, "file_name": "421_05.png", "page": 4, "dpi": 300, "bbox": [441, 464, 787, 567], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Network View of students from (a) North America (CAN, USA, MEX), (b) East Asia (CHN, HKG, TWN, JPN, KOR), and (c) Europe (PRT, ESP, GBR, FRA, DEU, NLD, POL, ITA) ", "caption_bbox": [440, 571, 775, 611]}, {"image_id": 6, "file_name": "421_06.png", "page": 4, "dpi": 300, "bbox": [73, 73, 413, 228], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Filtering posts in Study Groups, with (a) being the Feature Statistics View, and (b) the corresponding network graph. we further \ufb01lter students with high grades. We de\ufb01ne high grades as those \u2265 85, which accounts for the top 20% students with ef- fective grades, and con\ufb01rm our \ufb01nding on their obsessions: These students, compared with the general group (i.e., all the students par- ticipated in the forum), focus more on course related sub-forums, and much less in Study Groups, as shown in Fig. 3(b)B. The biased attention makes sense, since students are graded based on assign- ment performances. We also notice that the heights of Date bars in Fig. 3(a) are mostly identical, indicating high-grade-students post in the forum stably, instead of popping up randomly. Also, inter- estingly, they tend to interact with those in different countries. This might be worth deeper investigation. ", "caption_bbox": [73, 229, 408, 427]}, {"image_id": 7, "file_name": "421_07.png", "page": 4, "dpi": 300, "bbox": [440, 73, 779, 216], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Assignments in Feature Statistics View, posts in which ex- perience a periodical variation, and meet its local maxima almost always around the assignment due dates. ", "caption_bbox": [440, 215, 775, 255]}], "422": [{"image_id": 0, "file_name": "422_00.png", "page": 1, "dpi": 300, "bbox": [73, 86, 777, 475], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview of origin-destination matrix", "caption_bbox": [310, 490, 539, 504]}, {"image_id": 1, "file_name": "422_01.png", "page": 2, "dpi": 300, "bbox": [82, 583, 399, 744], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Selection example for the connection barchart: a full matrix (top) and the selection of one node as origin (bottom) ", "caption_bbox": [73, 760, 408, 787]}, {"image_id": 2, "file_name": "422_02.png", "page": 2, "dpi": 300, "bbox": [449, 73, 768, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Selection example between the coordinated maps (top) and the connection barchart (bottom) ", "caption_bbox": [440, 324, 775, 352]}, {"image_id": 3, "file_name": "422_03.png", "page": 2, "dpi": 300, "bbox": [448, 374, 768, 472], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Contribution selection: the node \u201dFASE III\u201d receives 1,551.87 trips from the total of 24,616.84 from \u201dFASEII\u201d. ", "caption_bbox": [440, 500, 775, 527]}, {"image_id": 4, "file_name": "422_04.png", "page": 3, "dpi": 300, "bbox": [82, 643, 402, 738], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualization of an origin-destination matrix using a col- ormap for \ufb02ow value. ", "caption_bbox": [73, 751, 408, 778]}, {"image_id": 5, "file_name": "422_05.png", "page": 4, "dpi": 300, "bbox": [449, 340, 762, 500], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Difference between correctness using the color coded ma- trix or the connection barchart. ", "caption_bbox": [440, 514, 775, 542]}, {"image_id": 6, "file_name": "422_06.png", "page": 4, "dpi": 300, "bbox": [465, 94, 754, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Difference between answering time using the color coded matrix or the connection barchart. ", "caption_bbox": [440, 286, 775, 314]}, {"image_id": 7, "file_name": "422_07.png", "page": 4, "dpi": 300, "bbox": [92, 346, 392, 515], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Average answering time for questions of type \u201dMost com- mon destination/origin\u201d. ", "caption_bbox": [73, 538, 408, 565]}, {"image_id": 8, "file_name": "422_08.png", "page": 4, "dpi": 300, "bbox": [94, 94, 394, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Average answering time for questions of type \u201dTotal amount of trips\u201d. ", "caption_bbox": [73, 285, 408, 312]}], "423": [{"image_id": 0, "file_name": "423_00.png", "page": 2, "dpi": 300, "bbox": [90, 74, 760, 209], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Edge Smoothing procedure: a) computation of the free space around control points b) determination of the new control points c) the new control points (in red) are added to the set of already existing control points, and new segments are added to route the edges. ", "caption_bbox": [73, 222, 775, 250]}, {"image_id": 1, "file_name": "423_01.png", "page": 2, "dpi": 300, "bbox": [473, 527, 744, 753], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Per Layer Bundle Division: (a) compute the perpen- dicular segment to the control point considering control points that already exist (b) per layer division of control points. ", "caption_bbox": [440, 766, 775, 807]}, {"image_id": 2, "file_name": "423_02.png", "page": 3, "dpi": 300, "bbox": [152, 300, 331, 582], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Edge-Node overlap heuristic: (a) the issue we can have drawing the per-layer bundles b) the over-discretization heuristic (with K = 3) we employ to deal with the edge-node overlap prob- lem. ", "caption_bbox": [73, 595, 408, 650]}, {"image_id": 3, "file_name": "423_03.png", "page": 3, "dpi": 300, "bbox": [174, 73, 676, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Bundle Crossing Reduction heuristic: a) initial scenario with bundle crossing b) computation of the barycenters of the projections of the control points neighbors on ds (barycenters are depicted with a red border) c) new order of the control points on ds . ", "caption_bbox": [73, 208, 775, 237]}, {"image_id": 4, "file_name": "423_04.png", "page": 4, "dpi": 300, "bbox": [439, 613, 794, 800], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualization of the subsample of BIOGRID multilayer graph: a) the visualization before applying our approach b) the re- sult obtained with the multilayer graph edge bundling strategy. ", "caption_bbox": [440, 813, 775, 855]}, {"image_id": 5, "file_name": "423_05.png", "page": 4, "dpi": 300, "bbox": [73, 73, 420, 632], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Result of the multilayer graph edge bundling approach on the Reality Mining dataset with three focus on different interaction patterns our method helps to highlight. ", "caption_bbox": [73, 643, 408, 684]}], "424": [{"image_id": 0, "file_name": "424_00.png", "page": 1, "dpi": 300, "bbox": [77, 56, 790, 563], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The visual analytics system for exploration and comparison of movements derived from geo-located microblog messages consists of multiple linked views: (1) map, (2) timeline, (3) velocity distribution & \ufb01ltering, (4) searchboxes, (5) grid creation panel, (6) comparison interface. The map shows distribution and direction of pilgrim movements in Mecca, Sep. 2015. Patterns (labeled a\u2013e) are described in a case study (Section 5.1). ", "caption_bbox": [73, 567, 792, 607]}, {"image_id": 1, "file_name": "424_01.png", "page": 3, "dpi": 300, "bbox": [75, 50, 416, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The abstract analysis process consists of an exploration part and a comparison part. Colors indicate an exploratory analysis for two different datasets, that precedes the comparative analysis. ", "caption_bbox": [73, 251, 417, 291]}, {"image_id": 2, "file_name": "424_02.png", "page": 3, "dpi": 300, "bbox": [511, 50, 721, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Rule-based categorization to assign the most likely means of transportation. Fuzziness can be interactively controlled with a preci- sion&recall slider. ", "caption_bbox": [448, 249, 792, 289]}, {"image_id": 3, "file_name": "424_03.png", "page": 4, "dpi": 300, "bbox": [73, 523, 416, 688], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Drawing of large movement data. From left: full opacity, alpha-blending, edge splatting with normalization and color mapping. ", "caption_bbox": [73, 695, 417, 722]}, {"image_id": 4, "file_name": "424_04.png", "page": 4, "dpi": 300, "bbox": [453, 49, 787, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The hierarchical graph model and weight-based link prop- agation. Original links in brown (leaf level) are propagated to upper levels (red, yellow), allowing for more abstract/aggregated views. ", "caption_bbox": [448, 214, 792, 254]}, {"image_id": 5, "file_name": "424_05.png", "page": 5, "dpi": 300, "bbox": [453, 682, 796, 794], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: For the \ufb01rst dataset loaded (here, taxis in New York) a grid structure is created (left). The same grid is \ufb01lled with the second dataset (Twitter data, center). The subtraction is shown on the right. ", "caption_bbox": [448, 801, 792, 841]}, {"image_id": 6, "file_name": "424_06.png", "page": 5, "dpi": 300, "bbox": [458, 43, 782, 204], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The density distribution (1) of one week Twitter data in Man- hattan (see Section 5.2) is dominated by large peaks that can be com- pressed interactively (2) shifting the maximum to a lower value. Be- sides the histogram, overall movement count, mean \u03bc, and standard deviation \u03c3 per pixel give further information about the distribution. ", "caption_bbox": [448, 205, 792, 273]}, {"image_id": 7, "file_name": "424_07.png", "page": 5, "dpi": 300, "bbox": [77, 43, 412, 219], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The grid structure is colored according to incoming or outgo- ing movement. Arrows indicate average movement direction. Standard deviation is encoded with varying opacity. A tooltip shows additional in- formation and highlights the movements for the underlying cell. ", "caption_bbox": [73, 226, 417, 279]}, {"image_id": 8, "file_name": "424_08.png", "page": 6, "dpi": 300, "bbox": [73, 48, 795, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The taxi dataset (left) shows different peeks at New York\u2019s airports (2,3,4) and in the inner city (1). Twitter data (center) has higher peeks and is not that smoothly distributed, but also gives information about movement in the north-west areas (6). The right image shows differences (red, blue) and some similarities (white), for example, the routes to and from Newark airport (cf. 4,7). ", "caption_bbox": [73, 205, 792, 245]}, {"image_id": 9, "file_name": "424_09.png", "page": 7, "dpi": 300, "bbox": [76, 47, 412, 304], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The upper two images show two graphs on the same hier- archy level: \ufb02ight data (left) and Twitter data (right). Flight data is more prominent around Atlanta (2), Twitter data in California and New York (1, 3). The lower images show that \ufb02ight data is being more prominent in the Chinese area (4). Twitter data has its peaks in Indonesia and Japan (5, 6). The left image shows connection differences while the right heatmap highlights different volumes of outgoing movement. ", "caption_bbox": [73, 307, 417, 400]}], "425": [{"image_id": 0, "file_name": "425_00.png", "page": 2, "dpi": 300, "bbox": [73, 336, 426, 526], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A taxonomy of visual representations of the same move- ment data. Top left: small multiples. Top right: animation with play- back controls. Bottom left: Gantt chart. Bottom middle: static 2D ge- ographic map with trajectories. Bottom right: 3D \u201cspace-time cube\u201d. ", "caption_bbox": [73, 543, 408, 596]}, {"image_id": 1, "file_name": "425_01.png", "page": 3, "dpi": 300, "bbox": [439, 74, 794, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: All variants of these Gantt charts show the same \ufb01ctitious data, and all use the same warm colors for locations and cold colors for persons. A is person-centric, and B is location-centric, each of them nesting one variable within another along the vertical axis. C, D, and E show ways of making rows more narrow. C does this by exploiting the fact that a person can only be in one place at a time. D and E either overlap or stack people, respectively, when multiple people are in the same location. In all charts, the background colors of rows are super\ufb02uous and only for illustration. Furthermore, the foreground colors used in A and B are not strictly necessary, though they may help with visual search tasks. Vertical black line segments are used to highlight meetings between people. ", "caption_bbox": [440, 352, 775, 511]}, {"image_id": 2, "file_name": "425_02.png", "page": 3, "dpi": 300, "bbox": [73, 245, 427, 500], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Patterns, outliers, meetings, and parallel movements. A shows someone going to work and the gym each weekday, and then only to the gym on the weekend. B shows a change in pattern: after going to work for 2 weeks, this person visits a doctor, then stays home several days (perhaps due to sickness). C illustrates possible meetings: a student and lecturer sometime coincide on the campus of a college, while also visiting a grocery store at different times. D shows movement together: two people leave home to visit the mall. Around 5:30pm, one goes to a cafe\u0301 before being joined by the other a bit later, then both return home. ", "caption_bbox": [73, 522, 408, 654]}, {"image_id": 3, "file_name": "425_03.png", "page": 4, "dpi": 300, "bbox": [177, 73, 672, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The main window. Upper right: 2D geographic map. Upper left: adjacency matrix showing meetings between people. Bottom: Gantt chart, in location-centric mode, with time folding activated to hide empty regions of time. Note the small labels below each fold indicated how much time has been compressed (\u201c13 h\u201d for 13 hours, \u201c4 d\u201d for 4 days, etc.). ", "caption_bbox": [73, 363, 775, 403]}, {"image_id": 4, "file_name": "425_04.png", "page": 4, "dpi": 300, "bbox": [73, 429, 424, 591], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Early, unsatisfactory attempts to indicate meetings in person-centric views, drawing either curves or straight line segments between the centers of intervals of all participating people. ", "caption_bbox": [73, 605, 408, 645]}, {"image_id": 5, "file_name": "425_05.png", "page": 4, "dpi": 300, "bbox": [73, 684, 427, 784], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The same time span as in Figure 4, but now with folds re- moved, to show how much empty space there is between meetings. World lines are also displayed. ", "caption_bbox": [73, 797, 408, 837]}, {"image_id": 6, "file_name": "425_06.png", "page": 5, "dpi": 300, "bbox": [177, 73, 672, 420], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: From an initial set of 12 people shown in the matrix, the user has selected 6 people, causing their meetings to be displayed in the Gantt chart. The identity of people in the Gantt chart is revealed in three ways: through coordinated highlighting (\u201cKaty\u201d is under the mouse cursor, and her name is highlighted with a grey rectangle in the matrix view), through excentric labels [16], and through color coding. ", "caption_bbox": [73, 433, 775, 473]}, {"image_id": 7, "file_name": "425_07.png", "page": 6, "dpi": 300, "bbox": [439, 73, 794, 283], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Case study 1: one week of activity in Montreal followed by a round-trip \ufb02ight to Durham (airport code: RDU) via New York (airport code: LGA). GPS tracking failed during the LGA-RDU leg of the trip, which shows up in the Gantt chart as a sudden jump from LGA to a hotel in Durham. ", "caption_bbox": [440, 297, 775, 364]}, {"image_id": 8, "file_name": "425_08.png", "page": 6, "dpi": 300, "bbox": [73, 617, 427, 691], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Case study 1: three months of activity within Montreal.", "caption_bbox": [83, 705, 398, 719]}, {"image_id": 9, "file_name": "425_09.png", "page": 6, "dpi": 300, "bbox": [73, 73, 427, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Person-centric mode, showing four meetings. People are identi\ufb01ed by their vertical position and also (redundantly) by their color (e.g., Alice is in the top row, and is blue). Black vertical line segments show meetings, with black dots disambiguating the partic- ipants in each meetings. For example, the 1st meeting involves all 6 people at Location 0, but the 2nd meeting only involves Alice and Eva at Location 34. ", "caption_bbox": [73, 290, 408, 383]}, {"image_id": 10, "file_name": "425_10.png", "page": 7, "dpi": 300, "bbox": [439, 616, 794, 704], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Case study 3: two people often together, at a university, at a dormitory, and at a bank. ", "caption_bbox": [440, 717, 775, 744]}, {"image_id": 11, "file_name": "425_11.png", "page": 7, "dpi": 300, "bbox": [466, 301, 751, 562], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Case study 3: an adjacency matrix for several people from the GeoLife dataset. ", "caption_bbox": [440, 575, 775, 602]}, {"image_id": 12, "file_name": "425_12.png", "page": 7, "dpi": 300, "bbox": [108, 73, 743, 249], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Case study 2: meetings between 6 members of our lab.", "caption_bbox": [260, 263, 587, 277]}, {"image_id": 13, "file_name": "425_13.png", "page": 8, "dpi": 300, "bbox": [73, 73, 427, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Case study 3: two people with identical data.", "caption_bbox": [103, 258, 378, 272]}], "426": [{"image_id": 0, "file_name": "426_00.png", "page": 1, "dpi": 300, "bbox": [77, 86, 772, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: User interface sketch of the visualization approach representing the execution of stored procedures on a timeline (A). Deviations from other runs are encoded in color (B) and detailed in histogram and trend views (C). ", "caption_bbox": [73, 405, 775, 432]}, {"image_id": 1, "file_name": "426_01.png", "page": 4, "dpi": 300, "bbox": [444, 627, 770, 688], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Graphical simpli\ufb01cation of a fan pattern in the node-link di- agram, illustrating the interactive collapsing and expanding of a sub- graph implementing the fan pattern. ", "caption_bbox": [440, 701, 775, 741]}, {"image_id": 2, "file_name": "426_02.png", "page": 4, "dpi": 300, "bbox": [75, 74, 775, 567], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visualization tool showing a nightly run of a stored procedure system and showing details of a selected procedure DWT1010P executed on August 1, 2013; the respective node is highlighted in the \ufb01gure by a red rectangle. ", "caption_bbox": [73, 575, 775, 602]}, {"image_id": 3, "file_name": "426_03.png", "page": 5, "dpi": 300, "bbox": [471, 78, 748, 172], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Color scale used for encoding the lateness and runtime deviations of executed procedures (top); transformed to a gray scale, a brightness gradient is revealed (bottom). ", "caption_bbox": [440, 183, 775, 223]}, {"image_id": 4, "file_name": "426_04.png", "page": 6, "dpi": 300, "bbox": [85, 74, 401, 463], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Histograms and trend charts relate a selected executed procedure to all instances of the procedure based on start time, run- time, and lateness; like in Figure 2, procedure DWT1010P executed on August 1, 2013 is selected. ", "caption_bbox": [73, 475, 408, 528]}], "427": [{"image_id": 0, "file_name": "427_00.png", "page": 1, "dpi": 300, "bbox": [78, 120, 758, 348], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1. Our approach to image categorization: (1) Analyze the distribution of images over metadata attributes and select interesting intervals; (2) Inspect intersections of attributes by using them as axes on a pivot table; (3) Additionally or alternatively, view images in more detail on a simple grid; (4) Categorize selected images; (5) Reuse the obtained categorization as metadata attribute for new insights. This example illustrates how this approach can be used to collect last year\u2019s sports highlights. ", "caption_bbox": [73, 357, 775, 410]}, {"image_id": 1, "file_name": "427_01.png", "page": 3, "dpi": 300, "bbox": [87, 83, 398, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2. Metadata can be described as a large table where columns represent attributes, rows represent images, and cells represent val- ues. Since images often do not have values for all attributes, the table is typically very sparse. ", "caption_bbox": [73, 236, 408, 289]}, {"image_id": 2, "file_name": "427_02.png", "page": 3, "dpi": 300, "bbox": [440, 74, 775, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3. Schematic depiction of our work\ufb02ow model and the ac- companying interface with its four views, connected using selections, brushing & linking. Uppercase words summarize the most important activities in each view. Arrows indicate the typical work\ufb02ow, however, neither the work\ufb02ow nor the interface restrict other paths. ", "caption_bbox": [440, 371, 775, 438]}, {"image_id": 3, "file_name": "427_03.png", "page": 4, "dpi": 300, "bbox": [73, 74, 777, 473], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. Screenshot showing ICLIC and its four views: the attribute view (top left), the image view (top right), the data view (bottom left), and the category view (bottom right). (a) Attributes can be sorted by name, frequency, and relevance. (b) Attributes can be searched by a regular expression. (c) Switch between RSVP and pivot mode. (d) The size of images can be adjusted, increasing or decreasing the number of images shown. (e) Convenience buttons for no/all/invert selection. (f) Search \ufb01eld to select images of which at least one value matches the query. (g) Legend that shows the number of images on each stack. (h) Attributes are presented as scented widgets, striped bars indicate unde\ufb01ned values. (i) Attributes can be dragged onto the axes of the image view. (j) Bars indicate the impact of the \ufb01lter steps. The \ufb01lter horizon, between the two steps, separates the pre- and post \ufb01lters. (k) Selected images are added to, or removed from categories via these buttons. (l) Radio buttons for \ufb01ltering images (not) in the category. (m) Status bar with detailed statistics about hovered elements. ", "caption_bbox": [73, 482, 775, 588]}, {"image_id": 4, "file_name": "427_04.png", "page": 5, "dpi": 300, "bbox": [92, 78, 762, 192], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5. Examples of attribute histogram tiles. The outer bars show the distribution of the complete collection, the gray bars show the distribution of the visible part, and the green bars show the selection. Green dots indicate bars with at least one selected image. The rightmost striped bar represents images that do not have this attribute. Filters can be applied by the yellow triangles (numerical, temporal data) and boxes (categorical data). Detailed inspection and \ufb01ltering is always done in the image view. Figures b, c, d, and e give the scores of our sorting algorithms. ", "caption_bbox": [73, 203, 775, 256]}, {"image_id": 5, "file_name": "427_05.png", "page": 6, "dpi": 300, "bbox": [439, 73, 778, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7. RSVP mode: optimized for detailed inspection and selec- tion of images, therefore metadata is hidden. ", "caption_bbox": [440, 276, 775, 303]}, {"image_id": 6, "file_name": "427_06.png", "page": 6, "dpi": 300, "bbox": [73, 73, 409, 269], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6. Pivot mode: used to organize images with attributes along the horizontal and/or vertical axes and an optional color map. ", "caption_bbox": [73, 279, 408, 306]}], "428": [{"image_id": 0, "file_name": "428_00.png", "page": 1, "dpi": 300, "bbox": [88, 86, 762, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Geo word clouds of cheese production in France (left: orthogonal, middle: 45 degrees, right: 10 degrees).", "caption_bbox": [135, 441, 712, 455]}, {"image_id": 1, "file_name": "428_01.png", "page": 4, "dpi": 300, "bbox": [112, 74, 732, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Geo word clouds of Flickr tags in Great Britain and Ireland (left: orthogonal, middle: 45 degrees, right: 10 degrees).", "caption_bbox": [109, 324, 740, 338]}, {"image_id": 2, "file_name": "428_02.png", "page": 5, "dpi": 300, "bbox": [81, 73, 402, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Geo word clouds of France: different color maps.", "caption_bbox": [92, 258, 390, 272]}, {"image_id": 3, "file_name": "428_03.png", "page": 5, "dpi": 300, "bbox": [84, 572, 399, 687], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: HCL color map, selecting consecutive colors.", "caption_bbox": [102, 697, 380, 711]}, {"image_id": 4, "file_name": "428_04.png", "page": 6, "dpi": 300, "bbox": [139, 549, 344, 753], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 5: Metrics on type of clustering (France)", "caption_bbox": [490, 985, 725, 999]}, {"image_id": 5, "file_name": "428_05.png", "page": 7, "dpi": 300, "bbox": [116, 757, 735, 972], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Point maps for Geo word clouds of French cheeses: placing the \ufb01rst three words.", "caption_bbox": [197, 985, 651, 999]}, {"image_id": 6, "file_name": "428_06.png", "page": 7, "dpi": 300, "bbox": [115, 73, 735, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Geo word clouds of French cheeses: extreme cases for clustering.", "caption_bbox": [235, 299, 613, 313]}, {"image_id": 7, "file_name": "428_07.png", "page": 8, "dpi": 300, "bbox": [131, 356, 352, 630], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Geo word cloud of Flickr tags in Great Britain and Ireland after manually merging the countries (rotations of 10 degrees). ", "caption_bbox": [73, 641, 408, 669]}], "429": [{"image_id": 0, "file_name": "429_00.png", "page": 3, "dpi": 300, "bbox": [73, 73, 777, 433], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The interface of the prototype where the limb reduction defect is analyzed. (A1) The univariate analysis view. (A2) The descriptive statistics information panel. (B) The variable grouping view. (C) The model evaluation and comparison view. ", "caption_bbox": [73, 446, 775, 473]}, {"image_id": 1, "file_name": "429_01.png", "page": 3, "dpi": 300, "bbox": [78, 867, 408, 966], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visual Analytics architecture for risk factors analysis.", "caption_bbox": [86, 983, 392, 997]}, {"image_id": 2, "file_name": "429_02.png", "page": 4, "dpi": 300, "bbox": [73, 727, 412, 828], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Indicators displayed in the univariate analysis view. The variables selected are highlighted in yellow. ", "caption_bbox": [73, 841, 408, 868]}, {"image_id": 3, "file_name": "429_03.png", "page": 5, "dpi": 300, "bbox": [74, 75, 776, 454], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A. The variable groups view. L0, L1, L12, and VA indicate risk factors identi\ufb01ed by Forward Stepwise selection, LASSO, Elastic Net, and our visual analytics approach, respectively. B. The result of a model with variables selected by L12. The gray in the rightmost column indicates that the model is not statistically signi\ufb01cant. The green background behind the chemical names in the \ufb01rst column indicates the presence of confounding. ", "caption_bbox": [73, 460, 775, 513]}, {"image_id": 4, "file_name": "429_04.png", "page": 6, "dpi": 300, "bbox": [440, 625, 793, 782], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Weak associations. A. 1,1,2-trichloroethane is included in a model with stable variables. It has a red bar indicating its sta- tistical signi\ufb01cance. B and C show the same pattern for 1,1,2,2- tetrachloroethane and 1,2-dichloropropane, respectively. D. The three of them are added into the same model. They all have gray bars which mean that they become non-signi\ufb01cant. ", "caption_bbox": [440, 785, 775, 865]}], "43": [{"image_id": 0, "file_name": "43_00.png", "page": 2, "dpi": 300, "bbox": [78, 447, 404, 773], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Original slice from the CT scan: the tumour is visible a darker object and the blood vessels as lighter objects. ", "caption_bbox": [78, 785, 403, 831]}, {"image_id": 1, "file_name": "43_01.png", "page": 2, "dpi": 300, "bbox": [433, 697, 737, 1000], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A low pass filter followed by histogram equalisation was applied to the image shown in figure 1 after it was cropped: tumour and blood vessels become apparent. ", "caption_bbox": [421, 1008, 747, 1070]}, {"image_id": 2, "file_name": "43_02.png", "page": 3, "dpi": 300, "bbox": [179, 714, 645, 1034], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: 3D model of the patient's liver showing the blood vessels (red), tumour (blue) and liver (yellow). The x- and y-axis corresponds to pixels and the z-axis to the slice number. ", "caption_bbox": [78, 1043, 734, 1073]}, {"image_id": 3, "file_name": "43_03.png", "page": 3, "dpi": 300, "bbox": [433, 245, 737, 548], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Semi-automatic delineation of the liver by region-growing. ", "caption_bbox": [421, 557, 746, 587]}, {"image_id": 4, "file_name": "43_04.png", "page": 4, "dpi": 300, "bbox": [78, 763, 399, 1031], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Graphical user interface showing the segmented image (top) and the original image (bottom) and associated histograms. ", "caption_bbox": [78, 1039, 403, 1085]}], "430": [{"image_id": 0, "file_name": "430_00.png", "page": 3, "dpi": 300, "bbox": [108, 74, 742, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Conceptual illustration of dimension reconstruction for visually interactive subspace analysis.", "caption_bbox": [173, 367, 674, 381]}, {"image_id": 1, "file_name": "430_01.png", "page": 4, "dpi": 300, "bbox": [102, 77, 372, 183], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Conceptual illustration of LDA. (a) The two classes are separated well when projected onto RD1. (b) M\u2019 on RD1 is the projected point of M. ", "caption_bbox": [73, 201, 408, 241]}, {"image_id": 2, "file_name": "430_02.png", "page": 4, "dpi": 300, "bbox": [73, 630, 412, 742], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Proposed analytical work\ufb02ow.", "caption_bbox": [143, 756, 338, 770]}, {"image_id": 3, "file_name": "430_03.png", "page": 4, "dpi": 300, "bbox": [468, 355, 749, 484], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Illustration of hierarchical dimension projection.", "caption_bbox": [468, 498, 747, 512]}, {"image_id": 4, "file_name": "430_04.png", "page": 4, "dpi": 300, "bbox": [469, 791, 747, 972], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Menu of data plot.", "caption_bbox": [538, 986, 676, 1000]}, {"image_id": 5, "file_name": "430_05.png", "page": 5, "dpi": 300, "bbox": [88, 74, 762, 496], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Overview of user interface with (a) dimension projection plot, (b) dimensional histogram list, (c) multi-viewed data exploration area, and (d) stacked dimensional histograms of two new dimensions reconstructed from cluster-tagged subspace5. ", "caption_bbox": [73, 509, 775, 536]}, {"image_id": 6, "file_name": "430_06.png", "page": 6, "dpi": 300, "bbox": [98, 73, 752, 402], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Experiments on the food data set: (a) projection of all dimensions; (b) four subspaces constructed during the \ufb01rst round of analysis; (c) the dimensional histograms of two RDs: namely RD-A from subspace1 and RD-B from subspace2; (d) improved data projections by adding the RDs into subpace3; (e) improved data projections by adding the original dimensions into subspace1 into subspace3. (f) the result of data projection by combining subspace4 with the two RDs. ", "caption_bbox": [73, 420, 775, 473]}, {"image_id": 7, "file_name": "430_07.png", "page": 7, "dpi": 300, "bbox": [98, 74, 752, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Experiments on the molecule data set: (a) the dimension projection of the molecule data set; (b) four subspaces constructed during the \ufb01rst round of analysis; (c) updated dimension projection after reconstructing two dimensions from subspace2 and subspace 3; (d) 6 clusters formed in subspace5 which is constructed by the two RDs; (e) tagging 6 clusters in subspace5 by colors and tracking them to gain the relationship between two cluster structures formed in subspace2 and subspace3. ", "caption_bbox": [73, 407, 775, 460]}], "431": [{"image_id": 0, "file_name": "431_00.png", "page": 1, "dpi": 300, "bbox": [446, 800, 768, 959], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Relative-angle distribution for a lithium ion for different time-scales shown as a 2D image and two histograms correspond- ing to the highlighted columns. ", "caption_bbox": [440, 965, 775, 1006]}, {"image_id": 1, "file_name": "431_01.png", "page": 3, "dpi": 300, "bbox": [130, 63, 350, 142], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: As an atom moves along a trajectory, with the position given by X(t), a single angle \u03b8 (t; \u0394) records the deviation from straight line motion for the positions X(t), X(t + \u0394), and X(t + 2\u0394). ", "caption_bbox": [73, 141, 408, 184]}, {"image_id": 2, "file_name": "431_02.png", "page": 3, "dpi": 300, "bbox": [459, 81, 751, 200], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Histogram of angles for \u0394 = 4.95 ps.", "caption_bbox": [490, 203, 725, 221]}, {"image_id": 3, "file_name": "431_03.png", "page": 3, "dpi": 300, "bbox": [459, 227, 750, 347], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Distribution of angles with time for \u0394 = 4.95 ps.", "caption_bbox": [461, 350, 754, 368]}, {"image_id": 4, "file_name": "431_04.png", "page": 3, "dpi": 300, "bbox": [459, 375, 750, 494], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Histogram of time-scales for \u03b8 = 166\u25e6 .", "caption_bbox": [484, 495, 732, 515]}, {"image_id": 5, "file_name": "431_05.png", "page": 4, "dpi": 300, "bbox": [604, 98, 766, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A lithium ion (dark gray) is shown at the center, and is bonded to four carbonyl Oxy- gen atoms (magenta), which are part of the EC molecules. ", "caption_bbox": [603, 328, 766, 397]}, {"image_id": 6, "file_name": "431_06.png", "page": 4, "dpi": 300, "bbox": [451, 651, 758, 779], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Visualizing data and visualization uncertainties in his- tograms for all time-scales. ", "caption_bbox": [440, 785, 775, 813]}, {"image_id": 7, "file_name": "431_07.png", "page": 4, "dpi": 300, "bbox": [450, 419, 760, 598], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Mean L2 (solid lines) and mean L\u221e (dashed lines) in the computed PDFs appear to have converged after about 500 steps of bootstrapping using any of the subset sizes which we experimented. ", "caption_bbox": [440, 603, 775, 645]}, {"image_id": 8, "file_name": "431_08.png", "page": 4, "dpi": 300, "bbox": [83, 79, 576, 315], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Relative-angle distribution visualized for multiple time-scales visualized as a single 2D im- age; each column is a 1D histogram. Vast differences in number of samples between histograms cause the left of the image (smaller time-scales) to be \u201cwashed out\u201d when the color map is applied to the func- tion range [0, 0.2] of the entire image (a). To remedy this, the same color map (b) must be dynamically mapped only to the function range, i.e., [0, 0.05], in the visible area to improve the visualization (c). ", "caption_bbox": [73, 328, 586, 397]}, {"image_id": 9, "file_name": "431_09.png", "page": 5, "dpi": 300, "bbox": [123, 74, 723, 448], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Visualization error in a given 2D image (a) can be reduced by either zooming in with in the limited resolution (i.e., reducing N for a given n) (b) or increasing the total available resolution (c) (i.e., increasing n for a given N). ", "caption_bbox": [73, 453, 775, 481]}, {"image_id": 10, "file_name": "431_10.png", "page": 6, "dpi": 300, "bbox": [103, 74, 748, 370], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Screenshots of our integrated analysis and visualization tool for interactive exploration of atomic trajectories.", "caption_bbox": [124, 374, 725, 388]}, {"image_id": 11, "file_name": "431_11.png", "page": 7, "dpi": 300, "bbox": [73, 66, 411, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: The 2D histogram at \u0394 = 0.05 ps, and \u03b8 \u2248 150\u25e6 , along with the two respective histograms along the corresponding axes, indicate coherent behavior correlated with con\ufb01ned motion. ", "caption_bbox": [73, 305, 408, 351]}, {"image_id": 12, "file_name": "431_12.png", "page": 8, "dpi": 300, "bbox": [77, 73, 770, 417], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Comparison of relative angle distributions of different species of atoms in the simulation.", "caption_bbox": [173, 429, 675, 443]}], "432": [{"image_id": 0, "file_name": "432_00.png", "page": 1, "dpi": 300, "bbox": [73, 86, 777, 368], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example of protein with PDB ID 1VIS demonstrating our visualization method. Left: the full SES model (33.3 FPS). Middle: with basic transparency (33.3 FPS). Right: a user-de\ufb01ned transparent visualization that includes cavities (32.2 FPS). The performance of the visualization was measured using the resolution of 1024 \u00d7 768 and the \ufb01ll rate was 48.3%. ", "caption_bbox": [73, 378, 775, 421]}, {"image_id": 1, "file_name": "432_01.png", "page": 3, "dpi": 300, "bbox": [73, 74, 777, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of the visualization pipeline. The input data (Sec. 3) contains snapshots of MD trajectories which are processed to construct the molecular surface and cavities (Sec. 4). Then, the surface areas of cavities are estimated (Sec. 5.3), which are used as the color codes, ranging from yellow (smallest) to magenta (largest). These areas serve for \ufb01ltering out of too small cavities. Finally, the surface elements are ray-cast (Sec. 5.1) to compose the surface fragments used in the \ufb01nal stage to visualize the surfaces transparently via a user-de\ufb01ned opacity modulation (Sec. 5.2). ", "caption_bbox": [73, 267, 775, 336]}, {"image_id": 2, "file_name": "432_02.png", "page": 3, "dpi": 300, "bbox": [458, 793, 758, 919], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparison between the original method [16] rendered with transparency (left) and our extended method (right). The orig- inal method renders also parts of spheres (red) and tori (blue) that lie below the surface. Our method produces only patches that are part of the surface. ", "caption_bbox": [440, 930, 775, 999]}, {"image_id": 3, "file_name": "432_03.png", "page": 4, "dpi": 300, "bbox": [74, 411, 409, 535], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Illustration of the data structure for storing spherical tri- angles. Triangles t1 and t2 are stored linearly in an array and their incident torus \u03c4 is connected to them via a hash table. ", "caption_bbox": [73, 546, 408, 589]}, {"image_id": 4, "file_name": "432_04.png", "page": 4, "dpi": 300, "bbox": [441, 73, 774, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Illustration of the surface graph construction. Trian- gles form vertices and toroidal patches form edges between them. Spherical patches are represented as cycles in the graph. ", "caption_bbox": [440, 239, 775, 280]}, {"image_id": 5, "file_name": "432_05.png", "page": 5, "dpi": 300, "bbox": [448, 714, 774, 850], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Ray-tracing a toroidal patch. Left: the saddle part of the torus (blue) is cut by the visibility sphere which was introduced in [15]. Right: the patch (blue) is cut from the whole toroidal ring by clipping planes (yellow) de\ufb01ned by the spherical triangles (green). ", "caption_bbox": [440, 860, 775, 929]}, {"image_id": 6, "file_name": "432_06.png", "page": 5, "dpi": 300, "bbox": [450, 193, 766, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Generation of bounding boxes for the SES patches. Left: OBBs for spherical triangles. Right: OBBs for toroidal patches. ", "caption_bbox": [440, 309, 775, 337]}, {"image_id": 7, "file_name": "432_07.png", "page": 5, "dpi": 300, "bbox": [84, 74, 398, 208], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Example of an isolated torus between two spheres. Left: isolated tori (yellow) do not have any neighboring triangles. There- fore, the surface component to which they belong cannot be deter- mined directly from the surface graph. Right: an isolated torus cuts circular holes in its neighboring spherical patches. ", "caption_bbox": [73, 218, 408, 287]}, {"image_id": 8, "file_name": "432_08.png", "page": 7, "dpi": 300, "bbox": [75, 74, 776, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Example of applying parameters K and O to protein with PDB ID 1CQW. Note that higher values of the overall opacity O emphasize the front molecular surface, while higher values of maximum exponent K give more prominence to the internal surfaces and cavities. ", "caption_bbox": [73, 288, 775, 316]}], "433": [{"image_id": 0, "file_name": "433_00.png", "page": 1, "dpi": 300, "bbox": [493, 259, 723, 433], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Left: The transmembrane channel through the protein 2OAR is detected as disconnected cavities. The default parameters are used to compute the cavities. Right: However, it can be con- nected by perturbing a few atoms around its bottleneck. ", "caption_bbox": [440, 436, 775, 489]}, {"image_id": 1, "file_name": "433_01.png", "page": 2, "dpi": 300, "bbox": [112, 74, 732, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Power diagram of a weighted point set in R2 , power edges and vertices are shown in green. (b) The weighted Delaunay com- plex (black edges) is the dual of the power diagram. (c) The \u03b1-complex K\u03b1 for \u03b1 = 0 is shown in red. This is the dual of the intersection of power diagram and union of balls. K\u03b1 forms the occupied region (OR) of the molecule. (d) The empty region (ER) in green. This region is de\ufb01ned by Delaunay \ufb02ow. The green triangles do not belong to OR and have \ufb02ow towards a triangle within the molecule. The set of simplices in OR and ER form the molecular region (MR). (e) ER consists of two maximally connected components, called cavities, shown in blue and yellow. ", "caption_bbox": [73, 201, 775, 269]}, {"image_id": 2, "file_name": "433_02.png", "page": 3, "dpi": 300, "bbox": [112, 73, 732, 195], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration of cavity connection method based on BOTTLENECK criterion using a 2D example. (a) The two cavities which are required to be connected are shown in the context of the molecule shown as a set of grey disks. The GMR is shown in green. (b) The maximum spanning tree (MaxST ) is computed for the network. (c) The representative nodes of the two cavities in the MaxST are colored red. (d) The connecting path detected between these cavities. (e) The only edge of the path which belongs to OR is highlighted in red. The lining atoms of this edge can be perturbed to physically connect these cavities. ", "caption_bbox": [73, 200, 775, 267]}, {"image_id": 3, "file_name": "433_03.png", "page": 3, "dpi": 300, "bbox": [122, 274, 716, 467], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Demonstration of cavity connection method applied to the protein 2OAR. (a) The two cavities which are required to be connected are shown in the context of the molecule shown in cartoon representation. (b) The complete dual graph GMR . The edges which belong to OR are colored red while edges belonging to ER are colored yellow. (c) The MaxST computed for GMR . Same coloring scheme is used to identify edges in OR and ER. (d) The MaxST is further pruned by restricting to paths connecting the cavity representatives. Here blue spheres show the cavity representatives. (e) Using cavity connection algorithm, the best path connecting the representative nodes of the two cavities shown in (a) is computed. The atoms are perturbed appropriately to obtain the merged cavity shown in this \ufb01gure. ", "caption_bbox": [73, 473, 775, 553]}, {"image_id": 4, "file_name": "433_04.png", "page": 4, "dpi": 300, "bbox": [90, 125, 755, 879], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The three linked views of cavities in 2OAR are shown. Cavities may be selected from any of these views. (a) The 3D view shows the two cavities selected for connection in green and violet colors. Other cavities are shown in grey. (b) 2D graph visualization of the cavities. (c) This panel shows the cavity dendrogram in which the height is proportional to the \u03b1min of the connecting path between cavities. Some additional 3D views are shown in the bottom row. From left to right: the dual graph representation, the simpli\ufb01ed MaxST , and the two cavities to be connected. ", "caption_bbox": [73, 894, 775, 947]}, {"image_id": 5, "file_name": "433_05.png", "page": 6, "dpi": 300, "bbox": [117, 248, 726, 444], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Cavity connection results for MscL transmembrane protein (PDB id: 2OAR). (a) All cavities detected in this protein are shown in the context of the molecule. The membrane is shown as red and blue layers. (b) We select two cavities at either end of the membrane for connection. (c) The connecting path found by the method is shown in pink. The two cavities shown in the dual graph representation for context. The maximum perturbation for the connecting path was found to be 0.4A\u030a. (d) Single connected cavity after atom perturbation. (e) The connecting path helps identify the known ion transfer channel. ", "caption_bbox": [73, 450, 775, 517]}, {"image_id": 6, "file_name": "433_06.png", "page": 6, "dpi": 300, "bbox": [82, 73, 767, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Comparison of cavity connection results with ROBUST C AVITIES. (a) The disconnected channel detected as two separate cavities (col- ored green and orange) in 2OAR. (b) The cavity connection result. (c) The ROBUST C AVITIES result. Clearly, the volume of the merged cavity has increased by a signi\ufb01cant amount as compared to the result obtained by our cavity connection method. (d)\u2013(f) Similar result is obtained for the protein 2YXQ. (g)\u2013(i) The result obtained for the protein 2YXR. ", "caption_bbox": [73, 193, 775, 246]}, {"image_id": 7, "file_name": "433_07.png", "page": 7, "dpi": 300, "bbox": [73, 79, 766, 456], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The results for Translocase SecY case study. (a) The cavities detected in the wild type protein (1RHZ). (b) The cavities selected for connection. (c) The connecting path (pink) between these cavities. The maximum perturbation for this connecting path was found to be 0.69A\u030a. (d) The resulting cavity after perturbation of atoms. (e) The connecting path as a channel across the membrane. (f)\u2013(j) Similar results for the half plug deletion mutant (2YXQ) of the protein. The maximum perturbation for the connecting path was found to be 0.42A\u030a. (k)\u2013(o) The results for the full plug deletion mutant (2YXR) of the protein. The maximum perturbation was found to be 0.43A\u030a. ", "caption_bbox": [73, 462, 775, 529]}, {"image_id": 8, "file_name": "433_08.png", "page": 8, "dpi": 300, "bbox": [84, 75, 754, 181], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The results for Myoglobin case study. (a) The set of cavities detected in Myoglobin bound with heme. (b) The cavities of interest in this protein that have been studied earlier are labeled. We are interested in \ufb01nding the connecting path between DP and Xe1 . (c) A connecting path (pink) from Xe1 is detected that traverses through Xe2 , Xe3 , Ph2, Ph1 and Xe4 to reach DP. This connection was suggested after extensive molecular dynamics simulations. However, we are able to detect this connection directly using the cavity connection method. The maximum perturbation required for detecting the path is found to be only 0.25A\u030a. (d) The detected path (pink) along with dual graph representations of the two selected cavities. (e) The merged cavity (blue) formed after atom perturbation. (f) Using PROXIMITY criterion for \ufb01nding the connecting path between DP and Xe1 results in detection of direct path (pink) which does not pass through other Xe sites. The maximum perturbation for this path was found to be 2.16A\u030a which suggests that direct connection between DP and Xe1 is highly improbable. ", "caption_bbox": [73, 190, 775, 296]}], "434": [{"image_id": 0, "file_name": "434_00.png", "page": 1, "dpi": 300, "bbox": [424, 86, 767, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Pointwise misalignments caused by small perturbation or asymmetric variation in velocity direction: a single point in just one pathline (a); shifting occurrence time of a wavelet (outlier) (b); a 2D illustration of dynamic time warping. ", "caption_bbox": [440, 380, 775, 433]}, {"image_id": 1, "file_name": "434_01.png", "page": 3, "dpi": 300, "bbox": [75, 76, 774, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Pipeline of our work. We \ufb01rstly trace pathlines in parallel from the raw ensemble data. By employing the parallel LCSS sequence encoding and distance metric, the generated pathlines then are encoded into LCSS sequences for further visualization and multiscale temporal comparison. ", "caption_bbox": [73, 245, 775, 285]}, {"image_id": 2, "file_name": "434_02.png", "page": 3, "dpi": 300, "bbox": [440, 296, 777, 480], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: 2D illustration of the block-index encoding and subse- quence comparison for multiscale temporal comparison. The block- index sequence of Run 0 is (0, 1, 2, 2, 3, 13, 14, 15, 16, 6, 7, 8, 9). The sequence of Run 1 is (0, 1, 2, 2, 3, 4, 5, 6, -4, -3, -2, 8, 9). ", "caption_bbox": [440, 481, 775, 536]}, {"image_id": 3, "file_name": "434_03.png", "page": 4, "dpi": 300, "bbox": [73, 74, 410, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Sensitivity to outliers when the noise is 0.5%. All distance \ufb01elds are normalized. The sensitivity are measured by three chang- ing rate thresholds. ", "caption_bbox": [440, 945, 775, 985]}, {"image_id": 4, "file_name": "434_04.png", "page": 5, "dpi": 300, "bbox": [439, 73, 777, 347], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Average timing results (in seconds) for the three distances computations. The numbers of processors of the two tests are 2 and 32, respectively. The total numbers of seeds are 80,000 and 540,000, respectively. \u201cLength\u201d is the average length of the traced pathline. The \u201cPW Time,\u201d \u201cDTW Time,\u201d and the \u201cLCSS Time\u201d are the corresponding distance function call times on all nodes. ", "caption_bbox": [440, 791, 775, 871]}, {"image_id": 5, "file_name": "434_05.png", "page": 5, "dpi": 300, "bbox": [77, 74, 407, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Ground truth test on a 2D synthetic time-varying \ufb02ow dataset: (a) variation \ufb01eld produced by pointwise distance; (b) varia- tion \ufb01eld produced by DTW distance; (c) variation \ufb01eld produced by our LCSS distance. ", "caption_bbox": [440, 350, 775, 403]}, {"image_id": 6, "file_name": "434_06.png", "page": 6, "dpi": 300, "bbox": [439, 384, 777, 612], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Multiscale temporal comparison for WRF data. Daily com- parative visualization from 7/1/2012 to 7/9/2012. Daily trends (detail) and weekly trends (overview) can be analyzed simultaneously. ", "caption_bbox": [440, 617, 775, 657]}, {"image_id": 7, "file_name": "434_07.png", "page": 6, "dpi": 300, "bbox": [100, 75, 747, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) Similarity \ufb01eld output by LCSS method with the same block size as (h); (b) variation \ufb01eld output by LCSS method with the same block size as (e); similarity \ufb01eld (c) and variation \ufb01eld (f) output by pointwise method; similarity \ufb01eld (d) and variation \ufb01eld (g) output by DTW method; similarity \ufb01eld (e) and variation \ufb01eld (h) output by LCSS method; The boxes in (e) and (h) are clustering regions with high LCSS variation. ", "caption_bbox": [73, 334, 775, 374]}, {"image_id": 8, "file_name": "434_08.png", "page": 8, "dpi": 300, "bbox": [73, 74, 777, 215], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparative results for GEOS-5 data. (a) Variation \ufb01eld computed by pointwise method. (b) Variation \ufb01eld (b) and similarity \ufb01eld (c) computed by LCSS distance. The LCSS similarity \ufb01eld and the ensemble pathlines around the equator behave similarly. (d) Similarity \ufb01eld results from another perspective to see the similarity distribution along altitude. The boxes in (b) and dashed boxes in (a), (c), and (d) represent the clustered regions with high LCSS variation. ", "caption_bbox": [73, 218, 775, 271]}], "435": [{"image_id": 0, "file_name": "435_00.png", "page": 3, "dpi": 300, "bbox": [98, 73, 752, 346], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visual comparison of two time surfaces using our new approach. Our analysis of this study case is described in Sec. 8. (a) The two time surfaces (green) in the turbulent channel dataset. The seeding planes (in blue) are placed in correspondence with a hairpin vortex (left) and two streamwise vortices (right), detected with the Q criterion [20] (in purple). (b, c) The original and the reformed surfaces with the tensor lines of the metric tensor \ufb01eld. The square roots of the related eigenvalues are mapped to colors in order to convey the local deformations. (d, e, f) Visualizations of the reformed velocity, vorticity and strain rate. The color of the surface encodes the magnitudes of the respective attribute, while the color of the glyphs depends on the alignment between the surface and the vectorial/tensorial quantity. ", "caption_bbox": [73, 361, 775, 441]}, {"image_id": 1, "file_name": "435_01.png", "page": 4, "dpi": 300, "bbox": [451, 74, 765, 391], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Examples of surface reformation. Orientation marks are displayed on the boundaries. The pink spheres indicate a user se- lected point and all the corresponding points                                                 across the surfaces. The surfaces are colored according to \u03bb0 \u03bb1 , using a logarithmic color scale (1st and 2nd columns). The same color scale is used for coloring the tensor lines, according to the square root of the respec- tive eigenvalues (3rd  column). (a) The surface can be reformed with ", "caption_bbox": [440, 404, 775, 504]}, {"image_id": 2, "file_name": "435_02.png", "page": 6, "dpi": 300, "bbox": [97, 73, 752, 395], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Two families of time surfaces in the heated cylinder dataset. (a, b) The 1st, 13th and 26th surface of each family. (c, d) Our stacked visualization strategy, where the transparency of the surfaces depends on the magnitude of the vorticity. The differences in the evolution of the vorticity across the two families are clearly exposed. The pink spheres indicate a manual selection (Sec.4). ", "caption_bbox": [73, 409, 775, 449]}, {"image_id": 3, "file_name": "435_03.png", "page": 8, "dpi": 300, "bbox": [81, 73, 769, 176], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Results obtained by adopting the (s0 , s1 ) parameterization. (a, b) Surfaces \u03d5 and \u03c8 from Fig. 1. (c) Surface family from Fig. 3ac.", "caption_bbox": [88, 189, 760, 205]}], "436": [{"image_id": 0, "file_name": "436_00.png", "page": 3, "dpi": 300, "bbox": [75, 315, 408, 458], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Comparison between the (a) \ufb01rst-order and (b) second- order access dependencies using graph models. ", "caption_bbox": [73, 461, 408, 488]}, {"image_id": 1, "file_name": "436_01.png", "page": 3, "dpi": 300, "bbox": [76, 74, 777, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Pipeline of our work. In the preprocessing stage, particles are uniformly seeded and traced by the input of the raw \ufb02ow data. The high- order access dependencies are further computed according to the generated pathlines. We further integrate high-order access dependencies into data blocks. A parallel particle tracing framework that performs high-order data prefetching is employed to demonstrate that our method achieves better ef\ufb01ciency than that of the \ufb01rst-order method. ", "caption_bbox": [73, 250, 775, 303]}, {"image_id": 2, "file_name": "436_02.png", "page": 3, "dpi": 300, "bbox": [440, 313, 777, 431], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration of (a) forward pathlines and (b) backward path- lines. In (c), the forward and backward pathline seeded in the same position are considered as one pathline. ", "caption_bbox": [440, 435, 775, 475]}, {"image_id": 3, "file_name": "436_03.png", "page": 4, "dpi": 300, "bbox": [73, 73, 405, 348], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: 2D example to show the computation of \ufb01rst-order and high-order access dependencies. (a) The nine pathlines originated from block (2, 1); (b) The graph model of access dependencies recorded in the pathlines from (a); (c) The individual access depen- dencies from 1st- to 3rd-order of block (2, 1); (d) The 3rd-order \u201cac- cumulated\u201d access dependencies of block (2, 1), which include all access dependencies with 1st, 2nd, and 3rd order. ", "caption_bbox": [73, 351, 408, 444]}, {"image_id": 4, "file_name": "436_04.png", "page": 4, "dpi": 300, "bbox": [441, 74, 775, 206], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Prediction precision of next data accesses under different block size and order settings using simple 2D synthetic data. ", "caption_bbox": [440, 210, 775, 237]}, {"image_id": 5, "file_name": "436_05.png", "page": 5, "dpi": 300, "bbox": [440, 274, 777, 397], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The (a) Isabel dataset and (b) GEOS-5 dataset used in our experiments. ", "caption_bbox": [440, 400, 775, 427]}, {"image_id": 6, "file_name": "436_06.png", "page": 5, "dpi": 300, "bbox": [73, 77, 773, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Recursive prefetching of multiple data entries at a time. In this example, we set the prefetching depth to four and prefetch only one data block at each prefetching depth level. When requesting block (0, 0), blocks (0, 1), (1, 1), (2, 1) and (2, 2) will be predicted one by one and are then prefetched together. At each prefetching depth level, the historical access information is updated. ", "caption_bbox": [73, 223, 775, 263]}, {"image_id": 7, "file_name": "436_07.png", "page": 6, "dpi": 300, "bbox": [440, 170, 777, 448], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Running time and data usage of the sixth-order method in full-range analysis when the number of blocks prefetched at each prefetching depth level N is different. ", "caption_bbox": [440, 451, 775, 491]}, {"image_id": 8, "file_name": "436_08.png", "page": 6, "dpi": 300, "bbox": [74, 171, 410, 449], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Running time and data usage of full-range analysis with dif- ferent numbers of processes. Here the number of blocks prefetched at each prefetching depth level is initially speci\ufb01ed as one. ", "caption_bbox": [73, 452, 408, 492]}, {"image_id": 9, "file_name": "436_09.png", "page": 7, "dpi": 300, "bbox": [440, 74, 777, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Running time and data usage of the sixth-order method in local-range analysis when the number of blocks prefetched at each prefetching depth level N is different. ", "caption_bbox": [440, 357, 775, 397]}, {"image_id": 10, "file_name": "436_10.png", "page": 7, "dpi": 300, "bbox": [74, 74, 410, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Running time and data usage of local-range analysis with different numbers of processes. Here the number of blocks prefetched at each prefetching depth level is initially speci\ufb01ed as one. ", "caption_bbox": [73, 357, 408, 397]}], "437": [{"image_id": 0, "file_name": "437_00.png", "page": 1, "dpi": 300, "bbox": [188, 120, 658, 296], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The Galilean invariant vector \ufb01eld and topology in the \ufb02ow behind a cylinder. Jacobian determinant is encoded in the color map.", "caption_bbox": [78, 307, 770, 321]}, {"image_id": 1, "file_name": "437_01.png", "page": 1, "dpi": 300, "bbox": [439, 715, 778, 889], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Dependence of classical vector \ufb01eld topology on the choice of a suitable frame of reference in the example of a \ufb02ow behind a cylinder on top of line integral convolution (LIC) [4] with the speed encoded in the colormap from Figure 2. ", "caption_bbox": [440, 901, 775, 956]}, {"image_id": 2, "file_name": "437_02.png", "page": 3, "dpi": 300, "bbox": [73, 560, 411, 631], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Regions with separating character (negative determinant) shown in blue and regions with attracting/repelling character (posi- tive determinant) shown in red. ", "caption_bbox": [73, 642, 408, 683]}, {"image_id": 3, "file_name": "437_03.png", "page": 3, "dpi": 300, "bbox": [439, 73, 774, 142], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The critical points of the determinant \ufb01eld are color coded in red for maxima, blue for minima, and yellow for saddle points. The color in the LIC encodes the value of the Jacobian determinant. ", "caption_bbox": [440, 153, 775, 194]}, {"image_id": 4, "file_name": "437_04.png", "page": 4, "dpi": 300, "bbox": [439, 162, 774, 231], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: LIC [4] of the GIVF with the GICPs and the speed en- coded in the colormap. ", "caption_bbox": [440, 242, 775, 270]}, {"image_id": 5, "file_name": "437_05.png", "page": 5, "dpi": 300, "bbox": [439, 584, 777, 844], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: LIC [4] of the analytic \ufb01eld in Figure 9f, which is the result of superposition of the \ufb01ve other \ufb01elds. ", "caption_bbox": [440, 856, 775, 884]}, {"image_id": 6, "file_name": "437_06.png", "page": 5, "dpi": 300, "bbox": [73, 696, 411, 768], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The clustering with respect to steepest ascend/descend for the example of the \ufb02ow behind a cylinder. ", "caption_bbox": [73, 778, 408, 806]}, {"image_id": 7, "file_name": "437_07.png", "page": 5, "dpi": 300, "bbox": [73, 74, 408, 142], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The GIVF from Figure 6 after pruning w.r.t. volume.", "caption_bbox": [83, 153, 397, 167]}, {"image_id": 8, "file_name": "437_08.png", "page": 6, "dpi": 300, "bbox": [439, 362, 778, 486], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: LIC of the GIVF color coded with respect to popular detectors of vortices and sources/sinks shows their correlation. The nodes are the critical points of the criterium \ufb01elds. Maxima are red, minima are blue and saddle points are yellow. ", "caption_bbox": [440, 498, 775, 553]}, {"image_id": 9, "file_name": "437_09.png", "page": 6, "dpi": 300, "bbox": [439, 74, 778, 154], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: GIVFs without pruning for exponents 0, 1, 4, and \u221e in the inverse distance weighting. The color shows the determinant. ", "caption_bbox": [440, 161, 775, 192]}, {"image_id": 10, "file_name": "437_10.png", "page": 7, "dpi": 300, "bbox": [439, 463, 778, 596], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: The petri dish-data set.", "caption_bbox": [522, 608, 694, 622]}, {"image_id": 11, "file_name": "437_11.png", "page": 7, "dpi": 300, "bbox": [73, 499, 411, 590], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Longer sequence of the double gyre dataset.", "caption_bbox": [100, 602, 377, 616]}, {"image_id": 12, "file_name": "437_12.png", "page": 7, "dpi": 300, "bbox": [439, 73, 778, 271], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: The swirling jet entering a \ufb02uid at rest.", "caption_bbox": [482, 283, 733, 297]}, {"image_id": 13, "file_name": "437_13.png", "page": 7, "dpi": 300, "bbox": [73, 358, 411, 494], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Top row shows the \ufb01rst time step, bottom row the time step of maximal displacement of the double gyre dataset. ", "caption_bbox": [73, 309, 408, 337]}], "438": [{"image_id": 0, "file_name": "438_00.png", "page": 2, "dpi": 300, "bbox": [482, 637, 732, 765], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) MSC of a 2D height function that induces a partitioning of the domain. (b) Linear models are \ufb01t to each partition. ", "caption_bbox": [440, 766, 775, 794]}, {"image_id": 1, "file_name": "438_01.png", "page": 3, "dpi": 300, "bbox": [439, 73, 777, 282], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: HDViz applied to the nuclear fuel dataset described in Section 7. (a) Topological skeleton: each summary curve in the visual space corresponds to a partition of the data; transparent tubes capture the spread (width) and density (luminance) of the partition. (b) Persistence chart: number of partitions plotted as a function of scale. (c) Scatterplot matrix of partitioned data. (d) Inverse coordinate plots: summary curves and partitioned data are projected onto a 2D plot where the x-axis represents the output dimension, and each y-axis represents an input dimension. ", "caption_bbox": [439, 281, 777, 405]}, {"image_id": 2, "file_name": "438_02.png", "page": 5, "dpi": 300, "bbox": [130, 74, 716, 411], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Our linked view visualization system using the same 2D test function of Fig. 1. The system includes (A) topology map, (B1-B3) scatterplots, (C) sensitivity view, (D) \ufb01tness view, (E1) persistence diagram, (E2) histogram, and (E3) persistence barcode. ", "caption_bbox": [73, 413, 776, 441]}, {"image_id": 3, "file_name": "438_03.png", "page": 6, "dpi": 300, "bbox": [439, 109, 777, 218], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: SA for the initial nuclear fuel dataset. (a) Topological map used to separate signal from noise. (b) Scatterplot projecting the most signi\ufb01cant input power scalef, grainradius scalef, and the output midplane stress. (c) Linear coef\ufb01cients. ", "caption_bbox": [440, 219, 775, 274]}, {"image_id": 4, "file_name": "438_04.png", "page": 7, "dpi": 300, "bbox": [439, 73, 780, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Left: sensitivity information of the new nuclear fuel dataset under the re\ufb01ned setting with four partitions. Right: global SA of the same dataset. ", "caption_bbox": [440, 301, 775, 342]}, {"image_id": 5, "file_name": "438_05.png", "page": 7, "dpi": 300, "bbox": [73, 73, 412, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: SA of the new nuclear fuel dataset: (a) topology map, (b) persistence diagram, (c) linked scatter plot projection, (d) linear coef\ufb01cients, and (e) \ufb01tness view with stepwise R2 scores. ", "caption_bbox": [73, 238, 410, 279]}, {"image_id": 6, "file_name": "438_06.png", "page": 7, "dpi": 300, "bbox": [73, 584, 407, 720], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: SA of the new nuclear fuel dataset under two re\ufb01ned settings: topology maps and scatterplots with three partitions (a)-(b) and four partitions (c)-(d), respectively. ", "caption_bbox": [73, 721, 409, 762]}], "439": [{"image_id": 0, "file_name": "439_00.png", "page": 1, "dpi": 300, "bbox": [73, 86, 777, 578], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Use case of EnsembleGraph to indicate the in\ufb02uences of Eurasian continent emisions on the surface ozone concentration over eastern Asia. According to similar behaviors between ensemble members over space and time, the neighborhood is partitioned into three parts (left thumbnails in the \ufb01rst three rows): eastern China, southwestern China, and northwestern China. Our novel graph-based interface provides an abstraction of the grouped regions. Users can therefore navigate and track regions of interest over space and time. The last row shows tracking partitioned over southeastern China using a graph view and linked spatial view. Users highlight regions for further analysis in the comparison view, where they compare values between individual runs and behavior similarities between ensembles over different subregions (charts in the \ufb01rst three rows). ", "caption_bbox": [73, 577, 775, 671]}, {"image_id": 1, "file_name": "439_01.png", "page": 3, "dpi": 300, "bbox": [76, 502, 409, 732], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a): BASE run. (b): EA run \u2014 one of the perturbation runs that is simulated for emission absence from the eastern Asia region. (c): Their difference. (d): Monthly O3 average in an chosen area over eastern China. This indicates that domestic emission in\ufb02uence over eastern China is high, especially in summer. ", "caption_bbox": [73, 731, 408, 799]}, {"image_id": 2, "file_name": "439_02.png", "page": 3, "dpi": 300, "bbox": [73, 74, 410, 205], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Seven source emission regions. During the ensemble sim- ulation, anthropogenic emissions from one of the seven regions are turned of, in order to calculate relative importance of in\ufb02uence from human activity around that source region. ", "caption_bbox": [73, 204, 408, 257]}, {"image_id": 3, "file_name": "439_03.png", "page": 4, "dpi": 300, "bbox": [439, 74, 777, 321], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Overview of the EnsembleGraph visual analysis frame- work. The \ufb01rst row is the data preprocessing part: we do partitioning and region tracking for the data domain to provide overall summa- rization. The second row is our interface including three main com- ponents. The temporal view shows regions of similar ensemble be- havior over time; the spatial view shows partitioning results as well as spatial patterns of individual runs; and the comparison view vi- sualizes emission in\ufb02uences of highlighted subregions for validation. The third row is the exploration \ufb02ow. ", "caption_bbox": [440, 320, 775, 440]}, {"image_id": 4, "file_name": "439_04.png", "page": 5, "dpi": 300, "bbox": [80, 582, 403, 749], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Partitioning ensemble domain according to the behavior vectors on each location. First, we calculate the behavior vector on each location according to the BASE run and the perturbation runs to quantify behavior of ensemble on each location using a vector. Then we classify all behavior vectors by clustering methods and use this result for ensemble domain partitioning. ", "caption_bbox": [73, 760, 408, 840]}, {"image_id": 5, "file_name": "439_05.png", "page": 7, "dpi": 300, "bbox": [441, 74, 777, 200], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Ensemble \ufb02ow simulation process. First row: a detail part at the end of the graph. Second row left: time series inside one ellipse region; Second row right: spatial view at the two time steps. ", "caption_bbox": [440, 199, 775, 239]}, {"image_id": 6, "file_name": "439_06.png", "page": 7, "dpi": 300, "bbox": [73, 148, 410, 314], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Southern Hemisphere divided into three regions according to ensemble behaviors. ", "caption_bbox": [73, 313, 408, 340]}], "44": [{"image_id": 0, "file_name": "44_00.png", "page": 3, "dpi": 300, "bbox": [90, 482, 399, 919], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An early version of the Spider prototype. Spider uses HTML and CSS to display a component repository, and to display information relating to spe- cific components. The left hand column contains a list of components currently available on the server. The top right hand side of the page shows the top of the listing for the GNU Regexp Char Classes com- ponent. Spider currently uses an HTML form in the lower half of the browser screen as the input device for test driver instructions. ", "caption_bbox": [83, 932, 405, 1072]}, {"image_id": 1, "file_name": "44_01.png", "page": 3, "dpi": 300, "bbox": [185, 55, 659, 397], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The Spider architecture works on a client/server model. The architecture on the server-side includes a test drive environment, a monitor that captures interesting events, and listeners that generate documentation for use in software visualisations. ", "caption_bbox": [83, 415, 749, 459]}], "440": [{"image_id": 0, "file_name": "440_00.png", "page": 2, "dpi": 300, "bbox": [73, 79, 408, 243], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The process of extracting merger trees from simulation output. Below, we see the same spatial domain at three timesteps. Over time, the particles coalesce into larger structures. A friends- of-friends algorithm identi\ufb01es these groups of particles, called ha- los, at each timestep. The merger tree above shows halos (nodes) linked by edges which indicate the halos they merge into in subse- quent timesteps. ", "caption_bbox": [73, 253, 408, 350]}, {"image_id": 1, "file_name": "440_01.png", "page": 3, "dpi": 300, "bbox": [77, 74, 411, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An overview of the system work\ufb02ow. The large scale particle data resides in a distributed system and is visualized using a paralleled remote renderer. The smaller scale halo merger tree data resides locally and is rendered using a desktop computer. ", "caption_bbox": [73, 240, 408, 295]}, {"image_id": 2, "file_name": "440_02.png", "page": 3, "dpi": 300, "bbox": [73, 312, 412, 496], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A snapshot of the user interface. The quantitative view and 3D particle rendering are placed on the top right and top left respectively. The merger tree visualization is placed below. Here, the user explores a subset of merger trees. For clarity in this \ufb01gure, we provide a zoomed-in view of the selection box that the user has drawn. ", "caption_bbox": [73, 506, 408, 589]}, {"image_id": 3, "file_name": "440_03.png", "page": 3, "dpi": 300, "bbox": [439, 74, 779, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Several merger trees (black) with time on the x axis and mass on the y axis. The user chooses a node with the selection box, which highlights all progenitors and descendants leading to and from that node (red). Large vertical jumps represent nodes at which a halo was subsumed into a much larger halo due to gravita- tional force. ", "caption_bbox": [440, 230, 775, 313]}, {"image_id": 4, "file_name": "440_04.png", "page": 4, "dpi": 300, "bbox": [73, 73, 412, 205], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison of different color mappings on particles. Right) Mapping the velocity of the particle. Left) Mapping the variance with the local velocity \ufb01eld. Blue indicates smaller val- ues while green/yellow indicates larger ones. ", "caption_bbox": [73, 215, 408, 270]}, {"image_id": 5, "file_name": "440_05.png", "page": 4, "dpi": 300, "bbox": [448, 73, 769, 413], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The default particle-based rendering, (a), in comparison with the alternate rendering technique, (b). The default particle view directly conveys data from the simulation, illuminating sim- ulation and analysis code behavior. The alternate technique offers stronger depth cues as well as further insight into the structure of voids and \ufb01laments present in the universe. ", "caption_bbox": [440, 420, 775, 503]}, {"image_id": 6, "file_name": "440_06.png", "page": 5, "dpi": 300, "bbox": [74, 73, 406, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The plot view can provides quantitative feedback based on the user\u2019s selection in one of the other view spaces. This can re\ufb02ect selection of a tree in the merger tree view (a), or of a halo in 3D space (b). The left side contains a plot of the missed progenitor history for a selected merger tree. The dots represent anomalous halos; the solid line re\ufb02ects the sum of the corresponding progen- itors. On the right, we plot velocity magnitude vs. distance from halo center, in simulation coordinates, for particles near a selected halo. This local velocity information provides intuition for how the halo is forming; peaks in the plot may indicate substructure. ", "caption_bbox": [73, 291, 408, 429]}, {"image_id": 7, "file_name": "440_07.png", "page": 6, "dpi": 300, "bbox": [439, 250, 779, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Comparison of one merger tree using a 10-particle per halo minimum (top) and a 100-particle per halo minimum (bottom). Because the smaller minimum allows more distinct progenitor ha- los to be identi\ufb01ed early on, the behavior of each tree differs signif- icantly over time. ", "caption_bbox": [440, 380, 775, 449]}, {"image_id": 8, "file_name": "440_08.png", "page": 6, "dpi": 300, "bbox": [439, 73, 779, 167], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Three consecutive snaphsots at late timesteps of a halo that may be experiencing tidal disruption. This is visible in the group of particles that becomes distinct from the host halo over time. ", "caption_bbox": [440, 177, 775, 232]}, {"image_id": 9, "file_name": "440_09.png", "page": 6, "dpi": 300, "bbox": [73, 73, 412, 151], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: In the merger tree view, the user selects a node with no progenitors that is much more massive than the simulation resolu- tion. This selection triggers highlighting of the relevant particles in the 3D view, seen in this \ufb01gured in the zoomed-in box. ", "caption_bbox": [73, 161, 408, 216]}, {"image_id": 10, "file_name": "440_10.png", "page": 6, "dpi": 300, "bbox": [73, 234, 412, 370], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Particle data for the selected heavy birth in Figure 8. The left image shows the selected halo while the right image shows the same halo a few timesteps later. Note the two satellite halos to the bottom left of the host halo; the halo detection algorithm deter- mines that the halo subsequently grows to include several smaller structures. ", "caption_bbox": [73, 380, 408, 463]}, {"image_id": 11, "file_name": "440_11.png", "page": 7, "dpi": 300, "bbox": [77, 327, 412, 449], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: The log/log plot of strong scaling results for our system (left) shows a decrease in performance at large numbers of nodes, indicating an overhead cost of the renderer. Weak scaling (right) shows nearly ideal total rendering time across all machine sizes. ", "caption_bbox": [73, 463, 408, 518]}, {"image_id": 12, "file_name": "440_12.png", "page": 7, "dpi": 300, "bbox": [73, 74, 412, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Comparison of two merger trees before (top) and af- ter (bottom) an update to the merger tree \ufb01nding algorithm. The presence of heavy birth phenomena, circled above in blue, is sig- ni\ufb01cantly reduced in the lower tree as very massive halos are now linked to smaller progenitors. ", "caption_bbox": [73, 236, 408, 305]}], "441": [{"image_id": 0, "file_name": "441_00.png", "page": 1, "dpi": 300, "bbox": [76, 86, 775, 307], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The proposed system\u2019s work\ufb02ow is divided into three phases. In the \ufb01rst study-centered phase, a questionnaire design is created or selected, and combined with visual stimuli to generate trials. The second phase involves conducting the study by submitting it to the crowd from where the response data is collected and stored in a centralized database. In the third result-centered phase, the study results are analyzed and a report is generated. ", "caption_bbox": [73, 310, 775, 361]}, {"image_id": 1, "file_name": "441_01.png", "page": 3, "dpi": 300, "bbox": [88, 74, 747, 231], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Four examples of the various reusable visual perception tasks supported by the proposed evaluation system. The two leftmost images are examples of absolute and ordinal depth tasks. The two rightmost images are examples of localization of critical points tasks and particle tracing tasks. Before launching a study, the researcher can choose one or more of these tasks right from within the evaluation environment. ", "caption_bbox": [73, 234, 775, 273]}, {"image_id": 2, "file_name": "441_02.png", "page": 5, "dpi": 300, "bbox": [100, 74, 750, 219], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An example sequence of stimuli generated using the automatic stimuli creation mechanism. By sweeping the focal distance parameter for a Depth of Field rendering we generate a set of stimuli to be used in our studies. Together with the color representation of the images we also store the depth buffer as annotation annotation layer. ", "caption_bbox": [73, 222, 775, 261]}, {"image_id": 3, "file_name": "441_03.png", "page": 6, "dpi": 300, "bbox": [83, 73, 767, 237], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The manual stimulus creation widget enables the selection of one canvas to serve as stimulus source, additional canvases for anno- tation layers and textual labels to be associated with the stimulus in order to support the subsequent analysis. The automatic stimuli creation widget supports to capture several stimuli by sweeping over parameters, it supports canvas selection and textual labels like the manual stimulus creation widget but also shows parameters selected for sweeping and allows for previewing of stimuli before uploading them to the system. ", "caption_bbox": [73, 242, 775, 293]}], "442": [{"image_id": 0, "file_name": "442_00.png", "page": 1, "dpi": 300, "bbox": [77, 80, 789, 556], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 1. The interface of our system showing the bipartite relation of U.S. senators\u2019 support of bills and amendments based on roll call vote records. The main view (A) displays clusters of senators in the bottom half and bills in the top half, based on whether the senators support common sets of bills and whether the bills are supported by the same group of senators. The clusters are determined automatically with co-clustering algorithms and displayed via adjacency matrices showing the cohesiveness of the clusters, or a treemap-like space \ufb01lling layout of the nodes. Using color coded party af\ufb01liations, an immediate observation is that the senators mostly vote in accordance with their parties. ", "caption_bbox": [106, 569, 757, 649]}, {"image_id": 1, "file_name": "442_01.png", "page": 3, "dpi": 300, "bbox": [441, 118, 786, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 2. System overview.", "caption_bbox": [438, 289, 560, 303]}, {"image_id": 2, "file_name": "442_02.png", "page": 4, "dpi": 300, "bbox": [471, 707, 732, 800], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 3. Projection of the bipartite relation onto a group of nodes: (a) the bipartite graph with a cluster consists of node A, B, C and D; (b) a one-mode graph formed by projecting the bipartite relation on the cluster, the weight of the edges is the number of common neighbors of two nodes (i.e., concordance); (c) the adjacency matrix displays the weighted one-mode graph. Nodes A, B, and C have similar bipartite connections. ", "caption_bbox": [425, 813, 776, 893]}, {"image_id": 3, "file_name": "442_03.png", "page": 5, "dpi": 300, "bbox": [507, 518, 720, 616], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 4. The buttons af\ufb01liated with each cluster visualization that support cluster representation and re\ufb01nement. ", "caption_bbox": [438, 629, 788, 656]}, {"image_id": 4, "file_name": "442_04.png", "page": 6, "dpi": 300, "bbox": [425, 343, 777, 539], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 6. A user marked all the Republicans as similar to each other (a), and the cluster of senators (b) found by the semi-supervised co-clustering algorithm, the clustering algorithm found Democrats with relatively neutral political standings (c). ", "caption_bbox": [425, 552, 775, 605]}], "443": [{"image_id": 0, "file_name": "443_00.png", "page": 2, "dpi": 300, "bbox": [73, 74, 777, 187], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) The three Reidemeister moves, which relate equivalent knot diagrams. Each move operates on a small region of a knot diagram. (I) Twist and untwist in either direction. (II) Move one loop completely over another. (III) Move a string completely over or under a crossing. (b) Illustration of \u201cGauss\u2019 braid\u201d, an experiment on three-dimensional form generation. (c)-(d) Mathematical knots and braids are often drawn and explained on \ufb02at 2D media such as a blackboard or a sheet of paper. (Photo courtesy of Lior Zaibel and Yishai Fried.) (e) A physical manipulative created using Polypropylene to show braiding procedures. (f) Plastic ropes are used to study three-dimensional knot structures. ", "caption_bbox": [73, 206, 775, 268]}, {"image_id": 1, "file_name": "443_01.png", "page": 2, "dpi": 300, "bbox": [450, 642, 768, 803], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: 3D spatial information of mathematical knots is encoded at the crossings. Crossing points are stored in the data structure of each rigid com- ponent. ", "caption_bbox": [440, 827, 775, 864]}, {"image_id": 2, "file_name": "443_02.png", "page": 3, "dpi": 300, "bbox": [466, 74, 749, 410], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Proposing the Reidemeister moves with multi-touch. The move in (a) is referred to as R1 , the one in (b) as R2 , and (c) as R3 . For any one of these moves R, the move can be applied either from right to left or left to right (the dashed curve segments indicate the local parts of knot diagrams to be overdrawn with a Reidemeister move.) ", "caption_bbox": [440, 428, 775, 490]}, {"image_id": 3, "file_name": "443_03.png", "page": 3, "dpi": 300, "bbox": [132, 81, 355, 336], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) The \u201c\ufb02at\u201d structure used to represent mathematical knots.(b) Creating 3D geometry for stands cross each other and computing a natural Cu- bic Spline for a smooth representation of mathematical knots. (c) Thickening the resultant curve by attaching \u201ctubes\u201d along the curve. (d) 2.5D rendering with light and material adds apparent 3D geometry, depth, and shape to the 2D image. ", "caption_bbox": [73, 355, 408, 430]}, {"image_id": 4, "file_name": "443_04.png", "page": 4, "dpi": 300, "bbox": [442, 422, 783, 686], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Unknotting using Reidemeister moves with multi-touch.", "caption_bbox": [462, 704, 753, 717]}, {"image_id": 5, "file_name": "443_05.png", "page": 4, "dpi": 300, "bbox": [74, 75, 777, 226], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The three basic types of Reidemeister moves can be decomposed into ten elementary moves in our user interface with support for dragging gestures.", "caption_bbox": [78, 237, 769, 250]}, {"image_id": 6, "file_name": "443_06.png", "page": 4, "dpi": 300, "bbox": [73, 446, 414, 746], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Resolving Crossings to Ensure Valid Moves. (a)-(b) Selecting an arc component and proposing R2 . (c) Toggle the crossing signs with a scroll. ", "caption_bbox": [73, 758, 408, 784]}, {"image_id": 7, "file_name": "443_07.png", "page": 4, "dpi": 300, "bbox": [453, 822, 764, 941], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Manipulating isotopes of a four-stranded braid using Reidemeister moves with multi-touch. ", "caption_bbox": [440, 960, 775, 985]}, {"image_id": 8, "file_name": "443_08.png", "page": 5, "dpi": 300, "bbox": [444, 360, 772, 574], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Moving two boxed braids together to perform the product of braids. ", "caption_bbox": [440, 592, 775, 617]}, {"image_id": 9, "file_name": "443_09.png", "page": 5, "dpi": 300, "bbox": [444, 188, 772, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Moving two boxed knots together to compose knots with our interface. ", "caption_bbox": [440, 307, 775, 332]}, {"image_id": 10, "file_name": "443_10.png", "page": 5, "dpi": 300, "bbox": [78, 266, 400, 493], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: R0 : the detour move and short cut move (i.e., the planar isotopy).", "caption_bbox": [73, 511, 408, 524]}, {"image_id": 11, "file_name": "443_11.png", "page": 5, "dpi": 300, "bbox": [86, 726, 397, 846], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Part of the knot is slid along its own string.", "caption_bbox": [118, 864, 363, 877]}, {"image_id": 12, "file_name": "443_12.png", "page": 5, "dpi": 300, "bbox": [453, 717, 764, 837], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Closure of two braids triggered by joining the ends of the strands.", "caption_bbox": [440, 855, 775, 868]}, {"image_id": 13, "file_name": "443_13.png", "page": 6, "dpi": 300, "bbox": [85, 73, 765, 203], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Desingularized knots and Seifert circles generated by multi-touch inputs that pull on the edges joining one crossing.", "caption_bbox": [147, 221, 701, 234]}, {"image_id": 14, "file_name": "443_14.png", "page": 6, "dpi": 300, "bbox": [466, 467, 751, 682], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: The supported manipulations in our system are based on the three types of Reidemeister moves. Our tool allows users to produce and trace equivalent knot diagrams through verifying and illustrating the mathematically valid moves. ", "caption_bbox": [440, 700, 775, 750]}, {"image_id": 15, "file_name": "443_15.png", "page": 6, "dpi": 300, "bbox": [76, 583, 417, 847], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: A interactive visual proof showing that knot composition does not depend on the order of the knots. ", "caption_bbox": [73, 864, 408, 890]}, {"image_id": 16, "file_name": "443_16.png", "page": 7, "dpi": 300, "bbox": [78, 73, 406, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Performance: completion rate, average time, number of moves un- dertaken, average time for accomplishing a valid move, percentage of dragging motion used, and numeric rating received for the accomplished tasks. ", "caption_bbox": [440, 226, 775, 263]}, {"image_id": 17, "file_name": "443_17.png", "page": 7, "dpi": 300, "bbox": [459, 73, 758, 174], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 18: Knot diagram samples used in our user study.", "caption_bbox": [481, 184, 734, 197]}], "444": [{"image_id": 0, "file_name": "444_00.png", "page": 1, "dpi": 300, "bbox": [98, 86, 752, 561], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A screenshot of the spot-tracking lens. The lens is following Belarus in the year 1995. Egypt, Syria, and Tunisia are automatically labeled since they move faster than Belarus. Ukraine and Russia are tracked. They are visible even when they go out of the spotlight. The color coding of countries is the same as in Gapminder[1], in which countries from the same geographic region share the same color. The world map on the top right corner provides a legend of the colors. ", "caption_bbox": [73, 574, 775, 627]}, {"image_id": 1, "file_name": "444_01.png", "page": 2, "dpi": 300, "bbox": [439, 74, 777, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The spotlight. Left: A screenshot of an animation. Non- focal objects and their labels are semi-transparent. Right: The same animation with the spotlight turned on. Automatic labeling is turned on for highlighting fast moving objects near the focal object. ", "caption_bbox": [440, 242, 775, 295]}, {"image_id": 2, "file_name": "444_02.png", "page": 2, "dpi": 300, "bbox": [73, 74, 411, 398], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The frame of reference. Top row: screenshots of an anima- tion showing a focal object moving from 1953 to 1955. No reference frame is used. Bottom row: screenshots of the same animation with a reference frame. It is easier to sense the movement of the focal object in the bottom view. ", "caption_bbox": [73, 411, 408, 478]}, {"image_id": 3, "file_name": "444_03.png", "page": 4, "dpi": 300, "bbox": [95, 73, 389, 437], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Illustration of view center trajectory generation.", "caption_bbox": [100, 449, 378, 463]}, {"image_id": 4, "file_name": "444_04.png", "page": 6, "dpi": 300, "bbox": [106, 77, 380, 243], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Videos preferred in the spotlight user study.", "caption_bbox": [110, 262, 372, 276]}, {"image_id": 5, "file_name": "444_05.png", "page": 7, "dpi": 300, "bbox": [73, 73, 778, 501], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The journey of Germany after World War II. 1: Germany recovers from WWII in 1945 quickly. 2 and 3. Germany quickly surpasses other European countries such as France and Belgium. 4. In 1967, Japan moves forward to join Germany\u2019s neighborhood. 5. More red bubbles (Asian countries) join Germany\u2019s neighborhood in 1989. Meanwhile, Germany retreats a little bit as the result of reuni\ufb01cation. 6. Red bubbles continue their progress in surpassing Germany. ", "caption_bbox": [73, 508, 775, 561]}, {"image_id": 6, "file_name": "444_06.png", "page": 8, "dpi": 300, "bbox": [73, 73, 777, 476], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The journey of India around its independence. 1, 2, and 3. Asian countries such as China, Vietnam, the Philippines, and Indonesia are in an unstable status as they are involved in World War II. India is relatively stable. 4, 5, and 6. In 1946, countries like Vietnam are recovering from the War. India, on the contrary, drops slightly but soon recovers by 1948. Meanwhile, Pakistan also drops and recovers synchronously. ", "caption_bbox": [73, 483, 775, 523]}], "445": [{"image_id": 0, "file_name": "445_00.png", "page": 2, "dpi": 300, "bbox": [449, 74, 776, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Comparison of the aspect ratio methods on the curve y = 1/x, where the line segments in the above row are equally s- paced on x axis while the ones in the bottom row are non-equally spaced. AL, AWO and RV are not only parameterization invariant but also symmetry preservation. MLC generates similar but different as- pect ratios for two parameterizations due to a local optimal solution, although it is essentially parameterization invariant. ", "caption_bbox": [440, 216, 775, 308]}, {"image_id": 1, "file_name": "445_01.png", "page": 3, "dpi": 300, "bbox": [85, 76, 762, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The average absolute slopes generated by applying various aspect ratio selection methods to 1D uniformly sampled curves (a) and 2D non-uniformly sampled contours (b). AL, AWO and RV are similar for 1D and 2D data, while AS is similar with AL for 1D curves but performs differently for 2D contours. ", "caption_bbox": [73, 354, 775, 394]}, {"image_id": 2, "file_name": "445_02.png", "page": 4, "dpi": 300, "bbox": [304, 610, 405, 697], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An isosce- les right triangle. ", "caption_bbox": [306, 711, 408, 738]}, {"image_id": 3, "file_name": "445_03.png", "page": 5, "dpi": 300, "bbox": [671, 883, 750, 938], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The slope distribution of KDE generated contours. ", "caption_bbox": [673, 950, 775, 990]}, {"image_id": 4, "file_name": "445_04.png", "page": 5, "dpi": 300, "bbox": [456, 75, 786, 640], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparison of aspect ratios generated by different meth- ods. (a) The negative log relative aspect ratios for 1D curves and 2D contours; (b) The log of averaged relative errors between AL and different methods, where the x and y axes show the relative errors computed from 1D curves and 2D contours shown in (a), respective- ly. AWO, RV and AL are very similar, while MLC performs poorly for some data sets. ", "caption_bbox": [440, 658, 775, 750]}, {"image_id": 5, "file_name": "445_05.png", "page": 6, "dpi": 300, "bbox": [452, 77, 768, 505], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Selected 2D contours from Figure 4 generated by different aspect ratio selection methods. As in the case of 1D curves, AWO, RV and AL are almost the same. MS is similar to AL, but it selects slightly taller aspect ratio for ecoli. MLC produces smaller aspect ratios in some cases (iris and census) but selects larger ones for the other data. ", "caption_bbox": [440, 522, 775, 601]}, {"image_id": 6, "file_name": "445_06.png", "page": 6, "dpi": 300, "bbox": [90, 77, 398, 505], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Selected 1D curves from Figure 4 show that AWO and RV produce almost the same aspect ratios with AL. MS selects smaller aspect ratios for most of data, while it produces overly taller aspect ratios in some cases (In(x) and 9-13). In contrast, MLC produces s- lightly larger aspect ratios for most of data, whereas it selects smaller ones for the gamma(2,16) and 9-13. ", "caption_bbox": [73, 522, 408, 601]}, {"image_id": 7, "file_name": "445_07.png", "page": 6, "dpi": 300, "bbox": [469, 619, 751, 832], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparison of AL, AWO and RV with ellipses generated by varying ratios of major to minor axis. (a) shows the relationship between the ratios of major to minor axis and the selected aspect ratios; (b)three ellipses with different ratios. The aspect ratios of all methods are almost the same, ellipses are banked to circles. ", "caption_bbox": [440, 849, 775, 915]}, {"image_id": 8, "file_name": "445_08.png", "page": 7, "dpi": 300, "bbox": [86, 76, 395, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison of the aspect ratios generated by MS, AWO, RV and AL on 2D circular contours with different discretization. MS behaves the same as AL when the number of edge is 20, while its resulted aspect ratios are taller when the number of edges are 10 and 30. In contrast, AL, AWO and RV always are very similar. ", "caption_bbox": [73, 290, 408, 356]}, {"image_id": 9, "file_name": "445_09.png", "page": 7, "dpi": 300, "bbox": [92, 373, 391, 443], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Banking a curve (a) where most of slope values (see (f)) are very small. AL (b), AWO (c), and RV (d) produce overly tall aspect ratios, while MLC (e) preserves the original shape. ", "caption_bbox": [73, 458, 408, 498]}], "446": [{"image_id": 0, "file_name": "446_00.png", "page": 1, "dpi": 300, "bbox": [424, 120, 769, 279], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: 2D projections of Wisconsin Cancer data [16] showing two classes as red and blue dots. (a & b) show pairs of dimensions with visibly good class separation and (c & d) with poor separation. Below are the scores of two separation measures (GON, DSC), which are between 100 for best separability, and 0 for worst separability. ", "caption_bbox": [440, 290, 775, 357]}, {"image_id": 1, "file_name": "446_01.png", "page": 3, "dpi": 300, "bbox": [103, 76, 742, 370], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Given a color-coded scatterplot, our global framework (Section 3.1) consists of two major steps. (1) We build a proximity graph of the unlabeled data (Section 3.3). Overall, we explore 143 different graphs from 17 base graphs. Some graphs need to be parameterized (no. of parameters we tested are shown in parentheses). Some graphs are directed, in which case we also look at their mutual (MUT) or symmetrical variants (SYM). (2) We then compute 14 different class-purity functions (Section 3.4). 12 of them are neighborhood-based (top branch), and 2 component-based (bottom branch). For neighborhood-based evaluations, we further differentiate between considering all (A) or target only (T) focus points, and between optimistic (O) and pessimistic (P) tie-breaking rules. This process leads to 2002 new separation measures. ", "caption_bbox": [73, 386, 775, 466]}, {"image_id": 2, "file_name": "446_02.png", "page": 4, "dpi": 300, "bbox": [73, 81, 773, 190], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Base-graphs without scale parameter\u2014 The points of the scatterplot s are represented as colored circles. The color is only meant to visually differentiate the points from each other; in particular, color does not re\ufb02ect any class membership. The light-blue point is the focus point xi , connected to its neighbors Ni through light-blue edges. Together light-blue and black edges form the proximity graph Gs . Yellow-\ufb01lled points indicates neighbors of xi . Thin black and red lines denote the Voronoi cells of the points. The colored dotted circles, as well as other colored visual marks show some properties of the graph that directly relate to the points with the same color. Grey color indicates empty-region areas which should not contain any point to enable some edge to exist. The actual proximity graphs (a)-(e) are described in Section 3.3.1. ", "caption_bbox": [73, 194, 775, 275]}, {"image_id": 3, "file_name": "446_03.png", "page": 4, "dpi": 300, "bbox": [73, 299, 745, 468], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Base graphs with scale parameter\u2014The visual encodings are the same as in Figure 4. Additionally yellow-\ufb01lled points indicate neighbors of xi last entering the neighborhood for the current setting of the scale parameter while red-\ufb01lled points show neighbors also valid for a lower setting of the current scale parameter. Directed edges are indicated as arrows. Small points in KNCG indicate the center of gravity of the current neighbors plus the candidate one, and in GONG they indicate the intermediary point center of the must-be-empty disc. The actual proximity graphs (a)-(f) are described in Section 3.3.2. ", "caption_bbox": [73, 474, 775, 541]}, {"image_id": 4, "file_name": "446_04.png", "page": 5, "dpi": 300, "bbox": [440, 74, 777, 206], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Illustration of the neighborhood-based class-purity evalu- ation. The focus point xi has label 1 (blue color). The class 0 is color-coded in red. The weights wi j \u2208 [0, 1] are indicated near the xi \u2019s neighbors. For MV and WV, the tie-breaking rule can be either opti- mistic b = 1 (O) or pessimistic b = 0 (P). The left case corresponds to pure-class, the right case to class-outlier, and the intermediary cases to mixed-class situations. ", "caption_bbox": [440, 215, 775, 308]}, {"image_id": 5, "file_name": "446_05.png", "page": 6, "dpi": 300, "bbox": [74, 74, 409, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Illustration of the component-based class-purity evaluation and associated measures LTCC (top) and MCEC (bottom). LTCC: The proportion of points contained in the largest connected compo- nent of the target class (here red) is used as a separation measure: the greater the class separation, the lower the number of connected components and the greater their size. MCEC: the number of mixed edges (magenta) in the original labeled graph is compared to the distribution of the number of mixed edges in the same graph with randomly permuted labels. The proportion of random counts greater than the original count serves as a separation measure: the lower the number of mixed edges, the greater the class separation. ", "caption_bbox": [73, 349, 408, 494]}, {"image_id": 6, "file_name": "446_06.png", "page": 7, "dpi": 300, "bbox": [441, 75, 773, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparison of the AUCBA distributions (boxplot) across all features for a given \ufb01xed one. 95% con\ufb01dence intervals are shown in pink. Groups of features are separated based on black/blue colors. Features are ranked based on the median value of the AUCBA distri- bution for each group separately. The features involved in the overall best measure GONG 0.35 DIR CPT are shown in bold font. ", "caption_bbox": [440, 287, 775, 367]}, {"image_id": 7, "file_name": "446_07.png", "page": 7, "dpi": 300, "bbox": [74, 315, 411, 515], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Box plot of the best new measures given a speci\ufb01c base graph (11 \u00d7 bold blue font) and class-purity features (14 \u00d7 bold black font), sorted by AUCBA. Along with the AUCBA (magenta line in the center of the box), the bootstrapping variance is shown using the de- fault boxplot Matlab function which displays the interquartile range (box), 1.5 times the interquartile range above and below the box (whiskers) covering 99.3% of the data if they are normally distributed, and outliers (red dots). This distribution shows the expected perfor- mance on unseen data. The best state-of-the-art measure, DSC, is shown in magenta. ", "caption_bbox": [73, 527, 408, 659]}, {"image_id": 8, "file_name": "446_08.png", "page": 7, "dpi": 300, "bbox": [135, 81, 346, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Distribution of AUCBA scores of the 2002 new separation measures and the best state-of-the-art DSC (red line). The closer the AUCBA is to 1, the better the measure; 0.5 equals a random guess. 58.4% of the new measures outperformed DSC. ", "caption_bbox": [73, 245, 408, 298]}, {"image_id": 9, "file_name": "446_09.png", "page": 8, "dpi": 300, "bbox": [73, 67, 410, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: (a) GON and DSC scores for all pairs of Wisconsin Cancer data scatterplots. Scatterplots with DSC \ufb01xed and low (b) and high (c) GON values (magenta circles in (a)). Scatterplots with GON \ufb01xed and low (d) and high (e) DSC values (black circles in (a)). ", "caption_bbox": [73, 284, 408, 337]}], "447": [{"image_id": 0, "file_name": "447_00.png", "page": 2, "dpi": 300, "bbox": [106, 262, 361, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Schematic data matrix representation of the block model for K = 3 and L = 2. (b) A concept of a spherical k-means algorithm. ", "caption_bbox": [73, 400, 408, 426]}, {"image_id": 1, "file_name": "447_01.png", "page": 2, "dpi": 300, "bbox": [109, 74, 374, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overview of our visualization framework.", "caption_bbox": [117, 239, 365, 252]}, {"image_id": 2, "file_name": "447_02.png", "page": 3, "dpi": 300, "bbox": [74, 74, 403, 159], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Coordinated view of the system, including (a) a classical PCP, (b) a clustered PCP, (c) a many (one)-to-many PCP, and (d) a block matrix diagram. ", "caption_bbox": [73, 168, 408, 207]}, {"image_id": 3, "file_name": "447_03.png", "page": 4, "dpi": 300, "bbox": [98, 475, 756, 704], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualization results on supernovae dataset with 132 data samples and 14 dimensions [2]. Numbers here represent cluster IDs.", "caption_bbox": [86, 711, 759, 724]}, {"image_id": 4, "file_name": "447_04.png", "page": 4, "dpi": 300, "bbox": [98, 214, 748, 441], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualization results on USDA food nutrient data with 722 records and 18 dimensions [1]. Numbers here represent cluster IDs.", "caption_bbox": [91, 448, 757, 461]}, {"image_id": 5, "file_name": "447_05.png", "page": 4, "dpi": 300, "bbox": [94, 75, 759, 177], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Many-to-many PCPs for the case of 3 \u2264 n \u2264 10.", "caption_bbox": [284, 184, 563, 197]}], "449": [{"image_id": 0, "file_name": "449_00.png", "page": 1, "dpi": 300, "bbox": [106, 86, 742, 372], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A clustered graph drawing and proximity graphs computed from the drawing", "caption_bbox": [214, 373, 634, 385]}, {"image_id": 1, "file_name": "449_01.png", "page": 2, "dpi": 300, "bbox": [443, 86, 776, 214], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A grid 10x10: (a) a drawing of the grid; (b) the dNNG of drawing (a); (c) a neighbourhood-faithful drawing. Drawing (a) is not neighbourhood-faithful drawing because its dNNG is not the same with the original grid. Drawing (c) is neighbourhood-faithful. ", "caption_bbox": [439, 220, 775, 272]}, {"image_id": 2, "file_name": "449_02.png", "page": 2, "dpi": 300, "bbox": [444, 281, 775, 422], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A drawing of the Wikispeedia dataset [17]", "caption_bbox": [481, 427, 734, 439]}, {"image_id": 3, "file_name": "449_03.png", "page": 3, "dpi": 300, "bbox": [442, 86, 793, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Average neighbourhood faithfulness measures by proximity graphs. ", "caption_bbox": [439, 349, 775, 374]}], "45": [{"image_id": 0, "file_name": "45_00.png", "page": 2, "dpi": 300, "bbox": [77, 644, 391, 1015], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1 DOI of a tree. The solid vertex is the focus.", "caption_bbox": [80, 1027, 386, 1041]}, {"image_id": 1, "file_name": "45_01.png", "page": 2, "dpi": 300, "bbox": [499, 166, 685, 686], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2 Logical Fisheye View of a tree. (a) Original view of the tree. (b) The logical fisheye view, k = -6, and the solid vertex is the focus. ", "caption_bbox": [444, 699, 739, 745]}, {"image_id": 2, "file_name": "45_02.png", "page": 3, "dpi": 300, "bbox": [140, 646, 320, 879], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3 The Geometric Fisheye View of the tree in Figure 2(a), d = 3.0. ", "caption_bbox": [85, 890, 372, 920]}, {"image_id": 3, "file_name": "45_03.png", "page": 3, "dpi": 300, "bbox": [445, 873, 740, 957], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4 Mapping between a clustered graph and a visualization system. ", "caption_bbox": [453, 964, 730, 994]}, {"image_id": 4, "file_name": "45_04.png", "page": 4, "dpi": 300, "bbox": [128, 85, 701, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5 Small screen view of 2(a). (a) GFV d = 3.0, LFV k= -4. (b) d = 5.0, k = -2. (c) d = 2.0, k = -2.", "caption_bbox": [123, 363, 702, 377]}, {"image_id": 5, "file_name": "45_05.png", "page": 6, "dpi": 300, "bbox": [436, 511, 750, 945], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8 Operation of close cluster and create cluster. (a) Closing cluster. (b)Creating cluster. ", "caption_bbox": [448, 959, 727, 989]}, {"image_id": 6, "file_name": "45_06.png", "page": 6, "dpi": 300, "bbox": [56, 79, 771, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7 (a) A clustered graph. (b) The cluster tree of (a), The leaves of the tree are the vertices of (a). (c) The vertices circled by rectangles are boundary nodes of (b), when solid vertex is focus and k=-5. ", "caption_bbox": [78, 342, 725, 372]}, {"image_id": 7, "file_name": "45_07.png", "page": 7, "dpi": 300, "bbox": [132, 430, 695, 700], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10 Small screen view and its cluster tree. (a) The cluster tree of the small screen view. All children of Vertex 3 are closed, and some children of vertex 7 are closed. (b) The leaves of (a) are the vertices of (b). ", "caption_bbox": [140, 713, 686, 759]}, {"image_id": 8, "file_name": "45_08.png", "page": 7, "dpi": 300, "bbox": [138, 79, 689, 346], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9 DOI recomputation. (a) The original DOI values when the solid vertex is focus. (b) The DOI values after geometric distortion d=4, and structural thresholding k=-5. ", "caption_bbox": [145, 360, 666, 390]}], "450": [{"image_id": 0, "file_name": "450_00.png", "page": 1, "dpi": 300, "bbox": [424, 86, 786, 740], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A: in this conventional overlaid view, time series curves are colored by group: black, red, or orange. B: with these compressed- superposed layers, the red and orange curves have been com- pressed horizontally to reduce occlusion of endpoints of line seg- ments. ", "caption_bbox": [440, 755, 776, 820]}, {"image_id": 1, "file_name": "450_01.png", "page": 2, "dpi": 300, "bbox": [74, 305, 417, 582], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A compressed-superposed layer provides details of fi- nancial data. Blue curves show performance of major Canadian S&P/TSX indexes over four days. The user has selected a single index (highlighted in orange), for which the constituent companies are shown in a compressed layer (in red). ", "caption_bbox": [73, 603, 408, 668]}, {"image_id": 2, "file_name": "450_02.png", "page": 3, "dpi": 300, "bbox": [76, 536, 417, 688], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Daily changes in stock values in 3 sectors of the NASDAQ, with each sector on a different layer. ", "caption_bbox": [73, 705, 408, 731]}, {"image_id": 3, "file_name": "450_03.png", "page": 3, "dpi": 300, "bbox": [466, 811, 751, 932], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Compressed-superposed layers where there are three in- tervals along x that are compressed, but many intermediate x values within each interval. ", "caption_bbox": [440, 946, 775, 985]}, {"image_id": 4, "file_name": "450_04.png", "page": 3, "dpi": 300, "bbox": [440, 76, 785, 211], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Approaches for separating the line segments of time series curves into layers: (A) compression and (B) masking. ", "caption_bbox": [440, 229, 775, 255]}, {"image_id": 5, "file_name": "450_05.png", "page": 4, "dpi": 300, "bbox": [99, 73, 384, 860], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Layout styles for 3 layers (red, orange and blue). A: conven- tional overlaid with only color coding. B: compressed-superposed. C: compressed-juxtaposed. D: shifted layers. ", "caption_bbox": [73, 874, 408, 913]}, {"image_id": 6, "file_name": "450_06.png", "page": 5, "dpi": 300, "bbox": [102, 489, 383, 810], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A: Horizontally-stacked Small Multiples (HSM). B: Vertically-stacked Small Multiples (VSM). ", "caption_bbox": [73, 825, 408, 851]}, {"image_id": 7, "file_name": "450_07.png", "page": 9, "dpi": 300, "bbox": [467, 240, 751, 749], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Conventional overlaid with opacity of 100% (Top), 50% (Middle), 25% (Bottom). Future work could compare these experi- mentally. ", "caption_bbox": [440, 765, 775, 804]}, {"image_id": 8, "file_name": "450_08.png", "page": 9, "dpi": 300, "bbox": [134, 495, 349, 715], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Top: Compressed-juxtaposed layers. Bottom: An alter- native design, where short horizontal strokes show y values with no slope. ", "caption_bbox": [73, 729, 408, 768]}], "451": [{"image_id": 0, "file_name": "451_00.png", "page": 1, "dpi": 300, "bbox": [84, 120, 771, 320], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Local lighting often cannot sufficiently highlight the shape of particle data sets (left), which can encumber the visual analysis. We present a method to create soft shadows for particle data sets using Implicit Sphere Shadow Maps, which enhances the perception of the shape of particle data sets (center). Directional shadows mostly convey larger-scale structural information. Our shadow map method can be combined with real-time Ambient Occlusion (AO), which is commonly used in scientific visualization (right). We use AO to recover spatial information in completely shadowed regions and add it in completely unshadowed ones. ", "caption_bbox": [106, 333, 743, 398]}, {"image_id": 1, "file_name": "451_01.png", "page": 2, "dpi": 300, "bbox": [439, 73, 774, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: If only one texel is sampled, visible artifacts can occur at the shadow borders (left). Sampling one additional ring of texels around the initial texel removes these artifacts (left). ", "caption_bbox": [440, 243, 775, 282]}, {"image_id": 2, "file_name": "451_02.png", "page": 2, "dpi": 300, "bbox": [128, 73, 352, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The shadow map is shown here as the large rectangle. Directional light is cast towards the data set. To determine if a point on the red sphere is shadowed, a ray/sphere intersection is computed with the blue sphere, since the parameters of this sphere are stored in the corresponding texel. The ray is cast from the red sphere surface point with inverse light direction. ", "caption_bbox": [73, 296, 411, 374]}, {"image_id": 3, "file_name": "451_03.png", "page": 3, "dpi": 300, "bbox": [133, 74, 355, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Depiction of the measures used to compute the shadow intensity of soft shadows. The shadow ray is spawned from the lower black sphere. The ray does not hit the sphere above, but will pass through the sphere\u2019s extension, hence a partial shadow is cast. ", "caption_bbox": [73, 268, 409, 320]}, {"image_id": 4, "file_name": "451_04.png", "page": 3, "dpi": 300, "bbox": [439, 74, 777, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Left: Default shadows with hard edges. Right: Same light direction and camera position, but with soft shadows enabled. ", "caption_bbox": [440, 245, 775, 270]}, {"image_id": 5, "file_name": "451_05.png", "page": 4, "dpi": 300, "bbox": [132, 75, 713, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: A comparison between local lighting (left), a combination of our ISSM shadows and AO [11] (center), and an image create by the Tachyon ray tracer included in VMD [8] (right). The data set (1AON) is a protein from the PDB [1]. Note how the large cavity in the center of the protein is nearly invisible when using only local lighting. In contrast, the combination of ISSM and AO highlights the structure clearly and achieves similar image quality to the offline ray tracing, which takes several seconds to compute. ", "caption_bbox": [73, 237, 775, 289]}, {"image_id": 6, "file_name": "451_06.png", "page": 4, "dpi": 300, "bbox": [443, 551, 767, 780], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Performance of our ISSM compared to deferred rendering with local lighting (LL, Phong shading) on our two test systems. The palest bar shows the frame rates for ISSM combined with AO. ", "caption_bbox": [439, 789, 775, 828]}, {"image_id": 7, "file_name": "451_07.png", "page": 4, "dpi": 300, "bbox": [85, 303, 766, 461], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A comparison of lighting methods applied to the largest test data set 1SVA*, a virus capsid of approximately one million atoms, which was instantiated from a single building block (PDB ID: 1SVA). Ambient Occlusion (AO) alone, which is often used in scientific visualization, highlights small-scale structures within the data very well, but lacks a relation to a specific, directional light source. Adding the directional shadows from the ISSM to the AO rendering not only compensates the over-darkening in the top left area but also creates an image that supports depth perception even better, since it is physically more meaningful. ", "caption_bbox": [73, 470, 775, 535]}], "452": [{"image_id": 0, "file_name": "452_00.png", "page": 1, "dpi": 300, "bbox": [517, 458, 699, 581], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A photo of an excavation site showing scattered stone tools.", "caption_bbox": [440, 595, 775, 607]}, {"image_id": 1, "file_name": "452_01.png", "page": 1, "dpi": 300, "bbox": [157, 144, 693, 370], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: 3D visualization views of stone tools. (a) Original view: shows restored models of stone tool that consist of 1 core and 5 flakes. (b) Relationship view: shows adjacent relationships among the stone tool components. (c) Exploded view: shows the assembly directions of each flake and the assembly sequence to instruct the efficient restoration of stone tools. ", "caption_bbox": [73, 383, 775, 422]}, {"image_id": 2, "file_name": "452_02.png", "page": 2, "dpi": 300, "bbox": [151, 334, 333, 534], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Traditional illustration of stone tools in a relic excavation report [14]. (a) The outline of the shape and grain characteristics of stone tools. (b) The identification of each stone tool by numbers. ", "caption_bbox": [73, 546, 408, 585]}, {"image_id": 3, "file_name": "452_03.png", "page": 2, "dpi": 300, "bbox": [495, 356, 722, 472], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Making a stone tool.", "caption_bbox": [533, 487, 682, 499]}, {"image_id": 4, "file_name": "452_04.png", "page": 2, "dpi": 300, "bbox": [502, 701, 714, 807], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Original input models and the generated adjacent relation- ships. Each sphere in (b) corresponds to the stone tool with the same color in (a). ", "caption_bbox": [440, 820, 775, 859]}, {"image_id": 5, "file_name": "452_05.png", "page": 3, "dpi": 300, "bbox": [491, 747, 726, 876], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Rotating separation of a flake. The striking point is shown as the yellow arrow in (a). Here, the yellow arrows are added to each result screenshot in order to show the striking point and clearly express the direction of separation. ", "caption_bbox": [440, 889, 775, 941]}, {"image_id": 6, "file_name": "452_06.png", "page": 3, "dpi": 300, "bbox": [461, 236, 755, 487], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Interactively generating the assembly order of stone tools. The f lake-6 is selected and marked as red as shown in the left figure. The position of f lake-6 is exchanged with f lake-7 as shown in the right figure( f lake-6\u21d4 f lake-7). ", "caption_bbox": [440, 500, 775, 552]}, {"image_id": 7, "file_name": "452_07.png", "page": 3, "dpi": 300, "bbox": [166, 441, 410, 674], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Calculation the coordinate system of a flake surface from adjacent points. ", "caption_bbox": [73, 689, 408, 715]}, {"image_id": 8, "file_name": "452_08.png", "page": 3, "dpi": 300, "bbox": [544, 74, 674, 188], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A cross section of the assembly of stone tools.", "caption_bbox": [469, 203, 746, 215]}, {"image_id": 9, "file_name": "452_09.png", "page": 3, "dpi": 300, "bbox": [150, 74, 334, 166], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The directed relationship graph and generated hierarchical tree. ", "caption_bbox": [73, 179, 408, 205]}, {"image_id": 10, "file_name": "452_10.png", "page": 4, "dpi": 300, "bbox": [512, 573, 704, 754], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: 3D exploded diagram of group 2.", "caption_bbox": [499, 769, 715, 781]}, {"image_id": 11, "file_name": "452_11.png", "page": 4, "dpi": 300, "bbox": [489, 312, 727, 531], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: 3D exploded diagram of group 1.", "caption_bbox": [499, 546, 715, 558]}, {"image_id": 12, "file_name": "452_12.png", "page": 4, "dpi": 300, "bbox": [124, 827, 360, 950], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Original models of group 1 and group 2.", "caption_bbox": [115, 965, 366, 977]}, {"image_id": 13, "file_name": "452_13.png", "page": 4, "dpi": 300, "bbox": [148, 72, 702, 259], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Assembly instruction with a step-by-step guide for group 2.", "caption_bbox": [253, 274, 595, 286]}, {"image_id": 14, "file_name": "452_14.png", "page": 4, "dpi": 300, "bbox": [145, 313, 341, 403], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Calculating the transform matrix of separation.", "caption_bbox": [100, 419, 382, 431]}], "453": [{"image_id": 0, "file_name": "453_00.png", "page": 2, "dpi": 300, "bbox": [74, 684, 409, 897], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Client side of BioLinker visualization has multiple views.", "caption_bbox": [79, 912, 402, 924]}, {"image_id": 1, "file_name": "453_01.png", "page": 3, "dpi": 300, "bbox": [439, 235, 783, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Main View in BioLinker : Visualizing all possible paths from PIK3CA (left) to TRAF6 (right) going through 5 or fewer hops. ", "caption_bbox": [440, 375, 775, 400]}, {"image_id": 2, "file_name": "453_02.png", "page": 3, "dpi": 300, "bbox": [73, 234, 410, 401], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Protein selector (using the search box) in BioLinker .", "caption_bbox": [89, 416, 393, 428]}, {"image_id": 3, "file_name": "453_03.png", "page": 3, "dpi": 300, "bbox": [74, 625, 409, 916], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Main view in BioLinker : displaying protein information to- gether with statistics of its immediate neighbors on mousing over. ", "caption_bbox": [73, 932, 410, 957]}, {"image_id": 4, "file_name": "453_04.png", "page": 4, "dpi": 300, "bbox": [73, 73, 410, 386], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualizing and interacting with conflict matrix in BioLinker : (a) Conflict matrix and publication view of the TGF-beta sub-network (b) Mousing over a potential conflict cell in the matrix (c) Publication data of the two highlighted index cards in (b). ", "caption_bbox": [439, 495, 776, 547]}, {"image_id": 5, "file_name": "453_05.png", "page": 4, "dpi": 300, "bbox": [441, 73, 770, 481], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Comparisons of protein network visualizations on six tasks.", "caption_bbox": [441, 662, 774, 674]}], "454": [{"image_id": 0, "file_name": "454_00.png", "page": 1, "dpi": 300, "bbox": [458, 677, 753, 889], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Flowchart of the system.", "caption_bbox": [522, 916, 692, 928]}, {"image_id": 1, "file_name": "454_01.png", "page": 2, "dpi": 300, "bbox": [488, 235, 721, 473], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Results of SMRP", "caption_bbox": [540, 492, 674, 504]}, {"image_id": 2, "file_name": "454_02.png", "page": 3, "dpi": 300, "bbox": [114, 896, 369, 972], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Tooltip", "caption_bbox": [200, 988, 281, 1000]}, {"image_id": 3, "file_name": "454_03.png", "page": 3, "dpi": 300, "bbox": [78, 76, 426, 202], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: ADR prediction for carbamazepine", "caption_bbox": [501, 301, 714, 313]}, {"image_id": 4, "file_name": "454_04.png", "page": 3, "dpi": 300, "bbox": [143, 254, 369, 404], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Genes shared by the pathways", "caption_bbox": [140, 422, 341, 434]}, {"image_id": 5, "file_name": "454_05.png", "page": 3, "dpi": 300, "bbox": [759, 531, 839, 572], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Pathway connection visualization for carbamazepine", "caption_bbox": [455, 692, 760, 704]}, {"image_id": 6, "file_name": "454_06.png", "page": 4, "dpi": 300, "bbox": [203, 76, 646, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Pathway connection visualization for fluorometholone", "caption_bbox": [269, 519, 578, 531]}, {"image_id": 7, "file_name": "454_07.png", "page": 4, "dpi": 300, "bbox": [200, 256, 652, 502], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: ADR prediction for fluorometholone", "caption_bbox": [132, 571, 349, 583]}], "455": [{"image_id": 0, "file_name": "455_00.png", "page": 2, "dpi": 300, "bbox": [440, 74, 776, 194], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A brief overview of the dataset used in our study, including the information of participant grouping, experimental tasks, and scan sessions. ", "caption_bbox": [440, 206, 775, 247]}, {"image_id": 1, "file_name": "455_01.png", "page": 4, "dpi": 300, "bbox": [73, 525, 410, 640], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The analytical flow of using the system. Each step involves one or more views/panel in the user interface. ", "caption_bbox": [73, 671, 408, 698]}, {"image_id": 2, "file_name": "455_02.png", "page": 4, "dpi": 300, "bbox": [73, 77, 775, 455], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The user interface of the system, which contains five components: (a) settings panel, (b) MDS view, (c) correlation matrix view, (d) 3D graph view, and (e) information view. ", "caption_bbox": [73, 465, 776, 492]}, {"image_id": 3, "file_name": "455_03.png", "page": 5, "dpi": 300, "bbox": [76, 86, 407, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visual cues for presenting additional information. (a) Session information indicated by the type of edges connecting two nodes. (b) The uncertainty of node positions introduced by MDS. The placement of nodes on the left have higher uncertainty values than the nodes on the right side. ", "caption_bbox": [73, 281, 411, 349]}, {"image_id": 4, "file_name": "455_04.png", "page": 7, "dpi": 300, "bbox": [85, 87, 765, 447], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) An MDS view showing the overview of the differences between scans in the entire dataset, including the averaged scans. Averaged scans tend to be similar to each other (top), while individual scans vary (bottom and left). Several scans are selected and their corresponding correlation matrices are displayed for visual comparison. (b) The session indicator lines allow the user to visualized the self-stability or similarity of RSFC matrices of each subject in multiple sessions. ", "caption_bbox": [73, 461, 775, 516]}, {"image_id": 5, "file_name": "455_05.png", "page": 8, "dpi": 300, "bbox": [76, 486, 414, 662], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) The maximum-to-minimum correlation matrix of sub- jects in the stress group who showed a positive cortisol response. (b) The maximum-to-minimum correlation matrix of subjects in the stress group who did not exhibit a physiological stress response. (a) tends to have higher values than (b) in general. The values in both matrices are between 0 and 2 because the range of values in the original matrices are \u22121 and 1. ", "caption_bbox": [73, 675, 411, 771]}, {"image_id": 6, "file_name": "455_06.png", "page": 8, "dpi": 300, "bbox": [76, 89, 775, 348], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) An MDS view showing that the RSFC of the control and stress groups between the pre- and post-task scans in day 1 are changed in a different manner. After setting up a relatively high threshold value, the brain regions where connectivity differentiates the two groups are easily identified. The difference of the averaged pre-post correlation values for both groups is shown in the correlation matrix (b) and 3D graph views (c). Note that the three perimeters shown in (b) and the nodes shown in (c) are colored based on the modularity information. Using consistent color encoding in these two views provides easy reference for the user. ", "caption_bbox": [73, 362, 775, 430]}], "456": [{"image_id": 0, "file_name": "456_00.png", "page": 1, "dpi": 300, "bbox": [109, 120, 757, 440], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Our system explores the controversy in reviews with elaborated visual analytics components. a) the aspect bubble view shows aspects aligned with their sentiments, b) the word cloud view provides an overview of features in an aspect, c) the bar chart view depicts the rating distribution, d) the sentiment pie view displays the sentiment divergences of aspects , e) the partition tree view presents the hierarchical structure of all aspects, f) the line chart view shows two controversial indexes over time, g) the text view provides the original reviews, h) the aspect burst view reveals the hierarchical structure of an aspect, and i) is the control panel. ", "caption_bbox": [106, 454, 743, 534]}, {"image_id": 1, "file_name": "456_01.png", "page": 3, "dpi": 300, "bbox": [127, 75, 725, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: System overview. Data analysis module first quantifies a controversy via the ratings, extracts aspects from review text, and estimates the sentiment toward aspects. Visual design module shows the controversy index evolution over time, and designs three linked views to analyze the cause of a controversy. ", "caption_bbox": [73, 260, 775, 301]}, {"image_id": 2, "file_name": "456_02.png", "page": 6, "dpi": 300, "bbox": [76, 75, 775, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Rand Index of aspect identification.", "caption_bbox": [495, 929, 718, 942]}, {"image_id": 3, "file_name": "456_03.png", "page": 7, "dpi": 300, "bbox": [441, 76, 794, 368], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Controversy analysis for a pair of Bose headphones on Amazon. The aspect bursts of the music, time, and quality aspects are shown in (a), (b) and (c), respectively. The child aspects of the padding aspect is presented in (d). ", "caption_bbox": [439, 375, 775, 430]}, {"image_id": 4, "file_name": "456_04.png", "page": 8, "dpi": 300, "bbox": [127, 77, 724, 483], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Controversy analysis for an Indian cuisine restaurant on Yelp. The rating distributions of two time periods, before 2014 and after 2014, are shown on the left and right of the line chart, respectively. The upper row of aspect bursts contains three aspect bursts before 2014, and the bottom row contains three aspect bursts after 2014. ", "caption_bbox": [73, 491, 777, 532]}, {"image_id": 5, "file_name": "456_05.png", "page": 9, "dpi": 300, "bbox": [470, 76, 747, 194], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Average user rating, hard controversy index, and soft controversy index for R1 (Controversy evolution characterization), R2 (Aspect presentation), R3 (Sentiment divergence visualization), and R4 (Easy to learn, Easy to use). ", "caption_bbox": [440, 197, 777, 252]}], "457": [{"image_id": 0, "file_name": "457_00.png", "page": 1, "dpi": 300, "bbox": [86, 86, 771, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Examples of annotated charts created with ChartAccent: (left) emphasizing the months when Charlotte and Seattle\u2019s temperatures are higher than New York\u2019s average; (right) the relationship between fertility rate and life expectancy, with text and image annotations for the United States, China, and India; countries from North and South America are highlighted in blue. ", "caption_bbox": [106, 384, 742, 423]}, {"image_id": 1, "file_name": "457_01.png", "page": 4, "dpi": 300, "bbox": [443, 75, 775, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An example line chart of average monthly temperatures indicating the types of data item, set, & series targets (a\u2013e) and co- ordinate space targets (f\u2013k); the parenthetical labels (a\u2013k) are anno- tations used to reference prior annotations. ", "caption_bbox": [440, 251, 775, 303]}, {"image_id": 2, "file_name": "457_02.png", "page": 5, "dpi": 300, "bbox": [75, 77, 772, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: ChartAccent\u2019s user interface; (1) manual annotations; (2) the selected annotation represented by a gray dotted rectangle; (3) the ChartAccent control panel; (4) the list of annotations currently applied to the chart; (5) the annotation editor, which allows one to modify (6) the annotation target; and (7) the visual properties of the selected annotation. ", "caption_bbox": [73, 347, 775, 386]}, {"image_id": 3, "file_name": "457_03.png", "page": 6, "dpi": 300, "bbox": [440, 74, 777, 222], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The ChartAccent architecture; the chart creator program that loads the data and renders the chart creates a ChartAccent ob- ject and registers chart elements; ChartAccent.js includes facilities for managing annotation layers and rendering an internal annotation representation to the chart in response to an end-user\u2019s interaction. ", "caption_bbox": [440, 232, 775, 297]}, {"image_id": 4, "file_name": "457_04.png", "page": 6, "dpi": 300, "bbox": [440, 306, 777, 485], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Data item annotations in a node-link graph and a treemap. Left: character co-occurrence graph in Les Mise\u0301rables, with a bubbleset-highlighted set (\u201cCluster 9\u201d) and 3 other nodes selected, with other nodes diminished in salience (data from [8]). Right: check- out count by Dewey category from Seattle Public Library, highlighting three items and diminishing the salience of others (data used with kind permission from George Legrady). ", "caption_bbox": [440, 499, 775, 590]}, {"image_id": 5, "file_name": "457_05.png", "page": 8, "dpi": 300, "bbox": [444, 330, 771, 511], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Task completion time by participant and by task; P9 (a soft- ware engineer and prolific maker of charts) had the shortest com- pletion time for most tasks. (This figure was generated with Chart- Accent.) ", "caption_bbox": [440, 525, 775, 577]}], "458": [{"image_id": 0, "file_name": "458_00.png", "page": 5, "dpi": 300, "bbox": [73, 73, 790, 511], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 1. Aeonium\u2019s coding interface consists of two panels: The top panel primarily supports the coding task and displays a single tweet to code (1) with keywords that the model recognizes highlighted (2), buttons to \ufb02ag that tweet as ambiguous, save it, or make it an exemplar tweet for the selected code (3), and a row of color-coded buttons representing codes in the coding schema with the code de\ufb01nition and an exemplar tweet from master coders (4). The bottom panel enhances the coding task by providing additional information such as the code de\ufb01nitions and examples from the master, user, and partner (5) to highlight discrepancies, distribution of coded tweets for the system, user, and partner keywords (6), helping to illustrate keyword relevance. The bottom panel also includes a list of the user\u2019s previously coded tweets (7) for additional context. ", "caption_bbox": [73, 531, 788, 610]}, {"image_id": 1, "file_name": "458_01.png", "page": 6, "dpi": 300, "bbox": [60, 72, 777, 512], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 2. The review interface supports understanding and negotiation of code boundaries and discrepancies between coders. Its tab-based view allows for switching between the detail view of each code (1). Each code tab provides comparison and edit capability of code de\ufb01nitions (2-4), overview of the data distribution (5), and distribution of coded tweets for keywords extracted (6), comparison of codes (7) to summarize agreement or disagreement between coders, and the list of coded tweets for analysis. Tweets can be \ufb01ltered with search terms (8) or by selecting a keyword (from 6) or a code pair (from 7). Users can reevaluate codes and provide feedback about a disagreement through a dropdown menu (9) or provide more context for their decisions by adding keywords extracted directly from the tweets (10). ", "caption_bbox": [61, 531, 777, 610]}], "459": [{"image_id": 0, "file_name": "459_00.png", "page": 3, "dpi": 300, "bbox": [124, 75, 360, 227], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Main concept of the quasi-biclique edge concentration (QBEC). By applying conventional edge concentration, the data is represented as two biclusters. On the other hand, by applying QBEC, the data can be represented as one bicluster. ", "caption_bbox": [73, 244, 410, 296]}, {"image_id": 1, "file_name": "459_01.png", "page": 4, "dpi": 300, "bbox": [469, 361, 748, 562], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Drawing results of genes vs Per data from a viewpoint different from Figure 3. First, one bicluster that contains Per int P1 and Per mit p1 is selected in (a). (b) is the filtering result for the selected bicluster. By changing \u00b5 to 1.0, 4 strong biclusters are found in (c). ", "caption_bbox": [440, 577, 776, 642]}, {"image_id": 2, "file_name": "459_02.png", "page": 4, "dpi": 300, "bbox": [469, 77, 748, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Drawing results of genes vs Per data. (a), (b), and (c) show biclusters that contain Per int P1 and Per mit p1 with \u00b5 = {0.6, 0.8, 1.0}, respectively. Finally, one bicluster found in (d) by changin \u00b5 to 0.6 to the result shown in (c). ", "caption_bbox": [439, 290, 775, 342]}, {"image_id": 3, "file_name": "459_03.png", "page": 4, "dpi": 300, "bbox": [102, 76, 381, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Drawing results of genes vs NucPos+SpnPos data. Two biclusters with \u00b5 = 0.8 are selected in (a). We obtaiend (b) by applying filtering operation for the two biclusters. ", "caption_bbox": [73, 286, 408, 325]}], "46": [{"image_id": 0, "file_name": "46_00.png", "page": 1, "dpi": 300, "bbox": [446, 280, 738, 673], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Example of a metro map: Sydney Cityrail", "caption_bbox": [427, 683, 748, 706]}, {"image_id": 1, "file_name": "46_01.png", "page": 2, "dpi": 300, "bbox": [88, 53, 407, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Example of a metro map metaphor.", "caption_bbox": [99, 302, 376, 325]}, {"image_id": 2, "file_name": "46_02.png", "page": 2, "dpi": 300, "bbox": [150, 357, 344, 519], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Example of a metro map graph.", "caption_bbox": [113, 527, 367, 550]}, {"image_id": 3, "file_name": "46_03.png", "page": 2, "dpi": 300, "bbox": [492, 575, 686, 737], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Example of a simpli ed metro map graph.", "caption_bbox": [427, 745, 742, 768]}, {"image_id": 4, "file_name": "46_04.png", "page": 4, "dpi": 300, "bbox": [141, 494, 346, 654], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Label positions for two map features. The", "caption_bbox": [83, 663, 404, 686]}, {"image_id": 5, "file_name": "46_05.png", "page": 5, "dpi": 300, "bbox": [82, 513, 407, 754], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Sydney Cityrail produced by Method 2.", "caption_bbox": [93, 762, 388, 785]}, {"image_id": 6, "file_name": "46_06.png", "page": 5, "dpi": 300, "bbox": [426, 358, 752, 599], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Sydney Cityrail produced by Method 4.", "caption_bbox": [438, 607, 733, 630]}, {"image_id": 7, "file_name": "46_07.png", "page": 5, "dpi": 300, "bbox": [82, 192, 407, 433], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Sydney Cityrail produced by Method 1.", "caption_bbox": [93, 441, 388, 464]}, {"image_id": 8, "file_name": "46_08.png", "page": 5, "dpi": 300, "bbox": [426, 53, 752, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Sydney Cityrail produced by Method 3.", "caption_bbox": [438, 302, 733, 325]}, {"image_id": 9, "file_name": "46_09.png", "page": 6, "dpi": 300, "bbox": [76, 53, 415, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Sydney Cityrail produced by Method 5.", "caption_bbox": [89, 302, 391, 325]}, {"image_id": 10, "file_name": "46_10.png", "page": 7, "dpi": 300, "bbox": [54, 213, 781, 880], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Sydney Cityrail metro map with labeling.", "caption_bbox": [255, 892, 570, 915]}, {"image_id": 11, "file_name": "46_11.png", "page": 8, "dpi": 300, "bbox": [83, 212, 752, 881], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Barcelona city metro map with labeling.", "caption_bbox": [258, 892, 567, 915]}, {"image_id": 12, "file_name": "46_12.png", "page": 9, "dpi": 300, "bbox": [134, 212, 694, 881], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Auckland metro map with labeling.", "caption_bbox": [273, 892, 551, 915]}, {"image_id": 13, "file_name": "46_13.png", "page": 10, "dpi": 300, "bbox": [83, 215, 752, 882], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: London metro map with labeling.", "caption_bbox": [279, 892, 546, 915]}], "460": [{"image_id": 0, "file_name": "460_00.png", "page": 1, "dpi": 300, "bbox": [94, 86, 756, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Examples of hierarchical edge bundling on a hierarchical dataset using different tree layouts. Leaf nodes are in blue. Bundled links are in red. ", "caption_bbox": [106, 371, 744, 396]}, {"image_id": 1, "file_name": "460_01.png", "page": 2, "dpi": 300, "bbox": [442, 710, 777, 919], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: We hypothesize that bundled cross-edges in a parent-centric layout (right) are more discernible than a root-centric layout (left). The hierarchy in this example is the animate subpackage structure within the flare software project. Each blue leaf node represents a source code file. Red links depict how these files refer each other. ", "caption_bbox": [440, 935, 775, 1000]}, {"image_id": 2, "file_name": "460_02.png", "page": 3, "dpi": 300, "bbox": [80, 445, 402, 521], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: We hypothesize that shorter links, with less sharp turns require less effort to understand. Examples of HEB using a circular vs. linear arrangement: in (a) the blue link requires more effort to trace than red link since the eye has to travel further to verify the connection; in (b) the blue link has a sharper turn than red link; in (c) the blue link is not only sharper but also longer than the red link. ", "caption_bbox": [73, 535, 409, 613]}, {"image_id": 3, "file_name": "460_03.png", "page": 3, "dpi": 300, "bbox": [450, 754, 773, 891], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Zooming into a CactusTree to see details about substruc- tures and internal connectivity. ", "caption_bbox": [440, 906, 777, 931]}, {"image_id": 4, "file_name": "460_04.png", "page": 4, "dpi": 300, "bbox": [83, 75, 402, 700], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualizing carnivora hierarchy within the mammal evolution- ary tree: (a) leaf nodes are displayed as images of species within the carnivora hierarchy and red links depict prey-predator relationships; (b) Selecting a leaf node canis lupus (gray wolf) highlights the direct species in its food chain. ", "caption_bbox": [73, 714, 411, 779]}, {"image_id": 5, "file_name": "460_05.png", "page": 4, "dpi": 300, "bbox": [440, 682, 777, 795], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: CactusTree for the mammal hierarchy with different scales factor in computing node size. ", "caption_bbox": [440, 810, 775, 835]}, {"image_id": 6, "file_name": "460_06.png", "page": 4, "dpi": 300, "bbox": [440, 158, 776, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An example of multiple, interconnected trees using Cactus- Trees to represent biological pathways. ", "caption_bbox": [440, 346, 777, 371]}], "461": [{"image_id": 0, "file_name": "461_00.png", "page": 1, "dpi": 300, "bbox": [108, 120, 744, 373], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Analysis of clusters and ambiguous vertices in the football network dataset [8,52]. (a): a typical layout, in which clusters are marked with different colors and ambiguous vertices are labeled with A, B, and C. (b): aggregated feature vectors of the ambiguous vertices B and C, respectively, under measure fk , where k = 10. From the distributions of colors, we can clearly see that vertices B and C have totally different patterns. Vertex B more likely belongs to the purple or green cluster. By contrast, vertex C has no preferred clusters to belong to. (c): four other final layouts for the same dataset induced by different initial layouts. We can see that the behaviors of vertices B and C agree with the patterns found in the aggregated feature vectors. ", "caption_bbox": [106, 379, 742, 457]}, {"image_id": 1, "file_name": "461_01.png", "page": 3, "dpi": 300, "bbox": [73, 589, 409, 682], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a)-(c): Three possible stable layouts of a simple graph (rota- tions, translations, and reflections are ignored) and their appearance counts; (d): Average uncertainty scores for each vertex. ", "caption_bbox": [73, 683, 410, 722]}, {"image_id": 2, "file_name": "461_02.png", "page": 5, "dpi": 300, "bbox": [441, 321, 777, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: GPU acceleration process: (a) layouts are preprocessed and stored in the video memory as feature vectors; (b) users interact with the graphic interface to input two masks; (c) masks are combined with the feature vectors to calculate statistics. ", "caption_bbox": [439, 415, 775, 467]}, {"image_id": 3, "file_name": "461_03.png", "page": 5, "dpi": 300, "bbox": [441, 557, 772, 690], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: General exploration pipeline: (a) selecting a measure (1) to view the representative layout with minimum total uncertainty; (b) brushing on nodes(3) or bars(2) to mark vertices into different groups; (c) selecting one or more groups (4) to examine the corresponding features and clustering result; (d) selecting and enlarging layouts (5) in the clustering result to view more details; (e) collapsing to see the entire layout set. ", "caption_bbox": [439, 702, 776, 793]}, {"image_id": 4, "file_name": "461_04.png", "page": 6, "dpi": 300, "bbox": [443, 372, 772, 600], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Discovery of two organizers. (a): layout that has the min- imum total uncertainty score under measure fd ; (b) and (c): sorted uncertainty scores of individual vertices (trimmed) under measures fd and fe , respectively. Organizers are marked with blue color in (a)-(c). ", "caption_bbox": [440, 602, 778, 655]}, {"image_id": 5, "file_name": "461_05.png", "page": 6, "dpi": 300, "bbox": [102, 334, 385, 381], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Three possible visual encodings of typicality: (a) color, (b) size, and (c) length + angle. ", "caption_bbox": [73, 390, 409, 415]}, {"image_id": 6, "file_name": "461_06.png", "page": 7, "dpi": 300, "bbox": [439, 851, 777, 995], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Four examples of uncommon stable layouts as results of poor initial layouts. ", "caption_bbox": [440, 994, 775, 1019]}, {"image_id": 7, "file_name": "461_07.png", "page": 7, "dpi": 300, "bbox": [77, 650, 407, 868], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Representative layouts of the top six clusters based on  fd features of the colored vertices. The proportion of each cluster is labeled on the corresponding representative. We can see that although these two groups have a clear gap between them, they are always arranged side-by-side. ", "caption_bbox": [73, 872, 409, 937]}, {"image_id": 8, "file_name": "461_08.png", "page": 7, "dpi": 300, "bbox": [443, 76, 773, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Representative layouts of the top six clusters based on fd features of the colored vertices. The proportion of each cluster is labeled on the corresponding representative. We can see that the distance between these two groups are generally random. ", "caption_bbox": [440, 299, 775, 351]}, {"image_id": 9, "file_name": "461_09.png", "page": 8, "dpi": 300, "bbox": [73, 450, 409, 677], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: One typical layout of the co-author dataset. All vertices that have low f\u03bb scores and high fe scores are marked with red color. All vertices that have degrees bigger than ten and have not been marked with red color are marked with blue color. ", "caption_bbox": [73, 678, 409, 730]}, {"image_id": 10, "file_name": "461_10.png", "page": 9, "dpi": 300, "bbox": [74, 75, 776, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Unstable vertices in terms of measure fk , where k = 50. Closed typicality glyphs indicate that the arrangements of vertices in this layout are typical in terms of 50-nearest neighbors of individual vertices. Five groups of outlier vertices with low typicality scores are marked with red, blue, green, brown, and orange colors, respectively. Different stable statuses of the same group are displayed together on top of a common background layout, and their proportions are provided nearby in the figures. The background layout does not connect to the foreground colored vertices. Instead, it only works as a reference map to indicate the locations of the stable layouts of the colored vertices. ", "caption_bbox": [73, 369, 775, 434]}], "462": [{"image_id": 0, "file_name": "462_00.png", "page": 3, "dpi": 300, "bbox": [64, 880, 766, 987], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Flowchart of FFTEB.", "caption_bbox": [348, 996, 499, 1008]}, {"image_id": 1, "file_name": "462_01.png", "page": 4, "dpi": 300, "bbox": [74, 171, 413, 444], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: FFTEB undirected and directional bundling of four datasets.", "caption_bbox": [73, 452, 414, 464]}, {"image_id": 2, "file_name": "462_02.png", "page": 5, "dpi": 300, "bbox": [61, 67, 792, 660], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Bundling of amazon graph [12] for different screen resolutions R and total number of edge sampling points N. Colors map edge density.", "caption_bbox": [73, 679, 775, 691]}, {"image_id": 3, "file_name": "462_03.png", "page": 6, "dpi": 300, "bbox": [78, 65, 768, 991], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparison of undirected FFTEB with several state-of-the-art bundling methods for the US migrations (top) and net50 (bottom) datasets. See Sec. 4.1. ", "caption_bbox": [73, 997, 775, 1021]}, {"image_id": 4, "file_name": "462_04.png", "page": 7, "dpi": 300, "bbox": [80, 68, 768, 482], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison of directional and undirected FFTEB with the corresponding CUBu variants for the France airlines dataset. See Sec. 4.1.", "caption_bbox": [74, 490, 775, 502]}, {"image_id": 5, "file_name": "462_05.png", "page": 8, "dpi": 300, "bbox": [63, 369, 415, 749], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Top: Directional bundling, large US migration graph [37] (600K edges, 63 billion sampling points). Bottom: Bundling of the much smaller migration graph (9780 edges, 290K sampling points). ", "caption_bbox": [73, 768, 414, 804]}, {"image_id": 6, "file_name": "462_06.png", "page": 8, "dpi": 300, "bbox": [73, 66, 777, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Bundling of eye trails for airline pilot training. See Sec. 4.3.", "caption_bbox": [256, 345, 592, 357]}], "463": [{"image_id": 0, "file_name": "463_00.png", "page": 2, "dpi": 300, "bbox": [425, 454, 777, 967], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The particle radius is adjusted using a resizing function to realize different opacities in the particle projection process for the developed system. ", "caption_bbox": [426, 981, 775, 1022]}, {"image_id": 1, "file_name": "463_01.png", "page": 2, "dpi": 300, "bbox": [425, 69, 777, 411], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Particle generation process: particles are generated with values, coordinates and normal information from a uniform sampling ", "caption_bbox": [426, 419, 775, 446]}, {"image_id": 2, "file_name": "463_02.png", "page": 3, "dpi": 300, "bbox": [495, 421, 732, 720], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Rendering result for prism section using different transfer functions (FPS: 8.77, transfer function changing time: 163.9 milliseconds) ", "caption_bbox": [438, 730, 787, 771]}, {"image_id": 3, "file_name": "463_03.png", "page": 3, "dpi": 300, "bbox": [106, 350, 374, 620], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: LOD rendering for time-varying data. Here \u201crepetition\u201d means how many set of generated particles used in the rendering. Generally, more particles will provide a better image quality but lead to a slow rendering (see detail in [1]). ", "caption_bbox": [73, 634, 423, 689]}, {"image_id": 4, "file_name": "463_04.png", "page": 4, "dpi": 300, "bbox": [49, 949, 777, 1094], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Animation rendering for the sphere section: upper two figures rendering produces a high-speed animation rendering. A high-quality show the 85th time step with a repetition of 20 (animation rendering)                                                                         image is also provided when we stop the animation at any time step of and 81 (animation stopped); lower two figures show the 123th time step                                                                         interest. The measured results and user feedback for the application of ", "caption_bbox": [61, 903, 775, 950]}, {"image_id": 5, "file_name": "463_05.png", "page": 4, "dpi": 300, "bbox": [60, 494, 413, 894], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1 Quantitative evaluation of particle-based rendering", "caption_bbox": [455, 370, 745, 383]}], "464": [{"image_id": 0, "file_name": "464_00.png", "page": 2, "dpi": 300, "bbox": [84, 74, 397, 411], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Comparing similarity map and representative isosurfaces generated using actual isosurfaces ((a) and (b)) against our approx- imation ((c) and (d)) with the CT data set. The isosurfaces are col- ored in the descending order of their importance: red, green, blue. The number in the brackets indicates the index of sampled isovalue. The marching cubes algorithm is used to extract the actual surfaces shown in (b) and (d) for given representative values. ", "caption_bbox": [73, 413, 408, 509]}, {"image_id": 1, "file_name": "464_01.png", "page": 4, "dpi": 300, "bbox": [84, 488, 393, 747], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Average traversal time for different numbers of sample points. We sampled from 0 to 3500 points with a step size of 50. ", "caption_bbox": [73, 750, 408, 777]}, {"image_id": 2, "file_name": "464_02.png", "page": 4, "dpi": 300, "bbox": [79, 89, 772, 409], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Rendering of the most important isosurfaces (a) to (d), with their corresponding similarity maps (e) to (h). The first and second columns show mixture fraction and vorticity of the combustion data set, respectively. The third column shows water vapor ratio of the hurricane data set, and the fourth column depicts GT of the ionization data set. ", "caption_bbox": [73, 411, 775, 452]}], "466": [{"image_id": 0, "file_name": "466_00.png", "page": 1, "dpi": 300, "bbox": [105, 144, 733, 448], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Our value-based spatial distribution representation includes spatial information (called a Spatial GMM) that is compact, which is lacking in current distribution based representations. We illustrate our approach with volume rendering of the probability field for the location of an isosurface of the Isabel dataset (500x500x100). Figures (a) and (f) show the ground truth isosurface rendering using +90Pa and -900 Pa, respectively. Using a hot to cold transfer function, where red indicates a high probability for the isosurface and blue indicates a low probability, the rest of the columns show volume renderings of our approach (the last column) compared with current approaches. Equipped with added spatial information, our representation is able to better identify with higher certainty the location of the isosurface including small details, which are missed in the other representations. The block sizes used to compute the renderings in the last four columns are 123 , 123 , 63 and 163 , respectively. In our approach, the value histogram costs 3.5MB and the Spatial GMM costs 3.26MB. ", "caption_bbox": [106, 463, 744, 587]}, {"image_id": 1, "file_name": "466_01.png", "page": 2, "dpi": 300, "bbox": [440, 465, 780, 708], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of our approach. In a pre-processing step (shown on the left), the dataset is subdivided into blocks and both a value distribution and spatial distributions (Spatial GMMs) are computed for each block. To estimate a value at a given location, Bayes\u2019 rule is used to integrate the value and spatial distributions to obtain the probability density function of values at this location (shown on the right). ", "caption_bbox": [440, 718, 775, 814]}, {"image_id": 2, "file_name": "466_02.png", "page": 3, "dpi": 300, "bbox": [73, 426, 413, 625], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: This diagram shows the steps used to compute the spatial GMM for a raw data block (shown in blue). Besides the computa- tion of the value distribution, the raw data in the block is used to construct the Spatial GMM. First, the locations of the data samples are collected into the corresponding bin interval according to the data value at that location (shown in the bottom left). Then, a Spatial GMM is constructed (shown on the right) for each bin interval using the locations in the interval (illustrated here for Bin0 ). ", "caption_bbox": [73, 636, 410, 748]}, {"image_id": 3, "file_name": "466_03.png", "page": 4, "dpi": 300, "bbox": [439, 78, 780, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Data structure for our data representation using Spatial GMMs. Each block is indexed with a table of the starting locations of each block (shown at the top). Each block (shown in blue) stores bins (bin b0 is shown in orange for Block0 ). Each bin stores K Gaussians of the GMM for the bin. The data structure of a Gaussian component is shown in red. ", "caption_bbox": [440, 314, 775, 396]}, {"image_id": 4, "file_name": "466_04.png", "page": 5, "dpi": 300, "bbox": [74, 74, 413, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: This flow chart shows the steps to compute the PDF consisting of probabilities associated with possible data values at a given a location `. The input of this algorithm is a 3D location `. ", "caption_bbox": [73, 288, 409, 329]}, {"image_id": 5, "file_name": "466_05.png", "page": 6, "dpi": 300, "bbox": [85, 299, 753, 439], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparison of RMSE when block histogram with our spatial GMM and without our spatial GMM are used under different block sizes. ", "caption_bbox": [73, 453, 775, 480]}, {"image_id": 6, "file_name": "466_06.png", "page": 6, "dpi": 300, "bbox": [88, 75, 754, 214], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The trade off between accuracy (RMSE) and storage cost when comparing our spatial GMM approach using different block sizes and current approaches. Block sizes from left to right for (a),(b) and (c) are 643 , 323 , 163 and 83 . Block sizes from left to right for (d) are 1283 , 643 , 323 and 163 . The bottom three curves show this trade off using our approach with upper bounds of 1, 3 and 5 on the number of Gaussian components. ", "caption_bbox": [73, 228, 777, 283]}, {"image_id": 7, "file_name": "466_07.png", "page": 7, "dpi": 300, "bbox": [91, 285, 760, 432], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Visual comparison of volume rendering in Pressure variable of Isabel dataset. The samples are drawn from the PDFs, which are calculated at all grid points of the raw data, using Monte Carlo sampling. The block size of (b),(c),(d) and (e) are 123 , 123 , 63 and 163 , respectively. In (e), the value histogram costs 3.5MB and the Spatial GMM costs 3.26MB. ", "caption_bbox": [73, 445, 777, 486]}, {"image_id": 8, "file_name": "466_08.png", "page": 7, "dpi": 300, "bbox": [88, 75, 753, 214], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison of varying and fixed number of Gaussian components schemes. The curves with same color use the same local block size. The solid and dotted lines indicate the representations generated from the varying and fixed number of Gaussian components schemes respectively. ", "caption_bbox": [73, 228, 775, 269]}, {"image_id": 9, "file_name": "466_09.png", "page": 8, "dpi": 300, "bbox": [84, 272, 766, 435], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Visual comparison of volume rendering in Plume dataset. The thumbnail at right upper of (a) is the global view of Plume. We zoom in to the red box region in this visual comparison. We zoom in and render part of the dataset. The samples are drawn from the PDFs, which are calculated at all grid points of the raw data, using Monte Carlo sampling. The block size of (b),(c),(d) and (e) are 133 , 133 , 63 and 163 , respectively. In (e), the value histogram costs 64MB and the Spatial GMM costs 39.17MB. ", "caption_bbox": [73, 448, 777, 503]}, {"image_id": 10, "file_name": "466_10.png", "page": 8, "dpi": 300, "bbox": [87, 74, 766, 203], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Visual comparison of volume rendering in combustion dataset. The samples are drawn from the PDFs, which are calculated at all grid points of the raw data, using Monte Carlo sampling. The block size of (b),(c),(d) and (e) are 103 , 103 , 53 and 163 , respectively. In (e), the value histogram costs 5.27MB and the Spatial GMM costs 15.36MB. ", "caption_bbox": [73, 216, 775, 257]}, {"image_id": 11, "file_name": "466_11.png", "page": 9, "dpi": 300, "bbox": [94, 315, 766, 432], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Uncertain isosurface (isovalue = 0.15) visualization of the Combustion dataset. (a) is the true isosurface from the raw data. The sizes of the distribution-based representations were similar in the results shown in (b),(c),(d), and (e). The color orange indicates locations with higher possibility for the location of the isosurface. The color blue indicates locations with less possibility for the isosurface. The settings used here are the same as used for the results in Figure 10. ", "caption_bbox": [73, 446, 775, 501]}, {"image_id": 12, "file_name": "466_12.png", "page": 9, "dpi": 300, "bbox": [84, 78, 766, 245], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Visual comparison of volume rendering in Turbine dataset. The samples are drawn from the PDFs, which are calculated at all grid points of the raw data, using Monte Carlo sampling. The block size of (b),(c),(d) and (e) are 223 , 223 , 103 and 323 , respectively. In (e), the value histogram costs 43.75MB and the Spatial GMM costs 107.79MB. ", "caption_bbox": [73, 258, 775, 299]}, {"image_id": 13, "file_name": "466_13.png", "page": 10, "dpi": 300, "bbox": [84, 73, 766, 218], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Images of the distribution similarity field. (a) is the similarity field from the raw data. (b)(c)(d) and (e) are the similarity field from other distribution representation with similar storage size. Red color indicates high similarity. Blue color indicates low similarity. The data representations here are the setting in Figure 10. ", "caption_bbox": [73, 231, 775, 272]}], "467": [{"image_id": 0, "file_name": "467_00.png", "page": 1, "dpi": 300, "bbox": [107, 144, 743, 632], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An illustration of our range likelihood tree guided exploration framework using the Massachusetts Bay Sea Trial Ensemble dataset. Starting from the initial range likelihood tree view (1), users can hover on different nodes in the tree to see their corresponding subranges (2), and examine the likelihoods of associated grid points in the range likelihood field view (3); after selecting a few subranges of interest, a multi-field transfer function widget (4) is created, which can be manipulated by the user to explore and classify grid points based on their likelihoods in different subranges in the multi-field classification view (5). ", "caption_bbox": [106, 647, 743, 715]}, {"image_id": 1, "file_name": "467_01.png", "page": 2, "dpi": 300, "bbox": [470, 123, 765, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visual analysis of probability distribution fields using conventional techniques. (a) Visualizing a distance field constructed from a 2D probability distribution field; regions associated with two distinct distributions can not be readily distinguished from their distances to the target. (b) Visualizing a low-dimensional embedding of a 3D probability distribution field using principal component analysis (PCA); no clear separation of clusters can be found. ", "caption_bbox": [440, 265, 776, 361]}, {"image_id": 2, "file_name": "467_02.png", "page": 3, "dpi": 300, "bbox": [89, 585, 394, 850], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Overview of the analytical workflow.", "caption_bbox": [123, 861, 359, 874]}, {"image_id": 3, "file_name": "467_03.png", "page": 3, "dpi": 300, "bbox": [454, 524, 752, 616], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Three probability distributions from different spatial lo- cations in an uncertain scalar field. They are summarized by two subranges (in two distinct colors) with the probabilities that each distribution falls within the subranges as [0.7, 0.3], [0.5, 0.5], and [0.3, 0.7], respectively. ", "caption_bbox": [440, 631, 777, 699]}, {"image_id": 4, "file_name": "467_04.png", "page": 4, "dpi": 300, "bbox": [489, 73, 728, 148], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An illustration of three range likelihood fields (RLFs), highlighting grid points with non-zero likelihoods. Based on spatial locality of grid points, RLF-a is similar to RLF-b, while RLF-c is different from RLF-a and RLF-b. ", "caption_bbox": [440, 159, 777, 214]}, {"image_id": 5, "file_name": "467_05.png", "page": 4, "dpi": 300, "bbox": [73, 77, 412, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Transforming distribution into range likelihoods. (a) Visualization of scalar fields sampled from a 2D distribution field. (b) Visualization of range likelihood fields (RLFs) transformed from the distribution field. ", "caption_bbox": [73, 305, 411, 360]}, {"image_id": 6, "file_name": "467_06.png", "page": 5, "dpi": 300, "bbox": [489, 283, 728, 366], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visualizing distributions of the material ensemble dataset using superimposed curves (top) and curve density estimation (bot- tom). ", "caption_bbox": [440, 376, 777, 417]}, {"image_id": 7, "file_name": "467_07.png", "page": 5, "dpi": 300, "bbox": [522, 73, 694, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The composite radial visualization of a range likelihood tree with distribution density map. ", "caption_bbox": [440, 241, 775, 268]}, {"image_id": 8, "file_name": "467_08.png", "page": 6, "dpi": 300, "bbox": [465, 748, 752, 960], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Exploring ranges at different levels in the RLT of the Massachusetts Bay Sea Trial Ensemble dataset. ", "caption_bbox": [440, 972, 775, 999]}, {"image_id": 9, "file_name": "467_09.png", "page": 6, "dpi": 300, "bbox": [139, 287, 344, 412], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Multi-field transfer function widget using parallel coordi- nates axes (top) and flexible coordinates axes (bottom). ", "caption_bbox": [73, 422, 410, 449]}, {"image_id": 10, "file_name": "467_10.png", "page": 7, "dpi": 300, "bbox": [127, 74, 723, 442], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Experiments on the Temporally Down-Sampled Hurricane Isabel dataset. See Section 6.2 for details about the exploration process.", "caption_bbox": [73, 454, 775, 467]}, {"image_id": 11, "file_name": "467_11.png", "page": 8, "dpi": 300, "bbox": [127, 77, 724, 690], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Experiments on the Ensemble HRRR Simulation dataset. See Section 6.3 for details about the exploration process.", "caption_bbox": [110, 704, 739, 717]}, {"image_id": 12, "file_name": "467_12.png", "page": 9, "dpi": 300, "bbox": [125, 73, 725, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Average runtime (in seconds) for the clustering algorithm.", "caption_bbox": [439, 382, 774, 395]}], "468": [{"image_id": 0, "file_name": "468_00.png", "page": 2, "dpi": 300, "bbox": [484, 73, 732, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The layout of our system interface.", "caption_bbox": [496, 218, 714, 230]}, {"image_id": 1, "file_name": "468_01.png", "page": 3, "dpi": 300, "bbox": [473, 74, 744, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The pipeline of our system.", "caption_bbox": [514, 232, 696, 244]}, {"image_id": 2, "file_name": "468_02.png", "page": 4, "dpi": 300, "bbox": [101, 79, 382, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) and (c) shows the density estimation results when only size weight is considered and the volume regions corresponding to the dense regions are shown in (b) and (d) respectively. The dense region corresponds to the unimportant background region in this dataset. (e) and (g) shows the density estimation results when both size weight and scatter weight are considered and the volume regions corresponding to the dense regions are shown in (f) and (h). More interesting regions are identified. ", "caption_bbox": [73, 283, 409, 387]}, {"image_id": 3, "file_name": "468_03.png", "page": 5, "dpi": 300, "bbox": [143, 74, 707, 151], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The middle six images show the density estimation results of the Temperature and Pressure subspace with different blending coefficients \u03b1 after filtering out data points with scatter weights larger than a user-defined threshold. When the value of \u03b1 is small such as 0.0 and 0.2, the influence of size weight on the density estimation result is small, so dense regions corresponding to some small size clusters can be identified. In this example, a dense region corresponding to the Hurricane center can be easily identified with a small value of \u03b1. When the value of \u03b1 is large, the influence of size weight on the density estimation result is large. In this example, a dense region corresponding to a large size cluster shows up as the value of \u03b1 increases. ", "caption_bbox": [73, 170, 777, 248]}, {"image_id": 4, "file_name": "468_04.png", "page": 5, "dpi": 300, "bbox": [89, 274, 394, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Basic steps of our bottom-up subspace exploration.", "caption_bbox": [90, 384, 391, 396]}, {"image_id": 5, "file_name": "468_05.png", "page": 6, "dpi": 300, "bbox": [88, 79, 396, 171], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Bottom-up dense region refinement. We start with an empty Gaussian component g={}. Initially we select the subspace of Temperature and Velocity. (a). The density estimation of the data points in the subspace of Temperature and Velocity. The dense region within the white cycle is selected. (b). The volume rendering highlights the selected region. The Gaussian component is also updated. Temperature and Velocity are added to g. Then, data points are filtered if they are not covered by g. A new set of data points are generated and the subspace matrix is updated. (c). The user selects the Pressure and QVapor subspace in the updated subspace matrix. Now, the current subspace is defined by Temperature, Pressure, QVapor and Velocity. The user explores the subspace by filtering out data points with scatter weights larger than a user-defined threshold and then performs density estimation. The region within the white cycle is selected by the user. (d). The volume rendering highlights the selected region. Pressure and QVapor are added to g and g is extended to a 4 dimensional Gaussian component. ", "caption_bbox": [73, 190, 411, 413]}, {"image_id": 6, "file_name": "468_06.png", "page": 7, "dpi": 300, "bbox": [167, 73, 682, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Experiments on the Hurricane Isabel dataset. Details about the exploration process are discussed in Section 6.1.", "caption_bbox": [123, 346, 724, 358]}, {"image_id": 7, "file_name": "468_07.png", "page": 8, "dpi": 300, "bbox": [447, 418, 769, 644], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Experiments on the Ionization Front Instability dataset. Details about the exploration process are discussed in Section 6.3 ", "caption_bbox": [440, 663, 778, 688]}, {"image_id": 8, "file_name": "468_08.png", "page": 8, "dpi": 300, "bbox": [178, 74, 672, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Experiments on the Turbulent Combustion dataset. Details about the exploration process are discussed in Section 6.2.", "caption_bbox": [110, 381, 738, 393]}, {"image_id": 9, "file_name": "468_09.png", "page": 9, "dpi": 300, "bbox": [494, 79, 722, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Weighted KDE results of the Temperature and velocity subspace of Isabel data set under different number of bins. ", "caption_bbox": [440, 242, 776, 267]}], "469": [{"image_id": 0, "file_name": "469_00.png", "page": 1, "dpi": 300, "bbox": [143, 150, 712, 572], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Interface of SwiftTuna. An analyst is exploring a multidimensional dataset with 100 million entities. Visualization cards (two expanded cards and six thumbnail cards) on the right side provide a univariate summary on a single dimension or visualize the relationship between two dimensions. The analyst expanded two visualization cards to further interact with them. The card list panel on the left side shows the list of all visualization cards as well as the progress of each card. ", "caption_bbox": [75, 576, 773, 635]}, {"image_id": 1, "file_name": "469_01.png", "page": 2, "dpi": 300, "bbox": [470, 73, 760, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Classification of SwiftTuna and relevant previous work according to their computation schemes, the maximum data size tested for evaluation, and system types. SwiftTuna does not prebuild a specific data structure but incrementally processes data online. example, imMens [23] supports real-time visual querying (R2) and ", "caption_bbox": [440, 306, 776, 389]}, {"image_id": 2, "file_name": "469_02.png", "page": 4, "dpi": 300, "bbox": [131, 74, 363, 257], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Visualization Methods According to Query Types", "caption_bbox": [282, 883, 567, 900]}, {"image_id": 3, "file_name": "469_03.png", "page": 5, "dpi": 300, "bbox": [86, 75, 777, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Tailed charts and dot plots. Inspired by gradient plots [8], we adopt gradients to visualize confidence intervals. (a) Tailed gradient plots prioritize prominent categories (e.g., the most frequent five categories) by visualizing them in half of the visual space, while the rest of the categories are outlined in another half of the space with a line (i.e., a tail). Gradients show the 95% confidence intervals of estimated values. (b) When all data are processed, the gradients eventually converge, and tailed dot plots replace tailed gradient plots. (c) Gradient plots. (d) Dot plots. When the number of categories on the x-axis is small (i.e., equal to or fewer than eight), we use previous gradient plots and dot plots instead of tailed versions of them. ", "caption_bbox": [73, 235, 775, 322]}, {"image_id": 4, "file_name": "469_04.png", "page": 5, "dpi": 300, "bbox": [118, 689, 736, 922], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Expanded visualization cards. Users can switch a visualization card from a thumbnail mode to an expanded mode by clicking on the checkbox on the top right corner. Expanded visualization cards provide two coordinated views, a focus view and a context view, as well as visualization-specific features such as using a log scale instead of a linear one or using a bivariate color scheme. (a) An expanded gradient plot (expanded from Figure 4c). (b) An expanded tailed gradient plot. (c) An expanded density plot. Density plots do not provide the context view for brushing, but users can directly brush on the focus view. ", "caption_bbox": [72, 925, 776, 998]}, {"image_id": 5, "file_name": "469_05.png", "page": 6, "dpi": 300, "bbox": [460, 73, 758, 374], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Card list panel. (a) The card list shows the list of visualization cards. Initially, cards for every single dimension are provided. (b) The progress list illustrates the progress of each card with a progress bar. Users can stop or resume processing the query of a card by clicking on stop and play icons, respectively. (c) Users can prioritize queries with two options: block order and list order. We elaborate on scheduling in Section 4.1. (d) Each time users brush on a visualization, a filter that represents the brushed area is added to the filter list. Users can click on a funnel icon to activate the filter. (e) Users can create a new card for two dimensions (e.g., for a density plots between two numerical dimensions) by clicking on a plus icon at the bottom of the card list. ", "caption_bbox": [438, 373, 774, 543]}, {"image_id": 6, "file_name": "469_06.png", "page": 7, "dpi": 300, "bbox": [106, 73, 381, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Massive parallel processing in SwiftTuna. SwiftTuna separates raw data to n blocks (i.e., B0 to Bn-1), and processes each block online in a parallel and distributed manner. The client aggregates each partial result and visualizes the aggregated result to users. Note that the actual processing order of blocks is randomized to alleviate a possible bias in the raw data. ", "caption_bbox": [73, 258, 408, 345]}], "47": [{"image_id": 0, "file_name": "47_00.png", "page": 3, "dpi": 300, "bbox": [427, 54, 757, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Macroscopic quantities of the Minority Game (Challet 2003) ", "caption_bbox": [427, 297, 749, 325]}, {"image_id": 1, "file_name": "47_01.png", "page": 3, "dpi": 300, "bbox": [427, 613, 757, 820], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Microscopic quantities of the Minority Game (Challet 2003) ", "caption_bbox": [427, 831, 749, 859]}, {"image_id": 2, "file_name": "47_02.png", "page": 4, "dpi": 300, "bbox": [427, 54, 757, 346], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visualisation of the Minority Game using a Spring Graph ", "caption_bbox": [427, 357, 749, 385]}, {"image_id": 3, "file_name": "47_03.png", "page": 5, "dpi": 300, "bbox": [427, 446, 757, 820], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Minority Game mod screenshot again showing the standard Unreal Tournament 2003 team scoreboard GUI overlay. Note that the computer- controlled player \u201cStargazer\u201d has swapped teams, thus making their original team the minority. ", "caption_bbox": [427, 831, 749, 901]}, {"image_id": 4, "file_name": "47_04.png", "page": 5, "dpi": 300, "bbox": [82, 152, 412, 457], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Minority Game mod screenshot showing the standard Unreal Tournament 2003 team scoreboard GUI overlay. Teams start with an equal number of players as the scoreboard indicates, and neither team is the minority. ", "caption_bbox": [83, 468, 405, 538]}, {"image_id": 5, "file_name": "47_05.png", "page": 5, "dpi": 300, "bbox": [427, 54, 757, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Minority Game mod screenshot showing our custom \u201cChoose a team\u201d GUI overlay that allows human players to change their team once their avatar has been killed. ", "caption_bbox": [427, 369, 749, 425]}], "470": [{"image_id": 0, "file_name": "470_00.png", "page": 2, "dpi": 300, "bbox": [501, 74, 716, 173], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An example of local deposit procedure with setting neigh- borhood size to 3 \u00d7 3. (a) The blue points are the active voxels for a bin. The number label on each voxel represents the accumulated deposit counts after performing local deposit. Voxels without num- bers mean that the count is zero. (b) The distance of bink between the target histogram with frequency 3 and the local histogram is performed only at the voxels in the search region (red circles). ", "caption_bbox": [440, 183, 777, 279]}, {"image_id": 1, "file_name": "470_01.png", "page": 3, "dpi": 300, "bbox": [440, 74, 777, 174], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The flow chart of our feature search algorithm.", "caption_bbox": [465, 185, 749, 198]}, {"image_id": 2, "file_name": "470_02.png", "page": 4, "dpi": 300, "bbox": [439, 74, 776, 150], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: An example of group selection for MBC algorithm. All grids represent the 2D joint histogram of a target feature. The num- ber in each cell is the value frequency for that bin. Bins of the same color have been grouped together. The left figure shows the joint histogram before grouping. The middle figure represents grouping bins by target frequency. The right figure represents separating the red group into two groups by bin indices. ", "caption_bbox": [440, 162, 777, 258]}, {"image_id": 3, "file_name": "470_03.png", "page": 5, "dpi": 300, "bbox": [107, 74, 368, 211], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) An example of stratified sampling within a cubical region. The sampling percentage is 50% in this case. (b) The distribution of errors between approximate results and ground truth for the Isabel dataset. The black one is the case of stratified sampling and the red one is the case of random sampling. ", "caption_bbox": [73, 222, 408, 290]}, {"image_id": 4, "file_name": "470_04.png", "page": 6, "dpi": 300, "bbox": [458, 73, 759, 177], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The performance speedup gained by our MBC approach compared to Wei et al.\u2019s [32]. (a) The individual performance speed- up for all test cases, where the x-axis is the number of bins reduced by MBC. (b) Grouping the test cases by data set and by the number of fields searched, showing the average performance gain. ", "caption_bbox": [440, 188, 777, 256]}, {"image_id": 5, "file_name": "470_05.png", "page": 6, "dpi": 300, "bbox": [78, 210, 406, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: The numbers of search results for MBC.", "caption_bbox": [484, 266, 731, 279]}, {"image_id": 6, "file_name": "470_06.png", "page": 7, "dpi": 300, "bbox": [89, 74, 395, 151], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The performance comparisons with previous work. Blue bars: Sizintsev et al.. Green bars: Wei et al.. Red bars: our merged- bin-comparison method. Notice that the logarithmic scale is used in the y-axes. If computation took more than a day, it is shown as 105 seconds on this chart. ", "caption_bbox": [73, 162, 410, 230]}, {"image_id": 7, "file_name": "470_07.png", "page": 7, "dpi": 300, "bbox": [100, 436, 381, 532], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The performance comparison of SAV. (a) The comparison between two cases with using different neighborhood sizes. (b) The performance speedup versus accuracy of results. ", "caption_bbox": [73, 543, 408, 584]}, {"image_id": 8, "file_name": "470_08.png", "page": 7, "dpi": 300, "bbox": [455, 74, 760, 151], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The computation time comparisons for joint feature searches with neighborhood size 313 . Dark blue bar: Sizintsev et al.. Light blue bar: Wei et al.. Yellow bar: MBC. Red bar: SAV. Notice the logarithmic scale on the y-axes. ", "caption_bbox": [440, 162, 778, 217]}, {"image_id": 9, "file_name": "470_09.png", "page": 7, "dpi": 300, "bbox": [468, 234, 749, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The computation time spent in different phases of the MBC and SAV approach, grouped by number of fields in the test. The three bars per group represent the Isabel, Combustion and Plume data sets (from left to right), respectively. ", "caption_bbox": [439, 344, 777, 399]}, {"image_id": 10, "file_name": "470_10.png", "page": 7, "dpi": 300, "bbox": [100, 238, 384, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The performance speedup gained by our SAV method using 20% sampling, compared to Wei et al.\u2019s work [32] for joint feature search. (a) All test cases where the x-axis is the percentage of total data points of the corresponding dataset. Notice the logarithmic scale for the x-axis. (b) Grouping the test cases in (a) by data set and the number of fields, showing the average performance. ", "caption_bbox": [73, 346, 408, 428]}, {"image_id": 11, "file_name": "470_11.png", "page": 8, "dpi": 300, "bbox": [73, 75, 778, 181], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 5: The run-time memory usage for the Plume dataset.", "caption_bbox": [458, 339, 757, 352]}, {"image_id": 12, "file_name": "470_12.png", "page": 9, "dpi": 300, "bbox": [78, 74, 406, 142], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Case study of the Ionization dataset. (a) Search result with the joint distribution of H2 , H2+ and H \u2212 variables. (b) Volume rendering for the magnitude of the curl of the velocity field. Red color represents where the magnitude value is greater than 3500; grey color represents where the magnitude value is less than 3500. ", "caption_bbox": [73, 153, 410, 221]}], "471": [{"image_id": 0, "file_name": "471_00.png", "page": 2, "dpi": 300, "bbox": [440, 74, 777, 249], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A schematic diagram of our proposed method.", "caption_bbox": [496, 260, 719, 271]}, {"image_id": 1, "file_name": "471_01.png", "page": 3, "dpi": 300, "bbox": [95, 73, 390, 206], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Different types of data partitioning schemes.", "caption_bbox": [133, 219, 348, 230]}, {"image_id": 2, "file_name": "471_02.png", "page": 6, "dpi": 300, "bbox": [93, 78, 758, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Distribution data driven probabilistic feature search in Tornado data set.", "caption_bbox": [264, 252, 585, 263]}, {"image_id": 3, "file_name": "471_03.png", "page": 7, "dpi": 300, "bbox": [83, 280, 767, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Distribution data driven probabilistic feature search in Hurricane Isabel data set.", "caption_bbox": [248, 423, 601, 434]}, {"image_id": 4, "file_name": "471_04.png", "page": 7, "dpi": 300, "bbox": [93, 84, 758, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Distribution data driven probabilistic feature search in Vortex data set.", "caption_bbox": [267, 253, 581, 264]}, {"image_id": 5, "file_name": "471_05.png", "page": 8, "dpi": 300, "bbox": [75, 74, 776, 221], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Visual comparison of U-velocity of Hurricane Isabel data. The reconstructed fields are generated using Monte Carlo sampling of distribution-based summarized data.", "caption_bbox": [82, 234, 766, 245]}, {"image_id": 6, "file_name": "471_06.png", "page": 9, "dpi": 300, "bbox": [75, 76, 775, 235], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Figures 9a-9d: visual comparison of Pressure field of Turbine data set. The reconstructed fields are generated using Monte Carlo sampling of summarized data. Figure 9e: storage vs quality comparison of turbine data set. It is observed that, with similar storage, proposed method produces more accurate visual quality. ", "caption_bbox": [73, 248, 776, 271]}], "472": [{"image_id": 0, "file_name": "472_00.png", "page": 1, "dpi": 300, "bbox": [454, 830, 759, 949], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An example tracking graph showing the evolution of features across time. Within the graph, each set of nodes in a vertical column represents features in one time step and shows the \u201ctracks\u201d of each feature as it evolves: splitting, merging, or disappearing. ", "caption_bbox": [440, 952, 778, 1007]}, {"image_id": 1, "file_name": "472_01.png", "page": 2, "dpi": 300, "bbox": [75, 165, 410, 535], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Our framework contains three views, using data from case study III. (a) Shows the data embedding of features using two sub- components: geometric embedding (left) and geospatial view (right). The geospatial view displays geographical information of features as well as various ancillary data such as radar and wind observations whereas the geometric embedding view displays the geometric infor- mation of the embedded features. (b) Visualizes the horizontal graph layout of the feature hierarchy along with a histogram-based view that summarizes the stability of features. Here, a zoomed-in view of the feature hierarchy (red box top) and histogram (red box bottom) is also displayed. Finally, (c) Shows the evolution of features using a tracking graph for a user-selected focused time step (indicated with a black arrow) and a time window. ", "caption_bbox": [73, 539, 411, 718]}, {"image_id": 2, "file_name": "472_02.png", "page": 4, "dpi": 300, "bbox": [125, 140, 355, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A set of seismic stations are deployed as a part of the National Science Foundation sponsored EarthScope USArray TA project [19, 27]. Here, the seismic station locations from January 1, 2010 to February 29, 2016 are displayed. For each station, the marker colors denote the first (top) and last (bottom) date of its pressure observations. Figure is adapted from [11]. ", "caption_bbox": [72, 370, 409, 452]}, {"image_id": 3, "file_name": "472_03.png", "page": 5, "dpi": 300, "bbox": [455, 580, 758, 837], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Case study I - Data : USArray mesoscale-filtered pressure- perturbations (hPa) are overlaid on composite radar reflectivity at 0000, 0300, 0800, and 1500 UTC August 12, 2011. Here, red circles indicate positive-pressure-perturbations and blue the negative- pressure-perturbations. The composite radar imagery is provided by the Iowa Environmental Mesonet web services. ", "caption_bbox": [440, 841, 777, 923]}, {"image_id": 4, "file_name": "472_04.png", "page": 6, "dpi": 300, "bbox": [90, 350, 760, 640], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Case study I - Visualization : (a) A tracking graph at +1.0 hPa showing the sudden disappearance and reappearance of a feature with a bow-like structure (in yellow). Here, this feature disappears at t = 165 and then reappears at t = 170. Exploring the feature hierarchies reveals that this is likely due to variations in pressure-perturbation in-between time steps. (b) Therefore, by locally modifying the feature threshold values for those time steps (from t = 165 to t = 170), a much simpler graph where this feature is stably evolving can be obtained. In both cases, features at several time steps are visualized. ", "caption_bbox": [73, 645, 775, 714]}, {"image_id": 5, "file_name": "472_05.png", "page": 6, "dpi": 300, "bbox": [90, 87, 760, 197], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Case study I - Visualization : Effects of varying the pressure-perturbation threshold to explore the entire feature space. Here, pressure-perturbation events and a portion of their corresponding tracking graphs are shown at (a) +0.75 hPa, (b) +1.0 hPa, and (c) +1.25 hPa thresholds. In each case, the focused time step of the tracking graph is indicated with a black arrow. ", "caption_bbox": [73, 202, 777, 243]}, {"image_id": 6, "file_name": "472_06.png", "page": 6, "dpi": 300, "bbox": [88, 251, 758, 312], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Case study I - Visualization : A longer tracking graph showing the evolution of pressure-perturbation events at +1.0 hPa. Here, the evolution of a feature with a bow-like structure is highlighted in red. ", "caption_bbox": [73, 315, 775, 342]}, {"image_id": 7, "file_name": "472_07.png", "page": 7, "dpi": 300, "bbox": [455, 73, 758, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Case study II - Data : USArray mesoscale-filtered pressure- perturbations (hPa) are overlaid on composite radar reflectivity for 0300, 0600, 0900, and 1200 UTC June 18, 2011. ", "caption_bbox": [440, 334, 777, 375]}, {"image_id": 8, "file_name": "472_08.png", "page": 7, "dpi": 300, "bbox": [79, 73, 401, 184], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Case study I - Visualization : For the same tracking graph as in Figure 7b, the horizontal graph layout of the feature hierarchy (top) and the histogram sub-view (bottom) at t = 168, as shown within the feature hierarchy view. For this particular time step, the feature hierarchy is a forest with a pressure-perturbation range +0.9 - +1.1 hPa (increasing from left-to-right). Here, the histogram contains 3000 bins. The localized, per-feature thresholds are obtained by creating an arbitrary cut (indicated by the black vertical curve) within a user-defined threshold range (indicated by the red square). ", "caption_bbox": [73, 187, 409, 325]}, {"image_id": 9, "file_name": "472_09.png", "page": 8, "dpi": 300, "bbox": [90, 74, 760, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Case study II - Visualization : (a) A tracking graph showing the evolution of pressure-perturbation events for 113 time steps at +1.0 hPa. Here, one of the thunderstorm complexes (in green) is not consistent across time. This feature disappears at t = 136 and then reappears and dies at t = 138. Again, it reappears at t = 140 and later at t = 146. (b) The resulting tracking graph after adaptive feature thresholding is used to locally modify the features (in green) to allow continuous feature tracking. ", "caption_bbox": [73, 314, 775, 369]}, {"image_id": 10, "file_name": "472_10.png", "page": 8, "dpi": 300, "bbox": [129, 593, 351, 747], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Case study II - Visualization : Both positive- (outlined in solid black line) and negative- (outlined in dashed black line) pressure-perturbation events are visualized alongside their radar im- agery and wind observations (in black arrows). Here, the size and direction of winds are indicated by the arrow length and orienta- tion. The image shows a strong coupling of positive- and negative- pressure-perturbation events. Such events are also collocated with strong winds going from the high- to low-pressure regions. ", "caption_bbox": [73, 749, 410, 859]}, {"image_id": 11, "file_name": "472_11.png", "page": 8, "dpi": 300, "bbox": [88, 377, 758, 531], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Case study II - Visualization : Simultaneously exploring both positive- and negative-pressure-perturbation events for multiple time steps. The graph on top shows the tracking graph at +1.0 hPa and the bottom at -1.0 hPa. Here, positive- (outlined in solid black line) and negative- (outlined in dashed black line) pressure-perturbation events existing at t = 86, 100, 120, and 150 time steps are also visualized. ", "caption_bbox": [73, 534, 775, 575]}, {"image_id": 12, "file_name": "472_12.png", "page": 9, "dpi": 300, "bbox": [81, 396, 403, 753], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Case study III - Visualization : (a) Tracking graph con- structed from the original data set. (b) Tracking graph after filtering the graph in (a) by total propagation distance of a feature (\u226510). (c) For the same focused time window, its equivalent tracking graph for the better preprocessed data set. In each graph, the focused time step is indicated with a black arrow, and the features at the focused time step are visualized along each graph. ", "caption_bbox": [73, 758, 410, 854]}, {"image_id": 13, "file_name": "472_13.png", "page": 9, "dpi": 300, "bbox": [450, 86, 766, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Case study III - Visualization : Features existing at +1.0 hPa for the same time step (at t = 326) in both (a) the original data set and (b) the cleaner, better preprocessed data set are visualized alongside their radar imagery. As indicated in the images, the pre- processed data set (b) contains less noise than the original data set (a). ", "caption_bbox": [439, 247, 777, 329]}, {"image_id": 14, "file_name": "472_14.png", "page": 9, "dpi": 300, "bbox": [89, 74, 392, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Case study III - Data : USArray mesoscale-filtered pressure-perturbations (hPa) are overlaid on composite radar reflec- tivity for 0400 UTC 24 May 2011, 1800 UTC 24 May 2011, 0000 UTC 25 May 2011, and 0600 UTC 25 May 2011. ", "caption_bbox": [73, 334, 410, 389]}, {"image_id": 15, "file_name": "472_15.png", "page": 10, "dpi": 300, "bbox": [95, 74, 751, 190], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Case study III - Visualization : A longer tracking graph showing the evolution of pressure-perturbation events for 49 time steps at +1.0 hPa. For the two selected feature tracks in red, the features existing at t = 307, t = 315, t = 316, and t = 318 time steps are visualized. The graph clearly shows the complexity within this case study. Specifically, several thunderstorm complexes appear to merge, split, form, and dissipate. ", "caption_bbox": [71, 192, 777, 247]}], "473": [{"image_id": 0, "file_name": "473_00.png", "page": 1, "dpi": 300, "bbox": [92, 86, 757, 498], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The visualization of region segmentation for Pudong New Area (h) in Shanghai during three time periods generated using MobiSeg: (a) 8-10 am on Monday; (b) 6-8 pm on Monday; (c) 12-2 pm on Sunday. By comparing three segmentation results and embedded activity glyphs, we identified two residential areas (a2, a3) as well as a CBD (a1) with shopping malls (b1) and official blocks (b4). The segmentation results were further verified by comparing to Baidu Street View (d-g). ", "caption_bbox": [73, 513, 775, 565]}, {"image_id": 1, "file_name": "473_01.png", "page": 4, "dpi": 300, "bbox": [122, 77, 728, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: System framework. After data fusion and feature extraction, MobiSeg can support interactive region segmentation in real-time.", "caption_bbox": [91, 244, 757, 256]}, {"image_id": 2, "file_name": "473_02.png", "page": 5, "dpi": 300, "bbox": [121, 74, 729, 498], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The user interface of MobiSeg with four major views: (a) Global Map View provides an overview of the entire mobility dataset for global exploration and enables flitering in both spatial and temporal domains; (b) Inspection View illustrates region segmentation results and support a general understanding of activities in these regions; (c) Detail View visualizes mobility feature vector time series of local districts for an in-depth investigation and comparison, and (d) Activity Pattern View facilitates interpretation of extracted latent activity patterns based on NMF. ", "caption_bbox": [73, 513, 775, 565]}, {"image_id": 3, "file_name": "473_03.png", "page": 6, "dpi": 300, "bbox": [512, 73, 704, 237], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Activity glyph, a stacked elliptical glyph design, embedded in the Inspection View to support a general understanding and com- parison of activities in different local districts. ", "caption_bbox": [440, 252, 775, 291]}, {"image_id": 4, "file_name": "473_04.png", "page": 6, "dpi": 300, "bbox": [506, 807, 711, 945], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The Detail View visualizes feature vector time series ex- tracted in a certain local district through a series of circular horizon graphs to facilitate detailed analysis and comparison. ", "caption_bbox": [440, 960, 775, 999]}, {"image_id": 5, "file_name": "473_05.png", "page": 7, "dpi": 300, "bbox": [79, 806, 401, 966], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Event glyph design with trapezoid-metaphor to visualize feature peaks representing activity events of latent activity patterns. ", "caption_bbox": [73, 973, 408, 998]}, {"image_id": 6, "file_name": "473_06.png", "page": 8, "dpi": 300, "bbox": [104, 610, 376, 726], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Adjustment of segmentation results for 8-10 am on April 6.", "caption_bbox": [73, 735, 408, 747]}, {"image_id": 7, "file_name": "473_07.png", "page": 9, "dpi": 300, "bbox": [113, 74, 737, 171], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visualization of five selected activity patterns with more taxi related activity events (indicated by red and orange event glyphs) to faciitate marketing for a start-up company. The color opacity of the event glyph indicates the probability of an event\u2019s occurrence in each pattern. ", "caption_bbox": [73, 185, 775, 210]}], "474": [{"image_id": 0, "file_name": "474_00.png", "page": 2, "dpi": 300, "bbox": [74, 76, 780, 343], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1. Categorization of travel time visualization", "caption_bbox": [491, 883, 745, 897]}, {"image_id": 1, "file_name": "474_01.png", "page": 3, "dpi": 300, "bbox": [441, 76, 776, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": " Figure 2: The locations of towns in (a) a physical space, and (b) a time space. The relative positions between South town, Downtown,             and North town are inverted in time space. ", "caption_bbox": [445, 253, 777, 295]}, {"image_id": 2, "file_name": "474_02.png", "page": 5, "dpi": 300, "bbox": [68, 76, 774, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) EM and a key structure used in [4] (b) DC and a rearranged key structure: black nodes violates the topology of a key structure    (c) DC constructed without GAP: the overlaps appear (d) DC constructed with GAP: overlaps are removed and replaced with anchors ", "caption_bbox": [82, 348, 765, 376]}, {"image_id": 3, "file_name": "474_03.png", "page": 5, "dpi": 300, "bbox": [74, 792, 410, 966], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 4: Pseudo code of GAP", "caption_bbox": [171, 971, 311, 985]}, {"image_id": 4, "file_name": "474_04.png", "page": 6, "dpi": 300, "bbox": [443, 723, 772, 960], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6. Mobile UI: A user can select a type of location (left), and           explore areas in the greater Seattle area (right) ", "caption_bbox": [448, 968, 772, 996]}, {"image_id": 5, "file_name": "474_05.png", "page": 6, "dpi": 300, "bbox": [91, 76, 763, 347], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": " Figure 5: (a) A raw road network obtained from OSM, and (b) the derived key structure with SRC. Red paths indicate the highways. Bigger nodes are terminal nodes, and smaller nodes are intermediate nodes. (c) Six stages of SRC: each pathway is encoded with a different color. ", "caption_bbox": [84, 355, 775, 383]}, {"image_id": 6, "file_name": "474_06.png", "page": 7, "dpi": 300, "bbox": [439, 75, 777, 168], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: User preference results in Study 1", "caption_bbox": [503, 176, 720, 190]}, {"image_id": 7, "file_name": "474_07.png", "page": 7, "dpi": 300, "bbox": [86, 553, 387, 643], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Yielding \ud835\udc0d\ud835\udc86\ud835\udc8f\ud835\udc85 (\ud835\udc99\u2032, \ud835\udc9a\u2032) by converting a coordinate system", "caption_bbox": [82, 651, 400, 667]}], "475": [{"image_id": 0, "file_name": "475_00.png", "page": 1, "dpi": 300, "bbox": [73, 144, 776, 476], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Comparison between in situ (a and b) and post hoc (c and d) visualization of magnetic flux vorticies in superconductors. The in situ method processes every single timestep during the simulation, and the post hoc processes every 100 timesteps after the simulation. The post hoc analysis show that three vortices #598, #489, and #485 recombine with each other and form new three vortices #590, #593, and #592 within the interval of 100 timesteps (from 6900 to 7000). The in situ visualization precisely shows that #588 and #489 first recombine into #590 and #591 at timestep 6990, and then #591 and #485 recombine into #593 and #592 at timestep 6992. The semitransparent spheres are material defects that attract vortices. ", "caption_bbox": [73, 477, 775, 555]}, {"image_id": 1, "file_name": "475_01.png", "page": 3, "dpi": 300, "bbox": [73, 74, 777, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Our in situ vortex visualization workflow, which consists of the online processing followed by post hoc visualization. The online processing extracts, tracks, analyzes, and reduces vortices during the simulation; and the post hoc visualization provides an interactive user interface to further explore and analyze vortices. ", "caption_bbox": [73, 294, 775, 333]}, {"image_id": 2, "file_name": "475_02.png", "page": 5, "dpi": 300, "bbox": [73, 75, 776, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Mesh subdivision for ambiguity-free vortex extraction and tracking: (a) the ambiguity case of a hexahedron intersected by two vortices; (b) the unambiguous case results where vortex A punctures cells DEHG and DEF G while vortex B punctures ABCF ; the punctured faces are DEH, DGE, ABC, and BF C; (c) and (d) show how a hexahedron is subdivided into six tetrahedra. ", "caption_bbox": [73, 279, 775, 318]}, {"image_id": 3, "file_name": "475_03.png", "page": 6, "dpi": 300, "bbox": [73, 135, 410, 508], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Dependency graph in the parallel execution of vortex ex- traction and tracking. Each extraction task Exi depends on the punc-                                         i depends on the intersected tured faces Fi ; each tracking task T ri\u2032                      i space-time edges Ei\u2032 and the extraction tasks Exi\u2032 and Exi . ", "caption_bbox": [73, 510, 408, 563]}, {"image_id": 4, "file_name": "475_04.png", "page": 6, "dpi": 300, "bbox": [441, 74, 777, 255], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Distance plot (minimum distance between vortices before and after recombination) in the Crossing simulation. The legends show the timestep of recombination and the involved vortices of the event. The dark blue line corresponds to the event in Figure 10. ", "caption_bbox": [440, 257, 775, 309]}, {"image_id": 5, "file_name": "475_05.png", "page": 7, "dpi": 300, "bbox": [445, 78, 770, 296], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Timings of TDGL iterations (Bramp simulation), primi- tive detection, vortex extraction, and vortex tracking with respect to different numbers of primitives. Timings of detect \u2217 GPU, detect \u2217 CPU, and detect \u2217 CPU mt correspond to the primitive detection with GPU, single-threaded CPU, and multithreaded CPU, respectively. ", "caption_bbox": [440, 304, 775, 382]}, {"image_id": 6, "file_name": "475_06.png", "page": 7, "dpi": 300, "bbox": [73, 74, 407, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Distance projection in the Unstable BX simulation. Two vortices approach (a) and then repel (b) each other before and after the recombination. The opacity in the figure encodes the time. ", "caption_bbox": [73, 299, 408, 338]}, {"image_id": 7, "file_name": "475_07.png", "page": 7, "dpi": 300, "bbox": [73, 353, 410, 453], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Software stack of our in situ vortex visualization framework. Various tools and APIs are used in both online processing and post hoc visualization. ", "caption_bbox": [73, 454, 408, 493]}, {"image_id": 8, "file_name": "475_08.png", "page": 9, "dpi": 300, "bbox": [74, 74, 777, 428], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: In situ vortex visualizations of the Crossing simulation: (a) the timeline view showing different types of events (B: birth, D: death, M: merge, S: split, R: recombination) over time; (b) the early stage of the simulation; (c) and (d) a recombination event that is highlighted by the black circles. The distance projection plots are in the left bottom corner of the images. ", "caption_bbox": [73, 430, 775, 469]}], "476": [{"image_id": 0, "file_name": "476_00.png", "page": 1, "dpi": 300, "bbox": [83, 118, 778, 599], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Usage of Interaction+: 1. with a click on the shortcut, Interaction+ is applied in an existing visualization; 2. Interaction+\u2019s toolbar is added on the top; 3. the user brushes a region of interest on the webpage; 4. Interaction+ adds an auxiliary visualization of the extracted visual information; interactions can be performed either in the auxiliary interface (e.g., filter by radius) or the original visualization (e.g., hover to compare). ", "caption_bbox": [73, 614, 775, 666]}, {"image_id": 1, "file_name": "476_01.png", "page": 3, "dpi": 300, "bbox": [440, 74, 777, 185], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Interaction+\u2019s Workflow: taking a webpage with existing vi- sualizations as input, Interaction+ extracts the visual information by parsing the HTML. Then Interaction+ adds on a set of interactions driven by the visual information, which can be performed in the origi- nal visualization or the auxiliary interface. ", "caption_bbox": [440, 201, 775, 266]}, {"image_id": 2, "file_name": "476_02.png", "page": 3, "dpi": 300, "bbox": [441, 642, 776, 825], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration of DOM: DOM tree of a webpage with bar chart, note that it is not fully expanded. ", "caption_bbox": [440, 839, 775, 865]}, {"image_id": 3, "file_name": "476_03.png", "page": 4, "dpi": 300, "bbox": [75, 774, 406, 934], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Selection: objects within a selected region are selected and summarized in the object panel. The corresponding objects in the original visualization are highlighted with a black border after clicking the group label in the object panel. ", "caption_bbox": [73, 948, 408, 1000]}, {"image_id": 4, "file_name": "476_04.png", "page": 4, "dpi": 300, "bbox": [456, 179, 760, 257], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Selection in Textual Context: brush a word in the context to rename an extracted object group. ", "caption_bbox": [440, 271, 775, 297]}, {"image_id": 5, "file_name": "476_05.png", "page": 4, "dpi": 300, "bbox": [456, 508, 760, 636], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Three Masks: templates to aggregate the visual objects.", "caption_bbox": [445, 652, 769, 665]}, {"image_id": 6, "file_name": "476_06.png", "page": 5, "dpi": 300, "bbox": [440, 284, 777, 631], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Arrangement: (a) the histogram shows the distribution of each visual attribute for the selected group of objects; (b) visual ob- jects are plotted in a scatter plot which consists of two attributes; (c) visual objects are drawn in MDS projection of multiple attributes. ", "caption_bbox": [440, 647, 775, 699]}, {"image_id": 7, "file_name": "476_07.png", "page": 5, "dpi": 300, "bbox": [88, 491, 402, 712], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Aggregation by Radial Mask: (a) Radial mask which slices the visualization radially and counts objects in sectors; (b) Radial mask calibration. ", "caption_bbox": [73, 728, 408, 767]}, {"image_id": 8, "file_name": "476_08.png", "page": 5, "dpi": 300, "bbox": [73, 167, 411, 404], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Aggregation by H-Parallel Mask: (a) H-Parallel mask which slices the visualization horizontally and counts objects in horizontal lanes; (b) Slicing procedure of H-Parallel mask. ", "caption_bbox": [73, 420, 408, 459]}, {"image_id": 9, "file_name": "476_09.png", "page": 6, "dpi": 300, "bbox": [443, 74, 777, 382], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Filtering: (a) either brushing the range of interest or defin- ing the top N constraint; (b) multiple filtering criteria combined via cross-filter mechanism; (c) group composition by logic operation. ", "caption_bbox": [440, 398, 775, 437]}, {"image_id": 10, "file_name": "476_10.png", "page": 6, "dpi": 300, "bbox": [442, 461, 777, 578], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Annotation: textual tag connected to the visual objects, with border as a highlight option. ", "caption_bbox": [440, 593, 775, 619]}, {"image_id": 11, "file_name": "476_11.png", "page": 6, "dpi": 300, "bbox": [73, 74, 410, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Comparison with Reference Line: (a) vertical line to com- pare objects which line up vertically, which also can handle complex shapes; (b) horizontal line to compare objects which line up horizon- tally. ", "caption_bbox": [73, 283, 408, 335]}, {"image_id": 12, "file_name": "476_12.png", "page": 7, "dpi": 300, "bbox": [90, 74, 754, 480], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Usage Scenario 1 Interaction+ Applied in The New York Times: (a) Interaction+ is laid over the whole visualization, which extracts 411 budget projects; histograms of visual attributes (i.e., color and radius) indicate projects\u2019 distributions over increase-cut levels and spendings respectively; Projects are filtered by different increase-cut levels, each of which is created as a new group for further examination. (b) changed to types of spending layout, Interaction+ divides proposals into mandatory and discretionary ones by V-Parallel mask. Interaction+ does quick count on the two types of proposals, i.e., 144 mandatory proposals and 267 discretionary ones. Filtering the top 100 spending projects, 61 of them are discretionary and 39 are mandatory. ", "caption_bbox": [73, 496, 775, 574]}, {"image_id": 13, "file_name": "476_13.png", "page": 8, "dpi": 300, "bbox": [100, 78, 751, 449], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Usage Scenario 2 Interaction+ Applied in the Infographic about Students: (a) Interaction+ helps with spatial selection; (b) days with the top highest and lowest attendance are filtered by Interaction+, annotated with labels; (c) the H-Parallel Mask in Interaction+ aggregates the students by three different health statuses; (d) Interaction+ does explicit comparison among the scores. ", "caption_bbox": [73, 465, 775, 504]}], "477": [{"image_id": 0, "file_name": "477_00.png", "page": 3, "dpi": 300, "bbox": [73, 273, 411, 519], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: System overview. The dots represent an example particle dataset. The yellow dots are the user\u2019s target occluded by the cyan ones. The magenta cube represents our virtual retractor. The mesh is shown in black. (a): 3D view of the system. (b)(c): Cross section views of the system. (b): Before deformation. (c): After deformation. (d): The fully-connected mesh used in previous work [37], for comparison. ", "caption_bbox": [73, 530, 411, 626]}, {"image_id": 1, "file_name": "477_01.png", "page": 3, "dpi": 300, "bbox": [453, 81, 764, 207], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Tetrahedralization of one cube is to decompose it into 5 tetrahedrons. (b) Tetrahedralization of neighboring cubes in correct directions. (c) A tetrahedral mesh based on regular grid. ", "caption_bbox": [440, 219, 775, 260]}, {"image_id": 2, "file_name": "477_02.png", "page": 3, "dpi": 300, "bbox": [451, 548, 759, 665], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Our mesh design. (a) is a cross section from the previously used mesh in Figure 2c. (b) is a cross section from our mesh design. It has an incision created by duplicating the blue nodes in (a). (c) gives a 3D view of our mesh design. ", "caption_bbox": [440, 679, 778, 734]}, {"image_id": 3, "file_name": "477_03.png", "page": 4, "dpi": 300, "bbox": [106, 187, 377, 566], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Components and parameters of the virtual retractor. (b) A cross section of (a) at the position of the grey frame. The forces applied on the nodes are illustrated as red and blue arrows. ", "caption_bbox": [73, 577, 410, 618]}, {"image_id": 4, "file_name": "477_04.png", "page": 5, "dpi": 300, "bbox": [439, 801, 777, 947], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) Creating a retractor by drawing a line segment on screen. (b) Creating a retractor by drawing a line segment in 3D space. ", "caption_bbox": [440, 958, 775, 999]}, {"image_id": 5, "file_name": "477_05.png", "page": 7, "dpi": 300, "bbox": [74, 349, 407, 524], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Exploring the cosmology dataset. Each sphere represents a simulated particle. A particle is colored grey if it does not belong to any halo. Otherwise, it is colored by the ID of the halo it belongs to. From (b), we can see two halos in the cluster circled by the yellow curve. In (d), one more halo in green is exposed by our method. As a comparison in (c), the deformation technique without cutting [37] cannot break the cluster or reveal the hidden green halo. ", "caption_bbox": [73, 537, 411, 633]}, {"image_id": 6, "file_name": "477_06.png", "page": 7, "dpi": 300, "bbox": [440, 274, 773, 434], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Exploring the viscous fluid dataset. Particles are colored by the concentration values using RdYiGn color map, where red is used for high value and green for low value. A hidden cluster is revealed by our method in (d), but not by the method in (c). ", "caption_bbox": [440, 446, 775, 501]}, {"image_id": 7, "file_name": "477_07.png", "page": 8, "dpi": 300, "bbox": [444, 77, 770, 431], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The example showing the effect of the transferred density based stiffness setting. The dataset is the vector magnitude of NEK dataset. The warm-cold color map is used, where red represents high value. (b) is a cross section view of (a). (c) and (d) are enlarged views of the deformation at the region circled by yellow dashed curve in (a). (c) and (d) are generated using different stiffness. The white arrows in (d) mark the position of its difference with (c). ", "caption_bbox": [439, 443, 775, 539]}, {"image_id": 8, "file_name": "477_08.png", "page": 8, "dpi": 300, "bbox": [74, 86, 407, 428], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Examples showing the effects of the density based stiffness setting. Two clusters are circled by yellow dashed curves. (a)-(c) show the deformation using increasing forces. The shapes of the clusters are well preserved, and the empty space near them are compressed to make space for the clusters. (d) shows a comparison of using uniform stiffness setting, which compresses the clusters and the empty space in the same way, and destroys some shape features. ", "caption_bbox": [73, 440, 409, 536]}, {"image_id": 9, "file_name": "477_09.png", "page": 9, "dpi": 300, "bbox": [75, 75, 407, 457], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The example showing the effect of the gradient based stiffness setting. The dataset is an MR volume dataset. (b) and (c) are generated using the same configurations except for the stiffness. Differences of (b) and (c) can be found in regions marked by yellow dashed curves. ", "caption_bbox": [73, 469, 411, 537]}, {"image_id": 10, "file_name": "477_10.png", "page": 9, "dpi": 300, "bbox": [446, 111, 768, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: (a) Frame rate (FPS) when changing the number of tetrahedrons in the mesh. (b) Frame rate for different sizes of particle datasets. (c) Frame rate for different sizes of volume datasets. ", "caption_bbox": [440, 228, 775, 269]}], "478": [{"image_id": 0, "file_name": "478_00.png", "page": 2, "dpi": 300, "bbox": [441, 75, 776, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: SD coordination between physical interaction space, and virtual visualisation space. A high-dimensional data space is mapped into a (lower) 3-dimensional visualisation space (a), which in turn is rendered onto some display (b) perceivable by the user (c). Attributes become dimensions, data elements points in this space. Interaction happens in interaction space and is mapped to the visualisation space (d). In the interaction space, a device like a slider can be aligned to a data axis for range selection on that axis, or a touch surface can be aligned with two data axes such that two touch points create a selection across two data axes. By contrast, a Vive controller interaction is typically not constrained to data dimensions. ", "caption_bbox": [439, 215, 775, 359]}, {"image_id": 1, "file_name": "478_01.png", "page": 4, "dpi": 300, "bbox": [489, 73, 726, 436], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Three designs for SD coordinated interaction.", "caption_bbox": [471, 438, 743, 450]}], "479": [{"image_id": 0, "file_name": "479_00.png", "page": 3, "dpi": 300, "bbox": [93, 74, 754, 311], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The gesture set used in our system. Please see also the accompanying video for an illustration of these gestures.", "caption_bbox": [107, 317, 741, 329]}, {"image_id": 1, "file_name": "479_01.png", "page": 3, "dpi": 300, "bbox": [439, 353, 777, 635], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The graphs provided in the user study.", "caption_bbox": [489, 647, 726, 659]}, {"image_id": 2, "file_name": "479_02.png", "page": 4, "dpi": 300, "bbox": [78, 776, 403, 929], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The completion time of completing tasks in different systems. The average time and standard error is provided. The tasks with significant difference are marked. The label (a-c) indicate the total time spending on different graphs: (a) brain graph, (b) force-directed graph, and (c) BioLayout graph. ", "caption_bbox": [73, 935, 411, 1000]}, {"image_id": 3, "file_name": "479_03.png", "page": 4, "dpi": 300, "bbox": [78, 77, 405, 249], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Participants rated the difficulty of performing each operation with gesture and mouse input. The average scores, standard errors, and the operations with significant difference are plotted. ", "caption_bbox": [73, 254, 410, 293]}, {"image_id": 4, "file_name": "479_04.png", "page": 4, "dpi": 300, "bbox": [76, 304, 404, 438], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Accuracy rates and their standard errors for each tasks. The label (a-c) indicate the accuracy rates on different graphs: (a) brain graph, (b) force-directed graph, and (c) BioLayout graph. ", "caption_bbox": [73, 443, 408, 482]}], "48": [{"image_id": 0, "file_name": "48_00.png", "page": 2, "dpi": 300, "bbox": [427, 524, 736, 769], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Kiviat charting as seen in the Borland\u2019s Togeth- erJ (TogetherJ 2003) ", "caption_bbox": [427, 810, 748, 838]}, {"image_id": 1, "file_name": "48_01.png", "page": 3, "dpi": 300, "bbox": [247, 56, 582, 560], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Metric collection system architecture for our study.", "caption_bbox": [246, 574, 586, 588]}, {"image_id": 2, "file_name": "48_02.png", "page": 3, "dpi": 300, "bbox": [427, 611, 769, 878], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Metrics visualisation provided by the Eclipse metrics plugin (Eclipse Metrics Plug-in 2003) and Touch- Graph (TouchGraph 2003). ", "caption_bbox": [427, 892, 748, 934]}, {"image_id": 3, "file_name": "48_03.png", "page": 4, "dpi": 300, "bbox": [205, 53, 628, 422], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A screenshot of the solar system metaphor as applied to the source code of the tool itself. The true colour scheme is a real starscape, but colours have been inverted for clarity in publication. ", "caption_bbox": [83, 436, 749, 464]}, {"image_id": 4, "file_name": "48_04.png", "page": 5, "dpi": 300, "bbox": [207, 622, 626, 990], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualisation in \u2019Coupling Mode\u2019. Note the contrast in relative size of the planets in some orbits.", "caption_bbox": [120, 1004, 712, 1018]}, {"image_id": 5, "file_name": "48_05.png", "page": 5, "dpi": 300, "bbox": [206, 108, 627, 476], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualisation in \u2019Lines of Code mode\u2019 indicates relative size of each class.", "caption_bbox": [182, 490, 649, 504]}, {"image_id": 6, "file_name": "48_06.png", "page": 6, "dpi": 300, "bbox": [111, 634, 376, 948], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Underlying architecture of the 3D visualisation tool. ", "caption_bbox": [83, 962, 404, 990]}], "480": [{"image_id": 0, "file_name": "480_00.png", "page": 1, "dpi": 300, "bbox": [123, 158, 728, 629], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (A) Intimacy Network Overview discloses the distribution of different types of players in the entire network. (B) Ranking lists facilitate users to explore and select different types of players. (C) Summary View of Changes of Alters\u2019 Ego-network presents the metric evolutions along with time. (D) Interaction Timeline provides the interaction overview between the ego and the alters. (E) Three timelines include (E1 ): Logon/Logout Timeline provides an overview of logon/logout activities of involved players in the corresponding time period; (E2 ): Ego-network Timeline maintains an impression of the status of the ego and his/her alters in the entire interaction network; and (E3 ): Intimacy Timeline provides a cumulative graph of the intimacy change between an ego and his/her alters. (F) Information View shows the distribution of different types of interaction, similarity distribution of involved players and a table summarizing the detailed attributes of the players. ", "caption_bbox": [106, 644, 745, 748]}, {"image_id": 1, "file_name": "480_01.png", "page": 4, "dpi": 300, "bbox": [101, 73, 746, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A typical approach by the data analyst (E.2) demonstrates how players\u2019 social contacts are established in the largest community of three game servers. The red line indicates those relationships of which the intimacy degree is over 100. A: small groups are established; B: External relationships are formed; C: Small groups begin to merge; D: Groups emerge into a larger community. ", "caption_bbox": [73, 263, 775, 302]}, {"image_id": 2, "file_name": "480_02.png", "page": 5, "dpi": 300, "bbox": [457, 178, 753, 306], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Layout of Interaction Timeline View.", "caption_bbox": [496, 313, 719, 325]}, {"image_id": 3, "file_name": "480_03.png", "page": 5, "dpi": 300, "bbox": [93, 416, 384, 562], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Example of the Interaction Timeline View of a dynamic ego interaction network at three subsequent time steps (t1 , t2 and t3 ): the ego is represented as the red node and the alters as black nodes. ", "caption_bbox": [73, 567, 408, 606]}, {"image_id": 4, "file_name": "480_04.png", "page": 6, "dpi": 300, "bbox": [455, 737, 748, 849], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Logon/Logout Timeline shows logon and logout activities of the involved players. Red represents the selected ego, and the darker color indicates the alters with higher intimacy. ", "caption_bbox": [440, 856, 776, 895]}, {"image_id": 5, "file_name": "480_05.png", "page": 6, "dpi": 300, "bbox": [78, 291, 403, 399], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visualizing the change centrality of an ego-network: (a) The value of the change centrality increases when a sudden change occurs to the ego-network. (b) The value of the change centrality remains the same when no changes occurs to the ego-network. ", "caption_bbox": [73, 404, 409, 456]}, {"image_id": 6, "file_name": "480_06.png", "page": 6, "dpi": 300, "bbox": [87, 120, 394, 212], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Calculation of 0/1/2-step change ratios and change centrali- ties between t1 and t2 of the example ego-network in Figure 3. ", "caption_bbox": [439, 73, 777, 100]}, {"image_id": 7, "file_name": "480_07.png", "page": 7, "dpi": 300, "bbox": [82, 651, 398, 880], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Summary view of changes of alters\u2019 ego-networks: (1) the example ego-network evolution; (2) the evolution of alters\u2019 ego- networks; and (3) the design of Summary View. ", "caption_bbox": [73, 879, 410, 918]}, {"image_id": 8, "file_name": "480_08.png", "page": 8, "dpi": 300, "bbox": [444, 705, 769, 788], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Another example of high impact on inactive player by a very active one: (A) Adjusting the time slide. (B) Select the player with the largest intimacy. (C) The player\u2019s ego-network expands significantly after the interaction with the ego, who is a very active player. ", "caption_bbox": [440, 799, 776, 851]}, {"image_id": 9, "file_name": "480_09.png", "page": 8, "dpi": 300, "bbox": [444, 505, 769, 665], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: High impact on inactive player by a very active one.", "caption_bbox": [454, 672, 760, 684]}, {"image_id": 10, "file_name": "480_10.png", "page": 8, "dpi": 300, "bbox": [107, 83, 741, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Typical PVP (Player A) and PVE (Player B) players: Both have established a dense ego-network since the first day (Ego-network Timelines). Compared with Player A, Player B has fewer friends with high intimacy, as there are fewer deep green bars in Logon/Logout Timeline of Player B. From the Intimacy Timeline, Player A has more interaction with other players compared with Player B, such as \u201ckilling players\u201d, \u201cbattles\u201d, etc., while Player B mainly focuses on \u201ckilling monsters\u201d. ", "caption_bbox": [73, 321, 777, 373]}, {"image_id": 11, "file_name": "480_11.png", "page": 9, "dpi": 300, "bbox": [88, 595, 393, 813], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: The ego\u2019s network from 8th \u2212 11th does not change signifi- cantly. The OCR metric (A) of ego-network is relatively stable. During the entire interaction with the ego, the alter\u2019s ego-network does not change significantly, either. The summary view (B) displays a smooth curve of the alter, indicating that the alter only interacts with the ego. ", "caption_bbox": [73, 817, 410, 884]}, {"image_id": 12, "file_name": "480_12.png", "page": 9, "dpi": 300, "bbox": [78, 289, 403, 375], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Two active players interact with each other from different perspective: A as the ego and B as the alter; A as the alter and B as the ego. ", "caption_bbox": [73, 381, 408, 420]}], "481": [{"image_id": 0, "file_name": "481_00.png", "page": 2, "dpi": 300, "bbox": [448, 74, 768, 178], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Examples of set-typed dataset with movies and genres, and steps of set network construction ", "caption_bbox": [440, 194, 775, 219]}, {"image_id": 1, "file_name": "481_01.png", "page": 2, "dpi": 300, "bbox": [82, 861, 402, 971], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Basic set exploration flow of NetSet", "caption_bbox": [129, 988, 352, 1000]}, {"image_id": 2, "file_name": "481_02.png", "page": 3, "dpi": 300, "bbox": [437, 559, 784, 735], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Positioning of sets on the network according to the centroid and intersection cardinality of the subset. ", "caption_bbox": [440, 751, 775, 776]}, {"image_id": 3, "file_name": "481_03.png", "page": 3, "dpi": 300, "bbox": [82, 709, 402, 888], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Query interface of NetSet system: \u201cEntertainment\u201d (coloured with red) and \u201cCulture\u201d (orange) sets are selected as must option, \u201cDesign\u201d (blue) set is selected as maybe, and \u201cTechnology\u201d (blue) and \u201cScience\u201d (green) sets are selected as not option. The right bar and number indicate the sum of intersection cardinality when the query executes. ", "caption_bbox": [73, 902, 408, 980]}, {"image_id": 4, "file_name": "481_04.png", "page": 4, "dpi": 300, "bbox": [453, 403, 762, 569], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The result of elements view with the intersection composed of \u201cTechnology\u201d, \u201cEntertainment\u201d, and \u201cBusiness\u201d topics in TED data. Left shows the talks shared by three topics, and bottom right shows the list view of the talks details. ", "caption_bbox": [440, 576, 775, 628]}, {"image_id": 5, "file_name": "481_05.png", "page": 4, "dpi": 300, "bbox": [82, 403, 399, 567], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Example of switching sets view by attributes of sets using TED Topics-talks data. The size of each node represents average values of Funny attribute. ", "caption_bbox": [73, 574, 408, 613]}, {"image_id": 6, "file_name": "481_06.png", "page": 4, "dpi": 300, "bbox": [126, 54, 712, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Overview of NetSet: Three activated topics in TED on a node-link graph visualization (left) synchronized with matrix-based set intersection visualization (top-right), and a list of elements which the topics are sharing is shown (bottom-right). ", "caption_bbox": [73, 364, 775, 389]}], "482": [{"image_id": 0, "file_name": "482_00.png", "page": 3, "dpi": 300, "bbox": [460, 653, 759, 818], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Facebook ego network facebook01 with 4,039 nodes.", "caption_bbox": [449, 832, 765, 845]}, {"image_id": 1, "file_name": "482_01.png", "page": 3, "dpi": 300, "bbox": [442, 75, 776, 191], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Comparison based on shape-based quality metrics.", "caption_bbox": [455, 203, 759, 216]}, {"image_id": 2, "file_name": "482_02.png", "page": 4, "dpi": 300, "bbox": [462, 488, 755, 634], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: As20010526: May 26, 2001 AS graph.", "caption_bbox": [485, 648, 730, 661]}, {"image_id": 3, "file_name": "482_03.png", "page": 4, "dpi": 300, "bbox": [441, 296, 775, 441], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Shape-based quality metrics comparison to FM3 .", "caption_bbox": [460, 451, 755, 467]}, {"image_id": 4, "file_name": "482_04.png", "page": 4, "dpi": 300, "bbox": [76, 781, 408, 930], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Running time comparison to FM3 .", "caption_bbox": [129, 940, 352, 956]}], "483": [{"image_id": 0, "file_name": "483_00.png", "page": 2, "dpi": 300, "bbox": [81, 77, 762, 251], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Illustrating a synthetic, ontological social network of eleven researchers affiliated with a university lab. (a) Based on an example schema, entities are of type [Person], and connections between them show [Collaboration]. There are three types of demographic attributes: [Location], [Age], and [Title]. (b) The data can be laid out in a force-directed graph. Each [Person] node has an edge to its respective set of attribute nodes. (c) The network can alternatively be shown in an adjacency matrix. ", "caption_bbox": [73, 263, 775, 318]}, {"image_id": 1, "file_name": "483_01.png", "page": 5, "dpi": 300, "bbox": [445, 76, 770, 541], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Privacy preserving operations: (a) The original dataset. (b) Applying a node merge to address k-anonymity. (c) Applying a node merge to address l-diversity. (d) Edge bundling to address l-diversity. ", "caption_bbox": [440, 553, 775, 608]}, {"image_id": 2, "file_name": "483_02.png", "page": 6, "dpi": 300, "bbox": [78, 76, 778, 473], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Graph layouts and matrix ordering affect privacy perception. All six plots show the same dataset, which contains the following privacy leak: two Senior Grads who live at MIT both hang out at Friends, a 2-diversity leak. (a) and (b) show two layouts of the graph with the leak unmarked (graphs (d) and (e) show the same layout with the leak highlighted). In (a), the leak is more visually perceptible, while in (b) it is hidden by line clutter and node positioning. In (c), the matrix row ordering places the leak-causing nodes by each other, allowing easier recognition as opposed to (f), where they are placed far apart in the set of matrix rows. ", "caption_bbox": [73, 485, 775, 553]}, {"image_id": 3, "file_name": "483_03.png", "page": 7, "dpi": 300, "bbox": [75, 74, 776, 347], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (A) Our system displays the loaded dataset and allows a number of interactions, such as (B-C) modifying graph display settings and (E-H) modifying the graph topology itself. (D) To resolve privacy issues, the user can review a list of detected leaks and choose a desired course of action. ", "caption_bbox": [73, 358, 775, 399]}], "484": [{"image_id": 0, "file_name": "484_00.png", "page": 2, "dpi": 300, "bbox": [442, 252, 777, 427], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) An example of raw trajectory data. (b) Construction of the FoN from raw trajectory data. (c) Extraction of higher-order dependencies from raw trajectories. (d) Construction of the HoN from higher-order dependencies. ", "caption_bbox": [440, 429, 775, 484]}, {"image_id": 1, "file_name": "484_01.png", "page": 2, "dpi": 300, "bbox": [106, 64, 740, 193], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The framework of HoNVis design. FoN and HoN are converted and extracted from the raw trajectory data, from which we identify nodes of interest. Five linked views are designed to enable the interrogation of single and multiple nodes. ", "caption_bbox": [73, 195, 775, 222]}, {"image_id": 2, "file_name": "484_02.png", "page": 4, "dpi": 300, "bbox": [89, 63, 758, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The overview of HoNVis, our visual analytics system for exploring the global shipping higher-order network. (a) Geographic view. (b) Dependency view. (c) Subgraph view. (d) Aggregation view. (e) Table view. (f) Parameter panel. ", "caption_bbox": [73, 425, 775, 452]}, {"image_id": 3, "file_name": "484_03.png", "page": 6, "dpi": 300, "bbox": [80, 76, 408, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The subgraph view. (a) HoN scatterplot and subgraph. (b) HoN scatterplot, subgraph expanded from the subgraph shown in (a), and stacked histogram showing node contribution. ", "caption_bbox": [73, 231, 408, 272]}, {"image_id": 4, "file_name": "484_04.png", "page": 7, "dpi": 300, "bbox": [78, 63, 409, 248], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The aggregation view. (a) Exact grouping using eco- realms. (b) to (d) The eco-realm of \u201cTemperate Northern Pacific\u201d with coarse grouping. (b) Uniform node weight. (c) Nodes are weighted by the number of original nodes. (d) Nodes are weighted by the number of ships. The same aggregated node is highlighted in black in (b) to (d). ", "caption_bbox": [73, 249, 408, 331]}, {"image_id": 5, "file_name": "484_05.png", "page": 7, "dpi": 300, "bbox": [452, 73, 765, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Identifying a port of interest. (a) The port Salvador in Brazil is highlighted with a magenta halo in the geographic view. (b) The nearby ports are listed in the table view ordered by their numbers of associated higher-order nodes. ", "caption_bbox": [440, 270, 775, 325]}, {"image_id": 6, "file_name": "484_06.png", "page": 8, "dpi": 300, "bbox": [83, 75, 402, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The higher-order dependencies related to Salvador. (a) Histograms of ship types and temporal activities of fourth-order movement patterns from Salvador. (b) Histograms of ship types and temporal activities for all ships from Salvador. (c) Higher-order dependencies related to Salvador in the dependency view. ", "caption_bbox": [73, 300, 408, 369]}, {"image_id": 7, "file_name": "484_07.png", "page": 9, "dpi": 300, "bbox": [439, 574, 778, 626], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Comparison of PageRank risk simulation on the FoN and the HoN. Blue ports are risks overestimated on the FoN and red ports are risks underestimated on the FoN. ", "caption_bbox": [440, 625, 775, 666]}, {"image_id": 8, "file_name": "484_08.png", "page": 9, "dpi": 300, "bbox": [84, 275, 757, 505], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Investigating higher-order dependencies at different granularities. (a) Studying a sector which both the current and previous ports are in the Tropical Atlantic eco-realm. (b) Studying a sector which the current ports are in the Tropical Atlantic eco-realm, but the previous ports are not. (c) Changing the view in (b) from uniform node weight to weighted by the number of ships. ", "caption_bbox": [73, 506, 775, 547]}, {"image_id": 9, "file_name": "484_09.png", "page": 9, "dpi": 300, "bbox": [80, 75, 774, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) Tracing how the species may propagate from Salvador in a stepwise manner. (b) The propagation eventually influences multiple ports in East Asia, which are far away from Salvador. (c) Another direction of the propagation covers multiple ports in Northwest Europe. ", "caption_bbox": [73, 231, 775, 258]}], "485": [{"image_id": 0, "file_name": "485_00.png", "page": 2, "dpi": 300, "bbox": [469, 781, 723, 856], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Evolutionary signature (edge evolution matrix) of an ani- mated mesh. ", "caption_bbox": [436, 869, 755, 895]}, {"image_id": 1, "file_name": "485_01.png", "page": 2, "dpi": 300, "bbox": [157, 98, 704, 346], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Tempo-spatial segmentation of \u2018Face-expressions\u2019 (top) and the graph representation (bottom). In the top row, each face corresponds to a temporal segment and the colors denote the spatial segmentation of each temporal segment. In the bottom row, \u2018N\u2019 and \u2018C\u2019 denote two different edge evolution behaviors between the neighboring two temporal segments, i.e., Not-changed and Collapsed. ", "caption_bbox": [92, 385, 759, 423]}, {"image_id": 2, "file_name": "485_02.png", "page": 2, "dpi": 300, "bbox": [94, 619, 410, 739], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Edge evolutions within a temporal segment. The dotted circle in the left graph is a sub-graph from the over-segmentation G0 , and the right graph is the corresponding sub-graph of a temporal segment, in which the three nodes \u03c91 , \u03c92 and \u03c93 show the same behavior and thus are merged into one spatial segment. ", "caption_bbox": [92, 752, 411, 815]}, {"image_id": 3, "file_name": "485_03.png", "page": 4, "dpi": 300, "bbox": [162, 94, 689, 550], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Tempo-spatial segmentation of (a) \u2018Face-expression\u2019 and (b) \u2018Galloping-horse\u2019 (RF: right fore, LF: left fore, RH: right hint, LH: left hint).", "caption_bbox": [90, 562, 757, 575]}], "486": [{"image_id": 0, "file_name": "486_00.png", "page": 1, "dpi": 300, "bbox": [424, 60, 725, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Distribution of mode water in the world [13].", "caption_bbox": [469, 444, 718, 457]}, {"image_id": 1, "file_name": "486_01.png", "page": 3, "dpi": 300, "bbox": [97, 100, 407, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Processing \ufb02ow.", "caption_bbox": [188, 320, 311, 333]}, {"image_id": 2, "file_name": "486_02.png", "page": 3, "dpi": 300, "bbox": [435, 463, 756, 650], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: User interface of the tool.", "caption_bbox": [513, 667, 677, 680]}, {"image_id": 3, "file_name": "486_03.png", "page": 3, "dpi": 300, "bbox": [110, 685, 384, 780], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: View-based 3D shape comparison.", "caption_bbox": [145, 798, 355, 811]}, {"image_id": 4, "file_name": "486_04.png", "page": 4, "dpi": 300, "bbox": [467, 495, 724, 581], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (Left) The most similar pair of mode water regions. (Right) The most dissimilar pair of mode water regions. ", "caption_bbox": [435, 593, 755, 619]}, {"image_id": 5, "file_name": "486_05.png", "page": 4, "dpi": 300, "bbox": [439, 99, 743, 403], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Distribution of 10-dimensional similarlity values visualized by PCP. (Upper-left) Colored based on months of the OFES dataset. (Upper-right) Colored based on PV of the OFES dataset. (Lower-left) Colored based on density of the OFES dataset. (Lower-right) Colored based on PV of the WOA13 dataset. ", "caption_bbox": [435, 420, 756, 483]}, {"image_id": 6, "file_name": "486_06.png", "page": 5, "dpi": 300, "bbox": [123, 98, 393, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Example of scenario which explores mode water regions of a simulation dataset which are similar to a particular mode water regions of an observation dataset. ", "caption_bbox": [92, 400, 411, 438]}], "487": [{"image_id": 0, "file_name": "487_00.png", "page": 3, "dpi": 300, "bbox": [139, 101, 715, 346], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The overview of our interface. The main view is a scrollable timeline view, which shows the speed of each player (colored by team) and the basketball as horizontal bands. Each band\u2019s opacity indicates the player/ball speed, and height indicates the player/ball distance from the court center at that instant. Missed and scored shots are shown as empty and \ufb01lled boxes on the basketball timeline. Users can play the team area animation (bottom left) for a selected duration. Finally, the scoring margin view (top left) shows the scoring de\ufb01cit between the two teams. ", "caption_bbox": [92, 352, 759, 403]}], "488": [{"image_id": 0, "file_name": "488_00.png", "page": 1, "dpi": 300, "bbox": [98, 60, 754, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Screen shots from performing camera navigation in an egocentric mode, using an MRI brain dataset. (a) gives the original position of the camera. Without our method, moving the camera forward will see a scene as (b), where the camera is trapped into opaque voxels and the view is blocked. Our method can detect this degeneration, and deform the obstacle automatically using animations as shown by (c)(d)(e). ", "caption_bbox": [123, 406, 727, 459]}, {"image_id": 1, "file_name": "488_01.png", "page": 3, "dpi": 300, "bbox": [450, 101, 738, 320], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration of deformation regions and tunnels. White is used for opaque data elements, and grey is for empty space. The pink frames represent deformation regions. (a) Compute the deformation region. Segment AB forms the central axis. (b) Update the deforma- tion region when needed. (c) Tunnel opening. (d) Tunnel closing. (e) An example of mixed animation and two tunnels existing at the same time. (f) A 3D view of the deformation region. ", "caption_bbox": [434, 334, 755, 426]}, {"image_id": 2, "file_name": "488_02.png", "page": 4, "dpi": 300, "bbox": [438, 98, 757, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The state transition diagram of our deformation system. Rectangles represent states; arrows represent transitions between states; and dashed ellipsoids represent events. T-O: time out. C: clear. O: occluded. Ori: original data. Cur: current data. ", "caption_bbox": [436, 342, 757, 395]}, {"image_id": 3, "file_name": "488_03.png", "page": 5, "dpi": 300, "bbox": [131, 449, 370, 566], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Cutting the triangular mesh to create a break for the cuboid shape model. ", "caption_bbox": [92, 576, 411, 602]}, {"image_id": 4, "file_name": "488_04.png", "page": 5, "dpi": 300, "bbox": [122, 99, 395, 371], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Parameters of two shape models, and mapping of locations between the original and deformed spaces. (a)(b): cuboid model. (c)(d): circular model. (a)(c): cross sections perpendicular to  v in (b) and (d). ", "caption_bbox": [91, 381, 412, 434]}, {"image_id": 5, "file_name": "488_05.png", "page": 6, "dpi": 300, "bbox": [454, 189, 734, 531], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Navigation to explore the brain phantom MRI dataset. Linear grayscale transfer function is used. See text for details. ", "caption_bbox": [435, 542, 756, 568]}, {"image_id": 6, "file_name": "488_06.png", "page": 6, "dpi": 300, "bbox": [127, 99, 376, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Examples of using color as a hint for displaced data elements. Red used in (a) and (b), and cyan used in (c). ", "caption_bbox": [92, 277, 411, 303]}, {"image_id": 7, "file_name": "488_07.png", "page": 7, "dpi": 300, "bbox": [102, 297, 400, 484], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Navigation to explore the isosurfaces of the geological dataset. Blue, pink, red are used for the low, middle, and high isovalues respectively. Green is used as a hint color for displacement. See text for details. ", "caption_bbox": [92, 495, 413, 548]}, {"image_id": 8, "file_name": "488_08.png", "page": 7, "dpi": 300, "bbox": [444, 139, 745, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Exploring the geological dataset using isosurfaces. Change the isovalue of the blue surface, while the camera is \ufb01xed. IV short for isovalue. ", "caption_bbox": [434, 362, 755, 401]}, {"image_id": 9, "file_name": "488_09.png", "page": 8, "dpi": 300, "bbox": [92, 392, 411, 545], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Exploration of the time varying blood cell simulation, compared with not using our method. Cyan color is blended on displaced cells. ", "caption_bbox": [91, 556, 411, 595]}, {"image_id": 10, "file_name": "488_10.png", "page": 8, "dpi": 300, "bbox": [101, 99, 402, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Exploring the value layers of the geological dataset using direct volume rendering. The transfer function has two narrow peaks. Change the value of one peak to change the position of the blue surface, while the camera is \ufb01xed. PV denotes the peak value. ", "caption_bbox": [91, 321, 410, 374]}, {"image_id": 11, "file_name": "488_11.png", "page": 8, "dpi": 300, "bbox": [434, 99, 754, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Exploration of the time varying blood cell simulation. Compare two shape models to show that the circular model can avoid abrupt change of cell locations. Cyan color is blended on displaced cells. ", "caption_bbox": [435, 279, 756, 332]}], "489": [{"image_id": 0, "file_name": "489_00.png", "page": 1, "dpi": 300, "bbox": [118, 60, 735, 633], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: KYE is composed of three panes: (a) the interactive table view relates visualizations with original data values, (b) the heatmap view supports both, investigating automatically detected problems and identifying additional data quality problems, and (c) the statistics view provides additional information for an informed reasoning. Here we show how KYE helps to reason about possible quality problems detected by automatic means. The heatmap (b) is con\ufb01gured (d) to relate different water measurement stations (y-axis) with the hour the measurements were taken (x-axis). The color is mapped to the total amount of detected quality problems for each heatmap cell. This reveals possible quality problems for measurements at station S18 at 12.00 noon. The tooltip shows that most detected problems for this cell refer to missing values. By exploring these values in the table view (a) we reason that the sensor which measures chlorophyll broke at 33 meter water depth, and thus, caused a big amount of missing values. ", "caption_bbox": [123, 646, 728, 747]}, {"image_id": 1, "file_name": "489_01.png", "page": 4, "dpi": 300, "bbox": [92, 100, 761, 232], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Iterative design process. The mockups and designs choices that \ufb01nally led to the design of KYE range from simple sketches to high \ufb01delity prototypes. The sketches in (a) and (b) were among our \ufb01rst ideas to detect speci\ufb01c quality problems. We considered (a) a time-line chart to identify abrupt changes of numerical values over time and (b) a chart displaying intervals as bars over time to identify irregularities in duration lengths. The stacked temporal bar chart in (c) was designed to communicate a multitude of quality problems in one graph. In (d) we already contemplated a heatmap visualization and sketched out the arrangement of different views. The \ufb01rst high \ufb01delity prototype (e) was used to verify the design choices and help to understand what interactions would be needed. (f) shows the \ufb01nal design of the prototype. ", "caption_bbox": [91, 257, 758, 333]}, {"image_id": 2, "file_name": "489_02.png", "page": 6, "dpi": 300, "bbox": [91, 100, 761, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Different ways of color mapping provide different views on the data, relevant to understand possible data quality problems. The data and axes con\ufb01guration of the heatmap are the same in each picture: months on the x-axis and stations on the y-axis. The color mapping in (a) encodes the amount of detected quality problems for the data in each heatmap cell. This reveals that February, August, and December are especially error-prone for almost all stations. Moreover, there was an unusual amount of errors detected for station S18 in April. In (b) we map the tuple count to color. There are more measurements taken at station S18 than at other stations. (c) shows mapping a calculated key \ufb01gure, i.e. the mean temperature for each heatmap cell. This points to an outlying high mean temperature in December. ", "caption_bbox": [91, 262, 758, 338]}, {"image_id": 3, "file_name": "489_03.png", "page": 7, "dpi": 300, "bbox": [91, 100, 761, 536], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An example of how KYE can be used to detect quality problems that were not detected by automatic checks. The x-axis of the heatmap shows day of month and the y-axis shows water temperature, while chlorophyll values are represented by color. We can identify two suspicious heatmap cells with unusual high (c) and unusual low temperatures (a). When selecting the cell with low temperatures (a), the linked table view shows the raw temperature values (b). Considering the neighbouring temperature values we reason that these unusual low temperatures must be a data quality problem. Moreover, there are no measurements on the 2nd day of month (d). And dark colors in the heatmap point to outlying mean chlorophyll values that might also present quality problems (e). ", "caption_bbox": [92, 548, 759, 625]}], "49": [{"image_id": 0, "file_name": "49_00.png", "page": 1, "dpi": 300, "bbox": [457, 501, 716, 880], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An example of a conventional drawing of a phylogenetic tree (a phenogram). The leaves indicate species; the internal nodes represent hypothetical an- cestors for the species; and branch lengths give an indication of evolutionary time. The leaf ordering is entirely arbitrary. ", "caption_bbox": [427, 897, 749, 980]}, {"image_id": 1, "file_name": "49_01.png", "page": 3, "dpi": 300, "bbox": [149, 139, 685, 347], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "           The 5.2 123DDvisualization Figure 2:Figure          visualisationof 10 of                                             phylogenies                                                a set of produced by fastDNAml.                                                         phylogenetic              Traces haveby                                                                           trees proposed     been turned onet.                                                                                                 Stewart     for several                                                                                                                 al. Notetaxa,the                                                                                                                               facilitating                                                                                                                                    large number                                                            comparison  of the trees [23]. of crossings between the coloured edges joining similar species in adjacent trees. Visualisation produced by TreeViewer: http://www.avl.iu.edu/projects/Tree3D/. Used by permission. ", "caption_bbox": [83, 358, 749, 405]}, {"image_id": 2, "file_name": "49_02.png", "page": 4, "dpi": 300, "bbox": [125, 67, 719, 438], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Another pair of views of the 2 12 D visualisation from Figure 3 but with crossings minimised using Algorithm 1. Note that crossings have been greatly reduced. ", "caption_bbox": [83, 463, 749, 496]}, {"image_id": 3, "file_name": "49_03.png", "page": 5, "dpi": 300, "bbox": [112, 66, 381, 1068], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Demonstration that one-layer crossing min- imisation problem subject to tree constraints is de- composable ", "caption_bbox": [83, 1093, 405, 1135]}, {"image_id": 4, "file_name": "49_04.png", "page": 6, "dpi": 300, "bbox": [91, 60, 410, 390], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An example of a circular drawing of the phylogenetic tree from Figure 1. ", "caption_bbox": [83, 411, 405, 439]}, {"image_id": 5, "file_name": "49_05.png", "page": 7, "dpi": 300, "bbox": [128, 73, 725, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A visualisation of the same data-set used in earlier figures but arranged in the circular style shown in cross-section in Figure 6. ", "caption_bbox": [83, 450, 749, 478]}], "490": [{"image_id": 0, "file_name": "490_00.png", "page": 1, "dpi": 300, "bbox": [78, 60, 774, 421], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Samples of stimuli used in our Study. Side-by-side PCP and SPLOM with two dif\ufb01culty levels: easy (a) and dif\ufb01cult (b). A multiple-selection \ufb01ltering is applied on (a). Multiple SPLOM points and PCP lines corresponding to a single data item are highlighted in (b); Here, participants were required to \ufb01nd the candidate with the best average mark in over 100-200 candidates. ", "caption_bbox": [122, 439, 727, 477]}, {"image_id": 1, "file_name": "490_01.png", "page": 3, "dpi": 300, "bbox": [434, 201, 770, 747], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Re-ordering axes in Combined view. Step 1: User initiate dragging by clicking top handle of PCP or left (or bottom) handle in SPLOM, the selected axis/column are responsive and the counterpart elements on the other view turn to green. Step 2: User drag selected axis/column to desired location. In PCP, axis switch simultaneously during the dragging while in SPLOM, matrices are only reordered when user \ufb01nish dragging. Step 3: User release the mouse and both views updated. SPLOM rows, columns, and cells updated with animated transition. ", "caption_bbox": [434, 763, 753, 876]}, {"image_id": 2, "file_name": "490_02.png", "page": 5, "dpi": 300, "bbox": [454, 99, 737, 237], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Self-declared prior experience of the 51 study participants.", "caption_bbox": [434, 250, 753, 263]}, {"image_id": 3, "file_name": "490_03.png", "page": 6, "dpi": 300, "bbox": [439, 99, 751, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Five commonly used strategies on Combined views.", "caption_bbox": [449, 316, 739, 329]}, {"image_id": 4, "file_name": "490_04.png", "page": 7, "dpi": 300, "bbox": [92, 650, 411, 759], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Mean results broken down by task for each of the three visualisation techniques. Results show time, accuracy and percentage of users preferring that visualisation. Yellow background indicates values that are signi\ufb01cantly different from the other two. Statistically signi\ufb01cant best values are highlighted in bold. ", "caption_bbox": [91, 776, 410, 839]}, {"image_id": 5, "file_name": "490_05.png", "page": 7, "dpi": 300, "bbox": [436, 399, 752, 631], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Mean and standard deviation for accuracy broken down by task for the three visualisation techniques in Combined view across six tasks. ", "caption_bbox": [435, 647, 754, 685]}, {"image_id": 6, "file_name": "490_06.png", "page": 7, "dpi": 300, "bbox": [437, 100, 744, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Mean and standard deviation for completion time broken down by task for the three visualisation techniques in Combined view across six tasks. ", "caption_bbox": [435, 344, 754, 382]}, {"image_id": 7, "file_name": "490_07.png", "page": 8, "dpi": 300, "bbox": [98, 99, 750, 255], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Left: (a):User preference of view in Combined view for each task. Right: (b) Strategies used in Combined view at each task (Based on aggregated eye-tracking visit duration data) ", "caption_bbox": [92, 271, 759, 297]}, {"image_id": 8, "file_name": "490_08.png", "page": 8, "dpi": 300, "bbox": [437, 322, 757, 449], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Upper (a): An example of Parallel Use strategy for 15 trials, training tasks (1-3) only display \ufb01rst 30 seconds. Lower (b): An example use of PCP 1st strategy. Strategy classi\ufb01cation rationale is described in Section 5.2. Percentages in blue and orange represents time used in PCP and SPLOM. Tick and cross represent correctness of the result (training tasks excluded). ", "caption_bbox": [436, 467, 755, 543]}, {"image_id": 9, "file_name": "490_09.png", "page": 9, "dpi": 300, "bbox": [91, 98, 412, 331], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Relative duration (bar-height) spent looking at each view in Combined view. Task 1-3 are Training tasks. ", "caption_bbox": [91, 348, 410, 374]}], "491": [{"image_id": 0, "file_name": "491_00.png", "page": 2, "dpi": 300, "bbox": [434, 99, 751, 378], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An illustration of the layout and visual encoding implemented in TagNet. The blue dot line illustrates an sentiment edge without using edge bundling for reducing edge-crossings. ", "caption_bbox": [434, 392, 753, 430]}, {"image_id": 1, "file_name": "491_01.png", "page": 3, "dpi": 300, "bbox": [99, 100, 756, 344], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: TagNet supports interaction tools for facilitating multi-scale exploration: (a) A distorted display of zoomed time slots can reveal more tags and their time-varying sentiment patterns within the zooming area; (b) Highlighting and tracking the sentiment edges of a tag can reveal its temporal distribution and associated keywords, from which the time information can be identi\ufb01ed to \ufb01lter the related messages. ", "caption_bbox": [92, 358, 759, 396]}, {"image_id": 2, "file_name": "491_02.png", "page": 4, "dpi": 300, "bbox": [99, 99, 752, 457], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Using TagNet to visually compare tweet subsets regarding the candidates of the 2016 US presidential election: (1) tags commonly used by the two candidates are placed in the center region. The shared tag @NYTime is selected for a detailed exploration; (2) The tag table summarizes all tags, the displayed tags, and the shared tags for each of the candidate subset; (3) The message table shows messages that contain the selected shared tag in the tag clouds; (4) The control panel allows users to query tags and adjust the layout aesthetics. ", "caption_bbox": [91, 472, 758, 523]}], "492": [{"image_id": 0, "file_name": "492_00.png", "page": 1, "dpi": 300, "bbox": [124, 60, 729, 553], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Overall structure of the visualization of a part of speech convolutional neural network model with visualization as input", "caption_bbox": [123, 562, 727, 575]}, {"image_id": 1, "file_name": "492_01.png", "page": 2, "dpi": 300, "bbox": [446, 100, 732, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Part of speech CNN structure", "caption_bbox": [500, 299, 688, 312]}, {"image_id": 2, "file_name": "492_02.png", "page": 4, "dpi": 300, "bbox": [111, 100, 391, 205], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Graph representation: (a) node\u2013link diagram; (b) quilt, each pair of levels in the graph produces a matrix whose cells encode edges between nodes ", "caption_bbox": [91, 209, 411, 248]}, {"image_id": 3, "file_name": "492_03.png", "page": 4, "dpi": 300, "bbox": [435, 100, 756, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Structure of the CNN PoS visualization prior to input", "caption_bbox": [444, 272, 745, 285]}, {"image_id": 4, "file_name": "492_04.png", "page": 5, "dpi": 300, "bbox": [91, 100, 410, 478], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualizing visualization: (a) color scheme; (b) node\u2013link thresholding to control which nodes and edges are visualized; (c) inspection of a node\u2019s incoming and outgoing edges; (d) query of input characters and embedding(s) that most strongly activate a node ", "caption_bbox": [91, 482, 410, 535]}, {"image_id": 5, "file_name": "492_05.png", "page": 6, "dpi": 300, "bbox": [436, 100, 753, 375], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Clustering and compression: (a) the convolutional layer clustered into three clusters with two of them expanded; (b) the convolutional layer compressed into three groups with one of them expanded ", "caption_bbox": [435, 381, 754, 434]}, {"image_id": 6, "file_name": "492_06.png", "page": 7, "dpi": 300, "bbox": [94, 101, 406, 249], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Node and layer summarization for the fully connected layers: (a) node summarization for the maxpooling, hidden and output layers; (b) layer summarization for the hidden layer; (c) layer summarization for all layers in the fully connected region ", "caption_bbox": [92, 253, 411, 306]}, {"image_id": 7, "file_name": "492_07.png", "page": 7, "dpi": 300, "bbox": [437, 101, 751, 224], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Summarized view of the large DNN", "caption_bbox": [484, 239, 703, 252]}, {"image_id": 8, "file_name": "492_08.png", "page": 8, "dpi": 300, "bbox": [91, 99, 412, 564], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: FCN PoS model: (a) overall structure; (b\u2013d) link colors hidden \u2192 output layer for visualizing, computation and ideally respectively; (e) link colors input \u2192 hidden layer for visualizing ", "caption_bbox": [91, 577, 410, 618]}, {"image_id": 9, "file_name": "492_09.png", "page": 8, "dpi": 300, "bbox": [436, 101, 754, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Noun versus verb differences in the CNN PoS model", "caption_bbox": [442, 251, 747, 264]}, {"image_id": 10, "file_name": "492_10.png", "page": 9, "dpi": 300, "bbox": [104, 99, 398, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: A large CNN: (a) feature map patterns with 12 clusters using scalability as input; (b) \ufb01rst two clusters expanded ", "caption_bbox": [91, 238, 410, 264]}], "493": [{"image_id": 0, "file_name": "493_00.png", "page": 1, "dpi": 300, "bbox": [119, 186, 730, 383], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Alignments that indicate the presence of radar signals colored by frequency values", "caption_bbox": [206, 392, 645, 405]}, {"image_id": 1, "file_name": "493_01.png", "page": 2, "dpi": 300, "bbox": [93, 257, 413, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Attributes of the emitted (a) and intercepted (b) data", "caption_bbox": [103, 361, 399, 374]}, {"image_id": 2, "file_name": "493_02.png", "page": 2, "dpi": 300, "bbox": [447, 523, 746, 578], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustration of the existing tools used in SIGINT analysis", "caption_bbox": [436, 588, 753, 601]}, {"image_id": 3, "file_name": "493_03.png", "page": 3, "dpi": 300, "bbox": [437, 270, 754, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: View encoding frequency by color and by radius position on HeloVis ", "caption_bbox": [435, 348, 754, 374]}, {"image_id": 4, "file_name": "493_04.png", "page": 3, "dpi": 300, "bbox": [92, 514, 414, 600], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Different representations of two different radar signals", "caption_bbox": [98, 613, 404, 626]}, {"image_id": 5, "file_name": "493_05.png", "page": 3, "dpi": 300, "bbox": [92, 762, 412, 843], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Different representations of a radar signal with several repeated pulses and missing values ", "caption_bbox": [92, 855, 411, 881]}], "494": [{"image_id": 0, "file_name": "494_00.png", "page": 1, "dpi": 300, "bbox": [122, 163, 738, 531], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: FraudVis interfaces: (a) Global fraud groups, (b) Part of raw data with title encoding the feature importance, (c) Group activity view for temporal sequence of fraud users\u2019 behavior, (d) User interaction view indicating relationships among users within a group, (e) The comparison of features that contribute the most to the detection result in overall and group scale, (f) Inter-group comparison for users in \ufb01ve most-similar-sized groups, (g) Tree view that decides the result and timeline of a certain user. ", "caption_bbox": [122, 536, 726, 587]}, {"image_id": 1, "file_name": "494_01.png", "page": 4, "dpi": 300, "bbox": [164, 325, 685, 514], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Result comparison between stock k-means and improvements in Case Study 2.", "caption_bbox": [217, 516, 633, 529]}, {"image_id": 2, "file_name": "494_02.png", "page": 4, "dpi": 300, "bbox": [194, 98, 658, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The work\ufb02ow of FraudVis. We offer two pipelines for different target users, an overview for experts and a set of more detailed views for domain experts and customers to drill down FraudVis with friendly instructions. ", "caption_bbox": [92, 289, 759, 315]}], "495": [{"image_id": 0, "file_name": "495_00.png", "page": 1, "dpi": 300, "bbox": [424, 60, 755, 469], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A real-world loan guarantee network formed from bank records, with each node representing an enterprise. ", "caption_bbox": [435, 468, 754, 494]}, {"image_id": 1, "file_name": "495_01.png", "page": 3, "dpi": 300, "bbox": [438, 528, 754, 633], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visualization of the network with (a) the rolling prediction risk, (b) K-shell value, and (c) authority score. ", "caption_bbox": [436, 632, 755, 658]}, {"image_id": 2, "file_name": "495_02.png", "page": 3, "dpi": 300, "bbox": [436, 329, 757, 500], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The interface for Visual Analytics for Enterprise Default Risk. We use a heatmap to code the rolling prediction risks over a month. ", "caption_bbox": [436, 499, 757, 525]}, {"image_id": 3, "file_name": "495_03.png", "page": 3, "dpi": 300, "bbox": [93, 99, 757, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of the system and tasks.", "caption_bbox": [322, 315, 529, 328]}, {"image_id": 4, "file_name": "495_04.png", "page": 4, "dpi": 300, "bbox": [439, 100, 755, 210], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) Structural hole spanner illustration example, reproduced from [15]; the structural hole spanners are editable for merging or reassigning actions. (b) Example of merging two communities on the structural hole spanner. ", "caption_bbox": [437, 211, 756, 262]}, {"image_id": 5, "file_name": "495_05.png", "page": 4, "dpi": 300, "bbox": [90, 100, 405, 552], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Defaults occur in clusters and we interactively edit the clusters. (a) 30 communities generated by a random walks algorithm; (b) 10 communities after interactive editing. The ratios for defaulting \ufb01rms are labeled separately on the left-hand side treemaps. ", "caption_bbox": [90, 551, 410, 602]}, {"image_id": 6, "file_name": "495_06.png", "page": 5, "dpi": 300, "bbox": [92, 100, 413, 312], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) guarantee network, where enterprise A (guarantor) guarantees B and C (borrowers) to get loans from the bank (lender). The (b\u2013e) graphs are classic loan guarantee patterns, speci\ufb01cally: (b) mutual guarantee, (c) revolving guarantee, (d) star shape guarantee, (e) joint liability guarantee. (f) revolving guarantees detected from a real-world loan guarantee network. ", "caption_bbox": [92, 311, 413, 387]}, {"image_id": 7, "file_name": "495_07.png", "page": 5, "dpi": 300, "bbox": [434, 100, 756, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visual analytics interface for evolving loan guarantees. The numbers in the graph are node ID ", "caption_bbox": [435, 335, 754, 361]}, {"image_id": 8, "file_name": "495_08.png", "page": 5, "dpi": 300, "bbox": [439, 372, 741, 620], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The guarantee network keeps evolving from July 2013 to April 2014. The numbers in the graph are node ID risks. Especially in a period of economic downturn, some enterprises will face operational dif\ufb01culties and the \ufb01nancial crisis will have a domino effect: the default phenomenon may spread rapidly in the network, and this could make a large number of enterprises fall into an unfavorable situation. The government and the banks always wish to monitor the default spread status and understand the complexity of the current issue of risks so that they can take precautionary measures, conduct research, and dissolve the risks to ensure that no regional or systematic \ufb01nancial risk occurs. ", "caption_bbox": [435, 624, 754, 772]}, {"image_id": 9, "file_name": "495_09.png", "page": 6, "dpi": 300, "bbox": [100, 99, 751, 316], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: One real diffusion path and the corresponding Sankey diagram.", "caption_bbox": [249, 317, 597, 330]}, {"image_id": 10, "file_name": "495_10.png", "page": 6, "dpi": 300, "bbox": [443, 348, 754, 420], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Loan guarantee process. The borrower wishing to get a loan from a bank \ufb01rst needs to sign loan guarantee contracts with guarantors before signing a loan contract. After the company receives its loan from the bank, it repays the loan by installments. ", "caption_bbox": [434, 425, 753, 476]}, {"image_id": 11, "file_name": "495_11.png", "page": 6, "dpi": 300, "bbox": [91, 341, 411, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Default path for a real network. The characters represent different enterprises. ", "caption_bbox": [91, 431, 410, 457]}, {"image_id": 12, "file_name": "495_12.png", "page": 7, "dpi": 300, "bbox": [125, 462, 377, 571], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Recall of forecasting models using different feature repre- sentation over time. Refer to Section 4.1 for the abbreviations. ", "caption_bbox": [92, 582, 412, 608]}, {"image_id": 13, "file_name": "495_13.png", "page": 7, "dpi": 300, "bbox": [110, 99, 393, 221], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Feature importance score from 2014Q3 to 2015Q4. Refer to Section 4.1 for the abbreviations. ", "caption_bbox": [435, 248, 754, 274]}, {"image_id": 14, "file_name": "495_14.png", "page": 7, "dpi": 300, "bbox": [471, 100, 722, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Statistics for communities generated by the random walk community detection algorithm [29]. ", "caption_bbox": [435, 350, 754, 376]}, {"image_id": 15, "file_name": "495_15.png", "page": 8, "dpi": 300, "bbox": [450, 716, 750, 883], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 19: (a) Pattern 15 highlighted on the loan guarantee network. (b) Pattern 15 model. (c) Alternative way to understand pattern 15. ", "caption_bbox": [436, 885, 757, 911]}, {"image_id": 16, "file_name": "495_16.png", "page": 8, "dpi": 300, "bbox": [93, 436, 760, 614], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Statistics for communities after interactive editing.", "caption_bbox": [115, 724, 387, 737]}, {"image_id": 17, "file_name": "495_17.png", "page": 8, "dpi": 300, "bbox": [99, 99, 758, 396], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 17: High default groups after interactive editing.", "caption_bbox": [298, 617, 553, 630]}, {"image_id": 18, "file_name": "495_18.png", "page": 9, "dpi": 300, "bbox": [95, 179, 755, 396], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 18: All the patterns (4-vertex-motif structures) detected from community 3. Among them, patterns 15, 16, and 17 show single-input, single-output, and feed-forward structures. ", "caption_bbox": [91, 398, 759, 424]}], "496": [{"image_id": 0, "file_name": "496_00.png", "page": 1, "dpi": 300, "bbox": [136, 60, 715, 511], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The visualization interface of high-order correlation graph (HOCG): (a) double overview+detail timeline selectors; (b) visualization controller; (c) correlation graph view; (d) the anomaly time series of individual nodes (objects); (e) visual interpretation of a selected point anomaly event; (f) the data value of the selected anomaly; (g) spatial detail view. ", "caption_bbox": [123, 510, 728, 548]}, {"image_id": 1, "file_name": "496_01.png", "page": 3, "dpi": 300, "bbox": [161, 96, 688, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The work\ufb02ow of our framework for analysis of collective anomalies.", "caption_bbox": [244, 203, 601, 216]}, {"image_id": 2, "file_name": "496_02.png", "page": 6, "dpi": 300, "bbox": [122, 99, 379, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Merging of events and event correlations over time.", "caption_bbox": [109, 251, 393, 264]}, {"image_id": 3, "file_name": "496_03.png", "page": 7, "dpi": 300, "bbox": [110, 99, 390, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Wedge-based metaphor design: (a) The node composed of multiple anomaly wedges, each wedge corresponds to a time interval having the same anomaly score on this node ; (b) When users hover one wedge on an object, the wedges having correlations with it on the other objects will be highlighted. ", "caption_bbox": [91, 202, 410, 265]}, {"image_id": 4, "file_name": "496_04.png", "page": 8, "dpi": 300, "bbox": [99, 275, 404, 503], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The dynamic HOCG of HVAC anomalies in two weeks. (a) all anomalies after \ufb01ltering with a zoom-in view. (b) the anomaly time series of three sensors in F3Z1. ", "caption_bbox": [91, 504, 410, 542]}, {"image_id": 5, "file_name": "496_05.png", "page": 8, "dpi": 300, "bbox": [95, 100, 408, 259], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The dynamic HOCG of movement anomalies in two weeks.", "caption_bbox": [91, 258, 412, 271]}, {"image_id": 6, "file_name": "496_06.png", "page": 8, "dpi": 300, "bbox": [441, 100, 759, 221], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The anomaly score time series (a) between PYoung1 and PYoung2 and (b) between PYoung1 and LBennett1. ", "caption_bbox": [435, 222, 754, 248]}, {"image_id": 7, "file_name": "496_07.png", "page": 9, "dpi": 300, "bbox": [105, 98, 396, 500], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Software analysis case study: (a) the initial HOCG view with a smaller time window close to the crash point selected; (b) zooming out to a large time window for the root cause analysis. ", "caption_bbox": [91, 502, 410, 540]}, {"image_id": 8, "file_name": "496_08.png", "page": 10, "dpi": 300, "bbox": [106, 98, 392, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The illustration of compromised software vulnerabilities: (a) normal case; (b) under malicious external input. ", "caption_bbox": [91, 246, 410, 272]}], "497": [{"image_id": 0, "file_name": "497_00.png", "page": 2, "dpi": 300, "bbox": [434, 708, 756, 878], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The pipeline for data processing and analysis.", "caption_bbox": [464, 879, 725, 892]}, {"image_id": 1, "file_name": "497_01.png", "page": 4, "dpi": 300, "bbox": [137, 100, 718, 276], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: System work\ufb02ow: After data preprocessing and interactive feature extraction/con\ufb01guration (Section 4.1), our system can support real-time monitoring (Section 4.2) and detail inspection & model updating (Section 4.3). ", "caption_bbox": [92, 277, 759, 301]}, {"image_id": 2, "file_name": "497_02.png", "page": 5, "dpi": 300, "bbox": [154, 99, 349, 554], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a) In the Correlation View, two concentrated rings (i.e., R1 and R2 ) and a node-link diagram with force-directed layout are de- signed to provide an overview of all sensors. Users can interactively choose target monitoring sensors. (b) For a certain target monitoring sensor, interactive analysis is supported to identify correlated sen- sors and facilitate feature extractions. ", "caption_bbox": [91, 555, 410, 621]}, {"image_id": 3, "file_name": "497_03.png", "page": 6, "dpi": 300, "bbox": [118, 100, 733, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) In-situ Monitoring View shows the risks detected by the monitoring algorithm for all target sensors of a module in real-time; (b) Summary View provides an overview of long-term trends of equipment conditions, which also keeps updating in real-time. ", "caption_bbox": [92, 265, 759, 289]}, {"image_id": 4, "file_name": "497_04.png", "page": 7, "dpi": 300, "bbox": [165, 101, 689, 397], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The system interface for detail inspection: (a) Multi-facet Filter Panel enables ef\ufb01cient exploration of detected high-risk cases; (b) Inspection View supports a closer inspection of vector time-series and analyzes their correlations. ", "caption_bbox": [92, 398, 759, 422]}, {"image_id": 5, "file_name": "497_05.png", "page": 8, "dpi": 300, "bbox": [117, 99, 388, 264], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Training Set View shows the distribution of chosen time- series in the training set and supports an interactive updating. ", "caption_bbox": [92, 265, 411, 289]}, {"image_id": 6, "file_name": "497_06.png", "page": 9, "dpi": 300, "bbox": [136, 100, 712, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: (a) In-situ Monitoring View and (b) Summary View for real-time monitoring of Module 2 based on the data of March.", "caption_bbox": [132, 234, 714, 247]}], "498": [{"image_id": 0, "file_name": "498_00.png", "page": 1, "dpi": 300, "bbox": [424, 60, 755, 494], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Heuristic Layout (Sugiyama)", "caption_bbox": [504, 507, 683, 520]}, {"image_id": 1, "file_name": "498_01.png", "page": 1, "dpi": 300, "bbox": [435, 534, 755, 732], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Optimal Layout", "caption_bbox": [535, 746, 652, 759]}, {"image_id": 2, "file_name": "498_02.png", "page": 3, "dpi": 300, "bbox": [465, 100, 723, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Two (of four) con\ufb01gurations for nodes u1 , v1 , u2 and v2 .", "caption_bbox": [446, 247, 741, 263]}, {"image_id": 3, "file_name": "498_03.png", "page": 3, "dpi": 300, "bbox": [122, 100, 380, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The two con\ufb01gurations in which edges u1 v1 and u2 v2 cross.", "caption_bbox": [91, 247, 412, 261]}, {"image_id": 4, "file_name": "498_04.png", "page": 4, "dpi": 300, "bbox": [435, 99, 757, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Sankey Example with Grouping Constraints", "caption_bbox": [470, 311, 719, 324]}], "499": [{"image_id": 0, "file_name": "499_00.png", "page": 1, "dpi": 300, "bbox": [110, 60, 739, 544], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A timeline showing the \ufb01rst Monday of the High School Communication Network dataset. The timeline is generated by comparing the commute-time 0-dimensional homological features of the time-varying network using the bottleneck distance. The 0-dimensional features capture connected component-like behaviors in the data at multiple scales. The timeline differentiates periods of highly connected behaviors, such as instances C, D, E, and F, from periods of low or no activity, such as A, B, or G. ", "caption_bbox": [122, 551, 727, 604]}, {"image_id": 1, "file_name": "499_01.png", "page": 2, "dpi": 300, "bbox": [141, 101, 710, 268], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The pipeline of our approach. An ordered sequence of graphs representing a time-varying graph is given as an input. Each graph instance is individually embedded into a metric space (Section 3.1). The topological features of each (metric-space-embedded) graph instance are extracted by computing persistent homology of its corresponding Rips \ufb01ltration; the topological features are encoded by persistence diagrams and visualized as barcodes (Section 3.2). Finally, persistence diagrams are compared and the structural changes among the graph instances are visualized (Sections 3.3 and 3.4). ", "caption_bbox": [91, 275, 758, 341]}, {"image_id": 2, "file_name": "499_02.png", "page": 3, "dpi": 300, "bbox": [126, 725, 379, 815], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The (a) shortest-path and (b) commute-time distance measured from a source point on a 2-dimensional surface embedded in R3 . Blue indicates the regions closest to the source. ", "caption_bbox": [92, 822, 411, 863]}, {"image_id": 3, "file_name": "499_03.png", "page": 3, "dpi": 300, "bbox": [490, 465, 701, 520], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Edges (left) and triangles (right) in a Rips complex.", "caption_bbox": [448, 530, 741, 543]}, {"image_id": 4, "file_name": "499_04.png", "page": 4, "dpi": 300, "bbox": [110, 99, 392, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Constructing a Rips \ufb01ltration from a distance matrix on a graph. The numbers above each Rips complex indicate the diameter at which the complex is computed. The corresponding 0-persistence diagrams are shown in the gray box to the right of each complex. ", "caption_bbox": [92, 396, 411, 449]}, {"image_id": 5, "file_name": "499_05.png", "page": 4, "dpi": 300, "bbox": [449, 432, 741, 849], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: From left to right, 1st row: three weighted graph instances G0 , G1 and G2 representing a time-varying graph. 2nd row: each graph instance is embedded into a metric space, represented by a shortest-path distance matrix. 3rd row shows the \ufb01ltrations in which topologically signi\ufb01cant events occur, resulting in persistence barcodes in the 4th row. 5th row: the persistence diagrams are compared pairwise using bottleneck and Wasserstein distance. ", "caption_bbox": [435, 866, 755, 958]}, {"image_id": 6, "file_name": "499_06.png", "page": 5, "dpi": 300, "bbox": [133, 99, 718, 414], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Timeline comparison for the seven weekdays of the High School Communications dataset together with graph instances along these timelines. These graph instances validate the different levels of communication visible using our approach. ", "caption_bbox": [92, 414, 759, 440]}, {"image_id": 7, "file_name": "499_07.png", "page": 6, "dpi": 300, "bbox": [452, 98, 738, 240], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Timeline of the High School Communications dataset for 1-dimensional features. The timeline was generated by comparing the commute-time features using bottleneck distance. The single outlier is a graph with a high persistence cycle. To highlight that feature, the graph is parameterized and visualized with a cyclic rainbow colormap [54]. ", "caption_bbox": [434, 247, 754, 326]}, {"image_id": 8, "file_name": "499_08.png", "page": 6, "dpi": 300, "bbox": [117, 700, 387, 875], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Top: Persistent homology timeline for the \ufb01rst Monday and Tuesday of the High School Communications dataset. Bottom: Timeline counting the number of events (sum of all weights) in each graph instance. The timeline shows how different features can be identi\ufb01ed in our approach as compared to edge counts alone. ", "caption_bbox": [91, 884, 412, 950]}, {"image_id": 9, "file_name": "499_09.png", "page": 6, "dpi": 300, "bbox": [438, 658, 744, 890], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Comparing shortest-path bottleneck ((a) and (b)) and Wasserstein ((c) and (d)) distance on 0-dimensional ((a) and (c)) and 1-dimensional ((b) and (d)) features in the EU E-Mail dataset. Since bottleneck distance captures the most perturbed feature, the result may be noisy. Wasserstein distance captures variation across all features in the graph, resulting in a smoother pattern. ", "caption_bbox": [434, 897, 755, 976]}, {"image_id": 10, "file_name": "499_10.png", "page": 7, "dpi": 300, "bbox": [102, 573, 402, 681], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Clustering of the weekly behavior in the EU E-Mail dataset using the Wasserstein distance on 1-dimensional features based on the shortest-path metric. The clusters shows four primary patterns and one outlier pattern (bottom). The number of weeks in each cluster is listed in the lower right. ", "caption_bbox": [92, 688, 411, 754]}, {"image_id": 11, "file_name": "499_11.png", "page": 7, "dpi": 300, "bbox": [123, 100, 731, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Highlights from the EU E-Mail dataset using the Wasserstein distance on 1-dimensional persistence diagrams based on shortest-path metric. A & B show graphs from a timeframe of normal weekly cyclic activity. C & F show timeframes of limited activity from December of 2003 and 2004 during the Christmas and New Years holidays. D shows an unexpected boost in activity on June 13, 2004 that is correlated with the release of results for the EU Parliamentary Election. E shows a 3- to 4-week period of low activity in November and December of 2004. We could not identify any externally correlated event to explain this occurrence. ", "caption_bbox": [91, 253, 761, 319]}, {"image_id": 12, "file_name": "499_12.png", "page": 8, "dpi": 300, "bbox": [91, 99, 406, 245], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Testing edge submodularity (property 3) using the graphs from Figure 13 (c). ", "caption_bbox": [435, 201, 754, 227]}, {"image_id": 13, "file_name": "499_13.png", "page": 8, "dpi": 300, "bbox": [435, 748, 740, 918], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Testing focus awareness (property 4). Each colored curve represents a graph among three randomly generated graphs. The difference between the targeted corruption and the random corruption is plotted against the percentage of the deleted edges. ", "caption_bbox": [435, 925, 756, 978]}, {"image_id": 14, "file_name": "499_14.png", "page": 8, "dpi": 300, "bbox": [90, 338, 414, 919], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Testing weight awareness (property 2). Points (W (eA,Ce ),W (eA, Be )) on and above the diagonal correspond to instances where property 2 is satis\ufb01ed. Three sets of graphs are represented by blue, orange, and green points respectively. ", "caption_bbox": [91, 926, 410, 979]}, {"image_id": 15, "file_name": "499_15.png", "page": 9, "dpi": 300, "bbox": [161, 101, 692, 222], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Study of the stability for different similarity measures under small perturbations. The x-axis of each plot shows the percentage of edges deleted from the graph. The y-axis represents the difference between the perturbed graph and the original graph. The y-axes are normalized to [0, 1] based upon the maximum observed values. ", "caption_bbox": [92, 233, 759, 274]}], "50": [{"image_id": 0, "file_name": "50_00.png", "page": 2, "dpi": 300, "bbox": [86, 169, 415, 950], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualisation pipeline", "caption_bbox": [147, 965, 339, 980]}, {"image_id": 1, "file_name": "50_01.png", "page": 3, "dpi": 300, "bbox": [427, 642, 751, 794], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Entity-relationship diagram", "caption_bbox": [473, 807, 703, 822]}, {"image_id": 2, "file_name": "50_02.png", "page": 4, "dpi": 300, "bbox": [459, 52, 719, 439], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Angle inhomogeneous model algorithm controls ", "caption_bbox": [427, 449, 749, 481]}, {"image_id": 3, "file_name": "50_03.png", "page": 5, "dpi": 300, "bbox": [130, 181, 359, 597], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Small candidate plagiarism cluster", "caption_bbox": [108, 615, 379, 630]}, {"image_id": 4, "file_name": "50_04.png", "page": 5, "dpi": 300, "bbox": [443, 66, 735, 1046], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Plagiarism examples", "caption_bbox": [495, 1064, 681, 1079]}, {"image_id": 5, "file_name": "50_05.png", "page": 6, "dpi": 300, "bbox": [475, 55, 705, 1057], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visualising course structure", "caption_bbox": [473, 1075, 703, 1090]}, {"image_id": 6, "file_name": "50_06.png", "page": 8, "dpi": 300, "bbox": [98, 610, 392, 991], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Inclusion of method metrics", "caption_bbox": [124, 1009, 363, 1024]}, {"image_id": 7, "file_name": "50_07.png", "page": 8, "dpi": 300, "bbox": [116, 53, 720, 503], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Class cluster", "caption_bbox": [346, 517, 485, 532]}], "500": [{"image_id": 0, "file_name": "500_00.png", "page": 1, "dpi": 300, "bbox": [123, 60, 731, 387], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A systematic overview of possible combination of visual channels (here, using modulo transformation: v = a \u00d7 M + b). Each sub-attribute a and b is mapped onto a separate corresponding visual channel. In case of combination of the same visual channels, those have been shown in two separate spaces. ", "caption_bbox": [124, 399, 730, 438]}, {"image_id": 1, "file_name": "500_01.png", "page": 2, "dpi": 300, "bbox": [90, 828, 412, 935], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visualization pipeline as formalized by Card et al. [7]. The step of visual mapping is the focus of this work. ", "caption_bbox": [91, 948, 410, 975]}, {"image_id": 2, "file_name": "500_02.png", "page": 3, "dpi": 300, "bbox": [90, 100, 412, 157], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: In horizon graph, the resulting quotients and reminders are mapped onto saturation and the vertical position, respectively. The sign of data attribute\u2019s value is mapped on hue (red for negative, blue for positive). Adapted from [15]. ", "caption_bbox": [91, 169, 410, 220]}, {"image_id": 3, "file_name": "500_03.png", "page": 3, "dpi": 300, "bbox": [91, 249, 407, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: In Order of Magnitude Markers each data attribute is divided into a coef\ufb01cient and a exponent of the logarithmic expression. Expo- nents are represented by colored bars and coef\ufb01cients by grey ones. The sign of each data value is mapped onto hue (red/blue). Adapted from [5]. ", "caption_bbox": [91, 338, 412, 401]}, {"image_id": 4, "file_name": "500_04.png", "page": 3, "dpi": 300, "bbox": [90, 421, 412, 490], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Slick Graph applies a frequency separation transformation on each data attribute. The low frequencies are mapped onto the verti- cal position (the smoothed line) and the high frequencies are encoded on the brightness of the area under the line. Adapted from [11]. ", "caption_bbox": [91, 503, 411, 554]}, {"image_id": 5, "file_name": "500_05.png", "page": 4, "dpi": 300, "bbox": [99, 101, 753, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Complete selection of visual mappings examined in this study displaying a dummy data set. Except line chart which was included as the reference point, all other techniques use composite visual mapping with modulo division as the transformation function. ", "caption_bbox": [91, 387, 758, 413]}, {"image_id": 6, "file_name": "500_06.png", "page": 5, "dpi": 300, "bbox": [437, 100, 754, 428], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Interface of the experiment, presenting a pair of charts with Size-Hue mapping with three-layers modulo transformation. (top) global view, (bottom) detail on the questions and answers. ", "caption_bbox": [435, 447, 755, 485]}, {"image_id": 7, "file_name": "500_07.png", "page": 6, "dpi": 300, "bbox": [103, 350, 742, 473], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Effect of data transformation function: modulo vs. logarithmic transformation.", "caption_bbox": [224, 302, 627, 315]}, {"image_id": 8, "file_name": "500_08.png", "page": 7, "dpi": 300, "bbox": [454, 476, 738, 908], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Effect of the real value difference on logarithmic error: comparing the \ufb01ve mappings. ", "caption_bbox": [436, 923, 756, 949]}, {"image_id": 9, "file_name": "500_09.png", "page": 7, "dpi": 300, "bbox": [110, 774, 394, 910], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Effect of the real value difference on discrimination accu- racy: Modulo vs. logarithmic transformation. ", "caption_bbox": [91, 925, 411, 951]}, {"image_id": 10, "file_name": "500_10.png", "page": 8, "dpi": 300, "bbox": [94, 100, 410, 372], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Effect of the real value difference on completion time: linear regression lines with 95% con\ufb01dence intervals. Horizon graph (HG) is the most vulnerable to the real value difference. ", "caption_bbox": [92, 387, 411, 425]}], "501": [{"image_id": 0, "file_name": "501_00.png", "page": 1, "dpi": 300, "bbox": [424, 60, 757, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Fragmentation process of a fullerene C60 that is positively ionized by 44 elementary charges (qmean = 40, see Section 4). (a) Initial state, not charged, state at (b) t = 125 fs, and (c) t = 375 fs of the fragments. The molecule is represented with the ball-and- stick model together with the fragment tree (colored), our space-time representation of its dynamics. Atoms (balls) are colored by their charge qi (in elementary charges). The deviation from the bond rest length (in A\u030a) is encoded in bonds (sticks) and in the fragment tree, which is color-coded according to the maximum bond length of the corresponding molecule fragment. ", "caption_bbox": [436, 400, 755, 526]}, {"image_id": 1, "file_name": "501_01.png", "page": 2, "dpi": 300, "bbox": [92, 101, 413, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of the interrelations and levels of detail (curved arrows pointing to \ufb01ner level) between our topological (orange) and geometric (blue) components. The statistical methods agglomerate results from multiple simulations (framed image stacks) into aggre- gated views (single image). Their comparison serves as probability estimation of individual results. Aggregations typically contain clusters that can be inspected by spatial analysis. ", "caption_bbox": [92, 285, 411, 373]}, {"image_id": 2, "file_name": "501_02.png", "page": 2, "dpi": 300, "bbox": [437, 101, 753, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A fullerene fragment j (belonging to graph Gi ) with its atoms (dots) and bonds (black lines) drawn with low saturation. Three cycles are visible around its center of mass ci, j (circle). A short time after ti , the bonds marked in red break, resulting in one of the cycles being broken and subfragments l, l + 1, and l + 2 being created (each belonging to Gi+1 ). Our method derives several quantities, namely the distances between the centers of mass (dotted lines; Section 3.1), the number of cycles (Section 3.2), cycle lengths (colored numbers; Sec- tion 3.3), and the trajectories (dashed lines) that connect fragments over space and time (Section 3.4). ", "caption_bbox": [435, 246, 754, 373]}, {"image_id": 3, "file_name": "501_03.png", "page": 3, "dpi": 300, "bbox": [91, 305, 404, 473], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The behavior of characteristic curves for different excitation energies depends on whether a \ufb01xed charge (no stochastic variation), or a varying change (following a Gaussian distribution) is used. ", "caption_bbox": [88, 483, 407, 521]}, {"image_id": 4, "file_name": "501_04.png", "page": 3, "dpi": 300, "bbox": [93, 100, 405, 249], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Histograms of eccentricities with Gaussian \ufb01t (orange), showing the pairwise distances of fragments at the \ufb01nal time step. ", "caption_bbox": [88, 260, 407, 286]}, {"image_id": 5, "file_name": "501_05.png", "page": 3, "dpi": 300, "bbox": [442, 99, 753, 435], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Simple cycles (fragment holes), averaged over simulations with varying charge qmean . Only the relevant initial phase is shown. ", "caption_bbox": [435, 445, 754, 472]}, {"image_id": 6, "file_name": "501_06.png", "page": 4, "dpi": 300, "bbox": [439, 100, 752, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Characteristic curves, calculated alongside the simulations, help detecting the variability of an ensemble of simulations. The 95% con\ufb01dence band becomes tighter with increasing ensemble size, showing that the mean function is a suitable descriptor. ", "caption_bbox": [435, 232, 754, 283]}, {"image_id": 7, "file_name": "501_07.png", "page": 4, "dpi": 300, "bbox": [94, 100, 408, 350], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparison of spatio-temporal visualizations at example of Figure 1c. (a) Direct visualization of fragments, (b) center of mass trajectories by molecule snapshoting, (c) trajectories for each indi- vidual atom, and our fragment tree approach (d) without additional quantities, and with focus on fragments (e) and tree (f). ", "caption_bbox": [91, 361, 410, 424]}, {"image_id": 8, "file_name": "501_08.png", "page": 5, "dpi": 300, "bbox": [95, 98, 413, 372], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: (a), (b): Fragment hole visualization of two simulations with equal eccentricity values (approximately 205 A\u030a) at the \ufb01nal time step. (c), (d): Corresponding fragment trees for q = 60 and t = 175 fs. Please refer to Figures 1 and 6 for the color legends. ", "caption_bbox": [92, 383, 411, 434]}], "502": [{"image_id": 0, "file_name": "502_00.png", "page": 1, "dpi": 300, "bbox": [112, 60, 742, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Modeling, evaluation and visualization of uncertain geometry. a) Modeling of uncertainty through multi-variate normal distributions. b) Uncertain geometry implied by uncertain points and lines. c) Evaluation grid with user-de\ufb01ned size to evaluate uncertain geometry. d) Evaluation of uncertain geometry at each grid point. e) Visualization of uncertain geometry showing the \u03bc-surface and U-surfaces based on different iso-values. ", "caption_bbox": [122, 431, 726, 483]}, {"image_id": 1, "file_name": "502_01.png", "page": 3, "dpi": 300, "bbox": [434, 100, 755, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: One dimensional example of two uncertainty-aware points. The probability density of each points outputs different results for the U-surface according to the selected treshold. ", "caption_bbox": [434, 233, 755, 271]}, {"image_id": 2, "file_name": "502_02.png", "page": 4, "dpi": 300, "bbox": [118, 100, 735, 355], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Resulting visualizations based on the presented methodology. a)-c) uncertainty-aware visualization of an aneurysm geometry. d)-e) uncertainty-aware visualization of an \ufb02uid phase surface. ", "caption_bbox": [92, 370, 760, 396]}], "503": [{"image_id": 0, "file_name": "503_00.png", "page": 1, "dpi": 300, "bbox": [103, 60, 753, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Secondary structure assignment uncertainty of photoactive yellow protein of E. coli (PDB ID: 2ZOI). The left image shows a typical ribbon diagram, illustrating the secondary structure assignments computed by STRIDE. The center image shows our uncertainty ribbon diagram with disagreement of four different secondary structure assignments mapped to shape distortion. The sequence diagram cutouts to the right depict assignments for two different sub-chains using two techniques: The upper one reveals an uncertain part of the sequence by stacking the individual results; the lower one shows a consensus \u03b1-helix with uncertain ends, where the deviating results at these ends are sorted by increasing uncertainty from bottom to top. ", "caption_bbox": [123, 419, 729, 496]}, {"image_id": 1, "file_name": "503_01.png", "page": 2, "dpi": 300, "bbox": [90, 100, 412, 228], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Secondary structure elements, letters, and colors by assign- ment method. ", "caption_bbox": [435, 98, 756, 124]}, {"image_id": 2, "file_name": "503_02.png", "page": 4, "dpi": 300, "bbox": [97, 100, 752, 265], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Overview of our uncertainty visualization technique. We start with protein data from RCSB or a simulation, i.e., atomic coordinates (a). By computing the secondary structure, we obtain a distribution of possible secondary structure elements per amino acid (b). Then, we aggregate across different sources of uncertainty such as time and discrepancy of multiple assignment methods (c). Finally, we render ribbon and sequence diagrams, depicting the combined distribution (d). ", "caption_bbox": [91, 281, 760, 332]}, {"image_id": 3, "file_name": "503_03.png", "page": 5, "dpi": 300, "bbox": [90, 873, 411, 925], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Typical sequence diagram consisting of a sequence row and an amino acid row. Helices are rendered as sine waves, strands as arrows. Colors and visual primitives are detailed in Table 1. ", "caption_bbox": [90, 937, 409, 975]}, {"image_id": 4, "file_name": "503_04.png", "page": 5, "dpi": 300, "bbox": [435, 99, 756, 331], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Stacked assignments. The grouped and sorted version (a) scales better than the projected version (b). ", "caption_bbox": [435, 341, 754, 367]}, {"image_id": 5, "file_name": "503_05.png", "page": 5, "dpi": 300, "bbox": [435, 381, 756, 486], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Multiple assignments combined into one sequence view: (a) morphed wireframe geometry, (b) \ufb01nal histogram view with uncer- tainty values encoded as gray bars above the sequence. High, dark gray bars denote high uncertainty, whereas low, lightly colored bars represent less uncertainty and more agreement. Where the uncer- tainty value reaches 0.0, the rendered structure equals the structure in the normal sequence views (cf. Figure 4). ", "caption_bbox": [435, 496, 756, 584]}, {"image_id": 6, "file_name": "503_06.png", "page": 6, "dpi": 300, "bbox": [435, 231, 754, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparison of alpha blending (left) and screen door trans- parency (right). From a distance, there is almost no visible difference. In close-up, the colors from Table 1 are visible (i.e., no color mixing). ", "caption_bbox": [435, 362, 756, 400]}, {"image_id": 7, "file_name": "503_07.png", "page": 6, "dpi": 300, "bbox": [91, 99, 412, 231], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Ribbon diagram of a protein. The original ribbon diagram shown in (a) and (b) is distorted based on the computed uncertainty value, resulting in (c). ", "caption_bbox": [91, 238, 410, 276]}, {"image_id": 8, "file_name": "503_08.png", "page": 6, "dpi": 300, "bbox": [435, 100, 756, 153], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison of the different geometry distortion methods. Compared to the sine distortion (b), the triangle distortion (c) needs less geometry to work properly. The dashed orange box illustrates one amino acid (amplitude ka = 1, frequency k f = 6). The specular highlights of the triangle waveform emphasize the shape more clearly. ", "caption_bbox": [435, 160, 756, 223]}, {"image_id": 9, "file_name": "503_09.png", "page": 7, "dpi": 300, "bbox": [86, 99, 756, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Our uncertainty visualization applied to insulin (PDB ID: 1RWE). The sequence diagram shows different assignment methods and our inferred agreement structure, stacked on top of each other. At amino acids for which all algorithms agree, only the agreement structure is shown. The inset on the left shows the behavior of the internal thresholds of the PROSIGN algorithm for the highlighted part. The inset to the right shows the uncertainty value mapped to frequency in geometry in addition to geometry morphing and screen door transparency. ", "caption_bbox": [86, 287, 755, 339]}, {"image_id": 10, "file_name": "503_10.png", "page": 8, "dpi": 300, "bbox": [146, 100, 357, 276], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Uncertainty of the secondary structure derived by aggre- gating the changes that occurred during a simulation. This conveys the in\ufb02uence of dynamics on the secondary structure. ", "caption_bbox": [91, 288, 411, 326]}, {"image_id": 11, "file_name": "503_11.png", "page": 8, "dpi": 300, "bbox": [434, 100, 756, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Visualization of positional uncertainty (i.e., \ufb02exibility com- puted by Root Mean Square Fluctuation) of the wild type of a dehalo- genase protein (left) and a mutant (right). As observable, the mutant is much more stable than the wild type. Both proteins were rendered as tubes instead of ribbons with coloring by secondary structure. ", "caption_bbox": [435, 251, 755, 314]}], "504": [{"image_id": 0, "file_name": "504_00.png", "page": 3, "dpi": 300, "bbox": [91, 326, 412, 439], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of one round of particle tracing. When N is 1, it needs three rounds for particles to trace through 3 blocks. But if N is 3, only one round of tracing is enough. ", "caption_bbox": [91, 443, 410, 481]}, {"image_id": 1, "file_name": "504_01.png", "page": 3, "dpi": 300, "bbox": [94, 98, 758, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Work\ufb02ow of our parallel particle tracing framework. Starting with the initial assignments of the raw data, particles are traced through a multiround process. Dynamic data repartitioning is performed after each round of tracing. Then with the new data assignments, the subsequent round repeats to trace particles. When all particles are \ufb01nished, this process will terminate. ", "caption_bbox": [91, 271, 758, 309]}, {"image_id": 2, "file_name": "504_02.png", "page": 4, "dpi": 300, "bbox": [86, 97, 752, 233], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: 2D example of workload estimation based on ADG. (a) During particle tracing, we build the access dependency graph on the \ufb02y; (b) For the originating block #1 with 8 particles in it, we predict the blocks that will be accessed and the number of particles in these blocks at each tracing depth level; (c) The workload of the originating block #1 is estimated as the sum of all the involved blocks in (b). ", "caption_bbox": [86, 236, 753, 274]}, {"image_id": 3, "file_name": "504_03.png", "page": 5, "dpi": 300, "bbox": [436, 99, 756, 244], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: (a) Streamline rendering of the Nek5000 data; (b) Pathline rendering of the Isabel data. ", "caption_bbox": [435, 248, 754, 274]}, {"image_id": 4, "file_name": "504_04.png", "page": 5, "dpi": 300, "bbox": [91, 99, 412, 344], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Data repartitioning according to the change of workloads (shown in the squares with red outline) estimated after one round of particle tracing; (b) maximal data duplication between partitions with different tracing depths. Each partition is bounded by a colored dashed line. The copies of duplicated blocks will be also added to the corresponding partitions. Note that data is duplicated only when the tracing depth is larger than one. ", "caption_bbox": [91, 347, 410, 435]}, {"image_id": 5, "file_name": "504_05.png", "page": 6, "dpi": 300, "bbox": [92, 99, 760, 497], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Performance and percentage breakdown for the analysis of the Nek5000 data. Figures (a) and (b) show the results of strong-scaling tests, while (c) and (d) show the results of weak-scaling tests. In each stacked bar, time for I/O, data repartitioning, particle tracing, and communication are encoded in different colors. At each kind of process count, the \ufb01ve stacked histograms represent the baseline method and our method with N = 1, 2, 3, 4, respectively. ", "caption_bbox": [91, 500, 760, 552]}, {"image_id": 6, "file_name": "504_06.png", "page": 7, "dpi": 300, "bbox": [91, 549, 759, 728], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Strong-scaling tests using the Nek5000 data with different numbers of processes to evaluate the parameter bp. Panels (a), (b), and (c) show the test results with different bp under tracing depth of 4. ", "caption_bbox": [91, 734, 759, 760]}, {"image_id": 7, "file_name": "504_07.png", "page": 7, "dpi": 300, "bbox": [90, 100, 759, 469], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Performance of a 64-process run with the Nek5000 data. (a) Gantt chart using the baseline method. (b) Gantt chart using our method. In the Gantt charts, each row represents a process, and the times for I/O, data repartitioning, particle tracing, and communication are encoded in different colors. (c) Bar chart showing the workload distribution of the blocks. (d) Line chart showing the evolution of load-balancing indicator. In the line chart, the dashed line represents the baseline method, while the solid line represents our method. The time axes of the two Gantt charts and the line chart are aligned for comparison. ", "caption_bbox": [91, 476, 760, 539]}, {"image_id": 8, "file_name": "504_08.png", "page": 8, "dpi": 300, "bbox": [92, 98, 760, 454], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Strong-scaling tests using the Isabel data with different numbers of processes. The performance benchmarks include the total running time, particle tracing time, and the overall level of load balance. Panels (a), (b), and (c) show the test results with different tracing depths, while panels (d), (e), and (f) show the comparison results using different numbers of time intervals (i.e., parameter tb) under a tracing depth of 3. ", "caption_bbox": [91, 457, 758, 495]}, {"image_id": 9, "file_name": "504_09.png", "page": 9, "dpi": 300, "bbox": [91, 98, 411, 237], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Performance comparison between our method and the k-d tree method [35] using the Isabel data with different numbers of processes. ", "caption_bbox": [91, 240, 410, 278]}], "505": [{"image_id": 0, "file_name": "505_00.png", "page": 3, "dpi": 300, "bbox": [458, 715, 732, 806], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Illustration of an LSTM network, and its unrolled view.", "caption_bbox": [447, 819, 742, 832]}, {"image_id": 1, "file_name": "505_01.png", "page": 3, "dpi": 300, "bbox": [114, 368, 387, 609], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An illustration of the mapping from particle trajectories to sequences. The passed block sequence of the blue particle is trans- formed to a sequence of movements prepended by its seeding block. The passed blocks of the yellow and green particles are totally differ- ent, but their movement sequences share a common subsequence highlighted in red boxes. ", "caption_bbox": [91, 622, 412, 698]}, {"image_id": 2, "file_name": "505_02.png", "page": 4, "dpi": 300, "bbox": [91, 445, 412, 499], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: LSTM-based network architecture used in our approach. Sizes of input and output data are shown between layers. ", "caption_bbox": [92, 512, 413, 538]}, {"image_id": 3, "file_name": "505_03.png", "page": 5, "dpi": 300, "bbox": [436, 98, 755, 394], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Hit ratios under different numbers of predictions using the model of different (a) numbers of training samples, (b) hidden sizes of the LSTM layer, (c) numbers of stacked LSTM layers, and (d) block sizes. ", "caption_bbox": [435, 408, 754, 459]}, {"image_id": 4, "file_name": "505_04.png", "page": 7, "dpi": 300, "bbox": [91, 100, 761, 379], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Work\ufb02ow of our parallel particle tracing framework with deep learning model-driven prediction and prefetching. The processing steps in preprocessing and tracing stages are distinguished by colors of arrows. ", "caption_bbox": [91, 392, 758, 418]}, {"image_id": 5, "file_name": "505_05.png", "page": 7, "dpi": 300, "bbox": [91, 604, 412, 691], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Three datasets used in our performance testing: (a) Hurri- cane Isbael, (b) GEOS-5 Simulation, and (c) Ocean Simulation. ", "caption_bbox": [91, 704, 411, 730]}, {"image_id": 6, "file_name": "505_06.png", "page": 8, "dpi": 300, "bbox": [434, 683, 754, 927], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Full-range analysis results of running time (a-c) and data usage (d-f) under different #processes. ", "caption_bbox": [434, 941, 753, 967]}, {"image_id": 7, "file_name": "505_07.png", "page": 8, "dpi": 300, "bbox": [91, 438, 410, 650], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Local-range analysis results of running time (a-c) and data usage (d-f) under different #processes. ", "caption_bbox": [90, 664, 409, 690]}, {"image_id": 8, "file_name": "505_08.png", "page": 8, "dpi": 300, "bbox": [435, 289, 755, 499], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Local-range analysis results of running time (a-c) and data usage (d-f) under different #seeds. ", "caption_bbox": [434, 513, 753, 539]}, {"image_id": 9, "file_name": "505_09.png", "page": 9, "dpi": 300, "bbox": [92, 441, 411, 648], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Full-range analysis results of running time (a-c) and data usage (d-f) under different #seeds. ", "caption_bbox": [91, 662, 410, 688]}], "506": [{"image_id": 0, "file_name": "506_00.png", "page": 2, "dpi": 300, "bbox": [125, 99, 380, 202], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A schematic diagram of the rotor structure of the compressor stage.", "caption_bbox": [106, 213, 395, 224]}, {"image_id": 1, "file_name": "506_01.png", "page": 2, "dpi": 300, "bbox": [435, 99, 756, 237], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A schematic diagram of the proposed analysis method. Our off-line learning and in situ prediction based analysis strategy allows the experts to study the evolution of features in large-scale data sets in an effective and timely manner. ", "caption_bbox": [435, 247, 754, 281]}, {"image_id": 2, "file_name": "506_02.png", "page": 3, "dpi": 300, "bbox": [457, 99, 732, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Interactive interface for selecting the region of interest from data.", "caption_bbox": [453, 313, 734, 324]}, {"image_id": 3, "file_name": "506_03.png", "page": 4, "dpi": 300, "bbox": [435, 99, 756, 199], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Figure 5a: A synthetic bivariate training data generated from two 2D mul- tivariate Gaussian distributions centered at (2,8) and (8,2) respectively; Figure 5c: Trained Gaussian membership functions (GMF) for the sample bivariate data; Figure 5b: Conceptual scheme of fuzzy clustering based rule identi\ufb01cation. ", "caption_bbox": [435, 211, 755, 257]}, {"image_id": 4, "file_name": "506_04.png", "page": 4, "dpi": 300, "bbox": [123, 100, 380, 214], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Interactive selection of samples for training where the stalled regions are roughly shown using a high entropy value isosurface. In the left image, the sample points highlighted (within the sphere in red) are selected from a stable region, whereas, in the right image the samples are picked from a stalled region. The differences in patterns among the three selected variable values shown in the PCP are notable. ", "caption_bbox": [91, 224, 411, 282]}, {"image_id": 5, "file_name": "506_05.png", "page": 5, "dpi": 300, "bbox": [506, 100, 686, 224], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The Gaussian membership functions (GMF) generated using sample data collected from a simulation run with CMF=13.8 kg/s. Each color indicates member- ship functions of a rule in the image. ", "caption_bbox": [435, 233, 755, 267]}, {"image_id": 6, "file_name": "506_06.png", "page": 5, "dpi": 300, "bbox": [91, 100, 413, 255], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visual analytics interface to study the stall features (CMF = 13.8 kg/s) esti- mated in situ through fuzzy rule-based system and local mass \ufb02ow rate computation. ", "caption_bbox": [91, 265, 411, 288]}, {"image_id": 7, "file_name": "506_07.png", "page": 6, "dpi": 300, "bbox": [102, 98, 750, 189], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visualization of entropy, Uvel, and temperature isosurfaces for locating the stalled regions in the CMF=13.8 kg/s data set. Figure 8a, 8b, and 8c show the isosurfaces at T = 375 when the global mass \ufb02ow rate drops as shown in the bottom left panel of Figure 6 indicating stall inception. Figure 8d, 8e, and 8f depict the isosurfaces of the same variables at later time, T = 560 when the stall is well developed. It can be seen that two separate stalled regions are formed as marked in the images. ", "caption_bbox": [91, 203, 758, 237]}, {"image_id": 8, "file_name": "506_08.png", "page": 7, "dpi": 300, "bbox": [450, 99, 741, 237], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Result of simulation run with CMF=14.0 kg/s. This resulted in a stalled condition which is visible from the stallness and mass \ufb02ow deviation plot. ", "caption_bbox": [435, 247, 754, 270]}, {"image_id": 9, "file_name": "506_09.png", "page": 7, "dpi": 300, "bbox": [118, 99, 384, 187], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Visualization of isosurfaces of the fuzzy system predicted stallness \ufb01eld. Figure 9a shows isosurface of 0.8 at T = 375, and Figure 9b shows isosurface of 0.8 at T = 560. The detected regions at both of these time steps correspond well with the regions identi\ufb01ed in Figure 8 validating the correctness of our method. ", "caption_bbox": [90, 200, 410, 246]}, {"image_id": 10, "file_name": "506_10.png", "page": 8, "dpi": 300, "bbox": [435, 100, 757, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Result of simulation run with CMF=14.5 kg/s. The simulation resulted in a stable run which is observed from uniform mass \ufb02ow chart and clean stallness plot. ", "caption_bbox": [435, 263, 754, 286]}, {"image_id": 11, "file_name": "506_11.png", "page": 8, "dpi": 300, "bbox": [122, 300, 381, 382], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Distribution-based spatial anomaly plot of entropy variable for the run with CMF=14.2 kg/s, proposed in [13]. ", "caption_bbox": [91, 392, 410, 415]}, {"image_id": 12, "file_name": "506_12.png", "page": 8, "dpi": 300, "bbox": [435, 300, 757, 382], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Spatial anomaly plot of entropy for the simulation run with CMF = 14.5 kg/s. It shows anomaly plot for revolutions 5-8. The left chart shows distribution-based spatial anomaly [13], and the right chart provides the point-wise spatial anomaly [9]. ", "caption_bbox": [435, 392, 754, 426]}, {"image_id": 13, "file_name": "506_13.png", "page": 8, "dpi": 300, "bbox": [90, 100, 413, 252], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Result of simulation run with CMF=14.2 kg/s. Provided CMF value drives the simulation into a stalled state which our proposed method is able to detect correctly. ", "caption_bbox": [91, 262, 410, 285]}], "507": [{"image_id": 0, "file_name": "507_00.png", "page": 2, "dpi": 300, "bbox": [492, 99, 699, 181], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An example of performing the strati\ufb01ed sampling on two bit vectors representing two bins b0 and b1 . Upper row: two bit vectors with full samples. Lower row: two bit vectors after drawing 50% of the samples from each block. ", "caption_bbox": [435, 191, 754, 244]}, {"image_id": 1, "file_name": "507_01.png", "page": 3, "dpi": 300, "bbox": [467, 100, 725, 171], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: An example of creating a compressed bit vector from the samples ID using WAH32. The data size is 1000 in this example. ", "caption_bbox": [435, 181, 754, 207]}, {"image_id": 2, "file_name": "507_02.png", "page": 3, "dpi": 300, "bbox": [122, 100, 380, 178], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Comparisons between two data blocks with different data complexities. Drawing samples evenly in both regions may cause insuf\ufb01cient information stored in the data block shown in the left and redundant information stored in the right data block. ", "caption_bbox": [91, 188, 410, 241]}, {"image_id": 3, "file_name": "507_03.png", "page": 3, "dpi": 300, "bbox": [123, 242, 380, 331], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The concept of our information guided strati\ufb01ed sampling.", "caption_bbox": [91, 340, 410, 353]}, {"image_id": 4, "file_name": "507_04.png", "page": 4, "dpi": 300, "bbox": [442, 100, 760, 181], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: An example of an assignment problem. (a) A1, A2, A3, and A4 represent four agents and T1, T2, T3, and T4 represent four tasks. One cost value is associated with each agent and task. (b) An example of a cost matrix. (C) The assignment result for the cost matrix shown in (b) ", "caption_bbox": [434, 194, 755, 260]}, {"image_id": 5, "file_name": "507_05.png", "page": 4, "dpi": 300, "bbox": [169, 100, 332, 207], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The comparisons between the bitmap generated from the data within a local block (A), and the bitmap generated from the data of one row (B). ", "caption_bbox": [90, 216, 409, 255]}, {"image_id": 6, "file_name": "507_06.png", "page": 5, "dpi": 300, "bbox": [123, 99, 381, 198], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: An example of determining the number of agents based on the value histograms of the subsampled data and the raw data ", "caption_bbox": [92, 209, 411, 235]}, {"image_id": 7, "file_name": "507_07.png", "page": 6, "dpi": 300, "bbox": [132, 249, 717, 474], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The comparison between our data recovery approach RCcost and two other approaches, RCnearest and RCmean , for different datasets.", "caption_bbox": [90, 488, 757, 503]}, {"image_id": 8, "file_name": "507_08.png", "page": 6, "dpi": 300, "bbox": [107, 100, 742, 211], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The comparison between our data sampling approach IGStS and two other approaches, AStRS and StRS, for different datasets.", "caption_bbox": [98, 221, 748, 234]}, {"image_id": 9, "file_name": "507_09.png", "page": 7, "dpi": 300, "bbox": [98, 100, 765, 214], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The performance comparison of our IGStS and RCcost approach with different parameter settings. (a) is the comparison for using different block size. (b) is the comparison for using different \u03c3 . (c), (d), and (e) are the comparisons for using different bin size. ", "caption_bbox": [91, 226, 758, 254]}, {"image_id": 10, "file_name": "507_10.png", "page": 8, "dpi": 300, "bbox": [186, 341, 663, 461], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Visual comparisons of isosurfaces 0.42 of Mixture Fraction of Combustion data. The sampling percentage for (a) to (c) are all set to 0.16. The isosurfaces are extracted from the reconstructed \ufb01elds which are generated from different sampling and recovery approaches. ", "caption_bbox": [90, 472, 757, 498]}, {"image_id": 11, "file_name": "507_11.png", "page": 8, "dpi": 300, "bbox": [130, 99, 720, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Visual comparisons for the HD(CP)2 dataset. The \ufb01gures in the \ufb01rst row are the rendered images for the reconstructed data. The \ufb01gures in the second row are the error images that show the differences between the raw data and the reconstructed data. ", "caption_bbox": [90, 298, 757, 327]}, {"image_id": 12, "file_name": "507_12.png", "page": 9, "dpi": 300, "bbox": [463, 267, 736, 377], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Performance comparisons for RCcost . Left: computation time for each block. Right: computation time vs. block size. ", "caption_bbox": [436, 389, 755, 416]}, {"image_id": 13, "file_name": "507_13.png", "page": 9, "dpi": 300, "bbox": [99, 100, 754, 218], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Visual comparisons of Pressure \ufb01eld of Turbine dataset.", "caption_bbox": [265, 229, 584, 242]}], "508": [{"image_id": 0, "file_name": "508_00.png", "page": 3, "dpi": 300, "bbox": [91, 99, 413, 324], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Critical points (spheres, blue: minima, white: saddles, green: maxima) and persistence diagrams of a clean (top) and noisy (bottom) 2D scalar \ufb01eld (from blue to green). From left to right: original 2D data, 3D terrain representation, persistence diagram. The diagrams clearly exhibit in both cases two large pairs, corresponding to the two main hills. In the noisy diagram (bottom), small bars near the diagonal correspond to noisy features in the data. In this scenario, the bottleneck distance between the diagrams is the persistence of the largest unmatched feature (red pair in the zoomed inset, center right) while the Wasserstein distance is the sum of the persistence of all unmatched pairs. ", "caption_bbox": [92, 336, 412, 474]}, {"image_id": 1, "file_name": "508_01.png", "page": 4, "dpi": 300, "bbox": [91, 100, 761, 287], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of our topologically controlled lossy compression scheme on a 2D elevation example. First the input data f : M \u2192 R is pre-simpli\ufb01ed into a function f   ((a), from top to bottom) to remove all topological features below a user persistence tolerance \u03b5 (as illustrated by the persistence diagram (b)). The compression is achieved by a topologically adaptive quantization of the range, which is segmented along the critical values of f   (c). A quantized function f    is constructed ((c), bottom) to only use a \ufb01nite set of possible data values for regular vertices, hence guaranteeing data compression, while still enforcing original values at critical points. This approach can be extended with point wise error control ((d)), by re\ufb01ning each quantization interval of f   larger than a target width ((d), bottom). Moreover, our approach can be combined with any third party compressor (e) to further improve the geometry of the compressed data. ", "caption_bbox": [92, 299, 760, 388]}, {"image_id": 2, "file_name": "508_02.png", "page": 5, "dpi": 300, "bbox": [90, 99, 412, 171], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Topologically controlled compression with pointwise error control. When pre-simplifying the input data f : M \u2192 R (left) into f   (center), the value variation of each simpli\ufb01ed extremum e equals the persistence P of the pair it belongs to, which is bounded by con- struction by \u03b5: | f (e) \u2212 f   (e)| = P \u2264 \u03b5 [11, 46]. When adding pointwise error control, each interval is subdivided such that its width does not exceed \u03b5 (right). Thus, when constructing the quantized function f    which maps each vertex to the middle of its interval, each simpli\ufb01ed extremum e of f may further move by a snapping distance s to the middle of its interval, which is itself bounded by half the width of the interval (\u03b5/2). Thus, | f (e) \u2212 f    (e)| = P + s \u2264 \u03b5 + \u03b5/2. ", "caption_bbox": [91, 183, 412, 322]}, {"image_id": 3, "file_name": "508_03.png", "page": 7, "dpi": 300, "bbox": [438, 773, 752, 885], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparison to the SQ compressor [27] (green: SQ-D, blue: SQ-R, red: our approach). Left: average normalized Wasserstein distance between the persistence diagrams of the input and decom- pressed data, for increasing compression rates. Right: average compression factors for increasing target persistence thresholds \u03b5. ", "caption_bbox": [435, 897, 755, 963]}, {"image_id": 4, "file_name": "508_04.png", "page": 7, "dpi": 300, "bbox": [457, 415, 739, 600], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Topologically controlled compression with (b) and without (c) compression-time simpli\ufb01cation. Topological simpli\ufb01cation (c to d) removes all critical point pairs not present in the topological index (red circles) and exactly maintains the others [46]. Thus, simplifying the data only at decompression (d) yields identical decompressed data (d vs b). The quantized function then admits a richer topology (c vs b), which deteriorates compression rates. ", "caption_bbox": [435, 614, 756, 702]}, {"image_id": 5, "file_name": "508_05.png", "page": 7, "dpi": 300, "bbox": [90, 100, 760, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Compression of the noisy 2D data set from Fig. 1 ((a), 80,642 bytes, top: 2D data, bottom: 3D terrain). In all cases (c-e), our compression algorithm was con\ufb01gured to maintain topological features more persistent than 20% of the function range, as illustrated with the persistence diagrams ((b), top: original noisy data D( f ), bottom: decompressed data D(g)). Our topology controlled compression (c), augmented with pointwise error control (d), and combined with ZFP [31] ((e), one bit per scalar) yields compression rates of 163, 50 and 14 respectively. ", "caption_bbox": [91, 321, 758, 372]}, {"image_id": 6, "file_name": "508_06.png", "page": 7, "dpi": 300, "bbox": [93, 386, 409, 487], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Performance analysis of our compression scheme (topolog- ical control only). Left: Compression rate for various 3D data sets, as a function of the target persistence threshold \u03b5 (percentage of the function range). Right: Bottleneck distance between  the persistence                                                                   diagrams of the input and decompressed data, d\u221eB D( f ), D(g) , for increasing target persistence thresholds \u03b5. ", "caption_bbox": [91, 500, 411, 577]}, {"image_id": 7, "file_name": "508_07.png", "page": 8, "dpi": 300, "bbox": [435, 100, 756, 390], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Wasserstein distance between the persistence diagrams of the original and decompressed data (\u03b5 = 1%). First line: ZFP 1bit/scalar, followed by a topology cleanup procedure. Second line: ZFP 1bit/scalar, augmented with our approach. ", "caption_bbox": [435, 883, 756, 934]}, {"image_id": 8, "file_name": "508_08.png", "page": 8, "dpi": 300, "bbox": [90, 100, 408, 211], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Topology driven data segmentation with multi-scale split trees, on the original data (left) and the data compressed with our approach (right). Top to bottom: persistence diagrams, sliced views of the data, output segmentations. The analysis yields compatible outcomes with and without compression, as shown with the bottom row, which exhibits identical segmentations (compression rate: 360). ", "caption_bbox": [435, 394, 754, 470]}, {"image_id": 9, "file_name": "508_09.png", "page": 9, "dpi": 300, "bbox": [91, 98, 412, 407], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 4: Rand index between the outputs of a data segmentation pipeline based on topological methods (Sect. 5.3), before and after compression, for several methods at compatible compression rates. ", "caption_bbox": [435, 878, 754, 916]}], "509": [{"image_id": 0, "file_name": "509_00.png", "page": 1, "dpi": 300, "bbox": [129, 60, 720, 418], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Illustrative visualization techniques such as cutaways or ghosting views are used to emphasize important concealed structures. Typically such structures are carefully segmented prior to the visualization. Our approach allows for the simple creation of illustrative visualizations without prior processing of the data. The leftmost image shows the visible human data set manipulated with our technique to reveal the skeleton and inner organs. The next image shows an illustrative visualization of the human cochlea. The second image from the right shows an illustrative cutaway of a beetle. The rightmost image shows a cutaway illustration of a high voltage power outlet. ", "caption_bbox": [123, 433, 730, 509]}, {"image_id": 1, "file_name": "509_01.png", "page": 3, "dpi": 300, "bbox": [91, 360, 413, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Overview of our approach for smart surrogate widgets and its integration into the volume visualization pipeline. To \ufb01t the surrogate widget into the rendered image, we analyze the visibility and compute a set of prominent points for the given visualization state. In the next step, we \ufb01t a sphere into the computed point set. The new sphere is combined with the existing widget. The updated widget can be used for further volume manipulation. ", "caption_bbox": [92, 546, 413, 634]}, {"image_id": 2, "file_name": "509_02.png", "page": 3, "dpi": 300, "bbox": [435, 337, 752, 519], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Smart surrogate widget rendered into the visualized volume. The widget is emphasized through a glow in this image. ", "caption_bbox": [434, 533, 755, 559]}, {"image_id": 3, "file_name": "509_03.png", "page": 3, "dpi": 300, "bbox": [105, 100, 373, 274], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: (a) Illustrators often approximate complex shapes with a set of circles and the connections between those (Illustration by Paulina Kawenka). (b) A set of only three spheres already gives a good approximation of the shape of a human head. ", "caption_bbox": [92, 282, 411, 333]}, {"image_id": 4, "file_name": "509_04.png", "page": 3, "dpi": 300, "bbox": [483, 100, 706, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Borders of structures Sk are detected by local maxima of \u03b2 . This de\ufb01nes a point cloud for the whole scene which is used for widget \ufb01tting. ", "caption_bbox": [434, 277, 753, 315]}, {"image_id": 5, "file_name": "509_05.png", "page": 4, "dpi": 300, "bbox": [92, 100, 411, 190], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: When a new sphere is added to the widget, it is connected to the closest existing sphere. As such the widgets can branch, as shown in the rightmost image. ", "caption_bbox": [91, 202, 410, 240]}, {"image_id": 6, "file_name": "509_06.png", "page": 4, "dpi": 300, "bbox": [449, 100, 764, 270], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: (a) The iris size can be changed by pulling on the circular iris opening. (b) The iris can be rotated by moving a handle representing the center of the iris opening. ", "caption_bbox": [439, 282, 758, 320]}, {"image_id": 7, "file_name": "509_07.png", "page": 4, "dpi": 300, "bbox": [100, 256, 405, 479], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The widget size can be changed by pulling on the outer frame. The selected widget part is emphasized with a glow. ", "caption_bbox": [91, 491, 410, 517]}, {"image_id": 8, "file_name": "509_08.png", "page": 4, "dpi": 300, "bbox": [458, 353, 746, 524], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The wedge can be adjusted through two independent sphere arcs (a) and can be rotated around the view vector by pulling on the poles of the wedge (b). ", "caption_bbox": [439, 531, 758, 569]}, {"image_id": 9, "file_name": "509_09.png", "page": 5, "dpi": 300, "bbox": [109, 100, 392, 346], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The upper row shows a simpli\ufb01ed cross section of the widget. The widget is opened with the wedge tool and the focus area is rendered transparent. The size of an area inside the smart widgets that is unaffected by the cone and the wedge manipulations can be changed with a simple slider. The computed volume can either be shown in with the same transfer function as the remaining data (a) or with a second transfer function (b). ", "caption_bbox": [91, 354, 410, 442]}, {"image_id": 10, "file_name": "509_10.png", "page": 5, "dpi": 300, "bbox": [434, 451, 756, 625], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: The standard setup of the smart surrogate interface. The numbered interface components are explained in detail in section 3.3. ", "caption_bbox": [435, 637, 756, 663]}, {"image_id": 11, "file_name": "509_11.png", "page": 5, "dpi": 300, "bbox": [443, 100, 750, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The upper row shows a simpli\ufb01ed cross section of the widget. The upper part of the armadillo is covered with a smart surrogate widget consisting of two spheres. Through a combination of cones and wedges it is now possible to look into the body by reducing the opacity inside the widget using (a) the initial transfer function or (b) the alternate transfer function. ", "caption_bbox": [434, 349, 753, 425]}, {"image_id": 12, "file_name": "509_12.png", "page": 6, "dpi": 300, "bbox": [129, 100, 378, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Comparison of normal volume rendering (regular) to our approach with additional handling of smart widgets (widgets) as mea- sured on an NVidia GeForce GTX 780 GPU with a viewport size of 967 \u00d7 967 pixels. ", "caption_bbox": [435, 198, 756, 250]}, {"image_id": 13, "file_name": "509_13.png", "page": 7, "dpi": 300, "bbox": [449, 99, 734, 567], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: (a) Medical illustration of the cochlea from Humboldt- University Berlin. (b) An illustrative visualization obtained with our technique by a \ufb01rst-time user during the user study. ", "caption_bbox": [435, 574, 755, 612]}, {"image_id": 14, "file_name": "509_14.png", "page": 7, "dpi": 300, "bbox": [100, 388, 402, 552], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Our algorithm tries to position the spheres close to the selected boundary. When \ufb02at surfaces are present this results in spheres that are bigger than the covered structure. ", "caption_bbox": [92, 565, 411, 603]}, {"image_id": 15, "file_name": "509_15.png", "page": 7, "dpi": 300, "bbox": [101, 99, 402, 321], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Example of a cutaway illustration generated using a combi- nation of the wedge and iris tool to reveal the inner structures of the beetle. ", "caption_bbox": [92, 336, 412, 374]}, {"image_id": 16, "file_name": "509_16.png", "page": 8, "dpi": 300, "bbox": [443, 323, 752, 489], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 19: (a) The smart surrogate widget covers the outlet with two spheres \ufb01rst \ufb01tting to the rounder top part and the lower end. To open the volume, we used the wedge tool for the lower sphere and the iris tool in the upper sphere. Both spheres are active in this image. (b) The volume covered by the iris and the wedge is shown with a different transfer function to depict the structure in front of the cut. (c) An inner volume is in\ufb02ated and shown with the same transfer function as used for the wedge and iris tool. ", "caption_bbox": [435, 502, 756, 603]}, {"image_id": 17, "file_name": "509_17.png", "page": 8, "dpi": 300, "bbox": [103, 100, 407, 441], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 17: (a) The skull of a pawpawsaurus seen from underneath, cavities of interest are not visible. (b) The \ufb01rst sphere of the widget is created, and we open the wedge tool. (c) The wedge tool is opened to reveal the nasal cavity. (d) A second sphere is added to the widget and iris tool is opened. (e) The iris tool is opened to reveal the brain cavity. (f) The \ufb01nal illustration showing the nasal and brain cavities. ", "caption_bbox": [91, 453, 411, 529]}, {"image_id": 18, "file_name": "509_18.png", "page": 8, "dpi": 300, "bbox": [455, 100, 734, 247], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 18: Using standard volume rendering methods the transfer function can be set to (a) show the outer geometry, to (b) show the inner structures, or to (c) show both using transparency. ", "caption_bbox": [435, 255, 754, 293]}, {"image_id": 19, "file_name": "509_19.png", "page": 9, "dpi": 300, "bbox": [99, 335, 413, 488], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 21: (a) The smart surrogate widget is opened to remove outer layers of the data. (b) The inner volume of the widget is displayed with only a single entropy level. ", "caption_bbox": [92, 501, 411, 539]}, {"image_id": 20, "file_name": "509_20.png", "page": 9, "dpi": 300, "bbox": [102, 98, 412, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 20: (a) Direct volume visualization of a supernova simulation entropy \ufb01eld. (b) Automatically placed smart surrogate widget. ", "caption_bbox": [92, 265, 411, 291]}], "51": [{"image_id": 0, "file_name": "51_00.png", "page": 2, "dpi": 300, "bbox": [69, 299, 407, 489], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1. Problem View.XSL applied to XML:LP.", "caption_bbox": [94, 499, 387, 514]}, {"image_id": 1, "file_name": "51_01.png", "page": 2, "dpi": 300, "bbox": [125, 551, 354, 1028], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2 MPS source file, CH09B", "caption_bbox": [141, 1038, 341, 1053]}, {"image_id": 2, "file_name": "51_02.png", "page": 2, "dpi": 300, "bbox": [426, 451, 758, 1049], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3. XML source file, CH09B", "caption_bbox": [481, 1057, 687, 1072]}, {"image_id": 3, "file_name": "51_03.png", "page": 3, "dpi": 300, "bbox": [77, 754, 774, 967], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7. Source file with SVG Dual.XSL applied. Compare to Figure 5.", "caption_bbox": [198, 986, 626, 1001]}, {"image_id": 4, "file_name": "51_04.png", "page": 3, "dpi": 300, "bbox": [77, 597, 767, 689], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6. Source file with SVG Solution.XSL applied, sorted descending by optimal value. Compare to Figure 4.", "caption_bbox": [82, 698, 742, 713]}, {"image_id": 5, "file_name": "51_05.png", "page": 3, "dpi": 300, "bbox": [105, 81, 717, 229], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. Solution View.XSL applied to XML:LP, solution information", "caption_bbox": [204, 236, 622, 251]}, {"image_id": 6, "file_name": "51_06.png", "page": 3, "dpi": 300, "bbox": [77, 477, 767, 596], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5. Solution View.XSL applied to XML:LP, constraint information", "caption_bbox": [197, 428, 628, 443]}, {"image_id": 7, "file_name": "51_07.png", "page": 5, "dpi": 300, "bbox": [76, 770, 407, 997], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9. XML:LP transform outline", "caption_bbox": [130, 1014, 351, 1029]}, {"image_id": 8, "file_name": "51_08.png", "page": 5, "dpi": 300, "bbox": [78, 392, 406, 713], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8. Screen shot of MPStrans.", "caption_bbox": [136, 720, 345, 735]}, {"image_id": 9, "file_name": "51_09.png", "page": 6, "dpi": 300, "bbox": [421, 679, 749, 1044], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12. MPStrans, Lindo solution to XML", "caption_bbox": [449, 1051, 719, 1066]}, {"image_id": 10, "file_name": "51_10.png", "page": 6, "dpi": 300, "bbox": [420, 80, 772, 554], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11. Lindo solution to our example model.", "caption_bbox": [439, 566, 730, 581]}, {"image_id": 11, "file_name": "51_11.png", "page": 8, "dpi": 300, "bbox": [84, 190, 415, 829], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14. XML:LP with the solution information.", "caption_bbox": [90, 837, 391, 852]}], "510": [{"image_id": 0, "file_name": "510_00.png", "page": 2, "dpi": 300, "bbox": [501, 678, 693, 787], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An illustration of our proxy where the image plane is shown on the upper right. Each pixel, such as the pixel shown in blue, stores a depth ordered list of sub-frustums (shown on the left). A distribution is associated with each sub-frustum containing a summary of the information within the sub-frustum. ", "caption_bbox": [435, 800, 754, 866]}, {"image_id": 1, "file_name": "510_01.png", "page": 2, "dpi": 300, "bbox": [499, 243, 693, 442], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An overview of our proposed technique.", "caption_bbox": [475, 452, 714, 465]}, {"image_id": 2, "file_name": "510_02.png", "page": 4, "dpi": 300, "bbox": [100, 139, 408, 245], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The proxy data structure for one view and one time step.", "caption_bbox": [92, 258, 408, 271]}, {"image_id": 3, "file_name": "510_03.png", "page": 4, "dpi": 300, "bbox": [512, 241, 670, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The green curve is the opacity function. The red dots are 100 samples drawn from a data distribution (red curve). Most red dots have no signi\ufb01cant opacity, so most of the sampling time is wasted. The blue dots are 100 samples drawn from the importance distribution (blue curve), which incorporates both the data distribu- tion (red curve) and the opacity function (green curve) by Equation 4. Most blue dots have signi\ufb01cant opacity. In order to avoid occlusion, red and blue circles are drawn separately on the top and bottom of the \ufb01gure. We normalize the highest peaks of the data distribution and importance distribution to 1 in order to visualize them clearly. ", "caption_bbox": [434, 371, 756, 502]}, {"image_id": 4, "file_name": "510_04.png", "page": 6, "dpi": 300, "bbox": [96, 507, 406, 680], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Static uncertainty visualization on the right bottom part of the 1st time step of Turbine dataset. (a) is the \u201dCool2Warn\u201d color map which is used to visualize the uncertainty. The color closer to blue indicates low uncertainty and the color closer to white or red indicates higher uncertainty. (b) is a grayscale image calculated from the difference between images rendered by the raw dataset and our proxy, and a given transfer function. (c) is the uncertainty visualization from our technique. This image is calculated by Algo- rithm 3. We highlight the regions which has high error in (b) and the corresponding regions in (c). ", "caption_bbox": [91, 692, 412, 823]}, {"image_id": 5, "file_name": "510_05.png", "page": 7, "dpi": 300, "bbox": [94, 717, 408, 880], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The 25th time step of Isabel dataset. (a) is the transfer function. The higher scalar value is at the top. The black curve is the opacity function and the right hand side indicates the highr opacity. (b) is the image rendered from the raw data. (c) is the image rendered from our proxy. ", "caption_bbox": [90, 892, 409, 958]}, {"image_id": 6, "file_name": "510_06.png", "page": 7, "dpi": 300, "bbox": [94, 439, 407, 601], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The 12th time step of Turbine dataset. (a) is the transfer function. The higher scalar value is at the top. The black curve is the opacity function and the right hand side indicates the highr opacity. (b) is the image rendered from the raw data. (c) is the image rendered from our proxy. ", "caption_bbox": [90, 613, 409, 679]}, {"image_id": 7, "file_name": "510_07.png", "page": 8, "dpi": 300, "bbox": [443, 622, 741, 711], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The impact of different histogram\u2019s bin counts on the image quality, proxy generation time and rendering time. ", "caption_bbox": [435, 723, 754, 749]}, {"image_id": 8, "file_name": "510_08.png", "page": 8, "dpi": 300, "bbox": [93, 99, 410, 262], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Quality (PSNR) of images rendered by different transfer function. Reported numbers of OF1, OF2 and OF3 are the average PSNR of all time steps of a dataset. Reported numbers of RTF are the mean and variance from PSNRs of 10 random transfer functions. ", "caption_bbox": [434, 99, 753, 152]}, {"image_id": 9, "file_name": "510_09.png", "page": 8, "dpi": 300, "bbox": [101, 355, 399, 428], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Image quality comparison between Importance sampling and basic Monte Carlo sampling for varying numbers of re-sample count. ", "caption_bbox": [91, 440, 410, 479]}, {"image_id": 10, "file_name": "510_10.png", "page": 9, "dpi": 300, "bbox": [100, 183, 404, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: The impact of different image resolutions on the image quality, proxy generation time and rendering time. In this test, the image width and height are the same. The X-axis in each sub\ufb01gure is the image width and height. ", "caption_bbox": [92, 284, 411, 337]}, {"image_id": 11, "file_name": "510_11.png", "page": 9, "dpi": 300, "bbox": [443, 153, 744, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: The impact of different size budgets on the image quality, proxy generation time and rendering time. ", "caption_bbox": [435, 254, 755, 280]}], "511": [{"image_id": 0, "file_name": "511_00.png", "page": 1, "dpi": 300, "bbox": [100, 184, 754, 620], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Screenshot of the integrated visualization system for phenotypic character networks. The main view shows the phenotypic character network, including numerical information of the phenotypic characters and the literature information. The left column and bottom of the screen display the \ufb01ltering interface for the network and the related text information, respectively. ", "caption_bbox": [122, 633, 726, 671]}, {"image_id": 1, "file_name": "511_01.png", "page": 3, "dpi": 300, "bbox": [100, 99, 403, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Data processing pipeline of the proposed system.", "caption_bbox": [110, 274, 387, 287]}, {"image_id": 2, "file_name": "511_02.png", "page": 4, "dpi": 300, "bbox": [99, 375, 403, 537], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Result of network visualization by FM3 and circular layout.", "caption_bbox": [91, 553, 408, 566]}, {"image_id": 3, "file_name": "511_03.png", "page": 4, "dpi": 300, "bbox": [100, 100, 403, 323], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Operational interface for \ufb01ltering the phenotypic characters networks in CausalNet. ", "caption_bbox": [91, 336, 410, 362]}, {"image_id": 4, "file_name": "511_04.png", "page": 4, "dpi": 300, "bbox": [443, 100, 747, 291], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Results of SEM analysis of phenotypic characters selected in CausalNet using iSEM. ", "caption_bbox": [435, 303, 754, 329]}], "512": [{"image_id": 0, "file_name": "512_00.png", "page": 1, "dpi": 300, "bbox": [122, 60, 736, 594], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Comparison of proxy graphs of as19990606 AS graph (5% sampling): (a)-(e) SP proxy graph method [18], (f)-(j) BCP-W proxy graph methods, (k)-(o) BCP-E proxy graph methods. ", "caption_bbox": [122, 593, 727, 621]}, {"image_id": 1, "file_name": "512_01.png", "page": 2, "dpi": 300, "bbox": [172, 139, 332, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The as19990606 AS (Autonomous Systems) graph visualized using FM 3 . ", "caption_bbox": [92, 288, 411, 314]}, {"image_id": 2, "file_name": "512_02.png", "page": 4, "dpi": 300, "bbox": [460, 328, 731, 739], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Comparison of average KS values of sampling quality met- rics (Closeness, CC, Degree, LCC, AND) of real-world graphs: proxy graphs computed by SP [18] (blue), BCP-W (red) and BCP-E (yellow) methods. Smaller KS values mean better results. ", "caption_bbox": [435, 742, 755, 793]}, {"image_id": 3, "file_name": "512_03.png", "page": 4, "dpi": 300, "bbox": [91, 197, 412, 300], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Statistics of real-world graphs.", "caption_bbox": [503, 246, 686, 259]}, {"image_id": 4, "file_name": "512_04.png", "page": 5, "dpi": 300, "bbox": [111, 158, 392, 956], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Improvement in KS distance by BCP methods over SP meth- ods. More negative values indicate that BCP algorithms are better. ", "caption_bbox": [91, 957, 411, 985]}, {"image_id": 5, "file_name": "512_05.png", "page": 6, "dpi": 300, "bbox": [91, 99, 759, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Comparison of proxy graphs of f acebook graph with 5% sampling ratio, computed by RV, RV-W and RV-E.", "caption_bbox": [155, 298, 691, 311]}, {"image_id": 6, "file_name": "512_06.png", "page": 6, "dpi": 300, "bbox": [91, 330, 759, 525], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Comparison of proxy graphs of f lights lcc graph with 10% sampling ratio, computed by RE, RE-W and RE-E.", "caption_bbox": [146, 524, 698, 537]}, {"image_id": 7, "file_name": "512_07.png", "page": 6, "dpi": 300, "bbox": [91, 556, 759, 740], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Comparison of proxy graphs of G13 graph with 15% sampling ratio, computed by RV, RV-W and RV-E.", "caption_bbox": [163, 740, 682, 753]}, {"image_id": 8, "file_name": "512_08.png", "page": 6, "dpi": 300, "bbox": [91, 771, 759, 957], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Comparison of proxy graphs of hamsterster lcc graph with 15% sampling ratio, computed by RE, RE-W and RE-E.", "caption_bbox": [136, 957, 709, 970]}, {"image_id": 9, "file_name": "512_09.png", "page": 7, "dpi": 300, "bbox": [92, 303, 760, 490], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Big graph data sets.", "caption_bbox": [183, 590, 318, 603]}, {"image_id": 10, "file_name": "512_10.png", "page": 7, "dpi": 300, "bbox": [92, 100, 760, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Comparison of proxy graphs of yeast lcc graph with 25% sampling ratio, computed by RE, RE-W and RE-E.", "caption_bbox": [148, 490, 698, 503]}, {"image_id": 11, "file_name": "512_11.png", "page": 7, "dpi": 300, "bbox": [504, 517, 699, 809], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Comparison of average improvement in KS metrics by BCP proxy graphs. More negative values indicate that BCP proxy graphs are better than SP proxy graphs. ", "caption_bbox": [437, 812, 756, 852]}, {"image_id": 12, "file_name": "512_12.png", "page": 8, "dpi": 300, "bbox": [154, 811, 349, 915], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Comparison of improvement in proxy quality metrics for proxy graphs of comAmazon graph, computed by BCP methods over SP methods. ", "caption_bbox": [91, 918, 410, 958]}, {"image_id": 13, "file_name": "512_13.png", "page": 8, "dpi": 300, "bbox": [154, 645, 349, 756], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Comparison of proxy quality metrics for proxy graphs of big graphs. The ratio was computed from the proxy quality metrics of BCP-W over BCP-E methods. The larger values the better improve- ment. ", "caption_bbox": [91, 759, 411, 810]}, {"image_id": 14, "file_name": "512_14.png", "page": 8, "dpi": 300, "bbox": [155, 311, 351, 613], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Comparison of improvement in KS metrics of comAmazon graph. ", "caption_bbox": [91, 614, 410, 641]}, {"image_id": 15, "file_name": "512_15.png", "page": 8, "dpi": 300, "bbox": [92, 100, 760, 283], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Visual comparison of proxy graphs of topology graph with 30% sampling ratio, computed by RV, RV-W and RV-E.", "caption_bbox": [137, 282, 712, 296]}, {"image_id": 16, "file_name": "512_16.png", "page": 9, "dpi": 300, "bbox": [442, 271, 761, 561], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 19: Summary of improvement of proxy graphs computed by BCP algorithms over SP methods using average KS metrics for large graph instances. ", "caption_bbox": [435, 563, 754, 601]}, {"image_id": 17, "file_name": "512_17.png", "page": 9, "dpi": 300, "bbox": [84, 525, 409, 642], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 18: Comparison of average runtime of DBCP at 30% with sequential 1-server (blue), 2-server (orange), and 5-server (green) for migration and as19990606 graphs. ", "caption_bbox": [91, 643, 410, 682]}, {"image_id": 18, "file_name": "512_18.png", "page": 9, "dpi": 300, "bbox": [91, 100, 760, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 17: Comparison of average runtime of DBCP on synthetic graphs: sequential 1-server (blue), 2-server (orange), and 5-server (green).", "caption_bbox": [99, 242, 750, 258]}], "513": [{"image_id": 0, "file_name": "513_00.png", "page": 1, "dpi": 300, "bbox": [91, 60, 761, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Optimally folding a linear layout: process tree [15] computed from the 2012 Business Process Intelligence Challenge [3].", "caption_bbox": [121, 442, 726, 455]}, {"image_id": 1, "file_name": "513_01.png", "page": 3, "dpi": 300, "bbox": [284, 381, 411, 487], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The width (wi ), top-height (hT )                        i and bottom-height (hBi ) of a block, spine dotted. ", "caption_bbox": [301, 499, 412, 550]}, {"image_id": 2, "file_name": "513_02.png", "page": 3, "dpi": 300, "bbox": [495, 99, 697, 190], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Two foldings of four blocks with maximum width W . Left: A greedy approach. Right: The optimal folding. ", "caption_bbox": [435, 201, 754, 228]}, {"image_id": 3, "file_name": "513_03.png", "page": 3, "dpi": 300, "bbox": [150, 720, 351, 937], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Packing blocks: Top: rows can overlap vertically as long as the blocks do not overlap. Bottom: rows cannot overlap vertically. ", "caption_bbox": [91, 948, 410, 975]}, {"image_id": 4, "file_name": "513_04.png", "page": 4, "dpi": 300, "bbox": [444, 100, 745, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Drawing blocks on connectors.", "caption_bbox": [499, 279, 688, 292]}, {"image_id": 5, "file_name": "513_05.png", "page": 4, "dpi": 300, "bbox": [138, 100, 366, 316], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Connectors are not folded along with the blocks; instead they are routed along the right side of the drawing. (Blocks without incident connectors are omitted.) ", "caption_bbox": [92, 328, 411, 366]}, {"image_id": 6, "file_name": "513_06.png", "page": 5, "dpi": 300, "bbox": [441, 100, 749, 773], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: 2017 BPI Challenge: visualization by Celonis [5].", "caption_bbox": [457, 792, 731, 805]}, {"image_id": 7, "file_name": "513_07.png", "page": 5, "dpi": 300, "bbox": [246, 449, 410, 586], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The height of a draw- ing is a descending function of its width. ", "caption_bbox": [264, 590, 412, 628]}, {"image_id": 8, "file_name": "513_08.png", "page": 6, "dpi": 300, "bbox": [124, 100, 727, 503], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: 2017 BPI Challenge: our algorithm applied to the \u2018Celonis graph\u2019 from Fig. 8.", "caption_bbox": [223, 516, 626, 529]}, {"image_id": 9, "file_name": "513_09.png", "page": 7, "dpi": 300, "bbox": [104, 836, 747, 951], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Block types (left-to-right): action, sequence, loop, choice, and parallel block; optional variants with dashed outlines.", "caption_bbox": [133, 966, 718, 979]}, {"image_id": 10, "file_name": "513_10.png", "page": 7, "dpi": 300, "bbox": [93, 382, 761, 458], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The output of ProM [16] for the process tree in Fig. 10.", "caption_bbox": [273, 472, 579, 485]}, {"image_id": 11, "file_name": "513_11.png", "page": 7, "dpi": 300, "bbox": [145, 99, 708, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Example of a process tree.", "caption_bbox": [337, 354, 515, 367]}, {"image_id": 12, "file_name": "513_12.png", "page": 8, "dpi": 300, "bbox": [161, 100, 690, 507], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Example process tree (Fig. 10): our algorithm for two aspect ratios.", "caption_bbox": [244, 523, 608, 536]}, {"image_id": 13, "file_name": "513_13.png", "page": 9, "dpi": 300, "bbox": [129, 544, 732, 943], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Timeline of Roman emperors from Augustus to Diocletian, drawn using our algorithm with aspect ratio 1.5.", "caption_bbox": [157, 956, 701, 969]}, {"image_id": 14, "file_name": "513_14.png", "page": 9, "dpi": 300, "bbox": [129, 99, 732, 498], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: 2017 BPI Challenge: output of our algorithm drawing the process tree extracted with the inductive miner in ProM, aspect ratio 1.5.", "caption_bbox": [102, 511, 755, 524]}, {"image_id": 15, "file_name": "513_15.png", "page": 10, "dpi": 300, "bbox": [442, 421, 747, 615], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16:         Instance corresponding to the 3-S AT formula (x1 \u2228 x2 \u2228 \u00acx4 ) \u2227 (\u00acx2 \u2228 \u00acx3 \u2228 x4 ) \u2227 (\u00acx1 \u2228 \u00acx3 \u2228 x4 ). ", "caption_bbox": [435, 629, 754, 656]}], "514": [{"image_id": 0, "file_name": "514_00.png", "page": 2, "dpi": 300, "bbox": [468, 98, 718, 170], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Geometric representation of space-time slices. (a): Con- necting slices with normalized coordinates. The two vertical lines represent two slices, which has x coordinates from l0 to r0 and from l1 to r1 . After linearly normalizing both [l0 , r0 ] and [l1 , r1 ] to [0, 1], the two points x0 and x1 have the same normalized coordinates. Thus the color along their connected line will be linearly interpolated from the colors of x0 and x1 . (b): Space-time slices of an object chain with T = 4 frames. The 2D coordinates next to each vertex show its texture coordinates. ", "caption_bbox": [434, 185, 761, 301]}, {"image_id": 1, "file_name": "514_01.png", "page": 2, "dpi": 300, "bbox": [118, 99, 381, 249], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An illustration of how Space-Time Slicing works to visualize object recognition chains. (a): A sampling of a sequence of video frames recognizing a car (enclosed by bounding boxes with cyan color). (b): An extrustion of the middle rows of pixels in each bounding box. (c): The continuous smoothing of the bounding boxes of (b) via texture mapping. (d): Adding extra outline to enclose an object chain. ", "caption_bbox": [86, 264, 413, 341]}, {"image_id": 2, "file_name": "514_02.png", "page": 3, "dpi": 300, "bbox": [94, 99, 406, 334], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Zoomed-in view of Space-Time Slices (on the right) around the rectangle in Fig. 4 (c). The yellow horizontal line in the right view corresponds to the video frame shown in the bottom left view, showing that two vehicles have been detected. The top left view shows the neighboring object chains. Again the yellow line (vertical in this case) corresponds to the same frame indicated in the other views. The yellow vertical line intersects two object chains, each of which is for a detected vehicle. Other isolated image patches show false positives in nearby video frames. ", "caption_bbox": [86, 347, 412, 463]}, {"image_id": 3, "file_name": "514_03.png", "page": 4, "dpi": 300, "bbox": [85, 99, 413, 474], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Space-Time Slicing of sequence KITTI-2011/09/29-0004 for detectors SSD-300-PASCAL (a), SSD-512-PASCAL (b), and SSD- 300-KITTI (c). Here we sample every 5 video frames. For illustration purpose, we manually add a yellow rectangle on (c) to highlight the time steps when SSD-300-KITTI started to detect a small car. ", "caption_bbox": [86, 486, 413, 551]}, {"image_id": 4, "file_name": "514_04.png", "page": 5, "dpi": 300, "bbox": [94, 99, 407, 372], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Adjusting of score thresholds for the detected bounding boxes in video sequence KITTI-2011/09/26-0029 by detectors SSD- 512-PASCAL. (a) - (c): The space-time slices with score higher than lower bound 0.0, 0.2, and 0.3, respectively. The yellow line in (c) indicates frame 241, which is also highlighted in the view of object chains in (d). The top image patches in (d) show plants on the road, which are the straight trail in (a). ", "caption_bbox": [86, 384, 414, 474]}], "515": [{"image_id": 0, "file_name": "515_00.png", "page": 3, "dpi": 300, "bbox": [458, 819, 770, 958], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Comparison of two average images where a neural network incorrectly predicts digit 3 as 7 and 3 as 8. Users use this information when refining and collecting more data   ", "caption_bbox": [441, 962, 770, 1004]}, {"image_id": 1, "file_name": "515_01.png", "page": 3, "dpi": 300, "bbox": [88, 110, 771, 538], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The interactive exploration environment shows information about performance, weakness, and insights for improvement. (a) compares the overall performance of classifiers at the class level. (b) shows the weakness of a classifier at the confusion level. Each cell has an instance composite image that is proportional to the size of the misclassification and a bar chart that shows the amount of prediction improvement through different models. (c) provides insight into performance improvements by showing misclassification instances and comparing the predictions with other models. ", "caption_bbox": [82, 545, 770, 612]}, {"image_id": 2, "file_name": "515_02.png", "page": 4, "dpi": 300, "bbox": [438, 98, 771, 634], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Improvement barcode chart on misclassifications where kNN (M-4) incorrectly predicts the digit 7 as a 1. M-1 is the best for improving incorrectly predicted instances. M-2 improves incorrectly predicted instances where M-1 cannot improve. ", "caption_bbox": [438, 641, 767, 694]}, {"image_id": 3, "file_name": "515_03.png", "page": 4, "dpi": 300, "bbox": [82, 245, 411, 459], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Improvement bar chart on misclassifications where kNN (M-4) incorrectly predicts the digit 4 as a 9. ", "caption_bbox": [79, 466, 408, 492]}], "516": [{"image_id": 0, "file_name": "516_00.png", "page": 2, "dpi": 300, "bbox": [438, 452, 757, 587], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: We illustrate the overview of the work\ufb02ow of our proposed technique. ", "caption_bbox": [434, 597, 759, 624]}, {"image_id": 1, "file_name": "516_01.png", "page": 3, "dpi": 300, "bbox": [92, 101, 410, 166], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: We display the overview of prior knowledge creation and usage in the temporal domain. ", "caption_bbox": [86, 178, 411, 205]}, {"image_id": 2, "file_name": "516_02.png", "page": 3, "dpi": 300, "bbox": [90, 765, 402, 905], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: We illustrate the statistically down-sampling of a raw volume to 23 low-resolution grids. The orange block is a local data block. The orange point is a down-sampled point represented by a GMM which is computed from the orange block, and a minimum and a maximum value of the orange block. ", "caption_bbox": [86, 915, 412, 982]}, {"image_id": 3, "file_name": "516_03.png", "page": 4, "dpi": 300, "bbox": [92, 646, 409, 766], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: We illustrate a 2D example of creating an item, f1 and s1 in the spatial information dictionary from the dark orange point in low-resolution space. The orange points are the neighboring points, and the orange blocks in high-resolution data are the corresponding neighboring data blocks. The mean and standard deviations are directly computed from the data in these data blocks to generate f1 . The location information s1 is extracted from the dark orange data block. ", "caption_bbox": [86, 778, 414, 886]}, {"image_id": 4, "file_name": "516_04.png", "page": 5, "dpi": 300, "bbox": [90, 394, 409, 583], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: We illustrate prior knowledge creation work\ufb02ow. The chess board at the left upper corner is a 2D example of the simulation parameter input space. The green squares are the result of the Latin hypercube sampling. We illustrate one sampled parameter, which is the input to Nyx, and one time step (t   ) output, for prior knowledge creation here. The white cubes at the bottom are the output volumes of quantities of interest at time step t   . The blue divisions illustrate the de\ufb01ned prior knowledge blocks. The orange block illustrates using a sliding block to extract sample instances creating one prior knowledge block. ", "caption_bbox": [86, 595, 412, 729]}, {"image_id": 5, "file_name": "516_05.png", "page": 7, "dpi": 300, "bbox": [92, 561, 407, 854], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) - (g) are average reconstruction RMSE of 7 quantities over 250 simulation runs. (h) is the average error of the power spectrum. (i) is the average in situ down-sampling time. X-axis is the time steps. Y-axis in (a) - (h) is the RMSE in log scale. ", "caption_bbox": [86, 866, 412, 920]}, {"image_id": 6, "file_name": "516_06.png", "page": 8, "dpi": 300, "bbox": [92, 291, 764, 432], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: We display isosurface of phi grav=0 at time step 153 from a simulation run with input parameters, comoving h = 0.55, comoving OmB = 0.02326 and comoving OmM = 0.1394. D.S. stands for down-sampling. The numbers in sub-\ufb01gure captions are the ratio of the storage consumption to the raw data size. ", "caption_bbox": [86, 443, 767, 483]}, {"image_id": 7, "file_name": "516_07.png", "page": 8, "dpi": 300, "bbox": [93, 100, 764, 224], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: We display volume rendering of density quantity at time step 180 from a simulation run with input parameters, comoving h = 0.61666, comoving OmB = 0.02216 and comoving OmM = 0.14328. D.S. stands for down-sampling. The numbers in sub-\ufb01gure captions are the ratio of the storage consumption to the raw data size. ", "caption_bbox": [86, 235, 767, 275]}, {"image_id": 8, "file_name": "516_08.png", "page": 9, "dpi": 300, "bbox": [438, 339, 761, 568], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: We show the impact of the reconstruction quality using different numbers of simulation runs for prior knowledge creation and a different number of Gaussian components. Every point on each curve is the average RMSE of quantities, \u201cdensity\u201d, \u201czmom\u201d and \u201cTemp\u201d. (c) is an isosurface from raw data. (d), (e) and (f) are isosurfaces from the reconstructed data with 5 prior simulation runs and 5 Gaussian components, 5 prior simulation runs and 1 Gaussian component, and 1 prior simulation run and 5 Gaussian components, respectively. ", "caption_bbox": [435, 581, 763, 702]}, {"image_id": 9, "file_name": "516_09.png", "page": 9, "dpi": 300, "bbox": [88, 338, 410, 477], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: (a) and (b) are power spectra computed from data at time step 200 with input parameters, comoving h = 0.84997, comov- ing OmB = 0.02304 and comoving OmM = 0.13552, and comov- ing h = 0.61666, comoving OmB = 0.02216 and comoving OmM = 0.14328, respectively. ", "caption_bbox": [86, 490, 413, 557]}, {"image_id": 10, "file_name": "516_10.png", "page": 9, "dpi": 300, "bbox": [91, 99, 763, 231], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: We display streamlines of the vector \ufb01eld from xmom, ymom and zmom quantities at time step 200 with input parameters, comoving h = 0.58333, comoving OmB = 0.02304, and comoving OmM = 0.12776. 250 seeds are put on the line between [0,0,0] and [255,255,255] to compute streamlines. We zoom-in to sub-domains of the data to show the details. The red and blue color on the streamlines indicate the higher and lower vector magnitudes, respectively. D.S. stands for down-sampling. The percentage in the sub-\ufb01gure captions are the ratio of the storage consumption to the raw data size. ", "caption_bbox": [86, 242, 767, 309]}, {"image_id": 11, "file_name": "516_11.png", "page": 10, "dpi": 300, "bbox": [86, 99, 411, 215], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: (a) Data values on raycast segments from 5 prior simula- tion runs and 20 randomly sampled test simulation runs. Data values on rays from prior simulation runs and sampled test simulation runs are plotted by colored solid lines and black dashed lines, respectively. Two simulation runs, a prior simulation run marked by (b) and a test simulation run marked by (c), show isosurfaces with isovalue 1010 in (b) and (c), respectively. ", "caption_bbox": [85, 228, 413, 322]}], "517": [{"image_id": 0, "file_name": "517_00.png", "page": 1, "dpi": 300, "bbox": [439, 641, 766, 743], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The comparision of traditional volume rendering pipeline and our proposed pipeline. (a) the pipeline of conventional volume rendering, (b) the pipeline of our approach. ", "caption_bbox": [439, 759, 768, 798]}, {"image_id": 1, "file_name": "517_01.png", "page": 4, "dpi": 300, "bbox": [81, 96, 410, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Work\ufb02ow of our approach including the overall network architecture of our model. ", "caption_bbox": [79, 261, 408, 287]}, {"image_id": 2, "file_name": "517_02.png", "page": 5, "dpi": 300, "bbox": [96, 94, 752, 257], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Network architecture of the generator, including encoding and decoding parts. (De)Convolutional layers together with other layers, represented using colored squares, construct the whole network architecture. ", "caption_bbox": [79, 270, 769, 296]}, {"image_id": 3, "file_name": "517_03.png", "page": 5, "dpi": 300, "bbox": [438, 321, 767, 471], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Network architecture of the discriminator. Which takes single image or a couple of images with 3 or 4 channels as input, and projects if the image or the image pair to true or false. ", "caption_bbox": [439, 487, 768, 526]}, {"image_id": 4, "file_name": "517_04.png", "page": 5, "dpi": 300, "bbox": [494, 588, 714, 663], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: We generate gaussian bases with random mean and devia- tion; then combine several bases to construct opacity functions ", "caption_bbox": [439, 678, 770, 704]}, {"image_id": 5, "file_name": "517_05.png", "page": 6, "dpi": 300, "bbox": [438, 366, 770, 525], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Typical exploration paths enabled by our interactive system.", "caption_bbox": [439, 538, 770, 551]}, {"image_id": 6, "file_name": "517_06.png", "page": 6, "dpi": 300, "bbox": [438, 91, 770, 272], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Interface of our interactive system. In the left is the volume exploration view, it supports choosing a dataset and uploading a goal image. Direct 3D-navigation is supported here. In the right is the image-level editing view, contrast, brightness and color curves are allowed to be edited int the editing view. ", "caption_bbox": [439, 286, 768, 351]}, {"image_id": 7, "file_name": "517_07.png", "page": 6, "dpi": 300, "bbox": [80, 135, 410, 220], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Loss curve of the training process. GL1 loss drops quickly after about ten epochs and becomes stable. Other loss terms, al- though smaller values indicate better performance, form competing for balance in the game framework. ", "caption_bbox": [79, 233, 410, 285]}, {"image_id": 8, "file_name": "517_08.png", "page": 7, "dpi": 300, "bbox": [438, 593, 770, 688], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Results of Carp dataset with different con\ufb01gurations. (a) The goal image, (b) the ground truth image, (c) the synthesized images with RGB channels as inputs and the weight for L1 loss \u03bb set to 1000, and (d) the synthesized images with RGBA channels as inputs. ", "caption_bbox": [438, 703, 768, 768]}, {"image_id": 9, "file_name": "517_09.png", "page": 7, "dpi": 300, "bbox": [439, 101, 770, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Synthesis results for different datasets. Ig the goal, Is the synthesized, It the ground truth, Id the difference between synthesized and ground truth. We show the Id \u00d7 5 due to the insigni\ufb01cant value of Id . For the biomedical data, there is a clear edge in different parts; the artifacts are possible to occur at the edge of each component. For the combustion data, the value is more continuous that the artifacts are evenly distributed in the image. ", "caption_bbox": [439, 361, 769, 451]}, {"image_id": 10, "file_name": "517_10.png", "page": 8, "dpi": 300, "bbox": [79, 548, 411, 801], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Quality of synthesized images with different sizes of in- puts/outputs. ", "caption_bbox": [80, 817, 411, 843]}, {"image_id": 11, "file_name": "517_11.png", "page": 8, "dpi": 300, "bbox": [161, 875, 328, 971], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Left without skip layers, right with skip layers", "caption_bbox": [110, 986, 377, 999]}, {"image_id": 12, "file_name": "517_12.png", "page": 9, "dpi": 300, "bbox": [87, 173, 400, 434], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Results of Carp and Engine dataset, (a) and (c) the ren- dering from existing literatures (Courtesy of [18, 40]). (b) and (d) the synthesized images under different viewpoints. ", "caption_bbox": [79, 450, 410, 489]}, {"image_id": 13, "file_name": "517_13.png", "page": 9, "dpi": 300, "bbox": [438, 94, 769, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: The failure case generated by our model. There are wrong colors and artifacts in the red circles of the synthesized image. ", "caption_bbox": [439, 238, 768, 264]}], "518": [{"image_id": 0, "file_name": "518_00.png", "page": 2, "dpi": 300, "bbox": [190, 100, 665, 294], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Three components that make up the system. Data is grabbed from different sources(in pink) and sent to the backend (in blue). The data is either placed in a PostGis Database or, in the case of weather, is interfaced back and forth by Weather Service Access Layer. Lastly, the Rest API handles communication between the backend and frontend (in green). ", "caption_bbox": [89, 306, 764, 345]}, {"image_id": 1, "file_name": "518_01.png", "page": 3, "dpi": 300, "bbox": [434, 448, 759, 664], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The timeline interface, addressing Z1 (a) the main timeline view for a selected \ufb01re (b) the calendar view for the timeline, enabling a user to select which perimeters they wish to view (the range is high- lighted in green) (c) wind speed and direction indicators originating from weather stations (d) the satellite layer, showing all satellite data between the selected perimeter (dark grey in the timeline) and the previous one, representing \ufb01re intensity and the con\ufb01dence in the intensity of a region. ", "caption_bbox": [434, 676, 758, 778]}, {"image_id": 2, "file_name": "518_02.png", "page": 3, "dpi": 300, "bbox": [189, 100, 665, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The interface of our system for exploring historical \ufb01re data.(a) The main view shows a map. Each point represents a \ufb01re where time is mapped to color and burned arcs to size. Zooming or clicking on a point will show detail information about that particular \ufb01re. (b) A panel to manage the available layers. (c) A Calender view displays seasonal information where the color represents total on-\ufb01re acreage for that day. (d) the Marble Mountain Wilderness area, examined in-depth in Section 5.1.   . (e) A glyph and \ufb01re aggregation, explained in-depth in Section 4.3 ", "caption_bbox": [89, 365, 764, 416]}, {"image_id": 3, "file_name": "518_03.png", "page": 4, "dpi": 300, "bbox": [438, 383, 756, 753], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Multiple time-steps of the River Complex Fire using both the perimeter and weather layer in the map view. ", "caption_bbox": [435, 766, 757, 792]}, {"image_id": 4, "file_name": "518_04.png", "page": 5, "dpi": 300, "bbox": [94, 488, 409, 649], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The satellite view. On the left, a spattering of mid-intensity \ufb01re activity is seen through T-42 for the River Complex \ufb01re. On the right, \ufb01re activity has mostly died down for T-60 and is focused around the eastern crown. ", "caption_bbox": [90, 661, 412, 712]}], "519": [{"image_id": 0, "file_name": "519_00.png", "page": 2, "dpi": 300, "bbox": [434, 99, 762, 511], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Examples of the type of visual representation used in printed reports for tracking data. These are heat-maps to show the density of visitors in different areas of the exhibition, and directed graph views with arrows showing the path of visitors around the exhibition. ", "caption_bbox": [434, 523, 760, 575]}, {"image_id": 1, "file_name": "519_01.png", "page": 2, "dpi": 300, "bbox": [90, 570, 409, 784], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An annotated print-out of the museum \ufb02oor-plan used for pen-and-paper tracking. ", "caption_bbox": [86, 804, 412, 830]}, {"image_id": 2, "file_name": "519_02.png", "page": 4, "dpi": 300, "bbox": [434, 587, 762, 784], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The tracking application interface. The user presses on different exhibits to indicate the movement of a visitor and uses the thumb-wheel dials to specify visitor characteristics or actions. ", "caption_bbox": [434, 796, 759, 835]}, {"image_id": 3, "file_name": "519_03.png", "page": 4, "dpi": 300, "bbox": [442, 99, 754, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The device con\ufb01guration and basic functionality of our platform. Tracking staff use a mobile device to track visitors moving around the exhibition. Devices used to track visitors and display the data are connected on the local Wi-Fi network by scanning a QR code. Data is automatically synchronized between connected devices and the data can be visualized on a mobile device or a mobile device connected to a large display. ", "caption_bbox": [434, 369, 760, 459]}, {"image_id": 4, "file_name": "519_04.png", "page": 5, "dpi": 300, "bbox": [435, 100, 761, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The main information visualization display with the graph view selected to show how visitors move around the exhibition. ", "caption_bbox": [434, 348, 760, 374]}, {"image_id": 5, "file_name": "519_05.png", "page": 5, "dpi": 300, "bbox": [87, 100, 414, 353], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Using the tracking app to record the movement of a museum visitor around the Romantic Scotland exhibition in Nanjing Museum. ", "caption_bbox": [86, 365, 412, 391]}, {"image_id": 6, "file_name": "519_06.png", "page": 5, "dpi": 300, "bbox": [434, 453, 762, 875], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The different types of projections used in the Smart Survey Tool visualization interface. These are an isometric projection, a military projection, and a top-down plan view. ", "caption_bbox": [434, 888, 760, 927]}, {"image_id": 7, "file_name": "519_07.png", "page": 6, "dpi": 300, "bbox": [87, 100, 412, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: The heat-map view with an isometric projection.", "caption_bbox": [111, 256, 386, 270]}, {"image_id": 8, "file_name": "519_08.png", "page": 6, "dpi": 300, "bbox": [434, 100, 763, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Using the visualization interface with a mobile device controlling a large display. ", "caption_bbox": [435, 332, 760, 358]}, {"image_id": 9, "file_name": "519_09.png", "page": 6, "dpi": 300, "bbox": [85, 286, 414, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A heat-map with the 16-30 age group and average visit duration selected shows us that males (left) tend to spend more time at the bench, while females (right) spend more time in the interactive booth. ", "caption_bbox": [86, 404, 411, 456]}, {"image_id": 10, "file_name": "519_10.png", "page": 8, "dpi": 300, "bbox": [436, 500, 761, 602], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Thumb-wheel widget with help text (in Chinese) activated by pressing the question mark icon. ", "caption_bbox": [434, 615, 759, 641]}, {"image_id": 11, "file_name": "519_11.png", "page": 8, "dpi": 300, "bbox": [434, 100, 762, 256], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Thumb-wheel widget with help text (in Chinese) activated by pressing the question mark icon. ", "caption_bbox": [434, 269, 759, 295]}, {"image_id": 12, "file_name": "519_12.png", "page": 8, "dpi": 300, "bbox": [86, 100, 414, 321], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Thumb-wheel widget with help text (in Chinese) activated by pressing the question mark icon. ", "caption_bbox": [86, 334, 411, 360]}, {"image_id": 13, "file_name": "519_13.png", "page": 8, "dpi": 300, "bbox": [436, 310, 762, 445], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Thumb-wheel widget with help text (in Chinese) activated by pressing the question mark icon. ", "caption_bbox": [434, 458, 759, 484]}], "52": [{"image_id": 0, "file_name": "52_00.png", "page": 1, "dpi": 300, "bbox": [473, 806, 709, 987], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A phylogenetic tree (Maddison and               Maddison, 1992) ", "caption_bbox": [450, 1006, 718, 1039]}, {"image_id": 1, "file_name": "52_01.png", "page": 2, "dpi": 300, "bbox": [419, 127, 748, 485], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A visualisation constructed manually, i.e. using vector graphics software to draw and add pie charts. Pie charts represent relative proportions of nucleotide content in genes. The black represents the GC content and the white represents the AT content (Ho et al. 2004). ", "caption_bbox": [421, 485, 747, 582]}, {"image_id": 2, "file_name": "52_02.png", "page": 2, "dpi": 300, "bbox": [93, 560, 383, 869], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Output format of the \u2018Compare\u2019 application", "caption_bbox": [78, 869, 401, 886]}, {"image_id": 3, "file_name": "52_03.png", "page": 3, "dpi": 300, "bbox": [542, 169, 624, 313], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A simple tree superimposed on the           tessellated background ", "caption_bbox": [452, 327, 717, 360]}, {"image_id": 4, "file_name": "52_04.png", "page": 3, "dpi": 300, "bbox": [429, 506, 737, 651], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: a) A tree structure. b) The corresponding spatial tessellation of the background in the colour- filling approach. c) A tree map showing the corresponding hierarchical tessellation. ", "caption_bbox": [421, 661, 746, 726]}, {"image_id": 5, "file_name": "52_05.png", "page": 4, "dpi": 300, "bbox": [463, 541, 684, 716], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: a) Relatively short branch lengths may obscure colours from view b) The topological layout shows colour changes clearly in this situation. ", "caption_bbox": [421, 735, 746, 784]}, {"image_id": 6, "file_name": "52_06.png", "page": 4, "dpi": 300, "bbox": [140, 258, 327, 413], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": " Figure 6: 11-class diverging colour scheme, 9-class sequential colour scheme, 5-class spectral diverging                    colour scheme. ", "caption_bbox": [87, 426, 394, 475]}], "520": [{"image_id": 0, "file_name": "520_00.png", "page": 1, "dpi": 300, "bbox": [116, 60, 714, 326], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A redacted version of Joseph Priestley\u2019s Chart of Biography from 1765 (left) and our Interactive Chart of Biography (right).", "caption_bbox": [112, 340, 737, 353]}, {"image_id": 1, "file_name": "520_01.png", "page": 4, "dpi": 300, "bbox": [92, 88, 758, 201], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Deriving new relationships between musicians", "caption_bbox": [289, 216, 559, 229]}, {"image_id": 2, "file_name": "520_02.png", "page": 5, "dpi": 300, "bbox": [79, 88, 411, 281], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Screenshot of the Interactive Chart of Biography", "caption_bbox": [104, 295, 384, 308]}, {"image_id": 3, "file_name": "520_03.png", "page": 6, "dpi": 300, "bbox": [439, 88, 770, 297], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Development of the lutenist profession", "caption_bbox": [487, 311, 719, 324]}, {"image_id": 4, "file_name": "520_04.png", "page": 7, "dpi": 300, "bbox": [79, 88, 770, 476], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Overview over the 3,856 persons working at Bayerische Staatsoper (2,573), Hochschule fu\u0308r Musik und Theater Mu\u0308nchen (879), Wu\u0308rzburger Hofkapelle (385) and Freisinger Hofkapelle (176) (right) and musicians\u2019 relations between the Bayerische Staatsoper and the Hochschule fu\u0308r Musik und Theater (left). Colored edges are intra-institutional, black edges are inter-institutional. The colored boxes show the af\ufb01liations of musicians to different institutions. ", "caption_bbox": [79, 490, 769, 542]}, {"image_id": 5, "file_name": "520_05.png", "page": 8, "dpi": 300, "bbox": [80, 107, 768, 480], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Signi\ufb01cant changes in the development of the Bayreuther Festspiele. The close reading shows Felix Josef Mottl.", "caption_bbox": [131, 495, 716, 508]}, {"image_id": 6, "file_name": "520_06.png", "page": 8, "dpi": 300, "bbox": [80, 533, 409, 770], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Deriving relations between musicians.", "caption_bbox": [129, 784, 359, 797]}, {"image_id": 7, "file_name": "520_07.png", "page": 9, "dpi": 300, "bbox": [79, 87, 770, 477], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A comparison of the Correspodirende Societa\u0308t der musikalischen Wissenschaften (turquoise) and the Salzburger Hofkapelle (yellow) with details on Johann Georg Leopold Mozart. ", "caption_bbox": [79, 491, 768, 517]}], "521": [{"image_id": 0, "file_name": "521_00.png", "page": 4, "dpi": 300, "bbox": [86, 100, 770, 444], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The main workspace comprises (A) a menu that enables users to switch between the different visualizations or to \ufb01lter the character network, (B) the main view where users can inspect the character networks with the aid of matrix-based or node-link visualizations, (C) the tab view where users can switch between a graph desktop, an entity list, a text view, and a word cloud view. ", "caption_bbox": [87, 456, 768, 495]}, {"image_id": 1, "file_name": "521_01.png", "page": 4, "dpi": 300, "bbox": [87, 520, 414, 699], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Four different node-link diagram encodings: (A) juxtaposed bar charts with length comparing edges and (B) pie charts with width comparing edges. ", "caption_bbox": [87, 713, 412, 752]}, {"image_id": 2, "file_name": "521_02.png", "page": 5, "dpi": 300, "bbox": [85, 368, 762, 580], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The grid view provides an overview of all selected charac- ter networks as juxtaposed small multiples in an adjacency matrix. The frames\u2019 colors represent the similarity between the respective character networks. ", "caption_bbox": [434, 579, 762, 631]}, {"image_id": 3, "file_name": "521_03.png", "page": 5, "dpi": 300, "bbox": [121, 101, 732, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Three different visual encodings for the comparison mode of the adjacency matrix: (A) juxtaposed color-coded bar charts, (B) split crosswise cells, and (C) color transition. ", "caption_bbox": [85, 315, 765, 341]}, {"image_id": 4, "file_name": "521_04.png", "page": 6, "dpi": 300, "bbox": [85, 98, 762, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The entity list enables users to select and deselect charac- ters from the graph, shows the number of characters\u2019 occurrences, and \ufb01ngerprint visualizations that represents the distribution of the entities in the different parts of the text document. ", "caption_bbox": [434, 407, 761, 459]}, {"image_id": 5, "file_name": "521_05.png", "page": 8, "dpi": 300, "bbox": [120, 100, 735, 464], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: (a) Our focus+context approach in the comparison mode with two different selected parts of the romance Parzival. (b) The graph desktop containing four user-selected graphs. ", "caption_bbox": [87, 477, 767, 503]}], "522": [{"image_id": 0, "file_name": "522_00.png", "page": 1, "dpi": 300, "bbox": [116, 136, 738, 456], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The overview map on the left demonstrates the guided-tour concept with \ufb01ve categories of evidence-based tasks in a hierarchical tree structure. Different narrative transition types are illustrated here: a) shows a drill-down path from an overall question to a next-level video-related question; b) presents a dig-in comparison of the audited learner group with the certi\ufb01cated learner group for the same video clickstream slide; and c) demonstrates a non-linear jump for an assignment content slide to a related video clickstream slide. The three screenshots on the right correspond to some storytelling slides presented in our use cases. ", "caption_bbox": [112, 485, 735, 550]}, {"image_id": 1, "file_name": "522_01.png", "page": 4, "dpi": 300, "bbox": [84, 98, 763, 382], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: We summarized \ufb01ve major categories of evidence-based tasks in a question-list format: video-related questions, assignment-related questions, forum-related questions, overall action-related questions, and learner-oriented questions. ", "caption_bbox": [79, 399, 767, 425]}, {"image_id": 2, "file_name": "522_02.png", "page": 6, "dpi": 300, "bbox": [79, 98, 770, 206], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: System architecture and data processing pipeline.", "caption_bbox": [279, 220, 567, 233]}, {"image_id": 3, "file_name": "522_03.png", "page": 6, "dpi": 300, "bbox": [440, 630, 770, 839], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: This \ufb01gure shows a screenshot of the system interface, including the slideshow in the middle, the history panel when hovering over the left corner, the overview map showing the current path on the right, and the control panel with the marking tools, the presentation mode, and the \ufb01le editing function. ", "caption_bbox": [439, 853, 769, 918]}, {"image_id": 4, "file_name": "522_04.png", "page": 7, "dpi": 300, "bbox": [440, 94, 770, 493], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: This \ufb01gure shows the exploration path in the overview map and their corresponding slides demonstrated in Case 1 for identifying problematic course materials. ", "caption_bbox": [439, 506, 768, 545]}, {"image_id": 5, "file_name": "522_05.png", "page": 8, "dpi": 300, "bbox": [439, 96, 770, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The \ufb01rst exploration transition demonstrated in Case 3 from a learner-oriented logic to a material-oriented logic. ", "caption_bbox": [439, 314, 768, 340]}, {"image_id": 6, "file_name": "522_06.png", "page": 9, "dpi": 300, "bbox": [80, 109, 403, 379], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The second exploration transition demonstrated in Case 3 from a material-oriented to a learner-oriented logic. ", "caption_bbox": [79, 397, 408, 423]}], "523": [{"image_id": 0, "file_name": "523_00.png", "page": 1, "dpi": 300, "bbox": [455, 402, 742, 636], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Top) An illustration of a recurrence within a dynamical sys- tem. Each point represents a phase space position (or state) x along a phase space trajectory. Recurrence occurs when the distance d(xi , xj ) between a pair of states at discrete time steps (i, j) is within a thresh- old, \u03b5 (the recurrence threshold). Bottom) An example recurrence plot computed from the phase space trajectory of an ion in a Tokamak fusion simulation. On the left is the un-thresholded recurrence plot (or distance matrix). To the right are the distance plots derived from it using progressively smaller thresholding parameters. ", "caption_bbox": [434, 651, 762, 767]}, {"image_id": 1, "file_name": "523_01.png", "page": 2, "dpi": 300, "bbox": [100, 168, 405, 285], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A depiction of the Tokamak fusion device. Right) An image of the inside of a real device. Left) A cross section depicting the poloidal plane, and two important types of particle modes, trapped (blue), and passing (red). ", "caption_bbox": [85, 298, 411, 350]}, {"image_id": 2, "file_name": "523_02.png", "page": 2, "dpi": 300, "bbox": [445, 99, 746, 423], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Phase plots in the poloidal plane (left) and velocity space (upper right) with a selected trajectory (black). Its distance plot is shown in the lower right. A pair of time steps that correspond to a recurrent state is selected with the mouse. The points/states at these two time steps are shown in pink and green dots along the trajectory in each of the phase plots. ", "caption_bbox": [434, 436, 760, 513]}, {"image_id": 3, "file_name": "523_03.png", "page": 3, "dpi": 300, "bbox": [136, 100, 719, 489], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A group of linked phase plots together with our custom distance plot. The left plot represents the poloidal plane, the lower middle plot represents velocity space, the upper middle plot represents the two angles of rotation (toroidal and poloidal), and the upper right plot represents the particle weight and magnetic radius. The background of each of these phase plots shows a heatmap based aggregation of all of the particles weights, while the speci\ufb01c trajectory being singled out is shown in bright green. This trajectories distance plot is shown in the lower right corner. The analyst has selected a cell in the distance plot and the states corresponding to this pair of time steps are plotted in each of the phase plots (black point with white border and white point with black border). ", "caption_bbox": [86, 501, 770, 578]}, {"image_id": 4, "file_name": "523_04.png", "page": 3, "dpi": 300, "bbox": [96, 602, 405, 759], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The design of our distance plot based visualization incor- porating events and particle weights. the upper left portion of the matrix represents the phase space distance plot, while the lower left represents the particle weights distance plot. Different color maps are used for each to distinguish them. In each case, lighter means smaller distances. The red/blue bands along the axis show the values of the weights over time with red indicating positive weight and blue negative weigh. The points along the diagonal represent the events. ", "caption_bbox": [86, 772, 413, 875]}, {"image_id": 5, "file_name": "523_05.png", "page": 4, "dpi": 300, "bbox": [103, 626, 397, 910], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Four examples of the dual phase space, particle weight distance plots. The left two plots are from passing particle trajectories, while the two on the right are from trapped particle trajectories, and include marks representing the direction change events. ", "caption_bbox": [85, 923, 412, 975]}, {"image_id": 6, "file_name": "523_06.png", "page": 4, "dpi": 300, "bbox": [453, 99, 743, 589], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A particle on its transition from magnetic con\ufb01nement to escape and absorption by the heat load diverter. The arrow shows that point along the trajectory in the upper view (in the poloidal plane), corresponds to the time step where an anomalous change in the evolution of the particle\u2019s weight occurred. It appears this marks an onset of the transition, before the subsequent loss of con\ufb01nement. ", "caption_bbox": [434, 601, 761, 678]}, {"image_id": 7, "file_name": "523_07.png", "page": 4, "dpi": 300, "bbox": [73, 241, 414, 380], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Computation times for a distance plot from trajectories of different dimensions and number of time steps. ", "caption_bbox": [86, 385, 411, 411]}], "524": [{"image_id": 0, "file_name": "524_00.png", "page": 1, "dpi": 300, "bbox": [120, 60, 751, 356], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Computational pipeline for uncertainty-aware Ramachandran Plots. a) Input data including a b-value (uncertainty) for each atoms position. b) Dihedral angle computation for peptides utilizing a probabilistic model for each atom. c) Uncertainty-aware Ramachandran Plot. ", "caption_bbox": [119, 370, 736, 409]}, {"image_id": 1, "file_name": "524_01.png", "page": 3, "dpi": 300, "bbox": [437, 430, 762, 805], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Uncertainty-aware Ramachandran Plot for the 3APR protein. a) Complete Ramachandran Plot showing allowed regions (dark blue) partially allowed regions (light blue) and undesired regions (yellow). b) Closeup of polypeptides that are certainly located in the desired areas. c) Closeup of polypetides that are not located in the desired areas ", "caption_bbox": [435, 820, 763, 897]}, {"image_id": 2, "file_name": "524_02.png", "page": 4, "dpi": 300, "bbox": [158, 99, 696, 385], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Comparison of the presented visualization to the state of the art, showing the dihedral angles of the 1axc protein. a) State of the art Ramachandran Plot. b) Uncertainty-aware Ramachandran Plot. The results show that the traditional visualization may lead to a miss-interpretation of the thermal stability in proteins. ", "caption_bbox": [86, 399, 767, 438]}], "525": [{"image_id": 0, "file_name": "525_00.png", "page": 1, "dpi": 300, "bbox": [135, 60, 726, 366], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: LBVH is a popular GPU tree construction algorithm for triangle geometry. We propose an adaptation of the algorithm for sparse volumes (left). The phases of our algorithm are comprised of \ufb01rst decomposing the volume into bricks and \ufb01nding the non-empty ones using a parallel voting strategy (second from left). We then perform a compaction operation and sort the non-empty bricks on a z-order Morton curve (second from right). We \ufb01nally build a hierarchy on the GPU by performing median splits based on the Morton codes and then propagating the leaf node bounding boxes up through the tree (right). ", "caption_bbox": [124, 385, 729, 448]}, {"image_id": 1, "file_name": "525_01.png", "page": 2, "dpi": 300, "bbox": [93, 99, 413, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Median split operation using Morton codes. Split axis and position in a range can be found by searching the two Morton codes where the \ufb01rst most signi\ufb01cant bits differ. ", "caption_bbox": [92, 313, 411, 351]}, {"image_id": 2, "file_name": "525_02.png", "page": 4, "dpi": 300, "bbox": [92, 370, 763, 606], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The most dominant phases of the construction algorithm, for (from left to right) 2563 , 5123 , 10243 , and 20483 volumes. Voting for empty bricks is a per-voxel operation, while the ensuing phases operate on bricks. Note how the voting phase dominates the other phases with increasing volume size. ", "caption_bbox": [92, 619, 759, 658]}, {"image_id": 3, "file_name": "525_03.png", "page": 5, "dpi": 300, "bbox": [94, 101, 762, 232], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Relation between construction and rendering times, for (from left to right) 2563 , 5123 , 10243 , and 20483 volumes. With increasing volume size, the construction phase becomes more dominant. ", "caption_bbox": [93, 246, 760, 272]}], "526": [{"image_id": 0, "file_name": "526_00.png", "page": 1, "dpi": 300, "bbox": [129, 60, 735, 419], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The input dataset, consisting of thousands of possible ligand trajectories, can be analyzed using a set of linked views. In our drill-down approach, the subsets of the original trajectories can be compared and analyzed in more detail, using the combination of chart matrix, selection chart panel, and 3D view. ", "caption_bbox": [124, 433, 728, 471]}, {"image_id": 1, "file_name": "526_01.png", "page": 4, "dpi": 300, "bbox": [93, 95, 762, 428], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Overview of the proposed tool and its individual parts: Chart Matrix (1), 3D View (2), and Selection Chart Panel (3). The letters mark the individual parts of the Chart Matrix: Small Multiples View (a), horizontal and vertical Marginal Charts (b) and overview scatterplot (c). ", "caption_bbox": [93, 441, 760, 467]}, {"image_id": 2, "file_name": "526_02.png", "page": 6, "dpi": 300, "bbox": [483, 99, 707, 318], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The ligand, closest to the active site, where it was trans- ported by following a trajectory. Surrounding amino acids that pre- vented the ligand from further moving towards the active site are depicted using a Balls and Sticks visualization and labeled. ", "caption_bbox": [434, 332, 755, 384]}, {"image_id": 3, "file_name": "526_03.png", "page": 6, "dpi": 300, "bbox": [96, 99, 414, 302], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Portion of the LinB dataset (>13,500 trajectories) visualized using our aggregation approaches. Trajectories are depicted using a density-based visualization. The structure is shown using the protein backbone with its width modulated by the maximum extent w.r.t. its mean conformation. ", "caption_bbox": [93, 333, 412, 396]}, {"image_id": 4, "file_name": "526_04.png", "page": 6, "dpi": 300, "bbox": [434, 646, 755, 783], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Comparison of trajectories from LinB and LinB32 datasets that transported DBE to the active site. Noticeable energy peaks can be observed for the LinB32 trajectories at the distance of 8-14 A\u030a from the active site. ", "caption_bbox": [434, 795, 753, 846]}, {"image_id": 5, "file_name": "526_05.png", "page": 7, "dpi": 300, "bbox": [85, 100, 754, 411], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Overview of the LinB dataset visualized using the Chart Matrix. The Minimum Active Site Distance and Area Under Curve properties were used to slice the data into 10 by 10 bins. The distribution of the trajectory data can be clearly observed. From the bins highlighted with the red rectangle, it can be seen that most of the trajectories transported the ligand to the distance of 3.1-5.5 A\u030a, i.e., to a location near the active site. ", "caption_bbox": [85, 424, 754, 462]}, {"image_id": 6, "file_name": "526_06.png", "page": 8, "dpi": 300, "bbox": [94, 100, 763, 411], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Overview of the LinB32 dataset visualized using the Chart Matrix. The Minimum Active Site Distance and Area Under Curve properties were used to slice the data into 10 by 10 bins. The distribution of the trajectory data can be clearly observed. From the bins highlighted with the red rectangle, it can be immediately seen that most of the trajectories did not transport the ligand to a location near the active site. ", "caption_bbox": [93, 424, 760, 462]}], "527": [{"image_id": 0, "file_name": "527_00.png", "page": 1, "dpi": 300, "bbox": [121, 60, 734, 478], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Based on the segmentation of circulation rolls in 3D convective \ufb02ows, we introduce an importance measure for streamlines to emphasize interior heat \ufb02ow patterns, and particle-based visualization to analyse the structure and speed of heat mixing across rolls. ", "caption_bbox": [122, 490, 733, 529]}, {"image_id": 1, "file_name": "527_01.png", "page": 2, "dpi": 300, "bbox": [91, 99, 413, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Randomly seeded streamlines in the instantaneous (left) and time-averaged (right) thermal convection \ufb02ow \ufb01eld. Ra = 105 , Pr = 0.7, \u0393 = 25. Coloring indicates temperature from low (blue) to high (orange). ", "caption_bbox": [90, 273, 414, 324]}, {"image_id": 2, "file_name": "527_02.png", "page": 3, "dpi": 300, "bbox": [435, 360, 757, 680], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a-c): FTLE values (using increasing integration time) in the midplane are mapped to brightness. (d): Circulation network ex- tracted in the FTLE \ufb01eld, overlayed on streamline image with selected misclassi\ufb01cations. ", "caption_bbox": [434, 692, 758, 743]}, {"image_id": 3, "file_name": "527_03.png", "page": 4, "dpi": 300, "bbox": [88, 564, 413, 794], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Correspondence between convection rolls (top) and tem- perature \ufb01eld (bottom, colored from warm (red) to cold (yellow)). Cir- culation rolls are indicated as spiralling transport structures in the \ufb02ow. Ridges and valleys in the temperature \ufb01eld indicate boundaries between the rolls. ", "caption_bbox": [89, 806, 413, 870]}, {"image_id": 4, "file_name": "527_04.png", "page": 4, "dpi": 300, "bbox": [435, 100, 757, 577], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Top: Time- and z-averaged temperature \ufb01eld; main negative eigenvalue of Hessian matrix of smoothed \ufb01eld. Middle: Thinned and pruned ridges; union of ridges and valleys. Bottom: Segmented rolls (with thickened boundaries) using four-coloring scheme; \ufb01nal network overlayed on streamline image with selected misclassi\ufb01cations. ", "caption_bbox": [434, 590, 757, 654]}, {"image_id": 5, "file_name": "527_05.png", "page": 4, "dpi": 300, "bbox": [88, 100, 413, 213], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Left: Small-scale turbulent velocity \ufb02uctuations remain in the time-averaged \ufb02ow \ufb01eld. Right: Flow trajectories crossing over to another cell indicate heat transport between rolls. ", "caption_bbox": [89, 226, 411, 265]}, {"image_id": 6, "file_name": "527_06.png", "page": 5, "dpi": 300, "bbox": [435, 99, 757, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Left: Distance values to roll boundaries (green), color coded from black (small values) to white (large values). Right: All 3D trajectories are colored from green (high distance to midplane) to red (short distance to midplane) and projected into the midplane using accumulative blending. ", "caption_bbox": [434, 273, 757, 337]}, {"image_id": 7, "file_name": "527_07.png", "page": 6, "dpi": 300, "bbox": [90, 100, 411, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Left: Trisectors are detected as ridge pixels whose Moore neighbourhood contains exactly three contiguous runs of ridge pixels. Right: Extracted trisectors after \ufb01ltering out nearby pairs. Blue (green) trisectors were found in the ridge (valley) \ufb01eld. ", "caption_bbox": [88, 273, 412, 324]}, {"image_id": 8, "file_name": "527_08.png", "page": 6, "dpi": 300, "bbox": [435, 100, 757, 223], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Left: Outer trajectories occlude interior ones. Right: Line- density control based on line curvature thins out outer trajectories and reveals the interior \ufb02ow structure in a superstructure circulation roll. ", "caption_bbox": [434, 235, 758, 274]}, {"image_id": 9, "file_name": "527_09.png", "page": 6, "dpi": 300, "bbox": [433, 462, 768, 678], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Focus and context streamline visualization: Few outer trajectories indicate the shape and size of circulation rolls, highly- curved roll-like interior lines and elongated helix-like lines close to the rolls\u2019 centerlines indicate speci\ufb01c circulation patterns. ", "caption_bbox": [434, 691, 758, 742]}, {"image_id": 10, "file_name": "527_10.png", "page": 7, "dpi": 300, "bbox": [434, 99, 759, 183], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Defect visualization: Highly anisotropic mixing behaviour between neighbouring rolls occurs in the vicinity of potential defectany of the extracted defect locations. ", "caption_bbox": [434, 195, 756, 234]}, {"image_id": 11, "file_name": "527_11.png", "page": 7, "dpi": 300, "bbox": [434, 390, 760, 846], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: The opacity of particles corresponds to dwell time, to highlight stable structures (top; long dwell time) or particle exchange between adjacent rolls (bottom; short dwell time). ", "caption_bbox": [434, 859, 756, 898]}, {"image_id": 12, "file_name": "527_12.png", "page": 7, "dpi": 300, "bbox": [91, 512, 412, 601], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Weak (left) and strong (right) mixing of air between adjacent rolls is revealed by coloring particles according to the roll in which they were seeded initially. While mixing proceeds along speci\ufb01c streams on the left, it evolves across the entire rolls on the right. ", "caption_bbox": [89, 614, 412, 665]}, {"image_id": 13, "file_name": "527_13.png", "page": 8, "dpi": 300, "bbox": [435, 99, 757, 298], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15: Isosurface indicating a 50% mixing ratio between the green and blue circulation rolls. The lefthand snapshot was taken shortly after seeding the particles in their respective cells, the righthand snapshot after letting the particles mix for a while. ", "caption_bbox": [434, 310, 756, 361]}, {"image_id": 14, "file_name": "527_14.png", "page": 8, "dpi": 300, "bbox": [89, 338, 414, 628], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14: Density map visualization of mixing ratio of particles from two adjacent circulation rolls. Mixing is approximately equal in blue regions. ", "caption_bbox": [90, 641, 412, 680]}, {"image_id": 15, "file_name": "527_15.png", "page": 9, "dpi": 300, "bbox": [98, 572, 413, 754], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 17: Particle visualization (temperature mapped to color) reveals rolls with vastly different and inhomogeneous mixing behaviour. ", "caption_bbox": [89, 772, 411, 798]}, {"image_id": 16, "file_name": "527_16.png", "page": 9, "dpi": 300, "bbox": [434, 99, 768, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 18: Similar mixing behaviour in the vicinity of defects at different locations. ", "caption_bbox": [434, 305, 756, 331]}, {"image_id": 17, "file_name": "527_17.png", "page": 9, "dpi": 300, "bbox": [99, 199, 411, 401], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16: Elongated helix-like streamlines are found in the rolls\u2019 cores. ", "caption_bbox": [89, 420, 412, 446]}], "528": [{"image_id": 0, "file_name": "528_00.png", "page": 5, "dpi": 300, "bbox": [103, 98, 389, 267], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1. Direct Visualization of the principal stresses inside the data set ANSICHT [10]\u2013[12] with ellipsoids. ", "caption_bbox": [78, 270, 411, 294]}, {"image_id": 1, "file_name": "528_01.png", "page": 6, "dpi": 300, "bbox": [453, 99, 745, 497], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2. Coloring of the tetrahedral mesh in the attribute space according to the depth in physical space after t years. ", "caption_bbox": [435, 502, 768, 528]}, {"image_id": 2, "file_name": "528_02.png", "page": 7, "dpi": 300, "bbox": [97, 265, 382, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3. Legend of the materials from the ANSICHT project used in Fig. 4 and following. For information on the materials, see [10]\u2013[12]. ", "caption_bbox": [78, 226, 411, 250]}, {"image_id": 3, "file_name": "528_03.png", "page": 7, "dpi": 300, "bbox": [103, 472, 389, 669], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. Coloring of the tetrahedral mesh in the attribute space according to the geological layer the element belonged to in physical space at two time points during the simulation. For information on the geological layers, see [10]\u2013[12] and Fig. 3. Orange-red marks the tetrahedra whose material belong to the inserted repository. ", "caption_bbox": [78, 674, 411, 735]}, {"image_id": 4, "file_name": "528_04.png", "page": 9, "dpi": 300, "bbox": [135, 100, 718, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5. Extended sets of attribute spaces derived from the \ufb01ber surface associated with the original attribute space. An interactor is placed inside the \ufb01ber surface on the left-hand side (black surface). It is used for the extraction of the \ufb01ber surfaces in each of the four spaces on the right-hand side respectively. ", "caption_bbox": [78, 361, 767, 398]}, {"image_id": 5, "file_name": "528_05.png", "page": 12, "dpi": 300, "bbox": [87, 99, 774, 900], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6.      The left hand side of the images shows the \u03c3eq     -p-T state space of the system (\u03c3   : 9.13 \u2217 105 Pa - 8.52 \u2217 107 Pa, p: \u22124.38 \u2217                                                                                                           eq    2                  7           \u25e6           \u25e6 10 Pa - 3.73 \u2217 10 Pa, T : 8.0 C - 142.8 C). The right hand side illustrates in Euclidean space the bounding surface of the region marked by the interactor in phase space (green box on the left). The background colors clarify the geological layers for context. For information on the geological layers, see [10]\u2013[12]. ", "caption_bbox": [78, 902, 767, 956]}, {"image_id": 6, "file_name": "528_06.png", "page": 13, "dpi": 300, "bbox": [86, 99, 773, 900], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7.      The left hand side of the images shows the \u03c3eq     -p-T state space of the system (\u03c3   : 9.13 \u2217 105 Pa - 8.52 \u2217 107 Pa, p: \u22124.38 \u2217                                                                                                           eq    2                  7           \u25e6           \u25e6 10 Pa - 3.73 \u2217 10 Pa, T : 8.0 C - 142.8 C). The right hand side illustrates in Euclidean space the bounding surface of the region marked by the interactor in phase space (green box on the left). The background colors clarify the geological layers for context. For information on the geological layers, see [10]\u2013[12]. ", "caption_bbox": [77, 902, 766, 956]}], "529": [{"image_id": 0, "file_name": "529_00.png", "page": 2, "dpi": 300, "bbox": [80, 95, 410, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The user interface of EngineQV.", "caption_bbox": [140, 272, 348, 285]}, {"image_id": 1, "file_name": "529_01.png", "page": 3, "dpi": 300, "bbox": [106, 101, 754, 316], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: EngineQV comprises a backend (i.e. database and query engines) and a frontend (i.e. query panel and vis panel). The three datasets are stored and handled by query engines in the backend. In the frontend, the query panel allows the user to communicate with the backend and the returned query results will be passed to each visualization component. ", "caption_bbox": [79, 332, 767, 373]}, {"image_id": 2, "file_name": "529_02.png", "page": 4, "dpi": 300, "bbox": [102, 101, 743, 466], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Use case 1: exploration of the \ufb02ight routes potentially in\ufb02uenced by the volcanic ash. The user may \ufb01rst use Geo-map as an overview to \ufb01nd the in\ufb02uenced \ufb02ights (a), and then the \ufb02ights and airports that may be affected by the volcanoes (\u2018west npac\u2019 region) can be clearly observed (RJFF and RJFR). The detail \ufb02ight information can be found in the timetable and histogram plot (b) while the erupted volcano events are illustrated in the timeline plot (c) by querying the keyword \u2018west npac\u2019. Since all of the \ufb02ights via RJFF and RJFR are happened before the volcano eruption, surrounding \ufb02ights are explored as shown in (d). Moreover, the user may zoom the map to explore the surrounding volcano and volcanic ash (e). ", "caption_bbox": [79, 477, 768, 558]}, {"image_id": 3, "file_name": "529_03.png", "page": 5, "dpi": 300, "bbox": [112, 95, 737, 282], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Use case 2: EngineGreen and EngineBlue show different patterns from 07th Nov 2017 to 05th Dec 2017 (a). By adjusting the time range, the \ufb02ight route of different behaviors are identi\ufb01ed (b). The geo-map under the airport mode with labels indicates the observation (c). ", "caption_bbox": [79, 293, 767, 320]}], "53": [{"image_id": 0, "file_name": "53_00.png", "page": 1, "dpi": 300, "bbox": [454, 748, 715, 1017], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Schematic diagram of optical paths for the 3x1 tiled display. ", "caption_bbox": [421, 1029, 728, 1059]}, {"image_id": 1, "file_name": "53_01.png", "page": 2, "dpi": 300, "bbox": [421, 182, 732, 417], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Front view of one of the tiled projectors, showing the 6-axis positioner in the mounting frame. ", "caption_bbox": [421, 425, 728, 455]}, {"image_id": 2, "file_name": "53_02.png", "page": 2, "dpi": 300, "bbox": [78, 430, 406, 676], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Light path on one projector: each light component is guided by optical fibre and reflected down onto the D-ILA chips by a mirror. ", "caption_bbox": [78, 684, 372, 730]}, {"image_id": 3, "file_name": "53_03.png", "page": 2, "dpi": 300, "bbox": [421, 695, 749, 817], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Seams with and without the masking.", "caption_bbox": [421, 827, 698, 841]}, {"image_id": 4, "file_name": "53_04.png", "page": 3, "dpi": 300, "bbox": [421, 789, 749, 1035], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: 3 x 3 display at the University of California San Diego (courtesy of SDSC-UCSD). ", "caption_bbox": [421, 1043, 746, 1073]}, {"image_id": 5, "file_name": "53_05.png", "page": 3, "dpi": 300, "bbox": [421, 477, 746, 617], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: SKA telescope showing gray levels.", "caption_bbox": [421, 625, 684, 639]}, {"image_id": 6, "file_name": "53_06.png", "page": 3, "dpi": 300, "bbox": [130, 814, 352, 1056], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: CIE coordinates of the tiled display.", "caption_bbox": [106, 1065, 374, 1079]}, {"image_id": 7, "file_name": "53_07.png", "page": 3, "dpi": 300, "bbox": [421, 197, 749, 345], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Viewing angle sensitivity of the display.", "caption_bbox": [440, 353, 728, 367]}, {"image_id": 8, "file_name": "53_08.png", "page": 3, "dpi": 300, "bbox": [102, 390, 379, 614], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: photometry measurements for the three projectors for white flat field. ", "caption_bbox": [78, 626, 403, 656]}, {"image_id": 9, "file_name": "53_09.png", "page": 4, "dpi": 300, "bbox": [78, 854, 394, 1041], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Medical imagery displayed using OpenDX.", "caption_bbox": [78, 1049, 394, 1063]}, {"image_id": 10, "file_name": "53_10.png", "page": 4, "dpi": 300, "bbox": [78, 431, 395, 582], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: SGI performer town on the display.", "caption_bbox": [78, 590, 352, 604]}], "530": [{"image_id": 0, "file_name": "530_00.png", "page": 2, "dpi": 300, "bbox": [82, 98, 771, 486], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) In this visualization, Radviz uses the keyword as a dimension anchor and the GitHub user as an instance. (b) Keyword dimension anchors are displayed in different colors for each field and have a bar chart proportional to the number of related projects. (c) The colors of the user nodes are displayed in a pie chart according to the ratio of the fields. (d) If two keywords appear in the same repository, they are connected. (e) The cumulative area chart shows the change in the amount of generation of the repositories by year. (f) Changes in the keyword ranking of the repository are shown. (g) List of repositories related to the currently selected condition, in the order of popularity. ", "caption_bbox": [79, 492, 767, 559]}, {"image_id": 1, "file_name": "530_01.png", "page": 3, "dpi": 300, "bbox": [84, 820, 409, 913], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A Link between Web (blue nodes) and Mobile (a yellow node) developers. ", "caption_bbox": [79, 919, 408, 945]}, {"image_id": 2, "file_name": "530_02.png", "page": 3, "dpi": 300, "bbox": [80, 395, 413, 521], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: User node of tensorflow (left) and Facebook (right).", "caption_bbox": [79, 522, 373, 534]}, {"image_id": 3, "file_name": "530_03.png", "page": 3, "dpi": 300, "bbox": [436, 170, 771, 400], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A Link between Web (blue nodes) and Mobile (a yellow node) developers. ", "caption_bbox": [438, 407, 767, 433]}, {"image_id": 4, "file_name": "530_04.png", "page": 4, "dpi": 300, "bbox": [439, 118, 772, 630], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Stacked area charts and keyword ranking visualization generated by repositories associated with the keyword 'machine learning'. ", "caption_bbox": [437, 637, 766, 676]}, {"image_id": 5, "file_name": "530_05.png", "page": 4, "dpi": 300, "bbox": [79, 472, 415, 834], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Keyword ranking and repository list generated by the popular user nodes in the Web front-end. ", "caption_bbox": [78, 841, 407, 867]}], "531": [{"image_id": 0, "file_name": "531_00.png", "page": 3, "dpi": 300, "bbox": [122, 104, 728, 290], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The visual analytics pipeline for taxi trajectories, including data analysis module and trajectory visualization module.", "caption_bbox": [119, 294, 729, 307]}, {"image_id": 1, "file_name": "531_01.png", "page": 4, "dpi": 300, "bbox": [455, 414, 747, 734], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Topical sub-trajectories of Topic 3 (a) and Topic 8 (b).", "caption_bbox": [445, 742, 754, 755]}, {"image_id": 2, "file_name": "531_02.png", "page": 4, "dpi": 300, "bbox": [120, 103, 729, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Topic 1 has three sub-trajectory clusters (a): near 2nd Ring Road south section and west section (b), from South 3rd Ring Road 5th section to North 3rd Ring Road 1st section (c), and from the northeast region to the southwest region (d). The detail information of the \ufb01rst cluster is shown in (e) and (f), and the detail information of the third cluster is shown in (g) and (h). ", "caption_bbox": [86, 369, 760, 409]}, {"image_id": 3, "file_name": "531_03.png", "page": 5, "dpi": 300, "bbox": [126, 276, 371, 495], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The result of LDA on the same data.", "caption_bbox": [136, 498, 359, 511]}, {"image_id": 4, "file_name": "531_04.png", "page": 5, "dpi": 300, "bbox": [102, 103, 395, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The topical sub-trajectories from the airport to downtown.", "caption_bbox": [86, 253, 408, 266]}], "532": [{"image_id": 0, "file_name": "532_00.png", "page": 5, "dpi": 300, "bbox": [98, 105, 412, 278], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 2: Number of well-represented documents considering differ- ent number of terms from each document shown in the term list and different sizes of lenses. The total number of documents in the VisPub corpus is 2544. We can see from the \ufb01gure, that for the DocuCompass approach, a lens of size 50 represented 1910 documents with each document had at least \ufb01ve terms shown in the term list during the experiment at least once. The rest 634 documents had not been represented by this lens with more than four terms during the experiment. ", "caption_bbox": [92, 292, 419, 424]}, {"image_id": 1, "file_name": "532_01.png", "page": 5, "dpi": 300, "bbox": [467, 107, 741, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 3: The overall representational quality of documents with DocuCompass approach for the VisPub dataset. the resolution of the visualization is 800 \u00d7 800 pixels. It shows for each document the number of cases where a term from the document was repre- sented in the term list. Dark green glyphs represent well-covered documents and dark brown glyphs badly covered documents. The size of the lens was set to 100 pixels and the term list length ten. ", "caption_bbox": [430, 362, 757, 464]}, {"image_id": 2, "file_name": "532_02.png", "page": 7, "dpi": 300, "bbox": [100, 97, 749, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 4: Relationships between information loss types and quality measures as well as corresponding visual cues. From left to right: The spatial projection quality measures the information loss caused by the spatialization. The user selection quality and the user exploration quality measure the information loss caused by the users\u2019 manual steering of the lens. The focal summarization quality assesses the information loss caused by the summarization step. ", "caption_bbox": [92, 312, 755, 370]}, {"image_id": 3, "file_name": "532_03.png", "page": 13, "dpi": 300, "bbox": [92, 99, 756, 432], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 9: The trajectories of the two group of users at the end of the experiment. The users XC1, XC2, NC1, NC2, NC3 are the ones with visual quality cues. The users X1, X2, N1, N2, N3 worked with systems without visual quality cues. We can see that the trajectories of the non-experts with cues are more similar to the ones of the experts. ", "caption_bbox": [91, 441, 754, 484]}], "533": [{"image_id": 0, "file_name": "533_00.png", "page": 3, "dpi": 300, "bbox": [102, 104, 392, 282], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The pipeline of our system. Our system loads the text col- lection and trains the Gibbs MedLDA to generate topics. The user creates new labels according to the topic visualization and retrains Gibbs MedLDA to re\ufb01ne the classi\ufb01ers. With the updated topic and classi\ufb01cation information, the user continues to label documents to re\ufb01ne the classi\ufb01ers until a satisfactory result is obtained. ", "caption_bbox": [86, 281, 410, 361]}, {"image_id": 1, "file_name": "533_01.png", "page": 4, "dpi": 300, "bbox": [120, 102, 730, 484], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Interface of our system using a result from Signal Media news with seven labels. (a) The label list shows the labels in the text collection, and the glyph presents the basic classi\ufb01cation results of the labels. (b) The topic scatter plot shows the topic and document distributions. (c) The classi\ufb01cation scatter plot displays the classi\ufb01cation results of a classi\ufb01er (Fig. 6). (d) The text list contains documents sorted by uncertainty and supports document labeling. (e) The word cloud shows the keywords of a topic to help users understand the meaning of the topics. (f) The topic weight view helps users understand the classi\ufb01ers. (g) The right-click menu provides training, keyword search, and undo operations. ", "caption_bbox": [86, 483, 762, 563]}, {"image_id": 2, "file_name": "533_02.png", "page": 5, "dpi": 300, "bbox": [455, 104, 747, 197], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Glyph of the education classi\ufb01er. The green and red color represent positive and negative documents, respectively. The pro- portion of user annotated positive or negative documents (the dark color) are compared with the proportion of classi\ufb01er predicted pos- itive or negative documents (the lighter color) via the length of the bars. The bars with greater height show the proportions of user annotated documents that are correctly predicted by classi\ufb01ers. ", "caption_bbox": [438, 196, 762, 289]}, {"image_id": 3, "file_name": "533_03.png", "page": 6, "dpi": 300, "bbox": [104, 106, 393, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (a) Plain text view showing the original information for a document. (b) New label view containing a new label with an initial training set. ", "caption_bbox": [86, 268, 408, 308]}, {"image_id": 4, "file_name": "533_04.png", "page": 6, "dpi": 300, "bbox": [103, 314, 394, 415], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Topic weights for each classi\ufb01er, which can be used to suggest documents in which topics that need to be labeled by users. ", "caption_bbox": [86, 414, 408, 441]}, {"image_id": 5, "file_name": "533_05.png", "page": 7, "dpi": 300, "bbox": [456, 585, 743, 805], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Topic scatter plot of Signal Media news. We add the label stock to further subclassify documents with the label \ufb01nance and economics. ", "caption_bbox": [438, 805, 760, 845]}, {"image_id": 6, "file_name": "533_06.png", "page": 7, "dpi": 300, "bbox": [116, 365, 736, 538], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Classi\ufb01cation result of sports labels in Signal Media news. (a) Creating sports labels. (b) Labeling documents around the classi\ufb01er boundary. (c) Unrelated documents labeled as negative for topic 21. ", "caption_bbox": [86, 543, 760, 570]}, {"image_id": 7, "file_name": "533_07.png", "page": 7, "dpi": 300, "bbox": [93, 103, 756, 339], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Visual exploration process of IEEE visualization publication.", "caption_bbox": [253, 343, 595, 356]}, {"image_id": 8, "file_name": "533_08.png", "page": 9, "dpi": 300, "bbox": [109, 338, 394, 577], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Operation records for \ufb01ve users from the user study. The color of the rectangles represents different operations. It is easy to \ufb01nd new operations and add or modify operations according to the views. ", "caption_bbox": [86, 576, 408, 629]}, {"image_id": 9, "file_name": "533_09.png", "page": 9, "dpi": 300, "bbox": [152, 107, 700, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: F1 score curved lines over the label number of RCV1-V2 classi\ufb01cation. (a) The classi\ufb01cation result of the training set. (b) The classi\ufb01cation result of the testing set. ", "caption_bbox": [86, 298, 760, 325]}], "534": [{"image_id": 0, "file_name": "534_00.png", "page": 2, "dpi": 300, "bbox": [141, 101, 713, 483], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Examples of group-in-a-box (GIB) layouts. The four GIB layouts look different but the original data are the same. (a) ST-GIB is based on tree mapping. (b) CD-GIB considers the links connecting the groups. (c) FD-GIB arranges the boxes with a force-directed layout. (d) TR-GIB is generated by reordering the boxes generated in the ST-GIB layout to minimize group proximity. ", "caption_bbox": [90, 500, 764, 539]}, {"image_id": 1, "file_name": "534_01.png", "page": 4, "dpi": 300, "bbox": [438, 99, 758, 349], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Computed measures of the tested graphs.", "caption_bbox": [473, 365, 719, 378]}, {"image_id": 2, "file_name": "534_02.png", "page": 6, "dpi": 300, "bbox": [114, 99, 388, 242], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Screenshot of the stimulus in Task 2, in which the partici- pants identi\ufb01ed the largest box. ", "caption_bbox": [89, 254, 413, 280]}, {"image_id": 3, "file_name": "534_03.png", "page": 7, "dpi": 300, "bbox": [129, 99, 727, 328], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 3: Gaze count of distractors in Task 2 (standard deviation).", "caption_bbox": [443, 908, 748, 921]}, {"image_id": 4, "file_name": "534_04.png", "page": 8, "dpi": 300, "bbox": [485, 98, 707, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Trajectory map for Task 4. The gaze movement is repre- sented with a pink line and gaze aggregation can be seen on the bundles of inter-links. ", "caption_bbox": [434, 260, 758, 299]}, {"image_id": 5, "file_name": "534_05.png", "page": 8, "dpi": 300, "bbox": [96, 98, 390, 567], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 4: Gaze count of distractors in Task 3 (standard deviation).", "caption_bbox": [443, 913, 748, 926]}, {"image_id": 6, "file_name": "534_06.png", "page": 9, "dpi": 300, "bbox": [462, 101, 733, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The website we constructed. This site provides the four GIB layouts together with further interactive analysis. ", "caption_bbox": [434, 293, 756, 319]}], "535": [{"image_id": 0, "file_name": "535_00.png", "page": 2, "dpi": 300, "bbox": [466, 334, 723, 416], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: What \u2014 data abstraction for different interviews. Icons derived from [11, Chap. 2] under CC BY-4.0 Licence. ", "caption_bbox": [434, 415, 756, 441]}, {"image_id": 1, "file_name": "535_01.png", "page": 3, "dpi": 300, "bbox": [90, 100, 766, 211], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Why \u2014 task abstraction for different interviews. Icons derived from [11, Chap. 3] under CC BY-4.0 Licence.", "caption_bbox": [152, 213, 701, 228]}], "536": [], "537": [{"image_id": 0, "file_name": "537_00.png", "page": 2, "dpi": 300, "bbox": [103, 87, 741, 215], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visual encodings design channel breakdown.", "caption_bbox": [286, 227, 561, 240]}, {"image_id": 1, "file_name": "537_01.png", "page": 3, "dpi": 300, "bbox": [117, 268, 363, 389], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Mean response time per channel.", "caption_bbox": [133, 401, 348, 414]}, {"image_id": 2, "file_name": "537_02.png", "page": 3, "dpi": 300, "bbox": [121, 82, 359, 203], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Mean percentage of fixation time per region (image cour- tesy of Henderson et al. [24]). ", "caption_bbox": [73, 215, 410, 242]}, {"image_id": 3, "file_name": "537_03.png", "page": 4, "dpi": 300, "bbox": [99, 304, 361, 479], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Analysis of accuracy results for Task 4 \u2013 Parameters Estimation. Results shown for each visual encoding, (mean, median) values are indicated below each bar. Error bars show 95% confidence intervals. ", "caption_bbox": [73, 481, 410, 536]}, {"image_id": 4, "file_name": "537_04.png", "page": 4, "dpi": 300, "bbox": [74, 74, 775, 250], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Analysis of accuracy results for Task 1, 2 & 3 respectively. Results shown for each visual encoding, (mean, median) values are indicated below each bar. Error bars show 95% confidence intervals. ", "caption_bbox": [73, 257, 775, 284]}, {"image_id": 5, "file_name": "537_05.png", "page": 5, "dpi": 300, "bbox": [77, 76, 773, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Analysis of response time results for Task 1, 2, & 3 respectively. Results shown for each visual encoding.", "caption_bbox": [136, 250, 712, 263]}, {"image_id": 6, "file_name": "537_06.png", "page": 5, "dpi": 300, "bbox": [116, 275, 364, 454], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Analysis of response time results for Tasks 4 \u2013 Parameters Estimation with balanced Emoji glyph. Results shown for each visual encoding. ", "caption_bbox": [73, 458, 409, 499]}, {"image_id": 7, "file_name": "537_07.png", "page": 7, "dpi": 300, "bbox": [65, 75, 774, 207], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Manhattan distances of target versus answer for Task 3. Data shows the number of incorrect answers and distance from target.", "caption_bbox": [84, 220, 763, 233]}, {"image_id": 8, "file_name": "537_08.png", "page": 8, "dpi": 300, "bbox": [79, 75, 766, 286], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Analysis of accuracy results for Task 1 & 4 \u2013 Parameters Estimation (unbalanced vs. balanced). Results are broken down by channel for each visual encoding, (mean, median) values are indicated below each bar. Error bars show 95% confidence intervals. ", "caption_bbox": [73, 290, 775, 317]}, {"image_id": 9, "file_name": "537_09.png", "page": 8, "dpi": 300, "bbox": [76, 335, 776, 508], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Analysis of response time results for Task 1 & 4 \u2013 Parameters Estimation (unbalanced vs. balanced). Results are broken down by channel for each visual encoding. ", "caption_bbox": [73, 517, 775, 544]}, {"image_id": 10, "file_name": "537_10.png", "page": 9, "dpi": 300, "bbox": [96, 302, 749, 488], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Pairwise Analysis of response time results of Chernoff, Emoji and Star glyphs for Task 1 & 4.", "caption_bbox": [162, 492, 687, 505]}, {"image_id": 11, "file_name": "537_11.png", "page": 9, "dpi": 300, "bbox": [95, 74, 750, 275], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Pairwise analysis of performance results of Chernoff, Emoji and Star glyphs for Task 1 & 4.", "caption_bbox": [166, 278, 682, 291]}], "538": [{"image_id": 0, "file_name": "538_00.png", "page": 2, "dpi": 300, "bbox": [152, 100, 704, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualizations deployed in the laboratory cafeteria", "caption_bbox": [281, 345, 571, 358]}, {"image_id": 1, "file_name": "538_01.png", "page": 3, "dpi": 300, "bbox": [130, 100, 726, 400], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Space where visualizations were deployed. Details: (A) kitchen counter, (B) watercooler and (C) bathroom and (D) mural", "caption_bbox": [110, 412, 743, 425]}, {"image_id": 2, "file_name": "538_02.png", "page": 4, "dpi": 300, "bbox": [487, 301, 706, 550], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Four of the glyphs shown in the Personal Activities visual- ization, with their corresponding MAC addresses. The top right chart shows a person predominantly present in the afternoons; bottom- right someone mostly present in the mornings. ", "caption_bbox": [435, 566, 759, 619]}, {"image_id": 3, "file_name": "538_03.png", "page": 4, "dpi": 300, "bbox": [88, 98, 415, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Detail of the bottom right quadrant of the Activity Clock, with the hour hand omitted. There is more variation and a higher median in the number of people in the cafeteria at 11-12am than 1-2pm. ", "caption_bbox": [88, 440, 413, 493]}], "539": [{"image_id": 0, "file_name": "539_00.png", "page": 3, "dpi": 300, "bbox": [448, 99, 748, 243], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Skeleton generation for the Spiral dataset. The scatterplot (left) is convolved with a Gaussian kernel, and a compact shape (blue in right image) is obtained by thresholding the expected average density. The skeleton of this shape is shown in red in the right image. ", "caption_bbox": [435, 253, 769, 307]}, {"image_id": 1, "file_name": "539_01.png", "page": 3, "dpi": 300, "bbox": [458, 676, 748, 876], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: PG generation from skeleton of Spiral dataset. The image and inset show graph vertices or control points (yellow), graph edges (red), and original scatterplot points (blue). ", "caption_bbox": [434, 888, 768, 929]}, {"image_id": 2, "file_name": "539_02.png", "page": 4, "dpi": 300, "bbox": [131, 802, 364, 893], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: (left) Voronoi cells for graph G. (right) Union V N of neighboring Voronoi cells that affect two selected control points marked red and green, respectively, for gSPG = 1. Control points move in the direction of their respective centroids. ", "caption_bbox": [78, 903, 412, 957]}, {"image_id": 3, "file_name": "539_03.png", "page": 4, "dpi": 300, "bbox": [82, 262, 414, 385], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Closest points (small dots) to a set of control points (large dots) for Spiral dataset. Color indicates which scatterplot points are associated to which control points. ", "caption_bbox": [78, 395, 412, 436]}, {"image_id": 4, "file_name": "539_04.png", "page": 4, "dpi": 300, "bbox": [520, 647, 684, 783], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Generating curve (green) for scatterplot (blue), skeleton (red), and computed principal curve (yellow) for Spiral dataset. We observe very good agreement between the three curves. Small vari- ations in shape may result in diverging curves for skeleton-based summarizations (black frame) [28]. ", "caption_bbox": [434, 793, 770, 861]}, {"image_id": 5, "file_name": "539_05.png", "page": 5, "dpi": 300, "bbox": [115, 374, 376, 498], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Datasets with varying degrees of complexity, noise, and sizes, used in our evaluation. ", "caption_bbox": [78, 958, 412, 985]}, {"image_id": 6, "file_name": "539_06.png", "page": 6, "dpi": 300, "bbox": [146, 101, 698, 501], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Principal graphs for three datasets of increasing complexity (self-intersections and loops). (a) Spiral. (b) Helix. (c) Rune. Our method (SPG) tested against two state-of-the-art methods (KPG, KDE-SCMS) as well as the data-generating curves. ", "caption_bbox": [78, 512, 766, 539]}, {"image_id": 7, "file_name": "539_07.png", "page": 7, "dpi": 300, "bbox": [84, 99, 749, 513], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Computation time for principal graphs for Spiral, Helix, and Rune datasets with varying number of points, noise levels, and resolutions rSPG \u2208 {128, 192, 256}. Our approach outperforms KDE-SCMS and KPG in terms of computational speed. ", "caption_bbox": [82, 525, 770, 554]}, {"image_id": 8, "file_name": "539_08.png", "page": 8, "dpi": 300, "bbox": [132, 407, 363, 604], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Distance between principal graphs and generating curves for different datasets and values of the kernel size \u03c3SPG ", "caption_bbox": [78, 617, 412, 646]}, {"image_id": 9, "file_name": "539_09.png", "page": 8, "dpi": 300, "bbox": [132, 100, 363, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Graph-theoretic scagnostics measures (computed using R [48]) for differently skewed datasets of same shape deliver (al- most) the same result. ", "caption_bbox": [434, 517, 770, 558]}, {"image_id": 10, "file_name": "539_10.png", "page": 8, "dpi": 300, "bbox": [450, 100, 754, 258], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: (top) Differently skewed data distributions for scatterplots of same shape: a) unskewed; b) negatively skewed; c) positively skewed. [28] computes equal curves regardless of variation in density. (bottom) SPG captures the skewed distributions leading to respec- tively shifted PGs (red) , (e) below the curve for negatively skewed distribution and (f) above for positively skewed, (d) overlapping the generating curve (green). ", "caption_bbox": [434, 268, 770, 363]}, {"image_id": 11, "file_name": "539_11.png", "page": 9, "dpi": 300, "bbox": [214, 100, 630, 485], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Visual data analysis of abalone dataset [11]. Middle column: MDS plots of 100 scatterplots for different weights w\u03c3 and w\u03c1 of the extended Hausdorff distance. Left and right columns: Selected scatterplots from the MDS plot in the respective row. Top row: decrease of variation from left (a) to right (b) in the MDS plot (w\u03c3 = 0.5). Middle row: Standard Hausdorff distance shows linear structures (c) at the bottom of the MDS plot and curved structures (d) at the top. Bottom row: Elongated scatterplots with same density behaviour along the PC show high similarity in MDS plot (w\u03c1 = 0.5). ", "caption_bbox": [77, 498, 765, 568]}], "54": [{"image_id": 0, "file_name": "54_00.png", "page": 2, "dpi": 300, "bbox": [230, 90, 579, 502], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The VARE architecture is based on a client/server model, with the server being split into repositories", "caption_bbox": [71, 513, 737, 532]}, {"image_id": 1, "file_name": "54_01.png", "page": 3, "dpi": 300, "bbox": [416, 745, 772, 953], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Native XML Databases store XML docu-", "caption_bbox": [415, 964, 737, 983]}, {"image_id": 2, "file_name": "54_02.png", "page": 4, "dpi": 300, "bbox": [92, 87, 718, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The XDSE architecture is based on the client/server model. The web interface communicates with", "caption_bbox": [71, 271, 737, 290]}, {"image_id": 3, "file_name": "54_03.png", "page": 4, "dpi": 300, "bbox": [415, 790, 697, 890], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: An XQuery query to generate a UML class", "caption_bbox": [415, 913, 737, 932]}, {"image_id": 4, "file_name": "54_04.png", "page": 5, "dpi": 300, "bbox": [160, 88, 650, 500], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The XDSE web interface where a user can create, delete, or list program trace collections; add,", "caption_bbox": [71, 509, 737, 528]}, {"image_id": 5, "file_name": "54_05.png", "page": 5, "dpi": 300, "bbox": [71, 645, 373, 1000], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The results of performing the query in", "caption_bbox": [71, 1023, 393, 1042]}, {"image_id": 6, "file_name": "54_06.png", "page": 6, "dpi": 300, "bbox": [71, 87, 403, 422], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A SOAP request to query test.pal. The", "caption_bbox": [71, 442, 393, 461]}, {"image_id": 7, "file_name": "54_07.png", "page": 7, "dpi": 300, "bbox": [70, 285, 767, 843], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A SVG interactive class diagram generated by Blur (a visualisation tool) from a PAL program trace", "caption_bbox": [71, 853, 737, 872]}, {"image_id": 8, "file_name": "54_08.png", "page": 8, "dpi": 300, "bbox": [79, 246, 764, 881], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A SVG interactive sequence diagram generated by Blur from a PAL program trace document of run-", "caption_bbox": [71, 891, 737, 910]}], "540": [{"image_id": 0, "file_name": "540_00.png", "page": 2, "dpi": 300, "bbox": [519, 469, 682, 618], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A drawing example of complex graphs", "caption_bbox": [486, 646, 713, 659]}, {"image_id": 1, "file_name": "540_01.png", "page": 2, "dpi": 300, "bbox": [112, 652, 385, 872], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Operation span and symmetry span sequences, adapted from Foster et al. [7]. ", "caption_bbox": [86, 885, 408, 910]}, {"image_id": 2, "file_name": "540_02.png", "page": 2, "dpi": 300, "bbox": [533, 691, 668, 865], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: A drawing example of simple graphs", "caption_bbox": [490, 881, 708, 894]}, {"image_id": 3, "file_name": "540_03.png", "page": 3, "dpi": 300, "bbox": [86, 103, 420, 215], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Descriptive statictics, and variable intercorrelations for Low Complexity ", "caption_bbox": [438, 102, 761, 127]}], "541": [{"image_id": 0, "file_name": "541_00.png", "page": 2, "dpi": 300, "bbox": [95, 100, 763, 246], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 1. The basic pivot: On the left, the dark set of seed nodes are selected. The selection then swings out to a subset of neighboring target nodes (middle, red), resulting in a new set of seed nodes (right). ", "caption_bbox": [95, 258, 760, 283]}, {"image_id": 1, "file_name": "541_01.png", "page": 3, "dpi": 300, "bbox": [86, 98, 414, 276], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 2. To \ufb01nd patients of a given doctor that are covered by a certain insurance provider, the user starts by \ufb01ltering the doctor nodes down to a single doctor (D  ). The user then pivots to patients (P1 ), then to insurance providers (I   , where another \ufb01lter is applied), then back to patients (P2 ). However, when the user pivots back to patients, the pivot returns all of the patients with the speci\ufb01ed insurance provider, but not necessarily patients of the original doctor (in red). ", "caption_bbox": [86, 288, 412, 375]}, {"image_id": 2, "file_name": "541_02.png", "page": 4, "dpi": 300, "bbox": [443, 99, 755, 368], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 4. When \ufb01lters are applied to a selection of nodes, a line is placed at the top of the interface to indicate that the \ufb01lter is active (A). Because the difference between fanning in and fanning out is so critical, it can be toggled in two ways: a global scope button inside the search \ufb01eld removes or restores all \ufb01lters, or individual \ufb01lters can be removed by \u201csnipping\u201d the line. Note how, in A, only one Team node can be se- lected, because the \ufb01lter is still in place. Clicking \u201cTeam\u201d will fan in. In B, because the global scope button has been clicked, the set of available Team nodes is larger; the \ufb01lter has been removed. Clicking \u201cTeam\u201d will fan out. ", "caption_bbox": [435, 382, 761, 505]}, {"image_id": 3, "file_name": "541_03.png", "page": 4, "dpi": 300, "bbox": [87, 99, 412, 595], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 3. Jacob\u2019s Ladder allows users to pivot from one category of nodes to another. A search box (A) shows search matches in the menu be- low. Matching nodes can be selected in aggregate, based on node type (\u201cTeam\u201d or \u201cStadium\u201d above the line), or individually based on value (be- low the line). Once a set of nodes has been selected, it is displayed as a histogram on the left of the search \ufb01eld (B). Subsequent searches are limited to the set of nodes that are connected to the previous selection, with line thickness encoding potential connections. The histogram sup- ports regrouping and sorting (C), as well as selecting and \ufb01ltering nodes (D) based on node attributes. The series of actions depicted are as fol- lows: A) Florida State is selected, B) the user pivots to Florida State\u2019s players, C) players are grouped by position, and D) the wide receivers (\u201cWR\u201d) are selected. ", "caption_bbox": [86, 609, 412, 769]}, {"image_id": 4, "file_name": "541_04.png", "page": 5, "dpi": 300, "bbox": [94, 101, 762, 257], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 5. This table shows details about each of the eleven participants, including their relative expertise and suggestive indicators that emerged as the study progressed. Participants are classi\ufb01ed as \u201cNovices\u201d when they self-reported little to no understanding or prior experience, \u201cIntermediate\u201d when they reported or demonstrated some familiarity, but no strong interest or experience, and \u201cExpert\u201d when they reported or demonstrated strong interest or experience. \u2217 This participant brie\ufb02y clicked the button at an inappropriate point, but quickly reverted the decision. \u2020 This participant speci\ufb01cally asked about the \ufb01lter lines, so they were given an explanation. \u2021 Technically, this participant found the \u201cfumble return\u201d attribute\u2014a different attribute of the Player-Game Statistics node type. Structurally, this is equivalent. ", "caption_bbox": [95, 269, 760, 343]}, {"image_id": 5, "file_name": "541_05.png", "page": 6, "dpi": 300, "bbox": [94, 99, 763, 224], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 6. We can see that ambiguity in a series of pivots only arises when \ufb01lters and cycles occur in the same traversal; when cycles are present without \ufb01lters (A), the only logical action is to fan out. When \ufb01lters are present, without cycles (B), the only logical action is to keep the \ufb01lter in place and fan in. However, when both are present (C), it is not clear whether to fan in or fan out: should the initial \ufb01lter on the Doctor nodes be reapplied? ", "caption_bbox": [95, 236, 760, 274]}, {"image_id": 6, "file_name": "541_06.png", "page": 8, "dpi": 300, "bbox": [94, 99, 762, 241], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 7. In this scenario, doctors frequently perform connective \ufb01ltering on potential treatments by the insurance companies that have covered those treatments for patients in the past. The system observes this behavior, and adapts the underlying data abstraction in response, adding direct connections between treatments and insurance companies through patients. ", "caption_bbox": [94, 253, 759, 291]}], "542": [{"image_id": 0, "file_name": "542_00.png", "page": 3, "dpi": 300, "bbox": [434, 99, 778, 310], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualisation of a selected brain region together with the corresponding activity time series on the data view wall. By using \ufb01nger-beam representation, a ROI can be selected, which is then highlighted and its neighbourhood in the FCN is shown. ", "caption_bbox": [435, 323, 760, 375]}, {"image_id": 1, "file_name": "542_01.png", "page": 4, "dpi": 300, "bbox": [86, 99, 413, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Complementary visual representations of an FCN, as a free 3D layout, as a adjacency matrix, and embedded in the anatomical model. Correlation values are mapped to a colour gradient. Interactive exploration is supported by selecting regions in the matrix representa- tions and dynamically updating linked views during selection. ", "caption_bbox": [86, 332, 413, 397]}], "543": [{"image_id": 0, "file_name": "543_00.png", "page": 2, "dpi": 300, "bbox": [442, 726, 766, 837], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Illustration of the mesh used for deformation.", "caption_bbox": [467, 850, 739, 863]}, {"image_id": 1, "file_name": "543_01.png", "page": 3, "dpi": 300, "bbox": [457, 104, 751, 405], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The moving trend of the data caused by the \ufb01nger move- ment. (c) and (d) are cross sections of the mesh. ", "caption_bbox": [439, 417, 770, 444]}, {"image_id": 2, "file_name": "543_02.png", "page": 4, "dpi": 300, "bbox": [180, 99, 312, 201], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Illustrating the computation of d(v, S f ) as in Eqaution 4.", "caption_bbox": [81, 209, 406, 227]}, {"image_id": 3, "file_name": "543_03.png", "page": 4, "dpi": 300, "bbox": [459, 321, 751, 558], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Illustrating the cutting operation. The mesh resolutions in (b) and (e) are intentionally reduced for easier view. ", "caption_bbox": [438, 572, 767, 599]}, {"image_id": 4, "file_name": "543_04.png", "page": 5, "dpi": 300, "bbox": [457, 94, 744, 215], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The work\ufb02ow of using our system on a touchscreen.", "caption_bbox": [450, 225, 756, 238]}, {"image_id": 5, "file_name": "543_05.png", "page": 5, "dpi": 300, "bbox": [449, 406, 760, 552], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Find the 3D location from a 2D touch point.", "caption_bbox": [471, 563, 736, 576]}, {"image_id": 6, "file_name": "543_06.png", "page": 6, "dpi": 300, "bbox": [99, 151, 389, 245], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: An example of the process of dragging.", "caption_bbox": [122, 257, 365, 270]}, {"image_id": 7, "file_name": "543_07.png", "page": 7, "dpi": 300, "bbox": [96, 701, 392, 850], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: An example of exploring the viscous \ufb02uid dataset.", "caption_bbox": [96, 862, 391, 875]}, {"image_id": 8, "file_name": "543_08.png", "page": 7, "dpi": 300, "bbox": [444, 352, 768, 675], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: The second example of exploring the viscous \ufb02uid dataset.", "caption_bbox": [439, 687, 768, 700]}, {"image_id": 9, "file_name": "543_09.png", "page": 9, "dpi": 300, "bbox": [89, 101, 760, 234], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The example of exploring the streamlines of the Plume data.", "caption_bbox": [248, 246, 599, 259]}], "544": [{"image_id": 0, "file_name": "544_00.png", "page": 1, "dpi": 300, "bbox": [93, 60, 763, 462], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Our system uses HoloLens to allow analysts to view sensitive information while collaborating in front of a wall display. (a): Two analysts in a collaborative analysis session wearing HoloLens over their work. (b): The left analyst\u2019s view through HoloLens. (c): The right analyst\u2019s view through HoloLens. For demonstration purpose, both public and private nodes and links are shown on the wall display. In practice, only the white nodes and links are shown on the wall display. The yellow nodes and links are shown in the left analyst\u2019s HoloLens while the blue nodes and links are shown in the right analyst\u2019s HoloLens. ", "caption_bbox": [119, 475, 737, 540]}, {"image_id": 1, "file_name": "544_01.png", "page": 4, "dpi": 300, "bbox": [481, 104, 713, 280], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Users with different levels of information access see different amounts of information through our prototype system. ", "caption_bbox": [434, 292, 759, 318]}, {"image_id": 2, "file_name": "544_02.png", "page": 4, "dpi": 300, "bbox": [86, 588, 415, 827], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The insight graph is created based on the story of Enron\u2019s downfall in 2001. ", "caption_bbox": [87, 839, 412, 865]}, {"image_id": 3, "file_name": "544_03.png", "page": 4, "dpi": 300, "bbox": [434, 439, 762, 707], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The user study environment has enough space in front of the wall-size display for the participants to move around freely. ", "caption_bbox": [434, 719, 759, 745]}, {"image_id": 4, "file_name": "544_04.png", "page": 5, "dpi": 300, "bbox": [85, 98, 414, 524], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: A client-server con\ufb01guration is used to serve and synchro- nize content between the wall-size display and the HoloLens headsets. The major technology used for each component of the con\ufb01guration is listed. ", "caption_bbox": [85, 536, 413, 588]}, {"image_id": 5, "file_name": "544_05.png", "page": 6, "dpi": 300, "bbox": [451, 312, 746, 703], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The upper picture shows the entire insight graph, and the bottom picture is a zoomed-in, mixed-reality view captured from HoloLens showing HoloLens visualization overlayed on the wall dis- play. The white nodes and links are shown in the shared display, the yellow nodes and links are only shown in the HoloLens of one participant, and the blue nodes and links are only shown to the other participant. The content inside the blue dashed box can only be seen through HoloLens. The content shown on the shared display and the content rendered by HoloLens fuse together into a seamless picture when viewed through HoloLens. Furthermore, a popup panel with additional information of selected nodes is only shown in HoloLens. ", "caption_bbox": [434, 716, 761, 857]}, {"image_id": 6, "file_name": "544_06.png", "page": 8, "dpi": 300, "bbox": [85, 101, 770, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Post-study questionnaire results show that people believe that adding OST-HMDs to a wall-size display helps collaborative visualization. For the comparison of physical navigation and dragging, participants do not have a strong opinion but leaning toward dragging. However, more statistical results are required to verify this. ", "caption_bbox": [86, 311, 768, 350]}], "545": [{"image_id": 0, "file_name": "545_00.png", "page": 1, "dpi": 300, "bbox": [113, 60, 742, 442], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Before (left) and after (right) coordinated distortion emphasis of two subsets (denoted by pink and teal highlight) of the displayed entities on four views. On the right panel, a single entity is highlighted in yellow. The input data is a citation graph extracted from the Open Research Corpus [1] in which nodes are research papers and edges are citing relationships. The graph is displayed as a node-link diagram (a) and as an adjacency matrix (b). (c) and (d) display properties of the papers. ", "caption_bbox": [122, 451, 732, 504]}, {"image_id": 1, "file_name": "545_01.png", "page": 4, "dpi": 300, "bbox": [438, 554, 756, 672], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: From a map of interest to distortion. The left plot shows the initial entity positions, and the interest \ufb01eld induced by the doi mapped to a color scale, with 1 being the highest interest. The interest \ufb01eld is computed by averaging the x and y magni\ufb01cation functions. The right plot shows the distorted entity positions and the distorted interest \ufb01eld. Notice the stretching of areas of higher interest (yellow) and the shrinking of those of lesser interest (violet). ", "caption_bbox": [434, 684, 756, 777]}, {"image_id": 2, "file_name": "545_02.png", "page": 5, "dpi": 300, "bbox": [482, 100, 711, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Schematic view of a constrained transformation function T of a 1D space (right) and its corresponding magni\ufb01cation function M (left). Areas of magni\ufb01cation (respectively demagni\ufb01cation) cor- respond to local slope ratio greater than 1 (respectively lower than 1) on T . Intervals are shrunk in demagni\ufb01ed areas (e.g. [A, B] mapped to [A  , B  ]) and enlarged in magni\ufb01ed areas (e.g. [D, E] mapped to [D  , E   ]). Around C, T is identical to the identity transformation (in dotted orange) therefore its image C  under T is identical to C relative to the domain. M is null from F to G therefore their images, F   and G  , are the same. ", "caption_bbox": [434, 226, 758, 359]}, {"image_id": 3, "file_name": "545_03.png", "page": 5, "dpi": 300, "bbox": [111, 100, 389, 238], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Overview of the method. The distortion process occurs at the mapping stage, once an initial pass has associated positions to every visual entity on each view. Distortion functions (ti ) are computed over 1-dimensional spaces, based on the doi and the initial entity positions (pi ). Distortion functions are subsequently applied to input entity positions and the resulting positions p i = ti \u25e6 pi are remapped to obtain the distorted views. ", "caption_bbox": [90, 248, 412, 341]}, {"image_id": 4, "file_name": "545_04.png", "page": 5, "dpi": 300, "bbox": [450, 671, 743, 797], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Schematic view of the computation of wD       i for the x- domains of two scatterplots. Di is the distribution of the value of pi .                                                                 i is wDi is the distribution of values of pi weighted by their doi. wD the smoothing of wDi , it associates an interest value to every point. ", "caption_bbox": [434, 804, 758, 866]}, {"image_id": 5, "file_name": "545_05.png", "page": 6, "dpi": 300, "bbox": [455, 101, 737, 398], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Examples of magni\ufb01cation (m) and transformation (t) for a set of entities E = {e1 , e2 , e3 , e4 , e5 }. The left column displays m, wD and wD for different doi, with \u03b1 = 0.6. The middle column shows the corresponding t and the right column is the plot of the distorted positions. The top row displays undistorted positions. doi values are uniform on the middle row, and non-uniform on the bottom row, with e4 and e5 being the entities of highest interest. Shadowed intervals cover points that belong to no area of in\ufb02uence. ", "caption_bbox": [434, 411, 758, 520]}, {"image_id": 6, "file_name": "545_06.png", "page": 7, "dpi": 300, "bbox": [446, 615, 746, 711], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Effect of increasing the interpolation parameter \u03b1. The left-most plot is undistorted and acts as a reference for the others, distorted based on the same doi displayed in brackets and mapped to mark size (h = 1/8, boxcar kernel). ", "caption_bbox": [434, 721, 757, 778]}, {"image_id": 7, "file_name": "545_07.png", "page": 7, "dpi": 300, "bbox": [445, 141, 746, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Effect of increasing the bandwidth h (from left to right). Top plots are undistorted and show the extents of kernels in teal. Bottom plots are distorted based on the same doi, displayed in brackets and mapped to mark size (\u03b1 = 1, boxcar kernel). ", "caption_bbox": [434, 348, 758, 403]}, {"image_id": 8, "file_name": "545_08.png", "page": 7, "dpi": 300, "bbox": [101, 493, 402, 685], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Effect of increasing the doi of the entity e3 , from left to right, relative to null (top) and uniform (bottom) doi values for other entities. The area of in\ufb02uence of e3 is represented in teal. On distorted plots it may appear non-square. doi values are displayed in brackets and mapped to mark size (\u03b1 = 1, h = 1/8, boxcar kernel). ", "caption_bbox": [90, 698, 412, 766]}, {"image_id": 9, "file_name": "545_09.png", "page": 8, "dpi": 300, "bbox": [438, 527, 748, 737], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Examples of distortion applied to mark shapes rather than points (doi( ) = 1, doi( ) = 0). ", "caption_bbox": [434, 749, 756, 777]}, {"image_id": 10, "file_name": "545_10.png", "page": 8, "dpi": 300, "bbox": [94, 101, 404, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Straightforward applications for point-like visualizations with axis coordinates as 1D input positions for distortion (doi( ) = 1, doi( ) = 0). Notice the marks circled in teal, completely or partly concealed on the top and clearly visible on the bottom. ", "caption_bbox": [89, 308, 413, 361]}, {"image_id": 11, "file_name": "545_11.png", "page": 8, "dpi": 300, "bbox": [438, 103, 740, 295], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Application on node-link diagrams of graphs and rooted tree. Here, Cartesian coordinates are used as input positions for distortion (only abscissa for c). (doi( ) = 1, doi( ) = 0). ", "caption_bbox": [434, 307, 756, 348]}], "55": [{"image_id": 0, "file_name": "55_00.png", "page": 1, "dpi": 300, "bbox": [460, 279, 688, 604], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: crossings in two different drawings", "caption_bbox": [450, 622, 726, 636]}, {"image_id": 1, "file_name": "55_01.png", "page": 2, "dpi": 300, "bbox": [481, 56, 693, 208], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: an arch", "caption_bbox": [534, 226, 642, 240]}, {"image_id": 2, "file_name": "55_02.png", "page": 2, "dpi": 300, "bbox": [114, 55, 346, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: two drawing models in this paper", "caption_bbox": [111, 359, 376, 373]}, {"image_id": 3, "file_name": "55_03.png", "page": 2, "dpi": 300, "bbox": [441, 254, 742, 620], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: two kinds of tower structure (edge set E3 is omitted) ", "caption_bbox": [427, 642, 749, 670]}, {"image_id": 4, "file_name": "55_04.png", "page": 3, "dpi": 300, "bbox": [96, 55, 385, 260], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: crossings in a single tower embedding", "caption_bbox": [99, 278, 389, 292]}, {"image_id": 5, "file_name": "55_05.png", "page": 4, "dpi": 300, "bbox": [95, 494, 339, 721], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: two kinds of shell embedding(edges in E5 are omitted) ", "caption_bbox": [83, 740, 404, 768]}, {"image_id": 6, "file_name": "55_06.png", "page": 4, "dpi": 300, "bbox": [479, 55, 695, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: crossings in a single shell embedding", "caption_bbox": [446, 382, 730, 396]}, {"image_id": 7, "file_name": "55_07.png", "page": 4, "dpi": 300, "bbox": [136, 255, 359, 482], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: a region formed by tracki and (z1 , z2 )", "caption_bbox": [98, 226, 390, 242]}, {"image_id": 8, "file_name": "55_08.png", "page": 5, "dpi": 300, "bbox": [182, 55, 302, 263], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: dashed lines can only be drawn as arcs to minimize the crossings ", "caption_bbox": [83, 278, 405, 306]}], "56": [{"image_id": 0, "file_name": "56_00.png", "page": 2, "dpi": 300, "bbox": [109, 463, 409, 799], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Spherical display setup giving approximate positioning. ", "caption_bbox": [133, 812, 394, 841]}, {"image_id": 1, "file_name": "56_01.png", "page": 2, "dpi": 300, "bbox": [431, 778, 742, 860], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Displayed images from left to right, projector 1 (left projector), the computer screen, and Projector 2 (right projector). Spherical world map provided courtesy of NASA/JPL-Caltech (http://maps.jpl.nasa.gov). ", "caption_bbox": [455, 866, 715, 940]}, {"image_id": 2, "file_name": "56_02.png", "page": 3, "dpi": 300, "bbox": [149, 509, 351, 705], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Optical mouse placement for detecting the spherical rotation. ", "caption_bbox": [133, 711, 394, 740]}, {"image_id": 3, "file_name": "56_03.png", "page": 4, "dpi": 300, "bbox": [434, 352, 737, 620], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Similar to Figure 4, this photo shows the nodes in Asia, and connections to Europe. ", "caption_bbox": [455, 626, 715, 655]}, {"image_id": 4, "file_name": "56_04.png", "page": 4, "dpi": 300, "bbox": [434, 74, 737, 301], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A photograph taken of the AS node visualisation  on   our    three-dimensional spherical display.    It shows the heavy ", "caption_bbox": [455, 307, 707, 351]}, {"image_id": 5, "file_name": "56_05.png", "page": 5, "dpi": 300, "bbox": [113, 74, 413, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Zoomed in on Australia. There is a strong internet communication on Alice Springs. ", "caption_bbox": [133, 267, 393, 296]}], "57": [{"image_id": 0, "file_name": "57_00.png", "page": 1, "dpi": 300, "bbox": [434, 534, 712, 654], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1 The RGB colour space (left) and the HSV colour space (right) ", "caption_bbox": [422, 665, 747, 695]}, {"image_id": 1, "file_name": "57_01.png", "page": 2, "dpi": 300, "bbox": [467, 229, 704, 565], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3 The RGB(top) and the CIELab (bottom) Colour Picker in Adobe Photoshop ", "caption_bbox": [422, 576, 747, 606]}, {"image_id": 2, "file_name": "57_02.png", "page": 2, "dpi": 300, "bbox": [155, 91, 328, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2 The Munsell Colour Space (top) and the          CIELab colour space1 (bottom) ", "caption_bbox": [94, 384, 387, 414]}, {"image_id": 3, "file_name": "57_03.png", "page": 3, "dpi": 300, "bbox": [115, 196, 368, 562], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4 The Munsell Colour Picker by Penn State University (top) and the Triplecode Munsell Palette2 (bottom) ", "caption_bbox": [78, 573, 389, 619]}, {"image_id": 4, "file_name": "57_04.png", "page": 4, "dpi": 300, "bbox": [87, 974, 396, 1061], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6 The control panel", "caption_bbox": [160, 1074, 320, 1089]}, {"image_id": 5, "file_name": "57_05.png", "page": 4, "dpi": 300, "bbox": [108, 81, 368, 181], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5 Two Kochanek-Bartels Cubic Splines with the same anchor points but different parameters. ", "caption_bbox": [78, 196, 385, 227]}, {"image_id": 6, "file_name": "57_06.png", "page": 4, "dpi": 300, "bbox": [431, 83, 745, 407], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7 The RGB Colour Cube and colour palettes when the translucent plane is in different positions ", "caption_bbox": [430, 419, 738, 450]}, {"image_id": 7, "file_name": "57_07.png", "page": 5, "dpi": 300, "bbox": [105, 261, 374, 423], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8 Division of the polygon into sub-regions.", "caption_bbox": [94, 439, 388, 454]}, {"image_id": 8, "file_name": "57_08.png", "page": 5, "dpi": 300, "bbox": [425, 78, 745, 169], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9 The HSV colour solid is divided into tetrahedrons for rendering ", "caption_bbox": [422, 181, 747, 212]}, {"image_id": 9, "file_name": "57_09.png", "page": 5, "dpi": 300, "bbox": [451, 488, 719, 731], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10 If the plane goes through the central axis, the colour palette (left) contains the full range of hues. ", "caption_bbox": [422, 751, 747, 782]}, {"image_id": 10, "file_name": "57_10.png", "page": 6, "dpi": 300, "bbox": [86, 77, 394, 269], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11 If the plane does not go through the centre axis, the colour palette (left) contains only a subset of hues. ", "caption_bbox": [78, 304, 403, 350]}, {"image_id": 11, "file_name": "57_11.png", "page": 6, "dpi": 300, "bbox": [428, 366, 739, 655], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13 Diagram of a colour chip (top) and how they appear in the Munsell tree (bottom) ", "caption_bbox": [422, 667, 747, 697]}, {"image_id": 12, "file_name": "57_12.png", "page": 6, "dpi": 300, "bbox": [85, 433, 396, 683], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12 If the central axis is on the plane, there are only two hues on the palette. ", "caption_bbox": [78, 706, 403, 736]}, {"image_id": 13, "file_name": "57_13.png", "page": 7, "dpi": 300, "bbox": [511, 875, 659, 1057], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 17 The shortest path between two colour chips", "caption_bbox": [425, 1072, 744, 1087]}, {"image_id": 14, "file_name": "57_14.png", "page": 7, "dpi": 300, "bbox": [95, 362, 385, 621], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 14 In intersection testing, the colour chips are       tested group by group and level by level. ", "caption_bbox": [83, 636, 398, 667]}, {"image_id": 15, "file_name": "57_15.png", "page": 7, "dpi": 300, "bbox": [425, 78, 745, 239], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 15 The 3-D palette of the Munsell colour picker.", "caption_bbox": [422, 250, 747, 265]}, {"image_id": 16, "file_name": "57_16.png", "page": 7, "dpi": 300, "bbox": [508, 431, 663, 563], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 16 Using a spline to do the colour interpolation", "caption_bbox": [423, 575, 745, 590]}, {"image_id": 17, "file_name": "57_17.png", "page": 8, "dpi": 300, "bbox": [80, 213, 398, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 18 Colour interpolations in Munsell", "caption_bbox": [112, 377, 368, 392]}], "58": [{"image_id": 0, "file_name": "58_00.png", "page": 2, "dpi": 300, "bbox": [148, 440, 683, 1022], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "                            3 Figure 3: Numbering on the 2 RC and types of expressions of operations ", "caption_bbox": [217, 1021, 608, 1037]}, {"image_id": 1, "file_name": "58_01.png", "page": 2, "dpi": 300, "bbox": [125, 173, 703, 374], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: \u201cDivergence via abstraction\u201d approach", "caption_bbox": [267, 387, 559, 402]}, {"image_id": 2, "file_name": "58_02.png", "page": 3, "dpi": 300, "bbox": [115, 87, 717, 277], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Example of cyclic puzzles", "caption_bbox": [305, 288, 519, 303]}, {"image_id": 3, "file_name": "58_03.png", "page": 4, "dpi": 300, "bbox": [170, 87, 655, 374], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: User interface of a permutation puzzle generator", "caption_bbox": [238, 384, 587, 399]}, {"image_id": 4, "file_name": "58_04.png", "page": 4, "dpi": 300, "bbox": [198, 812, 637, 1036], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: States of permutation puzzle 23RC/(123): (a) start (b) goal", "caption_bbox": [209, 1046, 619, 1063]}, {"image_id": 5, "file_name": "58_05.png", "page": 5, "dpi": 300, "bbox": [140, 453, 688, 786], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: New permutation puzzles and their layouts", "caption_bbox": [253, 803, 571, 818]}, {"image_id": 6, "file_name": "58_06.png", "page": 5, "dpi": 300, "bbox": [100, 140, 730, 356], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Layouts of 23 Rubik\u2019s Cube (a) Pyraminx (b)", "caption_bbox": [248, 367, 580, 384]}, {"image_id": 7, "file_name": "58_07.png", "page": 6, "dpi": 300, "bbox": [157, 441, 676, 720], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: (a) Orthogonal layout (b) visibility representations of cyclic puzzles", "caption_bbox": [175, 733, 650, 748]}, {"image_id": 8, "file_name": "58_08.png", "page": 6, "dpi": 300, "bbox": [196, 86, 632, 384], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: User interface of a cyclic puzzle generator", "caption_bbox": [274, 397, 552, 410]}, {"image_id": 9, "file_name": "58_09.png", "page": 7, "dpi": 300, "bbox": [148, 608, 688, 863], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Symmetric layouts of 33RC/205\u00b7123", "caption_bbox": [275, 891, 550, 908]}, {"image_id": 10, "file_name": "58_10.png", "page": 7, "dpi": 300, "bbox": [94, 80, 727, 543], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Symmetric layouts of 23RC/123", "caption_bbox": [286, 555, 539, 572]}, {"image_id": 11, "file_name": "58_11.png", "page": 8, "dpi": 300, "bbox": [105, 119, 721, 800], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Various layouts for the 33RC/205\u00b7123", "caption_bbox": [271, 806, 553, 823]}], "59": [{"image_id": 0, "file_name": "59_00.png", "page": 2, "dpi": 300, "bbox": [421, 302, 749, 559], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. 2D financial chart", "caption_bbox": [501, 567, 667, 582]}, {"image_id": 1, "file_name": "59_01.png", "page": 2, "dpi": 300, "bbox": [78, 78, 406, 325], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1. Ambient display in Sideshow", "caption_bbox": [126, 332, 355, 347]}, {"image_id": 2, "file_name": "59_02.png", "page": 2, "dpi": 300, "bbox": [78, 377, 404, 638], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2. Ambient display in BusTraffic", "caption_bbox": [122, 645, 359, 660]}, {"image_id": 3, "file_name": "59_03.png", "page": 2, "dpi": 300, "bbox": [78, 690, 401, 948], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3. Ambient display in InfoCanvas", "caption_bbox": [120, 955, 362, 970]}, {"image_id": 4, "file_name": "59_04.png", "page": 2, "dpi": 300, "bbox": [421, 774, 746, 1035], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5. 10:50 on 28/8/2003 the state of AMP stock", "caption_bbox": [431, 1042, 738, 1057]}, {"image_id": 5, "file_name": "59_05.png", "page": 3, "dpi": 300, "bbox": [77, 543, 403, 804], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7. 15:20 on 28/8/2003 the state of AMP stock", "caption_bbox": [78, 811, 385, 826]}, {"image_id": 6, "file_name": "59_06.png", "page": 3, "dpi": 300, "bbox": [421, 79, 737, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8. ambient MoneyColor frame", "caption_bbox": [473, 340, 694, 355]}, {"image_id": 7, "file_name": "59_07.png", "page": 3, "dpi": 300, "bbox": [77, 118, 403, 379], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6. 9:10 on 28/8/2003 the state of AMP stock", "caption_bbox": [91, 386, 391, 401]}], "60": [{"image_id": 0, "file_name": "60_00.png", "page": 1, "dpi": 300, "bbox": [437, 469, 733, 884], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Part of the Primer3 web interface showing one of the sets of criteria which can be set. Others can also be specified ", "caption_bbox": [421, 892, 746, 938]}, {"image_id": 1, "file_name": "60_01.png", "page": 2, "dpi": 300, "bbox": [166, 79, 661, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2 \u2013 Results page from Primer3 web interface, showing no acceptable primers were found.", "caption_bbox": [126, 439, 699, 453]}, {"image_id": 2, "file_name": "60_02.png", "page": 3, "dpi": 300, "bbox": [153, 566, 674, 958], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3 \u2013 The plot from the Primer3 Explorer. Each box represents a primer. The user can choose attributes to be represented by the axes and by colour (middle panel). As the ranges for the attributes are varied (with the sliders) those items which are excluded are greyed out. Details of the acceptable items are shown in the scrollable text window at the bottom. ", "caption_bbox": [78, 965, 747, 1027]}], "61": [{"image_id": 0, "file_name": "61_00.png", "page": 2, "dpi": 300, "bbox": [121, 59, 712, 677], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The features of a logic engine, Source: (Eades & Whitesides 1996)", "caption_bbox": [181, 696, 645, 710]}, {"image_id": 1, "file_name": "61_01.png", "page": 3, "dpi": 300, "bbox": [115, 53, 718, 471], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A configuration of a logic engine without collisions, Source: (Eades & Whitesides 1996)", "caption_bbox": [117, 484, 710, 498]}, {"image_id": 2, "file_name": "61_02.png", "page": 3, "dpi": 300, "bbox": [437, 534, 741, 855], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visualisation that corresponds to the logic engine and configuration of Figure 1. Formula: c1 = [\u00aca1 , a2 , a3 ], c2 = [a1 , \u00aca3 , \u00aca4 ], c3 = [\u00aca1 , \u00aca3 , a4 ] ", "caption_bbox": [427, 869, 749, 912]}, {"image_id": 3, "file_name": "61_03.png", "page": 4, "dpi": 300, "bbox": [115, 53, 718, 598], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Visualisation of a logic engine in mid-rotation. Formula: c1 = [a, \u00acb, \u00acc], c2 = [a, d, e], c3 = [c, \u00ace, \u00acf ], c4 = [b, \u00acd, f ] ", "caption_bbox": [83, 611, 749, 641]}, {"image_id": 4, "file_name": "61_04.png", "page": 5, "dpi": 300, "bbox": [454, 575, 724, 851], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Configuration for a = 1, b = 0, c = 0. Eval- uates to false. ", "caption_bbox": [427, 865, 749, 893]}, {"image_id": 5, "file_name": "61_05.png", "page": 5, "dpi": 300, "bbox": [93, 53, 396, 400], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualisation that corresponds to the con- figuration of Figure 2. ", "caption_bbox": [83, 413, 405, 441]}, {"image_id": 6, "file_name": "61_06.png", "page": 5, "dpi": 300, "bbox": [454, 218, 724, 495], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Configuration for a = 0, b = 0, c = 0. Eval- uates to true. ", "caption_bbox": [427, 508, 749, 536]}, {"image_id": 7, "file_name": "61_07.png", "page": 6, "dpi": 300, "bbox": [454, 758, 724, 1034], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Configuration for a = 0, b = 0, c = 1. Evaluates to false. ", "caption_bbox": [427, 1048, 749, 1076]}, {"image_id": 8, "file_name": "61_08.png", "page": 6, "dpi": 300, "bbox": [109, 758, 380, 1034], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Configuration for a = 0, b = 1, c = 1. Evaluates to false. ", "caption_bbox": [83, 1048, 405, 1076]}, {"image_id": 9, "file_name": "61_09.png", "page": 6, "dpi": 300, "bbox": [454, 408, 724, 685], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Configuration for a = 1, b = 0, c = 1. Evaluates to true. ", "caption_bbox": [427, 698, 749, 726]}, {"image_id": 10, "file_name": "61_10.png", "page": 6, "dpi": 300, "bbox": [109, 408, 380, 685], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Configuration for a = 0, b = 1, c = 0. Eval- uates to true. ", "caption_bbox": [83, 698, 405, 726]}, {"image_id": 11, "file_name": "61_11.png", "page": 6, "dpi": 300, "bbox": [454, 58, 724, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Configuration for a = 1, b = 1, c = 1. Evaluates to true. ", "caption_bbox": [427, 349, 749, 377]}, {"image_id": 12, "file_name": "61_12.png", "page": 6, "dpi": 300, "bbox": [109, 58, 380, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Configuration for a = 1, b = 1, c = 0. Eval- uates to false. ", "caption_bbox": [83, 349, 405, 377]}], "62": [{"image_id": 0, "file_name": "62_00.png", "page": 2, "dpi": 300, "bbox": [78, 461, 389, 695], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1. The MS-Taxonomy defines six main classes        within the multi-sensory design space. ", "caption_bbox": [78, 704, 393, 737]}, {"image_id": 1, "file_name": "62_01.png", "page": 2, "dpi": 300, "bbox": [441, 241, 740, 469], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2. A UML diagram shows the high-level architecture of the MS-Taxonomy. In software terms this is a multiple inheritance hierarchy. ", "caption_bbox": [448, 481, 729, 530]}, {"image_id": 2, "file_name": "62_02.png", "page": 2, "dpi": 300, "bbox": [438, 632, 734, 861], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3. The general concepts that describe Spatial   Metaphors. These concepts are most intuitive to    vision but can still be applied to the auditory                        domain. ", "caption_bbox": [434, 873, 744, 938]}, {"image_id": 3, "file_name": "62_03.png", "page": 3, "dpi": 300, "bbox": [81, 105, 386, 330], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5. Concepts that describe Temporal                Metaphors. ", "caption_bbox": [107, 629, 364, 662]}, {"image_id": 4, "file_name": "62_04.png", "page": 3, "dpi": 300, "bbox": [86, 391, 382, 613], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6. The steps of the MS-Process.", "caption_bbox": [474, 676, 704, 693]}, {"image_id": 5, "file_name": "62_05.png", "page": 3, "dpi": 300, "bbox": [449, 435, 728, 660], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1. Entry and exit criteria for the MS-Process.", "caption_bbox": [435, 1059, 743, 1076]}, {"image_id": 6, "file_name": "62_06.png", "page": 4, "dpi": 300, "bbox": [81, 745, 393, 979], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8. Demonstrating how the MS-Taxonomy is used to structure step of the MS-Process and how    the MS-Guidelines also feed into this process. ", "caption_bbox": [84, 993, 388, 1042]}, {"image_id": 7, "file_name": "62_07.png", "page": 4, "dpi": 300, "bbox": [435, 81, 741, 305], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9. The Evaluation step of the MS-Process", "caption_bbox": [444, 326, 733, 343]}, {"image_id": 8, "file_name": "62_08.png", "page": 4, "dpi": 300, "bbox": [84, 214, 389, 441], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7. The Display Mapping step of the MS-                    Process ", "caption_bbox": [95, 458, 377, 491]}, {"image_id": 9, "file_name": "62_09.png", "page": 5, "dpi": 300, "bbox": [436, 82, 721, 303], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10. The top-level structure of the MS-                  Guidelines ", "caption_bbox": [455, 326, 723, 359]}], "63": [{"image_id": 0, "file_name": "63_00.png", "page": 3, "dpi": 300, "bbox": [89, 347, 401, 692], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Dragging nodes in the skeletal interaction system. Constraints are maintained as the nodes are moved. ", "caption_bbox": [83, 703, 405, 745]}, {"image_id": 1, "file_name": "63_01.png", "page": 4, "dpi": 300, "bbox": [89, 223, 401, 447], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The graph used for part 1 of the user study.", "caption_bbox": [83, 458, 405, 472]}, {"image_id": 2, "file_name": "63_02.png", "page": 5, "dpi": 300, "bbox": [433, 140, 745, 540], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The results for part 1 of the user study.", "caption_bbox": [437, 550, 740, 564]}, {"image_id": 3, "file_name": "63_03.png", "page": 5, "dpi": 300, "bbox": [89, 54, 401, 403], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: The graph used for part 2 of the user study.", "caption_bbox": [83, 414, 405, 428]}, {"image_id": 4, "file_name": "63_04.png", "page": 7, "dpi": 300, "bbox": [89, 123, 401, 523], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The results for part 2 of the user study.", "caption_bbox": [92, 534, 395, 548]}], "64": [{"image_id": 0, "file_name": "64_00.png", "page": 1, "dpi": 300, "bbox": [427, 453, 747, 593], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A face of (a) a convex grid drawing, (b) an open rectangle-of-in uence drawing, and (c) a closed rectangle-of-in uence drawing. ", "caption_bbox": [427, 599, 749, 654]}, {"image_id": 1, "file_name": "64_01.png", "page": 1, "dpi": 300, "bbox": [427, 277, 747, 391], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: (a) Convex grid drawing, (b) open rectangle-of-in uence drawing which is a convex drawing, and (c) closed rectangle-of-in uence draw- ", "caption_bbox": [427, 397, 749, 452]}, {"image_id": 2, "file_name": "64_02.png", "page": 2, "dpi": 300, "bbox": [142, 53, 343, 254], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Nested quadrangles attaining our bounds.", "caption_bbox": [86, 259, 402, 286]}, {"image_id": 3, "file_name": "64_03.png", "page": 3, "dpi": 300, "bbox": [83, 55, 402, 388], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A 4-canonical decomposition of a 4-", "caption_bbox": [83, 396, 405, 423]}, {"image_id": 4, "file_name": "64_04.png", "page": 3, "dpi": 300, "bbox": [428, 165, 741, 562], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Illustration of algorithm.", "caption_bbox": [482, 569, 695, 596]}, {"image_id": 5, "file_name": "64_05.png", "page": 4, "dpi": 300, "bbox": [427, 503, 747, 609], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Trimmed rectangles.", "caption_bbox": [495, 615, 681, 642]}, {"image_id": 6, "file_name": "64_06.png", "page": 5, "dpi": 300, "bbox": [427, 861, 746, 968], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Illustration for Lemma 4.3.", "caption_bbox": [475, 976, 702, 1003]}, {"image_id": 7, "file_name": "64_07.png", "page": 5, "dpi": 300, "bbox": [122, 53, 362, 273], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Illustration for the proof of Theorem 1.", "caption_bbox": [93, 278, 394, 305]}], "65": [{"image_id": 0, "file_name": "65_00.png", "page": 1, "dpi": 300, "bbox": [421, 323, 751, 549], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1 High-density foreign currency exchange data stream (x-coordinate is the order number of trades). In these cases, it is helpful for traders to make decisions with visual display both of details of DP and global information including SP. However, in all existing foreign currency exchange trading systems and back- testing systems as we know, there are no mechanisms or facilities for showing the above two types of information in a same window at the same time. ", "caption_bbox": [421, 552, 746, 703]}, {"image_id": 1, "file_name": "65_01.png", "page": 2, "dpi": 300, "bbox": [421, 166, 759, 409], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3 SSV (k=7)", "caption_bbox": [532, 408, 650, 428]}, {"image_id": 2, "file_name": "65_02.png", "page": 2, "dpi": 300, "bbox": [77, 368, 407, 603], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2 Zoomed details (x-coordinate is from 10 Jul. to 20 Jul. 1999). ", "caption_bbox": [78, 606, 403, 641]}, {"image_id": 3, "file_name": "65_03.png", "page": 3, "dpi": 300, "bbox": [453, 897, 718, 1024], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9 Cartesian fish-eye view (one dimension).", "caption_bbox": [449, 1023, 733, 1043]}, {"image_id": 4, "file_name": "65_04.png", "page": 3, "dpi": 300, "bbox": [421, 762, 743, 874], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8 Both data set and window are divided into", "caption_bbox": [446, 876, 736, 896]}, {"image_id": 5, "file_name": "65_05.png", "page": 3, "dpi": 300, "bbox": [77, 723, 409, 961], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6 CBS (n=7)", "caption_bbox": [189, 960, 305, 980]}, {"image_id": 6, "file_name": "65_06.png", "page": 3, "dpi": 300, "bbox": [472, 230, 697, 373], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7 Cartesian fish-eye view (distortion scale is 4)", "caption_bbox": [437, 373, 744, 393]}, {"image_id": 7, "file_name": "65_07.png", "page": 3, "dpi": 300, "bbox": [138, 273, 345, 415], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5 A-the highest, B-the first, C- the last, D- the", "caption_bbox": [97, 431, 397, 451]}, {"image_id": 8, "file_name": "65_08.png", "page": 4, "dpi": 300, "bbox": [77, 755, 406, 991], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10 FFD for Channel Break Out rules.", "caption_bbox": [121, 990, 373, 1010]}, {"image_id": 9, "file_name": "65_09.png", "page": 4, "dpi": 300, "bbox": [421, 768, 749, 1004], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12 FGD for foreign currency exchange", "caption_bbox": [460, 1003, 721, 1023]}, {"image_id": 10, "file_name": "65_10.png", "page": 4, "dpi": 300, "bbox": [448, 346, 725, 467], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11 Fish-eye distortion on one dimension", "caption_bbox": [456, 467, 725, 487]}, {"image_id": 11, "file_name": "65_11.png", "page": 5, "dpi": 300, "bbox": [77, 118, 406, 354], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13 FGD for Channel Break Out.", "caption_bbox": [129, 357, 353, 377]}], "66": [{"image_id": 0, "file_name": "66_00.png", "page": 4, "dpi": 300, "bbox": [465, 574, 714, 904], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: fe repulsive effect", "caption_bbox": [503, 920, 673, 938]}, {"image_id": 1, "file_name": "66_01.png", "page": 4, "dpi": 300, "bbox": [130, 453, 360, 896], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Drawings generated by DNLS", "caption_bbox": [122, 912, 365, 929]}, {"image_id": 2, "file_name": "66_02.png", "page": 5, "dpi": 300, "bbox": [494, 52, 685, 430], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Sample of ODNLS", "caption_bbox": [498, 446, 673, 463]}, {"image_id": 3, "file_name": "66_03.png", "page": 5, "dpi": 300, "bbox": [113, 291, 377, 583], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: fe attractive effect", "caption_bbox": [156, 599, 331, 617]}, {"image_id": 4, "file_name": "66_04.png", "page": 6, "dpi": 300, "bbox": [434, 64, 746, 1039], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Experiment Results", "caption_bbox": [497, 1055, 679, 1072]}], "67": [{"image_id": 0, "file_name": "67_00.png", "page": 4, "dpi": 300, "bbox": [94, 87, 732, 323], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Each participant\u2019s response time for all 12 drawings", "caption_bbox": [227, 339, 597, 354]}, {"image_id": 1, "file_name": "67_01.png", "page": 4, "dpi": 300, "bbox": [94, 391, 391, 578], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Average response time for each               participant ", "caption_bbox": [119, 588, 365, 619]}, {"image_id": 2, "file_name": "67_02.png", "page": 4, "dpi": 300, "bbox": [414, 391, 729, 580], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Average response time for each drawing", "caption_bbox": [421, 594, 720, 609]}, {"image_id": 3, "file_name": "67_03.png", "page": 4, "dpi": 300, "bbox": [117, 881, 405, 912], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Error rate for each participant", "caption_bbox": [120, 844, 364, 859]}, {"image_id": 4, "file_name": "67_04.png", "page": 4, "dpi": 300, "bbox": [412, 629, 733, 830], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Error rate for each drawing", "caption_bbox": [457, 845, 684, 860]}, {"image_id": 5, "file_name": "67_05.png", "page": 6, "dpi": 300, "bbox": [441, 81, 729, 253], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Straight path vs. Non-Straight path", "caption_bbox": [449, 268, 719, 283]}], "68": [{"image_id": 0, "file_name": "68_00.png", "page": 3, "dpi": 300, "bbox": [470, 53, 708, 361], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Updating the projection plane.", "caption_bbox": [463, 373, 713, 390]}, {"image_id": 1, "file_name": "68_01.png", "page": 4, "dpi": 300, "bbox": [124, 53, 365, 333], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The prototype system AGI.", "caption_bbox": [129, 344, 359, 361]}, {"image_id": 2, "file_name": "68_02.png", "page": 5, "dpi": 300, "bbox": [478, 194, 700, 905], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Interactive layout of the AT&T graph ug 45 (with 97 nodes and 182 edges). ", "caption_bbox": [427, 920, 749, 950]}, {"image_id": 3, "file_name": "68_03.png", "page": 6, "dpi": 300, "bbox": [478, 75, 700, 1024], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Interactive layout of the AT&T graph ug 380 (with 1,104 nodes and 3,231 edges). ", "caption_bbox": [427, 1039, 749, 1069]}, {"image_id": 4, "file_name": "68_04.png", "page": 6, "dpi": 300, "bbox": [133, 75, 356, 1024], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Interactive layout of the AT&T graph ug 223 (with 244 nodes and 340 edges). ", "caption_bbox": [83, 1039, 405, 1069]}], "69": [{"image_id": 0, "file_name": "69_00.png", "page": 4, "dpi": 300, "bbox": [124, 52, 365, 1077], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Layered drawings of grafo115", "caption_bbox": [124, 1108, 364, 1123]}, {"image_id": 1, "file_name": "69_01.png", "page": 4, "dpi": 300, "bbox": [515, 52, 664, 1087], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Layered drawings of grafo11093", "caption_bbox": [461, 1118, 715, 1133]}, {"image_id": 2, "file_name": "69_02.png", "page": 5, "dpi": 300, "bbox": [138, 54, 351, 1077], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Layered drawings of grafo11138", "caption_bbox": [117, 1108, 371, 1123]}], "70": [{"image_id": 0, "file_name": "70_00.png", "page": 2, "dpi": 300, "bbox": [459, 771, 715, 967], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: System Architecture", "caption_bbox": [495, 1006, 681, 1023]}, {"image_id": 1, "file_name": "70_01.png", "page": 2, "dpi": 300, "bbox": [456, 72, 727, 138], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: An example of input data", "caption_bbox": [479, 169, 698, 186]}, {"image_id": 2, "file_name": "70_02.png", "page": 2, "dpi": 300, "bbox": [109, 362, 379, 548], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: A vibrator used in the haptic shoes", "caption_bbox": [103, 579, 380, 596]}, {"image_id": 3, "file_name": "70_03.png", "page": 3, "dpi": 300, "bbox": [456, 198, 726, 402], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Vibrators installed in shoe", "caption_bbox": [477, 433, 700, 450]}], "71": [{"image_id": 0, "file_name": "71_00.png", "page": 3, "dpi": 300, "bbox": [432, 148, 735, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "  Figure 2: Histogram of the distribution of C0 for  fibroblast microarray data and its approximation using a one-dimensional GMM with M = 4 mixtures. ", "caption_bbox": [427, 277, 740, 323]}, {"image_id": 1, "file_name": "71_01.png", "page": 3, "dpi": 300, "bbox": [95, 276, 381, 519], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: An example gene expression profile (a) and its DCT (b) and DST (c) coefficients. In this example,   the DCT provides a more compact representation                   than the DST. ", "caption_bbox": [83, 532, 399, 595]}, {"image_id": 2, "file_name": "71_02.png", "page": 5, "dpi": 300, "bbox": [142, 306, 663, 695], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "   Figure 3: 2-D visualisation of the GMM-based probability density function estimate based upon the first two  DCT coefficients of fibroblast log expression data. The original classification into ten clusters (A to J) from Iyer et al. (1998) is shown for the purpose of comparison. As mentioned in section 3.2, the horizontal and vertical axes       can be biologically interpreted as the average within-gene expression value and the average within-gene                                                  expression gradient. ", "caption_bbox": [78, 717, 746, 795]}], "72": [{"image_id": 0, "file_name": "72_00.png", "page": 2, "dpi": 300, "bbox": [427, 522, 764, 754], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The WilmaScope Model\u2013View\u2013Controller architecture. ", "caption_bbox": [427, 768, 749, 796]}, {"image_id": 1, "file_name": "72_01.png", "page": 2, "dpi": 300, "bbox": [183, 84, 650, 408], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: This diagram summarises the various ways in which WilmaScope may be adapted for use in applications. ", "caption_bbox": [83, 469, 749, 497]}, {"image_id": 2, "file_name": "72_02.png", "page": 3, "dpi": 300, "bbox": [83, 288, 750, 815], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Hierarchy of key classes in the graph and view packages and examples of how these classes may be implemented by layout and view plug-ins. ", "caption_bbox": [83, 829, 749, 857]}, {"image_id": 3, "file_name": "72_03.png", "page": 5, "dpi": 300, "bbox": [187, 76, 652, 455], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A visualisation of a set of metabolic pathways (see Section 1) demonstrating use of the hierarchical layout plug-in implemented with the DOT program. Also visible is a cross-sectional viewer which allows users to step through layers in such 2 12 D graph visualisations. ", "caption_bbox": [83, 471, 749, 519]}, {"image_id": 4, "file_name": "72_04.png", "page": 5, "dpi": 300, "bbox": [137, 573, 665, 1027], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualisation of the evolution of a citation network. The force-directed layout plug-in has been used together with constraints keeping nodes related to specific years aligned in parallel planes. ", "caption_bbox": [83, 1040, 749, 1068]}, {"image_id": 5, "file_name": "72_05.png", "page": 6, "dpi": 300, "bbox": [182, 637, 652, 1037], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: A small scale-free network produced by the stochastic scale-free graph generator plug-in.", "caption_bbox": [116, 1051, 716, 1065]}, {"image_id": 6, "file_name": "72_06.png", "page": 6, "dpi": 300, "bbox": [115, 87, 670, 474], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Another view of the citation-network from Figure 5. Nodes are constrained to concentric spherical shells with high-degree nodes placed on the outermost shells. ", "caption_bbox": [83, 546, 749, 574]}], "73": [{"image_id": 0, "file_name": "73_00.png", "page": 2, "dpi": 300, "bbox": [91, 440, 376, 717], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Simple example of bearing data", "caption_bbox": [121, 726, 344, 739]}, {"image_id": 1, "file_name": "73_01.png", "page": 3, "dpi": 300, "bbox": [79, 494, 384, 602], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Interaction diagram reproduced from (Card et al., 1999) ", "caption_bbox": [73, 615, 392, 643]}, {"image_id": 2, "file_name": "73_02.png", "page": 4, "dpi": 300, "bbox": [148, 791, 687, 1056], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Left diagram is an example of bearing data, right is the bearings clustered", "caption_bbox": [186, 1065, 635, 1078]}, {"image_id": 3, "file_name": "73_03.png", "page": 5, "dpi": 300, "bbox": [463, 163, 725, 426], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Simple scenario", "caption_bbox": [523, 434, 661, 447]}, {"image_id": 4, "file_name": "73_04.png", "page": 5, "dpi": 300, "bbox": [463, 462, 725, 724], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: World-centric bearing visualisation", "caption_bbox": [471, 732, 714, 745]}, {"image_id": 5, "file_name": "73_05.png", "page": 5, "dpi": 300, "bbox": [463, 760, 725, 1022], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Scenario i from an ownship-centric perspective", "caption_bbox": [443, 1031, 741, 1044]}, {"image_id": 6, "file_name": "73_06.png", "page": 6, "dpi": 300, "bbox": [140, 785, 683, 1059], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Multiple panels demonstrating brushing", "caption_bbox": [276, 1071, 544, 1084]}, {"image_id": 7, "file_name": "73_07.png", "page": 6, "dpi": 300, "bbox": [453, 155, 734, 436], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Brush labelling", "caption_bbox": [526, 444, 659, 457]}, {"image_id": 8, "file_name": "73_08.png", "page": 7, "dpi": 300, "bbox": [82, 516, 383, 817], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Time against the z-axis", "caption_bbox": [144, 825, 320, 838]}, {"image_id": 9, "file_name": "73_09.png", "page": 8, "dpi": 300, "bbox": [92, 737, 374, 1019], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A corrected solution", "caption_bbox": [151, 1027, 313, 1040]}, {"image_id": 10, "file_name": "73_10.png", "page": 8, "dpi": 300, "bbox": [92, 427, 374, 710], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: A scenario with an erroneous solution", "caption_bbox": [104, 718, 360, 731]}], "74": [{"image_id": 0, "file_name": "74_00.png", "page": 1, "dpi": 300, "bbox": [443, 572, 734, 795], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Quality models, metrics and quality", "caption_bbox": [448, 809, 728, 825]}, {"image_id": 1, "file_name": "74_01.png", "page": 2, "dpi": 300, "bbox": [84, 736, 403, 896], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Visualisation via mappings", "caption_bbox": [131, 912, 357, 928]}, {"image_id": 2, "file_name": "74_02.png", "page": 2, "dpi": 300, "bbox": [129, 168, 400, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: McCall et al. quality model", "caption_bbox": [129, 372, 358, 388]}, {"image_id": 3, "file_name": "74_03.png", "page": 3, "dpi": 300, "bbox": [427, 142, 751, 960], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Parallel visualisation pipelines: implemen- tation pipeline (left) and design pipeline (right) ", "caption_bbox": [427, 974, 748, 1004]}, {"image_id": 4, "file_name": "74_04.png", "page": 5, "dpi": 300, "bbox": [451, 491, 726, 1061], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Filtering", "caption_bbox": [531, 1074, 646, 1090]}, {"image_id": 5, "file_name": "74_05.png", "page": 5, "dpi": 300, "bbox": [146, 237, 342, 623], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Using domains to colour file view", "caption_bbox": [112, 636, 376, 652]}, {"image_id": 6, "file_name": "74_06.png", "page": 5, "dpi": 300, "bbox": [467, 56, 711, 447], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: File comparison", "caption_bbox": [509, 460, 668, 476]}, {"image_id": 7, "file_name": "74_07.png", "page": 7, "dpi": 300, "bbox": [114, 675, 374, 960], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Use of jittering to distinguish co-located data points ", "caption_bbox": [83, 973, 405, 1003]}, {"image_id": 8, "file_name": "74_08.png", "page": 7, "dpi": 300, "bbox": [174, 54, 659, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: A ggobi session in progress", "caption_bbox": [303, 546, 529, 562]}, {"image_id": 9, "file_name": "74_09.png", "page": 8, "dpi": 300, "bbox": [83, 54, 750, 376], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: A class cluster for a Java package", "caption_bbox": [279, 390, 552, 406]}, {"image_id": 10, "file_name": "74_10.png", "page": 9, "dpi": 300, "bbox": [114, 53, 375, 319], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: cluster with metrics", "caption_bbox": [149, 331, 339, 347]}], "75": [{"image_id": 0, "file_name": "75_00.png", "page": 2, "dpi": 300, "bbox": [82, 625, 412, 922], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Camera Focal length, Field of View, and View Frustum ", "caption_bbox": [83, 933, 405, 961]}, {"image_id": 1, "file_name": "75_01.png", "page": 3, "dpi": 300, "bbox": [82, 54, 412, 393], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: C = (cx , cy ) is the camera position, P0 is the current focus node and P1 = (sx , sy ) is the next focus node. \u03b8 = FOV, which is constant. ", "caption_bbox": [83, 405, 405, 449]}, {"image_id": 2, "file_name": "75_02.png", "page": 4, "dpi": 300, "bbox": [427, 706, 757, 981], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Two paths chosen by the two different context optimisation functions ", "caption_bbox": [427, 991, 749, 1019]}, {"image_id": 3, "file_name": "75_03.png", "page": 4, "dpi": 300, "bbox": [82, 476, 412, 665], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: One instance of the visibility function Fi for some i. The value t represents the position of the camera along the corresponding path Ci . ", "caption_bbox": [83, 675, 405, 719]}, {"image_id": 4, "file_name": "75_04.png", "page": 4, "dpi": 300, "bbox": [82, 54, 753, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Possible paths on a 2D surface revolution manifold", "caption_bbox": [228, 352, 603, 366]}], "76": [{"image_id": 0, "file_name": "76_00.png", "page": 1, "dpi": 300, "bbox": [427, 877, 768, 1027], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1. Overview of the Pattern Puzzle Metaphor: the call     graph is the source of the pieces positions and their                         connections. ", "caption_bbox": [435, 1033, 756, 1075]}, {"image_id": 1, "file_name": "76_01.png", "page": 2, "dpi": 300, "bbox": [429, 78, 753, 338], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": " Figure 2. The meaning of symbols used in the implementation of the Pattern Puzzle metaphor. ", "caption_bbox": [458, 348, 717, 376]}, {"image_id": 2, "file_name": "76_02.png", "page": 3, "dpi": 300, "bbox": [102, 148, 732, 615], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3. Visualizations of the BlowfishJ library by the Pattern Puzzle. Two packages: BlowfishJ and test, and their sub-components in the library are shown. Puzzles representing the three levels of hierarchy (package, class and method) are drawn. Note that the patterns in each puzzle indicate the relative value of complexity to those of other pieces in the same puzzle, instead of the overall value. The SHA1 pattern puzzle (bottom right) illustrates high interconnection complexity the diagram visually implies that the component could need more resources than the others. ", "caption_bbox": [104, 637, 721, 722]}, {"image_id": 3, "file_name": "76_03.png", "page": 4, "dpi": 300, "bbox": [69, 73, 399, 357], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. The user interface of the implementation of       the Pattern Puzzle Metaphor prototype. ", "caption_bbox": [95, 369, 379, 396]}], "77": [{"image_id": 0, "file_name": "77_00.png", "page": 2, "dpi": 300, "bbox": [78, 719, 757, 977], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Visualization in a matrix format presents an evolution of ideas for alarm clocks     in panel 1 (pen and marker), toasters in panel 2 (pen and marker), and spheroid                       form exploration in panel 3 (digital modelling). ", "caption_bbox": [160, 1007, 688, 1053]}, {"image_id": 1, "file_name": "77_01.png", "page": 3, "dpi": 300, "bbox": [84, 108, 742, 543], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visual representations of time and workflow can take many forms                    and yield different conceptual models. ", "caption_bbox": [182, 565, 633, 595]}, {"image_id": 2, "file_name": "77_02.png", "page": 4, "dpi": 300, "bbox": [81, 145, 754, 397], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "     Figure 3: This sketch captures ideas in a fluid and unscripted manner. Looking closer at the individual elements shows that each visualization builds upon               its predecessors to create a seemingly linear evolution. ", "caption_bbox": [161, 405, 655, 451]}], "78": [{"image_id": 0, "file_name": "78_00.png", "page": 2, "dpi": 300, "bbox": [162, 62, 672, 230], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Information processing model", "caption_bbox": [295, 262, 537, 279]}, {"image_id": 1, "file_name": "78_01.png", "page": 3, "dpi": 300, "bbox": [108, 59, 729, 293], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Multi-dimensional visualization efficiency. (a): modified from Tuovinen et al. [2004]; (b): modified from Kalyuga et al. [1999] ", "caption_bbox": [83, 310, 749, 342]}, {"image_id": 2, "file_name": "78_02.png", "page": 4, "dpi": 300, "bbox": [93, 543, 398, 748], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Model of user performance, mental effort and cognitive load ", "caption_bbox": [83, 769, 405, 799]}, {"image_id": 3, "file_name": "78_03.png", "page": 5, "dpi": 300, "bbox": [115, 53, 723, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Network data used in the study", "caption_bbox": [119, 969, 368, 986]}, {"image_id": 4, "file_name": "78_04.png", "page": 9, "dpi": 300, "bbox": [132, 53, 357, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Effort distribution for task 2 for the sepa- rated version of network 1 ", "caption_bbox": [83, 239, 405, 269]}], "79": [{"image_id": 0, "file_name": "79_00.png", "page": 1, "dpi": 300, "bbox": [454, 277, 724, 534], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Advice network formed by an auditing team. Courtesy of Krackhardt [1996]. Ellipses repre- sent managers; diamonds represent staff auditors and boxes represent secretaries. A line from Donna to Nancy indicates that Donna seeks advice from Nancy ", "caption_bbox": [427, 543, 749, 617]}, {"image_id": 1, "file_name": "79_01.png", "page": 3, "dpi": 300, "bbox": [476, 355, 706, 585], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Radial layout of betweenness centrality. Courtesy of Brandes et al. [2003b, Figure 7] ", "caption_bbox": [427, 595, 749, 627]}, {"image_id": 2, "file_name": "79_02.png", "page": 3, "dpi": 300, "bbox": [470, 53, 706, 288], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Target sociogram [Northway 1940], where node status is defined by how often the node is chosen ", "caption_bbox": [427, 299, 749, 329]}, {"image_id": 3, "file_name": "79_03.png", "page": 5, "dpi": 300, "bbox": [149, 106, 685, 999], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Sociograms used in the study", "caption_bbox": [296, 1023, 536, 1040]}, {"image_id": 4, "file_name": "79_04.png", "page": 6, "dpi": 300, "bbox": [490, 307, 700, 752], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: It is argued that Drawing (b) gives a stronger sense of group, and is easier to find rela- tionship patterns than Drawing (a) ", "caption_bbox": [427, 768, 749, 812]}], "80": [{"image_id": 0, "file_name": "80_00.png", "page": 2, "dpi": 300, "bbox": [427, 53, 761, 558], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Parallel coordinates of the centrality rank", "caption_bbox": [427, 565, 748, 584]}, {"image_id": 1, "file_name": "80_01.png", "page": 2, "dpi": 300, "bbox": [82, 573, 415, 927], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Scatterplot matrix of the centrality rank of", "caption_bbox": [83, 934, 404, 953]}, {"image_id": 2, "file_name": "80_02.png", "page": 5, "dpi": 300, "bbox": [427, 53, 761, 342], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Calculating the new position q of a ver-", "caption_bbox": [427, 349, 748, 368]}, {"image_id": 3, "file_name": "80_03.png", "page": 7, "dpi": 300, "bbox": [82, 64, 758, 490], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: The network described in Section 1 in 3D parallel coordinates, a method described in Section 3.2.", "caption_bbox": [83, 497, 749, 516]}, {"image_id": 4, "file_name": "80_04.png", "page": 7, "dpi": 300, "bbox": [82, 560, 758, 1029], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: The same PPI network as shown in Figure 4 with the same centrality measures represented with", "caption_bbox": [83, 1036, 749, 1055]}, {"image_id": 5, "file_name": "80_05.png", "page": 8, "dpi": 300, "bbox": [82, 470, 758, 979], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Padgett\u2019s Florentine families marital relation data. As in Figure 6 a hierarchy-based comparison of", "caption_bbox": [83, 986, 749, 1005]}, {"image_id": 6, "file_name": "80_06.png", "page": 8, "dpi": 300, "bbox": [82, 130, 758, 443], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The network used previously with the five centrality measures displayed in a hierarchy-based", "caption_bbox": [83, 450, 749, 469]}], "81": [{"image_id": 0, "file_name": "81_00.png", "page": 1, "dpi": 300, "bbox": [436, 805, 753, 1039], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2. Example of the mental map problem in circular drawing (Kaufmann and Wiese, 2002). ", "caption_bbox": [421, 1052, 746, 1082]}, {"image_id": 1, "file_name": "81_01.png", "page": 1, "dpi": 300, "bbox": [422, 661, 748, 759], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1. An example of the mental map problem.", "caption_bbox": [435, 769, 732, 783]}, {"image_id": 2, "file_name": "81_02.png", "page": 6, "dpi": 300, "bbox": [79, 661, 393, 896], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3. The overview of our algorithm.", "caption_bbox": [119, 912, 362, 926]}, {"image_id": 3, "file_name": "81_03.png", "page": 6, "dpi": 300, "bbox": [211, 959, 272, 1035], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. An example.", "caption_bbox": [78, 1053, 214, 1067]}, {"image_id": 4, "file_name": "81_04.png", "page": 6, "dpi": 300, "bbox": [422, 101, 767, 1013], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6. Removing nodes 7 and 8 from Figures", "caption_bbox": [429, 1031, 758, 1045]}, {"image_id": 5, "file_name": "81_05.png", "page": 8, "dpi": 300, "bbox": [90, 496, 434, 721], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8. Various drawings illustrating the preservation of the mental map.", "caption_bbox": [195, 735, 643, 749]}, {"image_id": 6, "file_name": "81_06.png", "page": 8, "dpi": 300, "bbox": [77, 788, 745, 1011], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9. Drawings obtained from Figure 8 by deleting nodes 22 and 23.", "caption_bbox": [195, 1027, 622, 1041]}, {"image_id": 7, "file_name": "81_07.png", "page": 8, "dpi": 300, "bbox": [78, 258, 762, 485], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7. A tree example.", "caption_bbox": [343, 197, 494, 211]}, {"image_id": 8, "file_name": "81_08.png", "page": 9, "dpi": 300, "bbox": [105, 81, 733, 1034], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10. A larger tree example.", "caption_bbox": [313, 1050, 511, 1064]}, {"image_id": 9, "file_name": "81_09.png", "page": 10, "dpi": 300, "bbox": [112, 103, 713, 727], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11. Drawings obtained from Figure 10 by deleting nodes 64 and 65.", "caption_bbox": [192, 743, 633, 757]}], "82": [{"image_id": 0, "file_name": "82_00.png", "page": 2, "dpi": 300, "bbox": [457, 390, 707, 622], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Anchored-map style", "caption_bbox": [492, 639, 672, 654]}, {"image_id": 1, "file_name": "82_01.png", "page": 2, "dpi": 300, "bbox": [105, 88, 737, 337], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Various styles of representing bipartite graphs", "caption_bbox": [245, 351, 581, 366]}, {"image_id": 2, "file_name": "82_02.png", "page": 4, "dpi": 300, "bbox": [85, 89, 401, 261], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Effect of the parameter q in the penalty", "caption_bbox": [94, 277, 387, 292]}, {"image_id": 3, "file_name": "82_03.png", "page": 6, "dpi": 300, "bbox": [89, 91, 415, 335], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Correlation between the penalty     and the number of edge crossings ", "caption_bbox": [159, 348, 410, 379]}, {"image_id": 4, "file_name": "82_04.png", "page": 7, "dpi": 300, "bbox": [201, 99, 642, 1009], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Interaction networks of yeast proteins (9 transcription factors)", "caption_bbox": [196, 1045, 627, 1060]}, {"image_id": 5, "file_name": "82_05.png", "page": 8, "dpi": 300, "bbox": [196, 101, 648, 1008], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Interaction networks of yeast proteins (63 transcription factors)", "caption_bbox": [192, 1043, 630, 1058]}], "83": [{"image_id": 0, "file_name": "83_00.png", "page": 3, "dpi": 300, "bbox": [182, 53, 652, 500], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: SnapShoot: the user interface of the editing page", "caption_bbox": [236, 531, 596, 545]}, {"image_id": 1, "file_name": "83_01.png", "page": 4, "dpi": 300, "bbox": [466, 272, 711, 616], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Topic Bar", "caption_bbox": [527, 642, 650, 656]}, {"image_id": 2, "file_name": "83_02.png", "page": 4, "dpi": 300, "bbox": [438, 53, 742, 217], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Cursor trajectory gradation", "caption_bbox": [473, 244, 703, 258]}, {"image_id": 3, "file_name": "83_03.png", "page": 4, "dpi": 300, "bbox": [124, 66, 365, 690], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Variation of visualization in out-line pro- cessor: the users have a choice of visualization styles depending on the situation of their task. ", "caption_bbox": [83, 728, 405, 770]}, {"image_id": 4, "file_name": "83_04.png", "page": 5, "dpi": 300, "bbox": [89, 453, 400, 672], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Sticky notes attached to the uploaded doc- ument ", "caption_bbox": [83, 698, 405, 726]}, {"image_id": 5, "file_name": "83_05.png", "page": 5, "dpi": 300, "bbox": [433, 395, 745, 578], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: SnapShoot system architecture", "caption_bbox": [463, 604, 713, 618]}, {"image_id": 6, "file_name": "83_06.png", "page": 5, "dpi": 300, "bbox": [100, 53, 388, 399], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Sowing Interface", "caption_bbox": [162, 426, 325, 440]}, {"image_id": 7, "file_name": "83_07.png", "page": 5, "dpi": 300, "bbox": [436, 53, 739, 329], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Sticky notes assembled in an united docu- ment ", "caption_bbox": [427, 356, 749, 384]}], "84": [{"image_id": 0, "file_name": "84_00.png", "page": 2, "dpi": 300, "bbox": [105, 286, 374, 770], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 1: Comparison of Time-series Hierarchy Structure with Ripple Presentation for Tree. ", "caption_bbox": [104, 782, 372, 812]}, {"image_id": 1, "file_name": "84_01.png", "page": 3, "dpi": 300, "bbox": [104, 648, 378, 883], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 2: Polar Representation of Child Nodes.", "caption_bbox": [106, 902, 370, 916]}, {"image_id": 2, "file_name": "84_02.png", "page": 3, "dpi": 300, "bbox": [426, 562, 744, 835], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 3: System architecture.", "caption_bbox": [504, 848, 669, 862]}, {"image_id": 3, "file_name": "84_03.png", "page": 4, "dpi": 300, "bbox": [78, 288, 401, 484], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 4: Sliders for parameter setting.", "caption_bbox": [129, 492, 347, 506]}, {"image_id": 4, "file_name": "84_04.png", "page": 4, "dpi": 300, "bbox": [426, 98, 749, 1012], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 5: Control flow of parameter setting.", "caption_bbox": [463, 1024, 709, 1038]}, {"image_id": 5, "file_name": "84_05.png", "page": 5, "dpi": 300, "bbox": [85, 781, 767, 1016], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 7: Discovery of latest news articles in the culture category.", "caption_bbox": [226, 1021, 598, 1035]}, {"image_id": 6, "file_name": "84_06.png", "page": 5, "dpi": 300, "bbox": [426, 448, 749, 716], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 6: News list with Ripple Presentation.", "caption_bbox": [461, 724, 711, 738]}, {"image_id": 7, "file_name": "84_07.png", "page": 6, "dpi": 300, "bbox": [441, 388, 726, 618], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 9: Angles of edges.", "caption_bbox": [517, 628, 655, 642]}, {"image_id": 8, "file_name": "84_08.png", "page": 6, "dpi": 300, "bbox": [78, 659, 750, 1017], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Fig. 8: Trackback links of Weblog articles \u201cGoogle launches Blog Search2\u201d with Ripple Presentation.", "caption_bbox": [113, 1021, 712, 1038]}], "85": [{"image_id": 0, "file_name": "85_00.png", "page": 2, "dpi": 300, "bbox": [443, 725, 734, 871], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Setting window of rent \ufb01lter", "caption_bbox": [471, 885, 705, 899]}, {"image_id": 1, "file_name": "85_01.png", "page": 2, "dpi": 300, "bbox": [83, 55, 403, 299], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Screenshot of FindFlow: The user is search- ing for an apartment in Tsukuba. ", "caption_bbox": [83, 313, 405, 341]}, {"image_id": 2, "file_name": "85_02.png", "page": 2, "dpi": 300, "bbox": [107, 602, 382, 898], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The query and a sub-query.", "caption_bbox": [129, 913, 359, 927]}, {"image_id": 3, "file_name": "85_03.png", "page": 3, "dpi": 300, "bbox": [100, 54, 390, 221], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Operations for connecting nodes.", "caption_bbox": [112, 234, 374, 248]}, {"image_id": 4, "file_name": "85_04.png", "page": 3, "dpi": 300, "bbox": [451, 54, 727, 341], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Divergence and junction", "caption_bbox": [483, 362, 693, 376]}, {"image_id": 5, "file_name": "85_05.png", "page": 3, "dpi": 300, "bbox": [100, 276, 390, 360], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Operations for disconnecting nodes.", "caption_bbox": [104, 374, 383, 388]}, {"image_id": 6, "file_name": "85_06.png", "page": 4, "dpi": 300, "bbox": [117, 56, 716, 425], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Packaging", "caption_bbox": [354, 441, 477, 455]}, {"image_id": 7, "file_name": "85_07.png", "page": 5, "dpi": 300, "bbox": [135, 54, 699, 422], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: System", "caption_bbox": [363, 437, 469, 451]}, {"image_id": 8, "file_name": "85_08.png", "page": 6, "dpi": 300, "bbox": [83, 129, 750, 974], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Example of search with FindFlow: Finding an apartment in Tsukuba.", "caption_bbox": [169, 990, 657, 1004]}], "86": [{"image_id": 0, "file_name": "86_00.png", "page": 2, "dpi": 300, "bbox": [483, 438, 690, 708], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Information visualization process", "caption_bbox": [455, 723, 713, 738]}, {"image_id": 1, "file_name": "86_01.png", "page": 3, "dpi": 300, "bbox": [77, 84, 403, 177], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Sequential layout", "caption_bbox": [159, 183, 322, 198]}, {"image_id": 2, "file_name": "86_02.png", "page": 3, "dpi": 300, "bbox": [483, 84, 691, 266], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: DOI of sequential layout", "caption_bbox": [481, 280, 686, 295]}, {"image_id": 3, "file_name": "86_03.png", "page": 3, "dpi": 300, "bbox": [488, 328, 686, 501], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: DOI of radial layout", "caption_bbox": [494, 513, 675, 528]}, {"image_id": 4, "file_name": "86_04.png", "page": 3, "dpi": 300, "bbox": [109, 459, 374, 723], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Radial layout for tree", "caption_bbox": [147, 736, 335, 751]}, {"image_id": 5, "file_name": "86_05.png", "page": 4, "dpi": 300, "bbox": [88, 454, 399, 699], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: RadialMobile", "caption_bbox": [170, 712, 311, 727]}, {"image_id": 6, "file_name": "86_06.png", "page": 4, "dpi": 300, "bbox": [86, 152, 366, 400], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: SequentialMobile", "caption_bbox": [159, 421, 323, 436]}], "87": [{"image_id": 0, "file_name": "87_00.png", "page": 1, "dpi": 300, "bbox": [454, 669, 722, 825], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1: Transition of \u03b3 of population", "caption_bbox": [468, 1064, 700, 1081]}, {"image_id": 1, "file_name": "87_01.png", "page": 2, "dpi": 300, "bbox": [459, 118, 713, 289], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Relation between population and migrants", "caption_bbox": [421, 301, 733, 315]}, {"image_id": 2, "file_name": "87_02.png", "page": 2, "dpi": 300, "bbox": [452, 554, 717, 698], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Transition of b", "caption_bbox": [510, 706, 658, 720]}, {"image_id": 3, "file_name": "87_03.png", "page": 2, "dpi": 300, "bbox": [90, 455, 361, 610], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 2: Transition of \u03b3 of migration", "caption_bbox": [127, 832, 354, 849]}, {"image_id": 4, "file_name": "87_04.png", "page": 3, "dpi": 300, "bbox": [421, 607, 751, 896], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: rank division of migration (color coding: number of migrants 1\uff5e80: rank0, 81\uff5e800: rank1, 801\uff5e 8000: rank2, 8001\uff5e80000: rank3, 80001\uff5e: rank4) ", "caption_bbox": [421, 901, 746, 951]}, {"image_id": 5, "file_name": "87_05.png", "page": 3, "dpi": 300, "bbox": [109, 756, 374, 912], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Transition of \u03b1,\u03b2                           \u03b2,\u03b3                             \u03b3 ", "caption_bbox": [146, 924, 336, 941]}, {"image_id": 6, "file_name": "87_06.png", "page": 4, "dpi": 300, "bbox": [77, 698, 405, 898], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Relational mapping", "caption_bbox": [152, 905, 329, 919]}, {"image_id": 7, "file_name": "87_07.png", "page": 4, "dpi": 300, "bbox": [77, 213, 407, 428], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Geographical mapping", "caption_bbox": [143, 440, 339, 454]}], "88": [{"image_id": 0, "file_name": "88_00.png", "page": 2, "dpi": 300, "bbox": [91, 55, 398, 365], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: IP Matrix", "caption_bbox": [182, 377, 305, 394]}, {"image_id": 1, "file_name": "88_01.png", "page": 2, "dpi": 300, "bbox": [452, 373, 728, 583], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Cyber Attack Monitor System", "caption_bbox": [465, 610, 711, 627]}, {"image_id": 2, "file_name": "88_02.png", "page": 3, "dpi": 300, "bbox": [139, 121, 694, 608], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: STARMINE Visualization", "caption_bbox": [305, 613, 526, 630]}, {"image_id": 3, "file_name": "88_03.png", "page": 3, "dpi": 300, "bbox": [97, 726, 415, 813], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Selecting an attack \u2013 Figure indicates: (1) amount of attack, (2) relative percentage of attacks, (3) name of attack ", "caption_bbox": [83, 840, 405, 884]}, {"image_id": 4, "file_name": "88_04.png", "page": 4, "dpi": 300, "bbox": [102, 150, 731, 604], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Information flow.", "caption_bbox": [332, 613, 499, 630]}, {"image_id": 5, "file_name": "88_05.png", "page": 5, "dpi": 300, "bbox": [109, 455, 384, 713], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Map View", "caption_bbox": [181, 730, 306, 747]}, {"image_id": 6, "file_name": "88_06.png", "page": 5, "dpi": 300, "bbox": [436, 384, 746, 554], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Visualizing Sasser worm (May 2004)", "caption_bbox": [447, 573, 730, 590]}, {"image_id": 7, "file_name": "88_07.png", "page": 5, "dpi": 300, "bbox": [439, 111, 743, 284], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Visualizing Sasser worm (April 2004)", "caption_bbox": [444, 298, 732, 315]}, {"image_id": 8, "file_name": "88_08.png", "page": 5, "dpi": 300, "bbox": [127, 116, 369, 358], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Globe View", "caption_bbox": [177, 377, 310, 394]}, {"image_id": 9, "file_name": "88_09.png", "page": 6, "dpi": 300, "bbox": [83, 586, 752, 1043], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Visualizing Blaster worm (March 2004)", "caption_bbox": [262, 1068, 570, 1085]}, {"image_id": 10, "file_name": "88_10.png", "page": 6, "dpi": 300, "bbox": [91, 68, 756, 504], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Visualizing Welchia worm (March 2004)", "caption_bbox": [260, 543, 572, 560]}], "89": [{"image_id": 0, "file_name": "89_00.png", "page": 3, "dpi": 300, "bbox": [421, 743, 746, 874], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Visualization of the Loadings matrix W for               a demographical data set ", "caption_bbox": [426, 883, 741, 915]}, {"image_id": 1, "file_name": "89_01.png", "page": 3, "dpi": 300, "bbox": [89, 95, 723, 203], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The visualization process, adapted from (Santos and Brodlie, 2004)", "caption_bbox": [182, 213, 638, 230]}, {"image_id": 2, "file_name": "89_02.png", "page": 4, "dpi": 300, "bbox": [98, 769, 728, 1059], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Data table visualization of the demographic data set (with table lens, see Kreuseler (2002))", "caption_bbox": [116, 1068, 709, 1085]}, {"image_id": 3, "file_name": "89_03.png", "page": 5, "dpi": 300, "bbox": [78, 82, 407, 225], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Normalized loadings visualization of the              demographic data set ", "caption_bbox": [92, 234, 389, 266]}, {"image_id": 4, "file_name": "89_04.png", "page": 5, "dpi": 300, "bbox": [78, 663, 406, 994], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "   Figure 5: Scatterplot matrix of a subspace of the demographic data set; countries with high death rate, low birth rate, high literacy and high life expectation  highlighted (all are former east European countries) ", "caption_bbox": [81, 1002, 400, 1065]}, {"image_id": 5, "file_name": "89_05.png", "page": 5, "dpi": 300, "bbox": [423, 410, 747, 735], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Scatter plot matrix with the first three              principal components ", "caption_bbox": [441, 744, 727, 776]}, {"image_id": 6, "file_name": "89_06.png", "page": 6, "dpi": 300, "bbox": [423, 710, 747, 1034], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Scatter plot relating the first PC to the      variables literacy and life expectation ", "caption_bbox": [440, 1043, 727, 1075]}, {"image_id": 7, "file_name": "89_07.png", "page": 6, "dpi": 300, "bbox": [197, 83, 629, 445], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Table visualization of the normalized PC scores of the demographic data set ordered by the first PC", "caption_bbox": [87, 454, 737, 471]}, {"image_id": 8, "file_name": "89_08.png", "page": 7, "dpi": 300, "bbox": [230, 88, 598, 351], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Spatial visualization of the first PC of the demographic data set (cutout of Asian countries;                      PC1 is represented by a colored circle at the capital location ", "caption_bbox": [114, 361, 710, 393]}, {"image_id": 9, "file_name": "89_09.png", "page": 7, "dpi": 300, "bbox": [172, 672, 655, 1058], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Scatter plot matrix of the original demographic data set with PC1 directions", "caption_bbox": [154, 1067, 671, 1084]}, {"image_id": 10, "file_name": "89_10.png", "page": 8, "dpi": 300, "bbox": [160, 79, 661, 334], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Example of Brushing& Linking utilizing PCA score data. Selecting high PC score values in the table view allows to link extreme values with respect to a prominent trend in the data with original data (scatter plot               visualization of the variables literacy (y-axis), GDP (x-axis) and population (color)) ", "caption_bbox": [83, 348, 742, 396]}, {"image_id": 11, "file_name": "89_11.png", "page": 8, "dpi": 300, "bbox": [138, 637, 689, 1004], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Table Visualization with adapted table lens function", "caption_bbox": [225, 1012, 600, 1029]}, {"image_id": 12, "file_name": "89_12.png", "page": 9, "dpi": 300, "bbox": [78, 743, 405, 1003], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": " Figure 14: ShapeVis visualization of data objects in  PC space using enriched labeling with data variable names (mapping objects to 2D locations using a spring        model, see Theisel and Kreuseler, 2002) ", "caption_bbox": [79, 1011, 402, 1074]}, {"image_id": 13, "file_name": "89_13.png", "page": 9, "dpi": 300, "bbox": [78, 86, 406, 292], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 13: Data table visualization of the demographic             data set, reordered by first PC          (with table lens, see Kreuseler, 2002) ", "caption_bbox": [78, 291, 403, 339]}], "90": [{"image_id": 0, "file_name": "90_00.png", "page": 4, "dpi": 300, "bbox": [82, 557, 753, 1061], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The Co-GDHints graphical user interface", "caption_bbox": [260, 1070, 572, 1087]}, {"image_id": 1, "file_name": "90_01.png", "page": 4, "dpi": 300, "bbox": [82, 60, 753, 509], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: The Co-UserHints framework", "caption_bbox": [296, 518, 536, 535]}], "91": [{"image_id": 0, "file_name": "91_00.png", "page": 1, "dpi": 300, "bbox": [435, 572, 743, 827], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Screenshot of NeL2", "caption_bbox": [499, 837, 677, 855]}, {"image_id": 1, "file_name": "91_01.png", "page": 2, "dpi": 300, "bbox": [435, 82, 743, 336], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Diagram before difference layer is added", "caption_bbox": [435, 348, 741, 365]}, {"image_id": 2, "file_name": "91_02.png", "page": 2, "dpi": 300, "bbox": [97, 632, 406, 1038], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Concept of layered structure", "caption_bbox": [126, 1053, 361, 1070]}, {"image_id": 3, "file_name": "91_03.png", "page": 2, "dpi": 300, "bbox": [435, 432, 743, 686], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Difference layer", "caption_bbox": [510, 697, 666, 714]}, {"image_id": 4, "file_name": "91_04.png", "page": 2, "dpi": 300, "bbox": [435, 781, 743, 1035], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Diagram after difference layer is added", "caption_bbox": [439, 1047, 736, 1064]}, {"image_id": 5, "file_name": "91_05.png", "page": 4, "dpi": 300, "bbox": [427, 103, 751, 507], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Sliders", "caption_bbox": [537, 519, 640, 536]}, {"image_id": 6, "file_name": "91_06.png", "page": 5, "dpi": 300, "bbox": [150, 602, 683, 1040], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Change visible state of some layers", "caption_bbox": [279, 1051, 553, 1068]}, {"image_id": 7, "file_name": "91_07.png", "page": 5, "dpi": 300, "bbox": [150, 77, 683, 516], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Co-authorship network diagram", "caption_bbox": [288, 527, 543, 544]}, {"image_id": 8, "file_name": "91_08.png", "page": 6, "dpi": 300, "bbox": [90, 806, 399, 1060], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Basis node Jiro Tanaka appears in 1983", "caption_bbox": [88, 1071, 398, 1088]}, {"image_id": 9, "file_name": "91_09.png", "page": 6, "dpi": 300, "bbox": [435, 53, 743, 307], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Communities build up", "caption_bbox": [486, 318, 690, 335]}], "92": [{"image_id": 0, "file_name": "92_00.png", "page": 1, "dpi": 300, "bbox": [460, 813, 718, 921], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Feature 1", "caption_bbox": [528, 945, 648, 962]}, {"image_id": 1, "file_name": "92_01.png", "page": 2, "dpi": 300, "bbox": [82, 369, 415, 631], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: \u00b0Search           1       query, \u00b0GoogleAPI,                          2           \u00b0Search                                       3         re- sults, \u00b0Analyzes        4         Web pages and conducts clustering, ", "caption_bbox": [83, 659, 405, 689]}, {"image_id": 2, "file_name": "92_02.png", "page": 3, "dpi": 300, "bbox": [141, 112, 746, 559], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Movement of focus.", "caption_bbox": [326, 567, 506, 584]}, {"image_id": 3, "file_name": "92_03.png", "page": 3, "dpi": 300, "bbox": [93, 711, 780, 1009], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Improved display interface.", "caption_bbox": [303, 1018, 529, 1035]}, {"image_id": 4, "file_name": "92_04.png", "page": 4, "dpi": 300, "bbox": [98, 53, 389, 236], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Relationship between clusters and labels.", "caption_bbox": [88, 260, 399, 277]}, {"image_id": 5, "file_name": "92_05.png", "page": 5, "dpi": 300, "bbox": [203, 844, 630, 1034], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Partial tree related to \u201dTextbook.\u201d", "caption_bbox": [279, 1058, 553, 1075]}, {"image_id": 6, "file_name": "92_06.png", "page": 5, "dpi": 300, "bbox": [219, 573, 612, 755], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Partial tree related to \u201dGeography.\u201d", "caption_bbox": [275, 779, 556, 796]}, {"image_id": 7, "file_name": "92_07.png", "page": 5, "dpi": 300, "bbox": [189, 73, 647, 486], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Presentation screen of our system for search query, \u201dJapan, History.\u201d", "caption_bbox": [175, 510, 657, 527]}], "93": [{"image_id": 0, "file_name": "93_00.png", "page": 4, "dpi": 300, "bbox": [437, 53, 744, 340], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Table of papers by Year (x-axis) and re- search area (y-axis). The research areas are arranged by their burst in activity. ", "caption_bbox": [427, 356, 749, 400]}, {"image_id": 1, "file_name": "93_01.png", "page": 4, "dpi": 300, "bbox": [89, 361, 399, 643], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Table of Papers by Year (x-axis) and au- thors (y-axis). The authors are arranged by their im- portance. Each rectangle represents a paper. Each segment within a rectangle represents an author of the paper. Selected authors are color-coded. ", "caption_bbox": [83, 655, 405, 727]}, {"image_id": 2, "file_name": "93_02.png", "page": 5, "dpi": 300, "bbox": [437, 56, 744, 284], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: User can choose to view the network from the top (2D view) or from an oblique angle (3D view). ", "caption_bbox": [427, 297, 749, 327]}, {"image_id": 3, "file_name": "93_03.png", "page": 5, "dpi": 300, "bbox": [89, 212, 397, 463], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Network View of selected papers. Papers are placed by research areas using SOM. ", "caption_bbox": [83, 476, 405, 506]}, {"image_id": 4, "file_name": "93_04.png", "page": 5, "dpi": 300, "bbox": [95, 535, 393, 803], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Network View of selected authors. Au- thors are placed according to their collaborations us- ing force-directed layout methods. ", "caption_bbox": [83, 818, 405, 862]}, {"image_id": 5, "file_name": "93_05.png", "page": 5, "dpi": 300, "bbox": [434, 624, 743, 842], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Double view mode layout. The Network View is shown above the Table View. Clicking on a node in one view will highlight the node in both views, as well as display the paper details. ", "caption_bbox": [427, 854, 749, 912]}, {"image_id": 6, "file_name": "93_06.png", "page": 7, "dpi": 300, "bbox": [82, 54, 751, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: The Table View of authors, showing all authors in the dataset. There are too many authors and papers to discern detailed information, so we allow filtering and focus+context through the user interface. ", "caption_bbox": [83, 544, 749, 574]}, {"image_id": 7, "file_name": "93_07.png", "page": 8, "dpi": 300, "bbox": [82, 53, 751, 533], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Table View of top 10 most widely cited authors in last 20 years. Stuart Card is deemed the most widely cited author in this period, followed by Jock Mackinlay and Ben Shneiderman. ", "caption_bbox": [83, 544, 749, 574]}, {"image_id": 8, "file_name": "93_08.png", "page": 9, "dpi": 300, "bbox": [82, 54, 751, 534], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Table View of authors. One of Ben Shneiderman\u2019s papers: \u201cTreemaps: A Space-Filling Approach to the Visualization of Hierarchical Information Structures.\u201d is highlighted. ", "caption_bbox": [83, 545, 749, 575]}, {"image_id": 9, "file_name": "93_09.png", "page": 10, "dpi": 300, "bbox": [197, 603, 627, 1050], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: The dual-plane view shows Ben Shneiderman\u2019s main research area is \u201cuser interface.\u201d", "caption_bbox": [122, 1062, 711, 1079]}, {"image_id": 10, "file_name": "93_10.png", "page": 10, "dpi": 300, "bbox": [82, 67, 751, 536], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: The Network View of authors shows that Card and Mackinlay are closely connected to Shneiderman.", "caption_bbox": [83, 549, 749, 566]}], "94": [{"image_id": 0, "file_name": "94_00.png", "page": 1, "dpi": 300, "bbox": [493, 401, 685, 685], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Examples of both graphs", "caption_bbox": [483, 690, 691, 707]}, {"image_id": 1, "file_name": "94_01.png", "page": 2, "dpi": 300, "bbox": [108, 182, 371, 309], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: Structure of TI and DI", "caption_bbox": [143, 315, 333, 333]}, {"image_id": 2, "file_name": "94_02.png", "page": 2, "dpi": 300, "bbox": [427, 193, 750, 589], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Springs of Type A", "caption_bbox": [503, 594, 671, 611]}, {"image_id": 3, "file_name": "94_03.png", "page": 2, "dpi": 300, "bbox": [539, 742, 637, 840], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Springs of Type B", "caption_bbox": [503, 846, 670, 863]}, {"image_id": 4, "file_name": "94_04.png", "page": 2, "dpi": 300, "bbox": [522, 913, 652, 1027], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Springs of Type C", "caption_bbox": [503, 1036, 671, 1053]}, {"image_id": 5, "file_name": "94_05.png", "page": 3, "dpi": 300, "bbox": [125, 803, 353, 934], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Placement of a shared vertex", "caption_bbox": [123, 940, 354, 957]}, {"image_id": 6, "file_name": "94_06.png", "page": 3, "dpi": 300, "bbox": [78, 339, 401, 557], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6 shows four types of electric forces.", "caption_bbox": [78, 562, 325, 579]}, {"image_id": 7, "file_name": "94_07.png", "page": 3, "dpi": 300, "bbox": [118, 586, 357, 751], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Four types of electric forces", "caption_bbox": [126, 755, 350, 772]}, {"image_id": 8, "file_name": "94_08.png", "page": 4, "dpi": 300, "bbox": [198, 81, 647, 456], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: OWL example", "caption_bbox": [339, 461, 486, 478]}], "95": [], "96": [{"image_id": 0, "file_name": "96_00.png", "page": 2, "dpi": 300, "bbox": [436, 369, 730, 522], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A rectangular grid and a four frequency icosahedron. ", "caption_bbox": [427, 535, 749, 563]}, {"image_id": 1, "file_name": "96_01.png", "page": 2, "dpi": 300, "bbox": [117, 687, 368, 881], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Left: Projection using Principle Component Analysis; Right: Projection using Self-Organizing Map. ", "caption_bbox": [83, 899, 405, 941]}, {"image_id": 2, "file_name": "96_02.png", "page": 3, "dpi": 300, "bbox": [107, 55, 376, 653], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: (a)The data set contains 7 clusters; (b) The GeoSOM; (c)The 2D SOM. ", "caption_bbox": [83, 672, 405, 700]}, {"image_id": 3, "file_name": "96_03.png", "page": 3, "dpi": 300, "bbox": [440, 376, 743, 611], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Linear initialization of the GeoSOM.", "caption_bbox": [446, 625, 731, 639]}, {"image_id": 4, "file_name": "96_04.png", "page": 4, "dpi": 300, "bbox": [119, 383, 367, 918], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Two views of the GeoSOM trained with the world traded data set for 30 epochs. ", "caption_bbox": [83, 936, 405, 964]}, {"image_id": 5, "file_name": "96_05.png", "page": 4, "dpi": 300, "bbox": [462, 280, 711, 526], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: The small red spheres shows the positions where nodes at each neurons can be placed. ", "caption_bbox": [427, 543, 749, 571]}, {"image_id": 6, "file_name": "96_06.png", "page": 5, "dpi": 300, "bbox": [467, 782, 712, 1024], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Distance between a node and an edge on the sphere ", "caption_bbox": [427, 1040, 749, 1068]}, {"image_id": 7, "file_name": "96_07.png", "page": 5, "dpi": 300, "bbox": [118, 581, 367, 806], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Calculate the intersection point of two edges on the sphere. ", "caption_bbox": [83, 824, 405, 852]}, {"image_id": 8, "file_name": "96_08.png", "page": 5, "dpi": 300, "bbox": [499, 188, 675, 364], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Check whether the intersection point E is inside edge AB. ", "caption_bbox": [427, 380, 749, 408]}, {"image_id": 9, "file_name": "96_09.png", "page": 6, "dpi": 300, "bbox": [445, 223, 728, 493], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 11: Select two point on the sphere. The first point A will be the center of the projection. The second point B and A defined the central axis and the split line to open the sphere. ", "caption_bbox": [427, 509, 749, 565]}, {"image_id": 10, "file_name": "96_10.png", "page": 6, "dpi": 300, "bbox": [117, 258, 370, 804], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Final layout of the world trade network.", "caption_bbox": [87, 822, 400, 836]}, {"image_id": 11, "file_name": "96_11.png", "page": 7, "dpi": 300, "bbox": [127, 56, 700, 344], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 12: Project the spherical image on to 2D plane such that user can have a global view of the data set. Mexico is chosen to be the center of projection. ", "caption_bbox": [83, 364, 749, 392]}], "97": [{"image_id": 0, "file_name": "97_00.png", "page": 1, "dpi": 300, "bbox": [450, 277, 727, 653], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Geography of the Sydney Cityrail network.", "caption_bbox": [427, 667, 749, 684]}, {"image_id": 1, "file_name": "97_01.png", "page": 2, "dpi": 300, "bbox": [82, 53, 407, 332], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: A force-directed graph layout.", "caption_bbox": [121, 343, 366, 360]}, {"image_id": 2, "file_name": "97_02.png", "page": 4, "dpi": 300, "bbox": [427, 53, 751, 369], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: Initial layout of RG2.", "caption_bbox": [494, 380, 682, 397]}, {"image_id": 3, "file_name": "97_03.png", "page": 4, "dpi": 300, "bbox": [82, 799, 407, 1018], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: Geography of the London Underground net- work. ", "caption_bbox": [83, 1036, 405, 1066]}, {"image_id": 4, "file_name": "97_04.png", "page": 6, "dpi": 300, "bbox": [136, 76, 704, 986], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Scaling results for Sydney Cityrail: (a) square root degree, (b) linear degree, (c) quadratic degree, (d) square root betweenness, (e) linear betweenness, (f) quadratic betweenness, (g) square root hubness, (h) linear hubness, (i) quadratic hubness. ", "caption_bbox": [83, 1012, 749, 1056]}, {"image_id": 5, "file_name": "97_05.png", "page": 7, "dpi": 300, "bbox": [82, 260, 751, 815], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Scaling results for London Underground: (a) square root degree, (b) linear degree, (c) quadratic degree, (d) square root betweenness, (e) linear betweenness, (f) quadratic betweenness, (g) square root hubness, (h) linear hubness, (i) quadratic hubness. ", "caption_bbox": [83, 836, 749, 880]}, {"image_id": 6, "file_name": "97_06.png", "page": 8, "dpi": 300, "bbox": [82, 252, 751, 815], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 7: Scaling results for RG1: (a) square root degree, (b) linear degree, (c) quadratic degree, (d) square root betweenness, (e) linear betweenness, (f) quadratic betweenness, (g) square root hubness, (h) linear hubness, (i) quadratic hubness. ", "caption_bbox": [83, 836, 749, 880]}, {"image_id": 7, "file_name": "97_07.png", "page": 9, "dpi": 300, "bbox": [110, 252, 729, 815], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 8: Scaling results for RG2: (a) square root degree, (b) linear degree, (c) quadratic degree, (d) square root betweenness, (e) linear betweenness, (f) quadratic betweenness, (g) square root hubness, (h) linear hubness, (i) quadratic hubness. ", "caption_bbox": [83, 836, 749, 880]}, {"image_id": 8, "file_name": "97_08.png", "page": 10, "dpi": 300, "bbox": [91, 733, 745, 990], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 10: Schematised versions of the London Underground network: (a) schematised original geography, (b) schematised linear betweenness scaling. ", "caption_bbox": [83, 1024, 749, 1054]}, {"image_id": 9, "file_name": "97_09.png", "page": 10, "dpi": 300, "bbox": [98, 89, 731, 561], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 9: Schematised versions of the Sydney Cityrail network: (a) schematised original geography, (b) schema- tised quadratic hubness scaling. ", "caption_bbox": [83, 624, 749, 654]}], "98": [{"image_id": 0, "file_name": "98_00.png", "page": 2, "dpi": 300, "bbox": [100, 566, 384, 677], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Table 1. Quantity of data per second and sample rates.", "caption_bbox": [88, 1037, 394, 1052]}, {"image_id": 1, "file_name": "98_01.png", "page": 3, "dpi": 300, "bbox": [93, 416, 391, 657], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "  Figure 2. Visualization types of signal data : (a) Line graph visualization, (b) Pseudo color image visualization,   (c) Three-dimensional surface visualization, (d) Polar                     view visualization. ", "caption_bbox": [78, 667, 403, 729]}, {"image_id": 2, "file_name": "98_02.png", "page": 3, "dpi": 300, "bbox": [445, 543, 726, 654], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3. Fisheye View : (a) Regular intervals and new   intervals. (b) Visualization using line graph applied                       fisheye view. ", "caption_bbox": [429, 663, 740, 709]}, {"image_id": 3, "file_name": "98_03.png", "page": 4, "dpi": 300, "bbox": [166, 936, 318, 1056], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5. User-defined multiple windows.", "caption_bbox": [122, 1063, 360, 1078]}, {"image_id": 4, "file_name": "98_04.png", "page": 4, "dpi": 300, "bbox": [150, 386, 404, 626], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4. Line graph, Histogram view and Wave view.", "caption_bbox": [86, 634, 395, 649]}], "99": [{"image_id": 0, "file_name": "99_00.png", "page": 1, "dpi": 300, "bbox": [426, 696, 746, 875], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 1: Conceptual architecture of the systemD2MS", "caption_bbox": [447, 888, 721, 904]}, {"image_id": 1, "file_name": "99_01.png", "page": 2, "dpi": 300, "bbox": [85, 333, 405, 554], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 2: The idea of user-centered system in D2MS and the                    visualization support ", "caption_bbox": [88, 559, 393, 589]}, {"image_id": 2, "file_name": "99_02.png", "page": 2, "dpi": 300, "bbox": [428, 338, 742, 582], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 3: View an individual rule in D2MS: top-left window shows the list of discovered rules, the middle-left and the top-right windows show a rule under inspection, and bottom window displays the instances covered by that rule. ", "caption_bbox": [421, 590, 747, 649]}, {"image_id": 3, "file_name": "99_03.png", "page": 3, "dpi": 300, "bbox": [78, 385, 406, 645], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 4: A rule viewed in its relations with others.", "caption_bbox": [111, 649, 370, 665]}, {"image_id": 4, "file_name": "99_04.png", "page": 3, "dpi": 300, "bbox": [78, 686, 408, 915], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 5: Visualization of rule No.2 for class LC", "caption_bbox": [118, 917, 364, 933]}, {"image_id": 5, "file_name": "99_05.png", "page": 4, "dpi": 300, "bbox": [76, 257, 397, 472], "visualization_bbox": {}, "nums_of_visualizations": {}, "caption_text": "Figure 6: Rules that contain\u201cGPT=H\u201d in the precedent part, obtained by a double click on node \u201cGPT=H\u201d in Figure 10. ", "caption_bbox": [78, 479, 403, 509]}]}